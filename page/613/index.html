<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta name="generator" content="Hugo 0.133.1">
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="编程大咖的博客">
		<meta property="og:url" content="https://bcdaka.github.io/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="编程大咖">
  <meta property="og:description" content="编程大咖的博客">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="website">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	
	<link rel="alternate" type="application/rss+xml" href="/index.xml" title="编程大咖">

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main list" role="main">
	<article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/28c18dafd054c2d0a1174d1037ab0718/" rel="bookmark">
			百度文心一言对标 ChatGPT，你怎么看？
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		文心一言 VS ChatGPT接受不完美 期待进步里程碑意义文心一言初体验✔ 文学创作✔ 商业文案创作✔ 数理逻辑推算✔ 中文理解✔ 多模态生成 写在最后 何为文心？“文”就是我们中华语言文字中的文，“心”是希望该语言模型可以用心的去理解语言，用心的去服务用户。
在近期全球陷入 ChatGPT 技术狂欢的同时，中国也有了对标 ChatGPT 的大预言模型。随着百度文心一言发布会的召开，我认真了观看了整个过程。作为一款百度十几年研发投入积累所得的产品，作为“中国版 ChatGPT”，我对它有着浓厚的兴趣，且第一时间申请了体验资格，参与到测试当中。
文心一言 VS ChatGPT 最近在网上经常性的看到这么一张图片，就是将文心一言与 ChatGPT 进行对比，而且差距显而易见。此外在某些站点也可以看到文心一言被“群嘲”。
近期全球陷入 ChatGPT 技术狂欢，ChatGPT 作为 OpenAI 开发的人工智能语言模型，由文本生成对话的训练数据驱动，与其他人工智能技术相比，ChatGPT 可以生成更为自然、流畅的语言回答，这确实是它最大的优势之一。而有人就将此优势拿去对比国内新发布的文心一言，矛头直指文心一言的种种不成熟。但我们可能忽略了一点，每个人工智能技术都有其独特的优势和适用场景。比如 AlphaGo 围棋机器学习模型可能在下棋方面表现出色，而像“聊天机器人”这样的技术则更适合于帮助人们进行自然的对话交流。因此将 ChatGPT 与其他人工智能技术进行比较可能需要考虑到多个因素，而不仅仅是它们的语言生成能力。
如果说非要以己之长比其之短，那么在中文与中华文化的理解上，ChatGPT 与文心一言就没得比，相信有很多人在中文语境下体验 ChatGPT 时也体会到过它“人工智障”的时候吧，那这又怎么说？
其实我想说的是每个语言模型都有自己的优势和适用环境，它们的设计目标是一致的，都是为了辅助人、帮助人、为人类提供更好的服务。所以在看待文心一言的问题上，我们不能仅仅将关注焦点聚集在在文心一言的瑕疵和不成熟上，而是应当站在更加长远且更加全面的角度来看待它。
接受不完美 期待进步 很喜欢李彦宏董事长在发布会上讲的那句话：“我们在使用的过程中有时候会感受到惊喜，有时候可能也会发现明显的错误，但有一点是可以肯定的，它的进步速度会非常快。”他本人也指出自己在体验过程当中，文心一言的能力不能叫做完美。
其实没有哪一个技术、哪一款产品是完美的，更何况这是第一代版本，它的发布则可以获得用户的反馈，迭代速度会加快，能力也会不断的成长与提升。即使有不完美，从现在的发展情况来看，文心一言也是国内互联网大厂中唯一成熟的产品，靠文心一言百度就已经证明了其在人工智能领域、在互联网行业当中的地位。
里程碑意义 随着文心一言语言模型的发布，无疑会对国内科技产业的发展产生带动作用，诸多同类型商业化产品也将会出现。其次在发布会上也提到，文心一言是百度十几年的研发投入积累、持续精耕的产物，这体现着百度在 AI 上的长期坚持。
在我看来，文心一言在国内人工智能领域具有里程碑式的意义，这不仅在于技术水平，更在于人工智能发展理念、对待 AI 的理念。当我们能够认识到这一层，就会发现仅仅去关注文心一言产品本身、仅仅拿它与同类型产品相比较就有点舍本求末了。借用网上的一句话：无需完美，已然具备里程碑意义！
文心一言初体验 文心一言的能力定位主要在于五个方面：文学创作、商业文案创作、数理逻辑推算、中文理解、多模态生成。
✔ 文学创作 从哲学角度续写《流浪地球》，文心一言提出了一些可能的思考方向，且提醒用户注意遵循小说的创作原则和规范。体现出文心一言的总结分析和推理能力，这是基于 5500 亿事实数据训练才得以保证事实性问题的准确性。
✔ 商业文案创作 如果说文学创作体现的是总结分析能力，那么商业文案的创作则是其理解表达、创新创意能力的展现。这种能力我们是没有办法专门去教语言模型的，正如“读书破万卷”，想要“满腹经纶、学识渊博”也得是在大量学习的基础之上，AI 语言模型基于的知识量更是不计其数。
✔ 数理逻辑推算 根据发布会的介绍来看，文心一言大模型训练数据包含万亿级的网页数据、数十亿搜索数据和图片数据、百亿级的语音日均调用数据，以及 5500 亿事实知识积累。所以在梳理逻辑推算方面，它给出答案的同时还能够做到对解题思路的一步步推理。
✔ 中文理解 作为植根于中国市场的语言模型，它对于中文和中华文化的理解能力也是相当高，相较于在中文语境下的 ChatGPT 有时会出现“人工智障”式的表现，文心一言则不会产生类似问题，毕竟百度对于中文语言的处理还是有明显优势的，对于国人的适用性来说，文心一言绝对优于 ChatGPT。
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/28c18dafd054c2d0a1174d1037ab0718/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/90a3e9489fa46d051167cff28b6b746d/" rel="bookmark">
			【AI大比拼】文心一言 VS ChatGPT-4
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		摘要：本文将对比分析两款知名的 AI 对话引擎：文心一言和 OpenAI 的 ChatGPT，通过实际案例让大家对这两款对话引擎有更深入的了解，以便大家选择合适的 AI 对话引擎。
亲爱的 CSDN 朋友们，大家好！近年来，随着人工智能技术的迅猛发展，AI 对话引擎越来越受到关注。今天，我们将带大家一起了解两款知名的 AI 对话引擎：文心一言和 OpenAI 的 ChatGPT，并通过实际案例让大家对这两款对话引擎有更深入的了解。
一、文心一言简介 文心一言是国内一款较为知名的 AI 对话引擎，它基于深度学习技术，能够理解自然语言并生成相应的回复。无论是对话机器人、问答系统还是自动撰写文章等应用场景，文心一言都能为开发者提供强大的支持。
文心一言案例：
用户：“世界上最高的山是什么？” 文心一言回复：“世界上最高的山是珠穆朗玛峰，位于尼泊尔和中国边境，海拔高度为 8,848 米。”
二、ChatGPT-4 简介 ChatGPT 是 OpenAI 推出的一款基于 GPT-4 架构的 AI 对话引擎。它具有强大的自然语言理解和生成能力，在各种对话场景中表现出色。从技术问答到闲聊对话，ChatGPT 都能为开发者提供优秀的解决方案。
ChatGPT 案例：
用户：“如何将 Python 列表转换为字符串？” ChatGPT 回复：“要将 Python 列表转换为字符串，可以使用 join 方法。假设你的列表名为 'my_list'，可以使用以下代码：''.join(map(str, my_list))...”
三、文心一言 VS ChatGPT-4 以上就是本次对文心一言和 ChatGPT 的比较分析，希望对大家有所帮助。在未来的 AI 对话引擎发展中，我们期待看到更多优秀的产品为我们带来更智能、更便捷的生活体验。欢迎大家在评论区留下你们的见解和经验，我们一起交流学习！
四、总结 文心一言和 ChatGPT 都是优秀的 AI 对话引擎，各自具有不同的优势。在选择时，开发者可以根据自身需求和项目特点进行考虑。如果你的项目主要针对中文市场，那么文心一言可能会更适合你；而如果你的项目需要处理英文对话或在国际市场上应用，那么 ChatGPT 可能会更适合。
语言支持：文心一言以中文为主，对中文语境和语法有更好的把握；而 ChatGPT 以英文为主，对英文语境和语法有更好的理解。
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/90a3e9489fa46d051167cff28b6b746d/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/33c185a5850f57034c1d3e5c10f53deb/" rel="bookmark">
			深度解析预训练权重的本质和作用：你真的了解它们吗？
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		文章目录 🌟写在前面🌟预训练权重的本质是什么？🌟为什么要使用预训练权重？🌟预训练权重会影响模型的性能吗？🌟改进自定义模型是否需要使用预训练权重？改变了网络结构后，预训练权重还有作用吗？🌟当我改变了结构后，依然使用原始的预训练权重会有哪些弊端呢？🌟在进行YOLOv5算法改进对比时，我可以都不使用权重吗？🌟如何预训练一个权重呢？预训练的大数据集必须和我的小数据集相似吗?🌟模型冻结训练是什么？有什么作用？🌟冻结训练和权重之间有什么关系？ 🌟写在前面 在这篇博客中，你将了解预训练权重的本质、为什么要使用它们以及它们对模型性能的影响。你将了解到在改进自定义模型时是否需要使用预训练权重，以及当你改变模型结构时使用原始预训练权重可能会产生的弊端。同时，你也将学习如何预训练一个权重，以及预训练的大数据集是否必须与你的小数据集相似。此外，你还将了解模型冻结训练的含义和作用，以及冻结训练和权重之间的关系。在本文中，我们还将通过对比改进YOLOv5算法的过程，探讨是否有必要使用预训练权重，并解释什么情况下可以不使用。
🌟预训练权重的本质是什么？ 预训练权重本质上是已经训练好的模型参数。在深度学习中，模型的参数通常以一些权重矩阵和偏置向量的形式存在，这些权重和偏置是通过反向传播算法从大量的训练数据中学习得到的。
预训练权重是在大规模数据集上训练的深度学习模型的参数。这些数据集通常包括数百万或数十亿的图像或文本数据，例如ImageNet、COCO、Wikipedia等。通过在这些数据集上训练模型，可以学习到一些通用的特征和模式，这些特征和模式可以被转移到其他任务中，例如物体检测、图像分割、自然语言处理等。
在预训练过程中，深度学习模型通过学习数据中的特征和模式来调整其参数，使其能够更好地拟合数据。当预训练过程结束后，将生成一组最优的模型参数（即权重矩阵和偏置向量），这些参数可以用于其他任务的初始值，从而加速模型的训练过程和提高模型的性能。
预训练权重可以被用来初始化模型参数，从而提高模型在目标检测任务上的性能。但需要注意的是，预训练权重通常是基于先前的模型结构训练的，如果您更改了模型结构，则可能需要重新训练模型或者微调预训练权重。
🌟为什么要使用预训练权重？ 使用预训练权重的核心思想是利用大规模数据集上训练得到的通用特征来初始化或微调新的神经网络模型。这些通用特征可以转移至新的任务中，从而提高模型的性能和泛化能力。
具体来说，使用预训练权重可以达到以下几个效果：
初始化网络参数：在使用神经网络训练新任务之前，通常需要随机初始化神经网络的参数。这样的话，神经网络会在新的数据上进行训练，并逐渐适应新的任务。但是，随机初始化的参数可能无法充分利用预训练模型已经学到的知识。因此，使用预训练权重可以更好地初始化神经网络的参数，从而更好地利用预训练模型学到的通用特征，加速模型训练并提高模型性能。微调模型：使用预训练权重可以进行微调，即通过在新的数据集上继续训练预训练模型，从而更好地适应新的任务。微调可以进一步提高模型的性能，并且可以减少过拟合风险。增强泛化能力：预训练模型已经在大规模数据集上进行了训练，并且学习到了很多通用特征，这些特征对于许多不同的任务都是有用的。因此，使用预训练权重可以增强模型的泛化能力，使其在不同的任务上表现更好。 总之，使用预训练权重可以更好地初始化神经网络参数，进行微调以适应新的任务，增强模型的泛化能力，并加速模型训练。
🌟预训练权重会影响模型的性能吗？ 预训练权重可以对模型的性能产生重要的影响。这是因为预训练权重是基于大规模数据集训练的深度学习模型的参数，可以为目标检测等任务提供有用的先验知识，从而加速模型的收敛速度和提高模型的性能。
使用预训练权重时，预训练模型已经学习到一些通用的特征和模式，可以作为目标检测任务中的初始值，从而减少训练时间和训练数据的需要。此外，预训练模型已经学习到一些常见的图像特征和模式，可以帮助模型更好地识别目标对象，并提高目标检测的准确性。
当然，预训练权重对模型性能的影响也取决于预训练模型的质量和任务之间的相似性。如果预训练模型与目标检测任务相似，则使用预训练权重可以带来显著的性能提升。但是，如果预训练模型与目标检测任务不相似，则使用预训练权重可能不会带来太多好处。
此外，需要注意的是，在使用预训练权重时，如果您更改了模型结构或训练数据，可能需要进行微调或重新训练以适应新的任务。否则，预训练权重可能无法很好地适应新的任务，导致性能下降。
🌟改进自定义模型是否需要使用预训练权重？改变了网络结构后，预训练权重还有作用吗？ 为了训练自定义模型，通常需要使用大量标注好的图像数据来训练模型。但是，当可用的训练数据不够多时，可以使用预训练权重来提高模型的性能。预训练权重是在大量数据集上训练得到的模型参数，通常是针对相关任务的数据集，例如COCO数据集。使用这些预训练权重可以将模型初始化为一个已经相对较好的状态，这可以使模型更快地收敛，并提高模型的性能。
但是，当您改变网络结构时，例如添加或删除了某些层，或更改了层的参数，预训练权重可能不太适用。因为这些预训练权重通常是针对特定的网络结构训练得到的，而如果您对网络结构进行了更改，这些预训练权重可能无法准确地应用于您的新模型。此时，您可能需要重新训练模型，或者使用一些其他技术来改进模型的性能，例如迁移学习或数据增强等。
总之，预训练权重在改进模型时是有用的，但是要注意，当您改变模型的网络结构时，预训练权重可能不太适用。在这种情况下，您可能需要重新训练模型，或使用其他技术来改进模型的性能。
🌟当我改变了结构后，依然使用原始的预训练权重会有哪些弊端呢？ 当您改变自定义模型的网络结构后，如果继续使用预训练权重，可能会遇到以下问题：
预训练权重可能无法适应新的网络结构。预训练权重是基于先前的网络结构进行训练的，如果您更改了网络结构，则权重可能不太适用于您的新模型。这可能导致模型的性能下降，或者需要更长的时间来收敛。预训练权重可能不包含您添加的新层或新参数的信息。如果您添加了新层或更改了参数，这些信息可能不包含在预训练权重中。这可能导致模型无法充分利用新的信息，并可能降低模型的性能。过度拟合。如果您使用预训练权重，但没有足够的数据来支持这种权重的使用，可能会导致过度拟合。这意味着模型在训练数据上表现良好，但在未见过的数据上表现不佳。 因此，当您改变自定义模型的网络结构后，最好重新训练模型，或使用其他技术来改进模型的性能。如果您决定继续使用预训练权重，则需要小心地调整模型的参数，并进行一些调整来确保模型可以充分利用预训练权重，并且不会过度拟合。
🌟在进行YOLOv5算法改进对比时，我可以都不使用权重吗？ 当您进行YOLOv5算法改进的对比实验时，可以选择不使用预训练权重，这样可以更加公平地评估不同改进算法的性能。不使用预训练权重意味着您将完全从头开始训练模型，这将需要更多的时间和计算资源，但也可以避免预训练权重对结果的影响。
请注意，不使用预训练权重可能需要更多的训练数据和更长的训练时间来达到与使用预训练权重相当的性能。另外，如果您使用了一些新的技术来改进模型，例如新的损失函数、数据增强等，这些技术可能需要更长的时间来训练模型，并且可能需要更多的数据来充分评估它们的性能。
综上所述，不使用预训练权重可能需要更多的时间和资源来训练模型，并且可能需要更多的数据来评估不同算法的性能。但是，这也可以避免预训练权重对结果的影响，并且可以更加公平地评估不同算法的性能。
🌟如何预训练一个权重呢？预训练的大数据集必须和我的小数据集相似吗? 预训练一个权重通常需要以下步骤：
选择预训练模型：选择一个预训练模型作为基础，通常选择一些在大规模数据集上表现良好的模型，例如ResNet、VGG、MobileNet等。
选择预训练数据集：选择一个大规模数据集进行训练，例如ImageNet、COCO等。这些数据集包含大量的标注数据，可以用于训练模型的权重。
迁移学习：使用预训练模型和预训练数据集，将其应用于新的任务中。通常可以使用预训练模型的权重作为新任务的初始值，然后在新的数据集上进行微调或重新训练，以适应新的任务。
预训练数据集和目标数据集并不需要完全相似，但它们应该具有一定的相似性。例如，如果您想在一个城市的交通摄像头上进行目标检测，那么预训练数据集可以是城市景观、道路交通等相关的数据集，这些数据集可以与目标检测任务有一定的相似性。预训练模型可以学习到一些通用的特征和模式，这些特征和模式可以用于新的任务中，并且可以通过微调或重新训练进行进一步优化。
需要注意的是，预训练权重可以在很多场景中提高模型的性能，但是在某些特殊的情况下，例如数据集非常小或与预训练数据集完全不同的情况下，预训练权重可能并不是很有用。在这种情况下，可能需要从头开始训练模型，或者使用其他技术来提高模型的性能。
🌟模型冻结训练是什么？有什么作用？ 模型冻结训练(Frozen Training)是指在神经网络训练过程中，固定神经网络的某些层的权重和偏置，只对部分层进行训练的过程。通常情况下，被固定的层一般是预训练模型的前几层或所有层，这些层被认为是抽取特征的部分。
模型冻结训练的作用是提高模型的训练效率和泛化能力。具体来说，模型冻结训练可以实现以下几个方面的优化：
减少计算量：深度神经网络通常包含大量参数，导致训练过程非常耗时，尤其是在GPU等加速器上训练时。而模型冻结训练可以减少需要更新的参数数量，降低计算量和内存消耗，从而加速训练过程。避免过拟合：在训练过程中，预训练模型的前几层通常可以认为是学习到的通用特征，这些特征对于很多任务都是有用的。固定这些层的权重和偏置，可以避免它们被过度拟合到当前任务上，从而提高模型的泛化能力。避免梯度消失：在深度神经网络中，深层的参数更新通常需要通过梯度传递来实现，但在传递过程中，由于梯度经过了多个非线性激活函数，导致梯度可能会逐渐消失，使得深层参数无法得到有效更新。而模型冻结训练可以避免这个问题的发生，因为被冻结的层不会参与梯度传递。 总之，模型冻结训练可以加速模型训练、提高模型的泛化能力、避免过拟合和梯度消失等问题。当然，要根据具体任务来决定应该冻结哪些层，以获得最好的训练效果。
🌟冻结训练和权重之间有什么关系？ 模型冻结训练和权重之间是有关系的。
在深度学习中，神经网络的权重是指神经元之间的连接权重，可以理解为神经元的输出和输入之间的关系，控制神经网络的输出。而在训练神经网络时，通过不断地调整权重和偏置，使得神经网络的输出能够更好地拟合训练数据，从而提高模型的性能。
在模型冻结训练中，通常会将预训练模型的前几层或所有层的权重和偏置固定住，不参与训练。这是因为在深度神经网络中，底层的权重和偏置往往能够提取出一些通用的特征，而这些通用的特征对于很多任务都是有用的。因此，我们可以利用已经学习到的通用特征，通过冻结权重和偏置的方式来加速训练，并提高模型的泛化能力，避免过拟合等问题。
当然，如果我们的训练数据集和预训练数据集不太相似，或者模型的输入数据与预训练模型的输入数据不太相似，那么冻结权重和偏置的效果可能会有所下降。在这种情况下，我们可能需要通过微调的方式来进一步优化模型。微调是指在模型冻结训练的基础上，对部分或全部权重和偏置进行微小调整，以适应新的任务或数据集。通过微调，我们可以让预训练模型更好地适应我们的任务或数据集，提高模型的性能。
有不同观点欢迎一起讨论学习~ 互相成长~🤝
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/3fbc148c4584f308eb659c7dbd7a9b27/" rel="bookmark">
			Access denied for user  root @ localhost  (using password: YES)
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		简述：在学习ssm时，某次打开idea，发现执行数据库的操作时会报如下错误：
Connection; nested exception is java.sql.SQLException: Access denied for user 'root'@'localhost' (using password: YES) 刚开始以为是我的配置文件写错了，经过多次检查，我意识到问题并不是这个。于是我找了很多帖子，发现叫修改配置文件，或者各种方法，但是我的问题还是不能得到解决。前前后后花了3个半小时，期间还经历了重装数据库，最后我发现重装连不能解决问题（重装也会在登陆时继续报改错）。在最后的迷茫之际，终于得到了解决，方法如下：
1：打开数据库安装路径，修改配置文件 my.ini ，在[mysqld]后面添加如下内容 skip-grant-tables 2：以管理员方式打开cmd,输入如下内容回车，停止数据库服务 net stop mysql 3：使用cmd命令进入mysql安装路径下的bin文件夹中，输入如下内容即可进入数据库（不需要输入密码） mysql -u root -p 4：使用mysql数据库 use mysql; 5：将密码置空 update user set authentication_string='' where user='root'; 6：刷新权限 flush privileges; 7：设置加密规则并更新新密码，授权(直接复制这些SQL语句你的密码会更新为123456) ALTER USER 'root'@'localhost' IDENTIFIED BY '123456' PASSWORD EXPIRE NEVER; alter user 'root'@'localhost' identified by '123456'; grant all privileges on *.* to "root"@'localhost'; flush privileges; 8：打开配置文件，将刚刚插入的内容删除并保存，退出文件 9：重启数据库 net start mysql 问题应该就可以解决啦！！！ps:第一次写博客，不会排版请见谅。
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/ff093bb8c31600446a9fbf82ffdf495e/" rel="bookmark">
			ChatGLM-6B (介绍以及本地部署)
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		中文ChatGPT平替——ChatGLM-6B ChatGLM-6B简介官方实例本地部署1.下载代码2.通过conda创建虚拟环境3.修改代码4.模型量化5.详细代码 调用示例 ChatGLM-6B 简介 ChatGLM-6B 是一个开源的、支持中英双语问答的对话语言模型，基于 General Language Model (GLM) 架构，具有 62 亿参数。结合模型量化技术，用户可以在消费级的显卡上进行本地部署（INT4 量化级别下最低只需 6GB 显存）。ChatGLM-6B 使用了和 ChatGLM 相同的技术，针对中文问答和对话进行了优化。经过约 1T 标识符的中英双语训练，辅以监督微调、反馈自助、人类反馈强化学习等技术的加持，62 亿参数的 ChatGLM-6B 已经能生成相当符合人类偏好的回答。
ChatGLM 参考了 ChatGPT 的设计思路，在千亿基座模型 GLM-130B1 中注入了代码预训练，通过有监督微调（Supervised Fine-Tuning）等技术实现人类意图对齐。ChatGLM 当前版本模型的能力提升主要来源于独特的千亿基座模型 GLM-130B。它是不同于 BERT、GPT-3 以及 T5 的架构，是一个包含多目标函数的自回归预训练模型。2022年8月，我们向研究界和工业界开放了拥有1300亿参数的中英双语稠密模型 GLM-130B1，该模型有一些独特的优势：
双语： 同时支持中文和英文。高精度（英文）： 在公开的英文自然语言榜单 LAMBADA、MMLU 和 Big-bench-lite 上优于 GPT-3 175B（API: davinci，基座模型）、OPT-175B 和 BLOOM-176B。高精度（中文）： 在7个零样本 CLUE 数据集和5个零样本 FewCLUE 数据集上明显优于 ERNIE TITAN 3.0 260B 和 YUAN 1.0-245B。快速推理： 首个实现 INT4 量化的千亿模型，支持用一台 4 卡 3090 或 8 卡 2080Ti 服务器进行快速且基本无损推理。可复现性： 所有结果（超过 30 个任务）均可通过我们的开源代码和模型参数复现。跨平台： 支持在国产的海光 DCU、华为昇腾 910 和申威处理器及美国的英伟达芯片上进行训练与推理。 官方实例 &gt;&gt;&gt; from transformers import AutoTokenizer, AutoModel &gt;&gt;&gt; tokenizer = AutoTokenizer.
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/ff093bb8c31600446a9fbf82ffdf495e/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/9576dcc93cc9a40822c2f01cfae25920/" rel="bookmark">
			【Java】还不懂this关键字？一分钟彻底弄懂this关键字
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		博主简介：努力学习的预备程序媛一枚~博主主页： @是瑶瑶子啦所属专栏: Java岛冒险记【从小白到大佬之路】 前言 问题：为什么会存在this?
在上一篇【JavaSE】一文看懂构造器/构造方法（Cunstructor）中，我们已经在构造器中初步窥得this关键字的冰山一角了。大家有没有考虑过，在一个类的构造器中，我们为什么要使用this.属性而不直接使用属性呢？毕竟一个类中，不管属性被什么关键字修饰，在类中都可以访问。随着这个问题，今天瑶瑶子带大家深入分析一下Java中this关键字,让大家彻底理解this关键字.
目录 前言Part1：构造器中的this1.1初识this:1.2：为何要this? Part2：this介绍2.1：this到底是什么？ Part3:使用细节&amp;注意事项 Part1：构造器中的this 1.1初识this: public class Account { private String name; private double balance; private String pwd; //Account类的一个构造器 public Account (String name,double balance,String pwd){ //构造器的实现---初始化对象 this.name = name; this.balance = balance;	this.pwd = pwd; } } 【思考】：不用this会怎么样？ class Account { private String name; private double balance; private String pwd; //Account类的一个构造器 public Account(String name, double balance, String pwd) { //构造器的实现---初始化对象 //不用this name = name; balance = balance; pwd = pwd; } public void showInfo() { System.
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/9576dcc93cc9a40822c2f01cfae25920/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/0edce334cd2d4e7470415e1be8fe9f0c/" rel="bookmark">
			IntelliJ IDEA安装教程（超详细）
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		✅作者简介：CSDN内容合伙人、阿里云专家博主、51CTO专家博主、新星计划第三季python赛道Top1🏆
📃个人主页：
IDEA的使用 IDEA的简单介绍IDEA的主要优势IDEA的卸载IDEA的安装第一个程序：HelloWorld结束语 IDEA的简单介绍 IDEA全称IntelliJ IDEA，是Java语言对的集成开发环境，IDEA在业界被认为是公认最好的Java开发工具。
IDEA的主要优势 ✅功能强大
①强大的整合能力。比如：Git Maven Spring等
②开箱即用的体验（集成版本控制系统，多语言支持的框架随时可用，无需额外安装插件）
✅符合人体工程学
①高度智能（快速的智能代码补全 实时代码分析 可靠的重构工具）
②提示功能的快速 便捷 范围广
③好用的快捷键和代码模板
④精准搜索
IDEA的卸载 ✅这里以windows10系统为例，此电脑点击找到卸载或更改程序，找到IDEA的安装包卸载即可
✅勾选这两个选项最后点击Uninstall等待卸载完成即可
IDEA的安装 IDEA下载地址：https://www.jetbrains.com//idea/download/#section=windows
两个版本：旗舰版(ULtimate) 社区版(Community）
这里我们选择下载社区版的IDEA，因为白嫖真香😍
根据自己的操作系统对应下载，这里我们选择Windows系统的社区版本，点击Download等待下载完成
找到安装包双击下载
✅点击Next
✅这里我选择自定义安装在D盘的IDEA Community 2022.3.1文件夹下，当然也可以选择不更改直接点击Next
✅勾选这两个选项点击Next
✅最后点击Install等待下载完成即可
第一个程序：HelloWorld 写Java程序的步骤:
①创建项目(projefct)
②创建模块(module)
③创建包(package)
④创建类(class)
✅双击打开IDEA，勾选Do not import settings点击OK
✅选择New Project这里选择创建一个空的项目名为JavaBasic，最后点击创建即可
✅右键项目创建一个模块名为Hacker
✅右键模块名下面的src文件夹创建一个包名为HackerDemo
✅右键包名创建一个类名为FirstDemo
✅编写程序输出Hello World，代码如下：
package HackerDemo; public class FirstDemo { public static void main(String[] args) { System.out.println("Hello World"); } } 运行结果如下：
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/0edce334cd2d4e7470415e1be8fe9f0c/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/115043f666fcc1dc4952d06a855744fc/" rel="bookmark">
			分享Python7个爬虫小案例（附源码）
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		在这篇文章中，我们将分享7个Python爬虫的小案例，帮助大家更好地学习和了解Python爬虫的基础知识。以下是每个案例的简介和源代码：
1. 爬取豆瓣电影Top250 这个案例使用BeautifulSoup库爬取豆瓣电影Top250的电影名称、评分和评价人数等信息，并将这些信息保存到CSV文件中。
import requests from bs4 import BeautifulSoup import csv # 请求URL url = '&lt;https://movie.douban.com/top250&gt;' # 请求头部 headers = { 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36' } # 解析页面函数 def parse_html(html): soup = BeautifulSoup(html, 'lxml') movie_list = soup.find('ol', class_='grid_view').find_all('li') for movie in movie_list: title = movie.find('div', class_='hd').find('span', class_='title').get_text() rating_num = movie.find('div', class_='star').find('span', class_='rating_num').get_text() comment_num = movie.find('div', class_='star').find_all('span')[-1].get_text() writer.writerow([title, rating_num, comment_num]) # 保存数据函数 def save_data(): f = open('douban_movie_top250.
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/115043f666fcc1dc4952d06a855744fc/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/9058c071f891cdacda47fa31bb2c56c4/" rel="bookmark">
			【java】HashMap底层实现原理
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		目录 一.哈希表(散列)1.什么是哈希表2.什么是哈希冲突(面试题)3.解决哈希冲突的方法(面试题)(1) 开放地址法① 线性探查②二次探查③随机探查 (2) 再哈希法(3) 链地址法(4)建立公共溢出区 二.HashMap1.HashMap的hash()算法(面试)(1)为什么不是`h = key.hashCode()`直接返回，而要 `h = key.hashCode() ^ (h &gt;&gt;&gt; 16)`来计算哈希值呢？(2)为什么HashMap的初始容量和扩容都是2的次幂(3)如果指定了不是2的次幂的容量会发生什么？ 2.HashMap为什么线程不安全(面试题)(1) 多线程下扩容造成的死循环和数据丢失(jdk1.7)(2)数据覆盖(jdk1.8) 3.HashMap解决线程不安全(面试题)(1) 使用HashTable解决线程不安全问题(弃用)(2)HashMap和HashTable的区别(3)Collections.synchronizedMap(不常用)(4)ConcurrentHashMap(常用) 4.为什么使用synchronized替换ReentrantLock锁呢？4.HashMap底层 数组 + 链表 / 红黑树(面试题)(1)HashMap为什么引入链表(2)HashMap为什么引入红黑树(3)为什么不一开始就使用红黑树(4)说说你对红黑树的理解(5) 红黑树为什么要变色、左旋和右旋操作 5.HashMap链表和红黑树转换(面试题)(1) 为什么链表长度大于8，并且表的长度大于64的时候，链表会转换成红黑树？(2) 为什么转成红黑树是8呢？而重新转为链表阈值是6呢？(3) 为什么负载因子是0.75？ 6.HashMap扩容(面试题)(1)什么时候会发生扩容？(2)为什么不是满了扩容？(3)扩容过程 一.哈希表(散列) 1.什么是哈希表 根据关键码值(Key value)而直接进行访问的数据结构。也就是说，它通过把关键码值映射到表中一个位置来访问记录，以加快查找的速度。这个映射函数叫做散列函数，存放记录的数组叫做散列表。
给定表M，存在函数H(key)，对任意给定的关键字值key，代入函数后若能得到包含该关键字的记录在表中的地址，则称表M为哈希(Hash)表，函数H(key)为哈希(Hash)函数。
2.什么是哈希冲突(面试题) 根据一定的规则放进存放哈希值的数组中，然后下标为1的数组已经有值了，后面根据规则，判定某个数也需要放到下标为1的数组中，这样就导致了只有一个位置两个人都要坐，就引起了冲突。(不同的key值产生的H(key)是一样的)。
3.解决哈希冲突的方法(面试题) (1) 开放地址法 插入一个元素的时候，先通过哈希函数进行判断，若是发生哈希冲突，就以当前地址为基准，根据再寻址的方法（探查序列），去寻找下一个地址，若发生冲突再去寻找，直至找到一个为空的地址为止。所以这种方法又称为再散列法。
Hi=(H(key)+di)%m //开放地址法计算下标公式 Hi：下标(储存的地址) H(key)：哈希函数(计算哈希值) di：增量 %：取模 m：哈希表的长度 探查方法如下
① 线性探查 di=1,2,3,…m-1；冲突发生时，顺序查看表中下一单元，直到找出一个空单元或查遍全表。
②二次探查 di=1^2, -1^2, 2^2, -2^2 …k^2, -k^2,(k&lt;=m/2)； 冲突发生时，在表的左右进行跳跃式探测，比较灵活。
③随机探查 di=伪随机数序列；冲突发生时，建立一个伪随机数发生器（如i=(i+p) % m），p是质数(在m范围取得质数)，生成一个伪随机序列，并给定一个随机数做起点，每次加上伪随机数++就行。
为了更好的理解，我们举一个例子
设哈希表长为14，哈希函数为H(key)=key%11。表中现有数据15、38、61和84，其余位置为空，如果用二次探测再散列处理冲突，则49的位置是？使用线性探测法位置是？ 解：因为H(key)=key%11 所以15的位置 = 15 % 11=4; 38的位置 = 38 % 11=5; 61的位置 = 61 % 11=6; 84的位置 = 84 % 11=7;(证明哈希表4,5,6,7已经有元素) 因为计算下标的公式为：Hi=(H(key)+di)mod%m 使用二次探测法 H(1) = (49%11 + 1^1) = 6;冲突 H(-1) = (49%11 + (-1^2)) = 4;冲突 注意 -1^2 = -1; (-1)^2 = 1; H(2) = (49%11 + 2^2) = 9;不冲突 二次探测法49的位置就是哈希表的9。 使用线性探测 H(1) = (49%11 + 1) = 6;冲突 H(2) = (49%11 + 2) = 7;冲突 H(3) = (49%11 + 3) = 8;不冲突 线性探测法49的位置就是哈希表的8。 (2) 再哈希法 再哈希法又叫双哈希法，有多个不同的Hash函数，当发生冲突时，使用第二个，第三个，….
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/9058c071f891cdacda47fa31bb2c56c4/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/964b3c464fb7f019e3d1db180283b2fc/" rel="bookmark">
			微信开发者工具下载安装教程
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		目录 微信小程序账号注册登录
微信开发者工具的下载和安装
小程序创建项目
微信小程序账号注册登录 下载地址：
官网：https://mp.weixin.qq.com/cgi-bin/wx
或者其他网盘资源，建议走官网，下载安装耗时不多。
①点击前往注册 ②按照步骤进行账号注册或已有账号点击右上角“立即登录” ③扫码后手机上确认申请 已有账号之后可以在微信公众平台 (qq.com)扫码登录，手机上确认选择登录账号。
在此可以对项目进行管理以及成员管理等。后续AppID可以点击此页面的头像选择账号获取到。
微信开发者工具的下载和安装 下载地址：https://developers.weixin.qq.com/miniprogram/dev/devtools/download.html
①选择稳定版或者喜欢的版本选中下载，下载地址无所谓。 ②下载完成后双击下载后的文件进行安装 点击”下一步”
点击”我接受”
点击浏览选择安装位置（不推荐存系统盘）
点击安装后等待安装完成。
点击完成，此时微信开发者工具就已经安装成功了。
安装完成后在开发过程中可以学习微信官方的开放文档，涵盖了API，框架，组件，服务端，云开发等类目。
链接：微信开放文档 (qq.com)
小程序创建项目 ①微信扫码登录账号 扫描成功后手机上点击确认登录
②选择小程序，点击 + 可以新创建项目，也可以右上角直接导入已有项目。
③新建小程序初始设置 AppID：点击测试号会自动生成一个测试号，也可以在微信公众平台个人账号里获取到AppID。
后端服务可以选择是否使用云服务。
点击确定之后，就进入了我们创建好的小程序，我选择的是TDesign零售电商模板
这里选择使用的是测试号，测试阶段没有域名，（实际上做微信小程序是需要域名的），所以我们点击设置并选择项目设置，勾选所指的选项就可以进行下面的操作了。
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/8a4bed7a8774817b6be22daa994a90f2/" rel="bookmark">
			手把手教你完成一个Python与OpenCV人脸识别项目（对图片、视频、摄像头人脸的检测）超详细保姆级记录！
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		课程来源：一天搞定人脸识别项目！学不会up直接下跪！（python+opencv）_哔哩哔哩_bilibili
环境配置详见：
在conda虚拟环境中安装OpenCv并在pycharm中使用_conda虚拟环境安装opencv_好喜欢吃红柚子的博客-CSDN博客
目录
一、读取图片
1.1 imshow和WaitKey方法 1.2 代码实现
1.3 效果展示 二、图片灰度化
2.1 图片灰度化作用 2.2 所需方法
2.2.1 设置灰度方法
2.2.2 保存图片方法
2.3 代码实现
2.4 效果展示
2.4.1 显示灰度图片 2.4.2 保存灰度图片
三、尺寸转换
3.1 尺寸转换方法
3.2 代码展示 3.3 效果展示
3.3.1 显示修改后的图片
3.3.2 保存图片
3.3.3 输出图片的大小
3.4 按下英文输入法中的m键后退出程序
四、绘制矩形和圆形框
4.1 绘制矩形
4.2 绘制圆形
4.3 代码实现
4.4 效果展示
五、人脸检测
5.1 OpenCV自带的分类器
5.2 detectMultiScale方法
5.3 代码
5.4 效果展示 六、检测多个人脸 6.1 代码实现
6.2 效果展示
七、对视频的检测
7.1 所需函数
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/8a4bed7a8774817b6be22daa994a90f2/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/32f7300a12bfa54e946e726c0a9d6b48/" rel="bookmark">
			损失函数——交叉熵损失（Cross-entropy loss）
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		交叉熵损失（Cross-entropy loss）是深度学习中常用的一种损失函数，通常用于分类问题。它衡量了模型预测结果与实际结果之间的差距，是优化模型参数的关键指标之一。以下是交叉熵损失的详细介绍。
假设我们有一个分类问题，需要将输入数据x分为C个不同的类别。对于每个输入数据x，我们定义一个C维的向量y^​，其中y^​i​表示x属于第i个类别的概率。我们的目标是使得y^​尽可能接近真实的标签y的概率分布。
假设真实标签y是一个C维的向量，其中只有一个元素为1，其余元素为0，表示x属于第k个类别。那么，我们可以使用交叉熵损失来衡量模型预测结果和真实标签之间的差距。交叉熵损失的公式如下： 其中，xi​表示真实标签的第i个元素，y​i​表示模型预测x属于第i个类别的概率。
交叉熵损失的本质是衡量两个概率分布之间的距离。其中一个概率分布是真实标签y的分布，另一个是模型预测的概率分布y^​。对于每个类别i，yi​表示真实标签x属于第i个类别的概率，y^​i​表示模型预测x属于第i个类别的概率。当两个概率分布越接近时，交叉熵损失越小，表示模型预测结果越准确。
交叉熵损失是一种凸函数，通常使用梯度下降等优化算法来最小化它。在深度学习中，交叉熵损失是常见的分类损失函数之一，广泛应用于图像分类、语音识别等任务中。
在PyTorch中，交叉熵损失可以使用torch.nn.CrossEntropyLoss实现。该函数将输入数据视为模型输出的概率分布，将目标标签视为类别索引，并计算这些概率与实际标签之间的交叉熵损失。
以下是一个示例代码片段，说明如何使用torch.nn.CrossEntropyLoss计算交叉熵损失：
import torch # 创建模型输出和目标标签 output = torch.randn(10, 5) # 10个样本，5个类别 target = torch.tensor([1, 0, 4, 2, 3, 1, 0, 4, 2, 3]) # 目标类别索引 # 创建交叉熵损失函数 criterion = torch.nn.CrossEntropyLoss() # 计算损失 loss = criterion(output, target) print(loss) 在训练中，你可以使用torch.nn.CrossEntropyLoss作为损失函数来优化模型。假设你已经有一个PyTorch模型和训练数据集，以下是一个简单的训练循环示例，它使用交叉熵损失函数来训练模型：
import torch import torch.nn as nn import torch.optim as optim # 定义模型 class MyModel(nn.Module): def __init__(self): super(MyModel, self).__init__() self.fc1 = nn.Linear(10, 5) self.fc2 = nn.
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/32f7300a12bfa54e946e726c0a9d6b48/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/12300118f2546f8086cfc3a1c4acfb27/" rel="bookmark">
			Stable Diffusion 原理介绍与源码分析（一）
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		Stable Diffusion 原理介绍与源码分析（一） 文章目录 Stable Diffusion 原理介绍与源码分析（一）前言（与正文无关，可以忽略）总览说明Stable Diffusion 整体框架重要论文重要组成模块分析UNetModel 介绍ResBlock 的实现timestep_embedding 实现Prompt 文本 embedding 的实现SpatialTransformer 的实现 小结 前言（与正文无关，可以忽略） Stable Diffusion 是 Stability AI 公司开源的 AI 文生图扩散模型。之前在文章 扩散模型 (Diffusion Model) 简要介绍与源码分析 中介绍了扩散模型的原理与部分算法代码，满足基本的好奇心后便将其束之高阁，没成想近期 AIGC 的发展速度之快大大出乎我的意料，尤其是亲手跑出下面这张 AI 生成的图像， Stable Diffusion 终又重新回到我的视野：
作为一名算法工程师，需要有一双能看透事物本质的眼睛，这张图片最先吸引我的不是内容，而是其生成质量：图像高清、细节丰富，非之前看到的一些粗陋 Toy 可比，红框中标注出来的不协调之处，也是瑕不掩瑜。因此，进一步分析 Stable Diffusion 整个工程框架的原理，实在是迫在眉睫，期待日后能修复红框中的不协调之处，为 AIGC 的进一步发展做出一个技术人员应有的贡献。
总览 Stable Diffusion 整个框架的源码有上万行，没有必要全部分析。本文以 “文本生成图像（text to image）” 为主线，考察 Stable Diffusion 的运行流程以及各个重要的组成模块，在介绍时采用 “总-分” 的形式，先概括整体框架，再分析各个组件（如 DDPM、DDIM 等），另外针对代码中的部分非主流逻辑，比如 predict_cids、return_ids 这些小细节谈谈我的看法。文章内容较长，准备拆分成多个部分。
源码地址：Stable Diffusion
说明 之前我写过很多代码分析文章，但在我遇到问题重新去翻阅时，发现要快速定位到目标位置并准确理解代码意图，仍然存在很大困难，密密麻麻的整块代码，每一次阅读都仿若初见，不易理解，原因在于摘录时引入过多的实现细节，降低了信息的传播效率。
经过一番思考，我不再图省事，决定采用伪代码的方式记录核心原理。平时我深度分析代码时会采用这种方式，对代码进行额外的抽象，相对会耗些时间，但私以为这是有益处的。举个例子，比如 DDPM 模型前向 Diffusion 的代码，如果我用伪代码的方式去写，将是如下的效果：
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/12300118f2546f8086cfc3a1c4acfb27/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/3422fa3f1d31f2aac619a79921a3366f/" rel="bookmark">
			Proximal Policy Optimization (PPO) 算法理解：从策略梯度开始
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		近端策略优化（PPO）算法是OpenAI在2017提出的一种强化学习算法，被认为是目前强化学习领域的SOTA方法，也是适用性最广的算法之一。本文将从PPO算法的基础入手，理解从传统策略梯度算法（例如REIFORCE算法）、自然策略梯度算法、信赖域策略优化算法（TRPO）直到PPO算法的演进过程，以及算法迭代过程中的优化细节。整体框图如下图所示。
图1. 本文整体框图 1. 传统策略梯度算法 1.1 从价值近似到策略近似 强化学习算法可以分为两大类：基于值函数的强化学习和基于策略的强化学习。
基于值函数的强化学习通过递归地求解贝尔曼方程来维护Q值函数（可以是离散的列表，也可以是神经网络），每次选择动作时会选择该状态下对应Q值最大的动作，使得未来积累的期望奖励值最大。经典的基于值函数的强化学习算法有Q-Learning、SARSA、DQN算法等。这些算法在学习后的Q值函数不再发生变化，每次做出的策略也是一定的，可以理解为确定性策略。基于策略的强化学习不再通过价值函数来确定选择动作的策略，而是直接学习策略本身，通过一组参数 θ \theta θ对策略进行参数化，并通过神经网络方法优化 θ \theta θ。
基于策略的强化学习用参数化概率分布 π θ ( a ∣ s ) = P ( a ∣ s ; θ ) \pi_\theta(a|s)=P(a|s;\theta) πθ​(a∣s)=P(a∣s;θ)代替了基于值函数的强化学习中的确定性策略 π : s → a \pi:s \to a π:s→a，在返回的动作概率列表中对不同的动作进行抽样选择。
1.2 定义目标函数 基于参数化策略的思想，我们的目标就是找到那些可能获得更多奖励的动作，使它们对应的概率更大，从而策略就更有可能选择这些动作。为此，我们定义的最大化目标函数 J ( θ ) J(\theta) J(θ)如下： max ⁡ θ J ( θ ) = max ⁡ θ E τ ∼ π θ R ( τ ) = max ⁡ θ ∑ τ P ( τ ; θ ) R ( τ ) \max_\theta J(\theta)=\max_\theta E_{\tau \sim \pi_{\theta}} R(\tau)=\max_\theta \sum_{\tau} P(\tau ; \theta) R(\tau) θmax​J(θ)=θmax​Eτ∼πθ​​R(τ)=θmax​τ∑​P(τ;θ)R(τ)其中 τ \tau τ是agent与环境交互产生的状态-动作轨迹 τ = ( s 1 , a 1 , … , s T , a T ) \tau=(s_1,a_1,\dots,s_T,a_T) τ=(s1​,a1​,…,sT​,aT​)，对 τ \tau τ求和代表的是与环境交互可能产生的所有情况。我们的目标是通过调整 θ \theta θ，使得获得更大奖励的轨迹出现的概率更高。
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/3422fa3f1d31f2aac619a79921a3366f/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/4a70bc8367cbd309c4ebcdbd3c9156cc/" rel="bookmark">
			【深度强化学习】(7) SAC 模型解析，附Pytorch完整代码
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		大家好，今天和各位分享一下 SAC (Soft Actor Critic) 算法，一种基于最大熵的无模型的深度强化学习算法。基于 OpenAI 的 gym 环境完成一个小案例，完整代码可以从我的 GitHub 中获得：
https://github.com/LiSir-HIT/Reinforcement-Learning/tree/main/Model
1. 基本原理 Deepmind 提出的 SAC (Soft Actor Critic) 算法是一种基于最大熵的无模型的深度强化学习算法，适合于真实世界的机器人学习技能。SAC 算法的效率非常高，它解决了离散动作空间和连续性动作空间的强化学习问题。SAC 算法在以最大化未来累积奖励的基础上引入了最大熵的概念，加入熵的目的是增强鲁棒性和智能体的探索能力。SAC 算法的目的是使未来累积奖励值和熵最大化，使得策略尽可能随机，即每个动作输出的概率尽可能的分散，而不是集中在一个动作上。
SAC 算法的目标函数表达式如下： 其中 T 表示智能体与环境互动的总时间步数，表示在策略 下 的分布， 代表熵值， 代表超参数，它的目的是控制最优策略的随机程度和权衡熵相对于奖励的重要性。
2. 公式推导 SAC 是一种基于最大化熵理论的算法。由于目标函数中加入熵值，这使得该算法的探索能力和鲁棒性得到了很大的提升，尽可能的在奖励值和熵值（即策略的随机性）之间取得最大化平衡。智能体因选择动作的随机性（更高的熵）而获得更高的奖励值，以使它不要过早收敛到某个次优确定性策略，即局部最优解。熵值越大，对环境的探索就越多，避免了策略收敛至局部最优，从而可以加快后续的学习速度。
因此，最优策略的 SAC 公式定义为：
其中 用来更新已找到最大总奖励的策略； 是熵正则化系数，用来控制熵的重要程度； 代表熵值，熵值越大，智能体对环境的探索度越大，使智能体能够找到一个更高效的策略，有助于加快后续的策略学习。
SAC 的 Q 值可以用基于熵值改进的贝尔曼方差来计算，价值函数定义如下：
其中， 从经验回放池 D 中采样获得，状态价值函数定义如下：
它表示在某个状态下预期得到的奖励。此外，SAC 中的策略网络 ，软状态价值网络 ，目标状态价值网络网络 ，以及 2 个软 Q 网络 ，它们分别由 参数化。
因此 SAC 中包含 5 个神经网络：策略网络 ，行为价值函数 ，目标函数 ，行为价值函数 。为了分别找到最优策略，将随机梯度下降法应用于他们的目标函数中。 此外，还采用了类似于双 Q 网络的形式，软 Q 值的最小值取两个由 和 参数化的 Q 值函数，这有助于避免过高估计不恰当的 Q 值，以提高训练速度。软 Q 值函数通过最小化贝尔曼误差来更新：
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/4a70bc8367cbd309c4ebcdbd3c9156cc/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/b91804b8ec98610106354e1a4b5cce63/" rel="bookmark">
			科技项目撰写：关键技术、研发内容、创新点的差异和案例
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		以下为回答朋友们关心的科技计划项目申报中撰写可行性研究报告时如何区分其中的“关键技术、研发内容、创新点”，它们在报告中有哪些联系。
下文以重点研发计划项目重点专项为例，仅供大家撰写时参考，实际撰写中必须根据申报指南提供的提纲与主管部门的最新要求为准。
一、关键技术
一般来说，可行性研究报告中提到的关键性技术，是指实现某一功能模块或者某一技术要求要攻破的关键点。这个关键点可能是一个或者个技术方法，关键技术是课题（项目）研究技术的具体核心技术点。
撰写中要求“围绕指南方向提出的研究内容和考核指标凝练拟解决的关键技术”，所以关键技术是具体的、核心的技术研究要点，是对核心技术形成过程中产生的关键性突破点。
从以上要求可以看出关键技术来源于研究内容，但比研究课题的技术更加具体和关键，比如，以“石墨烯基材料的关键制备技术研究开发及产业化”为项目题目申报某科技计划专题。
那么关键技术就是表面功能化技术、伽玛射线辐照技术（液相辐照技术/固相辐照技术）、自组装技术等下一级更加具体的核心技术。
二、主要研究内容
实际撰写中研究内容与关键技术很难区分，很多人写成了相同的内容，无法区分开去。
研究内容是提出实现整个研发过程需要重点突出的研发要点；这个要点是为了实现总体技术框架而搭建，所以它是一个整体的概念。撰写中需要一个总体技术框架图来便于评审专家理解、评判。
继续以“石墨烯基材料的关键制备技术研究开发及产业化”为项目题目来展示研究内容：
1、表面功能化技术
2、伽玛射线辐照技术（液相辐照技术/固相辐照技术）
3、自组装技术
4、模板合成技术
5、3D打印技术（喷墨打印成型/熔融沉积快速成型）
6、粉末冶金技术
我们可以看到1～3和关键技术相同了，但是研究内容包括更多，比如粉末冶金技术虽然不是课题关键技术，也有外部一些成熟技术参考，但是要用到本课题依然要开展研究。
除了比关键技术更加全面的技术框架外，研究内容还包括项目研究重点、研究思路、研究方案和成果转化方案等内容。
具体包括针对项目研究拟解决的问题，拟采用的方法、原理、机理、算法、模型等；项目研究方法（技术路线）的可行性、先进性分析等。
三、主要创新点
很多人容易把关键技术当创新点又重复写一遍，创新点是指整个项目中存在的创新观点，这些观点包括技术、理念、产品结构、应用等的创新。
创新点除了展示技术创新，还要描写创新成果、效益和影响等；所以，创新点最好的表达就是比较，比如与外国技术对比，与现有技术对比，在节能环保、节省成本、提高效益、增强精度等方面取得新的突破。
相对于关键技术描述的技术来说，创新点是代表着这个项目的亮点，它从结构创新、技术创新、理论创新、应用创新、运营模式创新等进行展示。
也就是说除了技术创新和关键技术内容相似外，创新点还有更多的其他内容。
譬如，创新基金中申报材料要求企业阐述行业发展状况、行业技术动态等，有些企业可能要写到行业中还存在需要开发的技术问题，与发达国家比较还存在哪些差距，那么在写到企业技术开发方面的时候，就要把这些问题考虑进去，本项目采取了什么技术手段，解决了什么问题，达到了什么效果，这就前后呼应，有一定整体效果。《节选自〈科技计划申报指南与可研报告撰写实务〉》。
关注政策变化，欢迎来到“项目申报学习交流群”
项目申报课程内部学习资料订阅清单（9月12日更新）
限时优惠预订：《专精特新申报系统填报指南》，系统填报与撰写范例
五折优惠预订：“企事业单位全面项目申报规划”宣讲/汇报PPT
优惠预订：项目申报相关岗位知识与技能测试题库
研究报告预订：项目申报行业发展趋势与职业选择分析
全套资料《2022年国家高新技术企业认定申报操作实务》预订
“专精特新”政策解读内训教材分享订阅通知
新手上路必备《项目申报工作入门指南》
项目申报必备宝典《专项资金项目评审要求及得分点解析》
无惧2022政策变化，《专项资金与荣誉资质申报指南》预订
申报资料预订：科技计划项目申报与可行性研究报告撰写实务
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/9b45fa2c65a8462e136fbd549be214f6/" rel="bookmark">
			OpenAI 发布GPT-4——全网抢先体验
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		OpenAI 发布GPT-4 最近 OpenAI 犹如开挂一般，上周才刚刚推出GPT-3.5-Turbo API，今天凌晨再次祭出GPT-4这个目前最先进的多模态预训练大模型。与上一代GPT3.5相比，GPT-4最大的飞跃是增加了识图能力，并且回答准确性也得到显著提高。GPT-4在多个专业和学术基准测试中展现出令人印象深刻的表现，有时甚至达到了人类水平。GPT-4 的关键特性之一是它能够理解和分析视觉和文本信息。通过结合这些模式，该模型能够对各种任务生成更准确、更细致的回答，例如图像说明或问题回答。此外，GPT-4 能够从大量数据中学习，并适应不同的上下文，使其成为自然语言处理、计算机视觉和机器学习等许多领域中非常有价值的工具。
文章目录 OpenAI 发布GPT-4GPT-4的能力对GPT-3.5错误的修正链式推理逻辑谬误数学能力 如何访问GPT-4总结 GPT-4的能力 虽然GPT-4是在其前身GPT-3.5的基础上升级而来，但是一些微妙的差异使得GPT-4可能颠覆整个游戏规则。
第一眼看上去，在一些随意交谈中很难看出GPT-3.5和GPT-4之间的区别。然而，当你让模型完成一些复杂的任务时，区别就显现出来了。GPT-4比GPT-3.5更可靠、更具创造力，并且能够处理更细微的指令。GPT-4最令人印象深刻的功能之一是它能够理解上下文并生成与当前情况更相关的响应。例如，如果你问它一个关于特定主题的问题，它能够考虑到对话的背景，并提供一个更准确和合情的答案。GPT-4的另一个显著改进是它的创造力。它可以对提示产生更具想象力和独创性的响应，使其成为作家、艺术家和任何想要挖掘其创造性一面工作者的绝佳工具。
我们具体看看 GPT-3 和 GPT-4 之间令人兴奋的区别，下图是 GPT-3 和 GPT-4 在各种基准测试中的表现对比：
从测试数据上看，GPT-4 比 GPT-3 整体好40%，在超过一半的测试中 GPT-4 比 GPT-3 有飞跃性进步。
再给大家看一个我个人认为很神奇的案例：给出食材，让GPT-4食谱。
上面案例展示了GPT-4良好的图像理解能力。
对GPT-3.5错误的修正 之前ChatGPT在很多问题上表现并不理想，为此我专门针对ChatGPT过去表现不佳的问题以及我关注的使用场景对GPT-4做了专门测试。
链式推理 GPT-3.5在一些非常复杂的问题，需要多条推理链的问题上，经常会要求提供更多信息。而GPT-4明显改进链式推理能力，在多推理链问题上表现良好。
GPT-3.5
GPT-4
逻辑谬误 GPT-3.5经常会在一些简单问题上犯逻辑错误，出现这种问题一般是由于问题中夹杂着一些无用的干扰项，比如：”蓝盒子里有一个苹果，蓝盒子里还有一个红盒子，红盒子有个盖子，请问我要如何取出苹果？“。其中”红色盒子有个盖子“就是无用干扰信息，GPT-3.5会给出完全荒谬的回答：
GPT-3.5
而GPT-4可以给出相对合理的答案，且很清楚地说明并避开了问题中的陷阱。
GPT-4
数学能力 GPT-3.5的数学能力广受诟病，甚至在一些简单的小学数学题上频频出错。比如：”我今年6岁，妹妹年龄是我的一半。那么当我90岁时，妹妹多少岁？“
GPT-3.5
GPT-3.5煞有介事的一步一步推理计算，最后给出45岁的错误答案。而GPT-4则修正了这方面的缺陷：
GPT-4
如何访问GPT-4 目前，ChatGPT Plus 会员可以通过 chat.openai.com 访问 GPT-4，但有使用上限。
在进入ChatGPT界面后，用户可以选择使用的模型。有3个模型可以选择
OpenAI很贴心的用直观可视化的方式对比了三个模型。
从官方给出的功能性能对比指引可以看出，GPT-4在推理能力和简明扼要方面明显由于GPT-3.5。
GPT-4的API与GPT-3.5的接口一致，不过目前需要申请开放。我已经第一时间加入了waitlist，等审批通过后再位大家带来GPT-4的接口使用体验报告。
总结 总的来说，GPT-4在推理能力上比GPT-3.5进步巨大，很多之前的问题都得到了修正和改良。我还没有测试GPT-4的多模能力，后面我会继续进行更多的测试，并即时更新文章分享给大家。
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/26d504c43e36b5348ef205a3f25a9a25/" rel="bookmark">
			分页存储概念清晰梳理（页面、页表、页表项、页面大小、页内地址等概念）
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		当我在学习操作系统的存储器管理这一章中的分页存储时发现我总是将许多概念混为一谈，当我求助于CSDN等众多网站的资源时发现其中的概念作者写的十分清晰但篇幅较长难以理解，因此我想用自己的理解用更加简洁明了的话语帮助更多困扰于分页存储系统概念的人员。
本文相关概念如下：
（1）（逻辑）地址空间
（2）页面、页
（3）页面大小
（4）页号
（5）位移量、偏移量、页内地址
（6）页表
（7）页表项
（8）页表项大小
（9）页表长度
（10）物理块、页框
（11）页内碎片
（12）页表（基址）寄存器
下面开始分别介绍：
1.（逻辑）地址空间：简单的理解为程序进程在运行时系统为其分配的运行内存空间。
2.页面（页）：将用户进程的（逻辑）地址空间划分为固定且大小相等的一个个区域。
注：页面和页是同一概念！！！划分出来的一个区域为一个页（页面）！！！
3.页面大小：页面的一个划分区域的大小。
4.页号：表明页面在划分区域过后的次序。
5.位移量、偏移量、页内地址：页内地址即位移量或称偏移量，三者大小都等同于页面大小！！！不要着急问为什么，下面进行分析：
书上有类似下面这个图
注意这是分页地址中的地址结构！！！并不是页面！！！而是系统存储方式的一种结构！！！其中的页号在上面已经提及，而其中的页内地址即页面大小（用于之后将其中的内容放在内存物理地址中），可以通过下面这图来更好理解：
最左边的一整个为一个进程（逻辑）地址空间，每一项才是一个页面！！！
6.页表：系统为每个进程建立的页面映像表，即下图或上图的中间一整块部分。
7.页表项：页表的其中一项，即下图的中间一整块部分的其中一行（如：页号为2且物理块号为6的整体为一个页表项。
8.页表项大小：下图的中间一整块部分的其中一行所占大小。
9.页表长度：指页表项的个数，即下图中间部分一共有几行，有几行页表长度就为多少。
根据这张图可以分析以上所提的概念：
在这个图当中最左边的整个叫用户程序（逻辑地址空间），通过划分区域形成若干项，其中的每一项叫做页面，大小叫做页面大小，页面通过页表（页面映像表）对应物理块号，物理块号再对应与内存中的每一个实际（物理）地址，此时才将页面的内容（即页内地址）放在该实际（物理）地址中。
10.物理块、页框：物理块即页框！！！是将内存空间划分为与先前页面的大小相等的若干块（此时才能将页面大小（页内地址）完全放入划分的内存中，在上图表示的区域为最右边内存实际(物理）地址的每一行，一个物理块或页框就是其中的一行。
11.页内碎片：再讲页内碎片的概念时可以先看下图的例子
可以看到在（逻辑）地址空间被划分为6个区域，每个区域为一个页面，前五个区域（上图红色部分）或称前五页的地址空间大小都为100且都已存满，而第六页的区域同样可以填充100空间大小的内容，但由于用户程序的大小为512，故最后一页的内容实际空间就只填充了12空间大小，即还差100-12=88的内容是空闲的，这空闲的内容就称为页内碎片。
第六页（上图红色部分）未填充（空闲）的内容为页内碎片。
12.页表（基址）寄存器：系统中只设置一个页表寄存器，进程执行时，将页表始地址和页表长度放入页表寄存器，将页表寄存器的开始地址和相应页号相加（并非简单相加，简单这样理解就足够）得到页表中映像的物理块的具体位置，然后通过该物理块对应于内存中的实际（物理）地址，将页内地址放入其中。
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/d75c59f8efd832166ffaf07d57fe7b27/" rel="bookmark">
			Anaconda安装教程（超详细版）
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		目录
一、Anaconda简介
二、运行环境
三、安装Anaconda
四、手动配置环境变量（重点）
五、测试Anaconda环境是否配置成功
一、Anaconda简介 Anaconda，一个开源的Python发行版本，可用于管理Python及其相关包，包含了conda、Python等180多个科学包及其依赖项。
二、运行环境 Windows11 （Window10用户亦可参考，仅环境变量打开位置不同）。
三、安装Anaconda （1）百度“Anaconda”或者输入网址“https://www.anaconda.com/”进入Anaconda官网。
默认版本为Windows，点击“Download”即可下载 。
（2）下载完成后双击“Anaconda3-2022.10-Windows-x86_64.exe”进行安装。
（3）点击“Next”。
(4) 点击“I Agree”。
（5）点击“Just Me” 之后点击“Next”。（如果电脑有多个用户，选择“All User”）。
（6）设置安装路径，最好为全英文且文件夹需为空，之后点击“Next”。
（7）选择手动安装路径，之后点击“Install”。(因为上一个Anaconda也是手动添加路径，本次依然选择手动添加，大家有兴趣的也可尝试上面的自动添加路径。)
（8）点击“Next”。
（9）点击“Next” 。
（10）点击“Finish”。 到这里Anaconda已经安装完成了，接下来到配置环境变量。
四、手动配置环境变量（重点） （1）打开“此电脑”，右键点击“属性”，选择“高级系统设置”，点击“环境变量”。
（2）在系统变量中找到“Path”(注意是区分是系统变量，不是环境变量；个别电脑“Path”可能大小写不同，但都是一样的，只是书写方式不同。) （3）双击“Path”，新建环境变量。
分三次输入以下信息（按自己实际安装路径输入）：
Anaconda安装路径 Anaconda安装路径\Scripts Anaconda安装路径\Library\bin
上图所示为个人安装路径，三条变量信息新建完成后点击“确定”。
五、测试Anaconda环境是否配置成功 （1）WIN+R打开cmd。
（2）输入“conda -version”。(查看conda版本)
(3)输入“conda info”。
（4）输入“activate”，回车。之后输入“python”。
如果输出内容与上图类似（可能版本号不同），则说明环境变量配置成功。
至此，Anaconda安装已全部完成。
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/42f5a66dc0e8e997ef9e06304cc371ae/" rel="bookmark">
			midjourney 初级使用说明
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		注册 直达官网，目前官网是可以直达的，但是Midjourney目前架设在Discord频道上，最终运行去discord 上面的，需要科学上网，自行搜索。
登录到Discord，以后，就是使用的开始。
使用 找到新手频道 在midjourney官方服务器上选择左侧边栏中可见的任何newbies-#xxx频道。
一般注册5分钟后，在频道对话框输入『 /imagine 』后面打上你的关键字命令，后面接一些图像的描述词，一般使用全英文。最后回车发送，等待机器处理作业，生成图像
##### 处理作业，生成图片
约需要一分钟的时间来生成四个选项。
生成图像将激活免费的midjourney试用版。试用版用户可以在需要订阅之前创建大约25个作业。作业是使用midjourney Bot的任何操作。作业包括使用/imagine 命令创建图像网格、放大图像或创建图像变体，所有这些都使用您的免费试用时间。使用/info命令检查您的快速剩余时间，以查看您的剩余试用时间。
效果展示 升级或创建变体 初始图像网格生成完成后，将显示两行按钮：
U按钮将图像放大，生成所选图像的更大版本并添加更多细节。V按钮会对选定的网格图像产生轻微的变化。创建变体会生成与所选图像的整体风格和构图类似的新图像网格。（重新滚动）重新运行作业。在这种情况下，它将重新运行原始提示，生成新的图像网格。 使用放大图像后，将出现一组新选项 制作变体：创建放大图像的变体，并生成包含四个选项的新网格。测试/轻升级重做：使用不同的升级模型重做升级。Web：在midjourney.com上打开图片库中的图片单击笑脸按钮可对Midtravel网站或Discord中的任何放大图像进行评分。每天，排名前1000的图像评分者都会获得一小时的免费快速模式时间。对你的工作或他人的工作进行排名。根据你的个人风格和观点进行排名 保存图片 单击图像以将其完全打开，然后右键单击并选择“保存图像”。在手机上，长按图像，然后点击右上角的下载图标。所有图像均可立即在midjourney.com/app上查看使用Discord登录以查看。
订阅 试用用户大约有25个免费工作。作业当前不会过期，但也不会续订。要制作更多图像，请在任何Bot频道中使用/subscribe命令生成到续费页面的个人链接
	</div>
</article>
</main>

<div class="pagination">
	<a class="pagination__item pagination__item--prev btn" href="/page/612/">«</a>
	<span class="pagination__item pagination__item--current">613/621</span>
	<a class="pagination__item pagination__item--next btn" href="/page/614/">»</a>
</div>

			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>