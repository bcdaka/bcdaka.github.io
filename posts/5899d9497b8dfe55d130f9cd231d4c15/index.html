<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【机器学习】dense的用法以及如何用Numpy构建一个简单神经网络 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/5899d9497b8dfe55d130f9cd231d4c15/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="【机器学习】dense的用法以及如何用Numpy构建一个简单神经网络">
  <meta property="og:description" content="引言 在TensorFlow和Keras中，Dense 层是全连接（fully connected）层的标准实现，其中每个输入都与每个输出有连接
文章目录 引言一、dense的用法1.1 步骤1.1.1 导入必要的库1.1.2 创建模型1.1.3 添加 `Dense` 层1.1.4 编译模型1.1.5 训练模型 1.2 代码示例1.3 代码解释1.4 总结 二、用Numpy构建一个简单神经网络2.1 导入第三方库2.2 数据集2.3 归一化数据2.4 Numpy模型2.5 预测2.6 网络功能2.7 总结 一、dense的用法 1.1 步骤 1.1.1 导入必要的库 通常，你需要从 tensorflow.keras 中导入 models 和 layers。
from tensorflow.keras import models, layers 1.1.2 创建模型 使用 models.Sequential() 创建一个顺序模型。
model = models.Sequential() 1.1.3 添加 Dense 层 使用 model.add() 方法添加 Dense 层到模型中。
model.add(layers.Dense(units, activation=&#39;activation_function&#39;)) 其中：
units 是层的输出维度，即该层中的神经元数量。activation 是激活函数，例如 ‘relu’、‘sigmoid’、‘softmax’ 等。 1.1.4 编译模型 选择损失函数、优化器，并定义评估指标。">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-08-21T15:50:15+08:00">
    <meta property="article:modified_time" content="2024-08-21T15:50:15+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【机器学习】dense的用法以及如何用Numpy构建一个简单神经网络</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_0"></a>引言</h2> 
<blockquote> 
 <p>在TensorFlow和Keras中，<code>Dense</code> 层是全连接（fully connected）层的标准实现，其中每个输入都与每个输出有连接</p> 
</blockquote> 
<p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#_0" rel="nofollow">引言</a></li><li><a href="#dense_9" rel="nofollow">一、dense的用法</a></li><li><ul><li><a href="#11__10" rel="nofollow">1.1 步骤</a></li><li><ul><li><a href="#111__11" rel="nofollow">1.1.1 导入必要的库</a></li><li><a href="#112__16" rel="nofollow">1.1.2 创建模型</a></li><li><a href="#113__Dense__21" rel="nofollow">1.1.3 添加 `Dense` 层</a></li><li><a href="#114__29" rel="nofollow">1.1.4 编译模型</a></li><li><a href="#115__34" rel="nofollow">1.1.5 训练模型</a></li></ul> 
   </li><li><a href="#12__39" rel="nofollow">1.2 代码示例</a></li><li><a href="#13__58" rel="nofollow">1.3 代码解释</a></li><li><a href="#14__62" rel="nofollow">1.4 总结</a></li></ul> 
  </li><li><a href="#Numpy_66" rel="nofollow">二、用Numpy构建一个简单神经网络</a></li><li><ul><li><a href="#21__68" rel="nofollow">2.1 导入第三方库</a></li><li><a href="#22__80" rel="nofollow">2.2 数据集</a></li><li><a href="#23__93" rel="nofollow">2.3 归一化数据</a></li><li><a href="#24_Numpy_113" rel="nofollow">2.4 Numpy模型</a></li><li><a href="#25__157" rel="nofollow">2.5 预测</a></li><li><a href="#26__206" rel="nofollow">2.6 网络功能</a></li><li><a href="#27__219" rel="nofollow">2.7 总结</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h2><a id="dense_9"></a>一、dense的用法</h2> 
<h3><a id="11__10"></a>1.1 步骤</h3> 
<h4><a id="111__11"></a>1.1.1 导入必要的库</h4> 
<p>通常，你需要从 <code>tensorflow.keras</code> 中导入 <code>models</code> 和 <code>layers</code>。</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras <span class="token keyword">import</span> models<span class="token punctuation">,</span> layers
</code></pre> 
<h4><a id="112__16"></a>1.1.2 创建模型</h4> 
<p>使用 <code>models.Sequential()</code> 创建一个顺序模型。</p> 
<pre><code class="prism language-python">model <span class="token operator">=</span> models<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<h4><a id="113__Dense__21"></a>1.1.3 添加 <code>Dense</code> 层</h4> 
<p>使用 <code>model.add()</code> 方法添加 <code>Dense</code> 层到模型中。</p> 
<pre><code class="prism language-python">model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span>units<span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'activation_function'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p>其中：</p> 
<ul><li><code>units</code> 是层的输出维度，即该层中的神经元数量。</li><li><code>activation</code> 是激活函数，例如 ‘relu’、‘sigmoid’、‘softmax’ 等。</li></ul> 
<h4><a id="114__29"></a>1.1.4 编译模型</h4> 
<p>选择损失函数、优化器，并定义评估指标。</p> 
<pre><code class="prism language-python">model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>optimizer<span class="token operator">=</span><span class="token string">'optimizer'</span><span class="token punctuation">,</span> loss<span class="token operator">=</span><span class="token string">'loss_function'</span><span class="token punctuation">,</span> metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<h4><a id="115__34"></a>1.1.5 训练模型</h4> 
<p>使用训练数据对模型进行训练。</p> 
<pre><code class="prism language-python">model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> epochs<span class="token operator">=</span>epochs<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">)</span>
</code></pre> 
<h3><a id="12__39"></a>1.2 代码示例</h3> 
<blockquote> 
 <p>以下是一个使用 <code>Dense</code> 层构建简单全连接神经网络的示例</p> 
</blockquote> 
<pre><code class="prism language-python"><span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras <span class="token keyword">import</span> models<span class="token punctuation">,</span> layers
<span class="token comment"># 创建模型</span>
model <span class="token operator">=</span> models<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># 添加输入层，假设输入数据有 64 个特征</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> input_shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 添加一个隐藏层，有 128 个神经元，并使用 ReLU 激活函数</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 添加输出层，假设是二分类问题，因此有一个神经元和 'sigmoid' 激活函数</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'sigmoid'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 编译模型</span>
model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>optimizer<span class="token operator">=</span><span class="token string">'adam'</span><span class="token punctuation">,</span> loss<span class="token operator">=</span><span class="token string">'binary_crossentropy'</span><span class="token punctuation">,</span> metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment"># 假设 x_train 和 y_train 是训练数据和标签</span>
<span class="token comment"># 训练模型</span>
<span class="token comment"># model.fit(x_train, y_train, epochs=10, batch_size=32)</span>
</code></pre> 
<h3><a id="13__58"></a>1.3 代码解释</h3> 
<ul><li>在这个例子中，我们创建了一个三层的全连接神经网络：一个输入层，一个隐藏层和一个输出层</li><li>使用<code>ReLU</code>激活函数在输入层和隐藏层，并在输出层使用<code>sigmoid</code>函数，因为这是一个二分类问题</li><li>编译模型时，我们选择了 <code>adam</code> 优化器和 <code>binary_crossentropy</code> 损失函数，这是二分类问题的常见选择</li></ul> 
<h3><a id="14__62"></a>1.4 总结</h3> 
<p>在实际应用中，需要用实际的训练数据替换 <code>x_train</code> 和 <code>y_train</code>，并设置合适的 <code>epochs</code> 和 <code>batch_size</code> 参数来训练模型</p> 
<h2><a id="Numpy_66"></a>二、用Numpy构建一个简单神经网络</h2> 
<h3><a id="21__68"></a>2.1 导入第三方库</h3> 
<pre><code class="prism language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
plt<span class="token punctuation">.</span>style<span class="token punctuation">.</span>use<span class="token punctuation">(</span><span class="token string">'./deeplearning.mplstyle'</span><span class="token punctuation">)</span>
<span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
<span class="token keyword">from</span> lab_utils_common <span class="token keyword">import</span> dlc<span class="token punctuation">,</span> sigmoid
<span class="token keyword">from</span> lab_coffee_utils <span class="token keyword">import</span> load_coffee_data<span class="token punctuation">,</span> plt_roast<span class="token punctuation">,</span> plt_prob<span class="token punctuation">,</span> plt_layer<span class="token punctuation">,</span> plt_network<span class="token punctuation">,</span> plt_output_unit
<span class="token keyword">import</span> logging
logging<span class="token punctuation">.</span>getLogger<span class="token punctuation">(</span><span class="token string">"tensorflow"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setLevel<span class="token punctuation">(</span>logging<span class="token punctuation">.</span>ERROR<span class="token punctuation">)</span>
tf<span class="token punctuation">.</span>autograph<span class="token punctuation">.</span>set_verbosity<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="22__80"></a>2.2 数据集</h3> 
<pre><code class="prism language-python">X<span class="token punctuation">,</span>Y <span class="token operator">=</span> load_coffee_data<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> Y<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
</code></pre> 
<p>让我们在下面绘制咖啡烘焙数据。这两个功能是以摄氏度为单位的温度和以分钟为单位的持续时间。在家烘焙咖啡建议持续时间最好保持在 12 到 15 分钟之间，而温度应在 175 到 260 摄氏度之间。当然，随着温度的升高，持续时间应该会缩短。</p> 
<pre><code class="prism language-python">plt_roast<span class="token punctuation">(</span>X<span class="token punctuation">,</span>Y<span class="token punctuation">)</span>
</code></pre> 
<p>输出结果：<br> <img src="https://images2.imgbox.com/b4/d4/8YRO0ZZE_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="23__93"></a>2.3 归一化数据</h3> 
<p>如果数据被归一化，那么将权重拟合到数据（反向传播）将更快地进行。这与您在课程 1 中使用的过程相同，其中数据中的每个要素都被归一化为具有相似的范围。以下过程使用 Keras 归一化层。它包含以下步骤：</p> 
<ul><li>创建一个“归一化层”。请注意，如此处应用的，这不是模型中的层</li><li>“适应”数据。这将学习数据集的均值和方差，并在内部保存值</li><li>对数据进行规范化，将归一化应用于利用学习模型的任何未来数据非常重要</li></ul> 
<pre><code class="prism language-python"><span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Temperature Max, Min pre normalization: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>np<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">0.2f</span><span class="token punctuation">}</span></span><span class="token string">, </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>np<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">0.2f</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Duration    Max, Min pre normalization: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>np<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">0.2f</span><span class="token punctuation">}</span></span><span class="token string">, </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>np<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">0.2f</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
norm_l <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Normalization<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
norm_l<span class="token punctuation">.</span>adapt<span class="token punctuation">(</span>X<span class="token punctuation">)</span>  <span class="token comment"># learns mean, variance</span>
Xn <span class="token operator">=</span> norm_l<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Temperature Max, Min post normalization: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>np<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>Xn<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">0.2f</span><span class="token punctuation">}</span></span><span class="token string">, </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>np<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span>Xn<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">0.2f</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Duration    Max, Min post normalization: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>np<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>Xn<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">0.2f</span><span class="token punctuation">}</span></span><span class="token string">, </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>np<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span>Xn<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">0.2f</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
</code></pre> 
<p>输出结果：<br> <img src="https://images2.imgbox.com/ad/20/XbmII1pB_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="24_Numpy_113"></a>2.4 Numpy模型</h3> 
<p><img src="https://images2.imgbox.com/c5/3a/dGeQgMWT_o.png" alt="在这里插入图片描述"><br> 让我们来构建讲座中描述的“咖啡烘焙网络”。有两层具有 sigmoid 激活<br> 可以使用 NumPy 构建自己的密集层。然后，这可以用来构建多层神经网络<br> <img src="https://images2.imgbox.com/08/85/RUejrd5k_o.png" alt="在这里插入图片描述"><br> 在第一个可选实验中，在 NumPy 和 Tensorflow 中构建了一个神经元，并注意到它们的相似性。一层仅包含多个神经元/单元。可以利用 for 循环访问层中的每个单元j，并执行该单位的权重W的点积，并将该单位的偏差相加 （b[j]） 形成 z。然后可以将激活函数 g（z） 应用于该结果。让我们在下面尝试构建一个“密集层”子程序</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">my_dense</span><span class="token punctuation">(</span>a_in<span class="token punctuation">,</span> W<span class="token punctuation">,</span> b<span class="token punctuation">,</span> g<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    Computes dense layer
    Args:
      a_in (ndarray (n, )) : Data, 1 example 
      W    (ndarray (n,j)) : Weight matrix, n features per unit, j units
      b    (ndarray (j, )) : bias vector, j units  
      g    activation function (e.g. sigmoid, relu..)
    Returns
      a_out (ndarray (j,))  : j units|
    """</span>
    units <span class="token operator">=</span> W<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
    a_out <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>units<span class="token punctuation">)</span>
    <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>units<span class="token punctuation">)</span><span class="token punctuation">:</span>               
        w <span class="token operator">=</span> W<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span>j<span class="token punctuation">]</span>                                    
        z <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>w<span class="token punctuation">,</span> a_in<span class="token punctuation">)</span> <span class="token operator">+</span> b<span class="token punctuation">[</span>j<span class="token punctuation">]</span>         
        a_out<span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">=</span> g<span class="token punctuation">(</span>z<span class="token punctuation">)</span>               
    <span class="token keyword">return</span><span class="token punctuation">(</span>a_out<span class="token punctuation">)</span>
<span class="token punctuation">)</span>
</code></pre> 
<p>以下单元利用上述 my_dense 子程序构建一个两层神经网络</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">my_sequential</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> W1<span class="token punctuation">,</span> b1<span class="token punctuation">,</span> W2<span class="token punctuation">,</span> b2<span class="token punctuation">)</span><span class="token punctuation">:</span>
    a1 <span class="token operator">=</span> my_dense<span class="token punctuation">(</span>x<span class="token punctuation">,</span>  W1<span class="token punctuation">,</span> b1<span class="token punctuation">,</span> sigmoid<span class="token punctuation">)</span>
    a2 <span class="token operator">=</span> my_dense<span class="token punctuation">(</span>a1<span class="token punctuation">,</span> W2<span class="token punctuation">,</span> b2<span class="token punctuation">,</span> sigmoid<span class="token punctuation">)</span>
    <span class="token keyword">return</span><span class="token punctuation">(</span>a2<span class="token punctuation">)</span>
</code></pre> 
<p>我们可以在 Tensorflow 中复制来自前一个实验室的经过训练的权重和偏差</p> 
<pre><code class="prism language-python">W1_tmp <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">8.93</span><span class="token punctuation">,</span>  <span class="token number">0.29</span><span class="token punctuation">,</span> <span class="token number">12.9</span> <span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">0.1</span><span class="token punctuation">,</span>  <span class="token operator">-</span><span class="token number">7.32</span><span class="token punctuation">,</span> <span class="token number">10.81</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token punctuation">)</span>
b1_tmp <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">9.82</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">9.28</span><span class="token punctuation">,</span>  <span class="token number">0.96</span><span class="token punctuation">]</span> <span class="token punctuation">)</span>
W2_tmp <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">31.18</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">27.59</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">32.56</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token punctuation">)</span>
b2_tmp <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span> <span class="token punctuation">[</span><span class="token number">15.41</span><span class="token punctuation">]</span> <span class="token punctuation">)</span>
</code></pre> 
<h3><a id="25__157"></a>2.5 预测</h3> 
<p>一旦有了经过训练的模型，就可以使用它来做出预测。回想一下，我们模型的输出是一个概率。在这种情况下，良好烤肉的概率。要做出决定，必须将概率应用于阈值。在本例中，我们将使用 0.5</p> 
<ul><li>让我们从编写一个类似于 Tensorflow 的 model.predict（） 的例程开始。这将采用一个矩阵 𝑋，行中有所有 𝑚个示例，并通过运行模型进行预测。</li></ul> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">my_predict</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> W1<span class="token punctuation">,</span> b1<span class="token punctuation">,</span> W2<span class="token punctuation">,</span> b2<span class="token punctuation">)</span><span class="token punctuation">:</span>
    m <span class="token operator">=</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    p <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>m<span class="token punctuation">)</span><span class="token punctuation">:</span>
        p<span class="token punctuation">[</span>i<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> my_sequential<span class="token punctuation">(</span>X<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> W1<span class="token punctuation">,</span> b1<span class="token punctuation">,</span> W2<span class="token punctuation">,</span> b2<span class="token punctuation">)</span>
    <span class="token keyword">return</span><span class="token punctuation">(</span>p<span class="token punctuation">)</span>
</code></pre> 
<p>我们可以在两个示例中尝试此例程：</p> 
<pre><code class="prism language-python">X_tst <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>
    <span class="token punctuation">[</span><span class="token number">200</span><span class="token punctuation">,</span><span class="token number">13.9</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment"># postive example</span>
    <span class="token punctuation">[</span><span class="token number">200</span><span class="token punctuation">,</span><span class="token number">17</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>   <span class="token comment"># negative example</span>
X_tstn <span class="token operator">=</span> norm_l<span class="token punctuation">(</span>X_tst<span class="token punctuation">)</span>  <span class="token comment"># remember to normalize</span>
predictions <span class="token operator">=</span> my_predict<span class="token punctuation">(</span>X_tstn<span class="token punctuation">,</span> W1_tmp<span class="token punctuation">,</span> b1_tmp<span class="token punctuation">,</span> W2_tmp<span class="token punctuation">,</span> b2_tmp<span class="token punctuation">)</span>
</code></pre> 
<p>为了将概率转换为决策，我们应用了一个阈值：</p> 
<pre><code class="prism language-python">yhat <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>predictions<span class="token punctuation">)</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>predictions<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> predictions<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">&gt;=</span> <span class="token number">0.5</span><span class="token punctuation">:</span>
        yhat<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        yhat<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"decisions = \n</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>yhat<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
This can be accomplished more succinctly<span class="token punctuation">:</span>
</code></pre> 
<p>输出结果：<br> <img src="https://images2.imgbox.com/ee/25/lHWailIl_o.png" alt="在这里插入图片描述"></p> 
<p>这可以更简洁地完成：</p> 
<pre><code class="prism language-python">
yhat <span class="token operator">=</span> <span class="token punctuation">(</span>predictions <span class="token operator">&gt;=</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"decisions = \n</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>yhat<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
</code></pre> 
<p>输出结果：<br> <img src="https://images2.imgbox.com/d6/61/ChxSh2tY_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="26__206"></a>2.6 网络功能</h3> 
<p>此图显示了整个网络的操作，与上一个实验的 Tensorflow 结果相同<br> 左图是最后一层的原始输出，由蓝色阴影表示。这叠加在由 X 和 O 表示的训练数据上<br> 右图是决策阈值之后网络的输出。这里的 X 和 O 对应于网络做出的决策</p> 
<pre><code class="prism language-python">netf<span class="token operator">=</span> <span class="token keyword">lambda</span> x <span class="token punctuation">:</span> my_predict<span class="token punctuation">(</span>norm_l<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span>W1_tmp<span class="token punctuation">,</span> b1_tmp<span class="token punctuation">,</span> W2_tmp<span class="token punctuation">,</span> b2_tmp<span class="token punctuation">)</span>
plt_network<span class="token punctuation">(</span>X<span class="token punctuation">,</span>Y<span class="token punctuation">,</span>netf<span class="token punctuation">)</span>
</code></pre> 
<p>输出结果：<br> <img src="https://images2.imgbox.com/03/d9/eGtTOxuD_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="27__219"></a>2.7 总结</h3> 
<p>在<code>NumPy</code>中构建了一个小型神经网络，揭示了构成神经网络中一层的相当简单和熟悉的函数</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/17c705a468df66cb2ca4462d0b759acf/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">云原生系列 - Nginx(高级篇)</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/295ac7776e57448a6fff7ebec52b6209/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">tomcat相关</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>