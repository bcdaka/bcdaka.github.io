<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>深度学习基础—学习率衰减与局部最优问题 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/ecdd8189a2200decf14f002d3f5645dc/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="深度学习基础—学习率衰减与局部最优问题">
  <meta property="og:description" content="1.学习率衰减 下图中，蓝色的线是min-batch梯度下降法过程中较大学习率的的优化路径，绿线是较小学习率的优化路径。
如果使用min-batch梯度下降法，在模型的学习过程中，会有很多噪声，在靠近最小值的时候，由于学习率a不变，因此最终算法在最小值附近摆动。要解决这个问题，就需要减少学习率a，让靠近最小值的过程中，模型的步长小一点，这就需要学习率衰减来解决。
一个训练集被拆成多个min-batch，对一个训练集训练一遍成为1epoch，我们有如下相关的学习率衰减公式：
其中，decay_rate是衰减率，epoch_num是训练的代数，a0是初始学习率，k是小于1的参数。这些做法都可以让学习率随着训练代数的增加，逐渐衰减，从而让模型更加接近最小值。
2.局部最优问题 接下来看看局部最优问题，如下图所示，蓝点是局部最优解，红点是全局最优解。局部最优和全局最优都是梯度为0的点，也就是所有维度都是凹函数。
下图是鞍点，鞍点是部分维度为凸函数，部分维度为凹函数的点，该点的梯度也为0。
实际的神经网络中，尤其是大模型，参数非常多，损失函数的图像在高维空间难以画出，运行过程中，遇到的梯度为0的点很难是局部最优点（这需要所有维度都是凹函数，概率极低）。最容易遇到的是鞍点，遇到鞍点是让人头疼的问题：
因为马鞍面有一部分很平缓，这部分的梯度很小，使用梯度下降法时会经过很长时间才能走到鞍点附近，在鞍点附近扰动，直到找到梯度更大的方向，梯度下降法才能有更深的进展。这个平稳段需要更好的优化算法来加速训练，Adam算法就是很成熟的优化算法，可以帮助我们加速走出平稳段和鞍点，从而搜索到全局最优。">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-08-19T23:42:15+08:00">
    <meta property="article:modified_time" content="2024-08-19T23:42:15+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">深度学习基础—学习率衰减与局部最优问题</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2>1.学习率衰减</h2> 
<p style="margin-left:.0001pt;text-align:justify;">        下图中，蓝色的线是min-batch梯度下降法过程中较大学习率的的优化路径，绿线是较小学习率的优化路径。</p> 
<p class="img-center"><img alt="" height="307" src="https://images2.imgbox.com/cc/ca/DDw7YBFx_o.png" width="692"></p> 
<p style="margin-left:.0001pt;text-align:justify;">        如果使用min-batch梯度下降法，在模型的学习过程中，会有很多噪声，在靠近最小值的时候，由于学习率a不变，因此最终算法在最小值附近摆动。要解决这个问题，就需要减少学习率a，让靠近最小值的过程中，模型的步长小一点，这就需要学习率衰减来解决。</p> 
<p style="margin-left:.0001pt;text-align:justify;">        一个训练集被拆成多个min-batch，对一个训练集训练一遍成为1epoch，我们有如下相关的学习率衰减公式：</p> 
<p class="img-center"><img alt="" height="217" src="https://images2.imgbox.com/5a/85/ebQw1yPJ_o.png" width="390"></p> 
<p style="margin-left:.0001pt;text-align:justify;">        其中，decay_rate是衰减率，epoch_num是训练的代数，a0是初始学习率，k是小于1的参数。这些做法都可以让学习率随着训练代数的增加，逐渐衰减，从而让模型更加接近最小值。</p> 
<h2 style="background-color:transparent;margin-left:.0001pt;text-align:justify;">2.局部最优问题</h2> 
<p style="margin-left:.0001pt;text-align:justify;">        接下来看看局部最优问题，如下图所示，蓝点是局部最优解，红点是全局最优解。局部最优和全局最优都是梯度为0的点，也就是所有维度都是凹函数。</p> 
<p class="img-center"><img alt="" height="340" src="https://images2.imgbox.com/50/d4/qLWk4JZT_o.png" width="442"></p> 
<p style="margin-left:.0001pt;text-align:justify;">        下图是鞍点，鞍点是部分维度为凸函数，部分维度为凹函数的点，该点的梯度也为0。</p> 
<p class="img-center"><img alt="" height="355" src="https://images2.imgbox.com/f2/34/j3P0Mj3B_o.png" width="513"></p> 
<p style="margin-left:.0001pt;text-align:justify;">        实际的神经网络中，尤其是大模型，参数非常多，损失函数的图像在高维空间难以画出，运行过程中，遇到的梯度为0的点很难是局部最优点（这需要所有维度都是凹函数，概率极低）。最容易遇到的是鞍点，遇到鞍点是让人头疼的问题：</p> 
<p class="img-center"><img alt="" height="193" src="https://images2.imgbox.com/39/2f/MVF2JTAp_o.png" width="693"></p> 
<p style="margin-left:.0001pt;text-align:justify;">        因为马鞍面有一部分很平缓，这部分的梯度很小，使用梯度下降法时会经过很长时间才能走到鞍点附近，在鞍点附近扰动，直到找到梯度更大的方向，梯度下降法才能有更深的进展。这个平稳段需要更好的优化算法来加速训练，Adam算法就是很成熟的优化算法，可以帮助我们加速走出平稳段和鞍点，从而搜索到全局最优。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/6c5a68357398733c17f45992b94acd54/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">基于Python的火车票售票系统/基于django的火车购票系统</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/235591bb21645b1712a15452da4bc708/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">从回调地狱到Promise乐园：JavaScript异步编程的进化</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>