<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>摸鱼大数据——Linux搭建大数据环境(集群免密码登录和安装Hadoop)二 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/1f8cede86c6a8d2dbc4d70c38a2439b3/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="摸鱼大数据——Linux搭建大数据环境(集群免密码登录和安装Hadoop)二">
  <meta property="og:description" content="集群设置免密登录 克隆node1虚拟机的前置条件：node1虚拟机存在且处于关闭状态
1.克隆出node2虚拟机 1.node1虚拟机: 右键 -&gt; &#34;管理&#34; -&gt; &#34;克隆&#34;
2.图形化弹窗中: &#34;下一页&#34;-&gt;&#34;下一页&#34;-&gt;选择&#34;创建完整克隆&#34;再&#34;下一页&#34;-&gt;填写&#34;node3和对应位置&#34;再点击&#34;完成&#34;
3.node3虚拟机: 右键 -&gt; &#34;设置&#34; -&gt; &#34;NAT模式&#34; -&gt; &#34;高级&#34; -&gt; &#34;生成&#34;Mac地址再&#39;确定&#39; -&gt; 最后点击&#34;确定&#34;
node3基础配置 修改ip地址
[root@node1 /]# vim /etc/sysconfig/network-scripts/ifcfg-ens33 # 注意此操作是在node3中修改ip地址 IPADDR=&#34;192.168.88.103&#34; 修改主机名
[root@node1 ~]# vim /etc/hostname # 注意此操作是在node3中修改主机名 node3 重启虚拟机
[root@node1 ~]# reboot 查看配置是否生效
[root@node3 ~]# ifconfig 3.CRT操作所有会话 SecureCRT软件: &#34;查看 &#34;- &gt; 选择&#34;交互窗口&#34; -&gt; 右键选择&#34;发送交互到所有会话&#34; 4.设置免密登录 三台虚拟机都生成公钥和私钥
输入命令(注意需要三次回车操作): ssh-keygen 三台虚拟机都执行完命令后,在 /root/.ssh 中会自动生成两个文件: id_rsa 和 id_rsa.pub
分别拷贝公钥给其他虚拟机
输入命令(注意需要输入yes和密码): ssh-copy-id node1 输入命令(注意需要输入yes和密码): ssh-copy-id node2 输入命令(注意需要输入yes和密码): ssh-copy-id node3 测试免密登录">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-05-14T18:15:00+08:00">
    <meta property="article:modified_time" content="2024-05-14T18:15:00+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">摸鱼大数据——Linux搭建大数据环境(集群免密码登录和安装Hadoop)二</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h3>集群设置免密登录</h3> 
<blockquote> 
 <p><strong>克隆node1虚拟机的前置条件：node1虚拟机存在且处于关闭状态</strong></p> 
</blockquote> 
<h4>1.克隆出node2虚拟机</h4> 
<p>1.node1虚拟机: 右键 -&gt; "管理" -&gt; "克隆"</p> 
<p><img alt="" height="797" src="https://images2.imgbox.com/ab/72/s2UhGWDV_o.png" width="1069"></p> 
<p></p> 
<p>2.图形化弹窗中: "下一页"-&gt;"下一页"-&gt;选择"创建完整克隆"再"下一页"-&gt;填写"node3和对应位置"再点击"完成"</p> 
<p></p> 
<p><img alt="" height="515" src="https://images2.imgbox.com/a9/e6/jua95ryI_o.png" width="1200"></p> 
<p><img alt="" height="517" src="https://images2.imgbox.com/2d/f6/Cp3xO2xV_o.png" width="1200"></p> 
<p>3.node3虚拟机: 右键 -&gt; "设置" -&gt; "NAT模式" -&gt; "高级" -&gt; "生成"Mac地址再'确定' -&gt; 最后点击"确定"</p> 
<p><img alt="" height="911" src="https://images2.imgbox.com/0d/bc/QzJ4chUB_o.png" width="1200"></p> 
<p></p> 
<h5>node3基础配置</h5> 
<ul><li> <p>修改ip地址</p> </li></ul> 
<pre>[root@node1 /]# vim /etc/sysconfig/network-scripts/ifcfg-ens33</pre> 
<blockquote> 
 <pre># 注意此操作是在node3中修改ip地址
IPADDR="192.168.88.103"</pre> 
</blockquote> 
<ul><li> <p>修改主机名</p> </li></ul> 
<pre>[root@node1 ~]# vim /etc/hostname </pre> 
<blockquote> 
 <pre># 注意此操作是在node3中修改主机名
node3</pre> 
</blockquote> 
<ul><li> <p>重启虚拟机</p> </li></ul> 
<pre>[root@node1 ~]# reboot</pre> 
<ul><li> <p>查看配置是否生效</p> </li></ul> 
<pre>[root@node3 ~]# ifconfig</pre> 
<h4>3.CRT操作所有会话</h4> 
<pre>SecureCRT软件: "查看 "- &gt;  选择"交互窗口" -&gt; 右键选择"发送交互到所有会话"</pre> 
<h4>4.设置免密登录</h4> 
<ul><li> <p>三台虚拟机都生成公钥和私钥</p> <pre>输入命令(注意需要三次回车操作): ssh-keygen</pre> 
  <blockquote> 
   <p>三台虚拟机都执行完命令后,在 <strong>/root/.ssh</strong> 中会自动生成两个文件: <strong>id_rsa</strong> 和 <strong>id_rsa.pub</strong></p> 
  </blockquote> </li><li> <p>分别拷贝公钥给其他虚拟机</p> <pre>输入命令(注意需要输入yes和密码): ssh-copy-id node1
输入命令(注意需要输入yes和密码): ssh-copy-id node2
输入命令(注意需要输入yes和密码): ssh-copy-id node3</pre> </li><li> <p>测试免密登录</p> <pre>输入命令(注意此时会直接登录成功): ssh node1
输入命令(注意此时会直接登录成功): ssh node2
输入命令(注意此时会直接登录成功): ssh node3</pre> </li></ul> 
<p></p> 
<h3>安装hadoop软件</h3> 
<h4>1.上传软件</h4> 
<blockquote> 
 <p>使用CRT等客户端远程上传 hadoop-3.3.0-Centos7-64-with-snappy.tar.gz文件到/export/software目录下</p> 
</blockquote> 
<h4>2.解压软件</h4> 
<pre>[root@node1 ~]# cd /export/software/
[root@node1 software]# tar -zxvf hadoop-3.3.0-Centos7-64-with-snappy.tar.gz -C /export/server/</pre> 
<h4>3.添加环境变量</h4> 
<pre>[root@node1 software]# vim /etc/profile</pre> 
<blockquote> 
 <pre># 把如下内容复制到profile文件的最后,注意:记得保存并退出wq
# 小技巧 : 按G + o快速到文件末尾
export HADOOP_HOME=/export/server/hadoop-3.3.0
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</pre> 
</blockquote> 
<ul><li> <p>修改完后重启生效</p> </li></ul> 
<pre>[root@node1 server]# source /etc/profile</pre> 
<h4>4.1修改配置文件[自动方式]</h4> 
<h5>上传文件</h5> 
<blockquote> 
 <p>使用CRT等客户端远程上传 <strong>配置好的文件压缩包</strong><code>hadoop-config.tar</code>文件到/export/software目录下</p> 
</blockquote> 
<h5>解压文件</h5> 
<pre>[root@node1 ~]# cd /export/software/
[root@node1 software]# tar -xvf hadoop-config.tar -C /export/server/</pre> 
<h5>覆盖原有文件</h5> 
<pre>[root@node1 software]# mv -f /export/server/hadoop-config/* /export/server/hadoop-3.3.0/etc/hadoop/
[root@node1 software]# rm -rf /export/server/hadoop-config*  </pre> 
<h4>4.2配置文件详解[手动方式]</h4> 
<p>需要进入/export/server/hadoop-3.3.0/etc/hadoop目录下修改如下配置文件</p> 
<ul><li> <p><strong>hadoop-env.sh</strong> : 文件中设置的是Hadoop运行时需要的环境变量</p> </li><li> <p><strong>core-site.xml </strong>: hadoop的核心配置文件,如果在core-site.xml里没有配置的属性,自动会获取core-default.xml 里的相同属性的值</p> </li><li> <p><strong>hdfs-site.xml </strong>: HDFS的核心配置文件,如果在hdfs-site.xml里没有配置的属性,会自动会获取hdfs-default.xml里的相同属性的值</p> </li><li> <p><strong>mapred-site.xml </strong>: MapReduce的核心配置文件,如果在mapred-site.xml里没有配置的属性,会自动会获取mapred-default.xml里的相同属性的值</p> </li><li> <p><strong>yarn-site.xml</strong> : YARN的核心配置文件,如果在yarn-site.xml里没有配置的属性,会自动会获取yarn-default.xml里的相同属性的值</p> </li><li> <p><strong>workers</strong> : 文件中记录集群的主机名。主要配合一键启动脚本如start-dfs.sh、stop-yarn.sh用来进行集群启动</p> </li></ul> 
<h5>①hadoop-env.sh文件</h5> 
<pre>[root@node1 hadoop]# vim hadoop-env.sh</pre> 
<blockquote> 
 <pre># 在55行添加JAVA_HOME,因为Hadoop把当前的执行环境当成远程服务器,所以需要重新配置下
export JAVA_HOME=/export/server/jdk1.8.0_65
# 在440行文件末尾添加以下内容
export HDFS_NAMENODE_USER=root
export HDFS_DATANODE_USER=root
export HDFS_SECONDARYNAMENODE_USER=root
export YARN_RESOURCEMANAGER_USER=root
export YARN_NODEMANAGER_USER=root </pre> 
</blockquote> 
<h5>② core-site.xml文件</h5> 
<pre>[root@node1 hadoop]# vim core-site.xml</pre> 
<blockquote> 
 <pre>&lt;!-- 在文件的&lt;configuration&gt;&lt;/configuration&gt;的标签中添加以下内容:  --&gt;
&lt;!-- 设置默认使用的文件系统 Hadoop支持file、HDFS、GFS、ali|Amazon云等文件系统 --&gt;
&lt;property&gt;
  &lt;name&gt;fs.defaultFS&lt;/name&gt;
  &lt;value&gt;hdfs://node1:8020&lt;/value&gt;
&lt;/property&gt;
​
&lt;!-- 设置Hadoop本地保存数据路径 --&gt;
&lt;property&gt;
  &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
  &lt;value&gt;/export/data/hadoop-3.3.0&lt;/value&gt;
&lt;/property&gt;
​
&lt;!-- 设置HDFS web UI用户身份 --&gt;
&lt;property&gt;
  &lt;name&gt;hadoop.http.staticuser.user&lt;/name&gt;
  &lt;value&gt;root&lt;/value&gt;
&lt;/property&gt;
​
&lt;!-- 整合hive 用户代理设置 --&gt;
&lt;property&gt;
  &lt;name&gt;hadoop.proxyuser.root.hosts&lt;/name&gt;
  &lt;value&gt;*&lt;/value&gt;
&lt;/property&gt;
​
&lt;property&gt;
  &lt;name&gt;hadoop.proxyuser.root.groups&lt;/name&gt;
  &lt;value&gt;*&lt;/value&gt;
&lt;/property&gt;
​
&lt;!-- 开启垃圾桶机制[可选操作] 1440 表示1440分钟也就是24小时一天的时间--&gt;
&lt;property&gt;
   &lt;name&gt;fs.trash.interval&lt;/name&gt;
   &lt;value&gt;1440&lt;/value&gt;
&lt;/property&gt;</pre> 
</blockquote> 
<h5>③ hdfs-site.xml文件</h5> 
<pre>[root@node1 hadoop]# vim hdfs-site.xml</pre> 
<blockquote> 
 <pre>&lt;!-- 在文件的&lt;configuration&gt;&lt;/configuration&gt;的标签中添加以下内容:  --&gt;    
    &lt;!-- 指定secondarynamenode运行位置 --&gt;
    &lt;property&gt;
   &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;
   &lt;value&gt;node2:9868&lt;/value&gt;
    &lt;/property&gt;</pre> 
</blockquote> 
<h5>④ mapred-site.xml文件</h5> 
<pre>[root@node1 hadoop]# vim mapred-site.xml</pre> 
<blockquote> 
 <pre>&lt;!-- 在文件的&lt;configuration&gt;&lt;/configuration&gt;的标签中添加以下内容:  --&gt;  
    &lt;!-- 设置MR程序默认运行模式： yarn集群模式 local本地模式 --&gt;
&lt;property&gt;
 &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
 &lt;value&gt;yarn&lt;/value&gt;
&lt;/property&gt;
​
&lt;!-- MR程序历史服务器端地址 --&gt;
&lt;property&gt;
 &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;
 &lt;value&gt;node1:10020&lt;/value&gt;
&lt;/property&gt;
​
&lt;!-- 历史服务器web端地址 --&gt;
&lt;property&gt;
 &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;
 &lt;value&gt;node1:19888&lt;/value&gt;
&lt;/property&gt;
​
&lt;property&gt;
 &lt;name&gt;yarn.app.mapreduce.am.env&lt;/name&gt;
 &lt;value&gt;HADOOP_MAPRED_HOME=${HADOOP_HOME}&lt;/value&gt;
&lt;/property&gt;
​
&lt;property&gt;
 &lt;name&gt;mapreduce.map.env&lt;/name&gt;
 &lt;value&gt;HADOOP_MAPRED_HOME=${HADOOP_HOME}&lt;/value&gt;
&lt;/property&gt;
​
&lt;property&gt;
 &lt;name&gt;mapreduce.reduce.env&lt;/name&gt;
 &lt;value&gt;HADOOP_MAPRED_HOME=${HADOOP_HOME}&lt;/value&gt;
&lt;/property&gt;</pre> 
</blockquote> 
<h5>⑤ yarn-site.xml文件</h5> 
<pre>[root@node1 hadoop]# vim yarn-site.xml</pre> 
<blockquote> 
 <pre>&lt;!-- 在文件的&lt;configuration&gt;&lt;/configuration&gt;的标签中添加以下内容:  --&gt;    
    &lt;!-- 设置YARN集群主角色运行机器位置 --&gt;
&lt;property&gt;
   &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;
   &lt;value&gt;node1&lt;/value&gt;
&lt;/property&gt;
​
&lt;property&gt;
   &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
   &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
&lt;/property&gt;
​
&lt;!-- 是否将对容器实施物理内存限制 --&gt;
&lt;property&gt;
   &lt;name&gt;yarn.nodemanager.pmem-check-enabled&lt;/name&gt;
   &lt;value&gt;false&lt;/value&gt;
&lt;/property&gt;
​
&lt;!-- 是否将对容器实施虚拟内存限制。 --&gt;
&lt;property&gt;
   &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt;
   &lt;value&gt;false&lt;/value&gt;
&lt;/property&gt;
​
&lt;!-- 开启日志聚集 --&gt;
&lt;property&gt;
 &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;
 &lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;
​
&lt;!-- 设置yarn历史服务器地址 --&gt;
&lt;property&gt;
   &lt;name&gt;yarn.log.server.url&lt;/name&gt;
   &lt;value&gt;http://node1:19888/jobhistory/logs&lt;/value&gt;
&lt;/property&gt;
​
&lt;!-- 保存的时间7天 --&gt;
&lt;property&gt;
 &lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt;
 &lt;value&gt;604800&lt;/value&gt;
&lt;/property&gt;</pre> 
</blockquote> 
<h5>⑥ workers文件</h5> 
<pre>[root@node1 hadoop]# vim workers</pre> 
<blockquote> 
 <pre># 用以下内容把之前内容覆盖
node1
node2
node3</pre> 
</blockquote> 
<h4>5.拷贝软件到其他机器</h4> 
<ul><li> <p>nod1主机上拷贝到node2和node3中各一份</p> </li></ul> 
<pre>[root@node1 server]# scp -r /export/server/hadoop-3.3.0  root@node2:/export/server/
[root@node1 server]# scp -r /export/server/hadoop-3.3.0  root@node3:/export/server/</pre> 
<ul><li> <p>node2主机配置环境变量</p> </li></ul> 
<pre>[root@node2 server]# echo 'export HADOOP_HOME=/export/server/hadoop-3.3.0' &gt;&gt; /etc/profile
[root@node2 server]# echo 'export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin' &gt;&gt; /etc/profile
[root@node2 server]# source /etc/profile</pre> 
<ul><li> <p>node3主机配置环境变量</p> </li></ul> 
<pre>[root@node3 server]# echo 'export HADOOP_HOME=/export/server/hadoop-3.3.0' &gt;&gt; /etc/profile
[root@node3 server]# echo 'export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin' &gt;&gt; /etc/profile
[root@node3 server]# source /etc/profile
</pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/10d748baea748b249ebdf1a8942bf323/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">IDEA文件出现java file outside of source root</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/3c0fe7a936dcbacacd84a2f2340ec24a/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【微信支付】【java】Springboot对接开发微信支付</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>