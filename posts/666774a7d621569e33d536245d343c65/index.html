<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>openEuler搭建hadoop Standalone 模式 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/666774a7d621569e33d536245d343c65/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="openEuler搭建hadoop Standalone 模式">
  <meta property="og:description" content="Standalone 升级软件安装常用软件关闭防火墙修改主机名和IP地址修改hosts配置文件下载jdk和hadoop并配置环境变量配置ssh免密钥登录修改配置文件初始化集群windows修改hosts文件测试 1、升级软件 yum -y update 2、安装常用软件 yum -y install gcc gcc-c&#43;&#43; autoconf automake cmake make \ zlib zlib-devel openssl openssl-devel pcre-devel \ rsync openssh-server vim man zip unzip net-tools tcpdump lrzsz tar wget 3、关闭防火墙 sed -i &#39;s/SELINUX=enforcing/SELINUX=disabled/g&#39; /etc/selinux/config setenforce 0 systemctl stop firewalld systemctl disable firewalld 4、修改主机名和IP地址 hostnamectl set-hostname hadoop vim /etc/sysconfig/network-scripts/ifcfg-ens32 参考如下：
TYPE=Ethernet PROXY_METHOD=none BROWSER_ONLY=no BOOTPROTO=none DEFROUTE=yes IPV4_FAILURE_FATAL=no IPV6INIT=yes IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_FAILURE_FATAL=no IPV6_ADDR_GEN_MODE=eui64 NAME=ens32 UUID=55e7ac28-39d7-4f24-b6bf-0f9fb40b7595 DEVICE=ens32 ONBOOT=yes IPADDR=192.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-06-21T12:03:12+08:00">
    <meta property="article:modified_time" content="2024-06-21T12:03:12+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">openEuler搭建hadoop Standalone 模式</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="Standalone_0"></a>Standalone</h2> 
<ol><li>升级软件</li><li>安装常用软件</li><li>关闭防火墙</li><li>修改主机名和IP地址</li><li>修改hosts配置文件</li><li>下载jdk和hadoop并配置环境变量</li><li>配置ssh免密钥登录</li><li>修改配置文件</li><li>初始化集群</li><li>windows修改hosts文件</li><li>测试</li></ol> 
<h3><a id="1_14"></a>1、升级软件</h3> 
<pre><code class="prism language-bash">yum <span class="token parameter variable">-y</span> update
</code></pre> 
<h3><a id="2_20"></a>2、安装常用软件</h3> 
<pre><code class="prism language-bash">yum <span class="token parameter variable">-y</span> <span class="token function">install</span> gcc gcc-c++ autoconf automake cmake <span class="token function">make</span> <span class="token punctuation">\</span>
 zlib zlib-devel openssl openssl-devel pcre-devel <span class="token punctuation">\</span>
 <span class="token function">rsync</span> openssh-server <span class="token function">vim</span> <span class="token function">man</span> <span class="token function">zip</span> <span class="token function">unzip</span> net-tools tcpdump lrzsz <span class="token function">tar</span> <span class="token function">wget</span>
</code></pre> 
<h3><a id="3_28"></a>3、关闭防火墙</h3> 
<pre><code class="prism language-bash"><span class="token function">sed</span> <span class="token parameter variable">-i</span> <span class="token string">'s/SELINUX=enforcing/SELINUX=disabled/g'</span> /etc/selinux/config
setenforce <span class="token number">0</span>
</code></pre> 
<pre><code class="prism language-bash">systemctl stop firewalld
systemctl disable firewalld
</code></pre> 
<h3><a id="4IP_40"></a>4、修改主机名和IP地址</h3> 
<pre><code class="prism language-bash">hostnamectl set-hostname hadoop
</code></pre> 
<pre><code class="prism language-bash"><span class="token function">vim</span> /etc/sysconfig/network-scripts/ifcfg-ens32
</code></pre> 
<blockquote> 
 <p>参考如下：</p> 
</blockquote> 
<pre><code class="prism language-bash"><span class="token assign-left variable">TYPE</span><span class="token operator">=</span>Ethernet
<span class="token assign-left variable">PROXY_METHOD</span><span class="token operator">=</span>none
<span class="token assign-left variable">BROWSER_ONLY</span><span class="token operator">=</span>no
<span class="token assign-left variable">BOOTPROTO</span><span class="token operator">=</span>none
<span class="token assign-left variable">DEFROUTE</span><span class="token operator">=</span>yes
<span class="token assign-left variable">IPV4_FAILURE_FATAL</span><span class="token operator">=</span>no
<span class="token assign-left variable">IPV6INIT</span><span class="token operator">=</span>yes
<span class="token assign-left variable">IPV6_AUTOCONF</span><span class="token operator">=</span>yes
<span class="token assign-left variable">IPV6_DEFROUTE</span><span class="token operator">=</span>yes
<span class="token assign-left variable">IPV6_FAILURE_FATAL</span><span class="token operator">=</span>no
<span class="token assign-left variable">IPV6_ADDR_GEN_MODE</span><span class="token operator">=</span>eui64
<span class="token assign-left variable">NAME</span><span class="token operator">=</span>ens32
<span class="token assign-left variable">UUID</span><span class="token operator">=</span>55e7ac28-39d7-4f24-b6bf-0f9fb40b7595
<span class="token assign-left variable">DEVICE</span><span class="token operator">=</span>ens32
<span class="token assign-left variable">ONBOOT</span><span class="token operator">=</span>yes
<span class="token assign-left variable">IPADDR</span><span class="token operator">=</span><span class="token number">192.168</span>.10.24
<span class="token assign-left variable">PREFIX</span><span class="token operator">=</span><span class="token number">24</span>
<span class="token assign-left variable">GATEWAY</span><span class="token operator">=</span><span class="token number">192.168</span>.10.2
<span class="token assign-left variable">DNS1</span><span class="token operator">=</span><span class="token number">192.168</span>.10.2
</code></pre> 
<h3><a id="5hosts_74"></a>5、修改hosts配置文件</h3> 
<pre><code class="prism language-bash"><span class="token function">vim</span> /etc/hosts
</code></pre> 
<blockquote> 
 <p>修改内容如下：</p> 
</blockquote> 
<pre><code class="prism language-bash"><span class="token number">192.168</span>.10.24	hadoop
</code></pre> 
<blockquote> 
 <p>重启系统</p> 
</blockquote> 
<pre><code class="prism language-bash"><span class="token function">reboot</span>
</code></pre> 
<h3><a id="6jdkhadoop_92"></a>6、下载jdk和hadoop并配置环境变量</h3> 
<blockquote> 
 <p>创建软件目录</p> 
</blockquote> 
<pre><code class="prism language-bash"><span class="token function">mkdir</span> <span class="token parameter variable">-p</span> /opt/soft 
</code></pre> 
<blockquote> 
 <p>进入软件目录</p> 
</blockquote> 
<pre><code class="prism language-bash"><span class="token builtin class-name">cd</span> /opt/soft
</code></pre> 
<blockquote> 
 <p>下载 JDK</p> 
</blockquote> 
<pre><code class="prism language-bash"></code></pre> 
<blockquote> 
 <p>下载 hadoop</p> 
</blockquote> 
<pre><code class="prism language-bash"><span class="token function">wget</span> https://dlcdn.apache.org/hadoop/common/hadoop-3.3.6/hadoop-3.3.6.tar.gz
</code></pre> 
<blockquote> 
 <p>解压 JDK 修改名称</p> 
</blockquote> 
<pre><code class="prism language-bash"><span class="token function">tar</span> <span class="token parameter variable">-zxvf</span> jdk-8u411-linux-x64.tar.gz
</code></pre> 
<pre><code class="prism language-bash"><span class="token function">mv</span> jdk1.8.0_411 jdk-8
</code></pre> 
<blockquote> 
 <p>解压 hadoop 修改名称</p> 
</blockquote> 
<pre><code class="prism language-bash"><span class="token function">tar</span> <span class="token parameter variable">-zxvf</span> hadoop-3.3.6.tar.gz
</code></pre> 
<pre><code class="prism language-bash"><span class="token function">mv</span> hadoop-3.3.6 hadoop-3
</code></pre> 
<blockquote> 
 <p>配置环境变量</p> 
</blockquote> 
<pre><code class="prism language-bash"><span class="token function">vim</span> /etc/profile.d/my_env.sh
</code></pre> 
<blockquote> 
 <p>编写以下内容：</p> 
</blockquote> 
<pre><code class="prism language-bash"><span class="token builtin class-name">export</span> <span class="token assign-left variable">JAVA_HOME</span><span class="token operator">=</span>/opt/soft/jdk-8

<span class="token builtin class-name">export</span> <span class="token assign-left variable">HDFS_NAMENODE_USER</span><span class="token operator">=</span>root
<span class="token builtin class-name">export</span> <span class="token assign-left variable">HDFS_SECONDARYNAMENODE_USER</span><span class="token operator">=</span>root
<span class="token builtin class-name">export</span> <span class="token assign-left variable">HDFS_DATANODE_USER</span><span class="token operator">=</span>root
<span class="token builtin class-name">export</span> <span class="token assign-left variable">HDFS_ZKFC_USER</span><span class="token operator">=</span>root
<span class="token builtin class-name">export</span> <span class="token assign-left variable">HDFS_JOURNALNODE_USER</span><span class="token operator">=</span>root
<span class="token builtin class-name">export</span> <span class="token assign-left variable">HADOOP_SHELL_EXECNAME</span><span class="token operator">=</span>root

<span class="token builtin class-name">export</span> <span class="token assign-left variable">YARN_RESOURCEMANAGER_USER</span><span class="token operator">=</span>root
<span class="token builtin class-name">export</span> <span class="token assign-left variable">YARN_NODEMANAGER_USER</span><span class="token operator">=</span>root

<span class="token builtin class-name">export</span> <span class="token assign-left variable">HADOOP_HOME</span><span class="token operator">=</span>/opt/soft/hadoop-3
<span class="token builtin class-name">export</span> <span class="token assign-left variable">HADOOP_INSTALL</span><span class="token operator">=</span><span class="token variable">$HADOOP_HOME</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable">HADOOP_MAPRED_HOME</span><span class="token operator">=</span><span class="token variable">$HADOOP_HOME</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable">HADOOP_COMMON_HOME</span><span class="token operator">=</span><span class="token variable">$HADOOP_HOME</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable">HADOOP_HDFS_HOME</span><span class="token operator">=</span><span class="token variable">$HADOOP_HOME</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable">YARN_HOME</span><span class="token operator">=</span><span class="token variable">$HADOOP_HOME</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable">HADOOP_CONF_DIR</span><span class="token operator">=</span><span class="token variable">$HADOOP_HOME</span>/etc/hadoop
<span class="token builtin class-name">export</span> <span class="token assign-left variable">JAVA_LIBRARY_PATH</span><span class="token operator">=</span><span class="token variable">$HADOOP_HOME</span>/lib/native

<span class="token builtin class-name">export</span> <span class="token assign-left variable"><span class="token environment constant">PATH</span></span><span class="token operator">=</span><span class="token environment constant">$PATH</span><span class="token builtin class-name">:</span><span class="token variable">$JAVA_HOME</span>/bin:<span class="token variable">$HADOOP_HOME</span>/bin:<span class="token variable">$HADOOP_HOME</span>/sbin

</code></pre> 
<blockquote> 
 <p>生成新的环境变量</p> 
</blockquote> 
<pre><code class="prism language-bash"><span class="token builtin class-name">source</span> /etc/profile
</code></pre> 
<h4><a id="7ssh_177"></a>7、配置ssh免密钥登录</h4> 
<blockquote> 
 <p>创建本地秘钥并将公共秘钥写入认证文件</p> 
</blockquote> 
<pre><code class="prism language-bash">ssh-keygen <span class="token parameter variable">-t</span> rsa <span class="token parameter variable">-P</span> <span class="token string">''</span> <span class="token parameter variable">-f</span> ~/.ssh/id_rsa
</code></pre> 
<pre><code class="prism language-bash">ssh-copy-id root@hadoop
</code></pre> 
<h3><a id="8_189"></a>8、修改配置文件</h3> 
<blockquote> 
 <p>hadoop-env.sh</p> 
 <p>core-site.xml</p> 
 <p>hdfs-site.xml</p> 
 <p>workers</p> 
 <p>mapred-site.xml</p> 
 <p>yarn-site.xml</p> 
</blockquote> 
<h5><a id="hadoopenvsh_203"></a>hadoop-env.sh</h5> 
<blockquote> 
 <p>文档末尾追加以下内容：</p> 
</blockquote> 
<pre><code class="prism language-bash"><span class="token builtin class-name">export</span> <span class="token assign-left variable">JAVA_HOME</span><span class="token operator">=</span>/opt/soft/jdk-8

<span class="token builtin class-name">export</span> <span class="token assign-left variable">HDFS_NAMENODE_USER</span><span class="token operator">=</span>root
<span class="token builtin class-name">export</span> <span class="token assign-left variable">HDFS_SECONDARYNAMENODE_USER</span><span class="token operator">=</span>root
<span class="token builtin class-name">export</span> <span class="token assign-left variable">HDFS_DATANODE_USER</span><span class="token operator">=</span>root
<span class="token builtin class-name">export</span> <span class="token assign-left variable">HDFS_ZKFC_USER</span><span class="token operator">=</span>root
<span class="token builtin class-name">export</span> <span class="token assign-left variable">HDFS_JOURNALNODE_USER</span><span class="token operator">=</span>root
<span class="token builtin class-name">export</span> <span class="token assign-left variable">HADOOP_SHELL_EXECNAME</span><span class="token operator">=</span>root

<span class="token builtin class-name">export</span> <span class="token assign-left variable">YARN_RESOURCEMANAGER_USER</span><span class="token operator">=</span>root
<span class="token builtin class-name">export</span> <span class="token assign-left variable">YARN_NODEMANAGER_USER</span><span class="token operator">=</span>root

<span class="token builtin class-name">export</span> <span class="token assign-left variable">JAVA_LIBRARY_PATH</span><span class="token operator">=</span><span class="token variable">$HADOOP_HOME</span>/lib/native

</code></pre> 
<h4><a id="coresitexml_224"></a>core-site.xml</h4> 
<pre><code class="prism language-xml"><span class="token prolog">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span>
<span class="token prolog">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>fs.defaultFS<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>hdfs://hadoop:9000<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>hadoop.tmp.dir<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>/home/hadoop_data<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>hadoop.http.staticuser.user<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>root<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>dfs.permissions.enabled<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>false<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>hadoop.proxyuser.root.hosts<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>*<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>hadoop.proxyuser.root.groups<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>*<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">&gt;</span></span>
</code></pre> 
<h4><a id="hdfssitexml_257"></a>hdfs-site.xml</h4> 
<pre><code class="prism language-xml"><span class="token prolog">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span>
<span class="token prolog">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>dfs.replication<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>dfs.namenode.secondary.http-address<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>hadoop:9868<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">&gt;</span></span>
</code></pre> 
<h4><a id="workers_274"></a>workers</h4> 
<blockquote> 
 <p>注意：</p> 
 <p>hadoop2.x中该文件名为slaves</p> 
 <p>hadoop3.x中该文件名为workers</p> 
</blockquote> 
<pre><code class="prism language-bash">hadoop
</code></pre> 
<h4><a id="mapredsitexml_286"></a>mapred-site.xml</h4> 
<pre><code class="prism language-xml"><span class="token prolog">&lt;?xml version="1.0"?&gt;</span>
<span class="token prolog">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>mapreduce.framework.name<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>yarn<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>mapreduce.application.classpath<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*:$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">&gt;</span></span>

</code></pre> 
<h4><a id="yarnsitexml_304"></a>yarn-site.xml</h4> 
<pre><code class="prism language-xml"><span class="token prolog">&lt;?xml version="1.0"?&gt;</span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>yarn.nodemanager.aux-services<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>mapreduce_shuffle<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>yarn.nodemanager.env-whitelist<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_HOME,PATH,LANG,TZ,HADOOP_MAPRED_HOME<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">&gt;</span></span>

</code></pre> 
<h3><a id="9_321"></a>9、初始化集群</h3> 
<pre><code class="prism language-bash"><span class="token comment"># 格式化文件系统</span>
hdfs namenode <span class="token parameter variable">-format</span>
<span class="token comment"># 启动 NameNode SecondaryNameNode DataNode </span>
start-dfs.sh
<span class="token comment"># 查看启动进程</span>
jps
<span class="token comment"># 看到 DataNode SecondaryNameNode NameNode 三个进程代表启动成功</span>
</code></pre> 
<pre><code class="prism language-shell"><span class="token comment"># 启动 ResourceManager daemon 和 NodeManager</span>
start-yarn.sh
<span class="token comment"># 看到 DataNode NodeManager SecondaryNameNode NameNode ResourceManager 五个进程代表启动成功</span>
</code></pre> 
<p><strong>重点提示：</strong></p> 
<pre><code class="prism language-bash"><span class="token comment"># 关机之前 依关闭服务</span>
stop-yarn.sh
stop-dfs.sh
<span class="token comment"># 开机后 依次开启服务</span>
start-dfs.sh
start-yarn.sh
</code></pre> 
<p>或者</p> 
<pre><code class="prism language-bash"><span class="token comment"># 关机之前关闭服务</span>
stop-all.sh
<span class="token comment"># 开机后开启服务</span>
start-all.sh
</code></pre> 
<pre><code class="prism language-bash"><span class="token comment">#jps 检查进程正常后开启胡哦关闭在再做其它操作</span>
</code></pre> 
<h3><a id="10windowshosts_363"></a>10、修改windows下hosts文件</h3> 
<blockquote> 
 <p>C:\Windows\System32\drivers\etc\hosts</p> 
 <p>追加以下内容：</p> 
</blockquote> 
<pre><code class="prism language-bash"><span class="token number">192.168</span>.171.10	hadoop
</code></pre> 
<blockquote> 
 <p>Windows11 注意 修改权限</p> 
</blockquote> 
<ol><li> <p>开始搜索 cmd</p> 
  <blockquote> 
   <p>找到命令头提示符 以管理身份运行</p> 
  </blockquote> <p><img src="https://images2.imgbox.com/f5/bf/YjSVznjx_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/c4/34/i7ZXabqG_o.png" alt="在这里插入图片描述"></p> </li><li> <p>进入 C:\Windows\System32\drivers\etc 目录</p> <pre><code class="prism language-cmd">cd drivers/etc
</code></pre> <p><img src="https://images2.imgbox.com/29/f3/tMkiPLHC_o.png" alt="在这里插入图片描述"></p> </li><li> <p>打开 hosts 配置文件</p> <pre><code class="prism language-cmd">start hosts
</code></pre> <p><img src="https://images2.imgbox.com/66/92/JrO57t28_o.png" alt="attrib"></p> <p><img src="https://images2.imgbox.com/65/8a/l6yjjTLz_o.png" alt="在这里插入图片描述"></p> </li><li> <p>追加以下内容后保存</p> <pre><code class="prism language-bash"><span class="token number">192.168</span>.10.24	hadoop
</code></pre> </li></ol> 
<h4><a id="11_407"></a>11、测试</h4> 
<h5><a id="111_hadoop_409"></a>11.1 浏览器访问hadoop</h5> 
<blockquote> 
 <p>浏览器访问: http://hadoop:9870</p> 
</blockquote> 
<p><img src="https://images2.imgbox.com/a9/c4/YVYG0Y1L_o.png" alt="namenode"></p> 
<blockquote> 
 <p>浏览器访问:http://hadoop:9868/</p> 
</blockquote> 
<p><img src="https://images2.imgbox.com/4d/e2/Pe6A5e3t_o.png" alt="secondary namenode"></p> 
<blockquote> 
 <p>浏览器访问:http://hadoop:8088</p> 
</blockquote> 
<p><img src="https://images2.imgbox.com/45/76/3xszpuPn_o.png" alt="resourcemanager"></p> 
<h5><a id="112__hdfs_426"></a>11.2 测试 hdfs</h5> 
<blockquote> 
 <p>本地文件系统创建 测试文件 wcdata.txt</p> 
</blockquote> 
<pre><code class="prism language-bash"><span class="token function">vim</span> wcdata.txt
</code></pre> 
<pre><code class="prism language-bash">Spark HBaseHive Flink
Storm Hadoop HBase SparkFlinkHBase
StormHBase Hadoop Hive
FlinkHBase Flink
Hive StormHive Flink HadoopHBase
HiveHadoop Spark HBase StormHBase
Hadoop Hive FlinkHBase Flink Hive StormHive
Flink HadoopHBase Hive
Spark HBaseHive Flink
Storm Hadoop HBase SparkFlinkHBase
StormHBase Hadoop Hive
FlinkHBase Flink
Hive StormHive Flink HadoopHBase
HiveHadoop Spark HBase StormHBase
Hadoop Hive FlinkHBase Flink Hive StormHive
Flink HadoopHBase Hive
Spark HBaseHive Flink
Storm Hadoop HBase SparkFlinkHBase
StormHBase Hadoop Hive
FlinkHBase Flink
Hive StormHive Flink HadoopHBase
HiveHadoop Spark HBase StormHBase
Hadoop Hive FlinkHBase Flink Hive StormHive
Flink HadoopHBase Hive
HiveHadoop Spark HBase StormHBase
Hadoop Hive FlinkHBase Flink Hive StormHive
Flink HadoopHBase Hive
Spark HBaseHive Flink
Storm Hadoop HBase SparkFlinkHBase
StormHBase Hadoop Hive
FlinkHBase Flink
Hive StormHive Flink HadoopHBase
HiveHadoop Spark HBase StormHBase
Hadoop Hive FlinkHBase Flink Hive StormHive
Flink HadoopHBase Hive
Spark HBaseHive Flink
Storm Hadoop HBase SparkFlinkHBase
StormHBase Hadoop Hive
HiveHadoop Spark HBase StormHBase
Hadoop Hive FlinkHBase Flink Hive StormHive
Flink HadoopHBase Hive
Spark HBaseHive Flink
Storm Hadoop HBase SparkFlinkHBase
StormHBase Hadoop Hive
FlinkHBase Flink
Hive StormHive Flink HadoopHBase
HiveHadoop Spark HBase StormHBase
Hadoop Hive FlinkHBase Flink Hive StormHive
Flink HadoopHBase Hive
Spark HBaseHive Flink
Storm Hadoop HBase SparkFlinkHBase
StormHBase Hadoop Hive
Spark HBaseHive Flink
Storm Hadoop HBase SparkFlinkHBase
StormHBase Hadoop Hive
FlinkHBase Flink
Hive StormHive Flink HadoopHBase
HiveHadoop Spark HBase StormHBase
Hadoop Hive FlinkHBase Flink Hive StormHive
Flink HadoopHBase Hive
Spark HBaseHive Flink
Storm Hadoop HBase SparkFlinkHBase
StormHBase Hadoop Hive
FlinkHBase Flink
Hive StormHive Flink HadoopHBase
HiveHadoop Spark HBase StormHBase
Hadoop Hive FlinkHBase Flink Hive StormHive
Flink HadoopHBase Hive
HiveHadoop Spark HBase StormHBase
Hadoop Hive FlinkHBase Flink Hive StormHive
Flink HadoopHBase Hive
Spark HBaseHive Flink
Storm Hadoop HBase SparkFlinkHBase
StormHBase Hadoop Hive
FlinkHBase Flink
Hive StormHive Flink HadoopHBase
HiveHadoop Spark HBase StormHBase
Hadoop Hive FlinkHBase Flink Hive StormHive
Flink HadoopHBase Hive
Spark HBaseHive Flink
Storm Hadoop HBase SparkFlinkHBase
StormHBase Hadoop Hive
Spark HBaseHive Flink
Storm Hadoop HBase SparkFlinkHBase
StormHBase Hadoop Hive
FlinkHBase Flink
Hive StormHive Flink HadoopHBase
HiveHadoop Spark HBase StormHBase
Hadoop Hive FlinkHBase Flink Hive StormHive
Flink HadoopHBase Hive
Spark HBaseHive Flink
Storm Hadoop HBase SparkFlinkHBase
StormHBase Hadoop Hive
FlinkHBase Flink
Hive StormHive Flink HadoopHBase
HiveHadoop Spark HBase StormHBase
Hadoop Hive FlinkHBase Flink Hive StormHive
Flink HadoopHBase Hive
HiveHadoop Spark HBase StormHBase
Hadoop Hive FlinkHBase Flink Hive StormHive
Flink HadoopHBase Hive
Spark HBaseHive Flink
Storm Hadoop HBase SparkFlinkHBase
StormHBase Hadoop Hive
FlinkHBase Flink
Hive StormHive Flink HadoopHBase
HiveHadoop Spark HBase StormHBase
Hadoop Hive FlinkHBase Flink Hive StormHive
Flink HadoopHBase Hive
Spark HBaseHive Flink
Storm Hadoop HBase SparkFlinkHBase
StormHBase Hadoop Hive
Spark HBaseHive Flink
Storm Hadoop HBase SparkFlinkHBase
StormHBase Hadoop Hive
FlinkHBase Flink
Hive StormHive Flink HadoopHBase
HiveHadoop Spark HBase StormHBase
Hadoop Hive FlinkHBase Flink Hive StormHive
Flink HadoopHBase Hive
Spark HBaseHive Flink
Storm Hadoop HBase SparkFlinkHBase
StormHBase Hadoop Hive
FlinkHBase Flink
Hive StormHive Flink HadoopHBase
HiveHadoop Spark HBase StormHBase
Hadoop Hive FlinkHBase Flink Hive StormHive
Flink HadoopHBase Hive
Spark HBaseHive Flink
Storm Hadoop HBase SparkFlinkHBase
StormHBase Hadoop Hive
FlinkHBase Flink
Hive StormHive Flink HadoopHBase
HiveHadoop Spark HBase StormHBase
Hadoop Hive FlinkHBase Flink Hive StormHive
Flink HadoopHBase Hive
HiveHadoop Spark HBase StormHBase
Hadoop Hive FlinkHBase Flink Hive StormHive
Flink HadoopHBase Hive
Spark HBaseHive Flink
Storm Hadoop HBase SparkFlinkHBase
StormHBase Hadoop Hive
FlinkHBase Flink
Hive StormHive Flink HadoopHBase
HiveHadoop Spark HBase StormHBase
Hadoop Hive FlinkHBase Flink Hive StormHive
Flink HadoopHBase Hive
Spark HBaseHive Flink
Storm Hadoop HBase SparkFlinkHBase
StormHBase Hadoop Hive
HiveHadoop Spark HBase StormHBase
Hadoop Hive FlinkHBase Flink Hive StormHive
Flink HadoopHBase Hive
Spark HBaseHive Flink
Storm Hadoop HBase SparkFlinkHBase
StormHBase Hadoop Hive
FlinkHBase Flink
Hive StormHive Flink HadoopHBase
HiveHadoop Spark HBase StormHBase
Hadoop Hive FlinkHBase Flink Hive StormHive
Flink HadoopHBase Hive
Spark HBaseHive Flink
Storm Hadoop HBase SparkFlinkHBase
StormHBase Hadoop Hive
Spark HBaseHive Flink
Storm Hadoop HBase SparkFlinkHBase
StormHBase Hadoop Hive
FlinkHBase Flink
Hive StormHive Flink HadoopHBase
HiveHadoop Spark HBase StormHBase
Hadoop Hive FlinkHBase Flink Hive StormHive
Flink HadoopHBase Hive
Spark HBaseHive Flink
Storm Hadoop HBase SparkFlinkHBase
StormHBase Hadoop Hive
FlinkHBase Flink
Hive StormHive Flink HadoopHBase
HiveHadoop Spark HBase StormHBase
Hadoop Hive FlinkHBase Flink Hive StormHive
Flink HadoopHBase Hive
HiveHadoop Spark HBase StormHBase
Hadoop Hive FlinkHBase Flink Hive StormHive
Flink HadoopHBase Hive
Spark HBaseHive Flink
Storm Hadoop HBase SparkFlinkHBase
StormHBase Hadoop Hive
FlinkHBase Flink
Hive StormHive Flink HadoopHBase
HiveHadoop Spark HBase StormHBase
Hadoop Hive FlinkHBase Flink Hive StormHive
Flink HadoopHBase Hive
Spark HBaseHive Flink
Storm Hadoop HBase SparkFlinkHBase
StormHBase Hadoop Hive
Spark HBaseHive Flink
Storm Hadoop HBase SparkFlinkHBase
StormHBase Hadoop Hive
FlinkHBase Flink
Hive StormHive Flink HadoopHBase
HiveHadoop Spark HBase StormHBase
Hadoop Hive FlinkHBase Flink Hive StormHive
Flink HadoopHBase Hive
Spark HBaseHive Flink
Storm Hadoop HBase SparkFlinkHBase
StormHBase Hadoop Hive
FlinkHBase Flink
Hive StormHive Flink HadoopHBase
HiveHadoop Spark HBase StormHBase
Hadoop Hive FlinkHBase Flink Hive StormHive
Flink HadoopHBase Hive
HiveHadoop Spark HBase StormHBase
Hadoop Hive FlinkHBase Flink Hive StormHive
Flink HadoopHBase Hive
Spark HBaseHive Flink
Storm Hadoop HBase SparkFlinkHBase
StormHBase Hadoop Hive
FlinkHBase Flink
Hive StormHive Flink HadoopHBase
HiveHadoop Spark HBase StormHBase
Hadoop Hive FlinkHBase Flink Hive StormHive
Flink HadoopHBase Hive
Spark HBaseHive Flink
Storm Hadoop HBase SparkFlinkHBase
StormHBase Hadoop Hive
</code></pre> 
<blockquote> 
 <p>在 HDFS 上创建目录 /wordcount/input</p> 
</blockquote> 
<pre><code class="prism language-bash">hdfs dfs <span class="token parameter variable">-mkdir</span> <span class="token parameter variable">-p</span> /wordcount/input
</code></pre> 
<blockquote> 
 <p>查看 HDFS 目录结构</p> 
</blockquote> 
<pre><code class="prism language-bash">hdfs dfs <span class="token parameter variable">-ls</span> /
</code></pre> 
<pre><code class="prism language-bash">hdfs dfs <span class="token parameter variable">-ls</span> /wordcount
</code></pre> 
<pre><code class="prism language-bash">hdfs dfs <span class="token parameter variable">-ls</span> /wordcount/input
</code></pre> 
<blockquote> 
 <p>上传本地测试文件 wcdata.txt 到 HDFS 上 /wordcount/input</p> 
</blockquote> 
<pre><code class="prism language-bash">hdfs dfs <span class="token parameter variable">-put</span> wcdata.txt /wordcount/input
</code></pre> 
<blockquote> 
 <p>检查文件是否上传成功</p> 
</blockquote> 
<pre><code class="prism language-bash">hdfs dfs <span class="token parameter variable">-ls</span> /wordcount/input
</code></pre> 
<pre><code class="prism language-bas">hdfs dfs -cat /wordcount/input/wcdata.txt
</code></pre> 
<h5><a id="113__mapreduce_697"></a>11.3 测试 mapreduce</h5> 
<blockquote> 
 <p>计算 PI 的值</p> 
</blockquote> 
<pre><code class="prism language-bash">hadoop jar <span class="token variable">$HADOOP_HOME</span>/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.6.jar pi <span class="token number">10</span> <span class="token number">10</span>
</code></pre> 
<blockquote> 
 <p>单词统计</p> 
</blockquote> 
<pre><code class="prism language-bash">hadoop jar <span class="token variable">$HADOOP_HOME</span>/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.6.jar wordcount /wordcount/input/wcdata.txt /wordcount/result
</code></pre> 
<pre><code class="prism language-bash">hdfs dfs <span class="token parameter variable">-ls</span> /wordcount/result
</code></pre> 
<pre><code class="prism language-bash">hdfs dfs <span class="token parameter variable">-cat</span> /wordcount/result/part-r-00000
</code></pre> 
<p>dcount</p> 
<pre><code>
```bash
hdfs dfs -ls /wordcount/input
</code></pre> 
<blockquote> 
 <p>上传本地测试文件 wcdata.txt 到 HDFS 上 /wordcount/input</p> 
</blockquote> 
<pre><code class="prism language-bash">hdfs dfs <span class="token parameter variable">-put</span> wcdata.txt /wordcount/input
</code></pre> 
<blockquote> 
 <p>检查文件是否上传成功</p> 
</blockquote> 
<pre><code class="prism language-bash">hdfs dfs <span class="token parameter variable">-ls</span> /wordcount/input
</code></pre> 
<pre><code class="prism language-bas">hdfs dfs -cat /wordcount/input/wcdata.txt
</code></pre> 
<h5><a id="113__mapreduce_741"></a>11.3 测试 mapreduce</h5> 
<blockquote> 
 <p>计算 PI 的值</p> 
</blockquote> 
<pre><code class="prism language-bash">hadoop jar <span class="token variable">$HADOOP_HOME</span>/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.6.jar pi <span class="token number">10</span> <span class="token number">10</span>
</code></pre> 
<blockquote> 
 <p>单词统计</p> 
</blockquote> 
<pre><code class="prism language-bash">hadoop jar <span class="token variable">$HADOOP_HOME</span>/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.6.jar wordcount /wordcount/input/wcdata.txt /wordcount/result
</code></pre> 
<pre><code class="prism language-bash">hdfs dfs <span class="token parameter variable">-ls</span> /wordcount/result
</code></pre> 
<pre><code class="prism language-bash">hdfs dfs <span class="token parameter variable">-cat</span> /wordcount/result/part-r-00000
</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/7bd088433e083682e49ec067f3721893/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">计算机必背单词——数据结构</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/b4b6bcf860369135344295598d75f056/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">关于html内嵌vuejs使用iframe无法加载vue实例解决方案，使用bootstrap再iframe</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>