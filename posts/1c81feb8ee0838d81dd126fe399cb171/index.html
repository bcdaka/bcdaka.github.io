<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【OrangePi AIpro】: 探索AI加成的开源硬件魅力 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/1c81feb8ee0838d81dd126fe399cb171/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="【OrangePi AIpro】: 探索AI加成的开源硬件魅力">
  <meta property="og:description" content="🌈个人主页: 鑫宝Code
🔥热门专栏: 闲话杂谈｜ 炫酷HTML | JavaScript基础 ​💫个人格言: &#34;如无必要，勿增实体&#34; 文章目录 Orange Pi: 探索开源硬件的魅力引言Orange Pi概述OrangePi AIPro产品介绍试用体验安装前准备开机联网体验 AI 应用样例Image_HDR_Enhance样例CartoonGAN 图像风格迁移 开源项目--给视频人物加上眼线 写在最后负载能力散热效能噪音控制 Orange Pi: 探索开源硬件的魅力 引言 在嵌入式系统的世界里，开源硬件平台如Raspberry Pi和Arduino早已成为创新者、教育者和爱好者的首选。然而，在这个领域中，还有一颗璀璨的明星——Orange Pi。本文将深入探索Orange Pi的起源、特点以及其在教育、项目开发和物联网应用中的潜力。
Orange Pi概述 什么是Orange Pi？
Orange Pi是深圳市橙子科技有限公司开发的一系列开源单板计算机（SBC）。它以提供高性价比的硬件解决方案而闻名，旨在为开发者提供一个功能强大且成本低廉的开发平台。
历史与背景
Orange Pi项目始于2014年，起初是为了与Raspberry Pi竞争，但很快发展出自己的特色。Orange Pi不断推出新的版本，从最初的H2&#43;到后来的Zero Plus2、Orange Pi 4等，每一款都针对不同的需求进行了优化。
OrangePi AIPro产品介绍 特性描述处理器4核64位处理器 &#43; AI处理器AI算力支持8-12TOPS内存8GB / 16GB LPDDR4X存储可外接32GB / 64GB / 128GB / 256GB eMMC模块图形处理器集成显示输出双4K HDMI输出- HDMI输出x2- M.2插槽支持SATA/NVMe SSD 2280- USB 3.0x2- Micro USB（串口打印调试功能）- MIPI摄像头接口x2- 电池接口预留应用领域AI边缘计算、深度视觉学习、视频流AI分析、视频图像分析、自然语言处理、智能小车、机械臂、人工智能、无人机、云计算、AR/VR、智能安防、智能家居等操作系统支持Ubuntu, openEuler用途AI算法原型验证、推理应用开发 详情查看官网链接">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-07-15T16:17:30+08:00">
    <meta property="article:modified_time" content="2024-07-15T16:17:30+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【OrangePi AIpro】: 探索AI加成的开源硬件魅力</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-tomorrow-night">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <hr> 
<img src="https://images2.imgbox.com/c3/d4/ZZfGmeqR_o.png" alt="鑫宝Code" width="150px"> 
<br> 
<img src="https://images2.imgbox.com/b6/50/DHJSdj4C_o.gif" width="300px"> 
<br> 
<p> <font color="#0099ff" size="3" face="粗体"><strong>🌈个人主页: <a href="https://xinbaocode.blog.csdn.net/" rel="nofollow">鑫宝Code</a></strong></font><br> <font color="#0099ff" size="3" face="粗体"><strong>🔥热门专栏: <a href="https://xinbaocode.blog.csdn.net/category_12565077.html" rel="nofollow">闲话杂谈</a>｜ <a href="https://xinbaocode.blog.csdn.net/category_12578048.html" rel="nofollow">炫酷HTML</a> | <a href="https://xinbaocode.blog.csdn.net/category_12578047.html" rel="nofollow">JavaScript基础</a> </strong></font><br> ​<font color="#0099ff" size="3" face="粗体"><strong>💫个人格言: "如无必要，勿增实体" </strong></font> <br><br> <img src="https://images2.imgbox.com/a4/bc/yszn2Of1_o.gif" width="100%"> </p> 
<hr> 
<p></p> 
<p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#Orange_Pi__40" rel="nofollow">Orange Pi: 探索开源硬件的魅力</a></li><li><ul><li><a href="#_43" rel="nofollow">引言</a></li><li><a href="#Orange_Pi_47" rel="nofollow">Orange Pi概述</a></li><li><a href="#OrangePi_AIPro_57" rel="nofollow">OrangePi AIPro产品介绍</a></li><li><a href="#_79" rel="nofollow">试用体验</a></li><li><ul><li><a href="#_80" rel="nofollow">安装前准备</a></li><li><a href="#_95" rel="nofollow">开机联网</a></li><li><a href="#_AI__103" rel="nofollow">体验 AI 应用样例</a></li><li><ul><li><a href="#Image_HDR_Enhance_115" rel="nofollow">Image_HDR_Enhance样例</a></li><li><a href="#CartoonGAN__121" rel="nofollow">CartoonGAN 图像风格迁移</a></li></ul> 
    </li><li><a href="#_128" rel="nofollow">开源项目--给视频人物加上眼线</a></li></ul> 
   </li><li><a href="#_264" rel="nofollow">写在最后</a></li><li><ul><li><a href="#_266" rel="nofollow">负载能力</a></li><li><a href="#_269" rel="nofollow">散热效能</a></li><li><a href="#_272" rel="nofollow">噪音控制</a></li></ul> 
  </li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h2><a id="Orange_Pi__40"></a>Orange Pi: 探索开源硬件的魅力</h2> 
<p><img src="https://images2.imgbox.com/ef/2f/qL13fO4t_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="_43"></a>引言</h3> 
<p>在嵌入式系统的世界里，开源硬件平台如<code>Raspberry Pi</code>和<code>Arduino</code>早已成为创新者、教育者和爱好者的首选。然而，在这个领域中，还有一颗璀璨的明星——<code>Orange Pi</code>。本文将深入探索<code>Orange Pi</code>的起源、特点以及其在教育、项目开发和物联网应用中的潜力。</p> 
<h3><a id="Orange_Pi_47"></a>Orange Pi概述</h3> 
<p><strong>什么是Orange Pi？</strong></p> 
<p>Orange Pi是深圳市橙子科技有限公司开发的一系列开源单板计算机（SBC）。它以提供高性价比的硬件解决方案而闻名，旨在为开发者提供一个功能强大且成本低廉的开发平台。</p> 
<p><strong>历史与背景</strong></p> 
<p>Orange Pi项目始于2014年，起初是为了与Raspberry Pi竞争，但很快发展出自己的特色。Orange Pi不断推出新的版本，从最初的H2+到后来的Zero Plus2、Orange Pi 4等，每一款都针对不同的需求进行了优化。</p> 
<h3><a id="OrangePi_AIPro_57"></a>OrangePi AIPro产品介绍</h3> 
<p><img src="https://images2.imgbox.com/fb/e8/DWvfZMko_o.png" alt="在这里插入图片描述"></p> 
<table><thead><tr><th><strong>特性</strong></th><th><strong>描述</strong></th></tr></thead><tbody><tr><td><strong>处理器</strong></td><td>4核64位处理器 + AI处理器</td></tr><tr><td><strong>AI算力</strong></td><td>支持8-12TOPS</td></tr><tr><td><strong>内存</strong></td><td>8GB / 16GB LPDDR4X</td></tr><tr><td><strong>存储</strong></td><td>可外接32GB / 64GB / 128GB / 256GB eMMC模块</td></tr><tr><td><strong>图形处理器</strong></td><td>集成</td></tr><tr><td><strong>显示输出</strong></td><td>双4K HDMI输出</td></tr><tr><td><strong>- HDMI输出</strong></td><td>x2</td></tr><tr><td><strong>- M.2插槽</strong></td><td>支持SATA/NVMe SSD 2280</td></tr><tr><td><strong>- USB 3.0</strong></td><td>x2</td></tr><tr><td><strong>- Micro USB</strong></td><td>（串口打印调试功能）</td></tr><tr><td><strong>- MIPI摄像头接口</strong></td><td>x2</td></tr><tr><td><strong>- 电池接口</strong></td><td>预留</td></tr><tr><td><strong>应用领域</strong></td><td>AI边缘计算、深度视觉学习、视频流AI分析、视频图像分析、自然语言处理、智能小车、机械臂、人工智能、无人机、云计算、AR/VR、智能安防、智能家居等</td></tr><tr><td><strong>操作系统支持</strong></td><td>Ubuntu, openEuler</td></tr><tr><td><strong>用途</strong></td><td>AI算法原型验证、推理应用开发</td></tr></tbody></table> 
<p>详情查看<a href="http://www.orangepi.cn/html/hardWare/computerAndMicrocontrollers/details/Orange-Pi-AIpro.html" rel="nofollow">官网链接</a></p> 
<h3><a id="_79"></a>试用体验</h3> 
<h4><a id="_80"></a>安装前准备</h4> 
<table><thead><tr><th><strong>设备名称</strong></th><th><strong>描述</strong></th></tr></thead><tbody><tr><td>Type-C PD-65W适配器</td><td>提供电力输入，用于为开发板供电。</td></tr><tr><td>32G TF卡</td><td>已经由官方预置，包含基本的操作系统或固件。</td></tr><tr><td>开发板</td><td>包括散热风扇等配件已安装完毕，核心硬件。</td></tr><tr><td>TF卡读卡器</td><td>用于将TF卡连接至电脑，以便烧录新的操作系统或固件。</td></tr><tr><td>HDMI线</td><td>用于连接开发板的HDMI输出端口至显示器或笔记本的HDMI输入端口。</td></tr><tr><td>显示屏</td><td>可选，如果你计划使用笔记本的屏幕，需要确保它支持HDMI输入。</td></tr><tr><td>有线键盘</td><td>用于输入命令和文本，确保与开发板的USB或Type-C接口兼容。</td></tr><tr><td>有线鼠标</td><td>提供额外的控制方式，确保与开发板的USB或Type-C接口兼容。</td></tr></tbody></table> 
<blockquote> 
 <p>个人需要准备<code>HDMI线</code>,<code>显示器</code>,<code>有线键盘</code> 和<code>有线鼠标</code>就可以啦。官方自带了<code>32G TF卡</code>和烧录好的镜像文件😍</p> 
</blockquote> 
<p><img src="https://images2.imgbox.com/12/6b/pkGIzqH4_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="_95"></a>开机联网</h4> 
<p>我们将相关线材都插入后，就可以点亮机器了。当电源插上的时候。我们可以看到显示器上显示如下的画面。<img src="https://images2.imgbox.com/a1/b6/ppPIdksq_o.png" alt="在这里插入图片描述"></p> 
<blockquote> 
 <p>这里密码是 <code>Mind@123</code></p> 
</blockquote> 
<p><img src="https://images2.imgbox.com/8d/06/u3MpS2ed_o.png" alt="在这里插入图片描述"></p> 
<p>输入密码后，我们就进入了系统，我们先连接WiFi,点击右上角的WiFi图标，选择要连接的WiFi即可。<br> <img src="https://images2.imgbox.com/62/73/FBY3q4q9_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="_AI__103"></a>体验 AI 应用样例</h4> 
<p>根据文档所言，我们进入samples目录，能看到8个项目文件，以及一个<code>start_notebook.sh</code> 文件，我们运行<code>start_notebook.sh</code> 文件，本地启动一个Jupyter 环境。我们复制本地的URL到浏览器打开。</p> 
<blockquote> 
 <p>项目运行时，开发版的温度在40多度左右，摸上去稍微发烫，还是不错的👍</p> 
</blockquote> 
<pre><code class="prism language-bash"><span class="token builtin class-name">cd</span> samples/
./start_notebook.sh
</code></pre> 
<p><img src="https://images2.imgbox.com/0c/42/Ho6IvNyE_o.png" alt="在这里插入图片描述"><br> 这样我们就可以看到对应的<code>Jupyter</code>网页了。</p> 
<p>这里有8个项目，我选择了2个感兴趣的项目进行运行。</p> 
<h5><a id="Image_HDR_Enhance_115"></a>Image_HDR_Enhance样例</h5> 
<p>这个项目主要是对曝光不足的项目进行HDR效果增强。<br> <img src="https://images2.imgbox.com/a4/e9/McpSIIAD_o.png" alt="在这里插入图片描述"><br> 我们点击Jupyter notebook进行运行。<br> <img src="https://images2.imgbox.com/b4/62/tZUD5ZsX_o.png" alt="在这里插入图片描述"><br> 可以看到结果如上所示，消耗的时候是<code>264ms</code> ,可以看出这块开发版的AI性能还是蛮快的。</p> 
<h5><a id="CartoonGAN__121"></a>CartoonGAN 图像风格迁移</h5> 
<p>这个项目主要是对图像进行卡通处理话，我们仍然点击Jupyter notebook进行运行。<br> 原图是这样的，<br> <img src="https://images2.imgbox.com/4e/0e/XrYVLb9T_o.png" alt="在这里插入图片描述"></p> 
<p>经过动画后，可以看到运行结果如下：<br> <img src="https://images2.imgbox.com/62/2e/fjg9YOl5_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="_128"></a>开源项目–给视频人物加上眼线</h4> 
<p>既然OrangePi AIpro 擅长AI 推理，那我们能够想到的就是采用一些比较流行的OpenCV项目来进行验证。<br> 目前采用的项目地址如下：</p> 
<blockquote> 
 <p>https://github.com/kaushil24/Artificial-Eyeliner/</p> 
</blockquote> 
<p><strong>项目概述</strong></p> 
<p>本项目的核心在于开发一种智能算法，旨在为静态图像中的面部自动添加眼线效果。这一过程涉及多个步骤，从精准定位面部特征开始，到细致描绘眼部轮廓，最终实现自然美观的眼线增强。以下是整个流程的精炼概述：</p> 
<p><strong>关键点提取</strong><br> <img src="https://images2.imgbox.com/51/ca/19Ww9xf5_o.png" alt="在这里插入图片描述"></p> 
<p>算法首先从每张人脸中精确提取出68个关键界标点，其中特别关注于与眼睛相关的第37至48号点，这些点构成了左眼和右眼的上下边缘。</p> 
<p><strong>插值技术</strong></p> 
<p>为了创建流畅且自然的眼线，我们对提取的关键点进行插值处理，通过在相邻点间增加虚拟点来构建平滑的线条。这一过程确保了眼线的连续性和美感。</p> 
<p><strong>眼线算法</strong></p> 
<p>流程图清晰地勾勒出了算法的执行逻辑：</p> 
<ol><li>首先，利用OpenCV将图像转化为NumPy数组，便于数学运算和图像处理。</li><li>接着，通过<code>face_detector()</code>函数定位脸部边界框，获取关键的坐标信息。</li><li>对于每一帧中的每一副脸庞，提取68个特征点，并从中选取与眼睛相关的点集。</li><li>使用<code>getEyeLandmarkPts()</code>函数，进一步细化为四个矩阵，分别代表左眼的上眼睑、下眼睑，以及右眼的相应部分。</li></ol> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">getEyeLandmarkPts</span><span class="token punctuation">(</span>face_landmark_points<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">'''
    Input: Coordinates of Bounding Box single face
    Returns: eye's landmark points
    '''</span>
    face_landmark_points<span class="token punctuation">[</span><span class="token number">36</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">-=</span><span class="token number">5</span>
    face_landmark_points<span class="token punctuation">[</span><span class="token number">39</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">+=</span><span class="token number">5</span>
    face_landmark_points<span class="token punctuation">[</span><span class="token number">42</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">-=</span><span class="token number">5</span>
    face_landmark_points<span class="token punctuation">[</span><span class="token number">45</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">+=</span><span class="token number">5</span>
    
    L_eye_top <span class="token operator">=</span> face_landmark_points<span class="token punctuation">[</span><span class="token number">36</span><span class="token punctuation">:</span> <span class="token number">40</span><span class="token punctuation">]</span>
    L_eye_bottom <span class="token operator">=</span> np<span class="token punctuation">.</span>append<span class="token punctuation">(</span>face_landmark_points<span class="token punctuation">[</span><span class="token number">39</span><span class="token punctuation">:</span> <span class="token number">42</span><span class="token punctuation">]</span><span class="token punctuation">,</span> face_landmark_points<span class="token punctuation">[</span><span class="token number">36</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>

    R_eye_top <span class="token operator">=</span> face_landmark_points<span class="token punctuation">[</span><span class="token number">42</span><span class="token punctuation">:</span>  <span class="token number">46</span><span class="token punctuation">]</span>
    R_eye_bottom <span class="token operator">=</span> np<span class="token punctuation">.</span>append<span class="token punctuation">(</span>face_landmark_points<span class="token punctuation">[</span><span class="token number">45</span><span class="token punctuation">:</span><span class="token number">48</span><span class="token punctuation">]</span><span class="token punctuation">,</span> face_landmark_points<span class="token punctuation">[</span><span class="token number">42</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>
       
    <span class="token keyword">return</span> <span class="token punctuation">[</span>L_eye_top<span class="token punctuation">,</span> L_eye_bottom<span class="token punctuation">,</span> R_eye_top<span class="token punctuation">,</span> R_eye_bottom<span class="token punctuation">]</span>
</code></pre> 
<ol start="5"><li>为达到更加逼真的视觉效果，调整端点位置，使其略微向外延伸，增加眼线的连贯性。</li><li>运用<code>interpolateCoordinates()</code>函数对每条曲线进行插值，确保线条的流畅度。</li></ol> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">interpolateCoordinates</span><span class="token punctuation">(</span>xy_coords<span class="token punctuation">,</span> x_intrp<span class="token punctuation">)</span><span class="token punctuation">:</span>
    x <span class="token operator">=</span> xy_coords<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span>
    y <span class="token operator">=</span> xy_coords<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>
    intrp <span class="token operator">=</span> interp1d<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> kind<span class="token operator">=</span><span class="token string">'quadratic'</span><span class="token punctuation">)</span>
    y_intrp <span class="token operator">=</span> intrp<span class="token punctuation">(</span>x_intrp<span class="token punctuation">)</span>
    y_intrp <span class="token operator">=</span> np<span class="token punctuation">.</span>floor<span class="token punctuation">(</span>y_intrp<span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> y_intrp
</code></pre> 
<ol start="7"><li>最后，通过<code>drawEyeLiner()</code>函数，基于插值后的坐标，绘制出连续的眼线，分别针对左眼和右眼。</li></ol> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">drawEyeliner</span><span class="token punctuation">(</span>img<span class="token punctuation">,</span> interp_pts<span class="token punctuation">)</span><span class="token punctuation">:</span>
    L_eye_interp<span class="token punctuation">,</span> R_eye_interp <span class="token operator">=</span> interp_pts

    L_interp_x<span class="token punctuation">,</span> L_interp_top_y<span class="token punctuation">,</span> L_interp_bottom_y <span class="token operator">=</span> L_eye_interp
    R_interp_x<span class="token punctuation">,</span> R_interp_top_y<span class="token punctuation">,</span> R_interp_bottom_y <span class="token operator">=</span> R_eye_interp

    overlay <span class="token operator">=</span> img<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># overlay = np.empty(img.shape)</span>
    <span class="token comment"># overlay = np.zeros_like(img)</span>

    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>L_interp_x<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        x1 <span class="token operator">=</span> L_interp_x<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
        y1_top <span class="token operator">=</span> L_interp_top_y<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
        x2 <span class="token operator">=</span> L_interp_x<span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span>
        y2_top <span class="token operator">=</span> L_interp_top_y<span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span>
        cv2<span class="token punctuation">.</span>line<span class="token punctuation">(</span>overlay<span class="token punctuation">,</span> <span class="token punctuation">(</span>x1<span class="token punctuation">,</span> y1_top<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>x2<span class="token punctuation">,</span> y2_top<span class="token punctuation">)</span><span class="token punctuation">,</span> color<span class="token punctuation">,</span> thickness<span class="token punctuation">)</span>

        y1_bottom <span class="token operator">=</span> L_interp_bottom_y<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
        y2_bottom <span class="token operator">=</span> L_interp_bottom_y<span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span>
        cv2<span class="token punctuation">.</span>line<span class="token punctuation">(</span>overlay<span class="token punctuation">,</span> <span class="token punctuation">(</span>x1<span class="token punctuation">,</span> y1_bottom<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>x1<span class="token punctuation">,</span> y2_bottom<span class="token punctuation">)</span><span class="token punctuation">,</span> color<span class="token punctuation">,</span> thickness<span class="token punctuation">)</span>

    
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>R_interp_x<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        x1 <span class="token operator">=</span> R_interp_x<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
        y1_top <span class="token operator">=</span> R_interp_top_y<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
        x2 <span class="token operator">=</span> R_interp_x<span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span>
        y2_top <span class="token operator">=</span> R_interp_top_y<span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span>
        cv2<span class="token punctuation">.</span>line<span class="token punctuation">(</span>overlay<span class="token punctuation">,</span> <span class="token punctuation">(</span>x1<span class="token punctuation">,</span> y1_top<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>x2<span class="token punctuation">,</span> y2_top<span class="token punctuation">)</span><span class="token punctuation">,</span> color<span class="token punctuation">,</span> thickness<span class="token punctuation">)</span>

        y1_bottom <span class="token operator">=</span> R_interp_bottom_y<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
        y2_bottom <span class="token operator">=</span> R_interp_bottom_y<span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span>
        cv2<span class="token punctuation">.</span>line<span class="token punctuation">(</span>overlay<span class="token punctuation">,</span> <span class="token punctuation">(</span>x1<span class="token punctuation">,</span> y1_bottom<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>x1<span class="token punctuation">,</span> y2_bottom<span class="token punctuation">)</span><span class="token punctuation">,</span> color<span class="token punctuation">,</span> thickness<span class="token punctuation">)</span>



    <span class="token comment"># background = Image.fromarray(img) # .convert("1")</span>
    <span class="token comment"># foreground = Image.fromarray(overlay).convert("1")</span>

    <span class="token comment"># newImg = Image.composite(foreground, background, foreground)#, mask='1')</span>
    
    <span class="token comment"># # img = cv2.bitwise_and(overlay, img)</span>
    <span class="token comment"># return cv2.cvtColor(np.array(newImg), cv2.COLOR_RGB2BGR)</span>

    overlay_crop <span class="token operator">=</span> overlay<span class="token punctuation">[</span><span class="token builtin">min</span><span class="token punctuation">(</span>L_interp_bottom_y<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">50</span> <span class="token punctuation">:</span> <span class="token builtin">max</span><span class="token punctuation">(</span>L_interp_top_y<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">50</span><span class="token punctuation">,</span> L_interp_x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">-</span><span class="token number">50</span> <span class="token punctuation">:</span> L_interp_x<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token number">50</span> <span class="token punctuation">]</span>
    <span class="token comment"># print(max(L_interp_top_y) + 15, min(L_interp_bottom_y) - 15, L_interp_x[0]-10, L_interp_x[-1] + 10 )</span>

    <span class="token keyword">return</span> overlay<span class="token punctuation">,</span> overlay_crop
</code></pre> 
<p><strong>调用项目</strong></p> 
<p>该项目的用发非常简单，首先从Github上克隆到本地</p> 
<pre><code class="prism language-shell"><span class="token function">git</span> clone https://github.com/kaushil24/Artificial-Eyeliner/
</code></pre> 
<p>接下来，打开命令提示符并键入以下代码以运行示例测试</p> 
<pre><code class="prism language-python"><span class="token comment"># 安装依赖文件</span>
pip install <span class="token operator">-</span>r requirements<span class="token punctuation">.</span>txt
python3 eyeliner<span class="token punctuation">.</span>py <span class="token operator">-</span>v <span class="token string">"Media/Sample Video.mp4"</span>
</code></pre> 
<p>我们也可以通过将视频路径放在参数中来使用自己的视频。完整的CLI命令如下：</p> 
<pre><code class="prism language-python">python eyeliner<span class="token punctuation">.</span>py <span class="token punctuation">[</span><span class="token operator">-</span>i image<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">-</span>v video<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">-</span>d dat<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">-</span>t thickness<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">-</span>c color<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">-</span>s save<span class="token punctuation">]</span>
</code></pre> 
<p>每个参数的具体含义如下：</p> 
<ul><li>i ：要在其上绘制眼线的图像的路径</li><li>v ：要在其上绘制眼线的视频的路径。</li><li>v ：也可以通过网络摄像头获取视频。例如：python3 -v webcam -s “Webcam output”</li><li>t ：整数（整数）以设置眼线的厚度。默认值= 2。推荐的数值介于1-5之间</li><li>d：shape_predictor_68_face_landmarks.dat文件的路径。默认路径在根目录中。除非将shape_predictor_68_face_landmarks.dat文件存储在其他位置，否则不需要使用此参数。</li><li>c ：更改眼线的颜色。语法-c 255 255 255。默认值= 0 0 0。其中每个数字代表其RGB值。</li><li>s ：要将输出保存到的位置和文件名。注意程序在保存文件时会自动添加扩展名。如果已经存在同名文件，它将覆盖该文件。</li></ul> 
<p>采用项目的数据我们可以得到如下的图：<br> <img src="https://images2.imgbox.com/ef/c1/eQ9a5CZV_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="_264"></a>写在最后</h3> 
<h4><a id="_266"></a>负载能力</h4> 
<p>此款开发版展现出了惊人的负载处理能力，它不仅在处理图片HDR上，甚至在视频上都有着很快的速度，在HDR上小号的的时间是200多ms,在视频给人物加上眼线也表现的很出色。</p> 
<h4><a id="_269"></a>散热效能</h4> 
<p>在散热设计上，Orange AI Pro同样交出了一份满意的答卷。即便在连续运行1小时的高强度测试中，得益于其内置的高效散热风扇，主板温度始终维持在一个令人安心的低位。</p> 
<h4><a id="_272"></a>噪音控制</h4> 
<p>在噪音控制方面，Orange AI Pro再次展现了其细腻的设计考量。除了启动的瞬间，会听到轻微的启动声，日常运行中，无论是执行繁重的AI模型运算，还是进行常规任务处理，其静谧无声的表现几乎让人忘记了风扇的存在，营造出一个宁静而专注的工作环境，体现了其在用户体验上的精益求精。</p> 
<p>确实，Orange Pi AIpro作为一款源自本土创新的开发板，其设计思路和易用性令人赞叹。遵循详尽的官方文档，即便是初学者也能迅速上手，仿佛一位亲切的导师引领着每一步操作，让复杂的技术变得触手可及。</p> 
<p>更让人瞩目的是，这款开发板搭载了令人印象深刻的8至20TOPS的AI算力，犹如一颗强劲的心脏，为前沿的AI探索注入了无限活力。丰富的扩展接口，如同一块空白的画布，等待着开发者们挥洒创意，无论是智能家居的智慧构建，还是物联网领域的无尽可能，Orange Pi AIpro都展现出了非凡的潜力和适应性。</p> 
<p>它的到来，仿佛是一位多才多艺的艺术家，既能在智能家居的舞台上大放异彩，又能游刃有余地穿梭于各式各样的AIoT场景之中。凭借着卓越的性能和高度的灵活性，Orange Pi AIpro无疑是嵌入式AI领域的一股清流，为未来的项目研发铺设了一条充满机遇的道路，其稳定性和可靠性更是为创新之旅保驾护航。</p> 
<p>总之，Orange Pi AIpro不仅仅是一款开发板，它是通往未来智能世界的一把钥匙，引领着我们走向更加智能、互联的生活。。</p> 
<blockquote> 
 <p>参考资料：<br> <a href="https://www.bilibili.com/video/BV1v2421w74k/?vd_source=944666b5bf1c9b18aa8317b65c9ffd8f" rel="nofollow">【香橙派教程】Orange Pi AIpro一键上手及黑科技功能演示</a></p> 
</blockquote> 
<img src="https://images2.imgbox.com/97/2a/T3IKrzq5_o.png" width="250" height="250"> 
<p> <img src="https://images2.imgbox.com/71/0a/vAXFpR59_o.gif" alt="End"> </p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/e80999cef80de29592bc90fb8c1894d7/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">VGMShield：揭秘视频生成模型滥用的检测与追踪技术</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/1b734a5bfaa8e67e465bcb6395be71b1/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">vue检测页面手指滑动距离，执行回调函数，使用混入的语法，多个组件都可以使用</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>