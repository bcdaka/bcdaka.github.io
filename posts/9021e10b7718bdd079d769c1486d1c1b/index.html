<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>使用 MinIO、Langchain 和 Ray Data 构建分布式嵌入式子系统 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/9021e10b7718bdd079d769c1486d1c1b/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="使用 MinIO、Langchain 和 Ray Data 构建分布式嵌入式子系统">
  <meta property="og:description" content="嵌入子系统是实现检索增强生成所需的四个子系统之一。它将您的自定义语料库转换为可以搜索语义含义的向量数据库。其他子系统是用于创建自定义语料库的数据管道，用于查询向量数据库以向用户查询添加更多上下文的检索器，最后是托管大型语言模型 （LLM） 的服务子系统，并将根据用户的查询和在向量数据库中找到的上下文生成答案。下图显示了这四个子系统在检索增强生成过程中如何协同工作。
在这篇文章中，我想重点介绍嵌入子系统。在此子系统中，构成组织自定义语料库的文档从其原始格式转换为文本，分解为较小的块，然后为每个块创建一个嵌入（这是一个向量，通常具有数百个维度）。创建嵌入后，原始块和向量都将存储在向量数据库中。 嵌入子系统在概念上易于理解，并且实现嵌入简单文本文件的简单脚本非常简单。但是，如果您必须为您的组织实施嵌入子系统，那么您如何为您的组织做出正确的设计决策，以及您如何应对不断增长的需求带来的复杂性？下面列出了一些设计决策和实际复杂性：
如何高效地运行多个实验来测试不同的配置选项？
如何处理文档中的表格和图像？
如何将嵌入子系统部署到生产环境中？
如何处理需要嵌入的大量文档？
什么是最好的载体数据库？
文档、嵌入模型和LLMs的最佳存储选项是什么？
解决这些问题的第一步是使用能够在工程工作站以及生产环境中运行的现代工具。具体来说，我们将使用 MinIO 进行所有存储，使用 Langchain 作为低代码解决方案来进行文档解析（我还将提供一些比 Langchain 更好地处理图像和表的选项），并使用 Ray Data 将分块和嵌入函数分发到集群中。毫不奇怪，分布式技术是我们解决方案的基础。您不仅可以使用商用硬件设置进行并行处理来获得高吞吐量，而且该解决方案是云原生的，使其可以跨云移植，并且还能够在本地运行。让我们从为我们的实验设置一个自定义语料库开始。
在 MinIO 中设置自定义语料库 如上所述，自定义语料库由数据管道创建，该数据管道将可能位于组织中多个门户的文档聚合到 MinIO 中。创建文档管道是另一篇文章的主题 - 所以现在，我们将手动将一些文档暂存到 MinIO 桶中。我在这里也只会使用文本文档来保持简单。但是，这里有一些处理文档中多种文件格式和非文本的提示。首先，查看 Unstructured 的库，用于分区、清理和提取。其次，如果您专门处理 PDF，请查看 Open-Parse 库。我们在之前的博客文章《使用 Open-Parse 智能分块提高 RAG 性能》中介绍了 Open-Parse。下面的屏幕截图显示了我们的自定义语料库。我从古腾堡计划中下载了四本被认为是经典的流行书籍的文本版本。
人性论——大卫·休谟
孙子兵法 - 孙子
杰基尔博士和海德先生的奇案 - 罗伯特·路易斯·史蒂文森
《海底两万里》——儒勒·凡尔纳
现在我们有了一个自定义语料库，我们可以设置一个向量数据库来保存嵌入。
设置 MinIO 和矢量数据库 我将使用的向量数据库是 Pgvector。Pgvector 是 PostgreSQL 的开源扩展，允许用户在数据库中存储、搜索和分析矢量数据。这篇文章的代码下载有一个 docker-compose 文件，其中包含 MinIO、Pgvector 和 pgAdmin。在与 docker-compose fill 相同的目录中运行以下命令会将这三个服务作为容器显示出来。
docker-compose up -d">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-08-02T19:16:09+08:00">
    <meta property="article:modified_time" content="2024-08-02T19:16:09+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">使用 MinIO、Langchain 和 Ray Data 构建分布式嵌入式子系统</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-github-gist">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <section id="nice"> 
 <figure> 
  <img src="https://images2.imgbox.com/d0/e5/xVG1yFVh_o.png" alt=""> 
 </figure> 
 <p>嵌入子系统是实现检索增强生成所需的四个子系统之一。它将您的自定义语料库转换为可以搜索语义含义的向量数据库。其他子系统是用于创建自定义语料库的数据管道，用于查询向量数据库以向用户查询添加更多上下文的检索器，最后是托管大型语言模型 （LLM） 的服务子系统，并将根据用户的查询和在向量数据库中找到的上下文生成答案。下图显示了这四个子系统在检索增强生成过程中如何协同工作。</p> 
 <figure> 
  <img src="https://images2.imgbox.com/b0/1e/7W4Zrrkv_o.png" alt=""> 
 </figure> 
 <p>在这篇文章中，我想重点介绍嵌入子系统。在此子系统中，构成组织自定义语料库的文档从其原始格式转换为文本，分解为较小的块，然后为每个块创建一个嵌入（这是一个向量，通常具有数百个维度）。创建嵌入后，原始块和向量都将存储在向量数据库中。 嵌入子系统在概念上易于理解，并且实现嵌入简单文本文件的简单脚本非常简单。但是，如果您必须为您的组织实施嵌入子系统，那么您如何为您的组织做出正确的设计决策，以及您如何应对不断增长的需求带来的复杂性？下面列出了一些设计决策和实际复杂性：</p> 
 <ul><li> 
   <section> 
    <p>如何高效地运行多个实验来测试不同的配置选项？</p> 
   </section></li><li> 
   <section> 
    <p>如何处理文档中的表格和图像？</p> 
   </section></li><li> 
   <section> 
    <p>如何将嵌入子系统部署到生产环境中？</p> 
   </section></li><li> 
   <section> 
    <p>如何处理需要嵌入的大量文档？</p> 
   </section></li><li> 
   <section> 
    <p>什么是最好的载体数据库？</p> 
   </section></li><li> 
   <section> 
    <p>文档、嵌入模型和LLMs的最佳存储选项是什么？</p> 
   </section></li></ul> 
 <p>解决这些问题的第一步是使用能够在工程工作站以及生产环境中运行的现代工具。具体来说，我们将使用 MinIO 进行所有存储，使用 Langchain 作为低代码解决方案来进行文档解析（我还将提供一些比 Langchain 更好地处理图像和表的选项），并使用 Ray Data 将分块和嵌入函数分发到集群中。毫不奇怪，分布式技术是我们解决方案的基础。您不仅可以使用商用硬件设置进行并行处理来获得高吞吐量，而且该解决方案是云原生的，使其可以跨云移植，并且还能够在本地运行。让我们从为我们的实验设置一个自定义语料库开始。</p> 
 <h3><span class="prefix"></span><span class="content">在 MinIO 中设置自定义语料库</span><span class="suffix"></span></h3> 
 <p>如上所述，自定义语料库由数据管道创建，该数据管道将可能位于组织中多个门户的文档聚合到 MinIO 中。创建文档管道是另一篇文章的主题 - 所以现在，我们将手动将一些文档暂存到 MinIO 桶中。我在这里也只会使用文本文档来保持简单。但是，这里有一些处理文档中多种文件格式和非文本的提示。首先，查看 Unstructured 的库，用于分区、清理和提取。其次，如果您专门处理 PDF，请查看 Open-Parse 库。我们在之前的博客文章《使用 Open-Parse 智能分块提高 RAG 性能》中介绍了 Open-Parse。下面的屏幕截图显示了我们的自定义语料库。我从古腾堡计划中下载了四本被认为是经典的流行书籍的文本版本。</p> 
 <ul><li> 
   <section> 
    <p>人性论——大卫·休谟</p> 
   </section></li><li> 
   <section> 
    <p>孙子兵法 - 孙子</p> 
   </section></li><li> 
   <section> 
    <p>杰基尔博士和海德先生的奇案 - 罗伯特·路易斯·史蒂文森</p> 
   </section></li><li> 
   <section> 
    <p>《海底两万里》——儒勒·凡尔纳</p> 
   </section></li></ul> 
 <figure> 
  <img src="https://images2.imgbox.com/bf/d2/OR5vdIgf_o.png" alt=""> 
 </figure> 
 <p>现在我们有了一个自定义语料库，我们可以设置一个向量数据库来保存嵌入。</p> 
 <h3><span class="prefix"></span><span class="content">设置 MinIO 和矢量数据库</span><span class="suffix"></span></h3> 
 <p>我将使用的向量数据库是 Pgvector。Pgvector 是 PostgreSQL 的开源扩展，允许用户在数据库中存储、搜索和分析矢量数据。这篇文章的代码下载有一个 docker-compose 文件，其中包含 MinIO、Pgvector 和 pgAdmin。在与 docker-compose fill 相同的目录中运行以下命令会将这三个服务作为容器显示出来。</p> 
 <pre class="custom"><code class="hljs">docker-compose up -d<br></code></pre> 
 <p>还有一个init.sql文件（如下所示）。docker-compose 文件将此文件映射到容器的启动目录。这会导致文件中的 SQL 运行，从而在 Postgres 中创建向量扩展和一个“嵌入”表，其中包含下面 SQL 文件中显示的字段。</p> 
 <pre class="custom"><code class="hljs">CREATE EXTENSION IF NOT EXISTS vector;<br><br>CREATE TABLE IF NOT EXISTS embeddings (<br> id SERIAL PRIMARY KEY,<br> embedding vector,<br> text text,<br> created_at timestamptz DEFAULT now()<br>);<br><br></code></pre> 
 <h3><span class="prefix"></span><span class="content">将嵌入模型保存到 MinIO</span><span class="suffix"></span></h3> 
 <p>我们将使用的嵌入模型是 Hugging Face 的开源模型。详细信息如下所示。在运行实验时指定特定版本始终是一个好主意。模型名称：intfloat/multilingual-e5-small修订版：ffdcc22a9a5c973ef0470385cef91e1ecb461d9f</p> 
 <p>不要被模型的名字所迷惑。它一点也不小。它是 1.4GB。我们需要下载这个模型并上传到 MinIO。这是一项一次性设置任务，用于在分布式环境中暂存此模型以进行实验。遗憾的是，我们需要的 Hugging Face 函数（snapshot_download）没有 S3 接口，所以我们会使用 MinIO Python SDK 将模型上传到 MinIO。更复杂的是，Hugging Face 模型不是单个文件。它是下载到指定目录中的文件集合。我们必须将整个目录上传到 MinIO，并使用 MinIO 路径保留文件夹结构。这是使用如下所示的“upload_model_to_minio”函数完成的。</p> 
 <pre class="custom"><code class="hljs">from huggingface_hub import snapshot_download<br><br>def upload_model_to_minio(bucket_name: str, full_model_name: str, revision: str) -&gt; None:<br>   <span class="hljs-string">''</span><span class="hljs-string">'<br>   Download a model from Hugging Face and upload it to MinIO. This function will use<br>   the current systems temp directory to temporarily save the model.<br>   '</span><span class="hljs-string">''</span><br><br>   <span class="hljs-comment"># Create a local directory for the model.</span><br>   <span class="hljs-comment">#home = str(Path.home())</span><br>   temp_dir = tempfile.gettempdir()<br>   base_path = f<span class="hljs-string">'{temp_dir}{os.sep}hf-models'</span><br>   os.makedirs(base_path, exist_ok=True)<br><br>   <span class="hljs-comment"># Get the user name and the model name.</span><br>   tmp = full_model_name.split(<span class="hljs-string">'/'</span>)<br>   user_name = tmp[0]<br>   model_name = tmp[1]<br><br>   <span class="hljs-comment"># The snapshot_download will use this pattern for the path name.</span><br>   model_path_name=f<span class="hljs-string">'models--{user_name}--{model_name}'</span><br>   <span class="hljs-comment"># The full path on the local drive.</span><br>   full_model_local_path = base_path + os.sep + model_path_name + os.sep + <span class="hljs-string">'snapshots'</span> + <br>                           os.sep + revision<br>   <span class="hljs-comment"># The path used by MinIO.</span><br>   full_model_object_path = model_path_name + <span class="hljs-string">'/snapshots/'</span> + revision<br><br>   <span class="hljs-built_in">print</span>(f<span class="hljs-string">'Starting download from HF to {full_model_local_path}.'</span>)<br>   snapshot_download(repo_id=full_model_name, revision=revision, cache_dir=base_path)<br><br>   <span class="hljs-built_in">print</span>(<span class="hljs-string">'Uploading to MinIO.'</span>)<br>   upload_local_directory_to_minio(full_model_local_path, bucket_name, <br>                                   full_model_object_path)<br>   shutil.rmtree(full_model_local_path)<br><br></code></pre> 
 <p>运行以下命令将使用此函数将我们的模型上传到名为“hf-models”的存储桶中。</p> 
 <pre class="custom"><code class="hljs">MODELS_BUCKET = <span class="hljs-string">'hf-models'</span><br>EMBEDDING_MODEL = <span class="hljs-string">'intfloat/multilingual-e5-small'</span><br>EMBEDDING_MODEL_REVISION = <span class="hljs-string">'ffdcc22a9a5c973ef0470385cef91e1ecb461d9f'</span><br><br>upload_model_to_minio(MODELS_BUCKET, EMBEDDING_MODEL, EMBEDDING_MODEL_REVISION)<br><br></code></pre> 
 <h3><span class="prefix"></span><span class="content">嵌入函数库</span><span class="suffix"></span></h3> 
 <p>当你使用像 Ray Data 这样的库来分发数据处理时——在本例中是文本的分块和每个块的嵌入生成——你真正要做的就是编排简单的函数调用，这些函数调用在此过程中执行一项任务。下面列出了从 MinIO 存储桶中的文档列表创建嵌入所需的所有函数，以及它们的参数和返回值。如您所见，我们拥有嵌入文档集合所需的一切。</p> 
 <pre class="custom"><code class="hljs">create_logger() -&gt; logging.Logger<br></code></pre> 
 <p>创建一个 Python 记录器，用于将调试、信息、错误、警告和关键消息发送到日志记录存储库。</p> 
 <pre class="custom"><code class="hljs">download_model_from_minio(bucket_name: str, full_model_name: str, revision: str) -&gt; str<br></code></pre> 
 <p>将模型从 MinIO 下载到当前系统临时目录。一旦它被加载到内存中，它将删除它。</p> 
 <pre class="custom"><code class="hljs">get_document_from_minio(bucket_name: str, object_name: str) -&gt; str:<br></code></pre> 
 <p>从 MinIO 下载单个文档，并将其保存到当前系统临时目录中。</p> 
 <pre class="custom"><code class="hljs">get_object_list(bucket_name: str) -&gt; List[str]:<br></code></pre> 
 <p>返回指定存储桶中的对象列表。此列表将发送到 Ray Data，后者将其均匀分布在集群中的所有 Ray actor 中。</p> 
 <pre class="custom"><code class="hljs">save_embeddings_to_vectordb(chunks, embeddings) -&gt; None:<br></code></pre> 
 <p>将嵌入和文本块一起保存到向量数据库中。</p> 
 <pre class="custom"><code class="hljs">upload_local_directory_to_minio(local_path:str, bucket_name:str , minio_path:str) -&gt; None<br></code></pre> 
 <p>将指定本地目录的内容上传到 MinIO，将文件夹结构保留为指定存储桶内的路径。</p> 
 <pre class="custom"><code class="hljs">upload_model_to_minio(bucket_name: str, full_model_name: str, revision: str) -&gt; None:<br><br></code></pre> 
 <p>从Hugging Face下载模型到当前系统临时目录，然后将模型上传到指定的Bucket，同时保留文件夹结构作为指定Bucket内的路径。</p> 
 <h3><span class="prefix"></span><span class="content">一个简单的嵌入子系统</span><span class="suffix"></span></h3> 
 <p>让我们使用上述函数并创建一个简单的非分布式脚本。下面的代码将为 Robert Louis Stevenson 的“The Strange Case of Dr Jekyll and Mr Hyde”创建嵌入。首先，我们需要下载我们希望使用的嵌入模型，并将其保存到 MinIO 中。这是一项一次性任务;您无需在每次想要嵌入新一批模型或运行实验时都这样做。</p> 
 <pre class="custom"><code class="hljs">MODELS_BUCKET = <span class="hljs-string">'hf-models'</span><br>EMBEDDING_MODEL = <span class="hljs-string">'intfloat/multilingual-e5-small'</span> <span class="hljs-comment"># Embedding model to use for converting text chunks to vector embeddings.</span><br>EMBEDDING_MODEL_REVISION = <span class="hljs-string">'ffdcc22a9a5c973ef0470385cef91e1ecb461d9f'</span><br><br>eu.upload_model_to_minio(MODELS_BUCKET, EMBEDDING_MODEL, EMBEDDING_MODEL_REVISION)<br></code></pre> 
 <p>接下来，我们需要从 MinIO 下载我们的模型，实例化它，创建一个分块器（或拆分器），创建嵌入并将它们保存到我们的 pgvector 数据库中。</p> 
 <pre class="custom"><code class="hljs">CHUNK_SIZE = 1000         <span class="hljs-comment"># Text chunk sizes which will be converted to vector embeddings</span><br>CHUNK_OVERLAP = 10<br>DIMENSION = 384           <span class="hljs-comment"># Embeddings size</span><br><br>model_path = eu.download_model_from_minio(MODELS_BUCKET, EMBEDDING_MODEL, <br><br>                                          EMBEDDING_MODEL_REVISION)<br>device = torch.device(<span class="hljs-string">"cuda"</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">"cpu"</span>)<br>embedding_model = SentenceTransformer(model_path, device=device)<br>chunker = RecursiveCharacterTextSplitter(chunk_size=CHUNK_SIZE, <br><br>                                         chunk_overlap=CHUNK_OVERLAP, length_function=len)<br><br>temp_file = eu.get_document_from_minio(BUCKET_NAME, <br><br>                                       <span class="hljs-string">'The Strange Case of Dr Jekyll and Mr Hyde.txt'</span>)<br>file = open(temp_file, <span class="hljs-string">'r'</span>)<br>data = file.read()<br>chunks = chunker.split_text(data)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">'Number of chunks:'</span>, len(chunks))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">'Length of the first chunk:'</span>, len(chunks[0]))<br><br>embeddings = embedding_model.encode(chunks, batch_size=BATCH_SIZE).tolist()<br><span class="hljs-built_in">print</span>(<span class="hljs-string">'Number of embeddings:'</span>, len(embeddings))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">'Length of the first embedding:'</span>, len(embeddings[0]))<br><br>eu.save_embeddings_to_vectordb(chunks, embeddings)<br><br></code></pre> 
 <p>请注意，如果我们可以访问 GPU，则我们正在使用 GPU。此外，一切都是配置驱动的，因此运行不同的实验就是更改配置以反映您希望运行的实验的问题。这包括根据需要更改嵌入模型。</p> 
 <p>下面是 pgAdmin 的屏幕截图，显示了我们新创建的嵌入。</p> 
 <figure> 
  <img src="https://images2.imgbox.com/d8/f6/5iDqleLl_o.png" alt=""> 
 </figure> 
 <p>现在我们有了一个简单的脚本，可以为单个文档创建嵌入，下一步是将此代码迁移到在集群中运行的框架。这将允许并行嵌入整个文档语料库。我们将使用 Ray Data 来执行此操作。</p> 
 <h3><span class="prefix"></span><span class="content">分发嵌入子系统</span><span class="suffix"></span></h3> 
 <p>分发嵌入子系统的第一步是将所有工作放入一个行为类似于函数的类中。这是使用 Python 的“__call__”内置方法完成的。（这是光线数据的要求。我们的班级如下所示。</p> 
 <pre class="custom"><code class="hljs">class Embed:<br><br>   def __init__(self):<br>       device = torch.device(<span class="hljs-string">"cuda"</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">"cpu"</span>)<br>      <br>       model_path = eu.download_model_from_minio(MODELS_BUCKET, EMBEDDING_MODEL, <br><br>                                                 EMBEDDING_MODEL_REVISION)<br>       self.embedding_model = SentenceTransformer(model_path, device=device)<br>       self.splitter = RecursiveCharacterTextSplitter(chunk_size=CHUNK_SIZE, <br><br>                                                      chunk_overlap=CHUNK_OVERLAP, <br><br>                                                      length_function=len)<br><br>   def __call__(self, batch_list: List[str]) -&gt; None:<br>       document_list = batch_list[<span class="hljs-string">"item"</span>]<br><br>       timings = []<br>       documents = []<br>       <span class="hljs-keyword">for</span> document_data <span class="hljs-keyword">in</span> document_list:<br>           start_time = time()<br>           bucket_name = document_data[0]<br>           object_name = document_data[1]<br>           temp_file = eu.get_document_from_minio(bucket_name, object_name)<br>           file = open(temp_file, <span class="hljs-string">'r'</span>)<br>           data = file.read()<br><br>           chunks = self.splitter.split_text(data)<br>           embeddings = self.embedding_model.encode(chunks, batch_size=BATCH_SIZE).tolist()<br>           eu.save_embeddings_to_vectordb(chunks, embeddings)<br>          <br>           total_time_sec = time() - start_time<br>           documents.append(object_name)<br>           timings.append(total_time_sec)<br><br>       <span class="hljs-built_in">return</span> {<!-- --><span class="hljs-string">'timings'</span>: timings, <span class="hljs-string">'documents'</span>: documents}<br><br></code></pre> 
 <p>Ray Data 将为我们将很快创建的 Ray 集群中的每个 actor 实例化一次此类。此对象将保持活动状态，并接收多个批次进行处理。请注意，“__init__”函数正在下载我们的嵌入模型，并使用它创建一个 SentenceTransformer。SentenceTransformer 类使使用嵌入模型变得容易。此外，我们还使用 LangChain 的 RecursiveCharacterTextSplitter 来分割或分块我们的文档。它根据字符列表（我们使用其默认列表）递归拆分文本，从列表中的第一个字符开始，如果第一个拆分太大，则继续到下一个字符。目标是将相关的文本片段保持在一起，保留它们的语义关系。所有这些设置工作仅在创建 Embed 对象时发生一次。我们本可以使用一个简单的函数来分配工作，但是必须为每个批次完成此设置工作，当您要进行设置工作时，这不是正确的设计。</p> 
 <p>接下来，我们需要初始化 Ray 集群。</p> 
 <pre class="custom"><code class="hljs"><br>ray.init(<br>   <span class="hljs-comment">#address="ray://ray-cluster-kuberay-head-svc:10001",</span><br>   runtime_env={<!-- --><br>       <span class="hljs-string">"env_vars"</span>: {<!-- --><br>           <span class="hljs-string">"MINIO_URL"</span>: MINIO_URL,<br>           <span class="hljs-string">"MINIO_ACCESS_KEY"</span>: MINIO_ACCESS_KEY,<br>           <span class="hljs-string">"MINIO_SECRET_KEY"</span>: MINIO_SECRET_KEY,<br>           <span class="hljs-string">"MINIO_SECURE"</span>: str(MINIO_SECURE),<br>           <span class="hljs-string">"PGVECTOR_HOST"</span>: os.environ[<span class="hljs-string">'PGVECTOR_HOST'</span>],<br>           <span class="hljs-string">"PGVECTOR_DATABASE"</span>: os.environ[<span class="hljs-string">'PGVECTOR_DATABASE'</span>],<br>           <span class="hljs-string">"PGVECTOR_USER"</span>: os.environ[<span class="hljs-string">'PGVECTOR_USER'</span>],<br>           <span class="hljs-string">"PGVECTOR_PASSWORD"</span>: os.environ[<span class="hljs-string">'PGVECTOR_PASSWORD'</span>],<br>           <span class="hljs-string">"PGVECTOR_PORT"</span>: os.environ[<span class="hljs-string">'PGVECTOR_PORT'</span>],<br>       },<br>       <span class="hljs-string">"pip"</span>: [              <br>           <span class="hljs-string">"datasets==2.19.0"</span>,<br>           <span class="hljs-string">"huggingface_hub==0.22.2"</span>,<br>           <span class="hljs-string">"minio==7.2.7"</span>,<br>           <span class="hljs-string">"psycopg2-binary==2.9.9"</span>,<br>           <span class="hljs-string">"pyarrow==16.0.0"</span>,<br>           <span class="hljs-string">"sentence-transformers==3.0.1"</span>,<br>           <span class="hljs-string">"torch==2.3.0"</span>,<br>           <span class="hljs-string">"transformers==4.40.1"</span>,<br>       ]<br>   }<br>)<br><br></code></pre> 
 <p>在我们的演示中，我们将创建一个本地 Ray 实例。我没有使用 Kubernetes 集群。这是在移动到真实集群之前让代码正常工作的最佳方法。我们还没有创建任何 Ray actor - 但我们正在发送 Ray 配置信息，告诉 Ray 每个 actor 需要的环境变量和库。接下来，我们创建一个 Ray 数据集来保存我们想要发送到将在每个 Ray actor 中运行的 Embed 类实例的所有数据。在我们的例子中，每个 Ray actor 都将收到一个存储在 MinIO 中的对象引用列表（文档的路径）。我们将使用上述函数库中的“get_object_list”函数。从 “ray.data.from_items（） 返回的 Ray 数据集包含的逻辑，当我们启动分布式嵌入过程时，该逻辑会将此列表转换为每个 actor 的较小批次。</p> 
 <pre class="custom"><code class="hljs"><br><span class="hljs-comment"># The embedding class expects bucket_name and document_name pairs - so add bucket name to each entry in the list.</span><br>document_list = eu.get_object_list(BUCKET_NAME)<br>list_for_ray = [[BUCKET_NAME, doc] <span class="hljs-keyword">for</span> doc <span class="hljs-keyword">in</span> document_list]<br><br>ray_ds = ray.data.from_items(list_for_ray)<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">type</span>(ray_ds))<br><span class="hljs-built_in">print</span>(ray_ds.schema)<br><br></code></pre> 
 <p>我们几乎已经准备好进行一些分布式计算，但我们还有一个编码任务要完成。我们需要将 Ray 数据集映射到我们的 Embed 类，并告诉 Ray 如何设置我们之前为此工作负载初始化的集群。这是使用 Ray 数据集的“map_batches”方法完成的。您可以将函数或可调用类发送到“map_batches”。如果发送函数，Ray Data 将使用无状态 Ray 任务。对于类，Ray Data 使用有状态的 Ray actor。</p> 
 <pre class="custom"><code class="hljs">ds_embed = ray_ds.map_batches(<br>   Embed,<br>   concurrency=ACTOR_POOL_SIZE,<br>   batch_size=BATCH_SIZE,  <span class="hljs-comment"># Large batch size to maximize GPU utilization.</span><br>   <span class="hljs-comment">#num_gpus=1,            # 1 GPU for each actor.</span><br>   num_cpus=1,             <span class="hljs-comment"># 1 CPU for each actor.</span><br>)<br></code></pre> 
 <p>请注意，我们正在传入需要为每个 actor 实例化的 Embed 类。我们还指定了 actor 的数量、每次调用 actor 的批量大小，最后指定了每个 actor 可访问的 GPU 和 CPU 数量。map_batches 方法返回另一个 Ray 数据集 （ds_embed），其中包含所有 actor 的所有返回值。这是 Embedded 中“__call__”方法的返回值的集合。</p> 
 <p>最后，我们准备开始我们的分布式嵌入工作。您可能已经注意到，上一个命令运行得非常快。那是因为还没有进行任何计算。Ray 中的转换（map_batch被认为是转换）是“惰性”。在通过循环访问数据集、保存数据集或检查数据集的属性来触发数据使用之前，不会执行它们。因此，我们需要向ds_embed请求 actor 的返回值。这是在下面完成的。下面的代码片段需要一些时间才能运行。</p> 
 <pre class="custom"><code class="hljs">def ray_data_task(ds_embed):<br>   results = []<br>   <span class="hljs-keyword">for</span> row <span class="hljs-keyword">in</span> ds_embed.iter_rows():<br>       documents = row[<span class="hljs-string">'documents'</span>]<br>       timings = row[<span class="hljs-string">'timings'</span>]<br>       results.append((documents, timings))<br>   <span class="hljs-built_in">return</span> results<br><br>results = ray_data_task(ds_embed)<br><br>results<br><br><br></code></pre> 
 <p>就是这样。大功告成。完成上述代码后，您将看到类似于下面显示的输出。</p> 
 <pre class="custom"><code class="hljs">[(<span class="hljs-string">'A Treatise of Human Nature.txt'</span>, 75.08733916282654),<br> (<span class="hljs-string">'The Art of War.txt'</span>, 21.960258722305298),<br> (<span class="hljs-string">'The Strange Case of Dr Jekyll and Mr Hyde.txt'</span>, 10.052802085876465),<br> (<span class="hljs-string">'Twenty Thousand Leagues under the Sea.txt'</span>, 39.24100613594055)]<br><br></code></pre> 
 <h3><span class="prefix"></span><span class="content">总结</span><span class="suffix"></span></h3> 
 <p>在这篇文章中，我们构建了一个分布式嵌入子系统，可以在工程工作站和完全分布式的云原生生产环境中运行。所介绍的代码具有以下优点，可直接解决我们简介中确定的复杂性和实际问题。</p> 
 <ul><li> 
   <section> 
    <p>实验可以高效运行，从而可以对不同的配置选项进行彻底测试。</p> 
   </section></li><li> 
   <section> 
    <p>除了配置选项之外，还应尝试使用解析选项。这将允许您处理多种文件类型并处理文档中的非文本数据。</p> 
   </section></li><li> 
   <section> 
    <p>使用此处显示的代码时，您的生产环境将运行工程师用于测试和试验的相同代码。</p> 
   </section></li><li> 
   <section> 
    <p>分布式嵌入子系统可以在集群中运行。集群可以快速扩展，以处理需要批量处理的大量文档，也可以针对实时工作负载进行扩展。</p> 
   </section></li><li> 
   <section> 
    <p>本文中介绍的代码封装了向量数据库调用，使工程师可以交换不同的产品。</p> 
   </section></li><li> 
   <section> 
    <p>MinIO 是生成式 AI 的最佳存储解决方案。正如我们在这篇文章中看到的，嵌入模型和文档必须存储在高速、可扩展的存储解决方案中。</p> 
   </section></li></ul> 
</section>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/ce7b8ed37a250fb9b99d84e66aa212df/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">大语言模型时代的挑战与机遇：青年发展、教育变革与就业前景</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/73fdcf978de56762c465ca667ab0d9e7/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">用于仅摄像头闭环驾驶的视觉语言模型</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>