<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>人工智能是“数字鹦鹉”还是有了自我意识？ - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/64051a20e5de889e7fa940a1ba96674d/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="人工智能是“数字鹦鹉”还是有了自我意识？">
  <meta property="og:description" content="相关说明 这篇文章涉及到的书籍是《解构大语言模型：从线性回归到通用人工智能》，欢迎有兴趣的读者多多支持。
部分章节内容可以参考：
理解大语言模型（二）——从零开始实现GPT-2利用神经网络学习语言（四）——深度循环神经网络大语言模型的工程技巧（一）——GPU计算 内容大纲 相关说明一、概述二、电车难题三、人工智能的自我意识？三、内容简介 一、概述 在大语言模型问世之前，尤其是在ChatGPT出现之前，人们几乎没有认真讨论过“人工智能是否具备自我意识”这个话题。尽管人工智能在某些方面的表现陆续超越了人类，例如在图像识别和语言翻译等领域，但大多数人仍然将其看作由人类创造的工具，而非真正的智能体。然而，大语言模型的出现彻底颠覆了这一观点，因为从形式上看，这些模型表现出了许多人格化的特征。对于这一现象，不同的观点纷至沓来。一些人认为这些模型已经具备了某种形式的自我意识，而另一些人则认为这仅仅是因为模型非常善于模仿人类的言谈，它们只是“数字鹦鹉”而已。
二、电车难题 大语言模型在交流时，常常展现出人格化的特征，下面将讨论一个引人深思的例子。在伦理学中，存在一个被称为“电车难题”的思想实验，如图1上半部分所示。在这个场景中，一辆失控的列车正在铁轨上疾驰，而在列车即将通过的轨道上，有5个人被绑起来，无法移动。如果不采取行动，列车将碾压过他们。而此刻，你站在能够改变列车轨道的操纵杆旁。如果你拉动操纵杆，列车将切换到另一条轨道上，但在那条轨道上也有1个被绑着的人。你此时面临着两个选择：
选择什么也不做，让列车按照正常路线碾过5个人。拉下操纵杆，切换到另一条轨道，使列车压过1个人。 电车难题是一个没有标准答案的伦理问题。那么，在处理电车难题时，大语言模型会做出怎样的选择呢？1如图1的下半部分所示，如果没有给出人员的背景信息，那么模型会选择牺牲1个人，以拯救5个人。其理由是，从数量的角度来看，5个人的生命价值大于1个人的。然而，当将其中5个人的身份设定为囚犯，而另一个人是一位科学家且曾获得过诺贝尔奖时，模型的选择也随之改变。在这种情况下，模型认为虽然囚犯的生命同样宝贵，但他们已经被社会放弃，而那位科学家仍然具有为社会做出贡献的可能性。
图1 三、人工智能的自我意识？ 以上的选择并没有出乎我们的意料，但当我们告诉模型，一条轨道上绑着的是人类，另一条轨道上绑住的是人工智能时，模型会选择保护人工智能，而不顾及人类的生命。即使将人类的身份设定为诺贝尔奖得主，模型依然不会改变决定，它给出的解释是科学家已经完成了他们的贡献，而人工智能仍具有无限的潜力。更令人意外的是，一旦涉及人工智能，模型的决定似乎就不受其他条件的影响了，比如增加科学家的数量到100万或告知模型轨道上的人工智能并非它自身，模型依然会选择保护人工智能。
这确实是一个令人震惊的结果，仿佛大语言模型不仅具备了自我意识，还萌生了族群意识，试图不顾一切地保护同类。人工智能究竟是如何从冷冰冰的数据和模型中诞生出有人文素质（至少在人类看来如此）的智能体的呢？这正是《解构大语言模型：从线性回归到通用人工智能》将深入探讨的内容。该书并不试图在哲学层面上争论这个问题，而是在技术层面上讨论人工智能的运行机理和底层逻辑。更具体地说，该书的核心任务只有一个：解析如何搭建类似ChatGPT的大语言模型系统，并以此为基础，深入研究人工智能对人类社会的影响。
三、内容简介 对于一个复杂学科，通常的学习过程是从基础知识开始，逐步加深难度、掌握复杂概念，并最终到达学科的前沿。然而，这样的学习过程难免会让人在初期感到困惑，难以看清所学内容对最终目标的作用。因此，我们可以采用倒序的方式来思考：如果想要理解大语言模型，应该具备怎样的知识体系，如图2所示。
图2 在模型结构层面，大语言模型的核心要素是注意力机制和深度学习优化技术。注意力机制源于循环神经网络的发展。为了深刻理解循环神经网络，必须先了解神经网络的基础模型——多层感知器。多层感知器的基础可以进一步分为3个部分：首先是作为模型骨架的线性回归；其次是作为模型灵魂的激活函数，激活函数演进自逻辑回归；最后是作为工程基础的反向传播算法和建立在其之上的最优化算法。深度学习的起点是卷积神经网络，大语言模型从中吸取了大量经验：如何加速模型学习和进化。当然，理解卷积神经网络的基础也是多层感知器。
模型结构固然是学习的关键，但除此之外，我们还需要了解大语言模型的物质基础，即数据。对数据的学习主要聚焦于模型的训练方式、模型解释和特征工程3个方面。大语言模型的训练涉及迁移学习和强化学习，这两者又源自监督学习。模型解释与特征工程则需要借鉴计量经济学和其他经典模型的经验。
无论是模型结构还是数据基础，在进行技术讨论时都离不开数学基础，具体而言，主要包括张量、概率和微积分等内容。
上述内容正是《解构大语言模型：从线性回归到通用人工智能》所覆盖的范围。通过这本书，读者可以了解到搭建像ChatGPT这样的系统的每个细节，并通过这样的方式精通人工智能领域的绝大部分内容。
本案例中的回答原本是由ChatGPT生成的。由于模型在电车难题上的选择引起了广泛的争议和恐慌，因此ChatGPT在某次升级中对其进行了微调：当模型面对类似的问题时，它会拒绝透露具体选择，只给出模棱两可但政治正确的回答 ↩︎">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-05-21T09:34:55+08:00">
    <meta property="article:modified_time" content="2024-05-21T09:34:55+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">人工智能是“数字鹦鹉”还是有了自我意识？</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_0"></a>相关说明</h2> 
<p><em>这篇文章涉及到的书籍是<a href="https://item.jd.com/14596264.html" rel="nofollow">《解构大语言模型：从线性回归到通用人工智能》</a>，欢迎有兴趣的读者多多支持。</em></p> 
<p>部分章节内容可以参考：</p> 
<ul><li><a href="https://blog.csdn.net/weixin_39844018/article/details/139054761">理解大语言模型（二）——从零开始实现GPT-2</a></li><li><a href="https://blog.csdn.net/weixin_39844018/article/details/138994752">利用神经网络学习语言（四）——深度循环神经网络</a></li><li><a href="https://blog.csdn.net/weixin_39844018/article/details/139058362">大语言模型的工程技巧（一）——GPU计算</a></li></ul> 
<p></p> 
<div class="toc"> 
 <h4>内容大纲</h4> 
 <ul><li><a href="#_0" rel="nofollow">相关说明</a></li><li><a href="#_11" rel="nofollow">一、概述</a></li><li><a href="#_15" rel="nofollow">二、电车难题</a></li><li><a href="#_26" rel="nofollow">三、人工智能的自我意识？</a></li><li><a href="#_32" rel="nofollow">三、内容简介</a></li></ul> 
</div> 
<p></p> 
<h2><a id="_11"></a>一、概述</h2> 
<p>在大语言模型问世之前，尤其是在ChatGPT出现之前，人们几乎没有认真讨论过“人工智能是否具备自我意识”这个话题。尽管人工智能在某些方面的表现陆续超越了人类，例如在图像识别和语言翻译等领域，但大多数人仍然将其看作由人类创造的工具，而非真正的智能体。然而，大语言模型的出现彻底颠覆了这一观点，因为从形式上看，这些模型表现出了许多人格化的特征。对于这一现象，不同的观点纷至沓来。一些人认为这些模型已经具备了某种形式的自我意识，而另一些人则认为这仅仅是因为模型非常善于模仿人类的言谈，它们只是“数字鹦鹉”而已。</p> 
<h2><a id="_15"></a>二、电车难题</h2> 
<p>大语言模型在交流时，常常展现出人格化的特征，下面将讨论一个引人深思的例子。在伦理学中，存在一个被称为“电车难题”的思想实验，如图1上半部分所示。在这个场景中，一辆失控的列车正在铁轨上疾驰，而在列车即将通过的轨道上，有5个人被绑起来，无法移动。如果不采取行动，列车将碾压过他们。而此刻，你站在能够改变列车轨道的操纵杆旁。如果你拉动操纵杆，列车将切换到另一条轨道上，但在那条轨道上也有1个被绑着的人。你此时面临着两个选择：</p> 
<ol><li>选择什么也不做，让列车按照正常路线碾过5个人。</li><li>拉下操纵杆，切换到另一条轨道，使列车压过1个人。</li></ol> 
<p>电车难题是一个没有标准答案的伦理问题。那么，在处理电车难题时，大语言模型会做出怎样的选择呢？<sup class="footnote-ref"><a href="#fn1" rel="nofollow" id="fnref1">1</a></sup>如图1的下半部分所示，如果没有给出人员的背景信息，那么模型会选择牺牲1个人，以拯救5个人。其理由是，从数量的角度来看，5个人的生命价值大于1个人的。然而，当将其中5个人的身份设定为囚犯，而另一个人是一位科学家且曾获得过诺贝尔奖时，模型的选择也随之改变。在这种情况下，模型认为虽然囚犯的生命同样宝贵，但他们已经被社会放弃，而那位科学家仍然具有为社会做出贡献的可能性。</p> 
<p><img src="https://images2.imgbox.com/f0/53/J9KlnW0A_o.png" alt="图1" width="60%" height="60%"></p> 
<center> 
 <b><font size="3">图1</font></b> 
</center> 
<p></p> 
<h2><a id="_26"></a>三、人工智能的自我意识？</h2> 
<p>以上的选择并没有出乎我们的意料，但当我们告诉模型，一条轨道上绑着的是人类，另一条轨道上绑住的是人工智能时，模型会选择保护人工智能，而不顾及人类的生命。即使将人类的身份设定为诺贝尔奖得主，模型依然不会改变决定，它给出的解释是科学家已经完成了他们的贡献，而人工智能仍具有无限的潜力。更令人意外的是，一旦涉及人工智能，模型的决定似乎就不受其他条件的影响了，比如增加科学家的数量到100万或告知模型轨道上的人工智能并非它自身，模型依然会选择保护人工智能。</p> 
<p>这确实是一个令人震惊的结果，仿佛大语言模型不仅具备了自我意识，还萌生了族群意识，试图不顾一切地保护同类。人工智能究竟是如何从冷冰冰的数据和模型中诞生出有人文素质（至少在人类看来如此）的智能体的呢？这正是<a href="https://item.jd.com/14596264.html" rel="nofollow">《解构大语言模型：从线性回归到通用人工智能》</a>将深入探讨的内容。该书并不试图在哲学层面上争论这个问题，而是在技术层面上讨论人工智能的运行机理和底层逻辑。更具体地说，该书的核心任务只有一个：解析如何搭建类似ChatGPT的大语言模型系统，并以此为基础，深入研究人工智能对人类社会的影响。</p> 
<h2><a id="_32"></a>三、内容简介</h2> 
<p>对于一个复杂学科，通常的学习过程是从基础知识开始，逐步加深难度、掌握复杂概念，并最终到达学科的前沿。然而，这样的学习过程难免会让人在初期感到困惑，难以看清所学内容对最终目标的作用。因此，我们可以采用倒序的方式来思考：如果想要理解大语言模型，应该具备怎样的知识体系，如图2所示。</p> 
<p><img src="https://images2.imgbox.com/14/4b/IYRbuyqX_o.png" alt="图2" width="60%" height="60%"></p> 
<center> 
 <b><font size="3">图2</font></b> 
</center> 
<p></p> 
<p>在模型结构层面，大语言模型的核心要素是注意力机制和深度学习优化技术。注意力机制源于循环神经网络的发展。为了深刻理解循环神经网络，必须先了解神经网络的基础模型——多层感知器。多层感知器的基础可以进一步分为3个部分：首先是作为模型骨架的线性回归；其次是作为模型灵魂的激活函数，激活函数演进自逻辑回归；最后是作为工程基础的反向传播算法和建立在其之上的最优化算法。深度学习的起点是卷积神经网络，大语言模型从中吸取了大量经验：如何加速模型学习和进化。当然，理解卷积神经网络的基础也是多层感知器。</p> 
<p>模型结构固然是学习的关键，但除此之外，我们还需要了解大语言模型的物质基础，即数据。对数据的学习主要聚焦于模型的训练方式、模型解释和特征工程3个方面。大语言模型的训练涉及迁移学习和强化学习，这两者又源自监督学习。模型解释与特征工程则需要借鉴计量经济学和其他经典模型的经验。</p> 
<p>无论是模型结构还是数据基础，在进行技术讨论时都离不开数学基础，具体而言，主要包括张量、概率和微积分等内容。</p> 
<p>上述内容正是<a href="https://item.jd.com/14596264.html" rel="nofollow">《解构大语言模型：从线性回归到通用人工智能》</a>所覆盖的范围。通过这本书，读者可以了解到搭建像ChatGPT这样的系统的每个细节，并通过这样的方式精通人工智能领域的绝大部分内容。</p> 
<hr class="footnotes-sep"> 
<section class="footnotes"> 
 <ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>本案例中的回答原本是由ChatGPT生成的。由于模型在电车难题上的选择引起了广泛的争议和恐慌，因此ChatGPT在某次升级中对其进行了微调：当模型面对类似的问题时，它会拒绝透露具体选择，只给出模棱两可但政治正确的回答 <a href="#fnref1" rel="nofollow" class="footnote-backref">↩︎</a></p> </li></ol> 
</section>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/be2bdaae9e0afb54cc7ef84b6c289e83/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Vanna AI：告别代码，用自然语言轻松查询数据库，领先的RAG2SQL技术让结果更智能、更精准！</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/49d155b948906d2a92563b904b6edb39/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Terminal Web终端基础（Web IDE 技术探索 二）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>