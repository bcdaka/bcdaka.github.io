<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>在 CentOS 8.2.2004 上部署 ELK 栈实现日志归集20240813 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/a3e5f0b0fe42d88724b977ca020eb158/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="在 CentOS 8.2.2004 上部署 ELK 栈实现日志归集20240813">
  <meta property="og:description" content="在 CentOS 8.2.2004 上部署 ELK 栈实现日志归集 在现代分布式系统中，日志的集中管理和分析至关重要。ELK（Elasticsearch, Logstash, Kibana）是一个强大的日志处理和分析平台，能够帮助我们实现日志的集中管理。在本文中，我将详细介绍如何在 CentOS 8.2.2004 环境下部署 ELK 栈，并在 CentOS 6.6 服务器上使用 Filebeat 收集日志。
环境概述 日志归集服务端: CentOS 8.2.2004Java 应用服务器: CentOS 6.6日志收集工具: Filebeat日志处理和可视化工具: Elasticsearch, Logstash, Kibana ELK 栈及 Filebeat 组件介绍 Elasticsearch: Elasticsearch 是一个分布式搜索和分析引擎。它在日志归集中起到了日志数据存储和快速检索的核心作用。日志数据被发送到 Elasticsearch 进行索引，随后可以通过 Kibana 快速搜索和可视化。
Logstash: Logstash 是一个数据处理管道，能够从多种来源收集数据、解析并进行过滤，然后将处理后的数据发送到 Elasticsearch。它在日志归集中充当数据转换和处理的角色，可以根据需要对日志数据进行丰富的过滤和解析操作。
Kibana: Kibana 是一个开源数据可视化工具，专门为与 Elasticsearch 配合使用而设计。它为日志数据提供了图形化的用户界面，可以方便地进行搜索、分析和可视化展示。在日志归集中，Kibana 是前端展示和分析日志数据的主要工具。
Filebeat: Filebeat 是一个轻量级的日志收集器，安装在日志来源服务器上（如 Java 应用服务器）。它负责监控日志文件并将日志数据发送到 Logstash 或 Elasticsearch。在日志归集中，Filebeat 是日志数据从来源服务器传输到日志处理平台的入口。
部署步骤概述 在 CentOS 8 上安装和配置 ELK 栈
安装 Java安装并配置 Elasticsearch安装并配置 Kibana安装并配置 Logstash 在 Java 应用服务器（CentOS 6.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-08-14T10:31:05+08:00">
    <meta property="article:modified_time" content="2024-08-14T10:31:05+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">在 CentOS 8.2.2004 上部署 ELK 栈实现日志归集20240813</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_CentOS_822004__ELK__0"></a>在 CentOS 8.2.2004 上部署 ELK 栈实现日志归集</h2> 
<p>在现代分布式系统中，日志的集中管理和分析至关重要。ELK（Elasticsearch, Logstash, Kibana）是一个强大的日志处理和分析平台，能够帮助我们实现日志的集中管理。在本文中，我将详细介绍如何在 CentOS 8.2.2004 环境下部署 ELK 栈，并在 CentOS 6.6 服务器上使用 Filebeat 收集日志。</p> 
<h3><a id="_4"></a>环境概述</h3> 
<ul><li><strong>日志归集服务端</strong>: CentOS 8.2.2004</li><li><strong>Java 应用服务器</strong>: CentOS 6.6</li><li><strong>日志收集工具</strong>: Filebeat</li><li><strong>日志处理和可视化工具</strong>: Elasticsearch, Logstash, Kibana</li></ul> 
<h3><a id="ELK__Filebeat__11"></a>ELK 栈及 Filebeat 组件介绍</h3> 
<ol><li> <p><strong>Elasticsearch</strong>: Elasticsearch 是一个分布式搜索和分析引擎。它在日志归集中起到了日志数据存储和快速检索的核心作用。日志数据被发送到 Elasticsearch 进行索引，随后可以通过 Kibana 快速搜索和可视化。</p> </li><li> <p><strong>Logstash</strong>: Logstash 是一个数据处理管道，能够从多种来源收集数据、解析并进行过滤，然后将处理后的数据发送到 Elasticsearch。它在日志归集中充当数据转换和处理的角色，可以根据需要对日志数据进行丰富的过滤和解析操作。</p> </li><li> <p><strong>Kibana</strong>: Kibana 是一个开源数据可视化工具，专门为与 Elasticsearch 配合使用而设计。它为日志数据提供了图形化的用户界面，可以方便地进行搜索、分析和可视化展示。在日志归集中，Kibana 是前端展示和分析日志数据的主要工具。</p> </li><li> <p><strong>Filebeat</strong>: Filebeat 是一个轻量级的日志收集器，安装在日志来源服务器上（如 Java 应用服务器）。它负责监控日志文件并将日志数据发送到 Logstash 或 Elasticsearch。在日志归集中，Filebeat 是日志数据从来源服务器传输到日志处理平台的入口。</p> </li></ol> 
<hr> 
<h3><a id="_23"></a>部署步骤概述</h3> 
<ol><li> <p><strong>在 CentOS 8 上安装和配置 ELK 栈</strong></p> 
  <ul><li>安装 Java</li><li>安装并配置 Elasticsearch</li><li>安装并配置 Kibana</li><li>安装并配置 Logstash</li></ul> </li><li> <p><strong>在 Java 应用服务器（CentOS 6.6）上安装和配置 Filebeat</strong></p> 
  <ul><li>安装 Filebeat</li><li>配置并启动 Filebeat</li></ul> </li></ol> 
<hr> 
<h3><a id="_1_CentOS_8__ELK__37"></a>步骤 1：在 CentOS 8 上安装和配置 ELK 栈</h3> 
<h4><a id="1__Java_39"></a>1. 安装 Java</h4> 
<p>在 CentOS 8 上安装 OpenJDK 11：</p> 
<pre><code class="prism language-bash"><span class="token function">sudo</span> dnf <span class="token function">install</span> java-11-openjdk-devel <span class="token parameter variable">-y</span>
</code></pre> 
<p><strong>作用</strong>: Java 是 Elasticsearch 和 Logstash 运行所必需的基础依赖。Elasticsearch 和 Logstash 都是基于 Java 构建的，因此需要安装 Java 运行时环境（JRE）来支持它们的运行。</p> 
<h4><a id="2__Elasticsearch_49"></a>2. 安装 Elasticsearch</h4> 
<ol><li> <p>添加 Elasticsearch 官方 GPG 密钥：</p> <pre><code class="prism language-bash"><span class="token function">sudo</span> <span class="token function">rpm</span> <span class="token parameter variable">--import</span> https://artifacts.elastic.co/GPG-KEY-elasticsearch
</code></pre> </li><li> <p>创建 Elasticsearch 的 yum 源：</p> <pre><code class="prism language-bash"><span class="token function">sudo</span> <span class="token function">vi</span> /etc/yum.repos.d/elasticsearch.repo
</code></pre> <p>在文件中输入以下内容：</p> <pre><code class="prism language-plaintext">[elasticsearch-7.x]
name=Elasticsearch repository for 7.x packages
baseurl=https://artifacts.elastic.co/packages/7.x/yum
gpgcheck=1
gpgkey=https://artifacts.elastic.co/GPG-KEY-elasticsearch
enabled=1
autorefresh=1
type=rpm-md
</code></pre> </li><li> <p>安装 Elasticsearch：</p> <pre><code class="prism language-bash"><span class="token function">sudo</span> dnf <span class="token function">install</span> elasticsearch <span class="token parameter variable">-y</span> <span class="token parameter variable">--disablerepo</span><span class="token operator">=</span>docker-ce-stable
</code></pre> 
  <blockquote> 
   <p><strong>注意</strong>: 如果遇到 Docker YUM 源相关的错误，可以通过禁用 Docker YUM 源来解决。</p> 
  </blockquote> </li><li> <p>配置 Elasticsearch：</p> <p>修改配置文件 <code>/etc/elasticsearch/elasticsearch.yml</code>：</p> <pre><code class="prism language-bash"><span class="token function">sudo</span> <span class="token function">vi</span> /etc/elasticsearch/elasticsearch.yml
</code></pre> <p>设置以下内容：</p> <pre><code class="prism language-yaml"><span class="token key atrule">cluster.name</span><span class="token punctuation">:</span> my<span class="token punctuation">-</span>elk<span class="token punctuation">-</span>cluster
<span class="token key atrule">node.name</span><span class="token punctuation">:</span> elk<span class="token punctuation">-</span>node<span class="token punctuation">-</span><span class="token number">1</span>
<span class="token key atrule">network.host</span><span class="token punctuation">:</span> 0.0.0.0
<span class="token key atrule">discovery.seed_hosts</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"localhost"</span><span class="token punctuation">]</span>
</code></pre> </li><li> <p>启动并设置 Elasticsearch 为开机自启：</p> <pre><code class="prism language-bash"><span class="token function">sudo</span> systemctl start elasticsearch
<span class="token function">sudo</span> systemctl <span class="token builtin class-name">enable</span> elasticsearch
</code></pre> </li></ol> 
<p><strong>作用</strong>: Elasticsearch 是日志归集的核心存储引擎，它将接收来自 Logstash 或 Filebeat 的日志数据，并对这些数据进行索引和存储。Elasticsearch 支持快速检索和查询，使得我们可以通过 Kibana 快速访问和分析日志数据。</p> 
<h4><a id="_Elasticsearch__110"></a>单节点 Elasticsearch 集群配置</h4> 
<p>如果你使用的是单节点集群，并且遇到了 <code>master_not_discovered_exception</code> 错误，可能是因为主节点配置不当。以下是解决方案：</p> 
<ol><li><strong>检查 <code>elasticsearch.yml</code> 配置</strong></li></ol> 
<p>确保 <code>elasticsearch.yml</code> 配置正确：</p> 
<pre><code class="prism language-yaml"><span class="token key atrule">cluster.name</span><span class="token punctuation">:</span> my<span class="token punctuation">-</span>elk<span class="token punctuation">-</span>cluster
<span class="token key atrule">node.name</span><span class="token punctuation">:</span> elk<span class="token punctuation">-</span>node<span class="token punctuation">-</span><span class="token number">1</span>
<span class="token key atrule">network.host</span><span class="token punctuation">:</span> 0.0.0.0

<span class="token comment"># 配置该节点为主节点</span>
<span class="token key atrule">node.master</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>
<span class="token key atrule">node.data</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>

<span class="token comment"># 设置单节点模式</span>
<span class="token key atrule">discovery.type</span><span class="token punctuation">:</span> single<span class="token punctuation">-</span>node
</code></pre> 
<p>保存配置后，重启 Elasticsearch：</p> 
<pre><code class="prism language-bash"><span class="token function">sudo</span> systemctl restart elasticsearch
</code></pre> 
<ol start="2"><li><strong>检查网络配置</strong></li></ol> 
<p>确保所有节点能够互相通信，尤其是在多节点配置下。检查防火墙设置，确保集群内部的通信端口（默认 9300）是开放的。</p> 
<ol start="3"><li><strong>检查 Elasticsearch 日志</strong></li></ol> 
<p>查看 Elasticsearch 日志文件 <code>/var/log/elasticsearch/elasticsearch.log</code>，以获取更详细的错误信息：</p> 
<pre><code class="prism language-bash"><span class="token function">sudo</span> <span class="token function">tail</span> <span class="token parameter variable">-f</span> /var/log/elasticsearch/elasticsearch.log
</code></pre> 
<h4><a id="_149"></a>总结</h4> 
<p>通过调整 <code>elasticsearch.yml</code> 配置和检查日志，你应该能够解决 <code>master_not_discovered_exception</code> 问题。一旦 Elasticsearch 集群恢复正常，Kibana 应该也能正常连接并启动。</p> 
<hr> 
<h4><a id="3__Kibana_155"></a>3. 安装 Kibana</h4> 
<ol><li> <p>在 CentOS 8 上安装 Kibana：</p> <pre><code class="prism language-bash"><span class="token function">sudo</span> dnf <span class="token function">install</span> kibana <span class="token parameter variable">-y</span>
</code></pre> </li><li> <p>配置 Kibana：</p> <p>修改配置文件 <code>/etc/kibana/kibana.yml</code>：</p> <pre><code class="prism language-bash"><span class="token function">sudo</span> <span class="token function">vi</span> /etc/kibana/kibana.yml
</code></pre> <p>设置以下内容：</p> <pre><code class="prism language-yaml"><span class="token key atrule">server.host</span><span class="token punctuation">:</span> <span class="token string">"0.0.0.0"</span>
<span class="token key atrule">elasticsearch.hosts</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"http://localhost:9200"</span><span class="token punctuation">]</span>
</code></pre> </li><li> <p>配置 <code>encryptionKey</code>:</p> <p>如果没有安装 <code>openssl</code>，请先安装：</p> <pre><code class="prism language-bash"><span class="token function">sudo</span> dnf <span class="token function">install</span> openssl <span class="token parameter variable">-y</span>
</code></pre> <p>使用 OpenSSL 生成三个加密密钥，分别用于 Kibana 的 <code>encryptionKey</code> 配置：</p> <pre><code class="prism language-bash">openssl rand <span class="token parameter variable">-base64</span> <span class="token number">32</span>
</code></pre> <p>将生成的三个密钥分别添加到 <code>kibana.yml</code> 配置文件中：</p> <pre><code class="prism language-yaml"><span class="token key atrule">xpack.encryptedSavedObjects.encryptionKey</span><span class="token punctuation">:</span> <span class="token string">"YOUR_GENERATED_ENCRYPTION_KEY"</span>
<span class="token key atrule">xpack.security.encryptionKey</span><span class="token punctuation">:</span> <span class="token string">"YOUR_GENERATED_SECURITY_KEY"</span>
<span class="token key atrule">xpack.reporting.encryptionKey</span><span class="token punctuation">:</span> <span class="token string">"YOUR_GENERATED_REPORTING_KEY"</span>
</code></pre> </li><li> <p>启动并设置 Kibana 为开机自启：</p> <pre><code class="prism language-bash"><span class="token function">sudo</span> systemctl start kibana
<span class="token function">sudo</span> systemctl <span class="token builtin class-name">enable</span> kibana
</code></pre> </li><li> <p>检查 Kibana 的状态：</p> <pre><code class="prism language-bash"><span class="token function">sudo</span> systemctl status kibana
</code></pre> </li><li> <p>查看 Kibana 日志:</p> <pre><code class="prism language-bash"><span class="token function">sudo</span> <span class="token function">tail</span> <span class="token parameter variable">-f</span> /var/log/kibana/kibana.log
</code></pre> </li></ol> 
<p><strong>作用</strong>: Kibana 为日志数据提供了一个可视化界面。通过 Kibana，我们可以搜索和分析存储在 Elasticsearch 中的日志数据，创建仪表板，生成图表，实时监控系统和应用的运行状态。</p> 
<h4><a id="_Kibana_221"></a>汉化 Kibana</h4> 
<p>要将 Kibana 的界面汉化，可以通过以下步骤进行配置：</p> 
<ol><li> <p><strong>编辑 Kibana 配置文件</strong>：</p> <pre><code class="prism language-bash"><span class="token function">sudo</span> <span class="token function">vi</span> /etc/kibana/kibana.yml
</code></pre> <p>将语言设置为中文：</p> <pre><code class="prism language-yaml"><span class="token key atrule">i18n.locale</span><span class="token punctuation">:</span> <span class="token string">"zh-CN"</span>
</code></pre> </li><li> <p><strong>重启 Kibana</strong>：</p> <p>保存配置文件后，重启 Kibana 服务：</p> <pre><code class="prism language-bash"><span class="token function">sudo</span> systemctl restart kibana
</code></pre> </li><li> <p><strong>验证汉化效果</strong>：</p> <p>通过浏览器访问 Kibana 界面，界面应该已经切换为简体中文。</p> </li></ol> 
<hr> 
<h4><a id="4__Logstash_251"></a>4. 安装 Logstash</h4> 
<ol><li>安装 Logstash：</li></ol> 
<pre><code class="prism language-bash">  <span class="token function">sudo</span> dnf <span class="token function">install</span> logstash <span class="token parameter variable">-y</span>
</code></pre> 
<ol start="2"><li> <p>配置 Logstash：</p> <p>在 <code>/etc/logstash/conf.d/</code> 目录下创建一个配置文件，例如 <code>filebeat-input.conf</code>：</p> <pre><code class="prism language-bash"><span class="token function">sudo</span> <span class="token function">vi</span> /etc/logstash/conf.d/filebeat-input.conf
</code></pre> <p>输入以下内容：</p> <pre><code class="prism language-yaml">input <span class="token punctuation">{<!-- --></span>
  beats <span class="token punctuation">{<!-- --></span>
    port =<span class="token punctuation">&gt;</span> 5044
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
filter <span class="token punctuation">{<!-- --></span>
  <span class="token comment"># 这里可以添加一些解析或过滤规则</span>
<span class="token punctuation">}</span>
output <span class="token punctuation">{<!-- --></span>
  elasticsearch <span class="token punctuation">{<!-- --></span>
    hosts =<span class="token punctuation">&gt;</span> <span class="token punctuation">[</span><span class="token string">"http://localhost:9200"</span><span class="token punctuation">]</span>
    index =<span class="token punctuation">&gt;</span> "app<span class="token punctuation">-</span>logs<span class="token punctuation">-</span>%<span class="token punctuation">{<!-- --></span>+YYYY.MM.dd<span class="token punctuation">}</span>"
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> </li><li> <p>启动并设置 Logstash 为开机自启：</p> <pre><code class="prism language-bash"><span class="token function">sudo</span> systemctl start logstash
<span class="token function">sudo</span> systemctl <span class="token builtin class-name">enable</span> logstash
</code></pre> </li></ol> 
<p><strong>作用</strong>: Logstash 是一个强大的数据处理引擎，它能够处理来自 Filebeat 的日志数据，并进行必要的过滤和解析，然后将处理后的数据传输到 Elasticsearch 进行存储。它的灵活性使得我们可以根据需求对日志数据进行复杂的处理和转换。</p> 
<hr> 
<h3><a id="_2_Java_CentOS_66_Filebeat_299"></a>步骤 2：在 Java 应用服务器（CentOS 6.6）上安装和配置 Filebeat</h3> 
<h4><a id="1__Filebeat_301"></a>1. 安装 Filebeat</h4> 
<p>下载并安装 Filebeat：</p> 
<pre><code class="prism language-bash"><span class="token function">curl</span> <span class="token parameter variable">-L</span> <span class="token parameter variable">-O</span> https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-7.12.0-x86_64.rpm
<span class="token function">sudo</span> <span class="token function">rpm</span> <span class="token parameter variable">-vi</span> filebeat-7.12.0-x86_64.rpm
</code></pre> 
<p><strong>作用</strong>: Filebeat 是一个轻量级的日志转发器，安装在日志来源服务器上（例如你的 Java 应用服务器）。它负责监控指定的日志文件，并将日志数据安全地传输到 Logstash 或 Elasticsearch。在分布式系统中，Filebeat 是日志数据收集的第一步。</p> 
<h4><a id="2__Filebeat_312"></a>2. 配置 Filebeat</h4> 
<p>修改 Filebeat 配置文件 <code>/etc/filebeat/filebeat.yml</code>：</p> 
<pre><code class="prism language-bash"><span class="token function">sudo</span> <span class="token function">vi</span> /etc/filebeat/filebeat.yml
</code></pre> 
<p>配置 Filebeat 读取 Java 应用日志文件：</p> 
<pre><code class="prism language-yaml"><span class="token key atrule">filebeat.inputs</span><span class="token punctuation">:</span>
<span class="token punctuation">-</span> <span class="token key atrule">type</span><span class="token punctuation">:</span> log
  <span class="token key atrule">enabled</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>
  <span class="token key atrule">paths</span><span class="token punctuation">:</span>
    <span class="token punctuation">-</span> /var/log/app/<span class="token important">*.log</span>  <span class="token comment"># 修改为你的实际日志路径</span>

<span class="token key atrule">output.logstash</span><span class="token punctuation">:</span>
  <span class="token key atrule">hosts</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"&lt;Logstash_Server_IP&gt;:5044"</span><span class="token punctuation">]</span>  <span class="token comment"># 指定 Logstash 的 IP 和端口</span>
</code></pre> 
<h4><a id="3__Filebeat__333"></a>3. 启动并设置 Filebeat 为开机自启</h4> 
<ol><li> <p>测试 Filebeat 配置：</p> <pre><code class="prism language-bash"><span class="token function">sudo</span> filebeat <span class="token builtin class-name">test</span> config
</code></pre> </li><li> <p>启动并设置 Filebeat 为开机自启：</p> <pre><code class="prism language-bash"><span class="token function">sudo</span> systemctl start filebeat
<span class="token function">sudo</span> systemctl <span class="token builtin class-name">enable</span> filebeat
</code></pre> </li></ol> 
<p><strong>作用</strong>: 配置并启动 Filebeat 后，它将开始监控指定的日志文件，并将日志数据传输到配置的 Logstash 或 Elasticsearch 节点。这一步确保了日志数据可以实时、安全地传输到日志处理平台。</p> 
<hr> 
<h3><a id="_3_352"></a>步骤 3：验证和调试</h3> 
<h4><a id="1__354"></a>1. 验证日志传输</h4> 
<p>在 Kibana 上访问 <code>http://&lt;Logstash_Server_IP&gt;:5601</code>，使用 Kibana 的“Discover”功能来查看是否接收到了 Java 应用服务器的日志。</p> 
<h4><a id="2__358"></a>2. 调试</h4> 
<p>如果日志没有正常传输，可以通过检查 Filebeat、Logstash 和 Elasticsearch 的日志来排查问题：</p> 
<pre><code class="prism language-bash"><span class="token function">sudo</span> <span class="token function">tail</span> <span class="token parameter variable">-f</span> /var/log/filebeat/filebeat.log
<span class="token function">sudo</span> <span class="token function">tail</span> <span class="token parameter variable">-f</span> /var/log/logstash/logstash-plain.log
<span class="token function">sudo</span> <span class="token function">tail</span> <span class="token parameter variable">-f</span> /var/log/elasticsearch/elasticsearch.log
</code></pre> 
<h4><a id="3__Elasticsearch__368"></a>3. 检查 Elasticsearch 集群的健康状况</h4> 
<p>确保其状态为 <code>green</code> 或 <code>yellow</code>：</p> 
<pre><code class="prism language-bash"><span class="token function">curl</span> <span class="token parameter variable">-X</span> GET <span class="token string">"localhost:9200/_cluster/health?pretty"</span>
</code></pre> 
<p>如果状态为 <code>red</code>，需要检查 Elasticsearch 日志以找出可能的原因。</p> 
<hr> 
<p>通过这篇文章，我们了解了如何在 CentOS 8.2.2004 上安装和配置 ELK 栈，并使用 Filebeat 从 Java 应用服务器上收集日志数据。这种日志归集方案能够有效地集中管理分布式系统中的日志，为系统运维和故障排查提供了极大的便利。</p> 
<p>希望这篇文章对你有所帮助，如果你在配置过程中遇到任何问题，欢迎随时与我交流！</p> 
<h3><a id="_encryptionKey__384"></a>附录：配置 <code>encryptionKey</code> 的作用</h3> 
<p><code>encryptionKey</code> 是 Kibana 中用于加密和解密保存的敏感数据的关键配置。敏感数据包括 API 密钥、凭据、报警规则等，<code>encryptionKey</code> 是 Kibana 的 <code>xpack.encryptedSavedObjects</code> 功能的一部分，尤其在使用 Kibana 的安全和监控功能时，它变得尤为重要。</p> 
<h4><a id="_encryptionKey__388"></a>配置 <code>encryptionKey</code> 的作用</h4> 
<ol><li> <p><strong>保护敏感数据</strong>:</p> 
  <ul><li>在 Kibana 中，有些数据是加密保存的（例如报警规则、API 密钥、连接凭据等），<code>encryptionKey</code> 用于加密和解密这些数据。没有这个密钥，Kibana 将无法正确地读取和写入这些加密的数据。</li></ul> </li><li> <p><strong>确保 Kibana 的安全功能正常工作</strong>:</p> 
  <ul><li>如果你使用了 Kibana 的某些功能，如报警、报告、监控等，Kibana 需要加密一些配置数据。在这种情况下，配置 <code>encryptionKey</code> 是必须的。</li></ul> </li><li> <p><strong>跨实例保持一致</strong>:</p> 
  <ul><li>在一个多实例 Kibana 集群中，所有实例都必须使用相同的 <code>encryptionKey</code>，以确保它们可以共同处理和解密相同的数据。</li></ul> </li></ol> 
<h4><a id="_encryptionKey__399"></a>不配置 <code>encryptionKey</code> 的后果</h4> 
<ol><li> <p><strong>功能限制</strong>:</p> 
  <ul><li>如果 <code>encryptionKey</code> 未配置，Kibana 将无法启用或使用依赖于加密对象的功能，如报警、行动、报告、监控等。这会导致 Kibana 显示警告，并且相关功能将被禁用。</li></ul> </li><li> <p><strong>潜在的启动问题</strong>:</p> 
  <ul><li>虽然 Kibana 可能仍然能够启动，但如果使用这些功能，缺少 <code>encryptionKey</code> 会导致 Kibana 的某些部分无法正常工作，表现为功能不可用或者在尝试使用这些功能时遇到错误。</li></ul> </li><li> <p><strong>警告信息</strong>:</p> 
  <ul><li>你可能会看到类似于以下的警告：<pre><code class="prism language-plaintext">Saved objects encryption key is not set. This will severely limit Kibana functionality.
</code></pre> </li></ul> <p>这些警告明确指出了未配置 <code>encryptionKey</code> 的后果。</p> </li></ol> 
<h4><a id="_415"></a>解决方案</h4> 
<p>如果你遇到了 Kibana 启动后功能受限或显示 <code>Kibana server is not ready yet</code> 的问题，并且日志中显示关于 <code>encryptionKey</code> 的警告，那么配置 <code>encryptionKey</code> 是必要的。如下是配置步骤：</p> 
<ol><li> <p><strong>生成一个随机的 32 字符加密密钥</strong>：</p> 
  <ul><li> <p>你可以使用 OpenSSL 生成一个安全的密钥：</p> <pre><code class="prism language-bash">openssl rand <span class="token parameter variable">-base64</span> <span class="token number">32</span>
</code></pre> </li></ul> </li><li> <p><strong>在 <code>kibana.yml</code> 中配置该密钥</strong>：</p> <p>编辑 <code>kibana.yml</code> 配置文件：</p> <pre><code class="prism language-bash"><span class="token function">sudo</span> <span class="token function">vi</span> /etc/kibana/kibana.yml
</code></pre> <p>添加以下行：</p> <pre><code class="prism language-yaml"><span class="token key atrule">xpack.encryptedSavedObjects.encryptionKey</span><span class="token punctuation">:</span> <span class="token string">"YOUR_GENERATED_ENCRYPTION_KEY"</span>
</code></pre> </li><li> <p><strong>重启 Kibana</strong>：</p> 
  <ul><li> <p>保存配置文件后，重启 Kibana 服务以应用新的设置：</p> <pre><code class="prism language-bash"><span class="token function">sudo</span> systemctl restart kibana
</code></pre> </li></ul> </li></ol> 
<h4><a id="_447"></a>总结</h4> 
<p>配置 <code>encryptionKey</code> 对于确保 Kibana 的某些核心功能正常工作是至关重要的。如果不配置它，某些功能将被禁用或无法使用。因此，如果你在日志中看到相关警告或 Kibana 功能受限的问题，务必按照上述步骤配置 <code>encryptionKey</code>。通过正确配置，你可以确保 Kibana 完整且安全地运行所有功能。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/d128b88979e344ea7042cf2717ff9bf2/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">信奥C&#43;&#43;，输入一个n*m的矩阵，在输入一个变量s，如果s==0,则水平翻转矩阵，否则垂直翻转矩阵</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/c294943d678b5aef251f6f6fd2f2863c/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【SQL Server】在 SSMS 中 使用 生成 SQL 脚本 方式 实现 数据库 备份 / 还原 ( 数据备份操作 - 生成 SQL 脚本 | 数据还原操作 - 执行 SQL 脚本 )</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>