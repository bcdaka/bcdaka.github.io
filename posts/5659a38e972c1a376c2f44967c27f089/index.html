<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>机器学习练手（三）：基于决策树的iris 多分类和波士顿房价预测 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/5659a38e972c1a376c2f44967c27f089/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="机器学习练手（三）：基于决策树的iris 多分类和波士顿房价预测">
  <meta property="og:description" content="总结：本文为和鲸python 可视化探索训练营资料整理而来，加入了自己的理解（by GPT4o）
原活动链接
原作者：vgbhfive，多年风控引擎研发及金融模型开发经验，现任某公司风控研发工程师，对数据分析、金融模型开发、风控引擎研发具有丰富经验。
在前一关中学习了如何使用肘部法则计算最佳分类数，也知道了计算 KMeans 分类的特征要求。在新的一关中，我们将开始学习训练决策树模型。
总结：注意训练模型后打印特征重要性的操作，clf.feature_importances_ ，用于后续优化模型
目录 决策树iris 数据集之多分类问题引入依赖加载数据训练模型和计算测试集指标特征重要性可视化决策树总结 波士顿房价之回归问题加载数据预处理数据训练回归模型计算测试集指标 闯关题STEP1：请根据要求完成题目 决策树 决策树字如其名，其主要展示类似于树状结构。
在分类问题中，表示基于特征对实例进行分类的过程，过程可以认为是 if-then 的集合 ;而在回归问题中，会被认为特征分布在分类空间上的条件概率分布。
iris 数据集之多分类问题 Iris 数据集算是机器学习算法的入门数据集，其包含有三个分类结果和四个特征信息，其分别是花萼长度，花萼宽度，花瓣长度，花瓣宽度，通过上述四个特征信息预测鸢尾花卉属于哪一类？
引入依赖 import pandas as pd import numpy as np from sklearn.datasets import load_iris from sklearn.model_selection import train_test_split from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor from sklearn.metrics import accuracy_score, r2_score, mean_squared_error 加载数据 # 1. 加载数据 iris = load_iris() x, y = pd.DataFrame(iris.data), iris.target x.head(), y ( 0 1 2 3 0 5.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-08-03T19:13:01+08:00">
    <meta property="article:modified_time" content="2024-08-03T19:13:01+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">机器学习练手（三）：基于决策树的iris 多分类和波士顿房价预测</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>总结：本文为和鲸python 可视化探索训练营资料整理而来，加入了自己的理解（by GPT4o）</p> 
<p><a href="https://www.heywhale.com/home/competition/66598b3271a1fd975a17d6ad?shareby=60dc1f6747bfe500173a51d0" rel="nofollow">原活动链接</a></p> 
<p>原作者：<a href="http://blog.vgbhfive.com" rel="nofollow"><strong>vgbhfive</strong></a>，多年风控引擎研发及金融模型开发经验，现任某公司风控研发工程师，对数据分析、金融模型开发、风控引擎研发具有丰富经验。</p> 
<p>在前一关中学习了如何使用肘部法则计算最佳分类数，也知道了计算 <code>KMeans</code> 分类的特征要求。在新的一关中，我们将开始学习训练决策树模型。</p> 
<p>总结：注意训练模型后打印特征重要性的操作，clf.feature_importances_ ，用于后续优化模型</p> 
<p></p> 
<div class="toc"> 
 <h4>目录</h4> 
 <ul><li><ul><li><ul><li><a href="#_11" rel="nofollow">决策树</a></li><li><a href="#iris__18" rel="nofollow">iris 数据集之多分类问题</a></li><li><ul><li><a href="#_22" rel="nofollow">引入依赖</a></li><li><a href="#_35" rel="nofollow">加载数据</a></li><li><a href="#_65" rel="nofollow">训练模型和计算测试集指标</a></li><li><a href="#_591" rel="nofollow">特征重要性</a></li><li><a href="#_609" rel="nofollow">可视化决策树</a></li><li><a href="#_630" rel="nofollow">总结</a></li></ul> 
    </li><li><a href="#_633" rel="nofollow">波士顿房价之回归问题</a></li><li><ul><li><a href="#_655" rel="nofollow">加载数据</a></li><li><a href="#_794" rel="nofollow">预处理数据</a></li><li><a href="#_881" rel="nofollow">训练回归模型</a></li><li><a href="#_1338" rel="nofollow">计算测试集指标</a></li></ul> 
    </li><li><a href="#_1360" rel="nofollow">闯关题</a></li><li><ul><li><a href="#STEP1_1362" rel="nofollow">STEP1：请根据要求完成题目</a></li></ul> 
   </li></ul> 
  </li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h4><a id="_11"></a>决策树</h4> 
<p>决策树字如其名，其主要展示类似于树状结构。</p> 
<p>在分类问题中，表示基于特征对实例进行分类的过程，过程可以认为是 <strong><code>if-then</code> 的集合</strong> ;而在回归问题中，会被认为特征分布在分类空间上的<strong>条件概率分布</strong>。</p> 
<h4><a id="iris__18"></a>iris 数据集之多分类问题</h4> 
<p><code>Iris</code> 数据集算是机器学习算法的入门数据集，其包含有三个分类结果和四个特征信息，其分别是花萼长度，花萼宽度，花瓣长度，花瓣宽度，通过上述四个特征信息预测鸢尾花卉属于哪一类？</p> 
<h5><a id="_22"></a>引入依赖</h5> 
<pre><code class="prism language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> load_iris
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>tree <span class="token keyword">import</span> DecisionTreeClassifier<span class="token punctuation">,</span> DecisionTreeRegressor
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> accuracy_score<span class="token punctuation">,</span> r2_score<span class="token punctuation">,</span> mean_squared_error
</code></pre> 
<h5><a id="_35"></a>加载数据</h5> 
<pre><code class="prism language-python"><span class="token comment"># 1. 加载数据</span>

iris <span class="token operator">=</span> load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span>
x<span class="token punctuation">,</span> y <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>iris<span class="token punctuation">.</span>data<span class="token punctuation">)</span><span class="token punctuation">,</span> iris<span class="token punctuation">.</span>target
x<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y
</code></pre> 
<pre><code>(     0    1    2    3
 0  5.1  3.5  1.4  0.2
 1  4.9  3.0  1.4  0.2
 2  4.7  3.2  1.3  0.2
 3  4.6  3.1  1.5  0.2
 4  5.0  3.6  1.4  0.2,
 array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]))
</code></pre> 
<h5><a id="_65"></a>训练模型和计算测试集指标</h5> 
<pre><code class="prism language-python"><span class="token comment"># 2. 切分数据集</span>

x_train<span class="token punctuation">,</span> x_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">,</span>random_state<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span>
x_train<span class="token punctuation">,</span> x_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test
</code></pre> 
<pre><code>(       0    1    2    3
 81   5.5  2.4  3.7  1.0
 133  6.3  2.8  5.1  1.5
 137  6.4  3.1  5.5  1.8
 75   6.6  3.0  4.4  1.4
 109  7.2  3.6  6.1  2.5
 ..   ...  ...  ...  ...
 71   6.1  2.8  4.0  1.3
 106  4.9  2.5  4.5  1.7
 14   5.8  4.0  1.2  0.2
 92   5.8  2.6  4.0  1.2
 102  7.1  3.0  5.9  2.1
 
 [105 rows x 4 columns],
        0    1    2    3
 73   6.1  2.8  4.7  1.2
 18   5.7  3.8  1.7  0.3
 118  7.7  2.6  6.9  2.3
 78   6.0  2.9  4.5  1.5
 76   6.8  2.8  4.8  1.4
 31   5.4  3.4  1.5  0.4
 64   5.6  2.9  3.6  1.3
 141  6.9  3.1  5.1  2.3
 68   6.2  2.2  4.5  1.5
 82   5.8  2.7  3.9  1.2
 110  6.5  3.2  5.1  2.0
 12   4.8  3.0  1.4  0.1
 36   5.5  3.5  1.3  0.2
 9    4.9  3.1  1.5  0.1
 19   5.1  3.8  1.5  0.3
 56   6.3  3.3  4.7  1.6
 104  6.5  3.0  5.8  2.2
 69   5.6  2.5  3.9  1.1
 55   5.7  2.8  4.5  1.3
 132  6.4  2.8  5.6  2.2
 29   4.7  3.2  1.6  0.2
 127  6.1  3.0  4.9  1.8
 26   5.0  3.4  1.6  0.4
 128  6.4  2.8  5.6  2.1
 131  7.9  3.8  6.4  2.0
 145  6.7  3.0  5.2  2.3
 108  6.7  2.5  5.8  1.8
 143  6.8  3.2  5.9  2.3
 45   4.8  3.0  1.4  0.3
 30   4.8  3.1  1.6  0.2
 22   4.6  3.6  1.0  0.2
 15   5.7  4.4  1.5  0.4
 65   6.7  3.1  4.4  1.4
 11   4.8  3.4  1.6  0.2
 42   4.4  3.2  1.3  0.2
 146  6.3  2.5  5.0  1.9
 51   6.4  3.2  4.5  1.5
 27   5.2  3.5  1.5  0.2
 4    5.0  3.6  1.4  0.2
 32   5.2  4.1  1.5  0.1
 142  5.8  2.7  5.1  1.9
 85   6.0  3.4  4.5  1.6
 86   6.7  3.1  4.7  1.5
 16   5.4  3.9  1.3  0.4
 10   5.4  3.7  1.5  0.2,
 array([1, 2, 2, 1, 2, 1, 2, 1, 0, 2, 1, 0, 0, 0, 1, 2, 0, 0, 0, 1, 0, 1,
        2, 0, 1, 2, 0, 2, 2, 1, 1, 2, 1, 0, 1, 2, 0, 0, 1, 1, 0, 2, 0, 0,
        1, 1, 2, 1, 2, 2, 1, 0, 0, 2, 2, 0, 0, 0, 1, 2, 0, 2, 2, 0, 1, 1,
        2, 1, 2, 0, 2, 1, 2, 1, 1, 1, 0, 1, 1, 0, 1, 2, 2, 0, 1, 2, 2, 0,
        2, 0, 1, 2, 2, 1, 2, 1, 1, 2, 2, 0, 1, 2, 0, 1, 2]),
 array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,
        0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0,
        0]))
</code></pre> 
<pre><code class="prism language-python"><span class="token comment"># 3. 构建决策树模型并训练模型</span>

clf <span class="token operator">=</span> DecisionTreeClassifier<span class="token punctuation">(</span>criterion<span class="token operator">=</span><span class="token string">'gini'</span><span class="token punctuation">)</span>

clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>
</code></pre> 
<div id="sk-container-id-1" class="sk-top-container"> 
 <div class="sk-text-repr-fallback"> 
  <pre>DecisionTreeClassifier()</pre> 
  <b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b> 
 </div> 
 <div class="sk-container"> 
  <div class="sk-item"> 
   <div class="sk-estimator fitted sk-toggleable"> 
    <label class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">  DecisionTreeClassifier<a class="sk-estimator-doc-link fitted" rel="nofollow noopener noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.tree.DecisionTreeClassifier.html">?Documentation for DecisionTreeClassifier</a><span class="sk-estimator-doc-link fitted">iFitted</span></label> 
    <div class="sk-toggleable__content fitted"> 
     <pre>DecisionTreeClassifier()</pre> 
    </div> 
   </div> 
  </div> 
 </div> 
</div> 
<pre><code class="prism language-python"><span class="token comment"># 4. 预测测试集</span>

y_pred <span class="token operator">=</span> clf<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python"><span class="token comment"># 5. 计算测试集的准确率</span>

acc <span class="token operator">=</span> accuracy_score<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span>
acc
</code></pre> 
<pre><code>1.0
</code></pre> 
<h5><a id="_591"></a>特征重要性</h5> 
<pre><code class="prism language-python"><span class="token comment"># 6. 特征重要性</span>
<span class="token comment"># feature_importances_ 是一个数组类型，里边的元素分别代表对应特征的重要性，所有元素之和为1。元素的值越大，则对应的特征越重要。</span>

imprtances <span class="token operator">=</span> clf<span class="token punctuation">.</span>feature_importances_
imprtances
</code></pre> 
<pre><code>array([0.        , 0.01911002, 0.42356658, 0.5573234 ])
</code></pre> 
<h5><a id="_609"></a>可视化决策树</h5> 
<pre><code class="prism language-python"><span class="token comment"># 打印决策树</span>

<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>tree <span class="token keyword">import</span> export_graphviz
<span class="token keyword">import</span> graphviz

<span class="token comment"># clf 为决策树对象</span>
dot_data <span class="token operator">=</span> export_graphviz<span class="token punctuation">(</span>clf<span class="token punctuation">)</span>
graph <span class="token operator">=</span> graphviz<span class="token punctuation">.</span>Source<span class="token punctuation">(</span>dot_data<span class="token punctuation">)</span>

<span class="token comment"># 生成 Source.gv.pdf 文件，可以下载打开</span>
<span class="token comment"># graph.view()</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/8d/bc/3ZWNMFbU_o.jpg" alt="Image Name"></p> 
<h5><a id="_630"></a>总结</h5> 
<p>通过可视化决策树，可以看出正如前面介绍的那样，分类决策树是 <code>if-then</code> 的集合，最终得到对应的分类结果。</p> 
<h4><a id="_633"></a>波士顿房价之回归问题</h4> 
<p>在二手房产交易中，其中最受关注的便是房屋价格问题，其涉及到多个方方面面，例如房屋面积、房屋位置、户型大小、户型面积、小区平均房屋价格等等信息。现在 sklearn 提供波士顿的房屋价格数据集，其中有 506 例记录，包含城镇人均犯罪率、住宅用地比例、平均房间数等特征信息，学习使用这些信息准确预测波士顿的房屋价格，之后以此类推收集想要购买区域的房屋价格信息，就可以预测自身购买房屋价格是否划算。</p> 
<p>波士顿房价数据集数据含义如下：</p> 
<table><thead><tr><th>特征列名称</th><th>特征含义</th></tr></thead><tbody><tr><td>CRIM</td><td>城镇人均犯罪率</td></tr><tr><td>ZN</td><td>占地面积超过25,000平方英尺的住宅用地比例</td></tr><tr><td>INDUS</td><td>每个城镇非零售业务的比例</td></tr><tr><td>CHAS</td><td>Charles River虚拟变量</td></tr><tr><td>NOX</td><td>一氧化氮浓度（每千万份）</td></tr><tr><td>RM</td><td>每间住宅的平均房间数</td></tr><tr><td>AGE</td><td>1940年以前建造的自住单位比例</td></tr><tr><td>DIS</td><td>波士顿的五个就业中心加权距离</td></tr><tr><td>RAD</td><td>径向高速公路的可达性指数</td></tr><tr><td>TAX</td><td>每10,000美元的全额物业税率</td></tr><tr><td>PTRATIO</td><td>城镇的学生与教师比例</td></tr><tr><td>B</td><td>1000*(Bk / 0.63)^2 其中Bk是城镇黑人的比例</td></tr><tr><td>LSTAT</td><td>区域中被认为是低收入阶层的比率</td></tr><tr><td>MEDV</td><td>自有住房的中位数报价, 单位1000美元</td></tr></tbody></table> 
<h5><a id="_655"></a>加载数据</h5> 
<pre><code class="prism language-python"><span class="token comment"># 1. 加载数据</span>

boston <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'./data/housing-3.csv'</span><span class="token punctuation">)</span>
boston<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<div> 
</div> 
<table border="1" class="dataframe"><thead><tr><th></th><th>CRIM</th><th>ZN</th><th>INDUS</th><th>CHAS</th><th>NOX</th><th>RM</th><th>AGE</th><th>DIS</th><th>RAD</th><th>TAX</th><th>PIRATIO</th><th>B</th><th>LSTAT</th><th>MEDV</th></tr></thead><tbody><tr><th>0</th><td>0.00632</td><td>18.0</td><td>2.31</td><td>0</td><td>0.538</td><td>6.575</td><td>65.2</td><td>4.0900</td><td>1</td><td>296.0</td><td>15.3</td><td>396.90</td><td>4.98</td><td>24.0</td></tr><tr><th>1</th><td>0.02731</td><td>0.0</td><td>7.07</td><td>0</td><td>0.469</td><td>6.421</td><td>78.9</td><td>4.9671</td><td>2</td><td>242.0</td><td>17.8</td><td>396.90</td><td>9.14</td><td>21.6</td></tr><tr><th>2</th><td>0.02729</td><td>0.0</td><td>7.07</td><td>0</td><td>0.469</td><td>7.185</td><td>61.1</td><td>4.9671</td><td>2</td><td>242.0</td><td>17.8</td><td>392.83</td><td>4.03</td><td>34.7</td></tr><tr><th>3</th><td>0.03237</td><td>0.0</td><td>2.18</td><td>0</td><td>0.458</td><td>6.998</td><td>45.8</td><td>6.0622</td><td>3</td><td>222.0</td><td>18.7</td><td>394.63</td><td>2.94</td><td>33.4</td></tr><tr><th>4</th><td>0.06905</td><td>0.0</td><td>2.18</td><td>0</td><td>0.458</td><td>7.147</td><td>54.2</td><td>6.0622</td><td>3</td><td>222.0</td><td>18.7</td><td>396.90</td><td>5.33</td><td>36.2</td></tr></tbody></table> 
<h5><a id="_794"></a>预处理数据</h5> 
<pre><code class="prism language-python"><span class="token comment"># 2. 获取特征集和房价</span>
x <span class="token operator">=</span> boston<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'MEDV'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> boston<span class="token punctuation">[</span><span class="token string">'MEDV'</span><span class="token punctuation">]</span>
x<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code>(      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \
 0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296.0   
 1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242.0   
 2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242.0   
 3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222.0   
 4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222.0   
 
    PIRATIO       B  LSTAT  
 0     15.3  396.90   4.98  
 1     17.8  396.90   9.14  
 2     17.8  392.83   4.03  
 3     18.7  394.63   2.94  
 4     18.7  396.90   5.33  ,
 0    24.0
 1    21.6
 2    34.7
 3    33.4
 4    36.2
 Name: MEDV, dtype: float64)
</code></pre> 
<pre><code class="prism language-python"><span class="token comment"># 3. 测试集与训练集 7:3</span>

x_train<span class="token punctuation">,</span> x_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.33</span><span class="token punctuation">)</span>
x_train<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> x_test<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y_train<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y_test<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code>(         CRIM    ZN  INDUS  CHAS    NOX     RM    AGE     DIS  RAD    TAX  \
 492   0.11132   0.0  27.74     0  0.609  5.983   83.5  2.1099    4  711.0   
 266   0.78570  20.0   3.97     0  0.647  7.014   84.6  2.1329    5  264.0   
 91    0.03932   0.0   3.41     0  0.489  6.405   73.9  3.0921    2  270.0   
 379  17.86670   0.0  18.10     0  0.671  6.223  100.0  1.3861   24  666.0   
 89    0.05302   0.0   3.41     0  0.489  7.079   63.1  3.4145    2  270.0   
 
      PIRATIO       B  LSTAT  
 492     20.1  396.90  13.35  
 266     13.0  384.07  14.79  
 91      17.8  393.55   8.20  
 379     20.2  393.74  21.78  
 89      17.8  396.06   5.70  ,
         CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \
 399  9.91655   0.0  18.10     0  0.693  5.852  77.8  1.5004   24  666.0   
 305  0.05479  33.0   2.18     0  0.472  6.616  58.1  3.3700    7  222.0   
 131  1.19294   0.0  21.89     0  0.624  6.326  97.7  2.2710    4  437.0   
 452  5.09017   0.0  18.10     0  0.713  6.297  91.8  2.3682   24  666.0   
 121  0.07165   0.0  25.65     0  0.581  6.004  84.1  2.1974    2  188.0   
 
      PIRATIO       B  LSTAT  
 399     20.2  338.16  29.97  
 305     18.4  393.36   8.93  
 131     21.2  396.90  12.26  
 452     20.2  385.09  17.27  
 121     19.1  377.67  14.27  ,
 492    20.1
 266    30.7
 91     22.0
 379    10.2
 89     28.7
 Name: MEDV, dtype: float64,
 399     6.3
 305    28.4
 131    19.6
 452    16.1
 121    20.3
 Name: MEDV, dtype: float64)
</code></pre> 
<h5><a id="_881"></a>训练回归模型</h5> 
<pre><code class="prism language-python"><span class="token comment"># 4. 创建 CART 回归树</span>

dtr <span class="token operator">=</span> DecisionTreeRegressor<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python"><span class="token comment"># 5. 训练构造 CART 回归树</span>

dtr<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>
</code></pre> 
<div id="sk-container-id-2" class="sk-top-container"> 
 <div class="sk-text-repr-fallback"> 
  <pre>DecisionTreeRegressor()</pre> 
  <b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b> 
 </div> 
 <div class="sk-container"> 
  <div class="sk-item"> 
   <div class="sk-estimator fitted sk-toggleable"> 
    <label class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">  DecisionTreeRegressor<a class="sk-estimator-doc-link fitted" rel="nofollow noopener noreferrer" target="_blank" href="https://scikit-learn.org/1.5/modules/generated/sklearn.tree.DecisionTreeRegressor.html">?Documentation for DecisionTreeRegressor</a><span class="sk-estimator-doc-link fitted">iFitted</span></label> 
    <div class="sk-toggleable__content fitted"> 
     <pre>DecisionTreeRegressor()</pre> 
    </div> 
   </div> 
  </div> 
 </div> 
</div> 
<pre><code class="prism language-python"><span class="token comment"># 6. 预测测试集中的房价</span>

y_pred <span class="token operator">=</span> dtr<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span>
y_pred
</code></pre> 
<pre><code>array([ 7.5, 28.7, 19.2, 16.7, 22. , 26.6, 21. , 15. , 13.2, 23.2,  8.8,
       25. , 13.8, 30.7, 32. , 13.3, 22.9, 19.6, 22.7,  8.8, 19.9, 15.6,
        7.5, 11.7, 36.2, 28.1, 17. , 20.2, 14.9, 25. , 20.2, 27.1, 17.5,
       36. , 14.9,  9.5, 23. , 16.7, 24.8, 20. , 20. ,  8.3, 31.6, 14.1,
       23.7, 19.4, 33.4, 29.6, 14.1, 22. , 23.1, 50. , 50. ,  8.3, 11.8,
       21. , 27.5, 15.2, 20. , 18.3,  8.3, 20.1, 17.6, 18.5, 32. , 17. ,
       19.9, 18.8, 11.7, 25. , 16. , 26.4, 32.7, 20.6, 50. , 14.4, 34.6,
       11.8, 20.1, 22.4, 28.6, 36.4, 12.6, 19.8, 34.6, 22.9,  5. , 33.1,
       50. , 20.3, 26.7, 18.2, 28.1, 44.8, 50. , 16. , 26.4, 23.2, 22.2,
       12. ,  8.3, 18.2, 19.6, 21.6, 11.9, 18.3, 28.1, 24.7, 22. , 32.5,
       20.6, 16.6, 18.2, 14.1, 20.5, 22. , 22.9,  7.5, 16.6, 19.9, 18.7,
       27.9, 23.2, 17.2, 23.8, 22.2, 20.9, 13.6, 19.3,  9.5, 27.9,  7.5,
       34.6, 13.8,  8.3, 50. , 10.2, 12.6, 32. , 24.2, 17. , 19.5, 23.7,
       24.3, 13.6, 22.6,  8.3, 23.1, 21.6, 24.5, 14. , 23.3, 24.4, 16.6,
       14.9, 22. ,  8.3, 19.9, 12.6, 10.2, 23.4, 24.7, 50. , 19.4, 20. ,
       14.3, 23. ])
</code></pre> 
<h5><a id="_1338"></a>计算测试集指标</h5> 
<pre><code class="prism language-python"><span class="token comment"># 7. 测试集结果评价</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> r2_score<span class="token punctuation">,</span> mean_squared_error<span class="token punctuation">,</span> mean_absolute_error

<span class="token comment"># r2_score 决定系数，反映因变量的全部变异能通过回归关系被自变量解释的比例。</span>
r2 <span class="token operator">=</span> r2_score<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span>
mse <span class="token operator">=</span> mean_squared_error<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span>
<span class="token comment"># 计算均值绝对误差 (MAE)</span>
mae <span class="token operator">=</span> mean_absolute_error<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span>
r2<span class="token punctuation">,</span> mse<span class="token punctuation">,</span> mae
</code></pre> 
<pre><code>(0.6862919611706397, 22.763832335329337, 3.143712574850299)
</code></pre> 
<h4><a id="_1360"></a>闯关题</h4> 
<h5><a id="STEP1_1362"></a>STEP1：请根据要求完成题目</h5> 
<p>Q1. iris数据集中共有四个特征，重要性最小的特征是哪个？<br> A. 花萼长度<br> B. 花萼宽度<br> C. 花瓣长度<br> D. 花瓣宽度</p> 
<pre><code class="prism language-python">a1 <span class="token operator">=</span> <span class="token string">'A'</span>
</code></pre> 
<pre><code class="prism language-python"><span class="token comment"># 获取数据集描述</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>iris<span class="token punctuation">.</span>DESCR<span class="token punctuation">)</span>
</code></pre> 
<pre><code>.. _iris_dataset:

Iris plants dataset
--------------------

**Data Set Characteristics:**

:Number of Instances: 150 (50 in each of three classes)
:Number of Attributes: 4 numeric, predictive attributes and the class
:Attribute Information:
    - sepal length in cm
    - sepal width in cm
    - petal length in cm
    - petal width in cm
    - class:
            - Iris-Setosa
            - Iris-Versicolour
            - Iris-Virginica

:Summary Statistics:

============== ==== ==== ======= ===== ====================
                Min  Max   Mean    SD   Class Correlation
============== ==== ==== ======= ===== ====================
sepal length:   4.3  7.9   5.84   0.83    0.7826
sepal width:    2.0  4.4   3.05   0.43   -0.4194
petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)
petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)
============== ==== ==== ======= ===== ====================

:Missing Attribute Values: None
:Class Distribution: 33.3% for each of 3 classes.
:Creator: R.A. Fisher
:Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)
:Date: July, 1988

The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken
from Fisher's paper. Note that it's the same as in R, but not as in the UCI
Machine Learning Repository, which has two wrong data points.

This is perhaps the best known database to be found in the
pattern recognition literature.  Fisher's paper is a classic in the field and
is referenced frequently to this day.  (See Duda &amp; Hart, for example.)  The
data set contains 3 classes of 50 instances each, where each class refers to a
type of iris plant.  One class is linearly separable from the other 2; the
latter are NOT linearly separable from each other.

.. dropdown:: References

  - Fisher, R.A. "The use of multiple measurements in taxonomic problems"
    Annual Eugenics, 7, Part II, 179-188 (1936); also in "Contributions to
    Mathematical Statistics" (John Wiley, NY, 1950).
  - Duda, R.O., &amp; Hart, P.E. (1973) Pattern Classification and Scene Analysis.
    (Q327.D83) John Wiley &amp; Sons.  ISBN 0-471-22361-1.  See page 218.
  - Dasarathy, B.V. (1980) "Nosing Around the Neighborhood: A New System
    Structure and Classification Rule for Recognition in Partially Exposed
    Environments".  IEEE Transactions on Pattern Analysis and Machine
    Intelligence, Vol. PAMI-2, No. 1, 67-71.
  - Gates, G.W. (1972) "The Reduced Nearest Neighbor Rule".  IEEE Transactions
    on Information Theory, May 1972, 431-433.
  - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al"s AUTOCLASS II
    conceptual clustering system finds 3 classes in the data.
  - Many, many more ...
</code></pre> 
<p>​</p> 
<pre><code class="prism language-python">
</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/f6059c15d48a080f14a8ce7fe48f1b83/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">OGG同步目标端中文乱码处理</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/d7bbdaa48280cf48df11f545f2086f43/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">鸿蒙媒体开发【相机数据采集保存】拍照和图片</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>