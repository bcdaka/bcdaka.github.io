<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>详解 HBase 的架构和基本原理 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/1a4cba24362a54498cc4e3d07a99ca14/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="详解 HBase 的架构和基本原理">
  <meta property="og:description" content="一、基本架构 StoreFile：保存实际数据的物理文件，StoreFile 以 HFile 的格式 (KV) 存储在 HDFS 上。每个 Store 会有一个或多个 StoreFile（HFile），数据在每个 StoreFile 中都是有序的MemStore：写缓存，由于 HFile 中的数据要求是有序的，所以数据是先存储在 MemStore 中，排好序后，等到达刷写时机才会刷写到 HFile，每次刷写都会形成一个新的 HFileWAL：由于数据要经 MemStore 排序后才能刷写到 HFile，但把数据保存在内存中会有很高的概率导致数据丢失，为了解决这个问题，数据会先写在一个叫做 Write-Ahead logfile 的文件中，然后再写入 MemStore 中。所以在系统出现故障的时候，数据可以通过这个日志文件重建 二、写流程原理 HBase 的读操作比写操作慢，且读写流程没有 master 参与
老版本：Zookeeper 中存储的是 -root- 表的位置信息，-root- 表存储的 meta 表的位置信息(防止 meta 表进行切分)Client 先访问 Zookeeper，获取 hbase:meta 表位于哪个 Region Server访问对应的 Region Server，获取 hbase:meta 表数据，根据写请求的 namespace:table/rowkey 信息查询出目标数据位于哪个 Region Server 中的哪个 Region 中，并将该 table 的 region 信息以及 meta 表的位置信息缓存在客户端的 meta cache，方便下次快速访问与目标表所在的 Region Server 进行通讯将写请求命令顺序写入（追加）到内存的 WAL，此时 wal 没有同步到 HDFS将数据写入对应的 MemStore，数据会在 MemStore 进行排序同步 wal 到 HDFS，若失败则回滚清空 MemStore 写入的数据向客户端发送 ack，此时的写请求已经完成等达到 MemStore 的刷写时机后，将数据刷写到 HFile 三、MemStore Flush MemStore Flush：刷写，将 Region 中存储在内存中的数据刷写到 HDFS 的磁盘中Flush 时机： RegionServer 级别： 当 RegionServer 中 memstore 的总大小达到 javaHeapSize × hbase.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-06-17T12:28:27+08:00">
    <meta property="article:modified_time" content="2024-06-17T12:28:27+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">详解 HBase 的架构和基本原理</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h3><a id="_0"></a>一、基本架构</h3> 
<p><img src="https://images2.imgbox.com/af/f1/Pa96yaix_o.png" alt="在这里插入图片描述"></p> 
<ul><li>StoreFile：保存实际数据的物理文件，StoreFile 以 HFile 的格式 (KV) 存储在 HDFS 上。每个 Store 会有一个或多个 StoreFile（HFile），数据在每个 StoreFile 中都是有序的</li><li>MemStore：写缓存，由于 HFile 中的数据要求是有序的，所以数据是先存储在 MemStore 中，排好序后，等到达刷写时机才会刷写到 HFile，每次刷写都会形成一个新的 HFile</li><li>WAL：由于数据要经 MemStore 排序后才能刷写到 HFile，但把数据保存在内存中会有很高的概率导致数据丢失，为了解决这个问题，数据会先写在一个叫做 Write-Ahead logfile 的文件中，然后再写入 MemStore 中。所以在系统出现故障的时候，数据可以通过这个日志文件重建</li></ul> 
<h3><a id="_11"></a>二、写流程原理</h3> 
<blockquote> 
 <p>HBase 的读操作比写操作慢，且读写流程没有 master 参与</p> 
</blockquote> 
<p><img src="https://images2.imgbox.com/2d/58/aamEV8AE_o.png" alt="在这里插入图片描述"></p> 
<ul><li>老版本：Zookeeper 中存储的是 <code>-root-</code> 表的位置信息，<code>-root-</code> 表存储的 <code>meta</code> 表的位置信息(防止 <code>meta</code> 表进行切分)</li><li>Client 先访问 Zookeeper，获取 <code>hbase:meta</code> 表位于哪个 <code>Region Server</code></li><li>访问对应的 <code>Region Server</code>，获取 <code>hbase:meta</code> 表数据，根据写请求的 <code>namespace:table/rowkey</code> 信息查询出目标数据位于哪个 <code>Region Server</code> 中的哪个 <code>Region</code> 中，并将该 table 的 <code>region</code> 信息以及 <code>meta</code> 表的位置信息缓存在客户端的 <code>meta cache</code>，方便下次快速访问</li><li>与目标表所在的 <code>Region Server</code> 进行通讯</li><li>将写请求命令顺序写入（追加）到内存的 <code>WAL</code>，此时 <code>wal</code> 没有同步到 HDFS</li><li>将数据写入对应的 <code>MemStore</code>，数据会在 <code>MemStore</code> 进行排序</li><li>同步 <code>wal</code> 到 HDFS，若失败则回滚清空 <code>MemStore</code> 写入的数据</li><li>向客户端发送 <code>ack</code>，此时的写请求已经完成</li><li>等达到 <code>MemStore</code> 的刷写时机后，将数据刷写到 <code>HFile</code></li></ul> 
<h3><a id="MemStore_Flush_30"></a>三、MemStore Flush</h3> 
<p><img src="https://images2.imgbox.com/11/e2/N0i0vJyb_o.png" alt="在这里插入图片描述"></p> 
<ul><li>MemStore Flush：刷写，将 Region 中存储在内存中的数据刷写到 HDFS 的磁盘中</li><li>Flush 时机： 
  <ul><li>RegionServer 级别： 
    <ul><li>当 RegionServer 中 memstore 的总大小达到 <code>javaHeapSize × hbase.regionserver.global.memstore.size(默认 0.4) × hbase.regionserver.global.memstore.size.lower.limit(默认 0.95)</code> 时，所有 region 会按照其所有 memstore 的大小顺序 (由大到小) 依次进行刷写。直到 RegionServer 中所有 memstore 的总大小减小到上述值以下；当 RegionServer 中 memstore 的总大小达到<code>javaHeapsize × hbase.regionserver.global.memstore.size</code> 时，会停止继续往所有的 memstore 写数据操作</li><li>当 memstore 中最后一条数据的写入时间达到<code>hbase.regionserver.optionalcacheflushinterval(默认 1h)</code> 的值时，触发 memstore flush</li><li>当 WAL 文件的数量超过 <code>hbase.regionserver.max.logs</code>，region 会按照时间顺序依次进行刷写，直到 WAL 文件数量减小到 <code>hbase.regionserver.max.log</code> 以下 (该属性名已经废弃，现无需手动设置，最大值为 32)，该参数用于防止生产上内存配置过大导致刷写时数据积累过大</li></ul> </li><li>Region 级别： 
    <ul><li>当某个 region 的 memstore 的大小达到了 <code>hbase.hregion.memstore.flush.size(默认 128M)</code> 时，这个 region 的所有 memstore 都会刷写</li><li>当某个 region 的 memstore 的大小达到了 <code>hbase.hregion.memstore.flush.size(默认 128M) × hbase.hregion.memstore.block.multiplier(默认 4)</code>时，会停止继续往该 memstore 写数据</li></ul> </li></ul> </li></ul> 
<h3><a id="_49"></a>四、读流程原理</h3> 
<p><img src="https://images2.imgbox.com/76/0b/araOztzA_o.png" alt="在这里插入图片描述"></p> 
<ul><li>Client 先访问 Zookeeper，获取 <code>hbase:meta</code> 表位于哪个 Region Server</li><li>访问对应的 Region Server，获取 <code>hbase:meta</code> 表，根据读请求的 <code>namespace:table/rowkey</code> 信息查询出目标数据位于哪个 Region Server 中的哪个 Region 中，并将该 table 的 region 信息以及 meta 表的位置信息缓存在客户端的 meta cache，方便下次访问</li><li>与目标 Region Server 进行通讯</li><li>分别在 BlockCache (读缓存)，MemStore 和 StoreFile (HFile) 中查询目标数据，并将查到的所有数据进行合并 (merge)。此处所有数据是指同一条数据的不同版本 (timestamp) 或者不同的类型 (Put/Delete)</li><li>将从 StoreFile 中查询到的数据块 (Block，HFile 数据存储单元，默认大小为 64KB) 缓存到 BlockCache</li><li>将合并后 timestamp 最大的数据返回给客户端</li></ul> 
<h3><a id="StoreFile_Compaction_63"></a>五、StoreFile Compaction</h3> 
<p><img src="https://images2.imgbox.com/0d/1c/nQc7wG0l_o.png" alt="在这里插入图片描述"></p> 
<ul><li>背景：由于 memstore 每次刷写都会生成一个新的 HFile，且同一个字段的不同版本 (timestamp) 和不同类型 (Put/Delete) 有可能会分布在不同的 HFile 中，因此查询时需要遍历所有的 HFile</li><li>为了减少 HFile 的个数，以及清理掉过期和删除的数据，HBase 会进行 StoreFile Compaction</li><li>StoreFile Compaction 分为两种： 
  <ul><li>Minor Compaction：会将临近的若干个较小的 HFile 合并成一个较大的 HFile，但不会清理过期和删除的数据，shell 命令为 <code>compact</code></li><li>Major Compaction：会将一个 Store 下的所有的 HFile 合并成一个大 HFile，并且会清理掉过期和删除的数据，shell 命令为 <code>major_compact</code></li></ul> </li><li>Major Compaction 触发条件： 
  <ul><li>HFile 存储时长达到 <code>hbase.hregion.majorcompaction(默认 7 天)</code> 的值时自动进行 Major Compaction，但生产上一般会关闭 (设置为 0)</li><li>当一个 store 中的 hfile 个数达到或超过 <code>hbase.hstore.compactionThreshold(默认 3)</code> 的值时自动进行 Major Compaction，或手动执行 <code>compact</code> 命令时也进行 Major Compaction</li></ul> </li></ul> 
<h3><a id="_79"></a>六、数据真正删除</h3> 
<ul><li>触发数据删除的条件：MemStore Flush 和 Major Compaction</li><li>当同一个字段的不同版本数据都在内存中， MemStore Flush 会删除版本小的数据，只将最大版本的数据刷写到磁盘；当同一个字段的不同类型数据都在内存中， MemStore Flush 只会删除 put 类型的数据 (delete 类型可能还要限制磁盘中的同字段数据)；当同一个字段的不同版本数据在不同的文件，此时 MemStore Flush 不会删除数据</li><li>Major Compaction 会删除需要保留的版本数之外的所有过时版本和 delete 类型的数据</li></ul> 
<h3><a id="Region_Split_87"></a>七、Region Split</h3> 
<p><img src="https://images2.imgbox.com/d0/b1/vk7lbkNw_o.png" alt="在这里插入图片描述"></p> 
<ul><li>默认情况下，每个 Table 起初只有一个 Region，随着数据的不断写入增加，Region 会触发自动进行拆分。刚拆分时，两个子 Region 都位于当前的 Region Server，但处于负载均衡的考虑，HMaster 有可能会将某个 Region 转移给其他的 Region Server</li><li>Region Split 触发时机： 
  <ul><li>0.94 版本之前：当 1 个 region 中的某个 Store 下所有 StoreFile 的总大小超过 <code>hbase.hregion.max.filesize(默认 10G)</code>，该 Region 就会进行拆分</li><li>0.94 版本之后：当 1 个 region 中的某个 Store 下所有 StoreFile 的总大小超过 <code>min(R^2 × hbase.hregion.memstore.flush.size, hbase.hregion.max.filesize)</code>， 该 Region 就会进行拆分，其中 R 为当前 Region Server 中属于该 Table 的 region 个数</li></ul> </li><li>自动切分会造成数据倾斜，产生数据热点问题，在生产上一般不使用，而是在建表时先进行预分区，后续插入数据时轮询的插入到不同的分区</li><li>官方建议使用一个列族，避免切分全局 flush 时产生大量小文件</li></ul>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/fd1c90e6f6b9b72c2e3ed06e550814c9/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Linux下Apache与Nginx服务器配置与优化</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/1468b88cdb75a8bfc77b16aae65b0d40/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【python】pandas常见文件读取方法</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>