<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>深度学习训练基于Pod和RDMA - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/5c22d2bbc1b2a3bfb4b96865a40df04e/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="深度学习训练基于Pod和RDMA">
  <meta property="og:description" content="目录
​编辑
引言
RDMA技术概述
InfiniBand
iWARP
RoCE
Pod和容器化环境
深度学习训练与RDMA结合
MPI和RDMA
深度学习框架与RDMA
实战：基于Pod和RDMA的深度学习训练
环境准备
步骤
YAML
性能和优势
结论
引言 随着深度学习在人工智能领域的快速发展，其在计算机视觉、自然语言处理、自动驾驶等多个领域都展现了强大的能力。然而，单个GPU的计算能力和内存大小已无法满足大规模深度学习训练的需求。为了使用更多的计算能力并缩短训练时间，分布式训练已成为解决大规模深度学习问题的关键方法。其中，RDMA（Remote Direct Memory Access）网络因其极高带宽与极低延迟的特性，在分布式训练中发挥着重要作用。本文将详细介绍如何在基于Pod的容器化环境中，利用RDMA网络进行深度学习训练。
RDMA技术概述 RDMA技术提供了一种跨过CPU、操作系统和TCP/IP协议栈，直接访问远端内存到本地内存的方式。它具有低延迟和低CPU使用率的优点。RDMA技术主要有三种实现方式：InfiniBand、iWARP和RoCE。其中，RoCE因其综合性能较好、兼容性较优、价格普惠而受到广泛认可。
InfiniBand InfiniBand设计之初就考虑了RDMA，从硬件级别保证可靠传输，但网卡和交换机的价格昂贵，兼容性差。
iWARP iWARP基于TCP或SCTP实现RDMA，对网络设备的要求较少，但TCP连接需要占用内核资源，市场认可度较低。
RoCE RoCE基于Ethernet实现RDMA，消耗的资源比iWARP少，支持的特性比iWARP多，需要FCoE实现可靠传输。RoCE的综合性能较好，价格普惠，且最新版本RoCEv2支持IPv4和IPv6，具有良好的可扩展性和应用前景。
Pod和容器化环境 在容器化集群环境中运行分布式模型训练时，通常使用Pod作为容器的基本单位。Pod是Kubernetes中的最小部署单元，可以包含一个或多个容器。在基于Pod的环境中，容器网络接口（CNI）用于实现容器间的网络通信。
深度学习训练与RDMA结合 MPI和RDMA MPI（Message Passing Interface）是一门比较老的技术，在高性能计算界几乎是标配，其对RDMA优化较好。MPI最大的优势有两点：一是MPI有一个高性能allreduce的实现，底层实现了tree aggregation；二是程序可以无缝移植到异构高性能计算环境，例如InfiniBand。
深度学习框架与RDMA 已有的深度学习框架大部分是基于传统的TCP/IP技术实现数据通信，在向RDMA网络移植时，有不同的技术方法可以选择：IPoIB、MPI以及RDMA Verbs。在这三种方法的选择上，需要在易用性和性能方面做出权衡。不合适的决策可能导致复杂且难以维护的代码实现。
例如，MXNet是一个模块化的深度学习框架，通过修改MXNet使其可以在RDMA网络上运行，可以将深度学习训练过程的通信部分划分为三个层次：点对点通信、Allreduce通信以及端到端训练。依据这种层次划分，可以提出增量式的移植与优化方法，使得性能的提升更有据可循。实验结果表明，在使用100个GPU时，并行效率可以从IPoIB版本的53%提升到96%，接近线性加速。
实战：基于Pod和RDMA的深度学习训练 环境准备 硬件环境： 服务器：若干台支持RDMA的服务器网卡：支持RoCE或InfiniBand的网卡交换机：支持RoCE或InfiniBand的交换机软件环境： Kubernetes集群：用于管理Pod和容器深度学习框架：如TensorFlow、PyTorch或MXNetMPI库：如mvapich2或MPICH容器网络接口（CNI）插件：支持RDMA的CNI插件 步骤 部署Kubernetes集群： 在服务器上安装Kubernetes，并配置网络插件以支持RDMA。配置RDMA网络： 在服务器上安装并配置RDMA网卡和驱动。配置交换机以支持RDMA网络。部署深度学习框架： 在Kubernetes集群中部署深度学习框架，并配置其使用RDMA进行通信。编写分布式训练代码： 使用MPI编写分布式训练代码，并配置其使用RDMA进行通信。将代码打包成容器镜像，并上传到Kubernetes集群中。创建Pod并启动训练： 使用Kubernetes的YAML文件定义Pod，并指定使用RDMA网络。启动Pod并开始进行分布式训练。 YAML 在Kubernetes中，要配置一个使用GPU和RDMA网络的Pod，需要创建一个YAML文件来定义Pod的规格。以下是一个示例YAML文件，它定义了一个使用example-gpu-dnn镜像的Pod，并假设你已经有一个支持RDMA的网络插件在Kubernetes集群中运行。
apiVersion: v1 kind: Pod metadata: name: example-gpu-dnn-pod labels: app: example-gpu-dnn spec: containers: - name: example-gpu-dnn-container image: example-gpu-dnn:latest imagePullPolicy: IfNotPresent resources: limits: nvidia.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-06-25T10:01:47+08:00">
    <meta property="article:modified_time" content="2024-06-25T10:01:47+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">深度学习训练基于Pod和RDMA</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h3 id="%E2%80%8B%E7%BC%96%E8%BE%91"><img alt="" height="675" src="https://images2.imgbox.com/bf/f0/ArXMNPlW_o.png" width="1200"></h3> 
<p id="main-toc"><strong>目录</strong></p> 
<p id="%E2%80%8B%E7%BC%96%E8%BE%91-toc" style="margin-left:40px;"><a href="#%E2%80%8B%E7%BC%96%E8%BE%91" rel="nofollow">​编辑</a></p> 
<p id="%E5%BC%95%E8%A8%80-toc" style="margin-left:40px;"><a href="#%E5%BC%95%E8%A8%80" rel="nofollow">引言</a></p> 
<p id="RDMA%E6%8A%80%E6%9C%AF%E6%A6%82%E8%BF%B0-toc" style="margin-left:40px;"><a href="#RDMA%E6%8A%80%E6%9C%AF%E6%A6%82%E8%BF%B0" rel="nofollow">RDMA技术概述</a></p> 
<p id="InfiniBand-toc" style="margin-left:80px;"><a href="#InfiniBand" rel="nofollow">InfiniBand</a></p> 
<p id="iWARP-toc" style="margin-left:80px;"><a href="#iWARP" rel="nofollow">iWARP</a></p> 
<p id="RoCE-toc" style="margin-left:80px;"><a href="#RoCE" rel="nofollow">RoCE</a></p> 
<p id="Pod%E5%92%8C%E5%AE%B9%E5%99%A8%E5%8C%96%E7%8E%AF%E5%A2%83-toc" style="margin-left:40px;"><a href="#Pod%E5%92%8C%E5%AE%B9%E5%99%A8%E5%8C%96%E7%8E%AF%E5%A2%83" rel="nofollow">Pod和容器化环境</a></p> 
<p id="%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83%E4%B8%8ERDMA%E7%BB%93%E5%90%88-toc" style="margin-left:40px;"><a href="#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83%E4%B8%8ERDMA%E7%BB%93%E5%90%88" rel="nofollow">深度学习训练与RDMA结合</a></p> 
<p id="MPI%E5%92%8CRDMA-toc" style="margin-left:80px;"><a href="#MPI%E5%92%8CRDMA" rel="nofollow">MPI和RDMA</a></p> 
<p id="%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6%E4%B8%8ERDMA-toc" style="margin-left:80px;"><a href="#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6%E4%B8%8ERDMA" rel="nofollow">深度学习框架与RDMA</a></p> 
<p id="%E5%AE%9E%E6%88%98%EF%BC%9A%E5%9F%BA%E4%BA%8EPod%E5%92%8CRDMA%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83-toc" style="margin-left:40px;"><a href="#%E5%AE%9E%E6%88%98%EF%BC%9A%E5%9F%BA%E4%BA%8EPod%E5%92%8CRDMA%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83" rel="nofollow">实战：基于Pod和RDMA的深度学习训练</a></p> 
<p id="%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87-toc" style="margin-left:80px;"><a href="#%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87" rel="nofollow">环境准备</a></p> 
<p id="%E6%AD%A5%E9%AA%A4-toc" style="margin-left:80px;"><a href="#%E6%AD%A5%E9%AA%A4" rel="nofollow">步骤</a></p> 
<p id="YAML-toc" style="margin-left:80px;"><a href="#YAML" rel="nofollow">YAML</a></p> 
<p id="%E6%80%A7%E8%83%BD%E5%92%8C%E4%BC%98%E5%8A%BF-toc" style="margin-left:80px;"><a href="#%E6%80%A7%E8%83%BD%E5%92%8C%E4%BC%98%E5%8A%BF" rel="nofollow">性能和优势</a></p> 
<p id="%E7%BB%93%E8%AE%BA-toc" style="margin-left:40px;"><a href="#%E7%BB%93%E8%AE%BA" rel="nofollow">结论</a></p> 
<hr id="hr-toc"> 
<p></p> 
<h3 id="%E5%BC%95%E8%A8%80">引言</h3> 
<p>随着深度学习在人工智能领域的快速发展，其在计算机视觉、自然语言处理、自动驾驶等多个领域都展现了强大的能力。然而，单个GPU的计算能力和内存大小已无法满足大规模深度学习训练的需求。为了使用更多的计算能力并缩短训练时间，分布式训练已成为解决大规模深度学习问题的关键方法。其中，RDMA（Remote Direct Memory Access）网络因其极高带宽与极低延迟的特性，在分布式训练中发挥着重要作用。本文将详细介绍如何在基于Pod的容器化环境中，利用RDMA网络进行深度学习训练。</p> 
<h3 id="RDMA%E6%8A%80%E6%9C%AF%E6%A6%82%E8%BF%B0">RDMA技术概述</h3> 
<p><img alt="" height="964" src="https://images2.imgbox.com/cd/2a/z0rQb0Sk_o.png" width="1200"></p> 
<p>RDMA技术提供了一种跨过CPU、操作系统和TCP/IP协议栈，直接访问远端内存到本地内存的方式。它具有低延迟和低CPU使用率的优点。RDMA技术主要有三种实现方式：InfiniBand、iWARP和RoCE。其中，RoCE因其综合性能较好、兼容性较优、价格普惠而受到广泛认可。</p> 
<h4 id="InfiniBand">InfiniBand</h4> 
<p>InfiniBand设计之初就考虑了RDMA，从硬件级别保证可靠传输，但网卡和交换机的价格昂贵，兼容性差。</p> 
<h4 id="iWARP">iWARP</h4> 
<p>iWARP基于TCP或SCTP实现RDMA，对网络设备的要求较少，但TCP连接需要占用内核资源，市场认可度较低。</p> 
<h4 id="RoCE">RoCE</h4> 
<p>RoCE基于Ethernet实现RDMA，消耗的资源比iWARP少，支持的特性比iWARP多，需要FCoE实现可靠传输。RoCE的综合性能较好，价格普惠，且最新版本RoCEv2支持IPv4和IPv6，具有良好的可扩展性和应用前景。</p> 
<h3 id="Pod%E5%92%8C%E5%AE%B9%E5%99%A8%E5%8C%96%E7%8E%AF%E5%A2%83">Pod和容器化环境</h3> 
<p>在容器化集群环境中运行分布式模型训练时，通常使用Pod作为容器的基本单位。Pod是Kubernetes中的最小部署单元，可以包含一个或多个容器。在基于Pod的环境中，容器网络接口（CNI）用于实现容器间的网络通信。</p> 
<h3 id="%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83%E4%B8%8ERDMA%E7%BB%93%E5%90%88">深度学习训练与RDMA结合</h3> 
<h4 id="MPI%E5%92%8CRDMA">MPI和RDMA</h4> 
<p>MPI（Message Passing Interface）是一门比较老的技术，在高性能计算界几乎是标配，其对RDMA优化较好。MPI最大的优势有两点：一是MPI有一个高性能allreduce的实现，底层实现了tree aggregation；二是程序可以无缝移植到异构高性能计算环境，例如InfiniBand。</p> 
<h4 id="%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6%E4%B8%8ERDMA">深度学习框架与RDMA</h4> 
<p>已有的深度学习框架大部分是基于传统的TCP/IP技术实现数据通信，在向RDMA网络移植时，有不同的技术方法可以选择：IPoIB、MPI以及RDMA Verbs。在这三种方法的选择上，需要在易用性和性能方面做出权衡。不合适的决策可能导致复杂且难以维护的代码实现。</p> 
<p>例如，MXNet是一个模块化的深度学习框架，通过修改MXNet使其可以在RDMA网络上运行，可以将深度学习训练过程的通信部分划分为三个层次：点对点通信、Allreduce通信以及端到端训练。依据这种层次划分，可以提出增量式的移植与优化方法，使得性能的提升更有据可循。实验结果表明，在使用100个GPU时，并行效率可以从IPoIB版本的53%提升到96%，接近线性加速。</p> 
<h3 id="%E5%AE%9E%E6%88%98%EF%BC%9A%E5%9F%BA%E4%BA%8EPod%E5%92%8CRDMA%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83">实战：基于Pod和RDMA的深度学习训练</h3> 
<h4 id="%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87">环境准备</h4> 
<ol><li><strong>硬件环境</strong>： 
  <ul><li>服务器：若干台支持RDMA的服务器</li><li>网卡：支持RoCE或InfiniBand的网卡</li><li>交换机：支持RoCE或InfiniBand的交换机</li></ul></li><li><strong>软件环境</strong>： 
  <ul><li>Kubernetes集群：用于管理Pod和容器</li><li>深度学习框架：如TensorFlow、PyTorch或MXNet</li><li>MPI库：如mvapich2或MPICH</li><li>容器网络接口（CNI）插件：支持RDMA的CNI插件</li></ul></li></ol> 
<h4 id="%E6%AD%A5%E9%AA%A4" style="background-color:transparent;">步骤</h4> 
<ol><li><strong>部署Kubernetes集群</strong>： 
  <ul><li>在服务器上安装Kubernetes，并配置网络插件以支持RDMA。</li></ul></li><li><strong>配置RDMA网络</strong>： 
  <ul><li>在服务器上安装并配置RDMA网卡和驱动。</li><li>配置交换机以支持RDMA网络。</li></ul></li><li><strong>部署深度学习框架</strong>： 
  <ul><li>在Kubernetes集群中部署深度学习框架，并配置其使用RDMA进行通信。</li></ul></li><li><strong>编写分布式训练代码</strong>： 
  <ul><li>使用MPI编写分布式训练代码，并配置其使用RDMA进行通信。</li><li>将代码打包成容器镜像，并上传到Kubernetes集群中。</li></ul></li><li><strong>创建Pod并启动训练</strong>： 
  <ul><li>使用Kubernetes的YAML文件定义Pod，并指定使用RDMA网络。</li><li>启动Pod并开始进行分布式训练。</li></ul></li></ol> 
<h4 id="YAML">YAML</h4> 
<p>在Kubernetes中，要配置一个使用GPU和RDMA网络的Pod，需要创建一个YAML文件来定义Pod的规格。以下是一个示例YAML文件，它定义了一个使用<code>example-gpu-dnn</code>镜像的Pod，并假设你已经有一个支持RDMA的网络插件在Kubernetes集群中运行。</p> 
<pre><code class="language-javascript">apiVersion: v1  
kind: Pod  
metadata:  
  name: example-gpu-dnn-pod  
  labels:  
    app: example-gpu-dnn  
spec:  
  containers:  
  - name: example-gpu-dnn-container  
    image: example-gpu-dnn:latest  
    imagePullPolicy: IfNotPresent  
    resources:  
      limits:  
        nvidia.com/gpu: 1 # 请求1个GPU  
    volumeMounts:  
    - name: rdma-device-plugin  
      mountPath: /var/lib/kubelet/device-plugins/  
  volumes:  
  - name: rdma-device-plugin  
    hostPath:  
      path: /var/lib/kubelet/device-plugins/  
      type: Directory  
  nodeSelector:  
    kubernetes.io/hostname: your-node-label # 指定运行Pod的节点，需要替换为实际的节点标签  
  affinity:  
    nodeAffinity:  
      requiredDuringSchedulingIgnoredDuringExecution:  
        nodeSelectorTerms:  
        - matchExpressions:  
          - key: feature.node.kubernetes.io/network-rdma.capable  
            operator: In  
            values:  
            - "true" # 确保Pod被调度到支持RDMA的节点上</code></pre> 
<p>在这个YAML文件中，做了以下几件事情：</p> 
<ol><li>定义了Pod的元数据和规格。</li><li>指定了容器使用的镜像<code>example-gpu-dnn:latest</code>。</li><li>设置了资源限制，请求1个GPU。</li><li>挂载了RDMA设备插件的目录，以便容器可以访问RDMA设备。</li><li>使用了<code>nodeSelector</code>来指定Pod应该运行在哪个节点上（需要替换为实际的节点标签）。</li><li>使用了<code>affinity</code>来确保Pod被调度到支持RDMA的节点上。</li></ol> 
<p>注意，需要根据实际环境和需求来调整这个YAML文件。特别是<code>nodeSelector</code>和<code>affinity</code>部分，需要确保它们与你的Kubernetes集群的配置相匹配。此外，如果RDMA设备插件不在<code>/var/lib/kubelet/device-plugins/</code>目录下，需要相应地修改<code>volumeMounts</code>和<code>volumes</code>部分。</p> 
<p> </p> 
<h4 id="%E6%80%A7%E8%83%BD%E5%92%8C%E4%BC%98%E5%8A%BF">性能和优势</h4> 
<p>通过基于Pod和RDMA的深度学习训练，可以获得以下性能和优势：</p> 
<ul><li><strong>高通信带宽</strong>：RDMA网络提供极高的通信带宽，可以加速数据在节点之间的传输。</li><li><strong>低延迟</strong>：RDMA网络具有极低的延迟，可以减少通信过程中的等待时间。</li><li><strong>低CPU使用率</strong>：RDMA网络绕过CPU进行数据传输，可以降低CPU的使用率。</li><li><strong>可扩展性</strong>：基于Pod的容器化环境可以轻松扩展训练规模，支持更多的GPU和节点。</li></ul> 
<h3 id="%E7%BB%93%E8%AE%BA">结论</h3> 
<p>通过结合Pod和RDMA技术，可以在容器化环境中实现高效、可扩展的深度学习训练。RDMA网络提供的高带宽、低延迟和低CPU使用率特性，可以显著提升分布式训练的性能。未来，随着RDMA技术的不断发展和普及，基于Pod和RDMA的深度学习训练将成为大规模深度学习应用的重要方向。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/15e1c64b19e16a9c84db035b9bc4b903/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Python 爬虫从入门到入狱之路一</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/80385eb02605f538c421ad65599f8156/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">爆火的儿童绘本如何用AI制作？一文解锁从制作到变现的全流程！</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>