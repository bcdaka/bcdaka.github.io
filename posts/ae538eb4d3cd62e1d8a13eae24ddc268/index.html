<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>在Mac M1笔记本上跑大语言模型llama3的4个步骤？（install、pull、run、ask） - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/ae538eb4d3cd62e1d8a13eae24ddc268/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="在Mac M1笔记本上跑大语言模型llama3的4个步骤？（install、pull、run、ask）">
  <meta property="og:description" content="要点 Ollama一个功能强大的本地大语言模型LLM运行工具，支持很多模型，并且操作极其简单快速回忆步骤： 下载ollama工具：https://ollama.com/download 下载模型：ollama pull llama3 #根据libs列表直接指定名字 运行模型：ollama run llama3 测试：直接问他问题（可以关闭网络） 步骤 Step1. 下载ollama（根据平台选择） https://ollama.com/download
下载后将软件安装，解压后拷贝到应用程序：
安装用户态命令：（点击install）
Step2：下载模型文件 支持的模型列表：https://ollama.com/library
比如llama3：
安装步骤：命令行直接安装
ollama pull llama3 实操：
这里需要耗费一些时间，具体根据网络和模型大小确定，模型大小参考：
ModelParametersSizeDownloadLlama 38B4.7GBollama run llama3Llama 370B40GBollama run llama3:70bMistral7B4.1GBollama run mistralDolphin Phi2.7B1.6GBollama run dolphin-phiPhi-22.7B1.7GBollama run phiNeural Chat7B4.1GBollama run neural-chatStarling7B4.1GBollama run starling-lmCode Llama7B3.8GBollama run codellamaLlama 2 Uncensored7B3.8GBollama run llama2-uncensoredLlama 2 13B13B7.3GBollama run llama2:13bLlama 2 70B70B39GBollama run llama2:70bOrca Mini3B1.9GBollama run orca-miniLLaVA7B4.5GBollama run llavaGemma2B1.4GBollama run gemma:2bGemma7B4.8GBollama run gemma:7bSolar10.7B6.1GBollama run solar 官方的参考资源：">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-04-23T10:07:18+08:00">
    <meta property="article:modified_time" content="2024-04-23T10:07:18+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">在Mac M1笔记本上跑大语言模型llama3的4个步骤？（install、pull、run、ask）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_1"></a>要点</h2> 
<ul><li>Ollama一个功能强大的本地大语言模型LLM运行工具，支持很多模型，并且操作极其简单</li><li>快速回忆步骤：</li></ul> 
<pre><code class="prism language-bash">下载ollama工具：https://ollama.com/download
下载模型：ollama pull llama3 <span class="token comment">#根据libs列表直接指定名字</span>
运行模型：ollama run llama3
测试：直接问他问题（可以关闭网络）
</code></pre> 
<h2><a id="_12"></a>步骤</h2> 
<h3><a id="Step1_ollama_13"></a>Step1. 下载ollama（根据平台选择）</h3> 
<p>https://ollama.com/download<br> <img src="https://images2.imgbox.com/b0/f9/LP6uc791_o.png" alt="在这里插入图片描述"><br> 下载后将软件安装，解压后拷贝到应用程序：<br> <img src="https://images2.imgbox.com/a6/2f/IYXM5lO4_o.png" alt="在这里插入图片描述"><br> 安装用户态命令：（点击install）<br> <img src="https://images2.imgbox.com/42/a7/ASaZWwa3_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="Step2_21"></a>Step2：下载模型文件</h3> 
<p>支持的模型列表：<a href="https://ollama.com/library" rel="nofollow">https://ollama.com/library</a><br> 比如llama3：<br> <img src="https://images2.imgbox.com/51/b2/LrrIszCu_o.png" alt="在这里插入图片描述"><br> 安装步骤：命令行直接安装</p> 
<pre><code class="prism language-bash">ollama pull llama3
</code></pre> 
<p>实操：<br> <img src="https://images2.imgbox.com/78/ad/RPPyLsei_o.png" alt="在这里插入图片描述"></p> 
<p>这里需要耗费一些时间，具体根据网络和模型大小确定，模型大小参考：</p> 
<table><thead><tr><th>Model</th><th>Parameters</th><th>Size</th><th>Download</th></tr></thead><tbody><tr><td>Llama 3</td><td>8B</td><td>4.7GB</td><td><code>ollama run llama3</code></td></tr><tr><td>Llama 3</td><td>70B</td><td>40GB</td><td><code>ollama run llama3:70b</code></td></tr><tr><td>Mistral</td><td>7B</td><td>4.1GB</td><td><code>ollama run mistral</code></td></tr><tr><td>Dolphin Phi</td><td>2.7B</td><td>1.6GB</td><td><code>ollama run dolphin-phi</code></td></tr><tr><td>Phi-2</td><td>2.7B</td><td>1.7GB</td><td><code>ollama run phi</code></td></tr><tr><td>Neural Chat</td><td>7B</td><td>4.1GB</td><td><code>ollama run neural-chat</code></td></tr><tr><td>Starling</td><td>7B</td><td>4.1GB</td><td><code>ollama run starling-lm</code></td></tr><tr><td>Code Llama</td><td>7B</td><td>3.8GB</td><td><code>ollama run codellama</code></td></tr><tr><td>Llama 2 Uncensored</td><td>7B</td><td>3.8GB</td><td><code>ollama run llama2-uncensored</code></td></tr><tr><td>Llama 2 13B</td><td>13B</td><td>7.3GB</td><td><code>ollama run llama2:13b</code></td></tr><tr><td>Llama 2 70B</td><td>70B</td><td>39GB</td><td><code>ollama run llama2:70b</code></td></tr><tr><td>Orca Mini</td><td>3B</td><td>1.9GB</td><td><code>ollama run orca-mini</code></td></tr><tr><td>LLaVA</td><td>7B</td><td>4.5GB</td><td><code>ollama run llava</code></td></tr><tr><td>Gemma</td><td>2B</td><td>1.4GB</td><td><code>ollama run gemma:2b</code></td></tr><tr><td>Gemma</td><td>7B</td><td>4.8GB</td><td><code>ollama run gemma:7b</code></td></tr><tr><td>Solar</td><td>10.7B</td><td>6.1GB</td><td><code>ollama run solar</code></td></tr></tbody></table> 
<p>官方的参考资源：<br> 8 GB 内存跑 7B models<br> 16 GB to run the 13B models<br> 32 GB to run the 33B models<br> 比如M1有16G内存，可以跑7B的模型。</p> 
<h3><a id="Step_59"></a>Step：运行模型</h3> 
<pre><code class="prism language-bash">ollama run llama3
</code></pre> 
<p>实操：（在M1的笔记本大概是s级别的，其他比如intel笔记本可能需要十几秒，M3等笔记本应该非常快）<br> 并且测试的时候可以尝试关闭网络。<br> 比如让他回答一个 gcc编译的问题：<br> <img src="https://images2.imgbox.com/1b/78/v0zqEv7i_o.png" alt="gcc"><br> 再来一个：“python如何使用list，举一个实际的例子”<br> <img src="https://images2.imgbox.com/11/db/CsRcrPYX_o.png" alt="py"></p> 
<h3><a id="Step_69"></a>Step：退出聊天</h3> 
<p>Ctrl + d 或者 /bye退出聊天</p> 
<h2><a id="_72"></a>其他</h2> 
<ul><li>ollama的github：<a href="https://github.com/ollama/ollama">https://github.com/ollama/ollama</a></li><li>ollama在mac本地是以类似git的方式存储的，存储的模型都是以blobs的形式，和git底层原理类似。<br> <img src="https://images2.imgbox.com/1b/55/y8QXPYhh_o.png" alt="在这里插入图片描述">- ollama在mac上模型存储的地址： ~/.ollama/models/blobs/</li><li>在models/manifests中存储了配置信息，比如llama的blob是哪个等信息</li><li>运行以后会自动启动RESTful的接口，也就是可以通过局域网访问，端口是11434，比如：<br> <img src="https://images2.imgbox.com/47/b7/3XqwNRur_o.png" alt="在这里插入图片描述"></li><li>可以通过curl使用restful方式访问：比如：</li></ul> 
<pre><code class="prism language-bash"><span class="token function">curl</span> http://localhost:11434/api/generate <span class="token parameter variable">-d</span> <span class="token string">'{
  "model": "llama3",
  "prompt":"Why is the sky blue?"
}'</span>
</code></pre> 
<ul><li>端侧的模型也具有记忆能力，还能反馈错误并且修改正</li><li>查看当前使用的模型等信息 /show info<br> <img src="https://images2.imgbox.com/6c/a8/Wjkh8KyO_o.png" alt="在这里插入图片描述"></li></ul> 
<h2><a id="_90"></a>最后</h2> 
<p>实操下来，因为ollma非常简单，只需要3个步骤就能使用模型，更多模型只需要一个pull就搞定。一台稍微不错的笔记本+网络，就能把各种大模型都用起来，快速上手吧。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/8eb080f1448f18a098f655e512c536b4/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Androidstudio项目升级遇到错误Namespace not specified. Specify a namespace in the module‘s build file</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/87e988a9794557be209fc92dde53cebb/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Hbase Java编程</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>