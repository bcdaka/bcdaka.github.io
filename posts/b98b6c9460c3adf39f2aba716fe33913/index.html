<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>如何保证每次画出的都同一张人脸？AI绘画Stable Diffusion的Reference only教程 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/b98b6c9460c3adf39f2aba716fe33913/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="如何保证每次画出的都同一张人脸？AI绘画Stable Diffusion的Reference only教程">
  <meta property="og:description" content=" Ai绘画有一个很现实的问题，要保证每次画出的都是同一个人物的话，很费劲。
Midjourney就不必说了，人物的高度一致性一直得不到很好的解决。而在Stable Diffusion（SD）中，常用办法是通过同一个Seed值（种子值），或者通过训练同一个人物的高质量Lora去控制。
Seed值控制虽然可大体达到目的，但是画出的人物姿态也高度趋同，而且稍微改变描述就会画出另外一个人来，而训练「高质量」模型则更费时费力。
直到最近SD的Controlnet插件推出了Reference only功能，这个问题才得到较好的改善。
一张稳定的人脸，配合不同的场景和动作，意味着角色人设可以得到继承和发挥。如应用到连贯的绘画场景中，例如漫画、虚拟角色设计等领域，意味着提高产能的可行性。
先看看效果。下面是SD画出的一张动漫人物参考图。
我们通过Reference Only功能，基于参考图去生成新的图片，大致效果如下(点击可看大图)：
可以看到，在改变了姿势、场景、构图之后，人物的脸部特征，包括发型，仍然得到很好的保留，维持了高度统一的形象。
同时也留意到，人物服装只是部分相同。这个时候，如果要保持一致性，应该通过更详细的Tag描述去控制，具体指定服装的颜色、样式和风格等。
换个「真人」图看看。下图是SD画的参考图：
修改描述词后，通过Reference Only生成新的图片例：
可以看到，“真人”效果和动漫人物效果结论相近，而且即使变换底模（大模型），人物脸部仍然可以得到很好的继承。
需要指出的是，在测试过程中发现：
1.并不是所有底模，都可以跟Reference only契合得很好，个别模型在成像过程中，有时候会出现色彩走样。
2.一些底模结合Reference only绘图时，并不总是支持多动作、多场景、多视角变换，个别场景很难被画出，例如，要把背景换成“大海”，即使“大海”的权重再高，也是无法实现，不知是何原因。
无论如何，Reference only可免去训练高质量模型即可保持人物一致，算是一个较大进步，如果下个版本可以解决上述2个问题，相信可以更好地赋能内容生产领域。
Reference only目前一共有3个预处理器可用，分别为：
Reference only：绘制与参考图类似的风格和脸部；
Reference adain：自适应规范，会更偏向于使用的模型，结果可能偏离参考图；
Reference adain&#43;attn：结合了上述两种。
具体的安装使用方法如下：
确保你的controlnet版本为最新（如果你用的是整合包，很可能包含了最新版，或者可一键更新），地址如下（需科学上网）： https://github.com/lllyasviel/ControlNet-v1-1-nightly
如无法下载，请看文末扫描获取插件安装包
2.建议在SD中生成参考图，并将参考图上传到Controlnet的图片作业区域，如下图界面：​​​​​​
3.勾选启用Controlnet，选择Reference only三个预处理器中的一个，并将Style Fidelity值设置为1，如下：
4.基于参考图的描述词生成图片即可，如需变换场景或细节例如发型等，可在正面提示词中调整，不会影响人脸继承。
写在最后 感兴趣的小伙伴，赠送全套AIGC学习资料，包含AI绘画、AI人工智能等前沿科技教程和软件工具，具体看这里。
AIGC技术的未来发展前景广阔，随着人工智能技术的不断发展，AIGC技术也将不断提高。未来，AIGC技术将在游戏和计算领域得到更广泛的应用，使游戏和计算系统具有更高效、更智能、更灵活的特性。同时，AIGC技术也将与人工智能技术紧密结合，在更多的领域得到广泛应用，对程序员来说影响至关重要。未来，AIGC技术将继续得到提高，同时也将与人工智能技术紧密结合，在更多的领域得到广泛应用。
一、AIGC所有方向的学习路线
AIGC所有方向的技术点做的整理，形成各个领域的知识点汇总，它的用处就在于，你可以按照下面的知识点去找对应的学习资源，保证自己学得较为全面。
二、AIGC必备工具
工具都帮大家整理好了，安装就可直接上手！
三、最新AIGC学习笔记
当我学到一定基础，有自己的理解能力的时候，会去阅读一些前辈整理的书籍或者手写的笔记资料，这些笔记详细记载了他们对一些技术点的理解，这些理解是比较独到，可以学到不一样的思路。
四、AIGC视频教程合集
观看全面零基础学习视频，看视频学习是最快捷也是最有效果的方式，跟着视频中老师的思路，从基础到深入，还是很容易入门的。
五、实战案例
纸上得来终觉浅，要学会跟着视频一起敲，要动手实操，才能将自己的所学运用到实际当中去，这时候可以搞点实战案例来学习。
若有侵权，请联系删除 ">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-04-28T11:23:13+08:00">
    <meta property="article:modified_time" content="2024-04-28T11:23:13+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">如何保证每次画出的都同一张人脸？AI绘画Stable Diffusion的Reference only教程</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p><img src="https://images2.imgbox.com/7c/89/HmI1Whv4_o.png" alt=""></p> 
<p>Ai绘画有一个很现实的问题，要保证每次画出的都是同一个人物的话，很费劲。</p> 
<p>Midjourney就不必说了，人物的高度一致性一直得不到很好的解决。而在Stable Diffusion（SD）中，常用办法是通过同一个Seed值（种子值），或者通过训练同一个人物的高质量Lora去控制。</p> 
<p>Seed值控制虽然可大体达到目的，但是画出的人物姿态也高度趋同，而且稍微改变描述就会画出另外一个人来，而训练「高质量」模型则更费时费力。</p> 
<p>直到最近SD的Controlnet插件推出了Reference only功能，这个问题才得到较好的改善。</p> 
<p>一张稳定的人脸，配合不同的场景和动作，意味着角色人设可以得到继承和发挥。如应用到连贯的绘画场景中，例如漫画、虚拟角色设计等领域，意味着提高产能的可行性。</p> 
<p>先看看效果。下面是SD画出的一张动漫人物参考图。</p> 
<p><img src="https://images2.imgbox.com/03/a7/Iaib7Tsy_o.png" alt=""></p> 
<p>我们通过Reference Only功能，基于参考图去生成新的图片，大致效果如下(点击可看大图)：</p> 
<p><img src="https://images2.imgbox.com/cf/53/pHgUz7Pf_o.png" alt=""></p> 
<p>可以看到，在改变了姿势、场景、构图之后，人物的脸部特征，包括发型，仍然得到很好的保留，维持了高度统一的形象。</p> 
<p>同时也留意到，人物服装只是部分相同。这个时候，如果要保持一致性，应该通过更详细的Tag描述去控制，具体指定服装的颜色、样式和风格等。</p> 
<p>换个「真人」图看看。下图是SD画的参考图：</p> 
<p><img src="https://images2.imgbox.com/78/b7/VWEB0lZo_o.png" alt=""></p> 
<p>修改描述词后，通过Reference Only生成新的图片例：</p> 
<p><img src="https://images2.imgbox.com/20/c3/OrGCbXxU_o.png" alt=""></p> 
<p>可以看到，“真人”效果和动漫人物效果结论相近，而且即使变换底模（大模型），人物脸部仍然可以得到很好的继承。</p> 
<p>需要指出的是，在测试过程中发现：</p> 
<p>1.并不是所有底模，都可以跟Reference only契合得很好，个别模型在成像过程中，有时候会出现色彩走样。</p> 
<p>2.一些底模结合Reference only绘图时，并不总是支持多动作、多场景、多视角变换，个别场景很难被画出，例如，要把背景换成“大海”，即使“大海”的权重再高，也是无法实现，不知是何原因。</p> 
<p>无论如何，Reference only可免去训练高质量模型即可保持人物一致，算是一个较大进步，如果下个版本可以解决上述2个问题，相信可以更好地赋能内容生产领域。</p> 
<p>Reference only目前一共有3个预处理器可用，分别为：</p> 
<blockquote> 
 <p>Reference only：绘制与参考图类似的风格和脸部；</p> 
 <p>Reference adain：自适应规范，会更偏向于使用的模型，结果可能偏离参考图；</p> 
 <p>Reference adain+attn：结合了上述两种。</p> 
</blockquote> 
<p>具体的安装使用方法如下：</p> 
<ol><li>确保你的controlnet版本为最新（如果你用的是整合包，很可能包含了最新版，或者可一键更新），地址如下（需科学上网）：</li></ol> 
<blockquote> 
 <p>https://github.com/lllyasviel/ControlNet-v1-1-nightly<br> 如无法下载，请看文末扫描获取插件安装包</p> 
</blockquote> 
<p>2.建议在SD中生成参考图，并将参考图上传到Controlnet的图片作业区域，如下图界面：​​​​​​</p> 
<p><img src="https://images2.imgbox.com/fe/36/XESHTyuu_o.png" alt=""></p> 
<p>3.勾选启用Controlnet，选择Reference only三个预处理器中的一个，并将Style Fidelity值设置为1，如下：</p> 
<p><img src="https://images2.imgbox.com/cb/4b/A7DBjLRR_o.png" alt=""></p> 
<p>4.基于参考图的描述词生成图片即可，如需变换场景或细节例如发型等，可在正面提示词中调整，不会影响人脸继承。</p> 
<h3><a id="_74"></a>写在最后</h3> 
<p><font face="幼圆" size="4" color="red">感兴趣的小伙伴，赠送全套AIGC学习资料，包含AI绘画、AI人工智能等前沿科技教程和软件工具，具体看这里。<br> </font><br> <img src="https://images2.imgbox.com/7b/16/F4Q32fOy_o.png"></p> 
<p>AIGC技术的未来发展前景广阔，随着人工智能技术的不断发展，AIGC技术也将不断提高。未来，AIGC技术将在游戏和计算领域得到更广泛的应用，使游戏和计算系统具有更高效、更智能、更灵活的特性。同时，AIGC技术也将与人工智能技术紧密结合，在更多的领域得到广泛应用，对程序员来说影响至关重要。未来，AIGC技术将继续得到提高，同时也将与人工智能技术紧密结合，在更多的领域得到广泛应用。<br>  <br> <img src="https://images2.imgbox.com/19/4e/svQvJN5K_o.png" alt="在这里插入图片描述"></p> 
<p><strong>一、AIGC所有方向的学习路线</strong></p> 
<p>AIGC所有方向的技术点做的整理，形成各个领域的知识点汇总，它的用处就在于，你可以按照下面的知识点去找对应的学习资源，保证自己学得较为全面。</p> 
<p><img src="https://images2.imgbox.com/ac/36/ThGGr5SN_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/32/6a/CXt0gFfE_o.png" alt="在这里插入图片描述"></p> 
<p><strong>二、AIGC必备工具</strong></p> 
<p>工具都帮大家整理好了，安装就可直接上手！<br> <img src="https://images2.imgbox.com/79/a8/RRo2R1vY_o.png" alt="在这里插入图片描述"></p> 
<p><strong>三、最新AIGC学习笔记</strong></p> 
<p>当我学到一定基础，有自己的理解能力的时候，会去阅读一些前辈整理的书籍或者手写的笔记资料，这些笔记详细记载了他们对一些技术点的理解，这些理解是比较独到，可以学到不一样的思路。<br> <img src="https://images2.imgbox.com/b9/20/lJ522pRg_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/0d/c0/Qygc2ftE_o.png" alt="在这里插入图片描述"></p> 
<p><strong>四、AIGC视频教程合集</strong></p> 
<p>观看全面零基础学习视频，看视频学习是最快捷也是最有效果的方式，跟着视频中老师的思路，从基础到深入，还是很容易入门的。</p> 
<p><img src="https://images2.imgbox.com/2d/a8/2T3n0z1m_o.png" alt="在这里插入图片描述"></p> 
<p><strong>五、实战案例</strong></p> 
<p>纸上得来终觉浅，要学会跟着视频一起敲，要动手实操，才能将自己的所学运用到实际当中去，这时候可以搞点实战案例来学习。<br> <img src="https://images2.imgbox.com/43/cc/FaNtEt4p_o.png" alt="在这里插入图片描述"></p> 
<img src="https://images2.imgbox.com/17/e8/5w9hFAV0_o.png"> 若有侵权，请联系删除
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/98ffa91a28786726cb9cab269fec2b48/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Python 语音识别系列-实战学习-语音识别特征提取</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/2ca73a53a639e15e4d6841fbe5e6d1e8/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">FlinkSQL 中lateral table</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>