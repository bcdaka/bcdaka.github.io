<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>图像生成新篇章：Stable Diffusion 3 Medium开源评析 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/2667d5be083cb4194ffa1747196bf99e/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="图像生成新篇章：Stable Diffusion 3 Medium开源评析">
  <meta property="og:description" content="摘要 在数字艺术与人工智能的交汇点上，Stable Diffusion 3（SD3）的开源无疑是一场技术革新的盛宴。就在3月份，我撰写了一篇博文，深入探讨了SD3的技术报告内容与介绍，文章发表在CSDN博客上，https://blog.csdn.net/sunbaigui/article/details/136898729。如今，随着SD3 Medium版本的开源，https://huggingface.co/spaces/stabilityai/stable-diffusion-3-medium，我们迎来了新的里程碑。在本文中，我将分享我对这一开源版本的初步体验，以及它对文生图开源社区所带来的影响。Stable Diffusion 3 Medium的开源是一个重要的技术里程碑，它不仅展示了AI在图像生成领域的最新进展，也为未来的艺术创作和技术开发提供了丰富的土壤。虽然仍有挑战需要克服，但我相信，通过社区的共同努力和不断的技术创新，我们将能够解锁更多的创造潜力，开拓数字艺术的新境界。
体验与分析 为了确保体验的一致性和可复现性，我在所有样例中使用了相同的随机数种子——&#34;888888888&#34;。这一决定让我能够更准确地评估SD3 Medium的性能，并与其他用户的结果进行比较。
图像文字与背景的突破 SD3 Medium在图像文字和背景生成方面取得了显著的进步。它能够更好地理解和执行复杂的文本提示，生成的图像在视觉美学、提示遵循和排版方面都有了显著提升。这不仅推动了整个社区在图像生成技术上的发展，也为未来的艺术创作提供了更多可能性。
前景主体及其交互动作的挑战 尽管在图像文字和背景上取得了成功，SD3 Medium在前景物体、尤其是人物与物体的交互方面仍有提升空间。在一些生成的图像中，前景主体细节部分往往容易出错，尤其是躯干/手指等，另外物体间的交互动作也需进一步优化。这些挑战提示我们，尽管技术取得了巨大进步，但在实现高度逼真的图像生成方面，仍需不断地研究和提升。
样例1： An astronaut riding a green horse
首先我们先看下官方样例结果：
在这个官方样例效果还不错，不过如果放开随机种子，多生成几次的话，局部细节不良率比较高。
样例2： The elderly person sits on a wrought-iron chair, holding a glass of wine, facing the sea where spring is warm and flowers are blooming, at a seaside holiday home, with flowers and the sea around, savoring the fine wine while looking towards the coast.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-06-14T08:00:00+08:00">
    <meta property="article:modified_time" content="2024-06-14T08:00:00+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">图像生成新篇章：Stable Diffusion 3 Medium开源评析</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2>摘要</h2> 
<p>        在数字艺术与人工智能的交汇点上，Stable Diffusion 3（SD3）的开源无疑是一场技术革新的盛宴。就在3月份，我撰写了一篇博文，深入探讨了SD3的技术报告内容与介绍，文章发表在CSDN博客上，<a href="https://blog.csdn.net/sunbaigui/article/details/136898729" title="https://blog.csdn.net/sunbaigui/article/details/136898729">https://blog.csdn.net/sunbaigui/article/details/136898729</a>。如今，随着SD3 Medium版本的开源，<a href="https://huggingface.co/spaces/stabilityai/stable-diffusion-3-medium" rel="nofollow" title="https://huggingface.co/spaces/stabilityai/stable-diffusion-3-medium">https://huggingface.co/spaces/stabilityai/stable-diffusion-3-medium</a>，我们迎来了新的里程碑。在本文中，我将分享我对这一开源版本的初步体验，以及它对文生图开源社区所带来的影响。Stable Diffusion 3 Medium的开源是一个重要的技术里程碑，它不仅展示了AI在图像生成领域的最新进展，也为未来的艺术创作和技术开发提供了丰富的土壤。虽然仍有挑战需要克服，但我相信，通过社区的共同努力和不断的技术创新，我们将能够解锁更多的创造潜力，开拓数字艺术的新境界。</p> 
<h3>体验与分析</h3> 
<p>为了确保体验的一致性和可复现性，我在所有样例中使用了相同的随机数种子——"888888888"。这一决定让我能够更准确地评估SD3 Medium的性能，并与其他用户的结果进行比较。</p> 
<h3>图像文字与背景的突破</h3> 
<p>SD3 Medium在图像文字和背景生成方面取得了显著的进步。它能够更好地理解和执行复杂的文本提示，生成的图像在视觉美学、提示遵循和排版方面都有了显著提升。这不仅推动了整个社区在图像生成技术上的发展，也为未来的艺术创作提供了更多可能性。</p> 
<h3>前景主体及其交互动作的挑战</h3> 
<p>尽管在图像文字和背景上取得了成功，SD3 Medium在前景物体、尤其是人物与物体的交互方面仍有提升空间。在一些生成的图像中，前景主体细节部分往往容易出错，尤其是躯干/手指等，另外物体间的交互动作也需进一步优化。这些挑战提示我们，尽管技术取得了巨大进步，但在实现高度逼真的图像生成方面，仍需不断地研究和提升。</p> 
<h5></h5> 
<h2>样例1：</h2> 
<p>An astronaut riding a green horse</p> 
<p>首先我们先看下官方样例结果：</p> 
<p><img alt="" height="1200" src="https://images2.imgbox.com/99/63/umBWYf3o_o.png" width="1200"></p> 
<p><span style="color:#fe2c24;">在这个官方样例效果还不错，不过如果放开随机种子，多生成几次的话，局部细节不良率比较高</span>。</p> 
<h2>样例2：</h2> 
<p>The elderly person sits on a wrought-iron chair, holding a glass of wine, facing the sea where spring is warm and flowers are blooming, at a seaside holiday home, with flowers and the sea around, savoring the fine wine while looking towards the coast.</p> 
<p>再让我们看几个自定义文本输入的结果，纯中文的结果较差，我们通过kimi做一道英文翻译，再将相应英文描述输入到stable-diffusion-3-medium中，看相应结果：</p> 
<p><img alt="" height="442" src="https://images2.imgbox.com/99/81/3CRsBkJb_o.png" width="1200"></p> 
<p><img alt="" height="1200" src="https://images2.imgbox.com/ad/c2/fw3BvUb7_o.png" width="1200"></p> 
<p><span style="color:#fe2c24;">老人的手部和腿部都有一些问题，词意理解的比较到位，图像中的背景生成细节丰富</span>。</p> 
<h2>样例3：</h2> 
<p></p> 
<p>Create a poster with the "FaceChain" inscription at the center, and a Chinese dragon soaring through clouds and mist above it.</p> 
<p><img alt="" height="386" src="https://images2.imgbox.com/63/b7/YJL7Szy1_o.png" width="1200"></p> 
<p><img alt="" height="1200" src="https://images2.imgbox.com/94/ce/P7xvbzJi_o.png" width="1200"></p> 
<p><span style="color:#fe2c24;">这里龙的局部包括龙头、龙翼、龙爪都有些个数与展示的不合理。但这边对FaceChain字样在图中的标识值得点赞，跟原技术报告中强调较强的图中文字嵌入能力是一致的，另外图中背景也理解到位</span>。</p> 
<h2>样例4：</h2> 
<p>Spider-Man is engaged in a fierce battle with a Transformer, set against the backdrop of the Amazon rainforest. Spider-Man fires a web from his hand, which ensnares the Transformer's head, causing the mighty robot to be seated firmly on the ground.</p> 
<p><img alt="" height="416" src="https://images2.imgbox.com/a4/62/bz1NEeRN_o.png" width="1200"></p> 
<p><img alt="" height="1200" src="https://images2.imgbox.com/0f/cc/CWvpb48R_o.png" width="1200"></p> 
<p><span style="color:#fe2c24;">这里意思没理解正确，如果放开随机种子多试几次会发现前景的交互细节有很多错误，但这里的图中背景也依然很好。</span></p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/2b199f6f55829a14be1b291eff81fda6/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">用【R语言】揭示大学生恋爱心理：【机器学习】与【深度学习】的案例深度解析</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/14c0377c920ec40d72500f1d424b4f4e/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">内网穿透方法有哪些？路由器端口映射外网和软件方案步骤</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>