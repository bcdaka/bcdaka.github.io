<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>有手就行，轻松本地部署 Llama、Qwen 大模型，无需 GPU - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/71a561aaf58329393be8e3c8ade50b36/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="有手就行，轻松本地部署 Llama、Qwen 大模型，无需 GPU">
  <meta property="og:description" content="用 CPU 也能部署私有化大模型？
对，没错，只要你的电脑有个 8G 内存，你就可以轻松部署 Llama、Gemma、Qwen 等多种开源大模型。
非技术人员，安装 Docker、Docker-compose 很费劲？
不用，这些都不需要安装，就一个要求：有手就行～
今天主要为大家分享保姆级教程：如何利用普通个人电脑，本地私有化部署 Qwen 大模型。
一、Ollama 与 Qwen7B 安装和使用 （一）下载 进入下载地址，目前支持 Mac、Windows、Linux 以及 docker 部署，本次演示，主要针对 Mac。
下载地址：https://github.com/ollama/ollama
我已经为大家提前下载好了 Mac、Windows 的安装包，公众号回复 ollama 领取。
（二）安装 Ollama 1、下载到本地，并解压后，双击 Ollama 图标。
2、点击 Move to Applications ，按照建议，将其移动到应用程序文件夹下。
3、按照从左到右的顺序执行这三步。到这 Ollama 安装完成了。
（三）安装模型 作为国内的优质大模型，Qwen 对于中文的支持力度还是很强的，最终选择用它来试手。
大家也可以尝试选择自己喜欢的模型，比如 Llama3、Gemma 等等。
1、进入模型仓库
地址：https://ollama.com/library
2、搜索对应模型。发现目前有 Qwen 0.5B ～ 110B 可供使用。
因为内存不够用，最终选择下载 Qwen:7b，大家可以按照自身硬件情况下载模型。
可以使用图中对应型号的命令，进行下载。7b 下载命令为：ollama run qwen:7b
官方建议： 至少有 8 GB 可用内存来运行 7 B 型号，16 GB 来运行 13 B 型号，32 GB 来运行 33 B 型号。">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-07-02T11:55:14+08:00">
    <meta property="article:modified_time" content="2024-07-02T11:55:14+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">有手就行，轻松本地部署 Llama、Qwen 大模型，无需 GPU</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p><strong>用 CPU 也能部署私有化大模型？</strong></p> 
<p>对，没错，只要你的电脑有个 8G 内存，你就可以轻松部署 Llama、Gemma、Qwen 等多种开源大模型。</p> 
<p><strong>非技术人员，安装 Docker、Docker-compose 很费劲？</strong></p> 
<p>不用，这些都不需要安装，就一个要求：有手就行～</p> 
<p>今天主要为大家分享保姆级教程：如何利用<code>普通个人电脑</code>，本地私有化部署 Qwen 大模型。</p> 
<h3><a id="Ollama__Qwen7B__12"></a><strong>一、Ollama 与 Qwen7B 安装和使用</strong></h3> 
<h4><a id="_14"></a><strong>（一）下载</strong></h4> 
<p>进入下载地址，目前支持 Mac、Windows、Linux 以及 docker 部署，本次演示，<strong>主要针对 Mac</strong>。</p> 
<blockquote> 
 <p>下载地址：https://github.com/ollama/ollama</p> 
 <p>我已经为大家提前下载好了 Mac、Windows 的安装包，公众号回复 <strong>ollama</strong> 领取。</p> 
</blockquote> 
<p><img src="https://images2.imgbox.com/6f/55/40xmW9bn_o.jpg" alt="图片"></p> 
<h4><a id="_Ollama_24"></a><strong>（二）安装 Ollama</strong></h4> 
<p>1、下载到本地，并解压后，双击 Ollama 图标。</p> 
<p><img src="https://images2.imgbox.com/ec/34/XtABbd6C_o.jpg" alt="图片"></p> 
<p>2、点击 <strong>Move to Applications</strong> ，按照建议，将其移动到应用程序文件夹下。</p> 
<p><img src="https://images2.imgbox.com/1c/7f/oTCbntK4_o.jpg" alt="图片"></p> 
<p>3、按照从左到右的顺序执行这三步。到这 Ollama 安装完成了。</p> 
<p><img src="https://images2.imgbox.com/5a/49/FFTndg7V_o.jpg" alt="图片"></p> 
<h4><a id="_38"></a><strong>（三）安装模型</strong></h4> 
<p>作为国内的优质大模型，Qwen 对于中文的支持力度还是很强的，最终选择用它来试手。</p> 
<p>大家也可以尝试选择自己喜欢的模型，比如 Llama3、Gemma 等等。</p> 
<p>1、进入模型仓库</p> 
<blockquote> 
 <p>地址：https://ollama.com/library</p> 
</blockquote> 
<p><img src="https://images2.imgbox.com/c1/12/2kw0XJAI_o.png" alt="在这里插入图片描述"></p> 
<p>2、搜索对应模型。发现目前有 <code>Qwen 0.5B ～ 110B</code> 可供使用。</p> 
<p>因为内存不够用，最终选择下载 <code>Qwen:7b</code>，大家可以按照自身硬件情况下载模型。</p> 
<p>可以使用图中对应型号的命令，进行下载。7b 下载命令为：<code>ollama run qwen:7b</code></p> 
<blockquote> 
 <p><strong>官方建议：</strong> 至少有 8 GB 可用内存来运行 7 B 型号，16 GB 来运行 13 B 型号，32 GB 来运行 33 B 型号。</p> 
</blockquote> 
<p><img src="https://images2.imgbox.com/6c/b4/PtSuvzNH_o.png" alt="在这里插入图片描述"></p> 
<p>3、下载完成，开始对话，中文能力的确可以～</p> 
<p>但是命令行对话总不是事儿啊，我们需要一个网页应用，这就得请出下一位主角：<code>ChatGPT-Next-Web</code>。</p> 
<p><img src="https://images2.imgbox.com/0a/a8/OjjEp92d_o.jpg" alt="图片"></p> 
<h3><a id="ChatGPTNextWeb__68"></a><strong>二、ChatGPT-Next-Web 安装和使用</strong></h3> 
<h4><a id="_70"></a><strong>（一）安装</strong></h4> 
<p>进入 <code>ChatGPT-Next-Web</code> 仓库地址，选择对应版本下载。</p> 
<blockquote> 
 <p>地址：https://github.com/ChatGPTNextWeb/ChatGPT-Next-Web/releases/tag/v2.12.4</p> 
</blockquote> 
<p>我选择了 <strong>NextChat_2.12.4_universal.dmg</strong></p> 
<blockquote> 
 <p>我已经为大家提前下载好了 Mac、Windows 安装包，公众号回复 <strong>ollama</strong> 领取。</p> 
</blockquote> 
<p><img src="https://images2.imgbox.com/88/00/KMtjDjGC_o.jpg" alt="图片"></p> 
<p>下载完成后，可以直接安装，无需额外下载其他软件。</p> 
<p><img src="https://images2.imgbox.com/c0/4f/T9Vp0F08_o.jpg" alt="图片"></p> 
<h4><a id="_86"></a><strong>（二）设置语言（可选）</strong></h4> 
<p>按需选择语言偏好。</p> 
<p><img src="https://images2.imgbox.com/eb/07/nErfJ6he_o.jpg" alt="图片"></p> 
<h4><a id="_92"></a><strong>（三）配置</strong></h4> 
<p>1、点击图标，进行配置页面。</p> 
<p>2、输入接口地址：http://localhost:11434</p> 
<p>3、自定义模型名：<strong>qwen:7b</strong></p> 
<p>4、模型（model）：<strong>qwen:7b()</strong> ，注意该选项在最下方。</p> 
<p><img src="https://images2.imgbox.com/52/60/tdu2CfzW_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="_105"></a><strong>四）对话测试</strong></h4> 
<p><strong>1、普通对话</strong></p> 
<p>效果还不错。</p> 
<p><img src="https://images2.imgbox.com/e1/41/UI57dpfK_o.jpg" alt="图片"></p> 
<p><strong>2、面具对话</strong></p> 
<p>使用面具对话功能时，需要注意，软件模型忽略了自定义的 qwen:7b，每次利用面具对话时，需要<code>重新选择模型</code>。</p> 
<p>2.1、没有选择模型时，则会出错。</p> 
<p><img src="https://images2.imgbox.com/4a/c3/SvN4fM22_o.jpg" alt="图片"></p> 
<p>2.2、点击图标，并选择正确的模型。</p> 
<p><img src="https://images2.imgbox.com/0d/f7/3YzTZbbQ_o.jpg" alt="图片"></p> 
<p><img src="https://images2.imgbox.com/82/0e/wYnilXfP_o.jpg" alt="图片"></p> 
<p>2.3、对话显示成功。</p> 
<p><img src="https://images2.imgbox.com/b2/86/2nl5FUAt_o.jpg" alt="图片"></p> 
<h3><a id="_131"></a><strong>三、总结</strong></h3> 
<p>没有消费级的 GPU，竟然都可以拥有自己的本地大模型。</p> 
<p>部署过程基本上没有卡点，一台普通的 Mac 就能搞定，太香了~</p> 
<p>想学习什么，欢迎留言告诉我。</p> 
<p>​</p> 
<h3><a id="_141"></a>如何学习大模型</h3> 
<p>现在社会上大模型越来越普及了，已经有很多人都想往这里面扎，但是却找不到适合的方法去学习。</p> 
<p>作为一名资深码农，初入大模型时也吃了很多亏，踩了无数坑。现在我想把我的经验和知识分享给你们，帮助你们学习AI大模型，能够解决你们学习中的困难。</p> 
<p>我已将重要的AI大模型资料包括市面上AI大模型各大白皮书、AGI大模型系统学习路线、AI大模型视频教程、实战学习，等录播视频免费分享出来，需要的小伙伴可以扫取。</p> 
<img src="https://images2.imgbox.com/19/22/Q3fE58SR_o.png"> 
<p><strong>一、AGI大模型系统学习路线</strong></p> 
<p>很多人学习大模型的时候没有方向，东学一点西学一点，像只无头苍蝇乱撞，我下面分享的这个学习路线希望能够帮助到你们学习AI大模型。</p> 
<p><img src="https://images2.imgbox.com/9e/e9/3PRQNYzt_o.png" alt="在这里插入图片描述"></p> 
<p><strong>二、AI大模型视频教程</strong></p> 
<p><img src="https://images2.imgbox.com/2c/8c/AHw2DORB_o.png" alt="在这里插入图片描述"></p> 
<p><strong>三、AI大模型各大学习书籍</strong></p> 
<p><img src="https://images2.imgbox.com/24/d8/8sVvN835_o.png" alt="在这里插入图片描述"></p> 
<p><strong>四、AI大模型各大场景实战案例</strong></p> 
<p><img src="https://images2.imgbox.com/11/8d/pxa1xbpc_o.png" alt="在这里插入图片描述"></p> 
<p><strong>五、结束语</strong></p> 
<p>学习AI大模型是当前科技发展的趋势，它不仅能够为我们提供更多的机会和挑战，还能够让我们更好地理解和应用人工智能技术。通过学习AI大模型，我们可以深入了解深度学习、神经网络等核心概念，并将其应用于自然语言处理、计算机视觉、语音识别等领域。同时，掌握AI大模型还能够为我们的职业发展增添竞争力，成为未来技术领域的领导者。</p> 
<p>再者，学习AI大模型也能为我们自己创造更多的价值，提供更多的岗位以及副业创收，让自己的生活更上一层楼。</p> 
<p><strong>因此，学习AI大模型是一项有前景且值得投入的时间和精力的重要选择。</strong></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/d913649b2a2230b4100478ee5d948c44/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【TS】TypeScript 入门指南：强大的JavaScript超集</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/ae8842dbd2510d2be87ef148c55156c9/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">前端接入chatgpt,实现流式文字的显示</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>