<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Sparkå®æ—¶ï¼ˆäº”ï¼‰ï¼šInputSourceæ•°æ®æºæ¡ˆä¾‹æ¼”ç¤º - ç¼–ç¨‹å¤§å’–</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/d5d6829c9b5285de6b8dc7f40c0872df/">
  <meta property="og:site_name" content="ç¼–ç¨‹å¤§å’–">
  <meta property="og:title" content="Sparkå®æ—¶ï¼ˆäº”ï¼‰ï¼šInputSourceæ•°æ®æºæ¡ˆä¾‹æ¼”ç¤º">
  <meta property="og:description" content="æ–‡ç« ç›®å½•
InputSourceæ•°æ®æºæ¡ˆä¾‹æ¼”ç¤º
ä¸€ã€â€‹â€‹â€‹â€‹â€‹â€‹â€‹File Source
1ã€è¯»å–textæ–‡ä»¶
2ã€è¯»å–csvæ–‡ä»¶
3ã€è¯»å–jsonæ–‡ä»¶
äºŒã€Socket SourceÂ ä¸‰ã€Rate Source
InputSourceæ•°æ®æºæ¡ˆä¾‹æ¼”ç¤º åœ¨Spark2.0ç‰ˆæœ¬ä¹‹åï¼ŒDataFrameå’ŒDatasetå¯ä»¥è¡¨ç¤ºé™æ€æœ‰è¾¹ç•Œçš„æ•°æ®ï¼Œä¹Ÿå¯ä»¥è¡¨ç¤ºæ— è¾¹ç•Œçš„æµå¼æ•°æ®ã€‚åœ¨Structured Streamingä¸­æˆ‘ä»¬å¯ä»¥ä½¿ç”¨SparkSessioné’ˆå¯¹æµå¼æ•°æ®æºåˆ›å»ºå¯¹åº”çš„Datasetæˆ–è€…DataFrameï¼Œå¹¶å¯ä»¥åƒå¤„ç†æ‰¹æ•°æ®ä¸€æ ·ä½¿ç”¨å„ç§Operatorsæ“ä½œå¤„ç†æµå¼æ•°æ®ã€‚
Structured Streamingçš„æ•°æ®æºç›®å‰æ”¯æŒFile Source ã€Socket Source ã€Rate Sourceã€Kafka Source ï¼Œä¸Kafkaçš„æ•´åˆåœ¨åç»­æ•´ç†ï¼Œè¿™é‡Œå¯¹å…¶ä»–ä¸‰ç§æ•°æ®æºåˆ†åˆ«æ¼”ç¤ºã€‚
ä¸€ã€â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹File Source Sturctured Streamingå¯ä»¥è¯»å–å†™å…¥ç›®å½•çš„æ–‡ä»¶ä½œä¸ºæ•°æ®æµï¼Œæ–‡ä»¶å°†æŒ‰ç…§æ–‡ä»¶ä¿®æ”¹æ—¶é—´çš„é¡ºåºè¿›è¡Œå¤„ç†ï¼Œæ–‡ä»¶å¿…é¡»åŸå­æ€§çš„å­˜å…¥åˆ°ç›‘æ§ç›®å½•ä¸­ï¼Œæ”¯æŒçš„æ ¼å¼æœ‰textã€csvã€jsonã€orcã€parquetã€‚
1ã€è¯»å–textæ–‡ä»¶ Scalaä»£ç å¦‚ä¸‹ï¼š
package com.lanson.structuredStreaming.source import org.apache.spark.sql.streaming.StreamingQuery import org.apache.spark.sql.{DataFrame, Dataset, SparkSession} /** * Structured Streamingç›‘æ§ç›®å½• textæ ¼å¼æ•°æ® */ object SSReadTextData { def main(args: Array[String]): Unit = { //1.åˆ›å»ºå¯¹è±¡ val spark: SparkSession = SparkSession.builder().master(&#34;local&#34;) .appName(&#34;SSReadTextData&#34;) .config(&#34;spark.sql.shuffle.partitions&#34;, 1) .getOrCreate() import spark.implicits._ spark.sparkContext.setLogLevel(&#34;Error&#34;) //2.ç›‘æ§ç›®å½• val ds: Dataset[String] = spark.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-07-25T23:49:05+08:00">
    <meta property="article:modified_time" content="2024-07-25T23:49:05+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="ç¼–ç¨‹å¤§å’–" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">ç¼–ç¨‹å¤§å’–</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Sparkå®æ—¶ï¼ˆäº”ï¼‰ï¼šInputSourceæ•°æ®æºæ¡ˆä¾‹æ¼”ç¤º</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/c8/87/Y84woCMl_o.jpg"></p> 
<p id="main-toc"><strong>æ–‡ç« ç›®å½•</strong></p> 
<p id="InputSource%E6%95%B0%E6%8D%AE%E6%BA%90%E6%A1%88%E4%BE%8B%E6%BC%94%E7%A4%BA-toc" style="margin-left:0px;"><a href="#InputSource%E6%95%B0%E6%8D%AE%E6%BA%90%E6%A1%88%E4%BE%8B%E6%BC%94%E7%A4%BA" rel="nofollow">InputSourceæ•°æ®æºæ¡ˆä¾‹æ¼”ç¤º</a></p> 
<p id="%E4%B8%80%E3%80%81%E2%80%8B%E2%80%8B%E2%80%8B%E2%80%8B%E2%80%8B%E2%80%8B%E2%80%8B%E2%80%8B%E2%80%8B%E2%80%8B%E2%80%8B%E2%80%8B%E2%80%8B%E2%80%8BFile%20Source-toc" style="margin-left:40px;"><a href="#%E4%B8%80%E3%80%81%E2%80%8B%E2%80%8B%E2%80%8B%E2%80%8B%E2%80%8B%E2%80%8B%E2%80%8B%E2%80%8B%E2%80%8B%E2%80%8B%E2%80%8B%E2%80%8B%E2%80%8B%E2%80%8BFile%20Source" rel="nofollow">ä¸€ã€â€‹â€‹â€‹â€‹â€‹â€‹â€‹File Source</a></p> 
<p id="1%E3%80%81%E8%AF%BB%E5%8F%96text%E6%96%87%E4%BB%B6-toc" style="margin-left:80px;"><a href="#1%E3%80%81%E8%AF%BB%E5%8F%96text%E6%96%87%E4%BB%B6" rel="nofollow">1ã€è¯»å–textæ–‡ä»¶</a></p> 
<p id="2%E3%80%81%E8%AF%BB%E5%8F%96csv%E6%96%87%E4%BB%B6-toc" style="margin-left:80px;"><a href="#2%E3%80%81%E8%AF%BB%E5%8F%96csv%E6%96%87%E4%BB%B6" rel="nofollow">2ã€è¯»å–csvæ–‡ä»¶</a></p> 
<p id="3%E3%80%81%E8%AF%BB%E5%8F%96json%E6%96%87%E4%BB%B6-toc" style="margin-left:80px;"><a href="#3%E3%80%81%E8%AF%BB%E5%8F%96json%E6%96%87%E4%BB%B6" rel="nofollow">3ã€è¯»å–jsonæ–‡ä»¶</a></p> 
<p id="%E4%BA%8C%E3%80%81Socket%20Source%C2%A0-toc" style="margin-left:40px;"><a href="#%E4%BA%8C%E3%80%81Socket%20Source%C2%A0" rel="nofollow">äºŒã€Socket SourceÂ </a></p> 
<p id="%E4%B8%89%E3%80%81Rate%20Source-toc" style="margin-left:40px;"><a href="#%E4%B8%89%E3%80%81Rate%20Source" rel="nofollow">ä¸‰ã€Rate Source</a></p> 
<hr id="hr-toc"> 
<p></p> 
<h2><strong>InputSourceæ•°æ®æºæ¡ˆä¾‹æ¼”ç¤º</strong></h2> 
<p style="margin-left:.0001pt;text-align:justify;">åœ¨Spark2.0ç‰ˆæœ¬ä¹‹åï¼ŒDataFrameå’ŒDatasetå¯ä»¥è¡¨ç¤ºé™æ€æœ‰è¾¹ç•Œçš„æ•°æ®ï¼Œä¹Ÿå¯ä»¥è¡¨ç¤ºæ— è¾¹ç•Œçš„æµå¼æ•°æ®ã€‚åœ¨Structured Streamingä¸­æˆ‘ä»¬å¯ä»¥ä½¿ç”¨SparkSessioné’ˆå¯¹æµå¼æ•°æ®æºåˆ›å»ºå¯¹åº”çš„Datasetæˆ–è€…DataFrameï¼Œå¹¶å¯ä»¥åƒå¤„ç†æ‰¹æ•°æ®ä¸€æ ·ä½¿ç”¨å„ç§Operatorsæ“ä½œå¤„ç†æµå¼æ•°æ®ã€‚</p> 
<p style="margin-left:.0001pt;text-align:justify;">Structured Streamingçš„æ•°æ®æºç›®å‰æ”¯æŒFile Source ã€Socket Source ã€Rate Sourceã€Kafka Source ï¼Œä¸Kafkaçš„æ•´åˆåœ¨åç»­æ•´ç†ï¼Œè¿™é‡Œå¯¹å…¶ä»–ä¸‰ç§æ•°æ®æºåˆ†åˆ«æ¼”ç¤ºã€‚</p> 
<p></p> 
<h3 id="%E4%B8%80%E3%80%81%E2%80%8B%E2%80%8B%E2%80%8B%E2%80%8B%E2%80%8B%E2%80%8B%E2%80%8B%E2%80%8B%E2%80%8B%E2%80%8B%E2%80%8B%E2%80%8B%E2%80%8B%E2%80%8BFile%20Source"><strong>ä¸€ã€â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹File Source</strong></h3> 
<p style="margin-left:.0001pt;text-align:justify;">Sturctured Streamingå¯ä»¥è¯»å–å†™å…¥ç›®å½•çš„æ–‡ä»¶ä½œä¸ºæ•°æ®æµï¼Œæ–‡ä»¶å°†æŒ‰ç…§æ–‡ä»¶ä¿®æ”¹æ—¶é—´çš„é¡ºåºè¿›è¡Œå¤„ç†ï¼Œæ–‡ä»¶å¿…é¡»åŸå­æ€§çš„å­˜å…¥åˆ°ç›‘æ§ç›®å½•ä¸­ï¼Œæ”¯æŒçš„æ ¼å¼æœ‰textã€csvã€jsonã€orcã€parquetã€‚</p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<h4 id="1%E3%80%81%E8%AF%BB%E5%8F%96text%E6%96%87%E4%BB%B6" style="text-align:justify;"><strong><strong>1ã€è¯»å–textæ–‡ä»¶</strong></strong></h4> 
<p style="margin-left:.0001pt;text-align:justify;">Scalaä»£ç å¦‚ä¸‹ï¼š</p> 
<pre><code class="language-Scala">package com.lanson.structuredStreaming.source

import org.apache.spark.sql.streaming.StreamingQuery
import org.apache.spark.sql.{DataFrame, Dataset, SparkSession}

/**
  *  Structured Streamingç›‘æ§ç›®å½• textæ ¼å¼æ•°æ®
  */
object SSReadTextData {
  def main(args: Array[String]): Unit = {

    //1.åˆ›å»ºå¯¹è±¡
    val spark: SparkSession = SparkSession.builder().master("local")
      .appName("SSReadTextData")
      .config("spark.sql.shuffle.partitions", 1)
      .getOrCreate()

    import  spark.implicits._

    spark.sparkContext.setLogLevel("Error")

    //2.ç›‘æ§ç›®å½•
    val ds: Dataset[String] = spark.readStream.textFile("./data/")

    val result: DataFrame = ds.map(line =&gt; {
      val arr: Array[String] = line.split("-")
      (arr(0).toInt, arr(1), arr(2).toInt)
    }).toDF("id", "name", "age")

    val query: StreamingQuery = result.writeStream
      .format("console")
      .start()

    query.awaitTermination()

  }

}
</code></pre> 
<p>Â ç»“æœï¼š</p> 
<p><img alt="" height="630" src="https://images2.imgbox.com/77/94/jE0dYAwG_o.png" width="1200"></p> 
<p>Javaä»£ç å¦‚ä¸‹ï¼š</p> 
<pre><code class="language-java">package com.lanson.structuredStreaming.source;

import java.util.concurrent.TimeoutException;
import org.apache.spark.api.java.function.MapFunction;
import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Encoders;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.SparkSession;
import org.apache.spark.sql.streaming.StreamingQueryException;
import scala.Tuple3;

public class SSReadTextData01 {
    public static void main(String[] args) throws TimeoutException, StreamingQueryException {
        //1.åˆ›å»ºå¯¹è±¡
        SparkSession spark = SparkSession.builder().master("local")
                .appName("SSReadSocketData01")
                .config("spark.sql.shuffle.partitions", 1)
                .getOrCreate();

        spark.sparkContext().setLogLevel("Error");

        Dataset&lt;String&gt; ds = spark.readStream().textFile("./data/");

        Dataset&lt;Tuple3&lt;Integer, String, Integer&gt;&gt; ds2 = ds.map(new MapFunction&lt;String, Tuple3&lt;Integer, String, Integer&gt;&gt;() {
            @Override
            public Tuple3&lt;Integer, String, Integer&gt; call(String line) throws Exception {
                String[] arr = line.split("-");

                return new Tuple3&lt;&gt;(Integer.valueOf(arr[0]), arr[1],Integer.valueOf(arr[2]) );
            }
        }, Encoders.tuple(Encoders.INT(), Encoders.STRING(), Encoders.INT()));

        Dataset&lt;Row&gt; result = ds2.toDF("id", "name", "age");

        result.writeStream()
                .format("console")
                .start()
                .awaitTermination();

    }
}
</code></pre> 
<p>Â ç»“æœï¼š</p> 
<p><img alt="" height="627" src="https://images2.imgbox.com/67/29/qlqoeXCy_o.png" width="1200"></p> 
<p style="margin-left:.0001pt;text-align:justify;">ä»¥ä¸Šä»£ç ç¼–å†™å®Œæˆä¹‹åï¼Œå‘ç›‘æ§çš„ç›®å½•â€œ./dataâ€ä¸­ä¸æ–­å†™å…¥å«æœ‰ä»¥ä¸‹å†…å®¹çš„æ–‡ä»¶ï¼Œå¯ä»¥çœ‹åˆ°æ§åˆ¶å°æœ‰å¯¹åº”çš„æµæ•°æ®è¾“å‡ºï¼Œè¿™é‡Œä¸€å®šæ˜¯åŸå­æ€§çš„å°†æ–‡ä»¶å¤åˆ¶åˆ°å¯¹åº”ç›®å½•ä¸‹ã€‚æ–‡ä»¶å†…å®¹å¦‚ä¸‹ï¼š</p> 
<pre><code class="language-java">1-zhangsan-18
2-lisi-19
3-ww-20</code></pre> 
<p></p> 
<h4 id="2%E3%80%81%E8%AF%BB%E5%8F%96csv%E6%96%87%E4%BB%B6"><strong>2ã€è¯»å–csvæ–‡ä»¶</strong></h4> 
<p style="margin-left:.0001pt;text-align:justify;">Scalaä»£ç å¦‚ä¸‹ï¼š</p> 
<pre><code class="language-Scala">package com.lanson.structuredStreaming.source

import org.apache.spark.sql.{DataFrame, Dataset, SparkSession}
import org.apache.spark.sql.streaming.StreamingQuery
import org.apache.spark.sql.types.StructType

/**
  * Structured Streaming è¯»å–CSVæ•°æ®
  */
object SSReadCsvData {
  def main(args: Array[String]): Unit = {
    //1.åˆ›å»ºå¯¹è±¡
    val spark: SparkSession = SparkSession.builder().master("local")
      .appName("SSReadCsvData")
      .config("spark.sql.shuffle.partitions", 1)
      .getOrCreate()

    import  spark.implicits._

    spark.sparkContext.setLogLevel("Error")

    //2.åˆ›å»ºCSVæ•°æ®schema
    val userSchema: StructType = new StructType().add("id", "integer")
      .add("name", "string")
      .add("gender", "string")
      .add("age", "integer")


    val result: DataFrame = spark.readStream
      .option("sep", ",")
      .schema(userSchema)
      .csv("./data/")

    val query: StreamingQuery = result.writeStream
      .format("console")
      .start()

    query.awaitTermination()

  }

}
</code></pre> 
<p>ç»“æœï¼š</p> 
<p><img alt="" height="725" src="https://images2.imgbox.com/bd/77/zu2LrK2p_o.png" width="1200"></p> 
<p>Javaä»£ç å¦‚ä¸‹</p> 
<pre><code class="language-Scala">package com.lanson.structuredStreaming.source;

import java.util.concurrent.TimeoutException;
import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.SparkSession;
import org.apache.spark.sql.streaming.StreamingQueryException;
import org.apache.spark.sql.types.StructType;

/**
 * Structured Streaming è¯»å–CSVæ•°æ®
 */

public class SSReadCsvData01 {
    public static void main(String[] args) throws TimeoutException, StreamingQueryException {
        //1.åˆ›å»ºå¯¹è±¡
        SparkSession spark = SparkSession.builder().master("local")
                .appName("SSReadCsvData")
                .config("spark.sql.shuffle.partitions", 1)
                .getOrCreate();

        spark.sparkContext().setLogLevel("Error");

        StructType userSchema = new StructType()
                .add("id", "integer")
                .add("name", "string")
                .add("gender", "string")
                .add("age", "integer");
        Dataset&lt;Row&gt; result = spark.readStream()
                .option("sep", ",")
                .schema(userSchema)
                .csv("./data/");

        result.writeStream()
                .format("console")
                .start()
                .awaitTermination();

    }
}
</code></pre> 
<p>Â ç»“æœï¼š</p> 
<p><img alt="" height="732" src="https://images2.imgbox.com/ce/e7/XFRaD9ml_o.png" width="1200"></p> 
<p>ä»¥ä¸Šä»£ç è¿è¡Œä¹‹åå‘å¯¹åº”ç›‘æ§çš„ç›®å½•ä¸‹åŸå­æ€§å†™å…¥å«æœ‰æ•°æ®çš„csvæ–‡ä»¶ï¼Œåœ¨æ§åˆ¶å°å¯ä»¥çœ‹åˆ°å®æ—¶ç›‘æ§å†…å®¹ã€‚æ–‡ä»¶å†…å®¹å¦‚ä¸‹ï¼š</p> 
<pre><code class="language-Scala">1,zhangsan,ä¸€ç­,100
2,lisi,äºŒç­,200
3,wangwu,ä¸€ç­,300
4,maliu,äºŒç­,100
5,tianqi,ä¸‰ç­,100
6,gaoba,ä¸‰ç­,50
7,zs2,å››ç­,50</code></pre> 
<p></p> 
<h4 id="3%E3%80%81%E8%AF%BB%E5%8F%96json%E6%96%87%E4%BB%B6"><strong>3ã€è¯»å–jsonæ–‡ä»¶</strong></h4> 
<p style="margin-left:.0001pt;text-align:justify;">Scalaä»£ç å¦‚ä¸‹ï¼š</p> 
<pre><code class="language-Scala">package com.lanson.structuredStreaming.source

import org.apache.spark.sql.{DataFrame, SparkSession}
import org.apache.spark.sql.streaming.StreamingQuery
import org.apache.spark.sql.types.StructType

/**
  *  Structured Streaming ç›‘æ§Jsonæ ¼å¼æ•°æ®
  */
object SSReadJsonData {
  def main(args: Array[String]): Unit = {
    //1.åˆ›å»ºå¯¹è±¡
    val spark: SparkSession = SparkSession.builder().master("local")
      .appName("SSReadCsvData")
      .config("spark.sql.shuffle.partitions", 1)
      .getOrCreate()

    import  spark.implicits._

    spark.sparkContext.setLogLevel("Error")

    //2.åˆ›å»º json æ•°æ®schema
    val userSchema: StructType = new StructType().add("id", "integer")
      .add("name", "string")
      .add("age", "integer")



    val result: DataFrame = spark.readStream
      .schema(userSchema)
      .json("./data/")

    val query: StreamingQuery = result.writeStream
      .format("console")
      .start()

    query.awaitTermination()

  }

}
</code></pre> 
<p>ç»“æœï¼š</p> 
<p><img alt="" height="394" src="https://images2.imgbox.com/fc/7a/CqJGVE0Q_o.png" width="1200"></p> 
<p></p> 
<p style="margin-left:.0001pt;text-align:justify;">Javaä»£ç å¦‚ä¸‹</p> 
<pre><code class="language-java">package com.lanson.structuredStreaming.source;


import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.SparkSession;
import org.apache.spark.sql.streaming.StreamingQuery;
import org.apache.spark.sql.streaming.StreamingQueryException;
import org.apache.spark.sql.types.StructType;
import java.util.concurrent.TimeoutException;

/**
 * Structured Streamingå®æ—¶ç›‘æ§ç›®å½•ä¸­jsonæ–‡ä»¶ä½œä¸ºæ•°æ®æµ
 */
public class SSReadJsonData01 {
    public static void main(String[] args) throws TimeoutException, StreamingQueryException {
        //1.åˆ›å»ºå¯¹è±¡
        SparkSession spark = SparkSession.builder().appName("File Source test")
            .master("local")
            .getOrCreate();

        //2.è®¾ç½®æ—¥å¿—
        spark.sparkContext().setLogLevel("Error");

        //3.è®¾ç½®Schema
        StructType userSchema = new StructType().add("id", "integer")
            .add("name", "string")
            .add("age", "integer");

        //4.æŒ‡å®šç›‘æ§ç›®å½•è¯»å–æ•°æ®jsonæ•°æ®
        Dataset&lt;Row&gt; ds = spark.readStream()
            .option("sep", ",")
            .schema(userSchema)
            .json("./data/");

        //5.æ‰“å°æ•°æ®åˆ°æ§åˆ¶å°
        StreamingQuery query =ds.writeStream()
            .format("console")
            .start();

        query.awaitTermination();

    }
}
</code></pre> 
<p>ç»“æœï¼š</p> 
<p><img alt="" height="357" src="https://images2.imgbox.com/75/e1/5O06egy7_o.png" width="1061"></p> 
<p>ä»¥ä¸Šä»£ç å¯åŠ¨ä¹‹åï¼Œå‘ç›‘æ§çš„ç›®å½•â€œ./dataâ€ä¸‹åŸå­å†™å…¥å«æœ‰ä»¥ä¸‹å†…å®¹çš„jsonæ–‡ä»¶ï¼Œåœ¨æ§åˆ¶å°å¯ä»¥çœ‹åˆ°å®æ—¶ç›‘æ§å†…å®¹ã€‚jsonæ–‡ä»¶å†…å®¹å¦‚ä¸‹ï¼š</p> 
<pre><code class="language-java">{"id":1,"name":"zs","age":18}
{"id":2,"name":"ls","age":19}
{"id":3,"name":"ww","age":20}
{"id":4,"name":"ml","age":21}
</code></pre> 
<p style="margin-left:.0001pt;text-align:justify;"><span style="color:#0d0016;"><strong>æ³¨æ„ï¼š</strong>å®æ—¶ç›‘æ§jsonæ ¼å¼æ•°æ®æ—¶ï¼Œåˆ›å»ºçš„Schema ä¸­çš„å­—æ®µéœ€è¦ä¸Jsonä¸­çš„å±æ€§ä¿æŒä¸€è‡´ï¼Œå¦åˆ™åœ¨æ˜ å°„æˆè¡¨æ—¶ï¼ŒSchemaä¸­å«æœ‰ä½†åœ¨Jsonä¸­æ²¡æœ‰çš„å±æ€§çš„å­—æ®µå¯¹åº”çš„æ•°æ®ä¼šä¸ºnullã€‚</span></p> 
<p></p> 
<h3 id="%E4%BA%8C%E3%80%81Socket%20Source%C2%A0"><strong>äºŒã€Socket SourceÂ </strong></h3> 
<p style="margin-left:.0001pt;text-align:justify;">è¯»å–Socketæ–¹å¼éœ€è¦æŒ‡å®šå¯¹åº”çš„hostå’Œportï¼Œè¯»å–Socketæ•°æ®æºå¤šç”¨äºæµ‹è¯•åœºæ™¯ï¼Œè¿™é‡Œä¸å†æ¼”ç¤ºã€‚</p> 
<p style="margin-left:.0001pt;text-align:justify;"><strong>å¯ä»¥å‚è€ƒæ¡ˆä¾‹ï¼š</strong></p> 
<p style="margin-left:.0001pt;text-align:justify;"><a href="https://blog.csdn.net/xiaoweite1/article/details/140649090?spm=1001.2014.3001.5501" title="Sparkå®æ—¶ï¼ˆä¸‰ï¼‰ï¼šStructured Streamingå…¥é—¨æ¡ˆä¾‹-CSDNåšå®¢">Sparkå®æ—¶ï¼ˆä¸‰ï¼‰ï¼šStructured Streamingå…¥é—¨æ¡ˆä¾‹-CSDNåšå®¢</a></p> 
<p></p> 
<h3 id="%E4%B8%89%E3%80%81Rate%20Source"><strong>ä¸‰ã€Rate Source</strong></h3> 
<p style="margin-left:.0001pt;text-align:justify;">Rate Sourceæ˜¯ä»¥æ¯ç§’æŒ‡å®šçš„è¡Œæ•°ç”Ÿæˆæ•°æ®ï¼Œæ¯ä¸ªè¾“å‡ºè¡ŒåŒ…å«ä¸€ä¸ªtimestampå’Œvalueï¼Œå…¶ä¸­timestampæ˜¯ä¸€ä¸ªTimestampå«æœ‰ä¿¡æ¯åˆ†é…çš„æ—¶é—´ç±»å‹ï¼Œvalueæ˜¯ä»0å¼€å§‹çš„Longç±»å‹çš„æ•°æ®ï¼ŒRate Sourceå¼å¤šç”¨äºæµ‹è¯•ã€‚</p> 
<p style="margin-left:.0001pt;text-align:justify;">scalaä»£ç å¦‚ä¸‹ï¼š</p> 
<pre><code class="language-Scala">package com.lanson.structuredStreaming.source

import org.apache.spark.sql.{DataFrame, SparkSession}

/**
  * SSRateSource
  */
object SSRateSource {
  def main(args: Array[String]): Unit = {
    //1.åˆ›å»ºå¯¹è±¡
    val spark: SparkSession = SparkSession.builder().master("local")
      .appName("rate test")
//      .config("spark.sql.shuffle.partitions", 1)
      .getOrCreate()

    val result: DataFrame = spark.readStream
      .format("rate")
      // é…ç½®æ¯ç§’ç”Ÿæˆå¤šå°‘è¡Œæ•°æ®ï¼Œé»˜è®¤1è¡Œ
      .option("rowsPerSecond", "10")
      .option("numPartitions", 5)
      .load()
    result.writeStream
      .format("console")
      .option("numRows","100")
      .option("truncate","false")
      .start()
      .awaitTermination()

  }

}
</code></pre> 
<p>ç»“æœï¼š</p> 
<p><img alt="" height="621" src="https://images2.imgbox.com/4c/b2/v1ZHMr5l_o.png" width="1200"></p> 
<p>Javaä»£ç å¦‚ä¸‹ï¼š</p> 
<pre><code class="language-java">package com.lanson.structuredStreaming.source;

import java.util.concurrent.TimeoutException;
import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.SparkSession;
import org.apache.spark.sql.streaming.StreamingQueryException;

public class ssratesource01 {
    public static void main(String[] args) throws TimeoutException, StreamingQueryException {
        //1.åˆ›å»ºå¯¹è±¡
       SparkSession spark = SparkSession.builder().master("local")
                .appName("rate test")
                .getOrCreate();
       spark.sparkContext().setLogLevel("Error");

        Dataset&lt;Row&gt; result = spark.readStream()
                .format("rate")
                // é…ç½®æ¯ç§’ç”Ÿæˆå¤šå°‘è¡Œæ•°æ®ï¼Œé»˜è®¤1è¡Œ
                .option("rowsPerSecond", "10")
                .option("numPartitions", 5)
                .load();

        result.writeStream()
                .format("console")
                .option("numRows","100")
                .option("truncate","false")
                .start()
                .awaitTermination();
    }
}
</code></pre> 
<p>ç»“æœï¼šÂ </p> 
<p><img alt="" height="485" src="https://images2.imgbox.com/6a/be/WOmSpbJ9_o.png" width="1200"></p> 
<p><img alt="" height="515" src="https://images2.imgbox.com/32/09/bP1Dx3rr_o.png" width="655">Â </p> 
<hr> 
<ul><li>ğŸ“¢åšå®¢ä¸»é¡µï¼š<a href="https://lansonli.blog.csdn.net/" rel="nofollow" title="https://lansonli.blog.csdn.net">https://lansonli.blog.csdn.net</a></li><li>ğŸ“¢æ¬¢è¿ç‚¹èµ ğŸ‘ æ”¶è— â­ç•™è¨€ ğŸ“ å¦‚æœ‰é”™è¯¯æ•¬è¯·æŒ‡æ­£ï¼</li><li>ğŸ“¢æœ¬æ–‡ç”± Lansonli åŸåˆ›ï¼Œé¦–å‘äº CSDNåšå®¢ğŸ™‰</li><li>ğŸ“¢åœä¸‹ä¼‘æ¯çš„æ—¶å€™ä¸è¦å¿˜äº†åˆ«äººè¿˜åœ¨å¥”è·‘ï¼Œå¸Œæœ›å¤§å®¶æŠ“ç´§æ—¶é—´å­¦ä¹ ï¼Œå…¨åŠ›å¥”èµ´æ›´ç¾å¥½çš„ç”Ÿæ´»âœ¨</li></ul>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/375243dc869d0e04bf9f7af653394298/" rel="prev">
			<span class="pager__subtitle">Â«&thinsp;Previous</span>
			<p class="pager__title">ã€äººå·¥æ™ºèƒ½ã€‘AIç»˜ç”»ï¼šç§‘æŠ€ä¸è‰ºæœ¯äº¤æ±‡çš„æ–°æ—¶ä»£</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/34e220bb1566faa62f8f551a49759748/" rel="next">
			<span class="pager__subtitle">Next&thinsp;Â»</span>
			<p class="pager__title">KubeSphereä»‹ç»åŠä¸€é”®å®‰è£…k8s</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 ç¼–ç¨‹å¤§å’–.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>