<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>超级详细Spring AI运用Ollama大模型 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/5504aad56f2365011b0816045bf47bd5/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="超级详细Spring AI运用Ollama大模型">
  <meta property="og:description" content="大模型工具Ollama 官网:https://ollama.com/
Ollama是一个用于部署和运行各种开源大模型的工具;
它能够帮助用户快速在本地运行各种大模型，极大地简化了大模型在本地运行的过程。用户通过执行几条命令就能在本地运行开源大模型，如Lama 2等;
综上，Ollama是一个大模型部署运行工具，在该工具里面可以部署运行各种大模型，方便开发者在本地搭建一套大模型运行环境;
下载:https://ollama.com/download
下载Ollama
说明:Ollama的运行会受到所使用模型大小的影响;
1、例如，运行一个7B(70亿参数)的模型至少需要8GB的可用内存(RAM)，而运行一个13B(130亿参数)的模型需要16GB的内存，33B(330亿参数)的型需要32GB的内存;
2、需要考虑有足够的磁盘空间，大模型的文件大小可能比较大，建议至少为Ollama和其模型预留50GB的磁盘空间3、性能较高的CPU可以提供更好的运算速度和效率，多核处理器能够更好地处理并行任务，选择具有足够核心数的CPU:
4、显卡(GPU):Ollama支持纯CPU运行，但如果电脑配备了NVIDIA GPU，可以利用GPU进行加速，提高模型的运行速度和性能;
命令行使用ollama 打开终端，输入 ollama -h,查看到所有的命令
service ollama start启动allama
输入ollama -v查看当前版本，能输出版本则安装成功
运行模型单行对话 拉取并运行llama2模型
ollama run llama2
直接输入该命令会检查目录下是否有该模型，没有会自动下载，下载好后自动运行该模型
其他模型见library (ollama.com)
# 查看 Ollama 版本 ollama -v # 查看已安装的模型 ollama list # 删除指定模型 ollama rm [modelname] # 模型存储路径 # C:\Users\&lt;username&gt;\.ollama\models ollama run qwen:0.5b
默认Ollama api会监听11434端口，可以使用命令进行查看netstat -ano |findstr 114341
//加依赖 &lt;dependency&gt; &lt;groupld&gt;org.springframework,ai&lt;/groupld&gt; &lt;artifactld&gt;spring-ai-ollama-spring-boot-starter&lt;/artifactld&gt; &lt;/dependency&gt; //写代码 注入OllamaChatClient @Resource private OllamaChatClient ollamaChatClient, //调用call方法 ollamaChatClient.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-06-05T17:52:23+08:00">
    <meta property="article:modified_time" content="2024-06-05T17:52:23+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">超级详细Spring AI运用Ollama大模型</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2>大模型工具Ollama</h2> 
<p>官网:https://ollama.com/<br> Ollama是一个用于部署和运行各种开源大模型的工具;<br> 它能够帮助用户快速在本地运行各种大模型，极大地简化了大模型在本地运行的过程。用户通过执行几条命令就能在本地运行开源大模型，如Lama 2等;<br> 综上，Ollama是一个大模型部署运行工具，在该工具里面可以部署运行各种大模型，方便开发者在本地搭建一套大模型运行环境;</p> 
<p>下载:https://ollama.com/download</p> 
<p><a href="https://ollama.com/download" rel="nofollow" title="下载Ollama">下载Ollama</a><br> 说明:Ollama的运行会受到所使用模型大小的影响;<br> 1、例如，运行一个7B(70亿参数)的模型至少需要8GB的可用内存(RAM)，而运行一个13B(130亿参数)的模型需要16GB的内存，33B(330亿参数)的型需要32GB的内存;<br> 2、需要考虑有足够的磁盘空间，大模型的文件大小可能比较大，建议至少为Ollama和其模型预留50GB的磁盘空间3、性能较高的CPU可以提供更好的运算速度和效率，多核处理器能够更好地处理并行任务，选择具有足够核心数的CPU:<br> 4、显卡(GPU):Ollama支持纯CPU运行，但如果电脑配备了NVIDIA GPU，可以利用GPU进行加速，提高模型的运行速度和性能;</p> 
<p><img alt="" height="1090" src="https://images2.imgbox.com/62/32/sxRAPrpE_o.png" width="1093"></p> 
<p>命令行使用ollama 打开终端，输入 <strong>ollama -h,查看到所有的命令</strong></p> 
<p>service ollama start启动allama</p> 
<p><img alt="" height="806" src="https://images2.imgbox.com/12/bd/B6T7SvvY_o.png" width="983"></p> 
<p>输入<code>ollama -v</code>查看当前版本，能输出版本则安装成功</p> 
<h2 id="运行模型单行对话">运行模型单行对话</h2> 
<p>拉取并运行llama2模型<br><code>ollama run llama2</code><br> 直接输入该命令会检查目录下是否有该模型，没有会自动下载，下载好后自动运行该模型<br> 其他模型见<a href="https://ollama.com/library" rel="nofollow" title="library (ollama.com)">library (ollama.com)</a></p> 
<pre><code class="language-Go"># 查看 Ollama 版本
ollama -v

# 查看已安装的模型
ollama list

# 删除指定模型
ollama rm [modelname]

# 模型存储路径
# C:\Users\&lt;username&gt;\.ollama\models</code></pre> 
<p>ollama run qwen:0.5b</p> 
<p><img alt="" height="905" src="https://images2.imgbox.com/fe/61/RuSpGyLG_o.png" width="1200"></p> 
<p><img alt="" height="570" src="https://images2.imgbox.com/dc/5f/KAximXUH_o.png" width="1108"></p> 
<p><img alt="" height="122" src="https://images2.imgbox.com/3d/bc/393N7tQb_o.png" width="535"></p> 
<p>默认Ollama api会监听11434端口，可以使用命令进行查看netstat -ano |findstr 114341</p> 
<p><img alt="" height="369" src="https://images2.imgbox.com/e1/ba/NSlzBFaw_o.png" width="541"></p> 
<p></p> 
<pre><code class="language-java">//加依赖
&lt;dependency&gt;
&lt;groupld&gt;org.springframework,ai&lt;/groupld&gt;
&lt;artifactld&gt;spring-ai-ollama-spring-boot-starter&lt;/artifactld&gt;
&lt;/dependency&gt;
//写代码
注入OllamaChatClient
@Resource
private OllamaChatClient ollamaChatClient,
//调用call方法
ollamaChatClient.call(msg);</code></pre> 
<h2>完整pom文件</h2> 
<pre><code class="language-XML">&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;
    &lt;parent&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;
        &lt;version&gt;3.3.0&lt;/version&gt;
        &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;
    &lt;/parent&gt;
    &lt;groupId&gt;com.zzq&lt;/groupId&gt;
    &lt;artifactId&gt;spring-ai-ollama&lt;/artifactId&gt;
    &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;
    &lt;name&gt;spring-ai-ollama&lt;/name&gt;
    &lt;description&gt;spring-ai-ollama&lt;/description&gt;
    &lt;properties&gt;
        &lt;java.version&gt;17&lt;/java.version&gt;
        &lt;!--        快照版本--&gt;
        &lt;spring-ai.version&gt;1.0.0-SNAPSHOT&lt;/spring-ai.version&gt;
    &lt;/properties&gt;
    &lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.ai&lt;/groupId&gt;
            &lt;artifactId&gt;spring-ai-ollama-spring-boot-starter&lt;/artifactId&gt;
        &lt;/dependency&gt;

        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt;
            &lt;scope&gt;runtime&lt;/scope&gt;
            &lt;optional&gt;true&lt;/optional&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;
            &lt;artifactId&gt;lombok&lt;/artifactId&gt;
            &lt;optional&gt;true&lt;/optional&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;
            &lt;scope&gt;test&lt;/scope&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
    &lt;dependencyManagement&gt;
        &lt;dependencies&gt;
            &lt;dependency&gt;
                &lt;groupId&gt;org.springframework.ai&lt;/groupId&gt;
                &lt;artifactId&gt;spring-ai-bom&lt;/artifactId&gt;
                &lt;version&gt;${spring-ai.version}&lt;/version&gt;
                &lt;type&gt;pom&lt;/type&gt;
                &lt;scope&gt;import&lt;/scope&gt;
            &lt;/dependency&gt;
        &lt;/dependencies&gt;
    &lt;/dependencyManagement&gt;

    &lt;build&gt;
        &lt;plugins&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;
                &lt;configuration&gt;
                    &lt;excludes&gt;
                        &lt;exclude&gt;
                            &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;
                            &lt;artifactId&gt;lombok&lt;/artifactId&gt;
                        &lt;/exclude&gt;
                    &lt;/excludes&gt;
                &lt;/configuration&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;
    &lt;!--    快照版本--&gt;
    &lt;repositories&gt;
        &lt;repository&gt;
            &lt;id&gt;spring-snapshot&lt;/id&gt;
            &lt;name&gt;Spring Snapshots&lt;/name&gt;
            &lt;url&gt;https://repo.spring.io/snapshot&lt;/url&gt;
            &lt;releases&gt;
                &lt;enabled&gt;false&lt;/enabled&gt;
            &lt;/releases&gt;
        &lt;/repository&gt;
    &lt;/repositories&gt;
&lt;/project&gt;
</code></pre> 
<h2>application文件内容</h2> 
<pre><code class="language-XML">spring:
  application:
    name:spring-ai-05-ollama
  ai:
    ollama:
      base-url: http://localhost:11434
      chat:
        options:
          model: qwen:0.5b

</code></pre> 
<h2>controller</h2> 
<pre><code class="language-java">package com.zzq.controller;

import jakarta.annotation.Resource;
import org.springframework.ai.ollama.OllamaChatModel;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RequestParam;
import org.springframework.web.bind.annotation.RestController;

@RestController
public class OllamaController {
   @Resource
    private OllamaChatModel ollamaChatModel;
   @RequestMapping(value = "/ai/ollama")
    public Object ollama(@RequestParam(value = "msg")String msg){
       String called=ollamaChatModel.call(msg);
       System.out.println(called);
       return called;
   }
}
</code></pre> 
<p><img alt="" height="184" src="https://images2.imgbox.com/41/3d/ApgUrFY6_o.png" width="1039"></p> 
<pre><code class="language-java">package com.zzq.controller;

import jakarta.annotation.Resource;
import org.springframework.ai.chat.model.ChatResponse;
import org.springframework.ai.chat.prompt.Prompt;
import org.springframework.ai.ollama.OllamaChatModel;
import org.springframework.ai.ollama.api.OllamaOptions;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RequestParam;
import org.springframework.web.bind.annotation.RestController;

@RestController
public class OllamaController {
   @Resource
    private OllamaChatModel ollamaChatModel;
   @RequestMapping(value = "/ai/ollama")
    public Object ollama(@RequestParam(value = "msg")String msg){
       String called=ollamaChatModel.call(msg);
       System.out.println(called);
       return called;
   }
    @RequestMapping(value = "/ai/ollama2")
    public Object ollama2(@RequestParam(value = "msg")String msg){
        ChatResponse chatResponse=ollamaChatModel.call(new Prompt(msg, OllamaOptions.create()
                .withModel("qwen:0.5b")//使用哪个大模型
                .withTemperature(0.4F)));//温度，温度值越高，准确率下降，温度值越低，准确率上升
        System.out.println(chatResponse.getResult().getOutput().getContent());
        return chatResponse.getResult().getOutput().getContent();
    }
}
</code></pre> 
<p></p> 
<p></p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/b2b806438fbabc532eff040a0266d900/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【C语言】结构体（及位段）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/b9f51387cb2b4fe8abc29ff346e83e47/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">ClickHouse内幕（1）数据存储与过滤机制</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>