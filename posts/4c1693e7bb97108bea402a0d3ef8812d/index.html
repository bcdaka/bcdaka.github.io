<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【机器学习】Whisper：开源语音转文本（speech-to-text）大模型实战 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/4c1693e7bb97108bea402a0d3ef8812d/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="【机器学习】Whisper：开源语音转文本（speech-to-text）大模型实战">
  <meta property="og:description" content="目录
一、引言
二、Whisper 模型原理
2.1 模型架构
2.2 语音处理
2.3 文本处理
三、Whisper 模型实战
3.1 环境安装
3.2 模型下载
3.3 模型推理
3.4 完整代码
3.5 模型部署
四、总结
一、引言 上一篇对​​​​​​​ChatTTS文本转语音模型原理和实战进行了讲解，第6次拿到了热榜第一🏆。今天，分享其对称功能（语音转文本）模型：Whisper。Whisper由OpenAI研发并开源，参数量最小39M，最大1550M，支持包含中文在内的多种语言。由于其低资源成本、优质的生存效果，被广泛应用于音乐识别、私信聊天、同声传译、人机交互等各种语音转文本场景，且商业化后价格不菲。今天免费分享给大家，不要再去花钱买语音识别服务啦！
二、Whisper 模型原理 2.1 模型架构 Whisper是一个典型的transformer Encoder-Decoder结构，针对语音和文本分别进行多任务（Multitask）处理。
2.2 语音处理 Whisper语音处理：基于680000小时音频数据进行训练，包含英文、其他语言转英文、非英文等多种语言。将音频数据转换成梅尔频谱图，再经过两个卷积层后送入 Transformer 模型。
2.3 文本处理 Whisper文本处理：文本token包含3类：special tokens（标记tokens）、text tokens（文本tokens）、timestamp tokens（时间戳），基于标记tokens控制文本的开始和结束，基于timestamp tokens让语音时间与文本对其。
仅用通俗易懂的语言描述了下Whisper的原理，如果想更深入的了解，请参考OpenAI官方Whisper论文。
三、Whisper 模型实战 3.1 环境安装 本文基于HuggingFace的transfomers库，采用pipeline方式进行极简单的模型实用实战，具体的pipeline以及其他transformers模型使用方式可以参考我之前的文章。
所以，您仅需要安装transformers库。
pip install transformers 当前，语音经常会和视频等其他媒介联系起来，所以我建议您顺带安装多媒体处理工具ffmpeg，没有提供pip库，仅能依靠apt-get安装。
sudo apt-get update &amp;&amp; apt-get install ffmpeg 3.2 模型下载 基于pipeline会自动进行模型下载，当然，如果您的网速不行，请替换HF_ENDPOINT为国内镜像。
os.environ[&#34;HF_ENDPOINT&#34;] = &#34;https://hf-mirror.com&#34; transcriber = pipeline(task=&#34;">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-06-28T18:51:59+08:00">
    <meta property="article:modified_time" content="2024-06-28T18:51:59+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【机器学习】Whisper：开源语音转文本（speech-to-text）大模型实战</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p id="%E2%80%8B%E7%BC%96%E8%BE%91%E2%80%8B%E2%80%8B%E2%80%8B%E2%80%8B%E2%80%8B%E2%80%8B%E2%80%8B" style="text-align:center;"><a id="AI_0"></a><img alt="" src="https://images2.imgbox.com/49/c0/eFVr1uvd_o.png"></p> 
<p id="main-toc"><strong>目录</strong></p> 
<p id="%E4%B8%80%E3%80%81%E5%BC%95%E8%A8%80-toc" style="margin-left:0px;"><a href="#%E4%B8%80%E3%80%81%E5%BC%95%E8%A8%80" rel="nofollow">一、引言</a></p> 
<p id="%E4%BA%8C%E3%80%81%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B-toc" style="margin-left:0px;"><a href="#%E4%BA%8C%E3%80%81%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B" rel="nofollow">二、Whisper 模型原理</a></p> 
<p id="2.1%20VITS%20%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84-toc" style="margin-left:40px;"><a href="#2.1%20VITS%20%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84" rel="nofollow">2.1 模型架构</a></p> 
<p id="2.2%20VITS%20%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83-toc" style="margin-left:40px;"><a href="#2.2%20VITS%20%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83" rel="nofollow">2.2 语音处理</a></p> 
<p id="2.3%C2%A0VITS%20%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86-toc" style="margin-left:40px;"><a href="#2.3%C2%A0VITS%20%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86" rel="nofollow">2.3 文本处理</a></p> 
<p id="%E4%B8%89%E3%80%81%E8%AE%AD%E7%BB%83%E4%B8%8E%E6%8E%A8%E7%90%86-toc" style="margin-left:0px;"><a href="#%E4%B8%89%E3%80%81%E8%AE%AD%E7%BB%83%E4%B8%8E%E6%8E%A8%E7%90%86" rel="nofollow">三、Whisper 模型实战</a></p> 
<p id="3.1%20ChatTTS%20%E7%AE%80%E4%BB%8B-toc" style="margin-left:40px;"><a href="#3.1%20ChatTTS%20%E7%AE%80%E4%BB%8B" rel="nofollow">3.1 环境安装</a></p> 
<p id="3.2%20ChatTTS%20%E4%BA%AE%E7%82%B9-toc" style="margin-left:40px;"><a href="#3.2%20ChatTTS%20%E4%BA%AE%E7%82%B9" rel="nofollow">3.2 模型下载</a></p> 
<p id="3.3%20ChatTTS%20%E6%95%B0%E6%8D%AE%E9%9B%86%C2%A0-toc" style="margin-left:40px;"><a href="#3.3%20ChatTTS%20%E6%95%B0%E6%8D%AE%E9%9B%86%C2%A0" rel="nofollow">3.3 模型推理</a></p> 
<p id="3.4%C2%A0Whisper%20%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81-toc" style="margin-left:40px;"><a href="#3.4%C2%A0Whisper%20%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81" rel="nofollow">3.4 完整代码</a></p> 
<p id="3.5%C2%A0Whisper%20%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2-toc" style="margin-left:40px;"><a href="#3.5%C2%A0Whisper%20%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2" rel="nofollow">3.5 模型部署</a></p> 
<p id="%E5%9B%9B%E3%80%81%E6%80%BB%E7%BB%93-toc" style="margin-left:0px;"><a href="#%E5%9B%9B%E3%80%81%E6%80%BB%E7%BB%93" rel="nofollow">四、总结</a></p> 
<hr id="hr-toc"> 
<p></p> 
<h2 id="%E4%B8%80%E3%80%81%E5%BC%95%E8%A8%80">一、引言</h2> 
<p>上一篇对<a class="link-info" href="https://blog.csdn.net/weixin_48007632/article/details/139929395?spm=1001.2014.3001.5502" title="​​​​​​​ChatTTS文本转语音模型">​​​​​​​ChatTTS文本转语音模型</a>原理和实战进行了讲解，第6次拿到了热榜第一🏆。今天，分享其对称功能（语音转文本）模型：Whisper。Whisper由OpenAI研发并开源，参数量最小39M，最大1550M，支持包含中文在内的多种语言。由于其低资源成本、优质的生存效果，被广泛应用于音乐识别、私信聊天、同声传译、人机交互等各种语音转文本场景，且商业化后价格不菲。今天免费分享给大家，不要再去花钱买语音识别服务啦！</p> 
<h2 id="%E4%BA%8C%E3%80%81%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B">二、Whisper 模型原理</h2> 
<h3 id="2.1%20VITS%20%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84">2.1 模型架构</h3> 
<p>Whisper是一个典型的transformer Encoder-Decoder结构，针对语音和文本分别进行多任务（Multitask）处理。</p> 
<p><img alt="" height="1200" src="https://images2.imgbox.com/dc/31/JT9lTOqh_o.png" width="1200"></p> 
<h3 id="2.2%20VITS%20%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83">2.2 语音处理</h3> 
<blockquote> 
 <p><strong>Whisper语音处理</strong>：基于680000小时音频数据进行训练，包含英文、其他语言转英文、非英文等多种语言。将音频数据转换成梅尔频谱图，再经过两个卷积层后送入 Transformer 模型。</p> 
</blockquote> 
<h3 id="2.3%C2%A0VITS%20%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86">2.3 文本处理</h3> 
<blockquote> 
 <p><strong>Whisper文本处理</strong>：文本token包含3类：special tokens（标记tokens）、text tokens（文本tokens）、timestamp tokens（时间戳），基于标记tokens控制文本的开始和结束，基于timestamp tokens让语音时间与文本对其。</p> 
</blockquote> 
<p>仅用通俗易懂的语言描述了下Whisper的原理，如果想更深入的了解，请参考<a class="link-info" href="https://arxiv.org/abs/2212.04356" rel="nofollow" title="OpenAI官方Whisper论文">OpenAI官方Whisper论文</a>。</p> 
<h2 id="%E4%B8%89%E3%80%81%E8%AE%AD%E7%BB%83%E4%B8%8E%E6%8E%A8%E7%90%86">三、Whisper 模型实战</h2> 
<h3 id="3.1%20ChatTTS%20%E7%AE%80%E4%BB%8B">3.1 环境安装</h3> 
<p>本文基于HuggingFace的transfomers库，采用pipeline方式进行极简单的模型实用实战，具体的pipeline以及其他transformers模型使用方式可以参考我之前的<a class="link-info" href="https://blog.csdn.net/weixin_48007632/article/details/139481089" title="文章">文章</a>。</p> 
<p>所以，您仅需要安装transformers库。</p> 
<pre><code class="language-python">pip install transformers</code></pre> 
<p>当前，语音经常会和视频等其他媒介联系起来，所以我建议您顺带安装多媒体处理工具ffmpeg，没有提供pip库，仅能依靠apt-get安装。</p> 
<pre><code class="language-bash">sudo apt-get update &amp;&amp; apt-get install ffmpeg</code></pre> 
<h3 id="3.2%20ChatTTS%20%E4%BA%AE%E7%82%B9">3.2 模型下载</h3> 
<p>基于pipeline会自动进行模型下载，当然，如果您的网速不行，请替换HF_ENDPOINT为国内镜像。</p> 
<pre><code class="language-python">os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"

transcriber = pipeline(task="automatic-speech-recognition", model="openai/whisper-medium")</code></pre> 
<p> 不同尺寸模型参数量、多语言支持情况、需要现存大小以及推理速度如下</p> 
<p><img alt="" height="490" src="https://images2.imgbox.com/a9/ce/trwjdSGx_o.png" width="1200"></p> 
<h3 id="3.3%20ChatTTS%20%E6%95%B0%E6%8D%AE%E9%9B%86%C2%A0">3.3 模型推理</h3> 
<p>推理函数仅需2行，非常简单，基于pipeline实例化1个模型对象，将要转换的音频文件传至模型对象中即可：</p> 
<pre><code class="language-python">def speech2text(speech_file):
    transcriber = pipeline(task="automatic-speech-recognition", model="openai/whisper-medium")
    text_dict = transcriber(speech_file)
    return text_dict</code></pre> 
<h3 id="3.4%C2%A0Whisper%20%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81">3.4 完整代码</h3> 
<p>运行完整代码：</p> 
<pre><code class="language-python">python run_whisper.py -a output_video_enhanced.mp3 </code></pre> 
<p>完整代码如下：</p> 
<pre><code class="language-python">import os
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
os.environ["CUDA_VISIBLE_DEVICES"] = "2"
os.environ["TF_ENABLE_ONEDNN_OPTS"] = "0"

from transformers import pipeline
import subprocess

def speech2text(speech_file):
    transcriber = pipeline(task="automatic-speech-recognition", model="openai/whisper-medium")
    text_dict = transcriber(speech_file)
    return text_dict

import argparse
import json
def main():
    parser = argparse.ArgumentParser(description="语音转文本")
    parser.add_argument("--audio","-a", type=str, help="输出音频文件路径")

    args = parser.parse_args()
    print(args) 

    text_dict = speech2text(args.audio)
    #print("视频内的文本是：\n" +  text_dict["text"])
    print("视频内的文本是：\n"+ json.dumps(text_dict,indent=4))

if __name__=="__main__":
    main()</code></pre> 
<p>这里采用argparse处理命令行参数，将mp3音频文件输入后，经过speech2text语音转文本函数处理，返回对应的文本，结果如下：</p> 
<p><img alt="" src="https://images2.imgbox.com/82/bb/x4OBnybd_o.png"></p> 
<h3 id="3.5%C2%A0Whisper%20%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2">3.5 模型部署</h3> 
<p>如果想将该服务部署成语音识别API服务，可以参考之前的<a class="link-info" href="https://blog.csdn.net/weixin_48007632/article/details/139757328?spm=1001.2014.3001.5502" title="FastAPI相关文章">FastAPI相关文章</a>。</p> 
<h2 id="%E5%9B%9B%E3%80%81%E6%80%BB%E7%BB%93"><strong>四、总结</strong></h2> 
<p>本文是上一篇chatTTS文章的夫妻篇，既然教了大家如何将文本转语音，就一定要教大家如何将语音转成文本，这样技术体系才完整。首先简要概述了Whisper的模型原理，然后基于transformers的pipeline库2行代码实现了Whisper模型推理，希望可以帮助到大家。码字不易，如果喜欢期待您的关注+3连+投票。</p> 
<p></p> 
<p>如果您还有时间，可以看看我的其他文章：</p> 
<p>《AI—工程篇》</p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/138583814?spm=1001.2014.3001.5501" title="AI智能体研发之路-工程篇（一）：Docker助力AI智能体开发提效">AI智能体研发之路-工程篇（一）：Docker助力AI智能体开发提效</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/138543709?spm=1001.2014.3001.5501" title="AI智能体研发之路-工程篇（二）：Dify智能体开发平台一键部署">AI智能体研发之路-工程篇（二）：Dify智能体开发平台一键部署</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/138506272?spm=1001.2014.3001.5501" title="AI智能体研发之路-工程篇（三）：大模型推理服务框架Ollama一键部署">AI智能体研发之路-工程篇（三）：大模型推理服务框架Ollama一键部署</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/138531565?spm=1001.2014.3001.5501" title="AI智能体研发之路-工程篇（四）：大模型推理服务框架Xinference一键部署">AI智能体研发之路-工程篇（四）：大模型推理服务框架Xinference一键部署</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/138673899?spm=1001.2014.3001.5501" title="AI智能体研发之路-工程篇（五）：大模型推理服务框架LocalAI一键部署">AI智能体研发之路-工程篇（五）：大模型推理服务框架LocalAI一键部署</a></p> 
<p>《AI—模型篇》</p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/138819599?spm=1001.2014.3001.5501" title="AI智能体研发之路-模型篇（一）：大模型训练框架LLaMA-Factory在国内网络环境下的安装、部署及使用">AI智能体研发之路-模型篇（一）：大模型训练框架LLaMA-Factory在国内网络环境下的安装、部署及使用</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139131558?spm=1001.2014.3001.5501" title="AI智能体研发之路-模型篇（二）：DeepSeek-V2-Chat 训练与推理实战">AI智能体研发之路-模型篇（二）：DeepSeek-V2-Chat 训练与推理实战</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139219617?spm=1001.2014.3001.5502" title="AI智能体研发之路-模型篇（三）：中文大模型开、闭源之争">AI智能体研发之路-模型篇（三）：中文大模型开、闭源之争</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139237430?spm=1001.2014.3001.5502" title="AI智能体研发之路-模型篇（四）：一文入门pytorch开发">AI智能体研发之路-模型篇（四）：一文入门pytorch开发</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139249095?spm=1001.2014.3001.5502" title="AI智能体研发之路-模型篇（五）：pytorch vs tensorflow框架DNN网络结构源码级对比">AI智能体研发之路-模型篇（五）：pytorch vs tensorflow框架DNN网络结构源码级对比</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139263131?spm=1001.2014.3001.5502" title="AI智能体研发之路-模型篇（六）：【机器学习】基于tensorflow实现你的第一个DNN网络">AI智能体研发之路-模型篇（六）：【机器学习】基于tensorflow实现你的第一个DNN网络</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139307081?spm=1001.2014.3001.5502" title="AI智能体研发之路-模型篇（七）：【机器学习】基于YOLOv10实现你的第一个视觉AI大模型">AI智能体研发之路-模型篇（七）：【机器学习】基于YOLOv10实现你的第一个视觉AI大模型</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139422184?spm=1001.2014.3001.5501" title="AI智能体研发之路-模型篇（八）：【机器学习】Qwen1.5-14B-Chat大模型训练与推理实战">AI智能体研发之路-模型篇（八）：【机器学习】Qwen1.5-14B-Chat大模型训练与推理实战</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139497336?spm=1001.2014.3001.5502" title="AI智能体研发之路-模型篇（九）：【机器学习】GLM4-9B-Chat大模型/GLM-4V-9B多模态大模型概述、原理及推理实战">AI智能体研发之路-模型篇（九）：【机器学习】GLM4-9B-Chat大模型/GLM-4V-9B多模态大模型概述、原理及推理实战</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139564359?spm=1001.2014.3001.5501" title="AI智能体研发之路-模型篇（十）：【机器学习】Qwen2大模型原理、训练及推理部署实战">AI智能体研发之路-模型篇（十）：【机器学习】Qwen2大模型原理、训练及推理部署实战</a></p> 
<p>《AI—Transformers应用》</p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139478765?spm=1001.2014.3001.5502" title="【AI大模型】Transformers大模型库（一）：Tokenizer">【AI大模型】Transformers大模型库（一）：Tokenizer</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139481089?spm=1001.2014.3001.5502" title="【AI大模型】Transformers大模型库（二）：AutoModelForCausalLM">【AI大模型】Transformers大模型库（二）：AutoModelForCausalLM</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139481581?spm=1001.2014.3001.5502" title="【AI大模型】Transformers大模型库（三）：特殊标记（special tokens）">【AI大模型】Transformers大模型库（三）：特殊标记（special tokens）</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139483010?spm=1001.2014.3001.5502" title="【AI大模型】Transformers大模型库（四）：AutoTokenizer">【AI大模型】Transformers大模型库（四）：AutoTokenizer</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632?spm=1011.2415.3001.5343" title="【AI大模型】Transformers大模型库（五）：AutoModel、Model Head及查看模型结构">【AI大模型】Transformers大模型库（五）：AutoModel、Model Head及查看模型结构</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139584579?spm=1001.2014.3001.5501" title="【AI大模型】Transformers大模型库（六）：torch.cuda.OutOfMemoryError: CUDA out of memory解决">【AI大模型】Transformers大模型库（六）：torch.cuda.OutOfMemoryError: CUDA out of memory解决</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139607194?spm=1001.2014.3001.5501" title="【AI大模型】Transformers大模型库（七）：单机多卡推理之device_map">【AI大模型】Transformers大模型库（七）：单机多卡推理之device_map</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139611462?spm=1001.2014.3001.5501" title="【AI大模型】Transformers大模型库（八）：大模型微调之LoraConfig">【AI大模型】Transformers大模型库（八）：大模型微调之LoraConfig</a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/43ee0d001e4354c66c94fd6e2a9ce6c1/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">K8S中的某个容器突然出现内存和CPU占用过高的情况解决办法</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/3465e10b6c2bf1ad06dda6aeabde4972/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">北京站圆满结束！MongoDB Developer Day上海站，周六见！</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>