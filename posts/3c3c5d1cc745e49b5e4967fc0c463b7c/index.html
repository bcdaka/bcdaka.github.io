<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Hive环境配置以及安装步骤 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/3c3c5d1cc745e49b5e4967fc0c463b7c/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="Hive环境配置以及安装步骤">
  <meta property="og:description" content="Hive环境配置及安装步骤可以归纳如下：
1. 安装前提 确保Hadoop全分布式集群已经搭建成功，并可以在各个节点上正常启动和关闭。 2. 卸载MariaDB（可选） 如果系统中安装了MariaDB，且计划使用MySQL作为Hive的元数据存储，则需要卸载MariaDB。 设置防火墙服务不启动（使用systemctl disable firewalld）。查看并卸载Linux自带的MariaDB数据库。 3. 安装MySQL 安装Hive通常需要一个关系型数据库来存储元数据，如MySQL。 上传MySQL安装包。解压安装包。安装依赖文件，注意安装顺序。 4. Hive安装 下载并解压Hive安装包 从Hive官网下载Hive安装包（如apache-hive-x.x.x-bin.tar.gz）。使用tar -zxvf命令解压到指定目录（如/usr/local）。配置环境变量 使用vim编辑器编辑/etc/profile或用户级别的.bashrc文件。添加Hive相关的环境变量，如HIVE_HOME、PATH等。使用source命令使配置立即生效。修改Hive组件配置文件 进入Hive安装目录下的conf文件夹。创建或修改配置文件，如hive-env.sh和hive-site.xml。 在hive-env.sh中设置Java、Hadoop、Hive等环境变量。在hive-site.xml中配置Hive的各种参数，如元数据存储位置、数据库连接信息等。创建临时文件夹 在Hive安装目录中创建临时文件夹tmp。初始化Hive元数据 将MySQL驱动移动到$HIVE_HOME/lib目录下。初始化Hive元数据，使用schematool工具将Hive的数据重新写入MySQL数据库中。启动Hive 启动Hive服务，并进行相关操作，如查看数据库、创建表、插入数据等。 5. 注意事项 确保Hadoop集群运行正常，且Hive配置中指定的Hadoop路径正确。根据实际需求选择合适的Hive版本和配置参数。备份重要数据，以防配置过程中出现问题导致数据丢失。 以上步骤仅供参考，具体安装和配置过程可能因环境和需求的不同而有所差异。在实际操作中，建议参考Hive官方文档和相关教程进行安装和配置。
若没安装hadoop集群则可采取以下步骤：
安装Hadoop集群的步骤可以大致分为以下几个部分：
一、安装前准备 选择合适的Hadoop版本：例如Hadoop 3.1.3。下载必要的软件包： Hadoop安装包（如hadoop-3.1.3.tar.gz）。JDK安装包（Hadoop运行需要Java环境）。虚拟机软件（如VMware Workstation 16 Pro）。CentOS或Ubuntu等Linux系统的镜像文件。 二、虚拟机安装与配置 安装虚拟机软件：确保使用的虚拟机软件版本与操作系统兼容（如VMware Workstation 16 Pro）。创建虚拟机： 使用虚拟机软件创建新的虚拟机。设置虚拟机名称、存储位置、磁盘大小等参数。安装Linux系统（如CentOS 7或Ubuntu）。配置网络： 为虚拟机分配静态IP地址，并确保各节点之间的网络连通性。配置hosts文件，实现主机名与IP地址的映射。关闭防火墙和SELinux：在Linux系统中关闭防火墙和SELinux，以确保Hadoop集群能够正常运行。 三、JDK安装与配置 上传JDK安装包：将JDK安装包上传到Linux系统的指定目录。解压并安装JDK：使用tar命令解压JDK安装包，并配置环境变量。 四、Hadoop安装与配置 上传Hadoop安装包：将Hadoop安装包上传到Linux系统的指定目录。解压Hadoop：使用tar命令解压Hadoop安装包。配置环境变量：编辑/etc/profile文件，添加Hadoop相关的环境变量。修改Hadoop配置文件： 修改hadoop-env.sh文件，设置Java环境变量。修改core-site.xml文件，配置Hadoop核心参数，如文件系统名称、NameNode地址等。修改hdfs-site.xml文件，配置HDFS相关参数，如数据块大小、副本数量等。修改mapred-site.xml文件（如果该文件不存在，可以从mapred-site.xml.template复制并改名），配置MapReduce相关参数。修改yarn-site.xml文件，配置YARN相关参数。格式化NameNode：在Hadoop主节点上运行hdfs namenode -format命令，格式化NameNode。 五、Hadoop集群配置 克隆虚拟机：使用虚拟机软件的克隆功能，创建多个具有相同配置的虚拟机节点。修改克隆节点的主机名和网络配置：确保每个节点具有唯一的主机名和网络配置。配置SSH免密登录：在Hadoop集群中配置SSH免密登录，以便于节点之间的通信。 六、启动Hadoop集群 启动HDFS：在NameNode节点上启动HDFS服务。启动YARN：在ResourceManager节点上启动YARN服务。验证Hadoop集群状态：通过Hadoop提供的命令行工具或Web界面，验证Hadoop集群的状态和运行情况。 以上步骤是一个基本的Hadoop集群安装和配置流程，具体细节可能因环境差异和版本不同而有所调整。在实际操作中，建议参考Hadoop官方文档和相关教程进行安装和配置。">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-05-30T17:06:28+08:00">
    <meta property="article:modified_time" content="2024-05-30T17:06:28+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Hive环境配置以及安装步骤</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>Hive环境配置及安装步骤可以归纳如下：</p> 
<h4>1. 安装前提</h4> 
<ul><li>确保Hadoop全分布式集群已经搭建成功，并可以在各个节点上正常启动和关闭。</li></ul> 
<h4>2. 卸载MariaDB（可选）</h4> 
<ul><li>如果系统中安装了MariaDB，且计划使用MySQL作为Hive的元数据存储，则需要卸载MariaDB。 
  <ol><li>设置防火墙服务不启动（使用<code>systemctl disable firewalld</code>）。</li><li>查看并卸载Linux自带的MariaDB数据库。</li></ol></li></ul> 
<h4>3. 安装MySQL</h4> 
<ul><li>安装Hive通常需要一个关系型数据库来存储元数据，如MySQL。 
  <ol><li>上传MySQL安装包。</li><li>解压安装包。</li><li>安装依赖文件，注意安装顺序。</li></ol></li></ul> 
<h4>4. Hive安装</h4> 
<ol><li><strong>下载并解压Hive安装包</strong> 
  <ul><li>从Hive官网下载Hive安装包（如<code>apache-hive-x.x.x-bin.tar.gz</code>）。</li><li>使用<code>tar -zxvf</code>命令解压到指定目录（如<code>/usr/local</code>）。</li></ul></li><li><strong>配置环境变量</strong> 
  <ul><li>使用<code>vim</code>编辑器编辑<code>/etc/profile</code>或用户级别的<code>.bashrc</code>文件。</li><li>添加Hive相关的环境变量，如<code>HIVE_HOME</code>、<code>PATH</code>等。</li><li>使用<code>source</code>命令使配置立即生效。</li></ul></li><li><strong>修改Hive组件配置文件</strong> 
  <ul><li>进入Hive安装目录下的<code>conf</code>文件夹。</li><li>创建或修改配置文件，如<code>hive-env.sh</code>和<code>hive-site.xml</code>。 
    <ul><li>在<code>hive-env.sh</code>中设置Java、Hadoop、Hive等环境变量。</li><li>在<code>hive-site.xml</code>中配置Hive的各种参数，如元数据存储位置、数据库连接信息等。</li></ul></li></ul></li><li><strong>创建临时文件夹</strong> 
  <ul><li>在Hive安装目录中创建临时文件夹<code>tmp</code>。</li></ul></li><li><strong>初始化Hive元数据</strong> 
  <ul><li>将MySQL驱动移动到<code>$HIVE_HOME/lib</code>目录下。</li><li>初始化Hive元数据，使用schematool工具将Hive的数据重新写入MySQL数据库中。</li></ul></li><li><strong>启动Hive</strong> 
  <ul><li>启动Hive服务，并进行相关操作，如查看数据库、创建表、插入数据等。</li></ul></li></ol> 
<h4>5. 注意事项</h4> 
<ul><li>确保Hadoop集群运行正常，且Hive配置中指定的Hadoop路径正确。</li><li>根据实际需求选择合适的Hive版本和配置参数。</li><li>备份重要数据，以防配置过程中出现问题导致数据丢失。</li></ul> 
<p>以上步骤仅供参考，具体安装和配置过程可能因环境和需求的不同而有所差异。在实际操作中，建议参考Hive官方文档和相关教程进行安装和配置。</p> 
<p>若没安装hadoop集群则可采取以下步骤：</p> 
<p>安装Hadoop集群的步骤可以大致分为以下几个部分：</p> 
<h4>一、安装前准备</h4> 
<ol><li><strong>选择合适的Hadoop版本</strong>：例如Hadoop 3.1.3。</li><li><strong>下载必要的软件包</strong>： 
  <ul><li>Hadoop安装包（如<code>hadoop-3.1.3.tar.gz</code>）。</li><li>JDK安装包（Hadoop运行需要Java环境）。</li><li>虚拟机软件（如VMware Workstation 16 Pro）。</li><li>CentOS或Ubuntu等Linux系统的镜像文件。</li></ul></li></ol> 
<h4>二、虚拟机安装与配置</h4> 
<ol><li><strong>安装虚拟机软件</strong>：确保使用的虚拟机软件版本与操作系统兼容（如VMware Workstation 16 Pro）。</li><li><strong>创建虚拟机</strong>： 
  <ul><li>使用虚拟机软件创建新的虚拟机。</li><li>设置虚拟机名称、存储位置、磁盘大小等参数。</li><li>安装Linux系统（如CentOS 7或Ubuntu）。</li></ul></li><li><strong>配置网络</strong>： 
  <ul><li>为虚拟机分配静态IP地址，并确保各节点之间的网络连通性。</li><li>配置hosts文件，实现主机名与IP地址的映射。</li></ul></li><li><strong>关闭防火墙和SELinux</strong>：在Linux系统中关闭防火墙和SELinux，以确保Hadoop集群能够正常运行。</li></ol> 
<h4>三、JDK安装与配置</h4> 
<ol><li><strong>上传JDK安装包</strong>：将JDK安装包上传到Linux系统的指定目录。</li><li><strong>解压并安装JDK</strong>：使用<code>tar</code>命令解压JDK安装包，并配置环境变量。</li></ol> 
<h4>四、Hadoop安装与配置</h4> 
<ol><li><strong>上传Hadoop安装包</strong>：将Hadoop安装包上传到Linux系统的指定目录。</li><li><strong>解压Hadoop</strong>：使用<code>tar</code>命令解压Hadoop安装包。</li><li><strong>配置环境变量</strong>：编辑<code>/etc/profile</code>文件，添加Hadoop相关的环境变量。</li><li><strong>修改Hadoop配置文件</strong>： 
  <ul><li>修改<code>hadoop-env.sh</code>文件，设置Java环境变量。</li><li>修改<code>core-site.xml</code>文件，配置Hadoop核心参数，如文件系统名称、NameNode地址等。</li><li>修改<code>hdfs-site.xml</code>文件，配置HDFS相关参数，如数据块大小、副本数量等。</li><li>修改<code>mapred-site.xml</code>文件（如果该文件不存在，可以从<code>mapred-site.xml.template</code>复制并改名），配置MapReduce相关参数。</li><li>修改<code>yarn-site.xml</code>文件，配置YARN相关参数。</li></ul></li><li><strong>格式化NameNode</strong>：在Hadoop主节点上运行<code>hdfs namenode -format</code>命令，格式化NameNode。</li></ol> 
<h4>五、Hadoop集群配置</h4> 
<ol><li><strong>克隆虚拟机</strong>：使用虚拟机软件的克隆功能，创建多个具有相同配置的虚拟机节点。</li><li><strong>修改克隆节点的主机名和网络配置</strong>：确保每个节点具有唯一的主机名和网络配置。</li><li><strong>配置SSH免密登录</strong>：在Hadoop集群中配置SSH免密登录，以便于节点之间的通信。</li></ol> 
<h4>六、启动Hadoop集群</h4> 
<ol><li><strong>启动HDFS</strong>：在NameNode节点上启动HDFS服务。</li><li><strong>启动YARN</strong>：在ResourceManager节点上启动YARN服务。</li><li><strong>验证Hadoop集群状态</strong>：通过Hadoop提供的命令行工具或Web界面，验证Hadoop集群的状态和运行情况。</li></ol> 
<p>以上步骤是一个基本的Hadoop集群安装和配置流程，具体细节可能因环境差异和版本不同而有所调整。在实际操作中，建议参考Hadoop官方文档和相关教程进行安装和配置。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/1e17720c7043bee2a1f73c8f81017f84/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">国内AIGC工具是否存在版权争议？（ 计育韬老师高校公益巡讲答疑实录2024）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/f571133a5d4a9520d61f0a10dd508895/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">day23--单元测试-反射-注解-动态代理</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>