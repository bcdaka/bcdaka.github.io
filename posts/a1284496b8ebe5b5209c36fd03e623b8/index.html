<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【爬虫实战】python文本分析库——Gensim - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/a1284496b8ebe5b5209c36fd03e623b8/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="【爬虫实战】python文本分析库——Gensim">
  <meta property="og:description" content="文章目录 01、引言02、主题分析以及文本相似性分析03、关键词提取04、Word2Vec 嵌入（词嵌入 Word Embeddings）05、FastText 嵌入（子词嵌入 Subword Embeddings）06、文档向量化 01、引言 Gensim是一个用于自然语言处理和文本分析的 Python 库，提供了许多强大的功能，包括文档的相似度计算、关键词提取和文档的主题分析，要开始使用Gensim，您需要安装它，再进行文本分析和NLP任务，安装Gensim可以使用pip：
pip install gensim 02、主题分析以及文本相似性分析 Gensim是一个强大的Python库，用于执行主题建模和文本相似性分析等自然语言处理任务。使用Gensim进行主题建模（使用Latent Dirichlet Allocation，LDA）和文本相似性分析（使用 similarities 模块中的 MatrixSimilarity 或 SparseMatrixSimilarity 来计算文档相似度），代码如下：
from gensim import corpora, models, similarities # 创建一个简单的文本数据集作为示例 documents = [ &#34;This is the first document.&#34;, &#34;This document is the second document.&#34;, &#34;And this is the third one.&#34;, &#34;Is this the first document?&#34;, ] # 预处理文本数据： # 切分文档为单词 text = [document.split() for document in documents] # 创建一个词典，将每个单词映射到一个唯一的整数ID dictionary = corpora.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-01-20T10:23:39+08:00">
    <meta property="article:modified_time" content="2024-01-20T10:23:39+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【爬虫实战】python文本分析库——Gensim</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><ul><li><a href="#01_2" rel="nofollow">01、引言</a></li><li><a href="#02_10" rel="nofollow">02、主题分析以及文本相似性分析</a></li><li><a href="#03_109" rel="nofollow">03、关键词提取</a></li><li><a href="#04Word2Vec__Word_Embeddings_160" rel="nofollow">04、Word2Vec 嵌入（词嵌入 Word Embeddings）</a></li><li><a href="#05FastText__Subword_Embeddings_199" rel="nofollow">05、FastText 嵌入（子词嵌入 Subword Embeddings）</a></li><li><a href="#06_242" rel="nofollow">06、文档向量化</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h3><a id="01_2"></a>01、引言</h3> 
<p>Gensim是一个用于自然语言处理和文本分析的 Python 库，提供了许多强大的功能，包括文档的相似度计算、关键词提取和文档的主题分析，要开始使用Gensim，您需要安装它，再进行文本分析和NLP任务，安装Gensim可以使用pip：</p> 
<pre><code>pip install gensim
</code></pre> 
<h3><a id="02_10"></a>02、主题分析以及文本相似性分析</h3> 
<p>Gensim是一个强大的Python库，用于执行主题建模和文本相似性分析等自然语言处理任务。使用Gensim进行主题建模（使用Latent Dirichlet Allocation，LDA）和文本相似性分析（使用 similarities 模块中的 MatrixSimilarity 或 SparseMatrixSimilarity 来计算文档相似度），代码如下：</p> 
<pre><code class="prism language-bash">from gensim <span class="token function">import</span> corpora, models, similarities

<span class="token comment"># 创建一个简单的文本数据集作为示例</span>
documents <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token string">"This is the first document."</span>,
    <span class="token string">"This document is the second document."</span>,
    <span class="token string">"And this is the third one."</span>,
    <span class="token string">"Is this the first document?"</span>,
<span class="token punctuation">]</span>
<span class="token comment"># 预处理文本数据：</span>
<span class="token comment"># 切分文档为单词</span>
text <span class="token operator">=</span> <span class="token punctuation">[</span>document.split<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> <span class="token for-or-select variable">document</span> <span class="token keyword">in</span> documents<span class="token punctuation">]</span>

<span class="token comment"># 创建一个词典，将每个单词映射到一个唯一的整数ID</span>
dictionary <span class="token operator">=</span> corpora.Dictionary<span class="token punctuation">(</span>text<span class="token punctuation">)</span>

<span class="token comment"># 使用词典将文本转化为文档-词袋（document-term）表示</span>
corpus <span class="token operator">=</span> <span class="token punctuation">[</span>dictionary.doc2bow<span class="token punctuation">(</span>doc<span class="token punctuation">)</span> <span class="token keyword">for</span> <span class="token for-or-select variable">doc</span> <span class="token keyword">in</span> text<span class="token punctuation">]</span>

<span class="token comment">#训练LDA模型并执行主题建模：</span>
<span class="token comment"># 训练LDA模型</span>
lda_model <span class="token operator">=</span> models.LdaModel<span class="token punctuation">(</span>corpus, <span class="token assign-left variable">num_topics</span><span class="token operator">=</span><span class="token number">2</span>, <span class="token assign-left variable">id2word</span><span class="token operator">=</span>dictionary, <span class="token assign-left variable">passes</span><span class="token operator">=</span><span class="token number">15</span><span class="token punctuation">)</span>

<span class="token comment"># 输出主题及其词汇</span>
<span class="token keyword">for</span> <span class="token for-or-select variable">topic</span> <span class="token keyword">in</span> lda_model.print_topics<span class="token punctuation">(</span><span class="token punctuation">)</span>:
    print<span class="token punctuation">(</span>topic<span class="token punctuation">)</span>

<span class="token comment">#文本相似性分析：</span>
from gensim <span class="token function">import</span> similarities

<span class="token comment"># 创建一个索引</span>
index <span class="token operator">=</span> similarities.MatrixSimilarity<span class="token punctuation">(</span>lda_model<span class="token punctuation">[</span>corpus<span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 定义一个查询文本</span>
query <span class="token operator">=</span> <span class="token string">"This is a new document."</span>

<span class="token comment"># 预处理查询文本</span>
query_bow <span class="token operator">=</span> dictionary.doc2bow<span class="token punctuation">(</span>query.split<span class="token punctuation">(</span><span class="token punctuation">))</span>

<span class="token comment"># 获取查询文本与所有文档的相似性得分</span>
sims <span class="token operator">=</span> index<span class="token punctuation">[</span>lda_model<span class="token punctuation">[</span>query_bow<span class="token punctuation">]</span><span class="token punctuation">]</span>

<span class="token comment"># 按相似性得分降序排列文档</span>
sims <span class="token operator">=</span> sorted<span class="token punctuation">(</span>enumerate<span class="token punctuation">(</span>sims<span class="token punctuation">)</span>, <span class="token assign-left variable">key</span><span class="token operator">=</span>lambda item: -item<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 输出相似文档及其得分</span>
<span class="token keyword">for</span> document_id, similarity <span class="token keyword">in</span> sims:
    print<span class="token punctuation">(</span>f<span class="token string">"Document {document_id}: Similarity = {similarity}"</span><span class="token punctuation">)</span>
</code></pre> 
<p>结果如下：</p> 
<p><img src="https://images2.imgbox.com/f5/1d/h11DhFrt_o.png" alt=""></p> 
<p>另一种方法，在gensim下用 Wasserstein 距离方法计算文档相似度，代码如下：</p> 
<pre><code class="prism language-bash">from gensim <span class="token function">import</span> corpora
from scipy.stats <span class="token function">import</span> wasserstein_distance
<span class="token function">import</span> numpy as np

<span class="token comment"># 示例文档</span>
documents <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token string">"This is the first document."</span>,
    <span class="token string">"This document is the second document."</span>,
    <span class="token string">"And this is the third one."</span>,
    <span class="token string">"Is this the first document?"</span>,
<span class="token punctuation">]</span>

<span class="token comment"># 预处理文本和创建词典</span>
text <span class="token operator">=</span> <span class="token punctuation">[</span>document.split<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> <span class="token for-or-select variable">document</span> <span class="token keyword">in</span> documents<span class="token punctuation">]</span>
dictionary <span class="token operator">=</span> corpora.Dictionary<span class="token punctuation">(</span>text<span class="token punctuation">)</span>

<span class="token comment"># 创建文档的词袋表示</span>
corpus <span class="token operator">=</span> <span class="token punctuation">[</span>dictionary.doc2bow<span class="token punctuation">(</span>doc<span class="token punctuation">)</span> <span class="token keyword">for</span> <span class="token for-or-select variable">doc</span> <span class="token keyword">in</span> text<span class="token punctuation">]</span>

<span class="token comment"># 创建文档的概率分布</span>
document_distributions <span class="token operator">=</span> <span class="token punctuation">[</span>np.array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> * len<span class="token punctuation">(</span>dictionary<span class="token punctuation">))</span> <span class="token keyword">for</span> <span class="token for-or-select variable">_</span> <span class="token keyword">in</span> range<span class="token punctuation">(</span>len<span class="token punctuation">(</span>corpus<span class="token punctuation">))</span><span class="token punctuation">]</span>

<span class="token keyword">for</span> i, doc_bow <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>corpus<span class="token punctuation">)</span>:
    <span class="token keyword">for</span> word_id, count <span class="token keyword">in</span> doc_bow:
        document_distributions<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>word_id<span class="token punctuation">]</span> <span class="token operator">=</span> count / len<span class="token punctuation">(</span>doc_bow<span class="token punctuation">)</span>

<span class="token comment"># 计算Wasserstein距离</span>
<span class="token comment"># 这里示例计算第一个文档和其他文档之间的Wasserstein距离</span>
<span class="token keyword">for</span> <span class="token for-or-select variable">i</span> <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">1</span>, len<span class="token punctuation">(</span>document_distributions<span class="token punctuation">))</span>:
    wasserstein_dist <span class="token operator">=</span> wasserstein_distance<span class="token punctuation">(</span>document_distributions<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>, document_distributions<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
    print<span class="token punctuation">(</span>f<span class="token string">"Wasserstein Distance between Document 0 and Document {i}: {wasserstein_dist}"</span><span class="token punctuation">)</span>
</code></pre> 
<p>结果如下：</p> 
<p><img src="https://images2.imgbox.com/44/11/oIiG66n1_o.png" alt=""></p> 
<h3><a id="03_109"></a>03、关键词提取</h3> 
<p>Gensim 允许你使用 TF-IDF 权重和其他算法来提取文档中的关键词。你可以使用 models.TfidfModel 来计算 TF-IDF 权重，然后使用 model.get_document_topics 来获取文档的主题分布，代码如下：</p> 
<pre><code class="prism language-bash">from gensim <span class="token function">import</span> corpora, models
from gensim.parsing.preprocessing <span class="token function">import</span> preprocess_string, strip_punctuation

<span class="token comment"># 示例文档</span>
documents <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token string">"This is the first document. It contains important information."</span>,
    <span class="token string">"This document is the second document. It also has important content."</span>,
    <span class="token string">"And this is the third one. It may contain some relevant details."</span>,
    <span class="token string">"Is this the first document? Yes, it is."</span>
<span class="token punctuation">]</span>

<span class="token comment"># 预处理文本</span>
def preprocess<span class="token punctuation">(</span>text<span class="token punctuation">)</span>:
    <span class="token comment"># 使用Gensim的文本预处理工具进行处理，包括去除标点符号</span>
    custom_filters <span class="token operator">=</span> <span class="token punctuation">[</span>strip_punctuation<span class="token punctuation">]</span>
    processed_text <span class="token operator">=</span> preprocess_string<span class="token punctuation">(</span>text, custom_filters<span class="token punctuation">)</span>
    <span class="token builtin class-name">return</span> processed_text

<span class="token comment"># 预处理文档并创建词袋表示</span>
text <span class="token operator">=</span> <span class="token punctuation">[</span>preprocess<span class="token punctuation">(</span>document<span class="token punctuation">)</span> <span class="token keyword">for</span> <span class="token for-or-select variable">document</span> <span class="token keyword">in</span> documents<span class="token punctuation">]</span>
dictionary <span class="token operator">=</span> corpora.Dictionary<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
corpus <span class="token operator">=</span> <span class="token punctuation">[</span>dictionary.doc2bow<span class="token punctuation">(</span>doc<span class="token punctuation">)</span> <span class="token keyword">for</span> <span class="token for-or-select variable">doc</span> <span class="token keyword">in</span> text<span class="token punctuation">]</span>

<span class="token comment"># 计算TF-IDF模型</span>
tfidf_model <span class="token operator">=</span> models.TfidfModel<span class="token punctuation">(</span>corpus<span class="token punctuation">)</span>
<span class="token assign-left variable">lda_model</span><span class="token operator">=</span>models.LdaModel<span class="token punctuation">(</span>corpus<span class="token punctuation">)</span>

<span class="token comment"># 获取TF-IDF加权</span>
<span class="token keyword">for</span> i, doc <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>corpus<span class="token punctuation">)</span>:
    tfidf_weights <span class="token operator">=</span> tfidf_model<span class="token punctuation">[</span>doc<span class="token punctuation">]</span>
    print<span class="token punctuation">(</span>f<span class="token string">"TF-IDF Weights for Document {i}: {tfidf_weights}"</span><span class="token punctuation">)</span>

<span class="token comment"># 获取文档的主题分布</span>
<span class="token keyword">for</span> i, doc <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>corpus<span class="token punctuation">)</span>:
    document_topics <span class="token operator">=</span> lda_model.get_document_topics<span class="token punctuation">(</span>doc<span class="token punctuation">)</span>
    print<span class="token punctuation">(</span>f<span class="token string">"Topic Distribution for Document {i}: {document_topics}"</span><span class="token punctuation">)</span>
</code></pre> 
<p>最终结果如下：</p> 
<p><img src="https://images2.imgbox.com/35/47/wzUqyCcv_o.png" alt=""></p> 
<h3><a id="04Word2Vec__Word_Embeddings_160"></a>04、Word2Vec 嵌入（词嵌入 Word Embeddings）</h3> 
<p>gensim支持训练和使用 Word2Vec 模型，以将单词映射到低维向量空间。Word2Vec是一种词嵌入技术，它可以捕捉单词之间的语义关系，使得词汇可以在向量空间中表示。这对于词义相似度计算、单词聚类和其他自然语言处理任务非常有用，代码如下：</p> 
<pre><code class="prism language-bash">from gensim.models <span class="token function">import</span> Word2Vec

<span class="token comment"># 示例文本数据</span>
sentences <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token punctuation">[</span><span class="token string">"this"</span>, <span class="token string">"is"</span>, <span class="token string">"a"</span>, <span class="token string">"sample"</span>, <span class="token string">"sentence"</span><span class="token punctuation">]</span>,
    <span class="token punctuation">[</span><span class="token string">"word2vec"</span>, <span class="token string">"is"</span>, <span class="token string">"used"</span>, <span class="token string">"to"</span>, <span class="token string">"create"</span>, <span class="token string">"word"</span>, <span class="token string">"embeddings"</span><span class="token punctuation">]</span>,
    <span class="token punctuation">[</span><span class="token string">"it"</span>, <span class="token string">"maps"</span>, <span class="token string">"words"</span>, <span class="token string">"to"</span>, <span class="token string">"low-dimensional"</span>, <span class="token string">"vectors"</span><span class="token punctuation">]</span>,
    <span class="token punctuation">[</span><span class="token string">"these"</span>, <span class="token string">"vectors"</span>, <span class="token string">"capture"</span>, <span class="token string">"semantic"</span>, <span class="token string">"meaning"</span>, <span class="token string">"of"</span>, <span class="token string">"words"</span><span class="token punctuation">]</span>,
<span class="token punctuation">]</span>

<span class="token comment"># 训练Word2Vec模型</span>
model <span class="token operator">=</span> Word2Vec<span class="token punctuation">(</span>sentences, <span class="token assign-left variable">vector_size</span><span class="token operator">=</span><span class="token number">100</span>, <span class="token assign-left variable">window</span><span class="token operator">=</span><span class="token number">5</span>, <span class="token assign-left variable">min_count</span><span class="token operator">=</span><span class="token number">1</span>, <span class="token assign-left variable">sg</span><span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

<span class="token comment"># 保存模型</span>
model.save<span class="token punctuation">(</span><span class="token string">"word2vec.model"</span><span class="token punctuation">)</span>

<span class="token comment"># 加载模型</span>
model <span class="token operator">=</span> Word2Vec.load<span class="token punctuation">(</span><span class="token string">"word2vec.model"</span><span class="token punctuation">)</span>

<span class="token comment"># 获取单词的向量表示</span>
word_vector <span class="token operator">=</span> model.wv<span class="token punctuation">[</span><span class="token string">"word2vec"</span><span class="token punctuation">]</span>
print<span class="token punctuation">(</span><span class="token string">"Vector representation for 'word2vec':"</span>, word_vector<span class="token punctuation">)</span>

<span class="token comment"># 查找与单词最相似的单词</span>
similar_words <span class="token operator">=</span> model.wv.most_similar<span class="token punctuation">(</span><span class="token string">"word2vec"</span>, <span class="token assign-left variable">topn</span><span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>
print<span class="token punctuation">(</span><span class="token string">"Most similar words to 'word2vec':"</span>, similar_words<span class="token punctuation">)</span>
</code></pre> 
<p>最终结果如下：</p> 
<p><img src="https://images2.imgbox.com/35/b2/OzFGgSQv_o.png" alt=""></p> 
<h3><a id="05FastText__Subword_Embeddings_199"></a>05、FastText 嵌入（子词嵌入 Subword Embeddings）</h3> 
<p>Gensim支持 FastText 模型，这是一个基于子词的嵌入模型，可以捕获单词的内部结构和形态，FastText在许多自然语言处理任务中表现出色，尤其在处理具有丰富形态变化的语言时非常有用，代码如下：</p> 
<pre><code class="prism language-bash">from gensim.models.fasttext <span class="token function">import</span> FastText

<span class="token comment"># 示例文本数据</span>
sentences <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token punctuation">[</span><span class="token string">"this"</span>, <span class="token string">"is"</span>, <span class="token string">"a"</span>, <span class="token string">"sample"</span>, <span class="token string">"sentence"</span><span class="token punctuation">]</span>,
    <span class="token punctuation">[</span><span class="token string">"fasttext"</span>, <span class="token string">"is"</span>, <span class="token string">"used"</span>, <span class="token string">"to"</span>, <span class="token string">"capture"</span>, <span class="token string">"word"</span>, <span class="token string">"subword"</span>, <span class="token string">"embeddings"</span><span class="token punctuation">]</span>,
    <span class="token punctuation">[</span><span class="token string">"it"</span>, <span class="token string">"can"</span>, <span class="token string">"handle"</span>, <span class="token string">"morphological"</span>, <span class="token string">"variations"</span>, <span class="token string">"in"</span>, <span class="token string">"words"</span><span class="token punctuation">]</span>,
    <span class="token punctuation">[</span><span class="token string">"fasttext"</span>, <span class="token string">"embeddings"</span>, <span class="token string">"are"</span>, <span class="token string">"useful"</span>, <span class="token string">"for"</span>, <span class="token string">"NLP"</span>, <span class="token string">"tasks"</span><span class="token punctuation">]</span>,
<span class="token punctuation">]</span>

<span class="token comment"># 训练FastText模型</span>
model <span class="token operator">=</span> FastText<span class="token punctuation">(</span>sentences, <span class="token assign-left variable">vector_size</span><span class="token operator">=</span><span class="token number">100</span>, <span class="token assign-left variable">window</span><span class="token operator">=</span><span class="token number">5</span>, <span class="token assign-left variable">min_count</span><span class="token operator">=</span><span class="token number">1</span>, <span class="token assign-left variable">sg</span><span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

<span class="token comment"># 保存模型</span>
model.save<span class="token punctuation">(</span><span class="token string">"fasttext.model"</span><span class="token punctuation">)</span>

<span class="token comment"># 加载模型</span>
model <span class="token operator">=</span> FastText.load<span class="token punctuation">(</span><span class="token string">"fasttext.model"</span><span class="token punctuation">)</span>

<span class="token comment"># 获取单词的向量表示</span>
word_vector <span class="token operator">=</span> model.wv<span class="token punctuation">[</span><span class="token string">"fasttext"</span><span class="token punctuation">]</span>
print<span class="token punctuation">(</span><span class="token string">"Vector representation for 'fasttext':"</span>, word_vector<span class="token punctuation">)</span>

<span class="token comment"># 查找与单词最相似的单词</span>
similar_words <span class="token operator">=</span> model.wv.most_similar<span class="token punctuation">(</span><span class="token string">"fasttext"</span>, <span class="token assign-left variable">topn</span><span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>
print<span class="token punctuation">(</span><span class="token string">"Most similar words to 'fasttext':"</span>, similar_words<span class="token punctuation">)</span>
</code></pre> 
<p>最终结果如下：</p> 
<p><img src="https://images2.imgbox.com/fe/95/6YTY3dJk_o.png" alt=""></p> 
<h3><a id="06_242"></a>06、文档向量化</h3> 
<p>使用Gensim将文档表示为词袋模型和TF-IDF向量，从而将文档转化为数值表示形式，以便用于文本分类、文本检索和文本聚类等任务代码如下：</p> 
<pre><code class="prism language-bash">from gensim <span class="token function">import</span> corpora

<span class="token comment"># 示例文档</span>
documents <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token string">"This is the first document. It contains important information."</span>,
    <span class="token string">"This document is the second document. It also has important content."</span>,
    <span class="token string">"And this is the third one. It may contain some relevant details."</span>,
    <span class="token string">"Is this the first document? Yes, it is."</span>,
<span class="token punctuation">]</span>

<span class="token comment"># 预处理文本并创建词袋表示</span>
text <span class="token operator">=</span> <span class="token punctuation">[</span>document.split<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> <span class="token for-or-select variable">document</span> <span class="token keyword">in</span> documents<span class="token punctuation">]</span>
dictionary <span class="token operator">=</span> corpora.Dictionary<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
corpus <span class="token operator">=</span> <span class="token punctuation">[</span>dictionary.doc2bow<span class="token punctuation">(</span>doc<span class="token punctuation">)</span> <span class="token keyword">for</span> <span class="token for-or-select variable">doc</span> <span class="token keyword">in</span> text<span class="token punctuation">]</span>

<span class="token comment"># 文档向量表示</span>
document_vectors <span class="token operator">=</span> <span class="token punctuation">[</span>dict<span class="token punctuation">(</span>doc<span class="token punctuation">)</span> <span class="token keyword">for</span> <span class="token for-or-select variable">doc</span> <span class="token keyword">in</span> corpus<span class="token punctuation">]</span>

<span class="token comment"># 输出文档向量</span>
<span class="token keyword">for</span> i, doc_vector <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>document_vectors<span class="token punctuation">)</span>:
    print<span class="token punctuation">(</span>f<span class="token string">"Document {i} Vector: {doc_vector}"</span><span class="token punctuation">)</span>

from gensim <span class="token function">import</span> corpora, models

<span class="token comment"># 示例文档</span>
documents <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token string">"This is the first document. It contains important information."</span>,
    <span class="token string">"This document is the second document. It also has important content."</span>,
    <span class="token string">"And this is the third one. It may contain some relevant details."</span>,
    <span class="token string">"Is this the first document? Yes, it is."</span>,
<span class="token punctuation">]</span>

<span class="token comment"># 预处理文本并创建词袋表示</span>
text <span class="token operator">=</span> <span class="token punctuation">[</span>document.split<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> <span class="token for-or-select variable">document</span> <span class="token keyword">in</span> documents<span class="token punctuation">]</span>
dictionary <span class="token operator">=</span> corpora.Dictionary<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
corpus <span class="token operator">=</span> <span class="token punctuation">[</span>dictionary.doc2bow<span class="token punctuation">(</span>doc<span class="token punctuation">)</span> <span class="token keyword">for</span> <span class="token for-or-select variable">doc</span> <span class="token keyword">in</span> text<span class="token punctuation">]</span>

<span class="token comment"># 计算TF-IDF模型</span>
tfidf_model <span class="token operator">=</span> models.TfidfModel<span class="token punctuation">(</span>corpus<span class="token punctuation">)</span>
corpus_tfidf <span class="token operator">=</span> tfidf_model<span class="token punctuation">[</span>corpus<span class="token punctuation">]</span>

<span class="token comment"># 文档TF-IDF向量表示</span>
tfidf_vectors <span class="token operator">=</span> <span class="token punctuation">[</span>dict<span class="token punctuation">(</span>doc<span class="token punctuation">)</span> <span class="token keyword">for</span> <span class="token for-or-select variable">doc</span> <span class="token keyword">in</span> corpus_tfidf<span class="token punctuation">]</span>

<span class="token comment"># 输出TF-IDF文档向量</span>
<span class="token keyword">for</span> i, tfidf_vector <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>tfidf_vectors<span class="token punctuation">)</span>:
    print<span class="token punctuation">(</span>f<span class="token string">"TF-IDF Vector for Document {i}: {tfidf_vector}"</span><span class="token punctuation">)</span>
</code></pre> 
<p>最终结果如下：</p> 
<p><img src="https://images2.imgbox.com/78/cf/TmpEol1f_o.png" alt=""></p> 
<p>以上就是本文对Gensim库文本分析的 方法介绍，希望能够帮助大家处理解决文本分析问题，感兴趣的小伙伴可以亲自去试试！</p> 
<p><font face="幼圆" size="4" color="red">感兴趣的小伙伴，赠送全套Python学习资料，包含面试题、简历资料等具体看下方。<br> </font><br> <img src="https://images2.imgbox.com/4d/41/1W33emqz_o.png"></p> 
<p><strong>一、Python所有方向的学习路线</strong></p> 
<p>Python所有方向的技术点做的整理，形成各个领域的知识点汇总，它的用处就在于，你可以按照下面的知识点去找对应的学习资源，保证自己学得较为全面。</p> 
<p><img src="https://images2.imgbox.com/2c/a8/ndIgM3C3_o.png" alt="img"><br> <img src="https://images2.imgbox.com/0c/bb/cOWfP9MU_o.png" alt="img"></p> 
<p><strong>二、Python必备开发工具</strong></p> 
<p>工具都帮大家整理好了，安装就可直接上手！<img src="https://images2.imgbox.com/6f/67/MMQGkLB8_o.gif" alt="img"></p> 
<p><strong>三、最新Python学习笔记</strong></p> 
<p>当我学到一定基础，有自己的理解能力的时候，会去阅读一些前辈整理的书籍或者手写的笔记资料，这些笔记详细记载了他们对一些技术点的理解，这些理解是比较独到，可以学到不一样的思路。</p> 
<p><img src="https://images2.imgbox.com/b2/63/y8hBdpz7_o.png" alt="img"></p> 
<p><strong>四、Python视频合集</strong></p> 
<p>观看全面零基础学习视频，看视频学习是最快捷也是最有效果的方式，跟着视频中老师的思路，从基础到深入，还是很容易入门的。</p> 
<p><img src="https://images2.imgbox.com/14/87/9GEJZP3r_o.png" alt="img"></p> 
<p><strong>五、实战案例</strong></p> 
<p>纸上得来终觉浅，要学会跟着视频一起敲，要动手实操，才能将自己的所学运用到实际当中去，这时候可以搞点实战案例来学习。</p> 
<p><img src="https://images2.imgbox.com/a6/f7/BCGBvpSM_o.png" alt="img"></p> 
<p><strong>六、面试宝典</strong></p> 
<p><img src="https://images2.imgbox.com/25/be/7zUdzTjW_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/af/67/6V2FDwoC_o.png" alt="在这里插入图片描述"></p> 
<p><strong>简历模板</strong><img src="https://images2.imgbox.com/5c/e3/7jIpRawQ_o.png" alt="在这里插入图片描述"><img src="https://images2.imgbox.com/f4/23/mHyQNS7M_o.png"><br> 若有侵权，请联系删除</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/abf699c0e0df6efe977f5333ef981518/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【Python】用tkinter设计图书管理登录UI界面（一）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/c8960a5458f626f716f5b84adfb12e6a/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">AI大模型开发架构设计（1）——LLM大模型Agent剖析和应用案例实战</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>