<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【机器学习】逻辑回归：原理、应用与实践 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/f99868af25310c2404eecce25bc7b7c7/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="【机器学习】逻辑回归：原理、应用与实践">
  <meta property="og:description" content="🌈个人主页: 鑫宝Code
🔥热门专栏: 闲话杂谈｜ 炫酷HTML | JavaScript基础 ​💫个人格言: &#34;如无必要，勿增实体&#34; 文章目录 逻辑回归：原理、应用与实践引言1. 逻辑回归基础1.1 基本概念1.2 Sigmoid函数 2. 模型构建2.1 线性决策边界2.2 参数估计 3. 损失函数与优化3.1 交叉熵损失函数3.2 优化算法 4. 多分类逻辑回归5. 实践应用与案例分析5.1 应用领域5.2 案例分析 6. 逻辑回归的局限与挑战7. 结论 逻辑回归：原理、应用与实践 引言 逻辑回归（Logistic Regression）是一种广泛应用于分类问题的统计学方法，尽管其名称中含有“回归”二字，但它实际上是一种用于解决二分类或多分类问题的线性模型。逻辑回归通过使用逻辑函数（通常为sigmoid函数）将线性模型的输出映射到概率空间，从而预测某个事件发生的概率。本文将深入探讨逻辑回归的理论基础、模型构建、损失函数、优化算法以及实际应用案例，并简要介绍其在机器学习领域的地位和局限性。
1. 逻辑回归基础 1.1 基本概念 逻辑回归主要用于处理因变量为离散型数据的问题，尤其是二分类问题，如判断一个用户是否会购买某产品、一封邮件是否为垃圾邮件等。其核心思想是通过建立输入特征与输出类别之间的逻辑关系模型，来预测输出为某一类别的概率。
1.2 Sigmoid函数 Sigmoid函数是逻辑回归中的关键组件，其表达式为：
σ ( z ) = 1 1 &#43; e − z \sigma(z) = \frac{1}{1 &#43; e^{-z}} σ(z)=1&#43;e−z1​
该函数将线性组合 z = θ T x z = \theta^T x z=θTx（其中$ \theta $为模型参数，(x)为输入特征向量）的输出映射到(0, 1)之间，可以解释为事件发生的概率。">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-06-03T12:46:21+08:00">
    <meta property="article:modified_time" content="2024-06-03T12:46:21+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【机器学习】逻辑回归：原理、应用与实践</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-tomorrow-night">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <hr> 
<img src="https://images2.imgbox.com/2c/04/rQjAIsXw_o.png" alt="鑫宝Code" width="150px"> 
<br> 
<img src="https://images2.imgbox.com/e0/55/UQlAEzxZ_o.gif" width="300px"> 
<br> 
<p> <font color="#0099ff" size="3" face="粗体"><strong>🌈个人主页: <a href="https://xinbaocode.blog.csdn.net/" rel="nofollow">鑫宝Code</a></strong></font><br> <font color="#0099ff" size="3" face="粗体"><strong>🔥热门专栏: <a href="https://xinbaocode.blog.csdn.net/category_12565077.html" rel="nofollow">闲话杂谈</a>｜ <a href="https://xinbaocode.blog.csdn.net/category_12578048.html" rel="nofollow">炫酷HTML</a> | <a href="https://xinbaocode.blog.csdn.net/category_12578047.html" rel="nofollow">JavaScript基础</a> </strong></font><br> ​<font color="#0099ff" size="3" face="粗体"><strong>💫个人格言: "如无必要，勿增实体" </strong></font> <br><br> <img src="https://images2.imgbox.com/bd/0b/lE7kfgtE_o.gif" width="100%"> </p> 
<hr> 
<p></p> 
<p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#_40" rel="nofollow">逻辑回归：原理、应用与实践</a></li><li><ul><li><a href="#_43" rel="nofollow">引言</a></li><li><a href="#1__47" rel="nofollow">1. 逻辑回归基础</a></li><li><ul><li><a href="#11__49" rel="nofollow">1.1 基本概念</a></li><li><a href="#12_Sigmoid_53" rel="nofollow">1.2 Sigmoid函数</a></li></ul> 
   </li><li><a href="#2__63" rel="nofollow">2. 模型构建</a></li><li><ul><li><a href="#21__65" rel="nofollow">2.1 线性决策边界</a></li><li><a href="#22__73" rel="nofollow">2.2 参数估计</a></li></ul> 
   </li><li><a href="#3__77" rel="nofollow">3. 损失函数与优化</a></li><li><ul><li><a href="#31__79" rel="nofollow">3.1 交叉熵损失函数</a></li><li><a href="#32__89" rel="nofollow">3.2 优化算法</a></li></ul> 
   </li><li><a href="#4__93" rel="nofollow">4. 多分类逻辑回归</a></li><li><a href="#5__98" rel="nofollow">5. 实践应用与案例分析</a></li><li><ul><li><a href="#51__100" rel="nofollow">5.1 应用领域</a></li><li><a href="#52__104" rel="nofollow">5.2 案例分析</a></li></ul> 
   </li><li><a href="#6__154" rel="nofollow">6. 逻辑回归的局限与挑战</a></li><li><a href="#7__161" rel="nofollow">7. 结论</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h2><a id="_40"></a>逻辑回归：原理、应用与实践</h2> 
<p><img src="https://images2.imgbox.com/fa/0d/8U3i9yOt_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="_43"></a>引言</h3> 
<p>逻辑回归（Logistic Regression）是一种广泛应用于分类问题的统计学方法，尽管其名称中含有“回归”二字，但它实际上是一种用于解决二分类或多分类问题的线性模型。逻辑回归通过使用逻辑函数（通常为sigmoid函数）将线性模型的输出映射到概率空间，从而预测某个事件发生的概率。本文将深入探讨逻辑回归的理论基础、模型构建、损失函数、优化算法以及实际应用案例，并简要介绍其在机器学习领域的地位和局限性。</p> 
<h3><a id="1__47"></a>1. 逻辑回归基础</h3> 
<h4><a id="11__49"></a>1.1 基本概念</h4> 
<p>逻辑回归主要用于处理因变量为离散型数据的问题，尤其是二分类问题，如判断一个用户是否会购买某产品、一封邮件是否为垃圾邮件等。其核心思想是通过建立输入特征与输出类别之间的逻辑关系模型，来预测输出为某一类别的概率。</p> 
<h4><a id="12_Sigmoid_53"></a>1.2 Sigmoid函数</h4> 
<p><img src="https://images2.imgbox.com/76/96/l7dCDdgd_o.png" alt="在这里插入图片描述"></p> 
<p>Sigmoid函数是逻辑回归中的关键组件，其表达式为：</p> 
<p><span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          σ 
         
        
          ( 
         
        
          z 
         
        
          ) 
         
        
          = 
         
         
         
           1 
          
          
          
            1 
           
          
            + 
           
           
           
             e 
            
            
            
              − 
             
            
              z 
             
            
           
          
         
        
       
         \sigma(z) = \frac{1}{1 + e^{-z}} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0359em;">σ</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.044em;">z</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 2.0908em; vertical-align: -0.7693em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.3214em;"><span class="" style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">1</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6973em;"><span class="" style="top: -2.989em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathnormal mtight" style="margin-right: 0.044em;">z</span></span></span></span></span></span></span></span></span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.7693em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></span></p> 
<p>该函数将线性组合<span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          z 
         
        
          = 
         
         
         
           θ 
          
         
           T 
          
         
        
          x 
         
        
       
         z = \theta^T x 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal" style="margin-right: 0.044em;">z</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.8913em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8913em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.1389em;">T</span></span></span></span></span></span></span></span><span class="mord mathnormal">x</span></span></span></span></span></span>（其中$ \theta $为模型参数，(x)为输入特征向量）的输出映射到(0, 1)之间，可以解释为事件发生的概率。</p> 
<h3><a id="2__63"></a>2. 模型构建</h3> 
<h4><a id="21__65"></a>2.1 线性决策边界</h4> 
<p>逻辑回归模型的形式化表达为：</p> 
<p><span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          P 
         
        
          ( 
         
        
          Y 
         
        
          = 
         
        
          1 
         
        
          ∣ 
         
        
          X 
         
        
          = 
         
        
          x 
         
        
          ) 
         
        
          = 
         
        
          σ 
         
        
          ( 
         
         
         
           θ 
          
         
           0 
          
         
        
          + 
         
         
         
           θ 
          
         
           1 
          
         
         
         
           x 
          
         
           1 
          
         
        
          + 
         
         
         
           θ 
          
         
           2 
          
         
         
         
           x 
          
         
           2 
          
         
        
          + 
         
        
          . 
         
        
          . 
         
        
          . 
         
        
          + 
         
         
         
           θ 
          
         
           n 
          
         
         
         
           x 
          
         
           n 
          
         
        
          ) 
         
        
       
         P(Y=1|X=x) = \sigma(\theta_0 + \theta_1x_1 + \theta_2x_2 + ... + \theta_nx_n) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.1389em;">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.2222em;">Y</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord">1∣</span><span class="mord mathnormal" style="margin-right: 0.0785em;">X</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0359em;">σ</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0278em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.8444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0278em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.8444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0278em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.6667em; vertical-align: -0.0833em;"></span><span class="mord">...</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.0278em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></span></p> 
<p>其中，<span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          ( 
         
        
          P 
         
        
          ( 
         
        
          Y 
         
        
          = 
         
        
          1 
         
        
          ∣ 
         
        
          X 
         
        
          = 
         
        
          x 
         
        
          ) 
         
        
       
         (P(Y=1|X=x) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.1389em;">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.2222em;">Y</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord">1∣</span><span class="mord mathnormal" style="margin-right: 0.0785em;">X</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span></span></span>表示给定特征(x)时，事件发生的概率；(\theta_i)为模型参数，(\theta_0)为截距项。</p> 
<h4><a id="22__73"></a>2.2 参数估计</h4> 
<p>逻辑回归通过极大似然估计（MLE）来确定模型参数。具体来说，是找到一组参数(\theta)，使得训练数据的似然性最大化。</p> 
<h3><a id="3__77"></a>3. 损失函数与优化</h3> 
<h4><a id="31__79"></a>3.1 交叉熵损失函数</h4> 
<p><img src="https://images2.imgbox.com/6b/a7/icnk3qkg_o.png" alt="在这里插入图片描述"></p> 
<p>逻辑回归常用的损失函数是交叉熵损失（Cross-Entropy Loss），它衡量了模型预测概率分布与真实概率分布的差异。对于二分类问题，损失函数定义为：</p> 
<p><span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          J 
         
        
          ( 
         
        
          θ 
         
        
          ) 
         
        
          = 
         
        
          − 
         
         
         
           1 
          
         
           m 
          
         
         
         
           ∑ 
          
          
          
            i 
           
          
            = 
           
          
            1 
           
          
         
           m 
          
         
        
          [ 
         
         
         
           y 
          
         
           i 
          
         
        
          log 
         
        
          ⁡ 
         
        
          ( 
         
         
         
           p 
          
         
           i 
          
         
        
          ) 
         
        
          + 
         
        
          ( 
         
        
          1 
         
        
          − 
         
         
         
           y 
          
         
           i 
          
         
        
          ) 
         
        
          log 
         
        
          ⁡ 
         
        
          ( 
         
        
          1 
         
        
          − 
         
         
         
           p 
          
         
           i 
          
         
        
          ) 
         
        
          ] 
         
        
       
         J(\theta) = -\frac{1}{m} \sum_{i=1}^{m} [y_i \log(p_i) + (1-y_i) \log(1-p_i)] 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0962em;">J</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 2.9291em; vertical-align: -1.2777em;"></span><span class="mord">−</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.3214em;"><span class="" style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathnormal">m</span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.686em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.6514em;"><span class="" style="top: -1.8723em; margin-left: 0em;"><span class="pstrut" style="height: 3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span class="" style="top: -3.05em;"><span class="pstrut" style="height: 3.05em;"></span><span class=""><span class="mop op-symbol large-op">∑</span></span></span><span class="" style="top: -4.3em; margin-left: 0em;"><span class="pstrut" style="height: 3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 1.2777em;"><span class=""></span></span></span></span></span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mop">lo<span style="margin-right: 0.0139em;">g</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mop">lo<span style="margin-right: 0.0139em;">g</span></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)]</span></span></span></span></span></span></p> 
<p>其中，(m)是样本数量，(y_i)是真实标签，(p_i)是模型预测的概率。</p> 
<h4><a id="32__89"></a>3.2 优化算法</h4> 
<p>常见的优化算法有梯度下降法及其变种（如批量梯度下降、随机梯度下降、小批量梯度下降）和拟牛顿法等。这些算法通过迭代更新模型参数，以逐步降低损失函数值，达到参数最优解。</p> 
<h3><a id="4__93"></a>4. 多分类逻辑回归</h3> 
<p>对于多分类问题，逻辑回归可以通过两种主要方式扩展：一对一（One-vs-One, OvO）和一对多（One-vs-All, OvA）。每种方法都有其适用场景和优缺点。<br> <img src="https://images2.imgbox.com/60/9a/H0xlVArc_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="5__98"></a>5. 实践应用与案例分析</h3> 
<h4><a id="51__100"></a>5.1 应用领域</h4> 
<p>逻辑回归因其简单有效，在金融风控、医疗诊断、市场营销等多个领域有着广泛应用。例如，在银行信用评估中，逻辑回归模型可以用来预测客户违约的可能性。</p> 
<h4><a id="52__104"></a>5.2 案例分析</h4> 
<p>考虑一个简化版的银行贷款申请预测模型。通过收集申请人的年龄、收入、信用评分等特征，利用逻辑回归模型预测申请人是否会违约。通过特征工程、模型训练、交叉验证和调参等步骤，最终得到一个具有较高预测准确率的模型，为银行审批贷款提供决策支持。</p> 
<p>首先，请确保安装了scikit-learn库。如果未安装，可以通过pip命令安装：</p> 
<pre><code class="prism language-bash">pip <span class="token function">install</span> scikit-learn
</code></pre> 
<p>然后，你可以使用以下Python代码来实现逻辑回归：</p> 
<pre><code class="prism language-python"><span class="token comment"># 导入必要的库</span>
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> LogisticRegression
<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> metrics
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScaler

<span class="token comment"># 加载数据集，这里以鸢尾花数据集为例，但鸢尾花是多分类问题，我们简化为二分类</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> load_iris
iris <span class="token operator">=</span> load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span>
X <span class="token operator">=</span> iris<span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span>  <span class="token comment"># 只取前两列特征，简化为二维问题</span>
y <span class="token operator">=</span> <span class="token punctuation">(</span>iris<span class="token punctuation">.</span>target <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">)</span>  <span class="token comment"># 将目标转换为二分类问题（0和1）</span>

<span class="token comment"># 数据预处理：标准化</span>
scaler <span class="token operator">=</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>
X_scaled <span class="token operator">=</span> scaler<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span>

<span class="token comment"># 划分训练集和测试集</span>
X_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>X_scaled<span class="token punctuation">,</span> y<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span>

<span class="token comment"># 创建逻辑回归模型实例</span>
logreg <span class="token operator">=</span> LogisticRegression<span class="token punctuation">(</span>max_iter<span class="token operator">=</span><span class="token number">10000</span><span class="token punctuation">)</span>

<span class="token comment"># 训练模型</span>
logreg<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>

<span class="token comment"># 预测测试集结果</span>
y_pred <span class="token operator">=</span> logreg<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span>

<span class="token comment"># 输出模型性能指标</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Accuracy:"</span><span class="token punctuation">,</span> metrics<span class="token punctuation">.</span>accuracy_score<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Precision:"</span><span class="token punctuation">,</span> metrics<span class="token punctuation">.</span>precision_score<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Recall:"</span><span class="token punctuation">,</span> metrics<span class="token punctuation">.</span>recall_score<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 输出模型系数和截距</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Coefficients:"</span><span class="token punctuation">,</span> logreg<span class="token punctuation">.</span>coef_<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Intercept:"</span><span class="token punctuation">,</span> logreg<span class="token punctuation">.</span>intercept_<span class="token punctuation">)</span>
</code></pre> 
<p>这段代码演示了如何使用逻辑回归进行二分类任务的基本流程。注意，真实项目中可能需要更复杂的数据预处理和特征工程，以及更细致的模型调整和验证。此外，逻辑回归默认使用的是L2正则化，可以通过调整参数来改变正则化类型或强度。</p> 
<h3><a id="6__154"></a>6. 逻辑回归的局限与挑战</h3> 
<p>尽管逻辑回归在众多领域表现良好，但其也有一定的局限性：</p> 
<ul><li>线性假设：逻辑回归假设特征与目标变量间存在线性关系，对于非线性关系可能无法很好地建模。</li><li>处理大规模特征或高维数据时可能会遇到过拟合问题。</li><li>对于类别极度不均衡的数据集，需要特别处理以避免模型偏向多数类。</li></ul> 
<h3><a id="7__161"></a>7. 结论</h3> 
<p>逻辑回归作为经典的机器学习算法之一，凭借其简单、直观且易于实现的特点，在分类任务中依然保持重要地位。尽管面临一些局限性，通过引入正则化、特征选择、非线性变换等手段，逻辑回归能够适应更复杂的实际问题。随着深度学习等新技术的发展，逻辑回归也被融合进更复杂的模型结构中，继续发挥其独特价值。理解逻辑回归不仅有助于掌握基本的机器学习原理，也是深入探索现代机器学习技术的坚实基础。</p> 
<img src="https://images2.imgbox.com/8e/6c/Vh6Y5t3e_o.png" width="250" height="250"> 
<p> <img src="https://images2.imgbox.com/69/ee/zQHUaAt5_o.gif" alt="End"> </p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/284451e3c74e37dfb065bdf9278b77bc/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">redis做为缓存，mysql的数据如何与redis进行同步呢？</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/d64755a83ad7e2f76705b12b5d722f0d/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">QT 音乐播放器【二】 歌词同步&#43;滚动&#43;特效</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>