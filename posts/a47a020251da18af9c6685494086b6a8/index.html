<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>简单爬虫：东方财富网股票数据爬取(20231230) - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/a47a020251da18af9c6685494086b6a8/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="简单爬虫：东方财富网股票数据爬取(20231230)">
  <meta property="og:description" content="目标网站：https://quote.eastmoney.com/center/gridlist.html#hs_a_board
需求：将东方财富网行情中心不同板块的股票数据爬取下来
目标是将各个选项卡的股票数据全部爬取并以excel文件保存在本地。
查看网页源代码发现并没有目标数据，因此需要对网页进行抓包分析，查看哪个文件里包含目标数据，打开开发者模式（F12），找到目标文件
首先查看url，获取沪京深A股的第一页数据
# 沪深京A股 url = &#34;https://62.push2.eastmoney.com/api/qt/clist/get?cb=jQuery1124007675389012158473_1703949729655&amp;pn=1&amp;pz=20&amp;po=1&amp;np=1&amp;ut=bd1d9ddb04089700cf9c27f6f7426281&amp;fltt=2&amp;invt=2&amp;wbp2u=|0|0|0|web&amp;fid=f3&amp;fs=m:0&#43;t:6,m:0&#43;t:80,m:1&#43;t:2,m:1&#43;t:23,m:0&#43;t:81&#43;s:2048&amp;fields=f1,f2,f3,f4,f5,f6,f7,f8,f9,f10,f12,f13,f14,f15,f16,f17,f18,f20,f21,f23,f24,f25,f22,f11,f62,f128,f136,f115,f152&amp;_=1703949729656&#34; 访问形式为GET
查看预览，发现需要爬取的数据在文件的‘data’中的&#39;diff&#39;里面，对应的文件数据如下图所示：
通过观察发现，该数据无法直接转换成json文件，需要删除上图中的红框内容，需要用正则表达式替换成空字符串
data = response.text # 找到开头到第一个&#39;(&#39;的部分 left_data = re.search(r&#39;^.*?(?=\()&#39;, data).group() # 将匹配到的内容加上&#39;(&#39;替换成空字符串 data = re.sub(left_data &#43; &#39;\(&#39;, &#39;&#39;, data) # 将结尾的&#39;);&#39;替换成空字符串 data = re.sub(&#39;\);&#39;, &#39;&#39;, data) # 用eval将data转换成字典 data = eval(data) 注意：这里在匹配开头内容时，如果使用下面的语句直接匹配到&#39;jQuery1124007675389012158473_1703949729655(&#39;再进行替换的话会出现错误
left_data = re.search(r&#39;^.*?\(&#39;, data).group() print(left_data) data = re.sub(left_data, &#39;&#39;, data) 出现这个错误的原因是出现了圆括号但是没有转义，导致被当成捕获组，将括号转义（前面加上斜杠）即可解决。因此需要先匹配出&#39;(&#39;之前的部分，在替代文本里拼接上&#39;\(&#39;才能进行成功替换。
将目标数据转换成字典类型后，我们需要提取出其中data下面diff的内容，并通过定义一个字典来存储我们需要的数据，通过观察网页表头和文件代码对应关系，定义以下的字典：
df = data[&#39;data&#39;][&#39;diff&#39;] for index in df: dict = { &#34;代码&#34;: index[&#34;f12&#34;], &#34;名称&#34;: index[&#39;f14&#39;], &#34;">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2023-12-31T00:23:39+08:00">
    <meta property="article:modified_time" content="2023-12-31T00:23:39+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">简单爬虫：东方财富网股票数据爬取(20231230)</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>目标网站：<a href="https://quote.eastmoney.com/center/gridlist.html#hs_a_board" rel="nofollow" title="https://quote.eastmoney.com/center/gridlist.html#hs_a_board">https://quote.eastmoney.com/center/gridlist.html#hs_a_board</a></p> 
<p>需求：将东方财富网行情中心不同板块的股票数据爬取下来</p> 
<p><img alt="" height="1200" src="https://images2.imgbox.com/92/23/CaMepEfF_o.png" width="1200"></p> 
<p>目标是将各个选项卡的股票数据全部爬取并以excel文件保存在本地。</p> 
<p>查看网页源代码发现并没有目标数据，因此需要对网页进行抓包分析，查看哪个文件里包含目标数据，打开开发者模式（F12），找到目标文件</p> 
<p><img alt="" height="1200" src="https://images2.imgbox.com/84/87/ZMLb5xAJ_o.png" width="1200"></p> 
<p>首先查看url，获取沪京深A股的第一页数据</p> 
<pre><code class="language-python"># 沪深京A股
url = "https://62.push2.eastmoney.com/api/qt/clist/get?cb=jQuery1124007675389012158473_1703949729655&amp;pn=1&amp;pz=20&amp;po=1&amp;np=1&amp;ut=bd1d9ddb04089700cf9c27f6f7426281&amp;fltt=2&amp;invt=2&amp;wbp2u=|0|0|0|web&amp;fid=f3&amp;fs=m:0+t:6,m:0+t:80,m:1+t:2,m:1+t:23,m:0+t:81+s:2048&amp;fields=f1,f2,f3,f4,f5,f6,f7,f8,f9,f10,f12,f13,f14,f15,f16,f17,f18,f20,f21,f23,f24,f25,f22,f11,f62,f128,f136,f115,f152&amp;_=1703949729656"</code></pre> 
<p></p> 
<p>访问形式为GET</p> 
<p>查看预览，发现需要爬取的数据在文件的‘data’中的'diff'里面，对应的文件数据如下图所示：</p> 
<p><img alt="" height="911" src="https://images2.imgbox.com/52/86/AkbeXuQ4_o.png" width="1057"></p> 
<p>通过观察发现，该数据无法直接转换成json文件，需要删除上图中的红框内容，需要用正则表达式替换成空字符串</p> 
<pre><code class="language-python">data = response.text
# 找到开头到第一个'('的部分
left_data = re.search(r'^.*?(?=\()', data).group()
# 将匹配到的内容加上'('替换成空字符串
data = re.sub(left_data + '\(', '', data)
# 将结尾的');'替换成空字符串
data = re.sub('\);', '', data)
# 用eval将data转换成字典
data = eval(data)
</code></pre> 
<p>注意：这里在匹配开头内容时，如果使用下面的语句直接匹配到'jQuery1124007675389012158473_1703949729655('再进行替换的话会出现错误</p> 
<pre><code class="language-python">left_data = re.search(r'^.*?\(', data).group()
print(left_data)
data = re.sub(left_data, '', data)</code></pre> 
<p><img alt="" height="301" src="https://images2.imgbox.com/cf/aa/arugTzoA_o.png" width="616"></p> 
<p>出现这个错误的原因是出现了圆括号但是没有<a href="https://so.csdn.net/so/search?q=%E8%BD%AC%E4%B9%89&amp;spm=1001.2101.3001.7020" title="转义">转义</a>，导致被当成捕获组，将括号转义（前面加上斜杠）即可解决。因此需要先匹配出'('之前的部分，在替代文本里拼接上'\('才能进行成功替换。</p> 
<p></p> 
<p><img alt="" height="1200" src="https://images2.imgbox.com/8f/9d/mAMhLzCy_o.png" width="1200"></p> 
<p>将目标数据转换成字典类型后，我们需要提取出其中data下面diff的内容，并通过定义一个字典来存储我们需要的数据，通过观察网页表头和文件代码对应关系，定义以下的字典：</p> 
<pre><code class="language-python">df = data['data']['diff']
for index in df:
    dict = {
            "代码": index["f12"],
            "名称": index['f14'],
            "最新价": index['f2'],
            "涨跌幅": index['f3'],
            "涨跌额": index['f4'],
            "成交量（手）": index['f5'],
            "成交额": index['f6'],
            "振幅(%)": index['f7'],
            "最高": index['f15'],
            "最低": index['f16'],
            "今开": index['f17'],
            "昨收": index['f18'],
            "量比": index['f10'],
            "换手率": index['f8'],
            "市盈率(动态)": index['f9'],
            "市净率": index['f23'],
           }
              </code></pre> 
<p>同时通过翻页和选其他板块来观察url，发现规律如下图：</p> 
<p><img alt="" height="581" src="https://images2.imgbox.com/72/a1/phKXipEx_o.png" width="1200">红框为页码数，蓝色代码部分为对应的不同板块，因此定义一个字典来保存各个板块的代码，用于循环抓取：</p> 
<pre><code class="language-python">cmd = {
    "沪深京A股": "f3&amp;fs=m:0+t:6,m:0+t:80,m:1+t:2,m:1+t:23,m:0+t:81+s:2048",
    "上证A股": "f3&amp;fs=m:1+t:2,m:1+t:23",
    "深证A股": "f3&amp;fs=m:0+t:6,m:0+t:80",
    "北证A股": "f3&amp;fs=m:0+t:81+s:2048",
    "新股": "f26&amp;fs=m:0+f:8,m:1+f:8",
    "创业板": "f3&amp;fs=m:0+t:80",
    "科创板": "f3&amp;fs=m:1+t:23",
    "沪股通": "f26&amp;fs=b:BK0707",
    "深股通": "f26&amp;fs=b:BK0804",
    "B股": "f3&amp;fs=m:0+t:7,m:1+t:3",
    "风险警示板": "f3&amp;fs=m:0+f:4,m:1+f:4",
}</code></pre> 
<p>在爬取时，需要判定何时停止爬取当前板块，下图显示沪深京A股有279页，我们通过修改url中的页码字段为280来查看返回什么<img alt="" height="1200" src="https://images2.imgbox.com/18/de/8LqFHIv7_o.png" width="1200"><img alt="" height="82" src="https://images2.imgbox.com/0f/b0/oLSmz9vR_o.png" width="968"></p> 
<p>可以看到返回的文件中，data后为null，因此，在每个板块循环爬取时，只要碰到页码的返回文件中data的内容为null时，则停止爬取当前板块。同时由于返回文件中，data后的内容是以null变量的形式展示的，我们需要定义一个变量null，否则会出现报错NameError: name 'null' is not defined</p> 
<pre><code class="language-python">null = "null"
for i in cmd.keys():
    page = 0
    stocks = []
    while True:
        page += 1
        data = get_html(cmd[i], page)
        if data['data'] != null:
            print("正在爬取"+i+"第"+str(page)+"页")
            df = data['data']['diff']
            for index in df:
                dict = {
                        "代码": index["f12"],
                        "名称": index['f14'],
                        "最新价": index['f2'],
                        "涨跌幅": index['f3'],
                        "涨跌额": index['f4'],
                        "成交量（手）": index['f5'],
                        "成交额": index['f6'],
                        "振幅(%)": index['f7'],
                        "最高": index['f15'],
                        "最低": index['f16'],
                        "今开": index['f17'],
                        "昨收": index['f18'],
                        "量比": index['f10'],
                        "换手率": index['f8'],
                        "市盈率(动态)": index['f9'],
                        "市净率": index['f23'],
                    }
                stocks.append(dict)
        else:
            break
    df = pd.DataFrame(stocks)
    df.to_excel("股票_"+i+".xlsx", index=False)</code></pre> 
<p>执行结果如下：</p> 
<p><img alt="" height="248" src="https://images2.imgbox.com/ae/a9/3cPrlJF9_o.png" width="208"></p> 
<p><img alt="" height="1042" src="https://images2.imgbox.com/1e/cc/3uKDnI2t_o.png" width="1200"></p> 
<p>完整源代码：</p> 
<pre><code class="language-python">import requests
import re
import pandas as pd


header = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Cookie": "qgqp_b_id=18c28b304dff3b8ce113d0cca03e6727; websitepoptg_api_time=1703860143525; st_si=92728505415389; st_asi=delete; HAList=ty-100-HSI-%u6052%u751F%u6307%u6570; st_pvi=46517537371152; st_sp=2023-10-29%2017%3A00%3A19; st_inirUrl=https%3A%2F%2Fcn.bing.com%2F; st_sn=8; st_psi=20231229230312485-113200301321-2076002087"
}


def get_html(cmd, page):
    url = f"https://7.push2.eastmoney.com/api/qt/clist/get?cb=jQuery112409467675731682619_1703939377395&amp;pn={page}&amp;pz=20&amp;po=1&amp;np=1&amp;ut=bd1d9ddb04089700cf9c27f6f7426281&amp;fltt=2&amp;invt=2&amp;wbp2u=|0|0|0|web&amp;fid={cmd}&amp;fields=f1,f2,f3,f4,f5,f6,f7,f8,f9,f10,f12,f13,f14,f15,f16,f17,f18,f20,f21,f23,f24,f25,f22,f11,f62,f128,f136,f115,f152&amp;_=1703939377396"
    response = requests.get(url, headers=header)
    data = response.text
    left_data = re.search(r'^.*?(?=\()', data).group()
    data = re.sub(left_data + '\(', '', data)
    # right_data = re.search(r'\)', data).group()
    data = re.sub('\);', '', data)
    data = eval(data)
    return data


cmd = {
    "沪深京A股": "f3&amp;fs=m:0+t:6,m:0+t:80,m:1+t:2,m:1+t:23,m:0+t:81+s:2048",
    "上证A股": "f3&amp;fs=m:1+t:2,m:1+t:23",
    "深证A股": "f3&amp;fs=m:0+t:6,m:0+t:80",
    "北证A股": "f3&amp;fs=m:0+t:81+s:2048",
    "新股": "f26&amp;fs=m:0+f:8,m:1+f:8",
    "创业板": "f3&amp;fs=m:0+t:80",
    "科创板": "f3&amp;fs=m:1+t:23",
    "沪股通": "f26&amp;fs=b:BK0707",
    "深股通": "f26&amp;fs=b:BK0804",
    "B股": "f3&amp;fs=m:0+t:7,m:1+t:3",
    "风险警示板": "f3&amp;fs=m:0+f:4,m:1+f:4",
}

null = "null"
for i in cmd.keys():
    page = 0
    stocks = []
    while True:
        page += 1
        data = get_html(cmd[i], page)
        if data['data'] != null:
            print("正在爬取"+i+"第"+str(page)+"页")
            df = data['data']['diff']
            for index in df:
                dict = {
                        "代码": index["f12"],
                        "名称": index['f14'],
                        "最新价": index['f2'],
                        "涨跌幅": index['f3'],
                        "涨跌额": index['f4'],
                        "成交量（手）": index['f5'],
                        "成交额": index['f6'],
                        "振幅(%)": index['f7'],
                        "最高": index['f15'],
                        "最低": index['f16'],
                        "今开": index['f17'],
                        "昨收": index['f18'],
                        "量比": index['f10'],
                        "换手率": index['f8'],
                        "市盈率(动态)": index['f9'],
                        "市净率": index['f23'],
                    }
                stocks.append(dict)
        else:
            break
    df = pd.DataFrame(stocks)
    df.to_excel("股票_"+i+".xlsx", index=False)
</code></pre> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/bdd194209730261864669050a1e0c29e/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Python face-recognition库，dlib库安装方法（附下载文件）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/4a967fc775e3f7448657a12fe64739c2/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">人工智能与医疗诊断：AI在医学影像诊断中的应用</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>