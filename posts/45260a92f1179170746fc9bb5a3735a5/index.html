<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【Datawhale AI 夏令营2024--CV】5 分钟体验一站式 baseline - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/45260a92f1179170746fc9bb5a3735a5/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="【Datawhale AI 夏令营2024--CV】5 分钟体验一站式 baseline">
  <meta property="og:description" content="一、赛题背景 随着人工智能技术的迅猛发展，深度伪造技术（Deepfake）正成为数字世界中的一把双刃剑。这项技术不仅为创意内容的生成提供了新的可能性，同时也对数字安全构成了前所未有的挑战。Deepfake技术可以通过人工智能算法生成高度逼真的图像、视频和音频内容，这些内容看起来与真实的毫无二致。然而，这也意味着虚假信息、欺诈行为和隐私侵害等问题变得更加严重和复杂。
为了应对这一挑战，我们举办了“外滩大会 - 全球Deepfake攻防挑战赛”。该挑战赛旨在邀请全球的参与者开发、测试和改进更加准确、有效和创新的检测模型，以应对各种类型的Deepfake攻击。这些模型将在真实世界的场景中进行测试，从而推动创新防御策略的发展，提高Deepfake识别的准确性。此次挑战赛不仅是对技术的比拼，更是对全球数字安全的一次重要贡献。我们期待着通过这次比赛，能够激发更多的创新思维和技术突破，共同应对Deepfake带来的安全威胁，保护数字世界的安全与真实性。
二、赛题任务 在这个赛道中，比赛任务是判断一张人脸图像是否为Deepfake图像，并输出其为Deepfake图像的概率评分。参赛者需要开发和优化检测模型，以应对多样化的Deepfake生成技术和复杂的应用场景，从而提升Deepfake图像检测的准确性和鲁棒性。
三、赛题数据集 1、第一阶段 在第一阶段，主办方将发布训练集和验证集。参赛者将使用训练集 (train_label.txt) 来训练模型，而验证集 (val_label.txt) 仅用于模型调优。文件的每一行包含两个部分，分别是图片文件名和标签值（label=1 表示Deepfake图像，label=0 表示真实人脸图像）。例如：
train_label.txt
img_name,target 3381ccbc4df9e7778b720d53a2987014.jpg,1 63fee8a89581307c0b4fd05a48e0ff79.jpg,0 7eb4553a58ab5a05ba59b40725c903fd.jpg,0 … val_label.txt
img_name,target cd0e3907b3312f6046b98187fc25f9c7.jpg,1 aa92be19d0adf91a641301cfcce71e8a.jpg,0 5413a0b706d33ed0208e2e4e2cacaa06.jpg,0 … 2、第二阶段 在第一阶段结束后，主办方将发布测试集。在第二阶段，参赛者需要在系统中提交测试集的预测评分文件 (prediction.txt)，主办方将在线反馈测试评分结果。文件的每一行包含两个部分，分别是图片文件名和模型预测的Deepfake评分（即样本属于Deepfake图像的概率值）。例如：
prediction.txt
img_name,y_pred cd0e3907b3312f6046b98187fc25f9c7.jpg,1 aa92be19d0adf91a641301cfcce71e8a.jpg,0.5 5413a0b706d33ed0208e2e4e2cacaa06.jpg,0.5 … 3、第三阶段 在第二阶段结束后，前30名队伍将晋级到第三阶段。在这一阶段，参赛者需要提交代码docker和技术报告。Docker要求包括原始训练代码和测试API（函数输入为图像路径，输出为模型预测的Deepfake评分）。主办方将检查并重新运行算法代码，以重现训练过程和测试结果。
三、评价指标 评估指标 比赛的性能评估主要使用ROC曲线下的AUC（Area under the ROC Curve）作为指标。AUC的取值范围通常在0.5到1之间。若AUC指标不能区分排名，则会使用TPR@FPR=1E-3作为辅助参考。
相关公式：
真阳性率 (TPR)：
TPR = TP / (TP &#43; FN)
假阳性率 (FPR)：
FPR = FP / (FP &#43; TN)
其中：
TP：攻击样本被正确识别为攻击；TN：真实样本被正确识别为真实；FP：真实样本被错误识别为攻击；FN：攻击样本被错误识别为真实。 参考文献：Aghajan, H., Augusto, J.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-07-12T02:43:18+08:00">
    <meta property="article:modified_time" content="2024-07-12T02:43:18+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【Datawhale AI 夏令营2024--CV】5 分钟体验一站式 baseline</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2 id="赛题背景">一、赛题背景</h2> 
<p>        随着人工智能技术的迅猛发展，深度伪造技术（Deepfake）正成为数字世界中的一把双刃剑。这项技术不仅为创意内容的生成提供了新的可能性，同时也对数字安全构成了前所未有的挑战。Deepfake技术可以通过人工智能算法生成高度逼真的图像、视频和音频内容，这些内容看起来与真实的毫无二致。然而，这也意味着虚假信息、欺诈行为和隐私侵害等问题变得更加严重和复杂。</p> 
<p>        为了应对这一挑战，我们举办了“外滩大会 - 全球Deepfake攻防挑战赛”。该挑战赛旨在邀请全球的参与者开发、测试和改进更加准确、有效和创新的检测模型，以应对各种类型的Deepfake攻击。这些模型将在真实世界的场景中进行测试，从而推动创新防御策略的发展，提高Deepfake识别的准确性。此次挑战赛不仅是对技术的比拼，更是对全球数字安全的一次重要贡献。我们期待着通过这次比赛，能够激发更多的创新思维和技术突破，共同应对Deepfake带来的安全威胁，保护数字世界的安全与真实性。</p> 
<p></p> 
<h2 id="赛题任务">二、赛题任务</h2> 
<p>        在这个赛道中，比赛任务是判断一张人脸图像是否为Deepfake图像，并输出其为Deepfake图像的概率评分。参赛者需要开发和优化检测模型，以应对多样化的Deepfake生成技术和复杂的应用场景，从而提升Deepfake图像检测的准确性和鲁棒性。</p> 
<p></p> 
<h2 id="赛题数据集">三、赛题数据集</h2> 
<h3 id="第一阶段">1、第一阶段</h3> 
<p>        在第一阶段，主办方将发布训练集和验证集。参赛者将使用训练集 (train_label.txt) 来训练模型，而验证集 (val_label.txt) 仅用于模型调优。文件的每一行包含两个部分，分别是图片文件名和标签值（label=1 表示Deepfake图像，label=0 表示真实人脸图像）。例如：</p> 
<p><strong>train_label.txt</strong></p> 
<pre><code>img_name,target
3381ccbc4df9e7778b720d53a2987014.jpg,1
63fee8a89581307c0b4fd05a48e0ff79.jpg,0
7eb4553a58ab5a05ba59b40725c903fd.jpg,0
…</code></pre> 
<p><strong>val_label.txt</strong></p> 
<pre><code>img_name,target
cd0e3907b3312f6046b98187fc25f9c7.jpg,1
aa92be19d0adf91a641301cfcce71e8a.jpg,0
5413a0b706d33ed0208e2e4e2cacaa06.jpg,0
…</code></pre> 
<h3 id="第二阶段">2、第二阶段</h3> 
<p>        在第一阶段结束后，主办方将发布测试集。在第二阶段，参赛者需要在系统中提交测试集的预测评分文件 (prediction.txt)，主办方将在线反馈测试评分结果。文件的每一行包含两个部分，分别是图片文件名和模型预测的Deepfake评分（即样本属于Deepfake图像的概率值）。例如：</p> 
<p><strong>prediction.txt</strong></p> 
<pre><code>img_name,y_pred
cd0e3907b3312f6046b98187fc25f9c7.jpg,1
aa92be19d0adf91a641301cfcce71e8a.jpg,0.5
5413a0b706d33ed0208e2e4e2cacaa06.jpg,0.5
…</code></pre> 
<h3 id="第三阶段">3、第三阶段</h3> 
<p>        在第二阶段结束后，前30名队伍将晋级到第三阶段。在这一阶段，参赛者需要提交代码docker和技术报告。Docker要求包括原始训练代码和测试API（函数输入为图像路径，输出为模型预测的Deepfake评分）。主办方将检查并重新运行算法代码，以重现训练过程和测试结果。</p> 
<p></p> 
<h2 id="评价指标">三、评价指标</h2> 
<h5 id="评估指标">评估指标</h5> 
<p>比赛的性能评估主要使用ROC曲线下的AUC（Area under the ROC Curve）作为指标。AUC的取值范围通常在0.5到1之间。若AUC指标不能区分排名，则会使用TPR@FPR=1E-3作为辅助参考。</p> 
<p><strong>相关公式：</strong></p> 
<blockquote> 
 <p>真阳性率 (TPR)：</p> 
 <p>TPR = TP / (TP + FN)</p> 
 <p>假阳性率 (FPR)：</p> 
 <p>FPR = FP / (FP + TN)</p> 
 <p>其中：</p> 
 <ul><li>TP：攻击样本被正确识别为攻击；</li><li>TN：真实样本被正确识别为真实；</li><li>FP：真实样本被错误识别为攻击；</li><li>FN：攻击样本被错误识别为真实。</li></ul> 
</blockquote> 
<p>参考文献：<a href="https://books.google.com/books?hl=zh-CN&amp;lr=&amp;id=64icBAAAQBAJ&amp;oi=fnd&amp;pg=PP1&amp;dq=Human-centric+interfaces+for+ambient+intelligence&amp;ots=mKNsJrymuK&amp;sig=_ZrNLwqT9R6BDddTLy02FF1B3WE" rel="nofollow" title="Aghajan, H., Augusto, J. C., &amp; Delgado, R. L. C. (Eds.). (2009). Human-centric interfaces for ambient intelligence. Academic Press.">Aghajan, H., Augusto, J. C., &amp; Delgado, R. L. C. (Eds.). (2009). Human-centric interfaces for ambient intelligence. Academic Press.</a></p> 
<p></p> 
<h2>四、baseline解析</h2> 
<ul><li><code>import torch</code>: 导入PyTorch库。</li><li><code>torch.manual_seed(0)</code>: 设置PyTorch的随机种子为0，这样可以保证每次运行时生成的随机数是固定的，有助于结果的复现性。</li><li><code>torch.backends.cudnn.deterministic = False</code>: 如果使用了CuDNN（CUDA深度神经网络库），此行代码表示不使用确定性算法，可以提高性能。</li><li><code>torch.backends.cudnn.benchmark = True</code>: 启用CuDNN的自动寻找最适合当前配置的高效算法，以提升性能。</li></ul> 
<pre><code class="language-python">import torch
torch.manual_seed(0)
torch.backends.cudnn.deterministic = False
torch.backends.cudnn.benchmark = True</code></pre> 
<p></p> 
<h4>导入了一些PyTorch和相关库的模块和函数，用于构建和训练深度学习模型。</h4> 
<ul><li><code>torchvision.models</code>：包含了常见的预训练模型，如AlexNet、ResNet等。</li><li><code>torchvision.transforms</code>：包含常见的图像变换操作，如裁剪、旋转、缩放等。</li><li><code>torchvision.datasets</code>：包含常见的数据集，如MNIST、CIFAR-10等。</li><li><code>torch.nn</code>：定义了神经网络层的接口和功能。</li><li><code>torch.optim</code>：包含了优化器，如SGD、Adam等。</li><li><code>torch.autograd.Variable</code>：提供了自动求导机制的变量类型。</li><li><code>torch.utils.data.dataset.Dataset</code>：定义了一个抽象的数据集类，用于自定义数据集。</li><li><code>timm</code>：一个用于图像模型的库，提供了大量现代化的模型架构。</li><li><code>time</code>：Python的时间处理库，通常用于计时或延时操作。</li></ul> 
<pre><code class="language-python">import torchvision.models as models
import torchvision.transforms as transforms
import torchvision.datasets as datasets
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.autograd import Variable
from torch.utils.data.dataset import Dataset
import timm
import time</code></pre> 
<p></p> 
<h4>导入了一些常见的数据处理和图像处理相关的库。</h4> 
<ul><li><code>pandas</code>：用于数据操作和分析，例如读取CSV文件。</li><li><code>numpy</code>：用于科学计算，支持多维数组和矩阵运算。</li><li><code>cv2</code>：OpenCV库，用于图像处理和计算机视觉任务。</li><li><code>PIL.Image</code>：Python Imaging Library，用于图像处理，如打开、保存、裁剪等。</li><li><code>tqdm_notebook</code>：用于在Jupyter Notebook中显示进度条，便于监控长时间运行的任务进度。</li></ul> 
<pre><code class="language-python">import pandas as pd
import numpy as np
import cv2
from PIL import Image
from tqdm import tqdm_notebook</code></pre> 
<p></p> 
<h4>读取了CSV格式的标签文件，并为每条数据添加了图像路径的列。</h4> 
<ul><li><code>pd.read_csv()</code>：使用pandas库读取CSV文件，将其转换为DataFrame格式。</li><li><code>train_label['path']</code>和<code>val_label['path']</code>：为每个数据样本添加了图像的完整路径，方便后续读取和处理图像数据。</li></ul> 
<pre><code class="language-python">train_label = pd.read_csv('/kaggle/input/deepfake/phase1/trainset_label.txt')
val_label = pd.read_csv('/kaggle/input/deepfake/phase1/valset_label.txt')

train_label['path'] = '/kaggle/input/deepfake/phase1/trainset/' + train_label['img_name']
val_label['path'] = '/kaggle/input/deepfake/phase1/valset/' + val_label['img_name']</code></pre> 
<pre><code class="language-python"># 统计train_label DataFrame 中 target 列中每个不同取值的频数（即每个类别的样本数量）
train_label['target'].value_counts()

# 对 val_label DataFrame 中 target 列进行统计，获取每个不同类别的样本数量。
val_label['target'].value_counts()

# 一个 pandas DataFrame 的函数调用，用于查看 train_label DataFrame 的前 10 行数据
train_label.head(10)</code></pre> 
<h3 id="模型训练与验证">2、模型训练与验证</h3> 
<pre><code class="language-python">class AverageMeter(object):
    """Computes and stores the average and current value"""
    def __init__(self, name, fmt=':f'):
        self.name = name    # 存储指标名称
        self.fmt = fmt      # 格式化字符串，用于打印输出
        self.reset()        # 调用 reset 方法初始化对象

    def reset(self):
        self.val = 0        # 当前值初始化为 0
        self.avg = 0        # 平均值初始化为 0
        self.sum = 0        # 值的总和初始化为 0
        self.count = 0      # 更新次数计数初始化为 0

    def update(self, val, n=1):
        self.val = val            # 更新当前值为给定的 val
        self.sum += val * n       # 将 val * n 累加到总和 sum 中
        self.count += n           # 更新计数器 count，增加 n
        self.avg = self.sum / self.count    # 计算新的平均值

    def __str__(self):
        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'
        return fmtstr.format(**self.__dict__)

class ProgressMeter(object):
    def __init__(self, num_batches, *meters):
        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)    # 获取批次格式化字符串
        self.meters = meters        # 存储所有的指标对象
        self.prefix = ""            # 前缀，用于输出时添加在格式化字符串前


    def pr2int(self, batch):
        entries = [self.prefix + self.batch_fmtstr.format(batch)]    # 添加批次信息
        entries += [str(meter) for meter in self.meters]             # 添加每个指标的字符串表示
        print('\t'.join(entries))        # 打印输出，以制表符分隔每个条目

    def _get_batch_fmtstr(self, num_batches):
        num_digits = len(str(num_batches // 1))        # 计算批次数的位数
        fmt = '{:' + str(num_digits) + 'd}'            # 格式化字符串，用于输出批次信息
        return '[' + fmt + '/' + fmt.format(num_batches) + ']'    # 返回格式化后的批次信息字符串</code></pre> 
<p></p> 
<pre><code class="language-python">def validate(val_loader, model, criterion):
    batch_time = AverageMeter('Time', ':6.3f')
    losses = AverageMeter('Loss', ':.4e')
    top1 = AverageMeter('Acc@1', ':6.2f')
    progress = ProgressMeter(len(val_loader), batch_time, losses, top1)

    # switch to evaluate mode
    model.eval()

    with torch.no_grad():
        end = time.time()
        for i, (input, target) in tqdm_notebook(enumerate(val_loader), total=len(val_loader)):
            input = input.cuda()
            target = target.cuda()

            # compute output
            output = model(input)
            loss = criterion(output, target)

            # measure accuracy and record loss
            acc = (output.argmax(1).view(-1) == target.float().view(-1)).float().mean() * 100
            losses.update(loss.item(), input.size(0))
            top1.update(acc, input.size(0))
            # measure elapsed time
            batch_time.update(time.time() - end)
            end = time.time()

        # TODO: this should also be done with the ProgressMeter
        print(' * Acc@1 {top1.avg:.3f}'
              .format(top1=top1))
        return top1</code></pre> 
<pre><code class="language-python">def predict(test_loader, model, tta=10):
    # switch to evaluate mode
    model.eval()
    
    test_pred_tta = None
    for _ in range(tta):
        test_pred = []
        with torch.no_grad():
            end = time.time()
            for i, (input, target) in tqdm_notebook(enumerate(test_loader), total=len(test_loader)):
                input = input.cuda()
                target = target.cuda()

                # compute output
                output = model(input)
                output = F.softmax(output, dim=1)
                output = output.data.cpu().numpy()

                test_pred.append(output)
        test_pred = np.vstack(test_pred)
    
        if test_pred_tta is None:
            test_pred_tta = test_pred
        else:
            test_pred_tta += test_pred
    
    return test_pred_tta</code></pre> 
<pre><code class="language-python">def train(train_loader, model, criterion, optimizer, epoch):
    batch_time = AverageMeter('Time', ':6.3f')
    losses = AverageMeter('Loss', ':.4e')
    top1 = AverageMeter('Acc@1', ':6.2f')
    progress = ProgressMeter(len(train_loader), batch_time, losses, top1)

    # switch to train mode
    model.train()

    end = time.time()
    for i, (input, target) in enumerate(train_loader):
        input = input.cuda(non_blocking=True)
        target = target.cuda(non_blocking=True)

        # compute output
        output = model(input)
        loss = criterion(output, target)

        # measure accuracy and record loss
        losses.update(loss.item(), input.size(0))

        acc = (output.argmax(1).view(-1) == target.float().view(-1)).float().mean() * 100
        top1.update(acc, input.size(0))

        # compute gradient and do SGD step
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        # measure elapsed time
        batch_time.update(time.time() - end)
        end = time.time()

        if i % 100 == 0:
            progress.pr2int(i)</code></pre> 
<pre><code class="language-python">class FFDIDataset(Dataset):
    def __init__(self, img_path, img_label, transform=None):
        self.img_path = img_path
        self.img_label = img_label
        
        if transform is not None:
            self.transform = transform
        else:
            self.transform = None
    
    def __getitem__(self, index):
        img = Image.open(self.img_path[index]).convert('RGB')
        
        if self.transform is not None:
            img = self.transform(img)
        
        return img, torch.from_numpy(np.array(self.img_label[index]))
    
    def __len__(self):
        return len(self.img_path)</code></pre> 
<h3 id="加载模型">3、加载模型</h3> 
<pre><code class="language-python">import timm
model = timm.create_model('resnet18', pretrained=True, num_classes=2)
model = model.cuda()</code></pre> 
<pre><code class="language-python">train_loader = torch.utils.data.DataLoader(
    FFDIDataset(train_label['path'].head(1000), train_label['target'].head(1000), 
            transforms.Compose([
                        transforms.Resize((256, 256)),
                        transforms.RandomHorizontalFlip(),
                        transforms.RandomVerticalFlip(),
                        transforms.ToTensor(),
                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
    ), batch_size=40, shuffle=True, num_workers=4, pin_memory=True
)

val_loader = torch.utils.data.DataLoader(
    FFDIDataset(val_label['path'].head(1000), val_label['target'].head(1000), 
            transforms.Compose([
                        transforms.Resize((256, 256)),
                        transforms.ToTensor(),
                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
    ), batch_size=40, shuffle=False, num_workers=4, pin_memory=True
)

criterion = nn.CrossEntropyLoss().cuda()
optimizer = torch.optim.Adam(model.parameters(), 0.005)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.85)
best_acc = 0.0
for epoch in range(2):
    scheduler.step()
    print('Epoch: ', epoch)

    train(train_loader, model, criterion, optimizer, epoch)
    val_acc = validate(val_loader, model, criterion)
    
    if val_acc.avg.item() &gt; best_acc:
        best_acc = round(val_acc.avg.item(), 2)
        torch.save(model.state_dict(), f'./model_{best_acc}.pt')</code></pre> 
<pre><code class="language-python">test_loader = torch.utils.data.DataLoader(
    FFDIDataset(val_label['path'], val_label['target'], 
            transforms.Compose([
                        transforms.Resize((256, 256)),
                        transforms.ToTensor(),
                        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
    ), batch_size=40, shuffle=False, num_workers=4, pin_memory=True
)

val_label['y_pred'] = predict(test_loader, model, 1)[:, 1]
val_label[['img_name', 'y_pred']].to_csv('submit.csv', index=None)</code></pre> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/efa3483e76cc3aa0973e0e914cd54ad3/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">人工智能的新前沿：为数据源带来智能</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/f5e9a52d4f144da1d1ec51a83678088e/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">[notice] A new release of pip is available: 24.0 -＞ 24.1.2[notice] To update, run: python.exe -m pi</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>