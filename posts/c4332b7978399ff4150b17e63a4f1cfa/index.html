<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>最完整的Web视频加密播放技术实现(含技术调研和Demo源码) - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/c4332b7978399ff4150b17e63a4f1cfa/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="最完整的Web视频加密播放技术实现(含技术调研和Demo源码)">
  <meta property="og:description" content="原文来源于：程序员成长指北，作者：然燃 如有侵权，联系删除
最近又遇到了web视频化的场景，之前也有过调研：H5视频化调研浅析1
但这次稍微复杂一些，这次解决的是：
视频播放的技术方案调研
服务端实现：
视频转码
生成不同码率的视频
进行视频标准加密
不同码率视频合并，用于动态码率播放
web端实现
web端播放器的设计
web端播放器的自定义扩展
可拖拽进度条
音量控制
根据当前带宽自适应码率切换
手动清晰度切换
倍速播放
样式自定义覆盖
标准加密视频播放
基于原生开发，可在所有框架运行，统一跨框架情况
各浏览器控件统一
其中web端源码已添加MIT协议并完全开源，如果看完对大家有帮助的话，欢迎大家star,issue,pr，也希望能友好交流～
demo地址：⇲https://chaxus.github.io/ran/src/ranui/player/
源码地址：⇲https://github.com/chaxus/ran/tree/main/packages/ranui
demo文档做了国际化，可切换到中文
任何一个项目，立项肯定先是技术调研，我们先看看一些大公司的视频播放方案
#一.一些知名公司的web视频播放方案 #1.B站 我们先看看B站的，毕竟B站的主营业务就是视频弹幕网站，简直专业对口。
先找一个例子：⇲www.bilibili.com/video/BV1FM…⇲2 访问它。
打开控制台，可以看到，视频在播放的时候，会不断的请求m4s的视频文件。
毕竟一整个视频文件往往比较大，不可能先请求完视频文件，再进行播放。因此将一个大的视频文件分割成很多小的片段，边加载边播放，是一种更好的方式。
每次请求的m4s文件大概在几十kb到几百kb不等。
那为什么不采用http的range呢，可以请求一个文件的部分内容，而且粒度更细，可以设置字节范围。在http请求的header中，类似这样
Range: bytes=3171375-3203867 我们可以检查这个链接请求https://upos-sz-mirror08c.bilivideo.com/upgcxcode/67/92/1008149267/1008149267-1-30064.m4s的请求头，就能发现，B站采用的是，即分片加载，同时还用了range的方式。
#2. 爱奇艺：（爱奇艺、土豆、优酷） 爱奇艺这里就不贴视频链接了，因为随便点一个视频，都要先看广告。
爱奇艺的视频主要请求的是f4v格式，也是分片加载。
播放一个视频时，请求多个f4v文件。
也采用Range。但和B站不一样的是，B站的Range属性是在m4s请求的请求头里面，而爱奇艺的看起来是在querystring上，在请求query上带着range参数。
因为没发现这个请求的header里面有range参数。比如： https://v-6fce1712.71edge.com/videos/other/20231113/6b/bb/3f3fe83b89124248c3216156dfe2f4c3.f4v?dis_k=2ba39ee8c55c4d23781e3fb9f91fa7a46&amp;dis_t=1701439831&amp;dis_dz=CNC-BeiJing&amp;dis_st=46&amp;src=iqiyi.com&amp;dis_hit=0&amp;dis_tag=01010000&amp;uuid=72713f52-6569e957-351&amp;cross-domain=1&amp;ssl=1&amp;pv=0.1&amp;cphc=arta&amp;range=0-9000
#3.抖音： 抖音的方案简单粗暴，访问的链接是这个： ⇲m.ixigua.com/douyin/shar…⇲3
通过查看控制台，我们可以发现，直接请求了一个视频的地址
没有进行分片，但用到了请求range，所以可以看到视频，是边播放边缓冲一部分。
不过我在开发的时候发现，目前租用的服务云厂商，默认会帮我们实现这项技术。
因为我把mp4视频上传到云服务器，通过链接进行播放的时候，就是边缓冲边播放的。
我们可以直接把这个视频地址拿出来，放到浏览器里面能直接播放，这样观察更明显。
但B站和爱奇艺却不能这样，因为他们采用的m4s和f4v都不是一种通用的视频格式，需要使用专门的软件或工具才能打开和编辑。
#4.小红书： 测试用的例子链接：⇲www.xiaohongshu.com/discovery/i…⇲4
小红书的方案更加简单粗暴，打开控制台，直接告诉你就是请求一个mp4，然后直接播放就完事了。
#5.总结 看完了以上的各家大厂的方案，我们可以看到，基本原理都是边播放边加载，减少直接加载大视频文本的成本。并且通过分片传输，还能动态控制视频码率（清晰度）。做到根据网速，加载不同码率的分片文件，做到动态码率适应。
同时采用的视频格式，比如f4v，m4s，都不是能直接播放的媒体格式，需要一定的处理。增加盗取视频的成本，增加一定的安全性。
如果没有强要求，也可以直接采用mp4，或者直接用video播放一个视频文件地址。
#二.常见的视频格式与协议 我们知道视频的常见格式有mp4，同时上面介绍了B站播放用的m4s格式，爱奇艺用的f4v格式
•除了这些还有哪些视频格式？
•为什么有这么多视频格式，有哪些不同点呢？
•为什么这些公司会采用这种格式来播放视频呢？
#1. B站用的m4s M4S格式不是一种通用的视频格式，需要使用专门的软件或工具才能打开和编辑。">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-06-19T13:27:29+08:00">
    <meta property="article:modified_time" content="2024-06-19T13:27:29+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">最完整的Web视频加密播放技术实现(含技术调研和Demo源码)</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <blockquote> 
 <p>原文来源于：程序员成长指北，作者：然燃 </p> 
 <p>如有侵权，联系删除</p> 
</blockquote> 
<p>最近又遇到了<code>web</code>视频化的场景，之前也有过调研：H5视频化调研浅析1</p> 
<p>但这次稍微复杂一些，这次解决的是：</p> 
<ol><li> <p>视频播放的技术方案调研</p> </li></ol> 
<p>服务端实现：</p> 
<ol><li> <p>视频转码</p> </li><li> <p>生成不同码率的视频</p> </li><li> <p>进行视频标准加密</p> </li><li> <p>不同码率视频合并，用于动态码率播放</p> </li></ol> 
<p><code>web</code>端实现</p> 
<ol><li> <p><code>web</code>端播放器的设计</p> </li><li> <p><code>web</code>端播放器的自定义扩展</p> </li><li> <p>可拖拽进度条</p> </li><li> <p>音量控制</p> </li><li> <p>根据当前带宽自适应码率切换</p> </li><li> <p>手动清晰度切换</p> </li><li> <p>倍速播放</p> </li><li> <p>样式自定义覆盖</p> </li><li> <p>标准加密视频播放</p> </li><li> <p>基于原生开发，可在所有框架运行，统一跨框架情况</p> </li><li> <p>各浏览器控件统一</p> </li></ol> 
<p>其中<code>web</code>端源码已添加<code>MIT</code>协议并完全开源，如果看完对大家有帮助的话，欢迎大家<code>star</code>,<code>issue</code>,<code>pr</code>，也希望能友好交流～</p> 
<p>demo地址：⇲https://chaxus.github.io/ran/src/ranui/player/</p> 
<p>源码地址：⇲https://github.com/chaxus/ran/tree/main/packages/ranui</p> 
<p><code>demo</code>文档做了国际化，可切换到中文</p> 
<p>任何一个项目，立项肯定先是技术调研，我们先看看一些大公司的视频播放方案</p> 
<h3>#一.一些知名公司的web视频播放方案</h3> 
<h3>#1.B站</h3> 
<p>我们先看看B站的，毕竟B站的主营业务就是视频弹幕网站，简直专业对口。</p> 
<p>先找一个例子：⇲www.bilibili.com/video/BV1FM…⇲2 访问它。</p> 
<p><img alt="" height="610" src="https://images2.imgbox.com/26/4c/UNeKZHsJ_o.png" width="1080"></p> 
<p>打开控制台，可以看到，视频在播放的时候，会不断的请求<code>m4s</code>的视频文件。</p> 
<p>毕竟一整个视频文件往往比较大，不可能先请求完视频文件，再进行播放。因此将一个大的视频文件分割成很多小的片段，边加载边播放，是一种更好的方式。</p> 
<p></p> 
<p class="img-center"><img alt="图片" height="198" src="https://images2.imgbox.com/22/db/yXbQGt7Q_o.jpg" width="1080"></p> 
<p>每次请求的<code>m4s</code>文件大概在几十<code>kb</code>到几百<code>kb</code>不等。</p> 
<p></p> 
<p class="img-center"><img alt="图片" height="318" src="https://images2.imgbox.com/4d/7c/PWly9hMq_o.jpg" width="1080"></p> 
<p>那为什么不采用<code>http</code>的<code>range</code>呢，可以请求一个文件的部分内容，而且粒度更细，可以设置字节范围。在<code>http</code>请求的<code>header</code>中，类似这样</p> 
<pre><code>Range: bytes=3171375-3203867
</code></pre> 
<p>我们可以检查这个链接请求<code>https://upos-sz-mirror08c.bilivideo.com/upgcxcode/67/92/1008149267/1008149267-1-30064.m4s</code>的请求头，就能发现，B站采用的是，即分片加载，同时还用了<code>range</code>的方式。</p> 
<h3>#2. 爱奇艺：（爱奇艺、土豆、优酷）</h3> 
<p>爱奇艺这里就不贴视频链接了，因为随便点一个视频，都要先看广告。</p> 
<p></p> 
<p class="img-center"><img alt="图片" height="607" src="https://images2.imgbox.com/51/d8/uLawSsah_o.jpg" width="1080"></p> 
<p>爱奇艺的视频主要请求的是<code>f4v</code>格式，也是分片加载。</p> 
<p>播放一个视频时，请求多个<code>f4v</code>文件。</p> 
<p>也采用<code>Range</code>。但和B站不一样的是，B站的<code>Range</code>属性是在<code>m4s</code>请求的请求头里面，而爱奇艺的看起来是在<code>querystring</code>上，在请求<code>query</code>上带着<code>range</code>参数。</p> 
<p>因为没发现这个请求的<code>header</code>里面有<code>range</code>参数。比如： <code>https://v-6fce1712.71edge.com/videos/other/20231113/6b/bb/3f3fe83b89124248c3216156dfe2f4c3.f4v?dis_k=2ba39ee8c55c4d23781e3fb9f91fa7a46&amp;dis_t=1701439831&amp;dis_dz=CNC-BeiJing&amp;dis_st=46&amp;src=iqiyi.com&amp;dis_hit=0&amp;dis_tag=01010000&amp;uuid=72713f52-6569e957-351&amp;cross-domain=1&amp;ssl=1&amp;pv=0.1&amp;cphc=arta&amp;range=0-9000</code></p> 
<h3>#3.抖音：</h3> 
<p>抖音的方案简单粗暴，访问的链接是这个： ⇲m.ixigua.com/douyin/shar…⇲3</p> 
<p>通过查看控制台，我们可以发现，直接请求了一个视频的地址</p> 
<p></p> 
<p class="img-center"><img alt="图片" height="613" src="https://images2.imgbox.com/58/d1/YlUmjP4X_o.jpg" width="1080"></p> 
<p>没有进行分片，但用到了请求<code>range</code>，所以可以看到视频，是边播放边缓冲一部分。</p> 
<p>不过我在开发的时候发现，目前租用的服务云厂商，默认会帮我们实现这项技术。</p> 
<p>因为我把<code>mp4</code>视频上传到云服务器，通过链接进行播放的时候，就是边缓冲边播放的。</p> 
<p>我们可以直接把这个视频地址拿出来，放到浏览器里面能直接播放，这样观察更明显。</p> 
<p></p> 
<p class="img-center"><img alt="图片" height="666" src="https://images2.imgbox.com/35/ff/4DhdPwYe_o.jpg" width="1080"></p> 
<p>但B站和爱奇艺却不能这样，因为他们采用的<code>m4s</code>和<code>f4v</code>都不是一种通用的视频格式，需要使用专门的软件或工具才能打开和编辑。</p> 
<h3>#4.小红书：</h3> 
<p>测试用的例子链接：⇲www.xiaohongshu.com/discovery/i…⇲4</p> 
<p>小红书的方案更加简单粗暴，打开控制台，直接告诉你就是请求一个<code>mp4</code>，然后直接播放就完事了。</p> 
<p></p> 
<p class="img-center"><img alt="图片" height="642" src="https://images2.imgbox.com/96/22/i63jdHAz_o.jpg" width="1080"></p> 
<h3>#5.总结</h3> 
<p>看完了以上的各家大厂的方案，我们可以看到，基本原理都是边播放边加载，减少直接加载大视频文本的成本。并且通过分片传输，还能动态控制视频码率（清晰度）。做到根据网速，加载不同码率的分片文件，做到动态码率适应。</p> 
<p>同时采用的视频格式，比如<code>f4v</code>，<code>m4s</code>，都不是能直接播放的媒体格式，需要一定的处理。增加盗取视频的成本，增加一定的安全性。</p> 
<p>如果没有强要求，也可以直接采用<code>mp4</code>，或者直接用<code>video</code>播放一个视频文件地址。</p> 
<h3>#二.常见的视频格式与协议</h3> 
<p>我们知道视频的常见格式有<code>mp4</code>，同时上面介绍了B站播放用的<code>m4s</code>格式，爱奇艺用的<code>f4v</code>格式</p> 
<ul><li> <p>•除了这些还有哪些视频格式？</p> </li><li> <p>•为什么有这么多视频格式，有哪些不同点呢？</p> </li><li> <p>•为什么这些公司会采用这种格式来播放视频呢？</p> </li></ul> 
<h3>#1. B站用的<code>m4s</code></h3> 
<p><code>M4S</code>格式不是一种通用的视频格式，需要使用专门的软件或工具才能打开和编辑。</p> 
<p><code>M4S</code> 通常会和 <code>MPEG-DASH</code> 流媒体技术一起，通过流式传输的视频的一小部分。播放器会按接收顺序播放这些片段。第一个 <code>M4S</code> 段会包含一些初始化的数据标识。</p> 
<p><code>MPEG-DASH</code> 是一种自适应比特率流媒体技术，通过将内容分解为一系列不同码率的<code>M4S</code>片段，然后根据当前网络带宽进行自动调整。如果想在在<code>web</code>音视频中采用<code>DASH</code>技术，可以看下 ⇲github.com/Dash-Indust…⇲5</p> 
<h3>#2. 爱奇艺的<code>f4v</code></h3> 
<p><code>F4V</code>是一种流媒体格式，它是由<code>Adobe</code>公司推出的，继<code>FLV</code>格式之后支持<code>H.264</code>编码的流媒体格式。<code>F4V</code>格式的视频不是一种通用的视频格式，<strong>但通常情况下</strong>，都可以将文件后缀改为<code>FLV</code>，这样就可以使用支持<code>FLV</code>的播放器进行观看。</p> 
<p><code>FLV</code>格式跟常见的<code>MP4</code>格式比起来，结构更加简单，所以加载<code>metadata</code>(视频元数据，比如视频时长等信息)会更快。具体结构我们可以在这里查到：⇲en.wikipedia.org/wiki/Flash_…⇲6</p> 
<p>比如，这是<code>FLV</code>文件的标准头，定义了从几个比特到几个比特之间，是什么含义。我们知道后，可以用<code>MediaSource</code>进行读取和转码。</p> 
<table><thead><tr><th>Field </th><th>Data Type </th><th>Default </th><th>Details  </th></tr></thead><tbody><tr><td>Signature 签名</td><td>byte[3]</td><td>"FLV" </td><td> 始终就是“FLV”</td></tr><tr><td>Version 版本</td><td>uint8</td><td>1</td><td> 只有0x01才有效</td></tr><tr><td>Flags 标志</td><td>uint8 位掩码</td><td>0x05</td><td>0x04是音频，0x01是视频（所以0x05是音频+视频）</td></tr><tr><td>Header Size </td><td>uint32_be</td><td>9</td><td>用于跳过较新的扩展标头</td></tr></tbody></table> 
<p>而<code>MP4</code>格式会稍微复杂一些，具体标准在 ⇲ISO/IEC 14496-12⇲7 大概有两百多页，这里放不下，对这方面有兴趣的可以自行查看。</p> 
<p>然而这并不表示<code>MP4</code>更差，因为它是一种基础通用标准，所以定义上会留有很多空间，和各种情况，甚至允许在标准之内进行自行发挥和扩展。而<code>FLV</code>格式则更加固定，但优点也是更加简单。</p> 
<p>对于<code>FLV</code>的视频播放，我们可以采用：⇲github.com/bilibili/fl…⇲8 <code>flvjs</code>主要作用就是用<code>MediaSource</code>将<code>flv</code>转码成<code>mp4</code>从而喂给浏览器进行播放。</p> 
<p>接下来是一些其他的视频格式，简单介绍一下：</p> 
<h3>#3.<code>AVI</code></h3> 
<p>文件名以<code>.avi</code>结尾，<code>AVI</code> 最初由 <code>Microsoft</code> 于 <code>1992</code> 年开发，是 <code>Windows</code> 的标准视频格式。<code>AVI</code> 文件使用较少的压缩来存储文件，并且比许多其他视频格式占用更多空间，这导致文件大小非常大，每分钟视频大约 <code>2-3 GB</code>。</p> 
<p>无损文件不会随着时间的推移而降低质量，无论您打开或保存文件多少次。此外，这允许在不使用任何编解码器的情况下播放。参考资料：⇲Audio Video Interleave⇲9</p> 
<h3>#4.<code>MPEG</code></h3> 
<p>文件名以“.mpg”或“.mpeg”结尾，MPEG 是由 ISO 和 IEC 联合成立的工作组联盟，旨在制定媒体编码标准，包括音频、视频、图形和基因组数据的压缩编码;以及各种应用程序的传输和文件格式。MPEG 格式用于各种多媒体系统。最广为人知的旧 MPEG 媒体格式通常使用 MPEG-1、MPEG-2 和 MPEG-4 AVC 媒体编码，MPEG-2 系统传输流和节目流。较新的系统通常使用 MPEG 基本媒体文件格式和动态流式处理（又名 .MPEG-DASH）。参考资料：⇲Moving Picture Experts Group⇲10</p> 
<h3>#5.<code>MP4</code></h3> 
<p>带有音频和视频的 MPEG-4 文件通常使用标准的 .mp4 扩展名。纯音频 MPEG-4 文件通常具有 .m4a 扩展名，原始 MPEG-4 可视比特流命名为 .m4v。Apple iPhone使用MPEG-4音频作为其铃声，但使用.m4r扩展名而不是.m4a扩展名。参考资料：⇲MPEG-4 Part 14⇲11</p> 
<h3>#6.<code>QuickTime</code></h3> 
<p>文件名以“.mov”结尾，QuickTime 能够包含媒体数据的抽象数据引用，并将媒体数据与媒体偏移和轨道编辑列表分离，这意味着 QuickTime 特别适合编辑，因为它能够就地导入和编辑（无需数据复制）。由于 QuickTime 和 MP4 容器格式都可以使用相同的 MPEG-4 格式，因此在仅限 QuickTime 的环境中，它们大多可以互换。MP4作为国际标准，得到了更多的支持。参考资料：⇲QuickTime File Format⇲12</p> 
<h3>#7.<code>TS</code></h3> 
<p>TS是MPEG2-TS的简称，是一种音视频封装格式。TS流的后缀通常是.ts、.mpg或者.mpeg，多数播放器直接支持这种格式的播放。TS格式主要用于直播的码流结构，具有很好的容错能力。</p> 
<h3>#三.浏览器对各种视频格式的兼容性</h3> 
<p>上面了解常用的视频格式，和适用范围之后，还需要看一下当前浏览器，对各种视频格式的支持程度，然后制定技术方案。</p> 
<h3>#1. Chrome</h3> 
<p>支持的视频格式从官方文档可以查到，主要有以下这些</p> 
<ul><li> <p>•MP4 (QuickTime/ MOV / ISO-BMFF / CMAF)</p> </li><li> <p>•Ogg</p> </li><li> <p>•WebM</p> </li><li> <p>•WAV</p> </li><li> <p>•HLS [Only on Android and only single-origin manifests</p> </li></ul> 
<p>官方文档如下：⇲www.chromium.org/audio-video…⇲13</p> 
<h3>#2. Safari</h3> 
<p>支持的视频格式有这些：</p> 
<p></p> 
<p class="img-center"><img alt="图片" height="203" src="https://images2.imgbox.com/d3/e7/kjfZUdwi_o.jpg" width="1080"></p> 
<p>官方文档：⇲developer.apple.com/library/arc…⇲14</p> 
<h3>#3.Firefox</h3> 
<p>支持的视频格式：</p> 
<p></p> 
<p class="img-center"><img alt="图片" height="905" src="https://images2.imgbox.com/a0/1b/tawDwodm_o.jpg" width="1080"></p> 
<p>官方文档：⇲support.mozilla.org/en-US/kb/ht…⇲15</p> 
<h3>#四.MediaSource和视频编码，解码，封装介绍</h3> 
<p>上面介绍了一些视频格式，和目前浏览器的一些兼容性问题。就能发现，在<code>web</code>上播放音视频其实限制还是很大的。如何解决这些限制，就会用到<code>MediaSource</code>。</p> 
<p>视频其实是无数个图片的叠加，如果视频是一秒<code>60</code>帧，大约一秒中需要播放<code>60</code>张图片。这就导致一个几分钟的视频，就会非常大。比如上面介绍的无损格式，<code>avi</code>格式，每分钟视频大约 <code>2-3 GB</code>。这时候视频就需要进行<code>编码</code>。其实就是压缩。</p> 
<p>编码分为视频编码和音频编码，常见的视频编码有：</p> 
<ul><li> <p>•<strong>MPEG系列</strong>：<code>MPEG-1</code>第二部分、<code>MPEG-2</code>第二部分（等同于<code>H.262</code>）、<code>MPEG-4</code>第二部分、<code>MPEG-4</code>第十部分（等同于<code>H.264</code>，有时候也被叫做“<code>MPEG-4</code> <code>AVC</code>”或“<code>H.264/AVC</code>”）。</p> </li><li> <p>•<strong>H.26x系列</strong>：<code>H.261</code>、<code>H.262</code>、<code>H.263</code>、<code>H.264</code>（等同于<code>MPEG-4</code>第十部分）、<code>H.265/HEVC</code>（<code>ITU-T</code>和<code>ISO/IEC</code>联合推出）。</p> </li><li> <p>•<strong>其它视频编码</strong>：<code>WMV</code>系列、<code>RV</code>系列、<code>VC-1</code>、<code>DivX</code>、<code>XviD</code>、<code>X264</code>、<code>X265</code>、<code>VP8</code>、<code>VP9</code>、<code>Sorenson Video</code>、<code>AVS</code>。</p> </li></ul> 
<p>常见的音频编码有：<code>AAC</code>，<code>MP3</code>，<code>AC-3</code>等</p> 
<p>编码之后，还需要将音频和视频合并在一个文件里，这就是<code>封装</code>。</p> 
<p></p> 
<p class="img-center"><img alt="图片" height="528" src="https://images2.imgbox.com/5a/fc/RB9YbpM9_o.jpg" width="1080"></p> 
<p>所以相对的，播放一个视频，就需要解封装，解码，音视频同步喂给声卡和显卡进行播放。</p> 
<p><code>MediaSource</code>做的就是这个工作，读取视频流，转换成浏览器能播放的格式。</p> 
<p>以下是<code>flv.js</code>的<code>parseChunks</code>部分内容。读取<code>buffer</code>，一个字节一个字节的根据标准进行解析。然后转码。</p> 
<pre><code>        if (byteStart === 0) {  // buffer with FLV header
            if (chunk.byteLength &gt; 13) {
                let probeData = FLVDemuxer.probe(chunk);
                offset = probeData.dataOffset;
            } else {
                return 0;
            }
        }

        if (this._firstParse) {  // handle PreviousTagSize0 before Tag1
            this._firstParse = false;
            if (byteStart + offset !== this._dataOffset) {
                Log.w(this.TAG, 'First time parsing but chunk byteStart invalid!');
            }

            let v = new DataView(chunk, offset);
            let prevTagSize0 = v.getUint32(0, !le);
            if (prevTagSize0 !== 0) {
                Log.w(this.TAG, 'PrevTagSize0 !== 0 !!!');
            }
            offset += 4;
        }

</code></pre> 
<h3>#1.MediaSource兼容性</h3> 
<p></p> 
<p class="img-center"><img alt="图片" height="411" src="https://images2.imgbox.com/29/fd/DDKWppWy_o.jpg" width="1080"></p> 
<p>由此可见，基本都是绿色，但有一个特殊情况，就是<code>Safari on IOS</code>。这部分支持程度还是棕色。</p> 
<h3>#五. HLS 播放方案</h3> 
<p>采用<code>HLS</code>技术方案，有以下几个原因：</p> 
<p>1.兼容性</p> 
<p>上面介绍了各种视频格式，还有浏览器的兼容性</p> 
<p>其中 <code>HLS</code>协议是<code>Apple</code>公司实现的，在 <code>Apple</code> 的全系列产品包括 <code>iPhone</code>、<code>iPad</code>、<code>Safari</code> 等都可以原生支持播放 <code>HLS</code>。</p> 
<p>对于其他浏览器，可以通过<code>MediaSource</code>解封装，解码，转码，进行播放。</p> 
<p>这样也就解决了<code>MediaSource</code>的兼容性问题。</p> 
<ol><li> <p>业务场景需求</p> </li></ol> 
<p>目前对于视频的加密有着强需求，比如需要用户付费才能观看一些视频。而<code>HLS</code>协议天然自带标准加密，同时也能基于<code>HLS</code>扩展私有加密。</p> 
<ol><li> <p><code>HLS</code>协议自带支持分片传输和动态码率自适应播放。</p> </li><li> <p>有现成的技术方案，Hls.js</p> </li></ol> 
<h3>#六. 服务端开发</h3> 
<p>选择了采用<code>HLS</code>协议的播放方式，那么首先需要处理视频，这部分目前是在服务端进行处理。利用<code>ffmpeg</code>的能力。</p> 
<p>如果以后能将<code>ffmpeg</code>搬上浏览器，且没有性能问题就好了。现在有类似的<code>webassembly</code>的<code>npm</code>包，但性能有点小问题</p> 
<h3>#1.视频的转码</h3> 
<p>视频的转码的<code>ffmpeg</code>命令如下：</p> 
<pre><code>ffmpeg -i input.mp4 -hls_time 10 -hls_list_size 0 -c:v h264 -b:v 2M -hls_segment_filename output_%05d.ts output.m3u8 -y
</code></pre> 
<p>每个参数的解释：</p> 
<ul><li> <p>•<code>-i</code> 指定输入的视频</p> </li><li> <p>•<code>-hls_time</code> 指定分片的时间，单位是秒</p> </li><li> <p>•<code>-hls_list_size</code> 指定<code>hls</code>列表的数量，这里不限制</p> </li><li> <p>•<code>-c:v</code> 指定视频的编码格式</p> </li><li> <p>•<code>-b:v</code> 指定视频的码率，这里是<code>2M</code>比特率</p> </li><li> <p>•<code>-hls_segment_filename</code> 指定输出的<code>ts</code>文件名字，这里表示是<code>output_ + 五位数字</code></p> </li><li> <p>•<code>output.m3u8</code>指定输出<code>m3u8</code>文件的名字</p> </li><li> <p>•<code>-y</code>有些场景，比如是否覆盖，直接选择是，避免程序卡住</p> </li></ul> 
<p>为了自动化执行，这里会用到<code>node</code>的<code>spawn</code>模块，创建一个子进程，在子进程中执行<code>ffmpeg</code>的命令。</p> 
<pre><code>const exec = ({ params, data }: ExecOption): Promise&lt;ExecResult&gt; =&gt; {
  return new Promise((r, j) =&gt; {
    const cp = spawn('ffmpeg', params);
    cp.stderr.pipe(process.stdout);
    cp.on('error', (err) =&gt; {
      j(err);
    });
    cp.on('close', (code) =&gt; {
      r({ code, data });
    });
    cp.on('exit', (code) =&gt; {
      r({ code, data });
    });
  });
};
</code></pre> 
<p>这时候，视频就会在指定的位置输出了，会生成一个<code>m3u8</code>和多个<code>ts</code></p> 
<p></p> 
<p class="img-center"><img alt="图片" height="388" src="https://images2.imgbox.com/33/7d/2uNeh26d_o.jpg" width="382"></p> 
<p><code>ts</code>是视频文件，<code>m3u8</code>更像是索引文件，用来描述<code>ts</code>，比如在什么时间，播放什么<code>ts</code>。主要内容如下：</p> 
<pre><code>#EXTM3U
#EXT-X-VERSION:3
#EXT-X-TARGETDURATION:10
#EXT-X-MEDIA-SEQUENCE:0
#EXTINF:10.380622,
5_00000.ts
#EXTINF:10.380622,
5_00001.ts
#EXTINF:10.380622,
5_00002.ts
#EXTINF:10.380622,
5_00003.ts
#EXTINF:6.560556,
5_00004.ts
#EXTINF:1.619378,
5_00005.ts
#EXTINF:5.024189,
5_00006.ts
#EXT-X-ENDLIST

</code></pre> 
<h3>#2.视频的标准加密</h3> 
<p><code>HLS</code>协议标准加密采用的是<code>AES</code>对称加密方案。先来实现一个最标准的加密：</p> 
<p>首先通过<code>node</code>原生模块<code>crypto</code>生成加密密钥：</p> 
<pre><code>import crypto from 'node:crypto';
// 生成加密密钥
const key = crypto
      .createHash('sha256')
      .update(crypto.randomBytes(32))
      .digest('base64');
const filePathKey = path.join(__dirname,`../../public/uploads/hls/${dir}/${fileName}.key`);

const content = `${ctx.origin}/uploads/hls/${dir}/${fileName}.key\n${filePathKey}\n`;
// 密钥的文件
const fileKey = await writeFile(path.join(__dirname, `../../public/uploads/hls/${dir}/${fileName}.key`),key);
const keyInfoPath = path.join(__dirname,`../../public/uploads/hls/${dir}/${fileName}_key.bin`);
// ffmpeg 需要的key.info
const keyInfo = await writeFile(keyInfoPath, content);
</code></pre> 
<p>然后再执行<code>ffmpeg</code>命令，这里同样需要用<code>node</code>的<code>spawn</code>模块进行封装成接口：</p> 
<pre><code>ffmpeg -i input.mp4 -hls_time 10 -hls_list_size 0 -c:v h264 -b:v 2M -hls_key_info_file keyInfoPath -hls_segment_filename output_%05d.ts output.m3u8 -y
</code></pre> 
<p>主要就增加了一个<code>hls_key_info_file</code>参数，表示加密密钥的地址。这时候，生成的<code>m3u8</code>文件就发生了变化，多了一行：</p> 
<pre><code>#EXTM3U
#EXT-X-VERSION:3
#EXT-X-TARGETDURATION:10
#EXT-X-MEDIA-SEQUENCE:0
#EXT-X-KEY:METHOD=AES-128,URI="http://localhost:30103/uploads/hls/5_1701577743851/5.key",IV=0x00000000000000000000000000000000
#EXTINF:10.380622,
5_00000.ts
#EXTINF:10.380622,
5_00001.ts
#EXTINF:10.380622,
5_00002.ts
#EXTINF:10.380622,
5_00003.ts
#EXTINF:6.560556,
5_00004.ts
#EXTINF:1.619378,
5_00005.ts
#EXTINF:5.024189,
5_00006.ts
#EXT-X-ENDLIST

</code></pre> 
<p>多了</p> 
<pre><code>#EXT-X-KEY:METHOD=AES-128,URI="http://localhost:30103/uploads/hls/5_1701577743851/5.key",IV=0x00000000000000000000000000000000
</code></pre> 
<ul><li> <p>•<code>METHOD</code>字段表示加密方式，这里是<code>AES</code></p> </li><li> <p>•<code>URI</code>表示密钥地址，这里是<code>http://localhost:30103/uploads/hls/5_1701577743851/5.key</code>，</p> </li><li> <p>•<code>IV</code>是加密解密时的偏移量，现在是0</p> </li></ul> 
<p>上述加密方式，虽然视频确实加密了，但会把密钥地址写在<code>m3u8</code>里。等于把房间上锁，然后在锁上贴一个纸条，上面写了密码。</p> 
<h3>#3.更好的安全方案</h3> 
<ul><li> <p>•有加密，必然需要解密</p> </li></ul> 
<p>首先我们知道，视频要在<code>web</code>端进行播放，那么无论如何，都肯定需要先解密，再播放。</p> 
<ul><li> <p>•肯定不能在<code>web</code>端放置密钥</p> </li><li> <p>•<code>web</code>端需要知道如何获取密钥</p> </li><li> <p>•密钥用一次即失效，每次加密视频都生成新的密钥</p> </li></ul> 
<p>目前更好的安全性方式主要有两种：</p> 
<ol><li> <p>在请求密钥的地址上进行加固：</p> </li></ol> 
<p></p> 
<p class="img-center"><img alt="图片" height="982" src="https://images2.imgbox.com/b7/e5/1kotVjxM_o.jpg" width="1080"></p> 
<ul><li> <p>•校验<code>cookie</code>，既然是发起请求，那么同域名会自动携带<code>cookie</code>，只有购买过的用户才能获取密钥。（总不能让付费的用户也不能看吧）</p> </li><li> <p>•生成密钥链接时，带上<code>ticket</code>，短时间失效，控制时效性</p> </li><li> <p>•请求头携带<code>auth</code>，进行用户校验。比如<code>jwt</code>方案就是如此</p> </li></ul> 
<ol><li> <p>采用私有加密方式，比如<code>m3u8</code>里的<code>METHOD</code>，可能不再是<code>AES</code>这种对称加密。自定义一套加密规则，这种方式安全性会极大提高，但同时就不遵守<code>HLS</code>协议的标准了。但大多数浏览器支持<code>MediaSource</code>。可以读取文件内容，进行自定义加密和解密。根据上文的兼容性调研，<code>MediaSource</code>在<code>IOS</code>上将会有兼容性问题，所以这种方案在<code>IOS</code>上也会有兼容性问题。</p> </li></ol> 
<h3>#4.自适应码率播放</h3> 
<p>这里先介绍一下码率和清晰度的关系：</p> 
<p>码率是指：</p> 
<blockquote> 
 <p>码率（也称为比特率）是指视频文件在单位时间内使用的数据流量。它反映了视频文件的数据压缩程度，码率越高，压缩比就越小，画面质量就越高，但文件体积也越大。通俗来说，码率可以看作是取样率，是视频编码中画面质量控制中最重要的部分。计算公式是文件体积=时间X码率/8。</p> 
</blockquote> 
<p>所以简单来说，码率越高，清晰度就越好。成正比关系。</p> 
<p>需要根据视频的质量，和业务场景，去定义，这里给出阿里云对码率和清晰度的定义，可供参考：</p> 
<p></p> 
<p class="img-center"><img alt="图片" height="458" src="https://images2.imgbox.com/08/38/11WKyP99_o.jpg" width="471"></p> 
<p>为了实现自适应码率播放，我们需要将不同码率的<code>m3u8</code>合并成一个多码率的<code>m3u8</code>。</p> 
<p>这里我没找到合适的<code>ffmpeg</code>命令，但总有办法的，最万能的方法就是，查看<code>HLS</code>协议中多码率的<code>m3u8</code>格式标准，自己写一个。</p> 
<p>目前用<code>node</code>去写一个这样的索引文件，具体内容如下：</p> 
<pre><code>#EXTM3U
#EXT-X-STREAM-INF:PROGRAM-ID=1,BANDWIDTH=1000000,CODECS="mp4a.40.2,avc1.64001f",RESOLUTION=1280x720,NAME="720"
hls/5_1701577771368/5.m3u8
#EXT-X-STREAM-INF:PROGRAM-ID=2,BANDWIDTH=50000,CODECS="mp4a.40.5,avc1.42000d",RESOLUTION=320x184,NAME="320"
hls/5_1701577744714/5.m3u8
</code></pre> 
<ul><li> <p>•<code>#EXT-X-STREAM-INF</code>: 流媒体的描述</p> </li><li> <p>•<code>PROGRAM-ID</code>: 表示唯一的<code>ID</code>。</p> </li><li> <p>•<code>BANDWIDTH</code>: 流媒体的带宽，即每秒传输的数据量。这里带宽为<code>50000</code>，意味着每秒传输的数据量大约为<code>50kbps</code>。</p> </li><li> <p>•<code>CODECS</code>: 流媒体使用的编解码器。这里是使用了<code>mp4a.40.5</code>（<code>AAC</code>音频编码）和<code>avc1.42000d</code>（<code>AVC</code>视频编码）。</p> </li><li> <p>•<code>RESOLUTION</code>: 这个字段指示了视频的分辨率，即宽度和高度。在这个例子中，视频分辨率为<code>320x184</code>。</p> </li><li> <p>•<code>NAME</code>: 这个字段为流媒体提供了一个名称，本例中名称为"<code>320</code>"。我会习惯把清晰度放在<code>NAME</code>这个字段这里，方便<code>web</code>端获取</p> </li></ul> 
<p>实现一个接口，传入以上的参数，动态拼接字符串，写入文件</p> 
<pre><code>async generateMasterPlayList(ctx: Context): Promise&lt;void&gt; {
    try {
      const { paths, filename = Date.now() } = ctx.request.body;
      let content = `#EXTM3U\n`;
      paths.forEach((item: MasterPlayListOption, index: number) =&gt; {
        const { id = index, bandWidth, codecs, resolution, name, url } = item;
        content += `#EXT-X-STREAM-INF:PROGRAM-ID=${id},BANDWIDTH=${bandWidth},CODECS="${codecs}",RESOLUTION=${resolution},NAME="${name}"\n${url}\n`;
      });
      const dir = path.join(__dirname, `../../public/uploads/hls/`);
      if (!existsSync(dir)) {
        await createDir(dir);
      }
      const filePath = dir + (filename.toString().endsWith('.m3u8') ? filename : `${filename}.m3u8`)
      const { success, error } = await writeFile(filePath, content);
      const basename = path.basename(filePath);
      return success
        ? ctx.successHandler({
            url: `${ctx.origin}/uploads/hls/${basename}`,
          })
        : ctx.failHandler(error);
    } catch (error) {
      ctx.errorHandler(error);
    }
  }
</code></pre> 
<p>那么<code>HLS</code>是如何自适应码率的呢？</p> 
<p>其实是根据<code>BANDWIDTH</code>这个字段，因为我们给不同的视频设置了不同的<code>BANDWIDTH</code>。那么就可以根据当前的网速，进行动态切换。</p> 
<p> </p> 
<h3>#七.web端的实现</h3> 
<p>上面做了大量的工作，主要是生成了<code>HLS</code>协议的视频播放的地址。接下来就是如何在<code>web</code>端进行播放。</p> 
<h3>#1.技术选型</h3> 
<p>我首先是看了现有的播放器<code>npm</code>，比较知名的</p> 
<ul><li> <p>•有西瓜<code>playler</code>： ⇲github.com/bytedance/x…⇲16</p> </li><li> <p>•阿里云点播方案：⇲help.aliyun.com/zh/vod/deve…⇲17</p> </li><li> <p>•知乎的<code>player</code>：⇲github.com/zhihu/griff…⇲18</p> </li></ul> 
<p>其中知乎和西瓜的播放器是开源的，阿里云点播方案没有开源代码，但是有开源<code>demo</code>。</p> 
<p></p> 
<p class="img-center"><img alt="图片" height="571" src="https://images2.imgbox.com/88/f7/YqFisOx8_o.jpg" width="1080"></p> 
<p>但基本上实现的功能都很丰富，同时配置项会不断的增加。</p> 
<p>如果只是简单的初始化一个播放器，那还好。但一般这种场景，我们都会对播放器进行一定程度的定制化。比如B站。</p> 
<p></p> 
<p class="img-center"><img alt="图片" height="627" src="https://images2.imgbox.com/59/0b/TnKvD2Tv_o.jpg" width="1080"></p> 
<p>就多了很多自定义的控件。进度条也是小电视的形状。</p> 
<p>我们这边也是如此，有自己的主题色，有自己的播放按钮等等，还有一些业务功能，也要放在控制条上。</p> 
<p>上述的开源方案，都需要花时间去研究配置项，而且使用方法都是<code>new Player(options)</code>的形式。</p> 
<p>但尽量视图的归视图，逻辑的归逻辑会更好些。</p> 
<p>更何况实现一个播放器也不是很困难。</p> 
<p>期望的<code>player</code>，能满足</p> 
<ol><li> <p>配置够简单，最好看到就知道是怎么用的</p> </li><li> <p>方便扩展和样式覆盖</p> </li><li> <p>支持<code>hls</code>播放</p> </li><li> <p>尽量适配前端的各种框架</p> </li><li> <p>方便接入，实现价值</p> </li></ol> 
<h3>#2.播放器设计</h3> 
<p>由于现在既有<code>react</code>项目，也有<code>vue</code>项目，甚至还有一些老的<code>jquery</code>项目。为了做到一次开发，任何项目都可以使用和接入。采用了<code>web components</code>技术方案。</p> 
<p><code>web components</code>就不做介绍了，具体可以去看这篇文章：⇲手写web components组件⇲19简单来说就是可以自定义元素，让我们像使用<code>section</code>一样使用自定义元素。</p> 
<p>播放器我们需要考虑的点有：</p> 
<ol><li> <p><code>video</code>生命周期：<code>loadedmeta</code>，<code>canplay</code>, <code>ended</code>, <code>error</code>等</p> </li><li> <p><code>video</code>状态：播放，正在播放，暂停，静音等</p> </li><li> <p><code>video</code>属性：总时长，当前时长，音量大小，倍速等</p> </li><li> <p><code>video</code>交互：暂停，播放，知识点，清晰度，倍速，全屏，进度控制，音量控制等</p> </li></ol> 
<h4>#(1).video的生命周期</h4> 
<p>对于video的生命周期，我们期望做到两件事情：</p> 
<ol><li> <p>我们能知道当前<code>video</code>处于什么生命周期</p> </li><li> <p>在不同的生命周期，能挂载自定义事件。比如视频触发了<code>ended</code>。我们需要在<code>ended</code>时期跳转下一个视频</p> </li></ol> 
<p>因此，我们需要监听<code>video</code>的生命周期：</p> 
<pre><code>listenEvent = () =&gt; {
    if (!this._video) return;
    this.clearListenerEvent();
    this._video.addEventListener('canplay', this.onCanplay);
    this._video.addEventListener('canplaythrough', this.onCanplaythrough);
    this._video.addEventListener('complete', this.onComplete);
    this._video.addEventListener('durationchange', this.onDurationchange);
    this._video.addEventListener('emptied', this.onEmptied);
    this._video.addEventListener('ended', this.onEnded);
    this._video.addEventListener('error', this.onError);
    this._video.addEventListener('loadeddata', this.onLoadeddata);
    this._video.addEventListener('loadedmetadata', this.onLoadedmetadata);
    this._video.addEventListener('loadstart', this.onLoadstart);
    this._video.addEventListener('pause', this.onPause);
    this._video.addEventListener('play', this.onPlay);
    this._video.addEventListener('playing', this.onPlaying);
    this._video.addEventListener('progress', this.onProgress);
    this._video.addEventListener('ratechange', this.onRatechange);
    this._video.addEventListener('seeked', this.onSeeked);
    this._video.addEventListener('seeking', this.onSeeking);
    this._video.addEventListener('stalled', this.onStalled);
    this._video.addEventListener('suspend', this.onSuspend);
    this._video.addEventListener('timeupdate', this.onTimeupdate);
    this._video.addEventListener('volumechange', this.onVolumechange);
    this._video.addEventListener('waiting', this.onWaiting);
 };
</code></pre> 
<p>在触发不同的时期时，让开发者知道。所以我们要先自定义事件，进行触发</p> 
<pre><code>const change = (name: string, value: unknown): void =&gt; {
const currentTime = this.getCurrentTime();
const duration = this.getTotalTime();
this.dispatchEvent(
  new CustomEvent('change', {
    detail: {
      type: name,
      data: value,
      currentTime,
      duration,
      tag: this, // 整个player的实例
    },
  }),
);
};
const onCanplaythrough = (e: Event) =&gt; {
    this.ctx.currentState = e.type;
    this.change('canplaythrough', e);
};

</code></pre> 
<p>这样就可以，当生命周期事件触发后，就会触发<code>onchange</code>。 在使用上，我们可以：</p> 
<pre><code>&lt;r-player onChange={change} src="hls/example.m3u8" &gt;&lt;/r-player&gt;

const change = (e:CustomEvent) =&gt; {
    const { type, data, currentTime, duration, tag } = e.detail
    if(type === 'ended'){
        console.log('video ended')
    }
}
</code></pre> 
<p>其中<code>type</code>的类型有：</p> 
<table><thead><tr><th>名称</th><th>说明</th></tr></thead><tbody><tr><td>canplay</td><td>浏览器可以播放媒体文件了，但估计没有足够的数据来支撑播放到结束，不必停下来进一步缓冲内容。</td></tr><tr><td>canplaythrough</td><td>浏览器估计它可以在不停止内容缓冲的情况下播放媒体直到结束。</td></tr><tr><td>complete</td><td>OfflineAudioContext 渲染完成。</td></tr><tr><td>durationchange</td><td>duration 属性的值改变时触发。</td></tr><tr><td>emptied</td><td>媒体内容变为空；例如，当这个 media 已经加载完成（或者部分加载完成），则发送此事件，并调用 load() 方法重新加载它。</td></tr><tr><td>ended</td><td>视频停止播放，因为 media 已经到达结束点。</td></tr><tr><td>loadedmetadata</td><td>已加载元数据。</td></tr><tr><td>progress</td><td>在浏览器加载资源时周期性触发。</td></tr><tr><td>ratechange</td><td>播放速率发生变化。</td></tr><tr><td>seeked</td><td>跳帧（seek）操作完成。</td></tr><tr><td>seeking</td><td>跳帧（seek）操作开始。</td></tr><tr><td>stalled</td><td>用户代理（user agent）正在尝试获取媒体数据，但数据意外未出现。</td></tr><tr><td>suspend</td><td>媒体数据加载已暂停。</td></tr><tr><td>loadeddata</td><td>media 中的首帧已经完成加载。</td></tr><tr><td>timeupdate</td><td>currentTime 属性指定的时间发生变化。</td></tr><tr><td>volumechange</td><td>音量发生变化。</td></tr><tr><td>waiting</td><td>由于暂时缺少数据，播放已停止。</td></tr><tr><td>play</td><td>播放已开始。</td></tr><tr><td>playing</td><td>由于缺乏数据而暂停或延迟后，播放准备开始。</td></tr><tr><td>pause</td><td>播放已暂停。</td></tr><tr><td>volume</td><td>音量发生变化。</td></tr><tr><td>fullscreen</td><td>触发全屏事件</td></tr></tbody></table> 
<p>在不同的生命周期，能挂载事情，因此我们需要一个发布订阅类。</p> 
<pre><code>type Callback = (...args: unknown[]) =&gt; unknown;

type EventName = string | symbol;

type EventItem = {
  name?: string | symbol;
  callback: Callback;
  initialCallback?: Callback;
};

const NEW_LISTENER = 'NEW_LISTENER';

export class SyncHook {
  private _events: Record&lt;EventName, Array&lt;EventItem&gt;&gt;;
  constructor() {
    this._events = {};
  }
  on = (eventName: EventName, eventItem: EventItem | Callback): void =&gt; {
    if (this._events[eventName] &amp;&amp; eventName !== Symbol.for(NEW_LISTENER)) {
      this.emit(Symbol.for(NEW_LISTENER), eventName);
    }

    const callbacks = this._events[eventName] || [];
    if (typeof eventItem === 'function') {
      callbacks.push({
        name: eventName,
        callback: eventItem,
      });
    } else {
      callbacks.push(eventItem);
    }

    this._events[eventName] = callbacks;
  };

  emit = (eventName: EventName, ...args: Array&lt;unknown&gt;): void =&gt; {
    const callbacks = this._events[eventName] || [];
    callbacks.forEach((item) =&gt; {
      const { callback } = item;
      callback(...args);
    });
  };

  once = (eventName: EventName, eventItem: EventItem | Callback): void =&gt; {
    let one: EventItem;
    if (typeof eventItem === 'function') {
      one = {
        name: eventName,
        callback: (...args: Array&lt;unknown&gt;) =&gt; {
          eventItem(...args);
          this.off(eventName, one);
        },
        initialCallback: eventItem,
      };
    } else {
      const { callback } = eventItem;
      one = {
        name: eventName,
        callback: (...args: Array&lt;unknown&gt;) =&gt; {
          callback(...args);
          this.off(eventName, one);
        },
        initialCallback: callback,
      };
    }
    this.on(eventName, one);
  };

  off = (eventName: EventName, eventItem: EventItem | Callback): void =&gt; {
    const callbacks = this._events[eventName] || [];
    const newCallbacks = callbacks.filter((item) =&gt; {
      if (typeof eventItem === 'function') {
        return (
          item.callback !== eventItem &amp;&amp; item.initialCallback !== eventItem
        );
      } else {
        const { callback } = eventItem;
        return item.callback !== callback &amp;&amp; item.initialCallback !== callback;
      }
    });
    this._events[eventName] = newCallbacks;
  };
}
</code></pre> 
<p>因此会给<code>player</code>元素上增加一个<code>ctx</code>属性，作为全局的上下文。</p> 
<pre><code>this.ctx = {
  currentTime: 0, // 当前时间
  duration: 0, // 总时长
  currentState: '', // 当前视频状态
  action: new SyncHook(), // 不同时期触发的状态
};
</code></pre> 
<p>我们想订阅视频的结束事件，我们可以</p> 
<p>通过<code>Ref</code>的方式:</p> 
<pre><code>&lt;r-player ref={PlayerRef} onChange={change} src="hls/example.m3u8" &gt;&lt;/r-player&gt;

const endedEvent = () =&gt; {
    console.log('video ended')
}

PlayerRef.current.ctx.action.off('ended',endedEvent)

PlayerRef.current.ctx.action.on('ended',endedEvent)
</code></pre> 
<p>通过<code>change</code>方法获取的实例:</p> 
<pre><code>&lt;r-player onChange={change} src="hls/example.m3u8" &gt;&lt;/r-player&gt;

let player

const endedEvent = () =&gt; {
    console.log('video ended')
}

const change = (e:CustomEvent) =&gt; {
    const { type, data, currentTime, duration, tag } = e.detail
    player = tag
}

player.action.off('ended',endedEvent)
player.action.on('ended',endedEvent)
</code></pre> 
<h4>#(2).video的状态和属性</h4> 
<p>需要在全局上下文中记录下播放器的状态和属性：</p> 
<pre><code>this.ctx = {
  currentTime: 0, // 当前时间
  duration: 0, // 总时长
  currentState: '', // 当前视频状态
  action: new SyncHook(), // 不同时期触发的状态
  volume: 0.5, // 当前音量
  playbackRate: 1, // 当前倍速
  clarity: '', // 当前清晰度
  fullScreen: false, // 是否全屏
  levels: [], // 清晰度列表
  url: '', // 当前播放的地址
  levelMap: new Map(), // 清晰度和名字的映射关系
};
</code></pre> 
<h4>#(3).自定义video</h4> 
<p>默认长这个样子</p> 
<p></p> 
<p class="img-center"><img alt="图片" height="611" src="https://images2.imgbox.com/22/80/UIL5vcMa_o.jpg" width="1080"></p> 
<p>demo地址：⇲chaxus.github.io/ran/src/ran…⇲20</p> 
<p>源码地址：⇲github.com/chaxus/ran/…⇲21</p> 
<p>如果不喜欢控制器或者按钮，直接样式覆盖，更符合直觉，没有学习成本。</p> 
<pre><code>.ran-player-controller{
    display: none
}
</code></pre> 
<p>由于播放器本身就是一个元素，那么可以任意的在里面添加元素，添加逻辑。</p> 
<pre><code>&lt;r-player onChange={change} src="hls/example.m3u8" &gt;
    &lt;section&gt;111111&lt;/section&gt;
&lt;/r-player&gt;
</code></pre> 
<p>所以，这就解决配置项，长达好几页的问题，同时看到也就知道怎么配置，怎么开发了。</p> 
<h3>#八.总结</h3> 
<p>目前已经从前后端的角度，实现了</p> 
<ol><li> <p>视频的标准加密</p> </li><li> <p>视频的动态码率播放</p> </li><li> <p>视频的分片加载</p> </li><li> <p>可拖拽进度条</p> </li><li> <p>音量控制</p> </li><li> <p>手动清晰度切换</p> </li><li> <p>倍速播放</p> </li><li> <p>样式自定义覆盖</p> </li><li> <p>基于原生开发，可在所有框架运行，统一跨框架情况，各浏览器控件统一 </p> </li></ol>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/54165dbf51225f9892f2a4bbda30384d/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">vitest-前端单元测试</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/c3bcfc0cf838c3e5ee39f181590f51a4/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【postgresql初级使用】触发器的enable与disable，可以自动化精准管理触发器，避免重写触发器复杂逻辑</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>