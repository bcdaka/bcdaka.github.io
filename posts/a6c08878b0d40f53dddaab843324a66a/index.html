<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>每日一看大模型新闻（2024.1.20-1.21）英伟达新对话QA模型准确度超GPT-4，却遭吐槽：无权重代码意义不大；Llama 2打败GPT-4！Meta让大模型自我奖励自迭代，再证合成数据是LL - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/a6c08878b0d40f53dddaab843324a66a/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="每日一看大模型新闻（2024.1.20-1.21）英伟达新对话QA模型准确度超GPT-4，却遭吐槽：无权重代码意义不大；Llama 2打败GPT-4！Meta让大模型自我奖励自迭代，再证合成数据是LL">
  <meta property="og:description" content="1.产品发布 1.1韩国Kakao：推出多模态大模型Honeybee 发布日期：2024.1.20
Kakao unveils multimodal large language model Honeybee - The Korea Times
主要内容：韩国科技巨头Kakao今天宣布他们已经开发了一种名为“蜜蜂”（Honeybee）的多模态大语言模型。据Kakao称，“蜜蜂”能够同时理解图像和文本，回复与图像和文本内容混合相关的咨询。该模型代码已在开源社区GitHub上发布。
2.技术更新 2.1英伟达新对话QA模型准确度超GPT-4，却遭吐槽：无权重代码意义不大 发布日期：2024.1.21
英伟达新对话QA模型准确度超GPT-4，却遭吐槽：无权重代码意义不大
主要内容：一年多来，ChatGPT及后续产品引领了问答（QA）模型的范式转变。它们能以对话方式交互、提出后续问题，并能在开放域或长文档中集成检索到的证据块。然而，构建一个与SOTA黑箱模型如GPT-4等效的对话QA模型仍是挑战。最近，英伟达的研究提出了具有GPT-4水平准确度的白箱对话QA模型ChatQA 70B。该模型采用了两阶段指令调优方法和用于对话QA的RAG增强检索器，以及严格的数据管理过程。研究显示，ChatQA-70B在10个对话QA数据集上的表现优于或接近GPT-3.5-turbo和GPT-4，且不依赖OpenAI的合成数据。尽管有这些成就，社区对英伟达不公开模型权重和代码持批评态度。
论文地址：https://huggingface.co/papers/2401.10225
2.2 AI看视频自动找“高能时刻” 发布日期：2024.1.21
AI看视频自动找“高能时刻”｜字节&amp;中科院自动化所@AAAI 2024
主要内容：字节跳动与中科院自动化研究所合作，开发了一种AI技术，能快速识别视频中的高光片段。这项研究的成果被AAAI 2024收录。他们创建了一个名为LiveFood的美食视频数据集用于训练，并提出了一种叫GPE的方法。GPE能够灵活地检测不同长度视频中的亮点部分，克服了传统方法的一些限制。通过在图像帧级别打分，GPE可以有效地定位到视频中的精彩瞬间。该技术在美食制作、展示和享用等场景中特别有用。研究人员收集了大量美食视频，并对高光时刻进行了标注以训练模型。GPE减少了深度学习中的遗忘问题，并在基准测试中展现了优异的性能。
2.3 Stability AI杀回来了：视频生成新Demo效果惊人 发布日期：2024.1.21
Stability AI杀回来了：视频生成新Demo效果惊人，网友：一致性超群
主要内容：Stability AI的CEO Emad Mostaque发布了一些视频，引发了网友对其新版本Stable Video Diffusion的猜测。这些视频展示了惊人的画面清晰度、一致性和流畅度：如一个毛绒熊在潜水，动作流畅，甚至还眨眼。此外，还有丰富的海水细节和一个动漫风格的夜晚街道。现在的Demo显示，机器人、杯子、灯盏和床被枕头的细节都更为丰富，机器人脸上也有光影映射。同时，Stability AI还发布了一个只有16亿参数的小语言模型StableLM2 1.6B，经过多语种训练。频繁的进展让人们怀疑Stability AI是否要翻身。
体验地址：Runway - Advancing creativity with artificial intelligence.
2.4 GPT-4V惨败！CV大神谢赛宁新作：V*重磅「视觉搜索」算法让LLM理解力逼近人类 发布日期：2024.1.20
GPT-4V惨败！CV大神谢赛宁新作：V*重磅「视觉搜索」算法让LLM理解力逼近人类
主要内容：Sam Altman在世界经济论坛上表示，人类级别的AI即将到来。然而，目前的AI模型在图像理解方面还存在问题，比如无法准确识别复杂场景中的特定物体。为此，研究人员提出了V*模型和SEAL框架，通过引导视觉搜索机制来提高多模态LLM的图像理解能力。实验结果显示，这些方法在处理高分辨率图像中具有优势，有助于推动AI向人类智能迈进。
参考资料：https://arxiv.org/abs/2312.14135
3.商业动态 3.1清华、小米、华为、 vivo、理想等多机构联合综述，首提个人LLM智能体、划分5级智能水平 发布日期：2024.1.21
清华、小米、华为、 vivo、理想等多机构联合综述，首提个人LLM智能体、划分5级智能水平
主要内容：该文总结了对常见问题的专家意见，包括部署个人LLM智能体的设计选择和潜在挑战。专家认为将LLM在边缘-云协同部署是首选，而纯云并不是一个被广泛接受的解决方案。在定制化方面，人们最接受的方法是组合使用微调和上下文学习。对于个人LLM智能体，最重要的能力是语言理解，而最不重要的能力是处理长上下文的能力。基于语音的交互是最受欢迎的方式，而理想智能体应具备高效的数据管理和搜索、工作和生活辅助、个性化服务和推荐、自动化任务规划和完成、情感支持和社交互动等关键功能。最紧迫的技术挑战包括智能、性能、安全和隐私、个性化和存储、传统操作系统支持等方面。个人LLM智能体需要具备任务执行、情境感知和记忆等基本能力，并需要针对效率进行优化。
论文地址：https://arxiv.org/abs/2401.05459
文献库：GitHub - MobileLLM/Personal_LLM_Agents_Survey: Paper list for Personal LLM Agents">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-03-20T17:54:35+08:00">
    <meta property="article:modified_time" content="2024-03-20T17:54:35+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">每日一看大模型新闻（2024.1.20-1.21）英伟达新对话QA模型准确度超GPT-4，却遭吐槽：无权重代码意义不大；Llama 2打败GPT-4！Meta让大模型自我奖励自迭代，再证合成数据是LL</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2 style="text-align:justify;"><strong>1.</strong><strong>产品发布</strong></h2> 
<p></p> 
<h3 style="background-color:transparent;text-align:justify;"><a name="_Toc23528"></a><strong>1.1</strong><strong>韩国Kakao：推出多模态大模型Honeybee</strong></h3> 
<p style="margin-left:.0001pt;text-align:justify;"><strong><strong>发布日期</strong></strong>：2024.1.20</p> 
<p style="margin-left:.0001pt;text-align:justify;"><a href="https://www.koreatimes.co.kr/www/tech/2024/01/129_367229.html" rel="nofollow" title="Kakao unveils multimodal large language model Honeybee - The Korea Times">Kakao unveils multimodal large language model Honeybee - The Korea Times</a></p> 
<p style="margin-left:.0001pt;text-align:justify;"><strong><strong>主要内容</strong></strong>：韩国科技巨头Kakao今天宣布他们已经开发了一种名为“蜜蜂”（Honeybee）的多模态大语言模型。据Kakao称，“蜜蜂”能够同时理解图像和文本，回复与图像和文本内容混合相关的咨询。该模型代码已在开源社区GitHub上发布。</p> 
<h2 style="text-align:justify;"><strong>2.技术更新</strong></h2> 
<p></p> 
<h3 style="text-align:justify;"><a name="_Toc10337"></a><strong><span style="background-color:#ffff00;">2.1英伟达新对话QA模型准确度超GPT-4，却遭吐槽：无权重代码意义不大</span></strong></h3> 
<p style="margin-left:.0001pt;text-align:justify;"><strong><strong>发布日期</strong></strong>：2024.1.21</p> 
<p style="margin-left:.0001pt;text-align:justify;"><a href="https://mp.weixin.qq.com/s/uLVVfQNau_SLUPptCDQNmw" rel="nofollow" title="英伟达新对话QA模型准确度超GPT-4，却遭吐槽：无权重代码意义不大">英伟达新对话QA模型准确度超GPT-4，却遭吐槽：无权重代码意义不大</a></p> 
<p style="margin-left:.0001pt;text-align:justify;"><strong><strong>主要内容</strong></strong>：一年多来，<strong><strong>ChatGPT及后续产品引领了问答（QA）模型的范式转变。它们能以对话方式交互、提出后续问题，并能在开放域或长文档中集成检索到的证据块</strong></strong>。然而，构建一个与SOTA黑箱模型如GPT-4等效的对话QA模型仍是挑战。最近，英伟达的研究提出了具有GPT-4水平准确度的白箱对话QA模型ChatQA 70B。<strong><strong>该模型采用了两阶段指令调优方法和用于对话QA的RAG增强检索器，以及严格的数据管理过程</strong></strong>。研究显示，ChatQA-70B在10个对话QA数据集上的表现优于或接近GPT-3.5-turbo和GPT-4，且不依赖OpenAI的合成数据。尽管有这些成就，社区对英伟达不公开模型权重和代码持批评态度。</p> 
<p style="margin-left:.0001pt;text-align:justify;"><strong><strong>论文地址</strong></strong>：<a href="https://huggingface.co/papers/2401.10225" rel="nofollow" title="https://huggingface.co/papers/2401.10225">https://huggingface.co/papers/2401.10225</a></p> 
<h3 style="text-align:justify;"><a name="_Toc7913"></a><strong>2.2 AI看视频自动找“高能时刻”</strong></h3> 
<p style="margin-left:.0001pt;text-align:justify;"><strong><strong>发布日期</strong></strong>：2024.1.21</p> 
<p style="margin-left:.0001pt;text-align:justify;"><a href="https://mp.weixin.qq.com/s/dFxGrYZbq0uxRs0QwLM8AQ" rel="nofollow" title="AI看视频自动找“高能时刻”｜字节&amp;中科院自动化所@AAAI 2024">AI看视频自动找“高能时刻”｜字节&amp;中科院自动化所@AAAI 2024</a></p> 
<p style="margin-left:.0001pt;text-align:justify;"><strong><strong>主要内容</strong></strong>：字节跳动与中科院自动化研究所合作，开发了一种AI技术，能快速识别视频中的高光片段。这项研究的成果被AAAI 2024收录。他们创建了一个名为LiveFood的美食视频数据集用于训练，并提出了一种叫GPE的方法。GPE能够灵活地检测不同长度视频中的亮点部分，克服了传统方法的一些限制。通过在图像帧级别打分，GPE可以有效地定位到视频中的精彩瞬间。<strong><strong>该技术在美食制作、展示和享用等场景中特别有用。研究人员收集了大量美食视频，并对高光时刻进行了标注以训练模型。GPE减少了深度学习中的遗忘问题</strong></strong>，并在基准测试中展现了优异的性能。</p> 
<h3 style="text-align:justify;"><a name="_Toc7997"></a><strong>2.3 Stability AI杀回来了：视频生成新Demo效果惊人</strong></h3> 
<p style="margin-left:.0001pt;text-align:justify;"><strong><strong>发布日期</strong></strong>：2024.1.21</p> 
<p style="margin-left:.0001pt;text-align:justify;"><a href="https://mp.weixin.qq.com/s/Xt3CZ_F3r0_iMG0YjE2GyA" rel="nofollow" title="Stability AI杀回来了：视频生成新Demo效果惊人，网友：一致性超群">Stability AI杀回来了：视频生成新Demo效果惊人，网友：一致性超群</a></p> 
<p style="margin-left:.0001pt;text-align:justify;"><strong><strong>主要内容</strong></strong>：Stability AI的CEO Emad Mostaque发布了一些视频，引发了网友对其新版本Stable Video Diffusion的猜测。<strong><strong>这些视频展示了惊人的画面清晰度、一致性和流畅度</strong></strong>：如一个毛绒熊在潜水，动作流畅，甚至还眨眼。此外，还有丰富的海水细节和一个动漫风格的夜晚街道。现在的Demo显示，机器人、杯子、灯盏和床被枕头的细节都更为丰富，机器人脸上也有光影映射。同时，<strong><strong>Stability AI还发布了一个只有16亿参数的小语言模型StableLM2 1.6B</strong></strong>，经过多语种训练。频繁的进展让人们怀疑Stability AI是否要翻身。</p> 
<p style="margin-left:.0001pt;text-align:justify;"><strong><strong>体验地址</strong></strong>：<a href="https://runwayml.com" rel="nofollow" title="Runway - Advancing creativity with artificial intelligence.">Runway - Advancing creativity with artificial intelligence.</a></p> 
<h3 style="text-align:justify;"><a name="_Toc2155"></a><strong>2.4 GPT-4V惨败！CV大神谢赛宁新作：V*重磅「视觉搜索」算法让LLM理解力逼近人类</strong></h3> 
<p style="margin-left:.0001pt;text-align:justify;"><strong><strong>发布日期</strong></strong>：2024.1.20</p> 
<p style="margin-left:.0001pt;text-align:justify;"><a href="https://mp.weixin.qq.com/s/kID5Wknd9K-_Em-2bkFZ-A" rel="nofollow" title="GPT-4V惨败！CV大神谢赛宁新作：V*重磅「视觉搜索」算法让LLM理解力逼近人类">GPT-4V惨败！CV大神谢赛宁新作：V*重磅「视觉搜索」算法让LLM理解力逼近人类</a></p> 
<p style="margin-left:.0001pt;text-align:justify;"><strong><strong>主要内容</strong></strong>：Sam Altman在世界经济论坛上表示，人类级别的AI即将到来。然而，目前的AI模型在图像理解方面还存在问题，比如无法准确识别复杂场景中的特定物体。为此，研究人员提出了V*模型和SEAL框架，<strong><strong>通过引导视觉搜索机制来提高多模态LLM的图像理解能力</strong></strong>。实验结果显示，这些方法在处理高分辨率图像中具有优势，有助于推动AI向人类智能迈进。</p> 
<p style="margin-left:.0001pt;text-align:justify;"><strong><strong>参考资料</strong></strong>：<a href="https://arxiv.org/abs/2312.14135" rel="nofollow" title="https://arxiv.org/abs/2312.14135">https://arxiv.org/abs/2312.14135</a></p> 
<h2 style="text-align:justify;"><strong>3.商业动态</strong></h2> 
<p></p> 
<h3 style="background-color:transparent;text-align:justify;"><a name="_Toc5204"></a><strong>3.1清华、小米、华为、 vivo、理想等多机构联合综述，首提个人LLM智能体、划分5级智能水平</strong></h3> 
<p style="margin-left:.0001pt;text-align:justify;"><strong><strong>发布日期</strong></strong>：2024.1.21</p> 
<p style="margin-left:.0001pt;text-align:justify;"><a href="https://mp.weixin.qq.com/s/JYB4BzsXhWF8pEUUkvn_GQ" rel="nofollow" title="清华、小米、华为、 vivo、理想等多机构联合综述，首提个人LLM智能体、划分5级智能水平">清华、小米、华为、 vivo、理想等多机构联合综述，首提个人LLM智能体、划分5级智能水平</a></p> 
<p style="margin-left:.0001pt;text-align:justify;"><strong><strong>主要内容</strong></strong>：该文总结了对常见问题的专家意见，包括部署个人LLM智能体的设计选择和潜在挑战。专家认为将LLM在边缘-云协同部署是首选，而纯云并不是一个被广泛接受的解决方案。<strong><strong>在定制化方面，人们最接受的方法是组合使用微调和上下文学习</strong></strong>。<strong><strong>对于个人LLM智能体，最重要的能力是语言理解，而最不重要的能力是处理长上下文的能力</strong></strong>。基于语音的交互是最受欢迎的方式，而理想智能体应具备高效的数据管理和搜索、工作和生活辅助、个性化服务和推荐、自动化任务规划和完成、情感支持和社交互动等关键功能。最紧迫的技术挑战包括智能、性能、安全和隐私、个性化和存储、传统操作系统支持等方面。<strong><strong>个人LLM智能体需要具备任务执行、情境感知和记忆等基本能力，并需要针对效率进行优化</strong></strong>。</p> 
<p style="margin-left:.0001pt;text-align:justify;"><strong><strong>论文地址</strong></strong>：<a href="https://arxiv.org/abs/2401.05459" rel="nofollow" title="https://arxiv.org/abs/2401.05459">https://arxiv.org/abs/2401.05459</a></p> 
<p style="margin-left:.0001pt;text-align:justify;"><strong><strong>文献库</strong></strong>：<a href="https://github.com/MobileLLM/Personal_LLM_Agents_Survey" title="GitHub - MobileLLM/Personal_LLM_Agents_Survey: Paper list for Personal LLM Agents">GitHub - MobileLLM/Personal_LLM_Agents_Survey: Paper list for Personal LLM Agents</a></p> 
<h3 style="text-align:justify;"><a name="_Toc32138"></a><strong><span style="background-color:#ffff00;">3.2 Llama 2打败GPT-4！Meta让大模型自我奖励自迭代，再证合成数据是LLM终局</span></strong></h3> 
<p style="margin-left:.0001pt;text-align:justify;"><strong><strong>发布日期</strong></strong>：2024.1.21</p> 
<p style="margin-left:.0001pt;text-align:justify;"><a href="https://mp.weixin.qq.com/s/rV5jeR5i4_Q1z4y6X8MlcA" rel="nofollow" title="Llama 2打败GPT-4！Meta让大模型自我奖励自迭代，再证合成数据是LLM终局">Llama 2打败GPT-4！Meta让大模型自我奖励自迭代，再证合成数据是LLM终局</a></p> 
<p style="margin-left:.0001pt;text-align:justify;"><strong><strong>主要内容</strong></strong>：Meta和纽约大学的研究团队提出了一种自我奖励语言模型，<strong><strong>通过让模型生成训练数据并评估这些数据的质量，然后用这些数据来自己训练自己</strong></strong>。这种方法可以让LLM在迭代训练过程中不断自我改进。实验结果显示，经过3次迭代，Llama 2-70B模型在AlpacaEval 2.0基准测试中战胜了GPT-4、Claude 2、Gemini Pro等模型。这表明，自我奖励语言模型是一种有效的方法，可以推动AI自我迭代大模型的发展。</p> 
<p style="margin-left:.0001pt;text-align:justify;"><strong><strong>论文</strong></strong>：<a href="https://arxiv.org/pdf/2401.10020.pdf" rel="nofollow" title="https://arxiv.org/pdf/2401.10020.pdf">https://arxiv.org/pdf/2401.10020.pdf</a></p> 
<h2 style="text-align:justify;"><strong>4.其他资讯</strong></h2> 
<p></p> 
<h3 style="text-align:justify;"><a name="_Toc29009"></a><strong><span style="background-color:#ffff00;">4.1</span></strong><strong><span style="background-color:#ffff00;">普林斯顿博士生高天宇指令微调进展速览：数据、算法和评估</span></strong></h3> 
<p style="margin-left:.0001pt;text-align:justify;"><strong><strong>发布日期</strong></strong>：2024.1.21</p> 
<p style="margin-left:.0001pt;text-align:justify;"><a href="https://mp.weixin.qq.com/s/k1p7GddGapkDF8q_4uPUQA" rel="nofollow" title="普林斯顿博士生高天宇指令微调进展速览：数据、算法和评估">普林斯顿博士生高天宇指令微调进展速览：数据、算法和评估</a></p> 
<p style="margin-left:.0001pt;text-align:justify;"><strong><strong>主要内容</strong></strong>：这篇文章总结了大型语言模型（LLM）在指令微调方面的研究进展。LLM虽然强大，但要应用于真实世界和通用任务求解，需要学会遵从用户指令并给出有意义的响应，而不是仅仅学舌互联网语言。因此，<strong><strong>指令微调成为一种有潜力的方法，旨在让LLM遵从用户指令并以有益、诚实且无害的方式给出响应。文章介绍了指令微调的两个阶段：基于用户指令和标准响应对模型进行监督式微调（SFT）和将模型与人类偏好对齐</strong></strong>。开源项目和数据构建方法的出现降低了成本，促进了指令微调的发展。最后，作者还介绍了他们在指令遵从评估方面的最新研究成果，强调设置正确的评估器的重要性。</p> 
<p style="margin-left:.0001pt;text-align:justify;"><strong><strong>博客地址</strong></strong>：<a href="https://nlpnewsletter.substack.com/p/instruction-tuning-vol-1" rel="nofollow" title="https://nlpnewsletter.substack.com/p/instruction-tuning-vol-1">https://nlpnewsletter.substack.com/p/instruction-tuning-vol-1</a></p> 
<h3 style="text-align:justify;"><a name="_Toc20295"></a><strong>4.2</strong><strong>月入过万只需用ChatGPT建个网站？AI创业博主在线教学</strong></h3> 
<p style="margin-left:.0001pt;text-align:justify;"><strong><strong>发布日期</strong></strong>：2024.1.20</p> 
<p style="margin-left:.0001pt;text-align:justify;"><a href="https://mp.weixin.qq.com/s/yoFx7usOeCQxfNH7Ru3nww" rel="nofollow" title="月入过万只需用ChatGPT建个网站？AI创业博主在线教学">月入过万只需用ChatGPT建个网站？AI创业博主在线教学</a></p> 
<p style="margin-left:.0001pt;text-align:justify;"><strong><strong>主要内容</strong></strong>：Paul Couvert利用ChatGPT创建了一个网站，之后并未进行任何操作，该网站却在搜索引擎上获得了很高的排名，给他带来了约1.33万人民币的月收入。<strong><strong>他的成功秘诀在于利用AI生成营销文案，提高网站排名和关注度。他的网站主要收入来源包括AI课程、广告和一对一咨询服务</strong></strong>。除此之外，他还做了一个AI客服工具，帮助商家快速回复邮件和客户问题。Paul的成功经验表明，利用AI技术可以大大提高网站的流量和关注度，为网站带来更多的收入。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/83c8247f35b7328f5d85222577a07503/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">MacBook 安装多版本Python和版本切换详解</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/f52cfb7e721f23056f58e30b3444e99f/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【MySQL】学习和总结使用列子查询查询员工工资信息</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>