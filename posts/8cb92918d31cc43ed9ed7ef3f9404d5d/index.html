<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>DDSP-SVC-3.0完全指南：一步步教你用AI声音开启音乐之旅 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/8cb92918d31cc43ed9ed7ef3f9404d5d/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="DDSP-SVC-3.0完全指南：一步步教你用AI声音开启音乐之旅">
  <meta property="og:description" content="本教程教你怎么使用工具训练数据集推理出你想要转换的声音音频，并且教你处理剪辑伴奏和训练后的音频合并一起，在文章的最后有用我自己声音处理的歌曲，哎哟，还怪不好意思的~，哈哈，快来试试看把！
DDSP-SVC3.0训练推理克隆声音，超物有所值，训练完毕有伴奏处理教程哦
1.使用的工具 要想训练ai声音，首先需要有各种工具，还需要我们提供你需要训练的声音，当然声音需要没有噪音存干声，如果要是歌曲就需要分离歌曲的背景和声音，然后将音频文件切分，切分的目的是为了保证训练不卡，否则音频文件太大，所以你知道我们需要什么工具了把！以下揭晓
Adobe Audition ：我主要用这个提取mp4的音频文件，后期可以用这个剪辑将伴奏和音频合起来
UVR5：这个是专门背景与人生分离的软件，一键安装就可以
Audio Slicer（音频切分）：这个可以不用专门下软件自己操作了，大神在webui里集成了，按一下自动切分。
DDSP-SVC-3.0：最重要的工具，启动后是个webui界面，然后呢我们需要在里边训练自己的声音，转换声音等操作。
整合包使用b站大佬羽毛布团提供的包-地址： https://pan.baidu.com/s/1DWqVpJ7b6ueoUv6h4yF1-A?pwd=ddsp
处理音频的工具可以去羽毛布团的这个整合包下载，注意不要下载so-svc文件哦： https://pan.baidu.com/s/12u_LDyb5KSOfvjJ9LVwCIQ?pwd=g8n4
2.素材准备 2.1 AU提取音频 将mp4提取音频文件，用AU操作，操作如下：
我是要把我在bilibili录制的视频下载下来的，需要借助bilibili的一些工具才能下载下来视频，我用的是这个在线解析bilibili视频的还是蛮方便的，链接在这里。
哔哩哔哩(bilibili)视频解析下载 - 保存B站视频到手机、电脑
然后得到的视频可以拖到如下的位置，
然后点击这个文件右键将音频提取到文件，然后点击新出的音频文件再点击最上面的菜单文件保存或另存为然后就得到音频文件了。
2.2 UVR5提取干声 下面提取说明按需去取。
音频如果比较纯的声音无噪音则直接可以切分音频了，如果不纯的化可以处理下，打开url5，
这个是处理伴奏和人声分离的。
伴奏人声分离以后可以去听听纯声，发现其实会有一些和声和混响的，我们要去去掉这个和声混响，根据下面操作。
如果不是唱歌而是干声去噪也可以使用如下这种方式处理看看效果，我是纯的背景有点噪音，然后用了去和声混响处理的，也是有点效果的。
3.启动DDSP-SVC 声音部分都处理完了，就可以启动webui了，进入DDSP-SVC-3.0目录，双击启动启动WebUI，然后弹出来一个cmd弹框，
复制这个路径打开webui webui的界面是这样的
3.1 音频切分 这时就可以音频切分了，按照下面的说明去处理。
切分后的文件。 找到切分后的输出目录然后全部将块音频全部复制到此目录下：DDSP-SVC-3.0\data\train\audio
然后就需要到webui界面下，这时需将DDSP-SVC-3.0\data\train里的音频以100:1的比例放入到此目录下：DDSP-SVC-3.0\data\val\audio，100:1就是100个文件里取一个这样的比例，也可以不用你自己挑，程序帮你挑完自己放入对应的校验集里也就是val目录下，程序操作如下：
3.2 数据预处理 数据预处理，这里也很快，按下面的说明进行填写，填写哪些都有注释，点击数据预处理就可以了。
3,3 训练前的参数设置 设置要训练的参数，其实都默认就行，但是配置低的要进行相应的更改，否则训练过程中会失败。然后点击写入配置文件就可以了，此时输出信息说写入配置完成就OK了。
3.4 开始训练 3.4.1 DDSP模型训练 然后就开始训练了， 一般是先训DDSP这个是比较重要的，第一次训练的化需要选择从头开始训练，如果训练过程中取消了，那么想要继续训练就选择继续上一次的训练进度，然后取消模型训练时一定要按照这个倍数取消“每隔多少步(steps)验证并保存一次模型（2000步）”,否则可能没保存上，
然后弹出cmd，一直在迭代步数中，代表训练中
观察loss值，无明显趋势觉得不需要训练就可以按取消了,ctrl&#43;c就会取消训练
训练完了就可以训练扩散模型了，报如下错需要修改fp16需要改成fp32了。
可以看训练趋势图，启动Tensorboard，按下面这个操作就可以了，倒时会告诉你地址。
就会出现这样的界面
3.4.2 扩展模型训练 DDSP训练完毕，我们开始训练扩散模型。如下方式这样就可以了，cmd和上面的ddsp是一样的，感觉差不多了就取消训练。都训练完毕了就到推理环节了。
训练好的模型在这里会出现，此目录：DDSP-SVC-3.0\exp
DDSP的在这个目录下，可以看到模型训练的步数
扩散训练的在这个地方
4.模型推理 兄弟们最后一步了，坚持住啊！
推理就选择我们自己训练的模型，选择音频，按下面的图片的步骤走，按顺序来就行。
4.1 音频转换 重点来了，开始声音替换 ，我第一次处理时间巨长，也看不到日志后来关掉重启，重试关掉重启几次，突然出现了日志，以及处理过程，然后很快就推理完成了，听了下，效果还行，我的数据集还行，40分钟差不多，训练步数7500步也不多，然后我的声音全部是说话，没有唱歌声音，最后出现的这个效果还行，有一点点感觉到ai的感觉，不知道是不是这个哥以及歌手唱腔的原因。">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2023-12-19T10:30:26+08:00">
    <meta property="article:modified_time" content="2023-12-19T10:30:26+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">DDSP-SVC-3.0完全指南：一步步教你用AI声音开启音乐之旅</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>本教程教你怎么使用工具训练数据集推理出你想要转换的声音音频，并且教你处理剪辑伴奏和训练后的音频合并一起，在文章的最后有用我自己声音处理的歌曲，哎哟，还怪不好意思的~，哈哈，快来试试看把！</p> 
<div class="csdn-video-box"> 
 <iframe id="Jxi2AlBf-1702953016354" frameborder="0" src="https://player.bilibili.com/player.html?aid=579814996" allowfullscreen="true" data-mediaembed="bilibili"></iframe> 
 <p>DDSP-SVC3.0训练推理克隆声音，超物有所值，训练完毕有伴奏处理教程哦</p> 
</div> 
<h2>1.使用的工具</h2> 
<p>要想训练ai声音，首先需要有各种工具，还需要我们提供你需要训练的声音，当然声音需要没有噪音存干声，如果要是歌曲就需要分离歌曲的背景和声音，然后将音频文件切分，切分的目的是为了保证训练不卡，否则音频文件太大，所以你知道我们需要什么工具了把！以下揭晓</p> 
<p>Adobe Audition ：我主要用这个提取mp4的音频文件，后期可以用这个剪辑将伴奏和音频合起来</p> 
<p>UVR5：这个是专门背景与人生分离的软件，一键安装就可以</p> 
<p>Audio Slicer（音频切分）：这个可以不用专门下软件自己操作了，大神在webui里集成了，按一下自动切分。</p> 
<p>DDSP-SVC-3.0：最重要的工具，启动后是个webui界面，然后呢我们需要在里边训练自己的声音，转换声音等操作。</p> 
<p>整合包使用b站大佬羽毛布团提供的包-地址： https://pan.baidu.com/s/1DWqVpJ7b6ueoUv6h4yF1-A?pwd=ddsp</p> 
<p>处理音频的工具可以去羽毛布团的这个整合包下载，注意不要下载so-svc文件哦： https://pan.baidu.com/s/12u_LDyb5KSOfvjJ9LVwCIQ?pwd=g8n4</p> 
<p></p> 
<h2>2.素材准备</h2> 
<h3>2.1 AU提取音频</h3> 
<p>将mp4提取音频文件，用AU操作，操作如下：</p> 
<p>我是要把我在bilibili录制的视频下载下来的，需要借助bilibili的一些工具才能下载下来视频，我用的是这个在线解析bilibili视频的还是蛮方便的，链接在这里。</p> 
<blockquote> 
 <p><a href="https://bili.iiilab.com/" rel="nofollow" title="哔哩哔哩(bilibili)视频解析下载 - 保存B站视频到手机、电脑">哔哩哔哩(bilibili)视频解析下载 - 保存B站视频到手机、电脑</a></p> 
</blockquote> 
<p>然后得到的视频可以拖到如下的位置，</p> 
<p><img alt="" height="350" src="https://images2.imgbox.com/ad/cc/WANQ3aSx_o.png" width="438"></p> 
<p>然后点击这个文件右键将音频提取到文件，然后点击新出的音频文件再点击最上面的菜单文件保存或另存为然后就得到音频文件了。</p> 
<p><img alt="" height="296" src="https://images2.imgbox.com/72/9c/MtQkKbQR_o.png" width="475"></p> 
<h3>2.2 UVR5提取干声</h3> 
<p>下面提取说明按需去取。</p> 
<p>音频如果比较纯的声音无噪音则直接可以切分音频了，如果不纯的化可以处理下，打开url5，</p> 
<p>这个是处理伴奏和人声分离的。</p> 
<p><img alt="" height="615" src="https://images2.imgbox.com/02/37/VN2nqYPx_o.png" width="579"></p> 
<p>伴奏人声分离以后可以去听听纯声，发现其实会有一些和声和混响的，我们要去去掉这个和声混响，根据下面操作。</p> 
<p><img alt="" height="610" src="https://images2.imgbox.com/37/fa/kxXdnwyN_o.png" width="571"></p> 
<p>如果不是唱歌而是干声去噪也可以使用如下这种方式处理看看效果，我是纯的背景有点噪音，然后用了去和声混响处理的，也是有点效果的。</p> 
<p><img alt="" height="403" src="https://images2.imgbox.com/62/b1/wnShBOXg_o.png" width="466"></p> 
<h2>3.启动DDSP-SVC</h2> 
<p>声音部分都处理完了，就可以启动webui了，进入DDSP-SVC-3.0目录，双击启动启动WebUI，然后弹出来一个cmd弹框，</p> 
<p><img alt="" height="56" src="https://images2.imgbox.com/a5/a9/ESkA2t7X_o.png" width="355"></p> 
<p>复制这个路径打开webui </p> 
<p><img alt="" height="194" src="https://images2.imgbox.com/d4/55/tAnI7Szq_o.png" width="498"></p> 
<p>webui的界面是这样的<img alt="" height="1200" src="https://images2.imgbox.com/d7/7c/dtfwsYNO_o.png" width="1200"></p> 
<h3>3.1 音频切分</h3> 
<p>这时就可以音频切分了，按照下面的说明去处理。</p> 
<p><img alt="" height="777" src="https://images2.imgbox.com/b2/32/rooMWBt2_o.png" width="1200"></p> 
<p>切分后的文件。 </p> 
<p><img alt="" height="411" src="https://images2.imgbox.com/32/91/Qvxo8Q3o_o.png" width="142"></p> 
<p>找到切分后的输出目录然后全部将块音频全部复制到此目录下：DDSP-SVC-3.0\data\train\audio</p> 
<p>然后就需要到webui界面下，这时需将DDSP-SVC-3.0\data\train里的音频以100:1的比例放入到此目录下：DDSP-SVC-3.0\data\val\audio，100:1就是100个文件里取一个这样的比例，也可以不用你自己挑，程序帮你挑完自己放入对应的校验集里也就是val目录下，程序操作如下：</p> 
<p><img alt="" height="278" src="https://images2.imgbox.com/d4/9f/DP8oPOfD_o.png" width="1200"></p> 
<h3>3.2 数据预处理 </h3> 
<p>数据预处理，这里也很快，按下面的说明进行填写，填写哪些都有注释，点击数据预处理就可以了。</p> 
<p><img alt="" height="411" src="https://images2.imgbox.com/3f/29/BaSMajxJ_o.png" width="1200"></p> 
<h3>3,3 训练前的参数设置</h3> 
<p>设置要训练的参数，其实都默认就行，但是配置低的要进行相应的更改，否则训练过程中会失败。然后点击写入配置文件就可以了，此时输出信息说写入配置完成就OK了。</p> 
<p> <img alt="" height="398" src="https://images2.imgbox.com/bc/24/5OVZhNKN_o.png" width="590"></p> 
<h3>3.4 开始训练</h3> 
<h4>3.4.1 DDSP模型训练</h4> 
<p>然后就开始训练了， 一般是先训DDSP这个是比较重要的，第一次训练的化需要选择从头开始训练，如果训练过程中取消了，那么想要继续训练就选择继续上一次的训练进度，然后取消模型训练时一定要按照这个倍数取消<strong>“每隔多少步(steps)验证并保存一次模型（2000步）”,</strong>否则可能没保存上，</p> 
<p><img alt="" height="577" src="https://images2.imgbox.com/be/4a/cFte9THS_o.png" width="1200"></p> 
<p>然后弹出cmd，一直在迭代步数中，代表训练中</p> 
<p><img alt="" height="291" src="https://images2.imgbox.com/b7/98/V3A6krsA_o.png" width="558"></p> 
<p> 观察loss值，无明显趋势觉得不需要训练就可以按取消了,ctrl+c就会取消训练</p> 
<p><img alt="" height="264" src="https://images2.imgbox.com/ae/b7/ylYqwRbX_o.png" width="596"></p> 
<p>训练完了就可以训练扩散模型了，报如下<span style="color:#0d0016;">错需要修改fp16需要改成fp32了。</span></p> 
<p><img alt="" height="244" src="https://images2.imgbox.com/ed/38/3eUHaAIF_o.png" width="874"></p> 
<p> <img alt="" height="250" src="https://images2.imgbox.com/4d/9a/N2OWkG3y_o.png" width="561"></p> 
<p> 可以看训练趋势图，启动Tensorboard，按下面这个操作就可以了，倒时会告诉你地址。</p> 
<p><img alt="" height="183" src="https://images2.imgbox.com/5d/62/lHtIhK8q_o.png" width="793"></p> 
<p>就会出现这样的界面</p> 
<p><img alt="" height="381" src="https://images2.imgbox.com/e7/25/e9kElgUc_o.png" width="358"></p> 
<h4>3.4.2 扩展模型训练</h4> 
<p>DDSP训练完毕，我们开始训练扩散模型。如下方式这样就可以了，cmd和上面的ddsp是一样的，感觉差不多了就取消训练。都训练完毕了就到推理环节了。</p> 
<p><img alt="" height="204" src="https://images2.imgbox.com/35/0d/7Pwe4K3R_o.png" width="461"></p> 
<p>训练好的模型在这里会出现，此目录：DDSP-SVC-3.0\exp</p> 
<p>DDSP的在这个目录下，可以看到模型训练的步数</p> 
<p><img alt="" height="268" src="https://images2.imgbox.com/28/98/oSCIAWXN_o.png" width="401"></p> 
<p> 扩散训练的在这个地方</p> 
<p><img alt="" height="219" src="https://images2.imgbox.com/f9/49/HPop7q9o_o.png" width="395"></p> 
<h2>4.模型推理 </h2> 
<p>兄弟们最后一步了，坚持住啊！</p> 
<p>推理就选择我们自己训练的模型，选择音频，按下面的图片的步骤走，按顺序来就行。</p> 
<p><img alt="" height="736" src="https://images2.imgbox.com/07/a3/AOIYoyKJ_o.png" width="1200"></p> 
<h3> 4.1 音频转换</h3> 
<p>重点来了，开始声音替换 ，我第一次处理时间巨长，也看不到日志后来关掉重启，重试关掉重启几次，突然出现了日志，以及处理过程，然后很快就推理完成了，听了下，效果还行，我的数据集还行，40分钟差不多，训练步数7500步也不多，然后我的声音全部是说话，没有唱歌声音，最后出现的这个效果还行，有一点点感觉到ai的感觉，不知道是不是这个哥以及歌手唱腔的原因。</p> 
<p>推理过程。</p> 
<p><img alt="" height="696" src="https://images2.imgbox.com/71/f4/O90ACrar_o.png" width="1011"></p> 
<p><img alt="" height="756" src="https://images2.imgbox.com/2b/a8/h7QGXEUQ_o.png" width="1200"></p> 
<h2> 5.让AI唱歌</h2> 
<p>我的音频是《慢慢喜欢你》这首歌的干声，然后把我的声音替换上去，转换了以后《慢慢喜欢你》就是我的声音了，接下来就需要把伴奏和我处理后的声音合在一起，打开AU这个软件就可以了</p> 
<p>选择多轨道</p> 
<p><img alt="" height="320" src="https://images2.imgbox.com/e5/d0/9JAgiQ2k_o.png" width="439"></p> 
<p>然后将伴奏文件和处理好的音频拖入进来，干声放入第一轨道，伴奏放入第二轨道，对齐就好</p> 
<p><img alt="" height="230" src="https://images2.imgbox.com/f3/2b/cz9X5DTL_o.png" width="566"></p> 
<p> 然后点击文件导出-多轨混音-整个会话就可以了。记得自己指定输出目录哦！</p> 
<p><img alt="" height="497" src="https://images2.imgbox.com/fa/56/FIqy8K07_o.png" width="579"></p> 
<p>来欣赏作品把：</p> 
<p>训练22000步的效果：</p> 
<p>《漫步人生路》</p> 
<div class="csdn-video-box"> 
 <iframe id="3NrTH4YQ-1702866326928" frameborder="0" src="https://player.bilibili.com/player.html?aid=452353925" allowfullscreen="true" data-mediaembed="bilibili"></iframe> 
 <p>笑对沧桑，漫步人生路，不问前程几何。</p> 
</div> 
<p></p> 
<p>《以渺小爱你》一路前行环保公益曲，最近非常喜欢</p> 
<div class="csdn-video-box"> 
 <iframe id="rL4yAdfY-1702952684861" frameborder="0" src="https://player.bilibili.com/player.html?aid=707439288" allowfullscreen="true" data-mediaembed="bilibili"></iframe> 
 <p>🎶由AI谱唱，一路向前，这首环保公益主题曲真的太治愈了！</p> 
</div> 
<p></p> 
<p>训练7500步的效果：</p> 
<p>《漠河舞厅》</p> 
<div class="csdn-video-box"> 
 <iframe id="3x09sExB-1702023212854" frameborder="0" src="https://player.bilibili.com/player.html?aid=621919312" allowfullscreen="true" data-mediaembed="bilibili"></iframe> 
 <p>🎵AI唱漠河舞厅，实现个人录音棚了！🎉</p> 
</div> 
<p></p> 
<p>《慢慢喜欢你》</p> 
<div class="csdn-video-box"> 
 <iframe id="KWvTcMYE-1702023693124" frameborder="0" src="https://player.bilibili.com/player.html?aid=749403909" allowfullscreen="true" data-mediaembed="bilibili"></iframe> 
 <p>「搞事情」了！我用自己的声音训练AI唱《慢慢喜欢你》</p> 
</div> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/c1d8eaa80b86be47e19e81a88e52d516/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Python中的定时器用法：Timer定时器和schedule库</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/e843eef7751ba885e1a7415891a8c0a8/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Kafka事务是怎么实现的？Kafka事务消息原理详解（文末送书）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>