<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>python萌新爬虫学习笔记【建议收藏】 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/e2b7dff893003a1e26998e96dcab6f2b/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="python萌新爬虫学习笔记【建议收藏】">
  <meta property="og:description" content="文章目录 发现宝藏前言1. 如何何请求解析url2. 如何获取标签里面的文本3. 如何解析JSON格式4. 如何添加常用的header5. 如何合并两个div6. 如何删除html dom的部分结构7. 如何一次性获取所有div标签里的文本8. python爬虫如何改变响应文本字符集编码9. 如何进行字符集转码10. response.text 和 respone.content的区别11. 如何发送post请求访问页面12. 如何获取 url 中的参数13. 如何下载图片 总结 发现宝藏 前些天发现了一个巨牛的人工智能学习网站，通俗易懂，风趣幽默，忍不住分享一下给大家。【宝藏入口】。
前言 为了巩固所学的知识，作者尝试着开始发布一些学习笔记类的博客，方便日后回顾。当然，如果能帮到一些萌新进行新技术的学习那也是极好的。作者菜菜一枚，文章中如果有记录错误，欢迎读者朋友们批评指正。
（博客的参考源码可以在我主页的资源里找到，如果在学习的过程中有什么疑问欢迎大家在评论区向我提出）
1. 如何何请求解析url 要解析 Python 中 Request 返回的 HTML DOM，你可以使用解析库，如 BeautifulSoup 或 lxml，来处理 HTML 文档。下面是使用 Beautiful Soup 和 lxml 的示例代码：首先，确保你已经安装了所需的库。对于 Beautiful Soup，你可以使用 pip install beautifulsoup4 进行安装。对于 lxml，你可以使用 pip install lxml 进行安装。使用 Beautiful Soup 库： BeautifulSoup 是一个 Python 库，用于网络爬虫目的。它提供了一种方便和高效的方式来从 HTML 和 XML 文档中提取数据。使用 BeautifulSoup，你可以解析和遍历 HTML 结构，搜索特定元素，并从网页中提取相关数据。 该库支持不同的解析器，如内置的 Python 解析器、lxml 和 html5lib，允许你根据特定需求选择最适合的解析器。BeautifulSoup 的优势在于它能够处理格式混乱或损坏的 HTML 代码，使其成为处理复杂情况下的网络爬虫任务的强大工具。 import requests from bs4 import BeautifulSoup # 发送请求获取 HTML response = requests.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-03-05T16:40:52+08:00">
    <meta property="article:modified_time" content="2024-03-05T16:40:52+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">python萌新爬虫学习笔记【建议收藏】</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#_2" rel="nofollow">发现宝藏</a></li><li><a href="#_6" rel="nofollow">前言</a></li><li><ul><li><a href="#1_url_11" rel="nofollow">1. 如何何请求解析url</a></li><li><a href="#2__65" rel="nofollow">2. 如何获取标签里面的文本</a></li><li><a href="#3_JSON_112" rel="nofollow">3. 如何解析JSON格式</a></li><li><a href="#4_header_174" rel="nofollow">4. 如何添加常用的header</a></li><li><a href="#5_div_198" rel="nofollow">5. 如何合并两个div</a></li><li><a href="#6_html_dom_211" rel="nofollow">6. 如何删除html dom的部分结构</a></li><li><a href="#7_div_253" rel="nofollow">7. 如何一次性获取所有div标签里的文本</a></li><li><a href="#8_python_286" rel="nofollow">8. python爬虫如何改变响应文本字符集编码</a></li><li><a href="#9__324" rel="nofollow">9. 如何进行字符集转码</a></li><li><a href="#10_responsetext__responecontent_352" rel="nofollow">10. response.text 和 respone.content的区别</a></li><li><a href="#11_post_372" rel="nofollow">11. 如何发送post请求访问页面</a></li><li><a href="#12__url__410" rel="nofollow">12. 如何获取 url 中的参数</a></li><li><a href="#13__436" rel="nofollow">13. 如何下载图片</a></li></ul> 
  </li><li><a href="#_474" rel="nofollow">总结</a></li></ul> 
</div> 
<p></p> 
<h2><a id="_2"></a>发现宝藏</h2> 
<p>前些天发现了一个巨牛的人工智能学习网站，通俗易懂，风趣幽默，忍不住分享一下给大家。【<a href="https://www.captainbed.cn/dl" rel="nofollow">宝藏入口</a>】。</p> 
<h2><a id="_6"></a>前言</h2> 
<p>为了巩固所学的知识，作者尝试着开始发布一些学习笔记类的博客，方便日后回顾。当然，如果能帮到一些萌新进行新技术的学习那也是极好的。作者菜菜一枚，文章中如果有记录错误，欢迎读者朋友们批评指正。<br> （博客的参考源码可以在我主页的资源里找到，如果在学习的过程中有什么疑问欢迎大家在评论区向我提出）</p> 
<h3><a id="1_url_11"></a>1. 如何何请求解析url</h3> 
<ul><li>要解析 Python 中 Request 返回的 HTML DOM，你可以使用解析库，如 BeautifulSoup 或 lxml，来处理 HTML 文档。下面是使用 Beautiful Soup 和 lxml 的示例代码：</li><li>首先，确保你已经安装了所需的库。对于 Beautiful Soup，你可以使用 <strong>pip install beautifulsoup4</strong> 进行安装。对于 lxml，你可以使用 <strong>pip install lxml</strong> 进行安装。</li><li>使用 Beautiful Soup 库：</li></ul> 
<blockquote> 
 <ol><li><font size="3">BeautifulSoup 是一个 Python 库，用于网络爬虫目的。它提供了一种方便和高效的方式来从 HTML 和 XML 文档中提取数据。使用 BeautifulSoup，你可以解析和遍历 HTML 结构，搜索特定元素，并从网页中提取相关数据。</font></li></ol> 
</blockquote> 
<blockquote> 
 <ol start="2"><li><font size="3">该库支持不同的解析器，如内置的 Python 解析器、lxml 和 html5lib，允许你根据特定需求选择最适合的解析器。BeautifulSoup 的优势在于它能够处理格式混乱或损坏的 HTML 代码，使其成为处理复杂情况下的网络爬虫任务的强大工具。</font></li></ol> 
</blockquote> 
<pre><code class="prism language-python"><span class="token keyword">import</span> requests
<span class="token keyword">from</span> bs4 <span class="token keyword">import</span> BeautifulSoup

<span class="token comment"># 发送请求获取 HTML</span>
response <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">)</span>
html <span class="token operator">=</span> response<span class="token punctuation">.</span>text

<span class="token comment"># 创建 Beautiful Soup 对象</span>
soup <span class="token operator">=</span> BeautifulSoup<span class="token punctuation">(</span>html<span class="token punctuation">,</span> <span class="token string">'html.parser'</span><span class="token punctuation">)</span>

<span class="token comment"># 通过选择器选择 DOM 元素进行操作</span>
element <span class="token operator">=</span> soup<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">'#my-element'</span><span class="token punctuation">)</span>
</code></pre> 
<ul><li>在上面的示例中，<strong>requests.get(url)</strong> 发送请求并获取HTML响应。然后，我们使用 <strong>response.text</strong> 获取响应的HTML内容，并将其传递给 Beautiful Soup 构造函数 <strong>BeautifulSoup(html, ‘html.parser’)</strong>，创建一个 Beautiful Soup 对象 <strong>soup</strong>。</li><li>接下来，你可以使用 Beautiful Soup 提供的方法和选择器，如 <strong>select()</strong>，来选择 HTML DOM 中的特定元素。在上述示例中，我们通过选择器 <strong>#my-element</strong> 选择具有 <strong>id</strong> 为 <strong>my-element</strong> 的元素。</li><li>使用 lxml 库：</li></ul> 
<pre><code class="prism language-python"><span class="token keyword">import</span> requests
<span class="token keyword">from</span> lxml <span class="token keyword">import</span> etree

<span class="token comment"># 发送请求获取 HTML</span>
response <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">)</span>
html <span class="token operator">=</span> response<span class="token punctuation">.</span>text

<span class="token comment"># 创建 lxml HTML 解析器对象</span>
parser <span class="token operator">=</span> etree<span class="token punctuation">.</span>HTMLParser<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 解析 HTML</span>
tree <span class="token operator">=</span> etree<span class="token punctuation">.</span>fromstring<span class="token punctuation">(</span>html<span class="token punctuation">,</span> parser<span class="token punctuation">)</span>

<span class="token comment"># 通过XPath选择 DOM 元素进行操作</span>
elements <span class="token operator">=</span> tree<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//div[@class="my-element"]'</span><span class="token punctuation">)</span>
</code></pre> 
<ul><li>在上面的示例中，我们首先使用 <strong>requests.get(url)</strong> 发送请求并获取HTML响应。然后，我们创建一个 lxml HTML 解析器对象 <strong>parser</strong>。</li><li>接下来，我们使用 <strong>etree.fromstring(html, parser)</strong> 解析 HTML，并得到一个表示 DOM 树的对象 <strong>tree</strong>。</li><li>最后，我们可以使用 XPath 表达式来选择 DOM 元素。在上述示例中，我们使用 XPath 表达式 <strong>//div[@class=“my-element”]</strong> 选择所有 <strong>class</strong> 属性为 <strong>“my-element”</strong> 的 <strong>div</strong> 元素。</li><li>无论是使用 Beautiful Soup 还是 lxml，都可以使用各自库提供的方法和属性来操作和提取选择的 DOM 元素。</li></ul> 
<h3><a id="2__65"></a>2. 如何获取标签里面的文本</h3> 
<p>在Python中，你可以使用多种库和方法来获取HTML标签里面的文本。以下是几种常见的方法：</p> 
<ul><li>方式一：使用BeautifulSoup库：</li></ul> 
<pre><code class="prism language-python">   <span class="token keyword">from</span> bs4 <span class="token keyword">import</span> BeautifulSoup

   <span class="token comment"># 假设html为包含标签的HTML文档</span>
   soup <span class="token operator">=</span> BeautifulSoup<span class="token punctuation">(</span>html<span class="token punctuation">,</span> <span class="token string">'html.parser'</span><span class="token punctuation">)</span>

   <span class="token comment"># 获取所有标签内的文本</span>
   text <span class="token operator">=</span> soup<span class="token punctuation">.</span>get_text<span class="token punctuation">(</span><span class="token punctuation">)</span>

   <span class="token comment"># 获取特定标签内的文本（例如p标签）</span>
   p_text <span class="token operator">=</span> soup<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'p'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get_text<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<ul><li>方式二：使用lxml库：</li></ul> 
<pre><code class="prism language-python">   <span class="token keyword">from</span> lxml <span class="token keyword">import</span> etree

   <span class="token comment"># 假设html为包含标签的HTML文档</span>
   tree <span class="token operator">=</span> etree<span class="token punctuation">.</span>HTML<span class="token punctuation">(</span>html<span class="token punctuation">)</span>

   <span class="token comment"># 获取所有标签内的文本</span>
   text <span class="token operator">=</span> tree<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//text()'</span><span class="token punctuation">)</span>

   <span class="token comment"># 获取特定标签内的文本（例如p标签）</span>
   p_text <span class="token operator">=</span> tree<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//p/text()'</span><span class="token punctuation">)</span>
</code></pre> 
<ul><li>方式三：使用正则表达式：</li></ul> 
<pre><code class="prism language-python">   <span class="token keyword">import</span> re

   <span class="token comment"># 假设html为包含标签的HTML文档</span>
   pattern <span class="token operator">=</span> re<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span><span class="token string">'&amp;lt;[^&amp;gt;]*&amp;gt;'</span><span class="token punctuation">)</span>
   text <span class="token operator">=</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span>pattern<span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">,</span> html<span class="token punctuation">)</span>
</code></pre> 
<p>这些方法可以根据你的需求选择其中之一，它们都可以帮助你提取出HTML标签里面的文本内容。请注意，这些方法在处理复杂的HTML文档时可能会有一些限制，因此建议使用专门的HTML解析库（如BeautifulSoup、lxml）来处理HTML文档以获得更好的灵活性和准确性。</p> 
<h3><a id="3_JSON_112"></a>3. 如何解析JSON格式</h3> 
<ul><li>要获取 JSON 数据中的 <strong>title</strong> 属性的值，你可以使用 Python 的 <strong>json</strong> 模块来解析 JSON 数据。在你的示例数据中，<strong>title</strong> 属性位于 data 字典中的 <strong>pageArticleList</strong> 列表中的每个元素中。</li><li>下面是一个示例代码，演示如何获取 <strong>title</strong> 属性的值：</li></ul> 
<pre><code class="prism language-python"><span class="token keyword">import</span> json

<span class="token comment"># 假设你已经获取到了 JSON 数据，将其存储在 json_data 变量中</span>
json_data <span class="token operator">=</span> <span class="token triple-quoted-string string">'''
{
  "status": 200,
  "message": "success",
  "datatype": "json",
  "data": {
    "pageArticleList": [
      {
        "indexnum": 0,
        "periodid": 20200651,
        "ordinate": "",
        "pageid": 2020035375,
        "pagenum": "6 科协动态",
        "title": "聚焦“科技创新+先进制造” 构建社会化大科普工作格局"
      }
    ]
  }
}
'''</span>

<span class="token comment"># 解析 JSON 数据</span>
data <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>json_data<span class="token punctuation">)</span>

<span class="token comment"># 提取 title 属性的值</span>
title <span class="token operator">=</span> data<span class="token punctuation">[</span><span class="token string">"data"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"pageArticleList"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"title"</span><span class="token punctuation">]</span>

<span class="token comment"># 输出 title 属性的值</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>title<span class="token punctuation">)</span>
</code></pre> 
<ul><li> <p>在上述示例中，我们将示例数据存储在 <strong>json_data</strong> 字符串中。然后，我们使用 <strong>json.loads()</strong> 函数将字符串解析为 JSON 数据，将其存储在 <strong>data</strong> 变量中。</p> </li><li> <p>然后，我们可以通过字典键的层级访问方式提取 <strong>title</strong> 属性的值。在这个示例中，我们使用 <strong>data[“data”][“pageArticleList”][0][“title”]</strong> 来获取 <strong>title</strong> 属性的值。</p> </li><li> <p>最后，我们将结果打印出来或根据需求进行其他处理。</p> </li><li> <p>或者是用get()获取具体属性的值</p> </li></ul> 
<pre><code class="prism language-python"><span class="token builtin">list</span> <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>res<span class="token punctuation">.</span>text<span class="token punctuation">)</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">list</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>i<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'edition'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/29/aa/YyeXjS82_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="4_header_174"></a>4. 如何添加常用的header</h3> 
<ul><li>如果想在实际的代码中设置HTTP请求头，可以通过使用相应编程语言和HTTP库的功能来完成。下面是一个示例，显示如何使用Python的requests库添加常用的请求头：</li></ul> 
<pre><code class="prism language-python"><span class="token keyword">import</span> requests

url <span class="token operator">=</span> <span class="token string">"https://example.com"</span>
headers <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token string">"User-Agent"</span><span class="token punctuation">:</span> <span class="token string">"Mozilla/5.0"</span><span class="token punctuation">,</span>
    <span class="token string">"Accept-Language"</span><span class="token punctuation">:</span> <span class="token string">"en-US,en;q=0.9"</span><span class="token punctuation">,</span>
    <span class="token string">"Referer"</span><span class="token punctuation">:</span> <span class="token string">"https://example.com"</span><span class="token punctuation">,</span>
    <span class="token comment"># 添加其他常用请求头...</span>
<span class="token punctuation">}</span>

response <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">,</span>stream<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> headers<span class="token operator">=</span>headers<span class="token punctuation">)</span>
</code></pre> 
<ul><li>在上述示例中，我们创建了一个headers字典，并将常用的请求头键值对添加到字典中。然后，在发送请求时，通过传递headers参数将这些请求头添加到GET请求中。<br> 请注意，实际使用时，可以根据需要自定义请求头部。常用的请求头包括 “<strong>User-Agent</strong>”（用户代理，用于识别客户端浏览器/设备）、“<strong>Accept-Language</strong>”（接受的语言）、“<strong>Referer</strong>”（来源页面）等。</li></ul> 
<h3><a id="5_div_198"></a>5. 如何合并两个div</h3> 
<pre><code class="prism language-python">    <span class="token comment"># 原始htmldom结构</span>
    html_title <span class="token operator">=</span> soup<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'div'</span><span class="token punctuation">,</span> <span class="token builtin">id</span><span class="token operator">=</span><span class="token string">'block-mit-page-title'</span><span class="token punctuation">)</span>
    html_content <span class="token operator">=</span> soup<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'div'</span><span class="token punctuation">,</span> <span class="token builtin">id</span><span class="token operator">=</span><span class="token string">'block-mit-content'</span><span class="token punctuation">)</span>

    <span class="token comment"># 合并两个部分</span>
    html_title<span class="token punctuation">.</span>append<span class="token punctuation">(</span>html_content<span class="token punctuation">)</span>
</code></pre> 
<h3><a id="6_html_dom_211"></a>6. 如何删除html dom的部分结构</h3> 
<ul><li>要在 Python 中删除已获取的 DOM 结构的一部分，你可以使用 Beautiful Soup 库来解析和操作 HTML。下面是一个示例代码，演示如何删除 DOM 结构的一部分：</li></ul> 
<pre><code class="prism language-python"><span class="token keyword">from</span> bs4 <span class="token keyword">import</span> BeautifulSoup

<span class="token comment"># 假设你已经获取到了 DOM 结构，将其存储在 dom 变量中</span>
dom <span class="token operator">=</span> <span class="token triple-quoted-string string">'''
&amp;lt;div class="container"&amp;gt;
    &amp;lt;h1&amp;gt;Hello, World!&amp;lt;/h1&amp;gt;
    &amp;lt;p&amp;gt;This is a paragraph.&amp;lt;/p&amp;gt;
&amp;lt;/div&amp;gt;
'''</span>

<span class="token comment"># 创建 Beautiful Soup 对象</span>
soup <span class="token operator">=</span> BeautifulSoup<span class="token punctuation">(</span>dom<span class="token punctuation">,</span> <span class="token string">'html.parser'</span><span class="token punctuation">)</span>

<span class="token comment"># 找到要删除的部分</span>
div_element <span class="token operator">=</span> soup<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'div'</span><span class="token punctuation">,</span> class_<span class="token operator">=</span><span class="token string">'container'</span><span class="token punctuation">)</span>
div_element<span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 输出修改后的 DOM 结构</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>soup<span class="token punctuation">.</span>prettify<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<ul><li>在上述示例中，我们首先将 DOM 结构存储在 <strong>dom</strong> 变量中。然后，我们使用 Beautiful Soup 创建了一个解析对象 <strong>soup</strong>。<br> 接下来，我们使用 <strong>find()</strong> 方法找到了要删除的部分，这里是 <strong>&lt;div class=“container”&gt;</strong>。然后，我们使用 <strong>extract()</strong> 方法将该元素从 DOM 结构中删除。</li><li>最后，我们使用 <strong>prettify()</strong> 方法将修改后的 DOM 结构输出，以便查看结果。<br> <code>在实际应用中，需要根据要删除的部分的选择器和属性进行适当的调整。</code></li></ul> 
<h3><a id="7_div_253"></a>7. 如何一次性获取所有div标签里的文本</h3> 
<ul><li>要一次性获取所有&lt;div&gt;标签里的文本，你可以使用BeautifulSoup库或lxml库进行解析。以下是使用这两个库的示例代码：</li><li>方式一：使用BeautifulSoup库：</li></ul> 
<pre><code class="prism language-python"><span class="token keyword">from</span> bs4 <span class="token keyword">import</span> BeautifulSoup

<span class="token comment"># 假设html为包含标签的HTML文档</span>
soup <span class="token operator">=</span> BeautifulSoup<span class="token punctuation">(</span>html<span class="token punctuation">,</span> <span class="token string">'html.parser'</span><span class="token punctuation">)</span>

<span class="token comment"># 查找所有div标签并获取其文本内容</span>
div_texts <span class="token operator">=</span> <span class="token punctuation">[</span>div<span class="token punctuation">.</span>get_text<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> div <span class="token keyword">in</span> soup<span class="token punctuation">.</span>find_all<span class="token punctuation">(</span><span class="token string">'div'</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre> 
<ul><li>方式二：使用lxml库：</li></ul> 
<pre><code class="prism language-python"><span class="token keyword">from</span> lxml <span class="token keyword">import</span> etree

<span class="token comment"># 假设html为包含标签的HTML文档</span>
tree <span class="token operator">=</span> etree<span class="token punctuation">.</span>HTML<span class="token punctuation">(</span>html<span class="token punctuation">)</span>

<span class="token comment"># 使用XPath查找所有div标签并获取其文本内容</span>
div_texts <span class="token operator">=</span> tree<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//div//text()'</span><span class="token punctuation">)</span>
</code></pre> 
<ul><li>使用这些代码，你可以一次性获取所有的&lt;div&gt;标签里的文本内容。请注意，这些方法返回的结果是一个列表，列表中的每个元素对应一个&lt;div&gt;标签的文本内容。你可以根据需要进一步处理这些文本内容。</li></ul> 
<h3><a id="8_python_286"></a>8. python爬虫如何改变响应文本字符集编码</h3> 
<ul><li> <p>在Python爬虫中，你可以通过以下几种方法来改变响应文本的字符集编码：</p> </li><li> <p>方式一：使用response.encoding属性：当使用requests库发送请求并获取到响应对象后，可以通过response.encoding属性来指定响应文本的字符集编码。根据响应中的内容，可以尝试不同的编码进行设置，例如UTF-8、GBK等。示例代码如下：</p> </li></ul> 
<pre><code class="prism language-python"><span class="token keyword">import</span> requests

response <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'https://example.com'</span><span class="token punctuation">)</span>
response<span class="token punctuation">.</span>encoding <span class="token operator">=</span> <span class="token string">'UTF-8'</span>  <span class="token comment"># 设置响应文本的字符集编码为UTF-8</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>text<span class="token punctuation">)</span>
</code></pre> 
<p><code>apparent_encoding用于获取响应内容的推测字符集编码,是一个只读属性，它只返回推测的字符集编码，并不能用于设置或更改字符集编码。如果需要更改字符集编码，请使用response.encoding属性进行设置</code></p> 
<ul><li>方式二：使用chardet库自动检测字符集编码：如果你不确定响应的字符集编码是什么，可以使用chardet库来自动检测响应文本的字符集编码。该库可以分析文本中的字符分布情况，并猜测出可能的字符集编码。示例代码如下：</li></ul> 
<pre><code class="prism language-python"><span class="token keyword">import</span> requests
<span class="token keyword">import</span> chardet

response <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'https://example.com'</span><span class="token punctuation">)</span>
encoding <span class="token operator">=</span> chardet<span class="token punctuation">.</span>detect<span class="token punctuation">(</span>response<span class="token punctuation">.</span>content<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">'encoding'</span><span class="token punctuation">]</span>  <span class="token comment"># 检测响应文本的字符集编码</span>
response<span class="token punctuation">.</span>encoding <span class="token operator">=</span> encoding  <span class="token comment"># 设置响应文本的字符集编码</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>text<span class="token punctuation">)</span>
</code></pre> 
<ul><li>方式三：使用Unicode编码：如果你无法确定响应文本的正确字符集编码，你可以将文本内容转换为Unicode编码，这样就不需要指定字符集编码了。示例代码如下：</li></ul> 
<pre><code class="prism language-python"><span class="token keyword">import</span> requests

response <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'https://example.com'</span><span class="token punctuation">)</span>
text <span class="token operator">=</span> response<span class="token punctuation">.</span>content<span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token string">'unicode-escape'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span>
</code></pre> 
<ul><li>以上是三种常见的方法来改变响应文本的字符集编码。根据具体情况选择最适合的方法来处理爬取的网页内容。记住，在处理字符集编码时，要注意处理异常情况，例如编码错误或无法识别字符集等。</li></ul> 
<h3><a id="9__324"></a>9. 如何进行字符集转码</h3> 
<ul><li> <p>字符集转码是指将文本从一种字符集编码转换为另一种字符集编码的过程。在Python中，可以使用**encode()<strong>和</strong>decode()**方法进行字符集转码操作。</p> </li><li> <p>方式一： <strong>encode(encoding)</strong> 将文本从当前字符集编码转换为指定的编码。其中，<strong>encoding</strong>参数是目标编码格式的字符串表示。示例代码如下：</p> </li></ul> 
<pre><code class="prism language-python">text <span class="token operator">=</span> <span class="token string">"你好"</span>
encoded_text <span class="token operator">=</span> text<span class="token punctuation">.</span>encode<span class="token punctuation">(</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>  <span class="token comment"># 将文本从当前编码转换为UTF-8编码</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>encoded_text<span class="token punctuation">)</span>
</code></pre> 
<ul><li>方式二：<strong>decode(encoding)</strong> 将文本从指定的编码格式解码为当前字符集编码。其中，<strong>encoding</strong>参数是原始编码格式的字符串表示。示例代码如下：</li></ul> 
<pre><code class="prism language-python">encoded_text <span class="token operator">=</span> <span class="token string">b'\xe4\xbd\xa0\xe5\xa5\xbd'</span>  <span class="token comment"># UTF-8 编码的字节串</span>
decoded_text <span class="token operator">=</span> encoded_text<span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>  <span class="token comment"># 将字节串从UTF-8解码为Unicode文本</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>decoded_text<span class="token punctuation">)</span>
</code></pre> 
<ul><li>在进行字符集转码时，需要确保原始文本和目标编码相匹配。如果不确定原始字符集，可以先使用字符集检测工具（如chardet）来确定原始编码，然后再进行转码操作。</li><li>使用正确的字符集编码进行转码操作可以确保文本在不同环境中的正确显示和处理。</li></ul> 
<h3><a id="10_responsetext__responecontent_352"></a>10. response.text 和 respone.content的区别</h3> 
<p>在许多编程语言的HTTP请求库中，比如Python的requests库，有两个常用的属性用于获取HTTP响应的内容：response.text和response.content。区别如下：</p> 
<ul><li>response.text：</li></ul> 
<blockquote> 
 <p><font size="3">1. response.text返回的是一个字符串，表示HTTP响应的内容。<br> 2. 这个字符串是根据HTTP响应的字符编码来解码的，默认使用UTF-8编码。<br> 3. 如果响应中包含了其他编码的内容，那么可以通过指定response.encoding属性来手动指定相应的编码方式进行解码。</font></p> 
</blockquote> 
<ul><li>response.content：</li></ul> 
<blockquote> 
 <p><font size="3"> 1. response.content返回的是一个字节流，表示HTTP响应的内容。<br> 2. 这个字节流是原始的二进制数据，没有进行任何编码解码操作。<br> 3. response.content适用于处理二进制文件，比如图片、音视频文件等。</font></p> 
</blockquote> 
<p>简而言之，response.text适用于处理文本内容，会自动进行编码解码操作，而response.content适用于处理二进制内容，返回的是原始字节流。</p> 
<p>使用哪个属性取决于你处理的内容类型和需求。如果你处理的是文本内容，比如HTML、JSON数据等，那么通常使用response.text。如果你处理的是二进制文件，比如图像或音视频文件，那么使用response.content更合适。</p> 
<h3><a id="11_post_372"></a>11. 如何发送post请求访问页面</h3> 
<p>解析一个请求主要关注以下几个方面</p> 
<ul><li>请求路径</li><li>请求参数（post请求是隐含参数，浏览器发送的是post请求）</li><li>请求头</li></ul> 
<p><img src="https://images2.imgbox.com/13/30/DWt78Xeo_o.png" alt="在这里插入图片描述"></p> 
<ul><li>请求类型</li></ul> 
<p>以下是一个示例代码</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> json

<span class="token keyword">import</span> requests
<span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    url <span class="token operator">=</span> <span class="token string">'https://www.gzyouthnews.org.cn/index/index'</span>
    header <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
        <span class="token string">'X-Requested-With'</span><span class="token punctuation">:</span><span class="token string">'XMLHttpRequest'</span>
    <span class="token punctuation">}</span>
    data<span class="token operator">=</span><span class="token punctuation">{<!-- --></span>
        <span class="token string">'act'</span><span class="token punctuation">:</span><span class="token string">'list'</span><span class="token punctuation">,</span>
        <span class="token string">'date'</span><span class="token punctuation">:</span><span class="token string">'2023-08-10'</span><span class="token punctuation">,</span>
        <span class="token string">'paper_id'</span><span class="token punctuation">:</span><span class="token number">1</span>
    <span class="token punctuation">}</span>
    res <span class="token operator">=</span> requests<span class="token punctuation">.</span>post<span class="token punctuation">(</span>url<span class="token operator">=</span>url<span class="token punctuation">,</span>headers<span class="token operator">=</span>header<span class="token punctuation">,</span>data<span class="token operator">=</span>data<span class="token punctuation">)</span>
    <span class="token builtin">list</span> <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>res<span class="token punctuation">.</span>text<span class="token punctuation">)</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">list</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>i<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'edition'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    main<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="12__url__410"></a>12. 如何获取 url 中的参数</h3> 
<p>要从给定的 URL 中获取参数 page=100，你可以使用 URL 解析库来解析 URL，并提取出所需的参数。<br> 以下是使用 Python 的 urllib.parse 模块解析 URL 参数的示例代码：</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> urllib<span class="token punctuation">.</span>parse <span class="token keyword">import</span> urlparse<span class="token punctuation">,</span> parse_qs

url <span class="token operator">=</span> <span class="token string">"https://blog.csdn.net/phoenix/web/v1/comment/list/131760390?page=100&amp;amp;size=10&amp;amp;fold=unfold&amp;amp;commentId="</span>

parsed_url <span class="token operator">=</span> urlparse<span class="token punctuation">(</span>url<span class="token punctuation">)</span>
query_params <span class="token operator">=</span> parse_qs<span class="token punctuation">(</span>parsed_url<span class="token punctuation">.</span>query<span class="token punctuation">)</span>

page_value <span class="token operator">=</span> query_params<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"page"</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>page_value<span class="token punctuation">)</span>
</code></pre> 
<p>在上述示例中，我们首先使用 <strong>urlparse</strong> 函数解析 URL，然后使用 <strong>parse_qs</strong> 函数解析查询参数部分。<strong>parse_qs</strong> 函数将查询参数解析为字典，其中键是参数名称，值是参数值的列表。</p> 
<p>然后，我们使用 <strong>query_params.get(“page”, [None])[0]</strong> 从字典中获取名为 <strong>page</strong> 的参数值。这将返回参数的值，如果该参数不存在，则返回 <strong>None</strong>。</p> 
<p>输出结果将是 <strong>100</strong>，这是从 URL <strong>https://blog.csdn.net/phoenix/web/v1/comment/list/131760390?page=100&amp;size=10&amp;fold=unfold&amp;commentId=</strong> 中提取的 <strong>page</strong> 参数的值。</p> 
<p>请注意，如果 URL 的参数值是字符串形式，你可能需要根据需要进行进一步的类型转换。</p> 
<h3><a id="13__436"></a>13. 如何下载图片</h3> 
<p>在Python中，你可以使用requests库来下载图片。以下是一个简单的脚本，演示了如何使用requests库下载指定URL的图片：</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> requests
<span class="token keyword">import</span> os

<span class="token comment"># 图片的URL</span>
url <span class="token operator">=</span> <span class="token string">'https://news.mit.edu//sites/default/files/styles/news_article__image_gallery/public/images/202310/moire-quasicrystal-mit-00.png?itok=DntO93gr'</span>

<span class="token comment"># 图片保存的文件名</span>
filename <span class="token operator">=</span> <span class="token string">'moire-quasicrystal-mit-00.png'</span>

<span class="token comment"># 图片保存的路径</span>
save_path <span class="token operator">=</span> <span class="token string">r'D:\imgs'</span>

<span class="token comment"># 确保保存的文件夹存在</span>
<span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>save_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>save_path<span class="token punctuation">)</span>

<span class="token comment"># 完整的保存文件路径</span>
full_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>save_path<span class="token punctuation">,</span> filename<span class="token punctuation">)</span>

<span class="token comment"># 下载图片</span>
response <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">)</span>

<span class="token comment"># 检查图片是否成功下载</span>
<span class="token keyword">if</span> response<span class="token punctuation">.</span>status_code <span class="token operator">==</span> <span class="token number">200</span><span class="token punctuation">:</span>
    <span class="token comment"># 将图片内容写入到文件中</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>full_path<span class="token punctuation">,</span> <span class="token string">'wb'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        f<span class="token punctuation">.</span>write<span class="token punctuation">(</span>response<span class="token punctuation">.</span>content<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'图片已保存到 </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>full_path<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
<span class="token keyword">else</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'下载失败，状态码：</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>response<span class="token punctuation">.</span>status_code<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>

</code></pre> 
<h2><a id="_474"></a>总结</h2> 
<p>欢迎各位留言交流以及批评指正，如果文章对您有帮助或者觉得作者写的还不错可以点一下关注，点赞，收藏支持一下。<br> （博客的参考源码可以在我主页的资源里找到，如果在学习的过程中有什么疑问欢迎大家在评论区向我提出）</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/e7402f04f722e89aaeaa2eaa6964be2a/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【cmake】pkg_check_modules 使用详解</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/ce9c54356f3b3336c518fd7d8f6a6f5d/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【数据库】关系模式规范化（设计范式）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>