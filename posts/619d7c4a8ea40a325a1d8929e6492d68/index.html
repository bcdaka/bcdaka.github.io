<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【spark sedona k8s】spark(sedona) on kubernetes(k8s) 搭建，使用spark-operator提交任务 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/619d7c4a8ea40a325a1d8929e6492d68/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="【spark sedona k8s】spark(sedona) on kubernetes(k8s) 搭建，使用spark-operator提交任务">
  <meta property="og:description" content="【spark sedona k8s】spark(sedona) on kubernetes(k8s) 搭建，使用spark-operator提交任务 引言 成功搭建 spark on yarn 后，总是觉得它与我们的服务之间不好联动。之前我们的服务都运行在 docker 之中，spark 又运行在 hadoop 中，我们要想通过服务控制集群执行任务，结合现在的情况，已有的解决方案十分麻烦，要么就是部署一个服务在 hadoop 的 master 节点上，通过系统命令来控制，要么就是安装第三方工具。总之不管哪种办法我都觉得不够好，于是便想到在 k8s 上跑 spark。
一、架构介绍 相较于之前的 spark 由 yarn 调度，使用 k8s 调度最大的好处是可以弹性伸缩，整个 k8s 集群中除了跑其他服务以外还能跑 spark 任务，其他服务不忙的时候，可以给 spark 的任务多一点资源。又因为 k8s 是自带 REST Api 的，所以我们在 k8s 上跑的服务可以通过访问 ApiServer 接口的方式直接向 k8s 提交 spark 任务。它的流程看起来像这样：
这样看起来就很优雅了，将 spark 的调度交给 k8s，k8s 能动态管理我们的任务所需资源，我们与 spark 的交互也可以挪到 java 服务上，k8s 的健壮性、容错性我就不多提了，集群搭建起来也挺简单的。接下来我们就开始搭建 spark on k8s 并且开启 spark operator 管理任务。
二、搭建 在正式开始之前，你得有一个能正常运行的 k8s 集群，接下来的操作默认你有了一个能正常运行的 k8s 集群。如果你的集群还没搭建起来，参考我的 另外一篇帖子，先搭建集群。">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-05-30T10:24:17+08:00">
    <meta property="article:modified_time" content="2024-05-30T10:24:17+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【spark sedona k8s】spark(sedona) on kubernetes(k8s) 搭建，使用spark-operator提交任务</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="spark_sedona_k8ssparksedona_on_kubernetesk8s_sparkoperator_0"></a>【spark sedona k8s】spark(sedona) on kubernetes(k8s) 搭建，使用spark-operator提交任务</h2> 
<h3><a id="_2"></a>引言</h3> 
<blockquote> 
 <p>成功搭建 <code>spark on yarn</code> 后，总是觉得它与我们的服务之间不好联动。之前我们的服务都运行在 <code>docker</code> 之中，<code>spark</code> 又运行在 <code>hadoop</code> 中，我们要想通过服务控制集群执行任务，结合现在的情况，已有的解决方案十分麻烦，要么就是部署一个服务在 <code>hadoop</code> 的 <code>master</code> 节点上，通过系统命令来控制，要么就是安装第三方工具。总之不管哪种办法我都觉得不够好，于是便想到在 <code>k8s</code> 上跑 <code>spark</code>。</p> 
</blockquote> 
<h3><a id="_5"></a>一、架构介绍</h3> 
<blockquote> 
 <p>相较于之前的 <code>spark</code> 由 <code>yarn</code> 调度，使用 <code>k8s</code> 调度最大的好处是可以弹性伸缩，整个 <code>k8s</code> 集群中除了跑其他服务以外还能跑 <code>spark</code> 任务，其他服务不忙的时候，可以给 <code>spark</code> 的任务多一点资源。又因为 <code>k8s</code> 是自带 <code>REST Api</code> 的，所以我们在 <code>k8s</code> 上跑的服务可以通过访问 <code>ApiServer</code> 接口的方式直接向 <code>k8s</code> 提交 <code>spark</code> 任务。它的流程看起来像这样：</p> 
</blockquote> 
<p><img src="https://images2.imgbox.com/f3/22/jFycV7pX_o.png" alt="在这里插入图片描述"></p> 
<blockquote> 
 <p>这样看起来就很优雅了，将 <code>spark</code> 的调度交给 <code>k8s</code>，<code>k8s</code> 能动态管理我们的任务所需资源，我们与 <code>spark</code> 的交互也可以挪到 <code>java</code> 服务上，<code>k8s</code> 的健壮性、容错性我就不多提了，集群搭建起来也挺简单的。接下来我们就开始搭建 <code>spark on k8s</code> 并且开启 <code>spark operator</code> 管理任务。</p> 
</blockquote> 
<h3><a id="_12"></a>二、搭建</h3> 
<blockquote> 
 <p>在正式开始之前，你得有一个能正常运行的 <code>k8s</code> 集群，接下来的操作默认你有了一个能正常运行的 <code>k8s</code> 集群。如果你的集群还没搭建起来，参考我的 <a href="https://blog.csdn.net/m0_53928179/article/details/139068769">另外一篇帖子</a>，先搭建集群。</p> 
</blockquote> 
<h4><a id="1_helm_15"></a>1、安装 <code>helm</code></h4> 
<blockquote> 
 <p>我们可以通过很多方式将 <code>Spark Operator</code> 引入到集群中，可以手动下载源代码来安装，也可以使用 <code>kustomize</code> 来安装，哪种方式都可以，<code>Spark Operator</code> 官方 <a href="https://github.com/kubeflow/spark-operator?tab=readme-ov-file">GitHub地址</a></p> 
</blockquote> 
<blockquote> 
 <p>我们用 <code>helm</code>，所以得先安装一个 <code>helm</code>，执行：</p> 
</blockquote> 
<pre><code class="prism language-sh"><span class="token function">sudo</span> <span class="token function">apt</span> update
<span class="token function">sudo</span> <span class="token function">apt</span> <span class="token function">install</span> <span class="token parameter variable">-y</span> <span class="token function">curl</span> apt-transport-https

<span class="token function">curl</span> https://baltocdn.com/helm/signing.asc <span class="token operator">|</span> <span class="token function">sudo</span> apt-key <span class="token function">add</span> -
<span class="token builtin class-name">echo</span> <span class="token string">"deb https://baltocdn.com/helm/stable/debian/ all main"</span> <span class="token operator">|</span> <span class="token function">sudo</span> <span class="token function">tee</span> /etc/apt/sources.list.d/helm-stable-debian.list

<span class="token function">sudo</span> <span class="token function">apt-get</span> update
<span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> helm
</code></pre> 
<h4><a id="2_helm__Spark_Operator_31"></a>2、添加 <code>helm</code> 仓库，安装 <code>Spark Operator</code></h4> 
<blockquote> 
 <p>需要将 <code>Spark Operator</code> 所在的仓库地址添加进去。<code>Bitnami</code> 提供了 <code>Spark Operator</code> 的 <code>Helm chart</code>。使用以下命令添加 <code>Bitnami</code> 仓库：</p> 
</blockquote> 
<pre><code class="prism language-sh">helm repo <span class="token function">add</span> spark-operator https://kubeflow.github.io/spark-operator
helm repo update
</code></pre> 
<blockquote> 
 <p>安装 <code>Spark Operator</code>：</p> 
</blockquote> 
<pre><code class="prism language-sh">kubectl create namespace spark-operator <span class="token comment"># 创建一个命名空间</span>

helm <span class="token function">install</span> spark-operator spark-operator/spark-operator <span class="token punctuation">\</span>
  <span class="token parameter variable">--namespace</span> spark-operator <span class="token punctuation">\</span>
  <span class="token parameter variable">--set</span> <span class="token assign-left variable">image.repository</span><span class="token operator">=</span>docker.io/kubeflow/spark-operator <span class="token punctuation">\</span> <span class="token comment"># 在这里指定镜像所在的仓库</span>
  <span class="token parameter variable">--set</span> <span class="token assign-left variable">image.tag</span><span class="token operator">=</span>v1beta2-1.4.6-3.5.0 <span class="token punctuation">\</span> <span class="token comment"># 可以在这里指定要安装的版本，但是前提是镜像仓库要存在</span>
  <span class="token parameter variable">--set</span> <span class="token assign-left variable">sparkJobNamespace</span><span class="token operator">=</span>default
</code></pre> 
<blockquote> 
 <p>如果安装报错最后一句是这句：</p> 
</blockquote> 
<pre><code class="prism language-sh">ensure CRDs are installed first
</code></pre> 
<blockquote> 
 <p>执行这个安装 <code>CRDs</code> ：</p> 
</blockquote> 
<pre><code class="prism language-sh">kubectl create <span class="token parameter variable">-f</span> https://raw.githubusercontent.com/GoogleCloudPlatform/spark-on-k8s-operator/master/manifest/crds/sparkoperator.k8s.io_sparkapplications.yaml
kubectl create <span class="token parameter variable">-f</span> https://raw.githubusercontent.com/GoogleCloudPlatform/spark-on-k8s-operator/master/manifest/crds/sparkoperator.k8s.io_scheduledsparkapplications.yaml
</code></pre> 
<blockquote> 
 <p>这是一个在线地址，你也可以将源代码拉下来执行：</p> 
</blockquote> 
<pre><code class="prism language-sh"><span class="token function">git</span> clone https://github.com/GoogleCloudPlatform/spark-on-k8s-operator.git
<span class="token builtin class-name">cd</span> spark-on-k8s-operator

kubectl apply <span class="token parameter variable">-f</span> manifest/crds/sparkoperator.k8s.io_sparkapplications.yaml
kubectl apply <span class="token parameter variable">-f</span> manifest/crds/sparkoperator.k8s.io_scheduledsparkapplications.yaml
</code></pre> 
<blockquote> 
 <p>在线地址执行和拉下来执行的效果是一样的，安装好 <code>CRDs</code> 后再执行上面的安装</p> 
</blockquote> 
<blockquote> 
 <p>执行完后去看看 <code>Pod</code> 的状态，要没有报错：</p> 
</blockquote> 
<pre><code class="prism language-sh">kubectl get pods <span class="token parameter variable">-n</span> spark-operator
</code></pre> 
<p><img src="https://images2.imgbox.com/33/30/QDiK6i45_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="3_80"></a>3、配置账户信息</h4> 
<blockquote> 
 <p>要想执行 <code>Spark</code> 任务，我们在提交任务的时候必需得指定一个 <code>k8s</code> 账户，它得绑定一个有权限的角色，才能有权限向 <code>k8s</code> 集群申请资源，创建一个账户：</p> 
</blockquote> 
<pre><code class="prism language-sh"><span class="token function">vi</span> spark-account.yaml
</code></pre> 
<blockquote> 
 <p>加入内容：</p> 
</blockquote> 
<pre><code class="prism language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> v1
<span class="token key atrule">kind</span><span class="token punctuation">:</span> ServiceAccount
<span class="token key atrule">metadata</span><span class="token punctuation">:</span>
  <span class="token key atrule">name</span><span class="token punctuation">:</span> spark<span class="token punctuation">-</span>account
  <span class="token key atrule">namespace</span><span class="token punctuation">:</span> spark<span class="token punctuation">-</span>operator
</code></pre> 
<blockquote> 
 <p>创建一个角色绑定，我们将刚创建的账户绑定到集群管理员角色：</p> 
</blockquote> 
<pre><code class="prism language-sh"><span class="token function">vi</span> spark-role-binding.yaml
</code></pre> 
<blockquote> 
 <p>加入内容：</p> 
</blockquote> 
<pre><code class="prism language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> rbac.authorization.k8s.io/v1
<span class="token key atrule">kind</span><span class="token punctuation">:</span> ClusterRoleBinding
<span class="token key atrule">metadata</span><span class="token punctuation">:</span>
  <span class="token key atrule">name</span><span class="token punctuation">:</span> spark<span class="token punctuation">-</span>cluster<span class="token punctuation">-</span>role<span class="token punctuation">-</span>binding
<span class="token key atrule">subjects</span><span class="token punctuation">:</span>
<span class="token punctuation">-</span> <span class="token key atrule">kind</span><span class="token punctuation">:</span> ServiceAccount
  <span class="token key atrule">name</span><span class="token punctuation">:</span> spark<span class="token punctuation">-</span>account
  <span class="token key atrule">namespace</span><span class="token punctuation">:</span> spark<span class="token punctuation">-</span>operator
<span class="token key atrule">roleRef</span><span class="token punctuation">:</span>
  <span class="token key atrule">kind</span><span class="token punctuation">:</span> ClusterRole
  <span class="token key atrule">name</span><span class="token punctuation">:</span> cluster<span class="token punctuation">-</span>admin
  <span class="token key atrule">apiGroup</span><span class="token punctuation">:</span> rbac.authorization.k8s.io
</code></pre> 
<blockquote> 
 <p>分别执行两个文件，注意先后顺序：</p> 
</blockquote> 
<pre><code class="prism language-sh">kubectl apply <span class="token parameter variable">-f</span> spark-account.yaml
kubectl apply <span class="token parameter variable">-f</span> spark-role-binding.yaml
</code></pre> 
<blockquote> 
 <p>如果你觉得绑定管理员角色不妥，那么可以自定义一个角色，加入内容大概像：</p> 
</blockquote> 
<pre><code class="prism language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> rbac.authorization.k8s.io/v1
<span class="token key atrule">kind</span><span class="token punctuation">:</span> ClusterRole
<span class="token key atrule">metadata</span><span class="token punctuation">:</span>
  <span class="token key atrule">name</span><span class="token punctuation">:</span> my<span class="token punctuation">-</span>role
<span class="token key atrule">rules</span><span class="token punctuation">:</span>
<span class="token punctuation">-</span> <span class="token key atrule">apiGroups</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">""</span><span class="token punctuation">]</span>
  <span class="token key atrule">resources</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"pods"</span><span class="token punctuation">,</span> <span class="token string">"pods/log"</span><span class="token punctuation">,</span> <span class="token string">"services"</span><span class="token punctuation">,</span> <span class="token string">"configmaps"</span><span class="token punctuation">,</span> <span class="token string">"secrets"</span><span class="token punctuation">,</span> <span class="token string">"persistentvolumeclaims"</span><span class="token punctuation">]</span>
  <span class="token key atrule">verbs</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"get"</span><span class="token punctuation">,</span> <span class="token string">"list"</span><span class="token punctuation">,</span> <span class="token string">"create"</span><span class="token punctuation">,</span> <span class="token string">"delete"</span><span class="token punctuation">,</span> <span class="token string">"watch"</span><span class="token punctuation">]</span>
<span class="token punctuation">-</span> <span class="token key atrule">apiGroups</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"batch"</span><span class="token punctuation">]</span>
  <span class="token key atrule">resources</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"jobs"</span><span class="token punctuation">]</span>
  <span class="token key atrule">verbs</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"get"</span><span class="token punctuation">,</span> <span class="token string">"list"</span><span class="token punctuation">,</span> <span class="token string">"create"</span><span class="token punctuation">,</span> <span class="token string">"delete"</span><span class="token punctuation">,</span> <span class="token string">"watch"</span><span class="token punctuation">]</span>
<span class="token punctuation">-</span> <span class="token key atrule">apiGroups</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">""</span><span class="token punctuation">]</span>
  <span class="token key atrule">resources</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"endpoints"</span><span class="token punctuation">]</span>
  <span class="token key atrule">verbs</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"get"</span><span class="token punctuation">,</span> <span class="token string">"create"</span><span class="token punctuation">,</span> <span class="token string">"delete"</span><span class="token punctuation">,</span> <span class="token string">"watch"</span><span class="token punctuation">]</span>
<span class="token punctuation">-</span> <span class="token key atrule">apiGroups</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"apps"</span><span class="token punctuation">]</span>
  <span class="token key atrule">resources</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"deployments"</span><span class="token punctuation">]</span>
  <span class="token key atrule">verbs</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"get"</span><span class="token punctuation">,</span> <span class="token string">"list"</span><span class="token punctuation">,</span> <span class="token string">"create"</span><span class="token punctuation">,</span> <span class="token string">"delete"</span><span class="token punctuation">,</span> <span class="token string">"watch"</span><span class="token punctuation">]</span>
</code></pre> 
<h4><a id="4_147"></a>4、测试</h4> 
<blockquote> 
 <p>编写一个定义 <code>Spark on K8s</code> 任务的 <code>yaml</code> 文件，加入内容：</p> 
</blockquote> 
<pre><code class="prism language-yaml"><span class="token key atrule">apiVersion</span><span class="token punctuation">:</span> <span class="token string">"sparkoperator.k8s.io/v1beta2"</span>
<span class="token key atrule">kind</span><span class="token punctuation">:</span> SparkApplication
<span class="token key atrule">metadata</span><span class="token punctuation">:</span>
  <span class="token key atrule">name</span><span class="token punctuation">:</span> spark<span class="token punctuation">-</span>pi
  <span class="token key atrule">namespace</span><span class="token punctuation">:</span> default
<span class="token key atrule">spec</span><span class="token punctuation">:</span>
  <span class="token key atrule">type</span><span class="token punctuation">:</span> Scala
  <span class="token key atrule">mode</span><span class="token punctuation">:</span> cluster
  <span class="token key atrule">image</span><span class="token punctuation">:</span> docker.io/spark<span class="token punctuation">:</span>3.5.1 <span class="token comment"># 这里与我们安装的spark operator版本不一样，但是我使用没问题</span>
  <span class="token key atrule">imagePullPolicy</span><span class="token punctuation">:</span> Always
  <span class="token key atrule">mainClass</span><span class="token punctuation">:</span> org.apache.spark.examples.SparkPi
  <span class="token key atrule">mainApplicationFile</span><span class="token punctuation">:</span> <span class="token string">"local:///opt/spark/examples/jars/spark-examples_2.12-3.5.1.jar"</span>
  <span class="token key atrule">sparkVersion</span><span class="token punctuation">:</span> <span class="token string">"3.5.1"</span>
  <span class="token key atrule">restartPolicy</span><span class="token punctuation">:</span>
    <span class="token key atrule">type</span><span class="token punctuation">:</span> Never
  <span class="token key atrule">driver</span><span class="token punctuation">:</span>
    <span class="token key atrule">cores</span><span class="token punctuation">:</span> <span class="token number">2</span>
    <span class="token key atrule">memory</span><span class="token punctuation">:</span> <span class="token string">"2G"</span>
    <span class="token key atrule">labels</span><span class="token punctuation">:</span>
      <span class="token key atrule">version</span><span class="token punctuation">:</span> 3.5.1
    <span class="token key atrule">serviceAccount</span><span class="token punctuation">:</span> spark<span class="token punctuation">-</span>account <span class="token comment"># 这里指定我们刚才创建的有权限的账户</span>
    <span class="token key atrule">env</span><span class="token punctuation">:</span>
      <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> SPARK_MODE
        <span class="token key atrule">value</span><span class="token punctuation">:</span> <span class="token string">"driver"</span>
  <span class="token key atrule">executor</span><span class="token punctuation">:</span>
    <span class="token key atrule">cores</span><span class="token punctuation">:</span> <span class="token number">1</span>
    <span class="token key atrule">instances</span><span class="token punctuation">:</span> <span class="token number">4</span>
    <span class="token key atrule">memory</span><span class="token punctuation">:</span> <span class="token string">"1G"</span>
    <span class="token key atrule">labels</span><span class="token punctuation">:</span>
      <span class="token key atrule">version</span><span class="token punctuation">:</span> 3.5.1
  <span class="token key atrule">arguments</span><span class="token punctuation">:</span>
    <span class="token punctuation">-</span> <span class="token string">"10000"</span>
</code></pre> 
<blockquote> 
 <p><code>***</code> 特别注意的是，一定要指定有权限的账户来运行任务，不然会报各种各样的错，我就是报了很多错，干脆直接用集群管理员的角色来运行任务，就没再报错了。</p> 
</blockquote> 
<blockquote> 
 <p>查看是否开启了任务，执行：</p> 
</blockquote> 
<pre><code class="prism language-sh">kubectl get sparkapplications
</code></pre> 
<p><img src="https://images2.imgbox.com/80/98/gEICoAFs_o.png" alt="在这里插入图片描述"></p> 
<blockquote> 
 <p>我的已经执行完了，你的应该看到提交或者执行中</p> 
</blockquote> 
<blockquote> 
 <p>想看具体的日志，可以去看 <code>Pod</code> 的日志：</p> 
</blockquote> 
<pre><code class="prism language-sh">kubectl logs spark-pi-driver
</code></pre> 
<blockquote> 
 <p>我们在开启任务后，会发现多了一个 <code>driver</code> 的 <code>pod</code> 和 <code>worker</code> 的 <code>pod</code>，<code>worker</code> 的 <code>pod</code> 数量取决于我们之前提交任务的配置文件中指定了几个，当然它也能动态的分配。例如我们的 <code>spark-pi.yaml</code> 任务就指定了四个 <code>worker pod</code>，我们查看一下：</p> 
</blockquote> 
<pre><code class="prism language-sh">kubectl get pods  <span class="token comment"># 不加 -n default 的话默认就是 -n default</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/7f/e2/67mbUVrc_o.png" alt="在这里插入图片描述"></p> 
<blockquote> 
 <p>果然就是启动了四个 <code>pod</code> 来运行任务，等它执行完，我们再看 <code>driver</code> 的日志：</p> 
</blockquote> 
<pre><code class="prism language-sh">kubectl logs spark-pi-driver
</code></pre> 
<p><img src="https://images2.imgbox.com/75/dd/XbUGuhtN_o.png" alt="在这里插入图片描述"></p> 
<blockquote> 
 <p>得到了结果，搭建成功</p> 
</blockquote> 
<h3><a id="_Sedona_211"></a>三、关于 <code>Sedona</code></h3> 
<blockquote> 
 <p>搭建 <code>Sedona</code> 就更简单了，我们只需要将上面用的 <code>Spark</code> 的镜像拉下来，写一个 <code>Dockerfile</code> ，将 <code>Sedona</code> 的插件 <code>jar</code> 包丢到对应的文件夹中去，重新构建镜像并上传到私有仓库或者公共仓库，只要 <code>k8s</code> 能拉取到就行，然后在 <code>任务.yaml</code> 中改一下镜像地址就行了，这里就不演示了，因为我也没弄，这个不难。</p> 
</blockquote> 
<h3><a id="_215"></a>四、关于历史服务器</h3> 
<blockquote> 
 <p>如果想用历史服务器，得将日志写到一个公共的持久化存储空间中，然后在 <code>k8s</code> 中跑一个历史服务器去读取日志文件，暴露一个 <code>service</code> 或 <code>ingress</code> 就能访问。</p> 
</blockquote> 
<h3><a id="_218"></a>五、测试</h3> 
<blockquote> 
 <p>我弄了四台机器，一台是 <code>12C 64G</code>，其他三台是 <code>12C 16G</code>，测试上面的 <code>spark-pi</code> 示例，计算 <code>五十万次</code>，开启8个 <code>worker pod</code>，结果是：</p> 
</blockquote> 
<p><img src="https://images2.imgbox.com/57/51/BQWQExvv_o.png" alt="在这里插入图片描述"></p> 
<blockquote> 
 <p>耗时 <code>78s</code>，将计算次数换为 <code>一百万次</code>，开启16个 <code>worker pod</code>，结果为：</p> 
</blockquote> 
<p><img src="https://images2.imgbox.com/42/e2/6hGeOubz_o.png" alt="在这里插入图片描述"></p> 
<blockquote> 
 <p>耗时 <code>142s</code>，我记得之前使用 <code>Spark on Yarn</code> 的时候也是计算五十万次，结果是两分钟多一点，计算一百万次失败了，半个小时没结果。现在使用 <code>Spark on Kubernetes</code>，效率有所提升，不知道是我的实验变量没控制好还是怎么的，有点意外，不过除了效率之外，在 <code>k8s</code> 上跑 <code>Spark</code> 的优点我觉得还是灵活性强，跑任务的时候一堆 <code>worker pod</code> 就创建出来跑任务了，任务结束后 <code>worker pod</code> 就都没了，不会占用集群中其他服务的资源，这点挺好的。此外由于 <code>k8s</code> 是自带 <code>REST Api</code> 的，所以和我们自己写的服务交互起来就比较方便，我们可以通过 <code>REST Api</code> 提交任务，查看任务等等</p> 
</blockquote> 
<h3><a id="_227"></a>写在最后</h3> 
<blockquote> 
 <p>当然，我上面的这些办法可能不是最好的，我也在探索最好的实践，写到此处只是自己查找时方便，如果能顺道帮助你解决一些问题那再好不过。<br> 学无止尽，瑞斯拜！</p> 
</blockquote>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/507e731fc9aa320c0db4cf4cf66281b2/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Midjourney指令的终极列表：完整指南</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/ed08751721daff385ad301d98af42565/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Stable Diffusion为什么生成的图片总是糊的？</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>