<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Hadoop 2.0 大家族（三） - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/544166ee1da71087b4bae093b8f6b2bb/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="Hadoop 2.0 大家族（三）">
  <meta property="og:description" content="目录 五、Hive（一）Hive简介（二）Hive入门 六、Oozie（一）Oozie简介（二）Oozie入门 五、Hive Hive是一个构建在Hadoop上的数据仓库框架，它起源于Facebook内部信息处理平台。Hive是一个构建在Hadoop上的数据仓库框架，它起源于Facebook内部信息处理平台。
（一）Hive简介 1、Hive基本框架
Hive包含Shell环境、元数据库、解析器和数据仓库等组件，其体系结构如图所示：
（1）用户接口：包括Hive Shell、Thrift客户端、Web接口。
（2）Thrift服务器：当Hive以服务器模式运行时，作为Thrift服务器，供客户端连接。
（3）元数据库：Hive元数据（如表信息）的集中存放地。
（4）解析器：将Hive语句翻译成MapReduce操作。
（5）Hadoop：底层分布式存储和计算引擎。
2、Hive语法
Hive的SQL称为HiveQL，它与大部分的SQL语法兼容，但是并不完全类似SQL。
（1）数据类型
基本类型：数值型、布尔型和字符串；
复杂类型：ARRAY、MAP和STRUCT。
（2）操作和函数
HiveQL操作符类似于SQL操作符，Hive提供了数理统计、字符串操作、条件操作等大量的内置函数，用户还可以自己编写函数。
（二）Hive入门 1、Hive部署
（1）内嵌模式
此模式是安装时的默认部署模式，此时元数据存储在一个内存数据库Derby中，并且所有组件（如数据库、元数据服务）都运行在同一个进程内。这种模式下，一段时间内只支持一个活动用户。但这种模式配置简单，所需机器较少，限于集群规模，本节Hive部署即采用这种模式。
（2）本地模式
此模式是Hive元数据服务依旧运行在Hive服务主进程中，但元数据存储在独立数据库中（可以是远程机器），当涉及元数据操作时，Hive服务中的元数据服务模块会通过JDBC和存储于DB里的元数据数据库交互。
（3）完全远程模式
元数据服务以独立进程运行，并且元数据存储在一个独立的数据库里。
下面讲解内嵌模式部署。
① 下载并安装Hive。
[root@iClient ~]# sudo yum install hive ② HDFS里新建Hive存储目录。
[root@iClient ~]# sudo –u hdfs hdfs dfs –mkdir /user/hive #HDFS里新建Hive存储目录 [root@iClient ~]# sudo –u hdfs hdfs dfs –chmod –R 1777 /user/hive #为目录设置适当权限 只需上述两步就可以直接使用Hive了，当然，也可以使用jps命令查看Hive进程。
2、Hive接口
Hive提供了强大的访问接口，从下图中即可看出Hive提供的诸多接口，此外也可以通过Hcatalog、Pig、BeeLine等访问Hive。
【例4】 按要求完成问题：
① 进入Hive命令行接口，获取Hive函数列表并单独查询count函数用法。">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-06-22T17:24:21+08:00">
    <meta property="article:modified_time" content="2024-06-22T17:24:21+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Hadoop 2.0 大家族（三）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>目录</h4> 
 <ul><li><ul><li><a href="#Hive_4" rel="nofollow">五、Hive</a></li><li><ul><li><a href="#Hive_6" rel="nofollow">（一）Hive简介</a></li><li><a href="#Hive_32" rel="nofollow">（二）Hive入门</a></li></ul> 
   </li><li><a href="#Oozie_105" rel="nofollow">六、Oozie</a></li><li><ul><li><a href="#Oozie_107" rel="nofollow">（一）Oozie简介</a></li><li><a href="#Oozie_111" rel="nofollow">（二）Oozie入门</a></li></ul> 
  </li></ul> 
 </li></ul> 
</div> 
<p></p> 
<hr> 
<h3><a id="Hive_4"></a>五、Hive</h3> 
<p>  Hive是一个构建在Hadoop上的数据仓库框架，它起源于Facebook内部信息处理平台。Hive是一个构建在Hadoop上的数据仓库框架，它起源于Facebook内部信息处理平台。</p> 
<h4><a id="Hive_6"></a>（一）Hive简介</h4> 
<p><strong>1、Hive基本框架</strong></p> 
<p>  Hive包含Shell环境、元数据库、解析器和数据仓库等组件，其体系结构如图所示：</p> 
<p><img src="https://images2.imgbox.com/3c/19/M5umltHx_o.png" alt="在这里插入图片描述" width="600"><br> （1）用户接口：包括Hive Shell、Thrift客户端、Web接口。<br> （2）Thrift服务器：当Hive以服务器模式运行时，作为Thrift服务器，供客户端连接。<br> （3）元数据库：Hive元数据（如表信息）的集中存放地。<br> （4）解析器：将Hive语句翻译成MapReduce操作。<br> （5）Hadoop：底层分布式存储和计算引擎。</p> 
<p><strong>2、Hive语法</strong></p> 
<p>  Hive的SQL称为HiveQL，它与大部分的SQL语法兼容，但是并不完全类似SQL。</p> 
<p><strong>（1）数据类型</strong></p> 
<p>  基本类型：数值型、布尔型和字符串；<br>   复杂类型：ARRAY、MAP和STRUCT。</p> 
<p><strong>（2）操作和函数</strong></p> 
<p>  HiveQL操作符类似于SQL操作符，Hive提供了数理统计、字符串操作、条件操作等大量的内置函数，用户还可以自己编写函数。</p> 
<h4><a id="Hive_32"></a>（二）Hive入门</h4> 
<p><strong>1、Hive部署</strong></p> 
<p><img src="https://images2.imgbox.com/18/82/KHjVYfkC_o.png" alt="在这里插入图片描述" width="300"><br> <strong>（1）内嵌模式</strong></p> 
<p>  此模式是安装时的默认部署模式，此时元数据存储在一个内存数据库Derby中，并且所有组件（如数据库、元数据服务）都运行在同一个进程内。这种模式下，一段时间内只支持一个活动用户。但这种模式配置简单，所需机器较少，限于集群规模，本节Hive部署即采用这种模式。</p> 
<p><img src="https://images2.imgbox.com/97/a3/AI9KVUfN_o.png" alt="在这里插入图片描述" width="400"><br> <strong>（2）本地模式</strong></p> 
<p>  此模式是Hive元数据服务依旧运行在Hive服务主进程中，但元数据存储在独立数据库中（可以是远程机器），当涉及元数据操作时，Hive服务中的元数据服务模块会通过JDBC和存储于DB里的元数据数据库交互。</p> 
<p><img src="https://images2.imgbox.com/93/69/lXptYkTs_o.png" alt="在这里插入图片描述" width="400"><br> <strong>（3）完全远程模式</strong></p> 
<p>  元数据服务以独立进程运行，并且元数据存储在一个独立的数据库里。</p> 
<p><img src="https://images2.imgbox.com/27/bc/GQC4ihzB_o.png" alt="在这里插入图片描述" width="400"><br>   下面讲解内嵌模式部署。</p> 
<p>① 下载并安装Hive。</p> 
<pre><code>[root@iClient ~]# sudo yum install hive
</code></pre> 
<p>② HDFS里新建Hive存储目录。</p> 
<pre><code>[root@iClient ~]# sudo –u hdfs hdfs dfs –mkdir /user/hive              #HDFS里新建Hive存储目录
[root@iClient ~]# sudo –u hdfs hdfs dfs –chmod –R 1777 /user/hive      #为目录设置适当权限
</code></pre> 
<p>  只需上述两步就可以直接使用Hive了，当然，也可以使用jps命令查看Hive进程。</p> 
<p><strong>2、Hive接口</strong></p> 
<p>  Hive提供了强大的访问接口，从下图中即可看出Hive提供的诸多接口，此外也可以通过Hcatalog、Pig、BeeLine等访问Hive。</p> 
<p><img src="https://images2.imgbox.com/44/87/eGDHbBIj_o.png" alt="在这里插入图片描述" width="500"><br> <strong>【例4】</strong> 按要求完成问题：<br> ① 进入Hive命令行接口，获取Hive函数列表并单独查询count函数用法。<br> ② 在Hive里新建member表，并将表6-6中的数据载入Hive里的member表中。<br> ③ 查询member表中所有记录，查询member表中gender值为1的记录，查询member表中gender值为1且age为22的记录，统计member中男性和女性出现次数。<br> ④ 试比较Pig中“单词计数”和“统计男女出现次数”的异同点。</p> 
<p><strong>解：</strong></p> 
<p>  问题①较为简单，参考下面两条命令即可，注意本题所有操作都在iClient上执行，为方便载入数据，本次使用root用户。</p> 
<pre><code>[root@iClient ~]# Hive                                                   #进入Hive命令行
hive&gt;show functions;                                                     #获取Hhive所有函数列表
hive&gt;describe function count;                                            #查看count函数用法
</code></pre> 
<p>  对于问题②，我们首先为表准备数据，即在iClient目录“/root”下新建文件memberData并写入如下内容，注意记录间为换行符，字段间以Tab键分割。</p> 
<pre><code>201401 aa 0 21 e0 p3 m
201402 bb 1 22 e1 p2 l
201403 cc 1 22 e2 p1 m
</code></pre> 
<p>  下面建表时将赋予各个字段合适的含义与类型，由于较为简单，请直接参考下面语句。</p> 
<pre><code>hive&gt;show tables;                  #查看当前Hive仓库中所有表（以确定当前无member表）
hive&gt;create table member(id int,name string,gender tinyint,age tinyint,edu string,prof string,income string)row format delimited fields terminated by '\t';            #使用合适字段与类型，新建member表
hive&gt;show tables;                                  #再次查看，将显示member表
hive&gt;load data local inpath '/root/memberData' into table member;      #将本地文件memberData载入HDFS
hive&gt;select * from member;                                      #查看表中所有记录
hive&gt;select * from member where gender=1;                       #查看表中gender值为1的记录
hive&gt;select * from member where gender=1 AND age=23;            #查看表中gender值为1且age为23的记录
hive&gt;select gender,count(*) from member group by gender;        #统计男女出现总次数
hive&gt;drop table member;                                    #删除member表
hive&gt;quit;                                                 #退出Hive命令行接口
</code></pre> 
<p>  统计表中“男女出现次数”是一个常见的SQL操作，统计“单词个数”更像是处理互联网的单词热度之类的操作，两个其实没有可比性，这里只是强调，Hive将Hadoop抽象成为SQL类型的数据仓库。</p> 
<h3><a id="Oozie_105"></a>六、Oozie</h3> 
<p>  Oozie起源于雅虎，主要用于管理与组织Hadoop工作流。Oozie的工作流必须是一个有向无环图，实际上Oozie就相当于Hadoop的一个客户端，当用户需要执行多个关联的MapReduce（MR）任务时，只需要将MR执行顺序写入workflow.xml，然后使用Oozie提交本次任务，Oozie会托管此任务流。</p> 
<h4><a id="Oozie_107"></a>（一）Oozie简介</h4> 
<p><img src="https://images2.imgbox.com/7b/16/wMMURA9o_o.png" alt="在这里插入图片描述" width="500"><br>   由于需要存储工作流信息，为提供高可靠性，确保任务配置不丢失，Oozie内部使用数据库来存储工作流相关信息，用户可以使用Oozie内嵌的Derby数据库，也可以使用MySQL、PostgreSQL、Oracle等数据库。</p> 
<h4><a id="Oozie_111"></a>（二）Oozie入门</h4> 
<p><strong>1、Oozie部署</strong></p> 
<p>  Oozie相当于Hadoop的一个客户端，因此集群中只有一台机器部署Oozie server端即可，由于可以有任意多个客户端连接Oozie，故每个客户端上都须部署Oozie client，本节选择在cMaster上部署Oozie server，在iClient上部署Oozie client。</p> 
<p><strong>（1）部署Oozie服务端</strong></p> 
<pre><code>[root@cMaster ~]# sudo yum install oozie        #cMaster上以root权限执行，部署Oozie服务端
</code></pre> 
<p><strong>（2）部署Oozie客户端</strong></p> 
<pre><code>[root@iClient ~]# sudo yum install oozie-client
</code></pre> 
<p><strong>（3）配置Oozie</strong></p> 
<p>  修改<code>/etc/oozie/conf/oozie-env.sh</code>中的<code>CATALINA_BASE</code>属性值，注释原值并指定新值，当此值指向oozie-server-0.20表明Oozie支持MRv1，指向oozie-server表示支持Yarn。注意cMaster、iClient都要配置，并保持一致。</p> 
<pre><code>#export CATALINA_BASE=/usr/lib/oozie/oozie-server-0.20
export CATALINA_BASE=/usr/lib/oozie/oozie-server
</code></pre> 
<p>  在<code>/etc/hadoop/conf/core-site.xml</code>文档里<code>configuration</code>标签间加入如下内容。注意，6台机器都要更新这个配置，并且配置此属性后，一定要重启集群中所有Hadoop服务，此属性值才能生效。</p> 
<pre><code>&lt;property&gt;&lt;name&gt;hadoop.proxyuser.oozie.groups&lt;/name&gt;&lt;value&gt;*&lt;/value&gt;&lt;/property&gt;
&lt;property&gt;&lt;name&gt;hadoop.proxyuser.oozie.hosts&lt;/name&gt;&lt;value&gt;*&lt;/value&gt;&lt;/property&gt;
</code></pre> 
<p>  下面是重启Hadoop集群的命令：</p> 
<pre><code>$ for x in `cd /etc/init.d ; ls hadoop-*` ; do service $x restart; done;        #除了iCleint外，其他机器都要执行
</code></pre> 
<p><strong>（4）创建Oozie数据库模式</strong></p> 
<pre><code>[root@cMaster ~]#sudo -u oozie /usr/lib/oozie/bin/ooziedb.sh create –run            #仅cMaster执行
</code></pre> 
<p><strong>（5）配置Oozie Web页面</strong></p> 
<p>  Oozie的Web界面用到第三方包，但由于版权原因ext-2.2并未打包进Oozie，事实上开启Oozie server不需要开启Oozie Web界面，但如果想在开启Oozie server同时也开启Oozie Web界面，则必须下载<code>ext-2.2.zip</code>并将其解压到目录<code>/var/lib/oozie</code>下。</p> 
<pre><code>[root@cMaster ~]# cd /var/lib/oozie/
[root@cMaster oozie]# sudo -u oozie wget http://archive.cloudera.com/gplextras/misc/ext-2.2.zip
[root@cMaster oozie]# sudo -u oozie unzip ext-2.2.zip
</code></pre> 
<p><strong>（6）将Oozie常用Jar包导入HDFS</strong></p> 
<p>  这一步也是可选的，如果工作流里包含Pig或Hive脚本，必须将这些jar包导入HDFS。</p> 
<pre><code>[root@cMaster ~]# sudo -u hdfs hdfs dfs -mkdir /user/oozie
[root@cMaster ~]# sudo -u hdfs hdfs dfs -chown oozie:oozie /user/oozie
[root@cMaster ~]# mkdir /tmp/ooziesharelib
[root@cMaster ~]# cd /tmp/ooziesharelib
[root@cMaster ~]# tar xzf /usr/lib/oozie/oozie-sharelib-yarn.tar.gz
[root@cMaster ~]# sudo -u oozie hdfs dfs -put share /user/oozie/share
</code></pre> 
<p><strong>（7）开启Oozie服务</strong></p> 
<pre><code>[root@cMaster ~]# sudo service oozie start
</code></pre> 
<p><strong>（8）查看Oozie服务</strong></p> 
<p>  当成功部署并在cMaster上开启Oozie服务后，如果配置了<code>ext-2.2</code>，在iClient上的浏览器中打开“cmaster:11000”将显示Oozie Web界面，也可以使用下述命令查看Oozie工作状态。</p> 
<pre><code>[root@iClient ~]# oozie admin -oozie http://cMaster:11000/oozie -status
</code></pre> 
<p><strong>2、Oozie访问接口</strong></p> 
<p>  Oozie最常用的是命令行接口，它的Web接口只可以看到Oozie托管的任务，不可以配置作业。</p> 
<p><strong>【例5】</strong> 按要求完成问题：<br> ① 进入Oozie客户端，查看常用命令。<br> ② 运行Oozie MR示例程序。<br> ③ 运行Oozie Pig、Hive等示例。<br> ④ 编写workflow.xml，完成一次WordCount。<br> ⑤ 编写workflow.xml，完成两次WordCount，且第一个WC的输出为第二个WC的输入。</p> 
<p><strong>解：</strong></p> 
<p>  对于问题①，在iClient上执行下述命令即可，用户可以是root或joe。</p> 
<pre><code>[root@iClient ~]# sudo -u joe oozie help         #查看所有Oozie命令
</code></pre> 
<p>  对于问题②，首先解压Oozie示例jar包，接着修改示例配置中的地址信息，最后上传至集群执行即可，读者按下述流程执行即可。</p> 
<pre><code>[root@iClient ~]#cd /usr/share/doc/oozie-4.0.0+cdh5.0.0+54
[root@iClient oozie-4.0.0+cdh5.0.0+54 ~]# tar -zxvf oozie-examples.tar.gz
</code></pre> 
<p>  编辑<code>examples/apps/map-reduce/job.properties</code>，将如下两行：</p> 
<pre><code>nameNode=hdfs://ocalhost:8020 
jobTracker=localhost:8021
</code></pre> 
<p>  替换成集群现在配置的地址与端口：</p> 
<pre><code>nameNode=hdfs://cMaster:8020
jobTracker=cMaster:8032
</code></pre> 
<p>  接着将<code>examples</code>上传至HDFS，使用Oozie命令执行即可：</p> 
<pre><code>[root@iClient oozie-4.0.0+cdh5.0.0+54]# sudo-u joe hdfs dfs -put examples examples
[root@iClient oozie-4.0.0+cdh5.0.0+54]# cd
[root@iClient ~]# sudo -u joe oozie job-oozie http://cMaster:11000/oozie -config /usr/share/doc/oozie-4.0.0+cdh5.0.0+54/examples/apps/map-reduce/job.properties -run
</code></pre> 
<p>  问题③其实和是一样的，读者可按上述过程使用oozie执行Pig或Hive等的示例脚本。切记修改相应配置（如<code>examples/apps/pig/job.properties</code>）后，再上传至集群，执行时也要定位到相应路径（如<code>sudo -u joe oozie ……/apps/pig/joe.properties -run</code>）。</p> 
<p>  对于问题④，可参考“<code>examples/apps/map-reduce/workflow.xml</code>”，其对应jar包在“<code>examples/apps/map-reduce/lib</code>”下，其下的<code>DemoMapper.class</code>和<code>DemoReducer.class</code>就是WordCount的代码，对应的源代码在“<code>examples/src</code>”下，可按如下步骤完成此问题。</p> 
<p>（1）编辑文件“<code>examples/apps/map-reduce/workflow.xml</code>”，找到下述内容：</p> 
<pre><code>&lt;property&gt;
&lt;name&gt;mapred.mapper.class&lt;/name&gt;&lt;value&gt;org.apache.oozie.example.SampleMapper&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
&lt;name&gt;mapred.reducer.class&lt;/name&gt;&lt;value&gt;org.apache.oozie.example.SampleReducer&lt;/value&gt;
&lt;/property&gt;
</code></pre> 
<p>（2）将其替换成：</p> 
<pre><code>&lt;property&gt; 
    &lt;name&gt;mapred.mapper.classs&lt;/name&gt;&lt;value&gt;org.apache.oozie.example.DemoMapper&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
&lt;name&gt;mapred.reducer.class&lt;/name&gt;&lt;value&gt;org.apache.oozie.example.DemoReducer&lt;/value&gt;
&lt;/property&gt; 
&lt;property&gt;&lt;name&gt;mapred.output.key.class&lt;/name&gt;&lt;value&gt;org.apache.hadoop.io.Text&lt;value&gt;&lt;/property&gt;
&lt;property&gt; 
    &lt;name&gt;mapred.output.value.class&lt;/name&gt;&lt;value&gt;org.apache.hadoop.io.IntWritable&lt;/value&gt;
&lt;/property&gt;
</code></pre> 
<p>（3）接着将原来HDFS里<code>examples</code>文件删除，按问题②的解答，上传执行即可，这里只给出删除原<code>examples</code>的命令，上传和执行命令和问题②解答一样。</p> 
<pre><code>[root@iClient ~]# sudo -u joe hdfs dfs -rm -r-fexamples                  #删除HDFS原examples文件
</code></pre> 
<p>  问题⑤是业务逻辑中最常遇到的情形，比如你的数据处理流是：“M1”→“R1”→ “Java1”→“Pig1”→“Hive1”→“M2”→“R2”→“Java2”，单独写出各类或脚本后，写出此逻辑对应的<code>workflow.xml</code>即可。限于篇幅，下面只给出<code>workflow.xml</code>框架， 请读者自行解决问题。</p> 
<pre><code>&lt;workflow-app xmlns="uri:oozie:workflow:0.2" name="map-reduce-wf"&gt; 
    &lt;start to="mr-node"/&gt;
    &lt;action name="mr-node"&gt;
        &lt;map-reduce&gt;第一个wordcount配置&lt;/map-reduce&gt;
        &lt;ok to="mr-wc2"/&gt;&lt;error to="fail"/&gt;
    &lt;/action&gt;
    &lt;action name="mr-wc2"&gt;
        &lt;map-reduce&gt;第二个wordcount配置&lt;/map-reduce&gt;
        &lt;ok to="end"/&gt;&lt;error to="fail"/&gt;
    &lt;/action&gt;
    &lt;kill name="fail"&gt;
        &lt;message&gt;Map/Reduce failed error message[${wf:errorMessage(wf:lastErrorNode())}] &lt;/message&gt;
    &lt;/kill&gt;
    &lt;end name="end"/&gt;
&lt;/workflow-app&gt;
</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/a4f95a6e9bdfcc5a43afbd83d482985f/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Stable Diffusion部署教程，开启你的AI绘图之路</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/d79aff98373a123b39a44fd6bf79f5f6/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">原生鸿蒙AI浓度要爆表了：鸿蒙原生智能加持，华为小艺进化成系统级智能体...</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>