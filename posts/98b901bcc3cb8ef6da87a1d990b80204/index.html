<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【AIGC调研系列】Phi-3 VS Llama3 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/98b901bcc3cb8ef6da87a1d990b80204/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="【AIGC调研系列】Phi-3 VS Llama3">
  <meta property="og:description" content="2024-04-24日发布的Phi-3系列模型在多个方面展现出了对Llama-3的性能优势。首先，Phi-3-small（7B参数）在MMLU上的得分高于Llama-3-8B-Instruct模型，分别为75.3%和66%[1]。此外，具有3.8B参数的Phi-3 Mini在性能上优于Llama3 8b[3]，并且在多项基准测试中超过了Llama 3 8B[12]。我搜索到的资料表明，在小模型尺寸下，Phi-3系列模型展现出了显著的性能优势。
尽管Llama-3在代码生成等任务上实现了全面领先，并且在多个关键的基准测试中性能优于业界先进同类模型[7][8][9]，但Phi-3系列模型通过其高质量数据集的训练，以及特别设计以支持多语言和兼容性[4][12][13]，展现了其在不同领域的强大能力。特别是，Phi-3系列模型被优化至可在手机端运行，这一点对于移动设备用户来说是一个重要的优势[4][5][10]。
虽然Llama-3在某些特定任务上可能仍然表现出色，但从整体性能、多语言支持、以及在移动设备上的可用性来看，Phi-3系列模型展现出了能够击败Llama-3的能力。因此，基于我搜索到的资料，可以得出结论，Phi-3确实能够在多个方面超越Llama-3。
Phi-3系列模型在哪些具体任务上超越了Llama-3？ Phi-3系列模型在多个具体任务上超越了Llama-3。首先，Phi-3系列模型在语言理解和推理任务上展现出了优秀的性能，尽管参数数量较少，但其性能在某些基准测试中甚至超过了参数数量更多的模型[14]。特别是，Phi-3-Mini版本在MMLU语言理解基准测试中达到了69%的得分，在MT基准测试中得分为8.这些成绩表明，Phi-3系列模型在处理语言理解和推理任务方面具有较高的效率和准确性。
此外，Phi-3系列模型支持多语言，并且使用了tiktoken分词器以及增加了10%多语种数据，这使得Phi-3系列模型在多语言处理任务上也表现出色[15]。这一点对于需要处理多种语言内容的应用场景尤为重要，能够提供更加灵活和广泛的语言处理能力。
同时，其对多语言的支持和优化也使其在多语言处理任务上超越了Llama-3[15]。
Llama-3与Phi-3系列模型在性能上的比较有哪些最新的研究或数据支持？ Llama-3与Phi-3系列模型在性能上的比较，根据最新的研究或数据支持，可以从以下几个方面进行分析：
参数规模和训练数据：Llama-3模型发布了8B和70B参数的版本，而Phi-3系列模型则包括mini（38亿参数）、small（70亿参数）和medium（140亿参数）三个版本[24][26]。这表明Llama-3在参数规模上更为广泛，覆盖了从小型到大型的不同应用场景。性能提升：Llama-3通过扩大词汇量、更长的上下文长度和先进的训练技术来增强大型语言模型技术，设定了新标准，挑战行业顶级竞争对手[25]。相比之下，Phi-3系列模型虽然也展示了出色的性能，特别是在基准跑分性能上超出Mixtral 8x7B和GPT-3.5[26]，但具体的性能提升细节较少提及。此外，英特尔至强6处理器针对Meta Llama 3模型的推理性能测试显示，Llama-3比Llama-2快1.04倍[29]。这些改进表明Llama-3在处理速度和效率方面进行了显著优化。多语言支持和数据清洗：Llama-3的预训练数据集比Llama-2使用的数据集大7倍，并且包含4倍多的代码，超过5%的预训练数据集由30多种语言的高质量非英语数据组成[30]。这种多语言支持和严格的数据清洗方法可能为Llama-3提供了更广泛的应用场景和更高的数据质量。 Llama-3与Phi-3系列模型在性能上的比较显示，Llama-3在参数规模、性能提升、应用和效率以及多语言支持和数据清洗方面具有明显优势。然而，Phi-3系列模型在特定场景下的性能表现也不容忽视，尤其是在基准跑分性能上的出色表现[26]。因此，两者各有千秋，适用于不同的应用场景和需求。
Phi-3系列模型如何优化以支持多语言和兼容性，具体实现方式是什么？ Phi-3系列模型为了支持多语言和兼容性，采取了以下具体实现方式：
多语言支持：Phi-3-Small模型通过使用tiktoken分词器来改进多语言分词，这意味着它能够更好地处理不同语言的文本数据。这种优化使得Phi-3-Small模型在处理多语言文本时更加高效和准确[35]。兼容性：Phi-3系列模型采用了模块化的前端、无服务器架构，并提供了REST API和Websocket接口。这种设计不仅提高了模型的灵活性，也增强了其与不同平台和服务的兼容性。用户可以通过这些接口轻松地将Phi-3模型集成到各种应用场景中，无论是云端还是边缘计算环境[36]。性能优化：尽管Phi-3系列模型在多语言支持和兼容性方面进行了优化，但它们仍然保持了高性能的特点。例如，Phi-3-Mini是一个拥有38亿参数的语言模型，经过3.3万亿token的训练，其整体性能在学术基准和内部测试上成绩优异。这表明Phi-3系列模型在保证多语言支持和兼容性的同时，也没有牺牲其推理能力和处理速度[37]。 Phi-3系列模型通过采用先进的分词技术、提供灵活的接口以及保持高性能的设计，有效地支持了多语言和兼容性需求。这些优化措施使得Phi-3系列模型能够在多种环境下高效运行，满足不同用户的需求。
在移动设备上的运行效率和用户体验方面，Phi-3系列模型相比Llama-3有哪些改进？ Phi-3系列模型相比Llama-3在移动设备上的运行效率和用户体验方面有以下改进：
运行效率：Phi-3系列模型是专为小参数设计的，这意味着它们在保持高性能的同时，参数数量较少。Phi-3 Mini可以测量38亿个参数，其训练数据集比GPT-4等大型语言模型要小[42]。这表明Phi-3系列模型能够在资源有限的移动设备上高效运行，而不需要像Llama 3那样依赖强大的硬件支持。Llama 3每秒输出800个token，需要较慢的生成速度以保证内容的可读性和对任务流程的理解[40]，这可能意味着在移动设备上运行时，其效率不如Phi-3系列模型。用户体验：Phi-3系列模型的设计考虑到了移动设备的使用场景，使其能够在本地直接运行，无需依赖云服务或外部网络连接[43]。这种设计显著提升了用户体验，因为用户可以享受到即时反馈和隐私保护的优势。相比之下，Llama 3虽然在多任务语言理解、复杂阅读理解等方面取得了巨大进步[38]，但其较高的硬件要求和对网络的依赖可能会限制其在移动设备上的用户体验。 Phi-3系列模型通过其小参数设计和对移动设备友好性的优化，在移动设备上的运行效率和用户体验方面相比Llama-3有了显著的改进。
关于Phi-3和Llama-3的最新基准测试结果是什么？ 关于Phi-3和Llama-3的最新基准测试结果，目前没有直接提及Phi-3的信息。然而，对于Llama-3，有多个来源提供了详细的性能评估。
Llama 3在关键基准测试中表现优异，尤其是在编程等任务上优于同类竞争模型。Meta声称Llama 3在MMLU、HumanEval和GSM-8K上的表现超越了Gemini 1.5 Pro[44]。此外，Llama 3的8B和70B参数版本在预训练语言模型的应用中取得了令人印象深刻的结果，这些模型被广泛用于文本生成、翻译、摘要、查询回答等任务[49]。Llama 3还通过改进tokenizer提高了token化效率，并添加了组查询关注（GQA）功能到8B版本中[46]。
然而，随着更强模型如Claude 3、Llama 3甚至GPT-5的发布，业界对更难、更有区分度的基准测试的需求增加。LMSYS推出的下一代基准测试Arena-Hard引起了广泛关注，这个新测试基准显示Llama 3的两个指令微调版本在Arena-Hard上的得分与之前大家分数相近的MT Bench相比，区分度从22.6%提升到87.4%，这表明Llama 3在新的挑战面前遇到了一些困难[50][51]。
关于Llama 3的最新基准测试结果显示其在多个关键基准测试中表现出色，尤其是在编程等任务上。同时，面对新的挑战和更难的基准测试，Llama 3也展现了一定的适应性和潜力。但是，目前没有关于Phi-3的具体信息。
欢迎大家微信关注我，可与AI自由对话（终身免费）：
参考资料 1. Phi-3 - 微软最新推出的新一代小模型系列 - AI工具集 [2024-04-24]
2. &#34;小而精&#34;，微软发布Phi-3，3.8B 性能比肩Llama-3-8B - 知乎专栏 [2024-04-24]
3. 人人可拥有GPT4，比得上GPT4的开源Llama3 原创 - CSDN博客 [2024-04-24]">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-04-24T10:55:13+08:00">
    <meta property="article:modified_time" content="2024-04-24T10:55:13+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【AIGC调研系列】Phi-3 VS Llama3</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>2024-04-24日发布的Phi-3系列模型在多个方面展现出了对Llama-3的性能优势。首先，Phi-3-small（7B参数）在MMLU上的得分高于Llama-3-8B-Instruct模型，分别为75.3%和66%[1]。此外，具有3.8B参数的Phi-3 Mini在性能上优于Llama3 8b[3]，并且在多项基准测试中超过了Llama 3 8B[12]。我搜索到的资料表明，在小模型尺寸下，Phi-3系列模型展现出了显著的性能优势。</p> 
<p>尽管Llama-3在代码生成等任务上实现了全面领先，并且在多个关键的基准测试中性能优于业界先进同类模型[7][8][9]，但Phi-3系列模型通过其高质量数据集的训练，以及特别设计以支持多语言和兼容性[4][12][13]，展现了其在不同领域的强大能力。特别是，Phi-3系列模型被优化至可在手机端运行，这一点对于移动设备用户来说是一个重要的优势[4][5][10]。</p> 
<p>虽然Llama-3在某些特定任务上可能仍然表现出色，但从整体性能、多语言支持、以及在移动设备上的可用性来看，Phi-3系列模型展现出了能够击败Llama-3的能力。因此，基于我搜索到的资料，可以得出结论，Phi-3确实能够在多个方面超越Llama-3。</p> 
<h3>Phi-3系列模型在哪些具体任务上超越了Llama-3？</h3> 
<p>Phi-3系列模型在多个具体任务上超越了Llama-3。首先，Phi-3系列模型在语言理解和推理任务上展现出了优秀的性能，尽管参数数量较少，但其性能在某些基准测试中甚至超过了参数数量更多的模型[14]。特别是，Phi-3-Mini版本在MMLU语言理解基准测试中达到了69%的得分，在MT基准测试中得分为8.这些成绩表明，Phi-3系列模型在处理语言理解和推理任务方面具有较高的效率和准确性。</p> 
<p>此外，Phi-3系列模型支持多语言，并且使用了tiktoken分词器以及增加了10%多语种数据，这使得Phi-3系列模型在多语言处理任务上也表现出色[15]。这一点对于需要处理多种语言内容的应用场景尤为重要，能够提供更加灵活和广泛的语言处理能力。</p> 
<p>同时，其对多语言的支持和优化也使其在多语言处理任务上超越了Llama-3[15]。</p> 
<h3>Llama-3与Phi-3系列模型在性能上的比较有哪些最新的研究或数据支持？</h3> 
<p>Llama-3与Phi-3系列模型在性能上的比较，根据最新的研究或数据支持，可以从以下几个方面进行分析：</p> 
<ol><li><strong>参数规模和训练数据</strong>：Llama-3模型发布了8B和70B参数的版本，而Phi-3系列模型则包括mini（38亿参数）、small（70亿参数）和medium（140亿参数）三个版本[24][26]。这表明Llama-3在参数规模上更为广泛，覆盖了从小型到大型的不同应用场景。</li><li><strong>性能提升</strong>：Llama-3通过扩大词汇量、更长的上下文长度和先进的训练技术来增强大型语言模型技术，设定了新标准，挑战行业顶级竞争对手[25]。相比之下，Phi-3系列模型虽然也展示了出色的性能，特别是在基准跑分性能上超出Mixtral 8x7B和GPT-3.5[26]，但具体的性能提升细节较少提及。此外，英特尔至强6处理器针对Meta Llama 3模型的推理性能测试显示，Llama-3比Llama-2快1.04倍[29]。这些改进表明Llama-3在处理速度和效率方面进行了显著优化。</li><li><strong>多语言支持和数据清洗</strong>：Llama-3的预训练数据集比Llama-2使用的数据集大7倍，并且包含4倍多的代码，超过5%的预训练数据集由30多种语言的高质量非英语数据组成[30]。这种多语言支持和严格的数据清洗方法可能为Llama-3提供了更广泛的应用场景和更高的数据质量。</li></ol> 
<p>Llama-3与Phi-3系列模型在性能上的比较显示，Llama-3在参数规模、性能提升、应用和效率以及多语言支持和数据清洗方面具有明显优势。然而，Phi-3系列模型在特定场景下的性能表现也不容忽视，尤其是在基准跑分性能上的出色表现[26]。因此，两者各有千秋，适用于不同的应用场景和需求。</p> 
<h3>Phi-3系列模型如何优化以支持多语言和兼容性，具体实现方式是什么？</h3> 
<p>Phi-3系列模型为了支持多语言和兼容性，采取了以下具体实现方式：</p> 
<ol><li><strong>多语言支持</strong>：Phi-3-Small模型通过使用tiktoken分词器来改进多语言分词，这意味着它能够更好地处理不同语言的文本数据。这种优化使得Phi-3-Small模型在处理多语言文本时更加高效和准确[35]。</li><li><strong>兼容性</strong>：Phi-3系列模型采用了模块化的前端、无服务器架构，并提供了REST API和Websocket接口。这种设计不仅提高了模型的灵活性，也增强了其与不同平台和服务的兼容性。用户可以通过这些接口轻松地将Phi-3模型集成到各种应用场景中，无论是云端还是边缘计算环境[36]。</li><li><strong>性能优化</strong>：尽管Phi-3系列模型在多语言支持和兼容性方面进行了优化，但它们仍然保持了高性能的特点。例如，Phi-3-Mini是一个拥有38亿参数的语言模型，经过3.3万亿token的训练，其整体性能在学术基准和内部测试上成绩优异。这表明Phi-3系列模型在保证多语言支持和兼容性的同时，也没有牺牲其推理能力和处理速度[37]。</li></ol> 
<p>Phi-3系列模型通过采用先进的分词技术、提供灵活的接口以及保持高性能的设计，有效地支持了多语言和兼容性需求。这些优化措施使得Phi-3系列模型能够在多种环境下高效运行，满足不同用户的需求。</p> 
<h3>在移动设备上的运行效率和用户体验方面，Phi-3系列模型相比Llama-3有哪些改进？</h3> 
<p>Phi-3系列模型相比Llama-3在移动设备上的运行效率和用户体验方面有以下改进：</p> 
<ol><li><strong>运行效率</strong>：Phi-3系列模型是专为小参数设计的，这意味着它们在保持高性能的同时，参数数量较少。Phi-3 Mini可以测量38亿个参数，其训练数据集比GPT-4等大型语言模型要小[42]。这表明Phi-3系列模型能够在资源有限的移动设备上高效运行，而不需要像Llama 3那样依赖强大的硬件支持。Llama 3每秒输出800个token，需要较慢的生成速度以保证内容的可读性和对任务流程的理解[40]，这可能意味着在移动设备上运行时，其效率不如Phi-3系列模型。</li><li><strong>用户体验</strong>：Phi-3系列模型的设计考虑到了移动设备的使用场景，使其能够在本地直接运行，无需依赖云服务或外部网络连接[43]。这种设计显著提升了用户体验，因为用户可以享受到即时反馈和隐私保护的优势。相比之下，Llama 3虽然在多任务语言理解、复杂阅读理解等方面取得了巨大进步[38]，但其较高的硬件要求和对网络的依赖可能会限制其在移动设备上的用户体验。</li></ol> 
<p>Phi-3系列模型通过其小参数设计和对移动设备友好性的优化，在移动设备上的运行效率和用户体验方面相比Llama-3有了显著的改进。</p> 
<h3>关于Phi-3和Llama-3的最新基准测试结果是什么？</h3> 
<p>关于Phi-3和Llama-3的最新基准测试结果，目前没有直接提及Phi-3的信息。然而，对于Llama-3，有多个来源提供了详细的性能评估。</p> 
<p>Llama 3在关键基准测试中表现优异，尤其是在编程等任务上优于同类竞争模型。Meta声称Llama 3在MMLU、HumanEval和GSM-8K上的表现超越了Gemini 1.5 Pro[44]。此外，Llama 3的8B和70B参数版本在预训练语言模型的应用中取得了令人印象深刻的结果，这些模型被广泛用于文本生成、翻译、摘要、查询回答等任务[49]。Llama 3还通过改进tokenizer提高了token化效率，并添加了组查询关注（GQA）功能到8B版本中[46]。</p> 
<p>然而，随着更强模型如Claude 3、Llama 3甚至GPT-5的发布，业界对更难、更有区分度的基准测试的需求增加。LMSYS推出的下一代基准测试Arena-Hard引起了广泛关注，这个新测试基准显示Llama 3的两个指令微调版本在Arena-Hard上的得分与之前大家分数相近的MT Bench相比，区分度从22.6%提升到87.4%，这表明Llama 3在新的挑战面前遇到了一些困难[50][51]。</p> 
<p>关于Llama 3的最新基准测试结果显示其在多个关键基准测试中表现出色，尤其是在编程等任务上。同时，面对新的挑战和更难的基准测试，Llama 3也展现了一定的适应性和潜力。但是，目前没有关于Phi-3的具体信息。</p> 
<p>欢迎大家微信关注我，可与AI自由对话（终身免费）：</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/70/63/CjAsCT76_o.jpg"></p> 
<p></p> 
<h3>参考资料</h3> 
<p><a href="https://ai-bot.cn/phi-3/" rel="nofollow" title="1. Phi-3 - 微软最新推出的新一代小模型系列 - AI工具集 [2024-04-24]">1. Phi-3 - 微软最新推出的新一代小模型系列 - AI工具集 [2024-04-24]</a></p> 
<p><a href="https://zhuanlan.zhihu.com/p/694088548" rel="nofollow" title='2. "小而精"，微软发布Phi-3，3.8B 性能比肩Llama-3-8B - 知乎专栏 [2024-04-24]'>2. "小而精"，微软发布Phi-3，3.8B 性能比肩Llama-3-8B - 知乎专栏 [2024-04-24]</a></p> 
<p><a href="https://blog.csdn.net/shadowcz007/article/details/138142821" title="3. 人人可拥有GPT4，比得上GPT4的开源Llama3 原创 - CSDN博客 [2024-04-24]">3. 人人可拥有GPT4，比得上GPT4的开源Llama3 原创 - CSDN博客 [2024-04-24]</a></p> 
<p><a href="https://juejin.cn/post/7360890020120870948" rel="nofollow" title="4. 微软科技大佬推出Phi-3性能超Llama-3或GPT并可在手机端运行。 [2024-04-24]">4. 微软科技大佬推出Phi-3性能超Llama-3或GPT并可在手机端运行。 [2024-04-24]</a></p> 
<p><a href="https://www.datalearner.com/blog/1051713851616894" rel="nofollow" title="5. 微软发布第三代Phi-3系列模型，评测结果超过同等参数规模水平 [2024-04-24]">5. 微软发布第三代Phi-3系列模型，评测结果超过同等参数规模水平 [2024-04-24]</a></p> 
<p><a href="https://www.163.com/dy/article/J0FTLPO50556703U.html" rel="nofollow" title="6. 手机秒变超脑！微软Phi-3已经超越主流大模型！|人工智能 - 网易 [2024-04-24]">6. 手机秒变超脑！微软Phi-3已经超越主流大模型！|人工智能 - 网易 [2024-04-24]</a></p> 
<p><a href="https://www.jiqizhixin.com/articles/2024-04-19" rel="nofollow" title="7. 开源大模型Llama 3王者归来！最大底牌4000亿参数，性能直逼GPT-4 [2024-04-19]">7. 开源大模型Llama 3王者归来！最大底牌4000亿参数，性能直逼GPT-4 [2024-04-19]</a></p> 
<p><a href="https://www.53ai.com/news/qianyanjishu/1181.html" rel="nofollow" title="8. Llama3中文基准测评出炉！性能惊艳，数学、代码能力接近GPT4 - 53AI">8. Llama3中文基准测评出炉！性能惊艳，数学、代码能力接近GPT4 - 53AI</a></p> 
<p><a href="https://www.woshipm.com/aigc/6035995.html" rel="nofollow" title="9. 全网首发，Meta Llama-3 全方位详解 [2024-04-19]">9. 全网首发，Meta Llama-3 全方位详解 [2024-04-19]</a></p> 
<p><a href="https://blog.csdn.net/weixin_40425640/article/details/138145031" title="10. 微软开源了Phi-3-mini适用于移动硬件设备原创 - CSDN博客 [2024-04-24]">10. 微软开源了Phi-3-mini适用于移动硬件设备原创 - CSDN博客 [2024-04-24]</a></p> 
<p><a href="https://zhuanlan.zhihu.com/p/694022715" rel="nofollow" title="11. 开源模型会越来越落后？Llama-3 评测结果出炉 - 知乎专栏 [2024-04-24]">11. 开源模型会越来越落后？Llama-3 评测结果出炉 - 知乎专栏 [2024-04-24]</a></p> 
<p><a href="https://www.thepaper.cn/newsDetail_forward_27132665" rel="nofollow" title="12. 微软推出iPhone能跑的ChatGPT级模型，网友：OpenAI得把GPT-3.5 ... [2024-04-24]">12. 微软推出iPhone能跑的ChatGPT级模型，网友：OpenAI得把GPT-3.5 ... [2024-04-24]</a></p> 
<p><a href="https://finance.sina.cn/2024-04-23/detail-inasvrzs8721956.d.html" rel="nofollow" title="13. 微软推出iPhone能跑的ChatGPT级模型，性能超Llama-3_手机新浪网 [2024-04-24]">13. 微软推出iPhone能跑的ChatGPT级模型，性能超Llama-3_手机新浪网 [2024-04-24]</a></p> 
<p><a href="https://www.zhihu.com/question/653860527" rel="nofollow" title="14. 如何评价微软发布的 phi-3？ - 知乎 [2024-04-23]">14. 如何评价微软发布的 phi-3？ - 知乎 [2024-04-23]</a></p> 
<p><a href="https://m.chinaz.com/2024/0423/1612093.shtml" rel="nofollow" title="15. 微软发布iPhone可运行的ChatGPT级AI模型Phi-3系列 ... - Chinaz.com [2024-04-24]">15. 微软发布iPhone可运行的ChatGPT级AI模型Phi-3系列 ... - Chinaz.com [2024-04-24]</a></p> 
<p><a href="https://simonwillison.net/2024/Apr/23/phi-3-technical-report/" rel="nofollow" title="17. A quote from Phi-3 Technical Report - simonwillison.net [2024-04-23]">17. A quote from Phi-3 Technical Report - simonwillison.net [2024-04-23]</a></p> 
<p><a href="https://www.aihub.cn/tools/llm/phi-3/" rel="nofollow" title="18. Phi-3：微软公布的开源小型语言模型，支持移动设备- AIHub | AI导航 [2024-04-24]">18. Phi-3：微软公布的开源小型语言模型，支持移动设备- AIHub | AI导航 [2024-04-24]</a></p> 
<p><a href="https://analyticsindiamag.com/microsoft-introduces-phi-3-llm-that-runs-on-the-phone/" rel="nofollow" title="19. Microsoft Introduces Phi-3, LLM That Runs on the Phone [2024-04-23]">19. Microsoft Introduces Phi-3, LLM That Runs on the Phone [2024-04-23]</a></p> 
<p><a href="https://new.qq.com/rain/a/20240423A07MJK00" rel="nofollow" title="20. 微软发布Phi-3：小模型击败Llama 3，手机上可以丝滑运行 [2024-04-23]">20. 微软发布Phi-3：小模型击败Llama 3，手机上可以丝滑运行 [2024-04-23]</a></p> 
<p><a href="https://zhuanlan.zhihu.com/p/694176229" rel="nofollow" title="21. 微软发布Phi-3，性能超Llama-3，可手机端运行 - 知乎 [2024-04-23]">21. 微软发布Phi-3，性能超Llama-3，可手机端运行 - 知乎 [2024-04-23]</a></p> 
<p><a href="https://mspoweruser.com/zh-CN/microsoft-introduces-phi-3-family-of-models-that-outperform-other-models-of-its-class/" rel="nofollow" title="22. Microsoft 推出 Phi-3 系列型号，其性能优于同类其他型号 [2024-04-23]">22. Microsoft 推出 Phi-3 系列型号，其性能优于同类其他型号 [2024-04-23]</a></p> 
<p><a href="https://ai.zol.com.cn/867/8675907.html" rel="nofollow" title="23. 微软推出Phi-3 AI 模型：性能超越大参数模型！-中关村在线 [2024-04-24]">23. 微软推出Phi-3 AI 模型：性能超越大参数模型！-中关村在线 [2024-04-24]</a></p> 
<p><a href="https://www.thepaper.cn/newsDetail_forward_27106328" rel="nofollow" title="24. 开源大模型Llama 3王者归来：最大底牌4000亿参数，性能直逼GPT-4_澎湃号·湃客_澎湃新闻-The Paper [2024-04-21]">24. 开源大模型Llama 3王者归来：最大底牌4000亿参数，性能直逼GPT-4_澎湃号·湃客_澎湃新闻-The Paper [2024-04-21]</a></p> 
<p><a href="https://www.unite.ai/zh-CN/%E6%8E%A8%E5%87%BA-Meta-llama-3-%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%80%E6%AC%A1%E9%A3%9E%E8%B7%83/" rel="nofollow" title="25. 揭晓 Meta Llama 3：大型语言模型的飞跃 - Unite.AI [2024-04-21]">25. 揭晓 Meta Llama 3：大型语言模型的飞跃 - Unite.AI [2024-04-21]</a></p> 
<p><a href="https://www.ithome.com/0/763/610.htm" rel="nofollow" title="26. iPhone 上本地每秒生成 12 个 tokens，微软发布 phi-3-mini 模型：38 亿参数 - IT之家 [2024-04-23]">26. iPhone 上本地每秒生成 12 个 tokens，微软发布 phi-3-mini 模型：38 亿参数 - IT之家 [2024-04-23]</a></p> 
<p><a href="https://m.thepaper.cn/newsDetail_forward_27086698" rel="nofollow" title="27. 开源大模型Llama 3王者归来，最大底牌4000亿参数，性能直逼GPT-4 [2024-04-19]">27. 开源大模型Llama 3王者归来，最大底牌4000亿参数，性能直逼GPT-4 [2024-04-19]</a></p> 
<p><a href="http://www.cww.net.cn/article?id=589421" rel="nofollow" title="29. 英特尔披露至强6处理器针对Meta Llama 3模型的推理性能 - 通信世界 [2024-04-24]">29. 英特尔披露至强6处理器针对Meta Llama 3模型的推理性能 - 通信世界 [2024-04-24]</a></p> 
<p><a href="https://zhuanlan.zhihu.com/p/693323342" rel="nofollow" title="30. 陈巍：LLaMA3大模型技术全网最全解析——模型架构与训练方法（收录于GPT-4/ChatGPT技术与产业分析） - 知乎">30. 陈巍：LLaMA3大模型技术全网最全解析——模型架构与训练方法（收录于GPT-4/ChatGPT技术与产业分析） - 知乎</a></p> 
<p><a href="https://segmentfault.com/a/1190000044814016" rel="nofollow" title="31. 人工智能 - Meta Llama 3 来啦!性能算力究竟如何？ - 个人文章 - SegmentFault 思否 [2024-04-19]">31. 人工智能 - Meta Llama 3 来啦!性能算力究竟如何？ - 个人文章 - SegmentFault 思否 [2024-04-19]</a></p> 
<p><a href="https://wap.sciencenet.cn/blog-377709-1430985.html?mobile=1" rel="nofollow" title="32. 如何用Llama 3 免费本地AI 分析数据和可视化？-王树义的博文 - 科学网 [2024-04-24]">32. 如何用Llama 3 免费本地AI 分析数据和可视化？-王树义的博文 - 科学网 [2024-04-24]</a></p> 
<p><a href="http://www.itbear.com.cn/html/2024-04/484944.html" rel="nofollow" title="33. 微软推出38亿参数phi-3-mini模型：每秒可生成12个tokens-人工智能-ITBear科技资讯 [2024-04-23]">33. 微软推出38亿参数phi-3-mini模型：每秒可生成12个tokens-人工智能-ITBear科技资讯 [2024-04-23]</a></p> 
<p><a href="https://www.jdon.com/73426.html" rel="nofollow" title="34. 微软Phi-3-Mini-4K-Instruct发布 - 汲道 [2024-04-24]">34. 微软Phi-3-Mini-4K-Instruct发布 - 汲道 [2024-04-24]</a></p> 
<p><a href="https://zhuanlan.zhihu.com/p/694064408" rel="nofollow" title="35. Microsoft 推出 Phi-3 系列型号，其性能优于同类其他型号, 可以在手机等边缘端得到很好的性能。 - 知乎 [2024-04-22]">35. Microsoft 推出 Phi-3 系列型号，其性能优于同类其他型号, 可以在手机等边缘端得到很好的性能。 - 知乎 [2024-04-22]</a></p> 
<p><a href="https://top.aibase.com/tool/phi-3-mini-4k-instruct-onnx" rel="nofollow" title="36. Phi-3-mini-4k-instruct-onnx使用入口地址Ai模型最新工具和软件app下载">36. Phi-3-mini-4k-instruct-onnx使用入口地址Ai模型最新工具和软件app下载</a></p> 
<p><a href="https://www.53ai.com/news/qianyanjishu/1251.html" rel="nofollow" title="37. 微软发布Phi-3，性能超Llama-3，可手机端运行- 大模型知识库 - 53AI">37. 微软发布Phi-3，性能超Llama-3，可手机端运行- 大模型知识库 - 53AI</a></p> 
<p><a href="https://zhuanlan.zhihu.com/p/693334299" rel="nofollow" title="38. 全球最强开源大模型Llama 3重磅发布：深度解析与展望 - 知乎 [2024-04-19]">38. 全球最强开源大模型Llama 3重磅发布：深度解析与展望 - 知乎 [2024-04-19]</a></p> 
<p><a href="http://www.citnews.com.cn/news/202404/177866.html" rel="nofollow" title="39. 微软开源最强小参数大模型—Phi-3 Mini [2024-04-24]">39. 微软开源最强小参数大模型—Phi-3 Mini [2024-04-24]</a></p> 
<p><a href="https://m.thepaper.cn/newsDetail_forward_27109633" rel="nofollow" title="40. Llama 3每秒输出800个token逼宫openAI - 澎湃新闻 [2024-04-21]">40. Llama 3每秒输出800个token逼宫openAI - 澎湃新闻 [2024-04-21]</a></p> 
<p><a href="https://m.36kr.com/p/2739577630091778" rel="nofollow" title="41. Meta震撼发布Llama 3，一夜重回开源大模型铁王座 - 36氪 [2024-04-18]">41. Meta震撼发布Llama 3，一夜重回开源大模型铁王座 - 36氪 [2024-04-18]</a></p> 
<p><a href="https://itnews.vip/?p=14647" rel="nofollow" title="42. 微软推出其规模最小的人工智能模型Phi-3 - ITnews.vip [2024-04-24]">42. 微软推出其规模最小的人工智能模型Phi-3 - ITnews.vip [2024-04-24]</a></p> 
<p><a href="https://favtutor.com/articles/microsoft-phi-3/" rel="nofollow" title="43. Meet Phi-3: Microsoft's New LLM That Can Run On Your Phone - FavTutor [2024-04-23]">43. Meet Phi-3: Microsoft's New LLM That Can Run On Your Phone - FavTutor [2024-04-23]</a></p> 
<p><a href="https://www.aihub.cn/tools/llm/llama-3/" rel="nofollow" title="44. Llama 3-Meta最新推出的新一代开源大模型 - AIHub | AI导航 [2024-04-19]">44. Llama 3-Meta最新推出的新一代开源大模型 - AIHub | AI导航 [2024-04-19]</a></p> 
<p><a href="https://news.cqnews.net/1/detail/1230795119132377088/web/content_1230795119132377088.html" rel="nofollow" title="45. 重磅！Meta推出开源大模型Llama 3，性能直逼GPT-4 - 华龙网 [2024-04-19]">45. 重磅！Meta推出开源大模型Llama 3，性能直逼GPT-4 - 华龙网 [2024-04-19]</a></p> 
<p><a href="https://m.36kr.com/p/2739979933935880" rel="nofollow" title="46. 开源大模型Llama 3王者归来，最大底牌4000亿参数，性能直逼GPT-4 [2024-04-19]">46. 开源大模型Llama 3王者归来，最大底牌4000亿参数，性能直逼GPT-4 [2024-04-19]</a></p> 
<p><a href="https://view.inews.qq.com/a/20240419A08NAM00" rel="nofollow" title="47. Meta正式发布Llama 3，号称是最强开源大模型 - QQ.COM [2024-04-19]">47. Meta正式发布Llama 3，号称是最强开源大模型 - QQ.COM [2024-04-19]</a></p> 
<p><a href="https://m.huxiu.com/article/2924915.html" rel="nofollow" title="48. 开源大模型Llama 3来了，能干得过GPT-4么？ - 虎嗅 [2024-04-19]">48. 开源大模型Llama 3来了，能干得过GPT-4么？ - 虎嗅 [2024-04-19]</a></p> 
<p><a href="https://cn.techbriefly.com/meta-ai-%E7%9A%84-llama-3-%E5%9F%BA%E5%87%86%E6%B5%8B%E8%AF%95%E7%BB%93%E6%9E%9C%E5%9C%A8%E8%BF%99%E9%87%8C-tech-91610/" rel="nofollow" title="49. Meta AI 的 Llama 3 基准测试结果在这里 | TechBriefly CN [2024-04-19]">49. Meta AI 的 Llama 3 基准测试结果在这里 | TechBriefly CN [2024-04-19]</a></p> 
<p><a href="https://zhuanlan.zhihu.com/p/693947727" rel="nofollow" title="50. LMSYS新测试基准，最强开源Llama 3分数骤降，实时更新竞技场数据，差距拉开了 - 知乎 [2024-04-22]">50. LMSYS新测试基准，最强开源Llama 3分数骤降，实时更新竞技场数据，差距拉开了 - 知乎 [2024-04-22]</a></p> 
<p><a href="https://www.thepaper.cn/newsDetail_forward_27122772" rel="nofollow" title="51. 新测试基准发布，最强开源Llama 3尴尬了 - 澎湃新闻 [2024-04-24]">51. 新测试基准发布，最强开源Llama 3尴尬了 - 澎湃新闻 [2024-04-24]</a></p> 
<p><a href="https://wap.eastmoney.com/a/202404193052076115.html" rel="nofollow" title="53. 开源社区分水岭：Meta大模型Llama 3发布参数最高或达4000亿 [2024-04-19]">53. 开源社区分水岭：Meta大模型Llama 3发布参数最高或达4000亿 [2024-04-19]</a></p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/a9ba8c1032aaea84ff8cecaa1f663737/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">深入探索：Zookeeper&#43;消息队列（kafka）集群</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/170840a96b5ffaed26ac2a4ad7e81398/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">使用kafka-clients依赖 集成kafka</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>