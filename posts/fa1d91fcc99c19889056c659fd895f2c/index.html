<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>LLaMA-Factory&#43;qwen多轮对话微调测评 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/fa1d91fcc99c19889056c659fd895f2c/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="LLaMA-Factory&#43;qwen多轮对话微调测评">
  <meta property="og:description" content="目录
训练的时间和效果
数据准备
数据样例
数据配置
环境搭建
模型微调训练
模型预测
运行成功的web UI
LLaMA-Factory地址：https://github.com/hiyouga/LLaMA-Factory/blob/main/README_zh.md
qwen地址：https://huggingface.co/Qwen/Qwen-7B-Chat/tree/main
训练的时间和效果 7580例对话数据，单卡A6000，显存45GB
{&#39;train_runtime&#39;: 429687.6086, &#39;train_samples_per_second&#39;: 2.646, &#39;train_steps_per_second&#39;: 0.662, &#39;train_loss&#39;: 0.0977083860479767, &#39;epoch&#39;: 150.0} ***** train metrics ***** epoch = 150.0 train_loss = 0.0977 train_runtime = 4 days, 23:21:27.60 train_samples_per_second = 2.646 train_steps_per_second = 0.662 Figure saved at: /home/wangyp/Big_Model/llama_factory_sft300/training_loss.png 04/08/2024 18:26:00 - WARNING - llmtuner.extras.ploting - No metric eval_loss to plot. [INFO|modelcard.py:450] 2024-04-08 18:26:00,005 &gt;&gt; Dropping the following result as it does not have all the necessary fields: {&#39;task&#39;: {&#39;name&#39;: &#39;Causal Language Modeling&#39;, &#39;type&#39;: &#39;text-generation&#39;}} 数据准备 数据样例 [ {&#34;">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-04-29T11:41:54+08:00">
    <meta property="article:modified_time" content="2024-04-29T11:41:54+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">LLaMA-Factory&#43;qwen多轮对话微调测评</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p id="main-toc"><strong>目录</strong></p> 
<p id="%E8%AE%AD%E7%BB%83%E7%9A%84%E6%97%B6%E9%97%B4%E5%92%8C%E6%95%88%E6%9E%9C-toc" style="margin-left:40px;"><a href="#%E8%AE%AD%E7%BB%83%E7%9A%84%E6%97%B6%E9%97%B4%E5%92%8C%E6%95%88%E6%9E%9C" rel="nofollow">训练的时间和效果</a></p> 
<p id="%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87-toc" style="margin-left:40px;"><a href="#%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87" rel="nofollow">数据准备</a></p> 
<p id="%E6%95%B0%E6%8D%AE%E6%A0%B7%E4%BE%8B-toc" style="margin-left:80px;"><a href="#%E6%95%B0%E6%8D%AE%E6%A0%B7%E4%BE%8B" rel="nofollow">数据样例</a></p> 
<p id="%E6%95%B0%E6%8D%AE%E9%85%8D%E7%BD%AE-toc" style="margin-left:80px;"><a href="#%E6%95%B0%E6%8D%AE%E9%85%8D%E7%BD%AE" rel="nofollow">数据配置</a></p> 
<p id="%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA-toc" style="margin-left:40px;"><a href="#%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA" rel="nofollow">环境搭建</a></p> 
<p id="%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E8%AE%AD%E7%BB%83-toc" style="margin-left:40px;"><a href="#%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E8%AE%AD%E7%BB%83" rel="nofollow">模型微调训练</a></p> 
<p id="%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B-toc" style="margin-left:40px;"><a href="#%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B" rel="nofollow">模型预测</a></p> 
<p id="%E8%BF%90%E8%A1%8C%E6%88%90%E5%8A%9F%E7%9A%84web%20UI-toc" style="margin-left:40px;"><a href="#%E8%BF%90%E8%A1%8C%E6%88%90%E5%8A%9F%E7%9A%84web%20UI" rel="nofollow">运行成功的web UI</a></p> 
<hr id="hr-toc"> 
<p></p> 
<p>LLaMA-Factory地址：<a href="https://github.com/hiyouga/LLaMA-Factory/blob/main/README_zh.md" title="https://github.com/hiyouga/LLaMA-Factory/blob/main/README_zh.md">https://github.com/hiyouga/LLaMA-Factory/blob/main/README_zh.md</a></p> 
<p>qwen地址：<a href="https://huggingface.co/Qwen/Qwen-7B-Chat/tree/main" rel="nofollow" title="https://huggingface.co/Qwen/Qwen-7B-Chat/tree/main">https://huggingface.co/Qwen/Qwen-7B-Chat/tree/main</a></p> 
<h3 id="%E8%AE%AD%E7%BB%83%E7%9A%84%E6%97%B6%E9%97%B4%E5%92%8C%E6%95%88%E6%9E%9C">训练的时间和效果</h3> 
<p>7580例对话数据，单卡A6000，显存45GB</p> 
<pre><code class="language-bash">{'train_runtime': 429687.6086, 'train_samples_per_second': 2.646, 'train_steps_per_second': 0.662, 'train_loss': 0.0977083860479767, 'epoch': 150.0}



***** train metrics *****
  epoch                    =               150.0
  train_loss               =              0.0977
  train_runtime            = 4 days, 23:21:27.60
  train_samples_per_second =               2.646
  train_steps_per_second   =               0.662
Figure saved at: /home/wangyp/Big_Model/llama_factory_sft300/training_loss.png
04/08/2024 18:26:00 - WARNING - llmtuner.extras.ploting - No metric eval_loss to plot.
[INFO|modelcard.py:450] 2024-04-08 18:26:00,005 &gt;&gt; Dropping the following result as it does not have all the necessary fields:
{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}
</code></pre> 
<h3 id="%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87">数据准备</h3> 
<h4 id="%E6%95%B0%E6%8D%AE%E6%A0%B7%E4%BE%8B">数据样例</h4> 
<pre><code class="language-python">[
{"id": "x3959", "conversations": [{"from": "user", "value": "明白了，谢谢医生的解答。我会带孩子去医院咨询专业医生的意见。"}, {"from": "assistant", "value": "非常好，建议您与儿科医生进行进一步的沟通和检查，以确定最适合您孩子的治疗方案。如果对生长激素还有其他疑问，随时都可以来咨询我。希望孩子能够健康地成长！"}, {"from": "user", "value": "我想给我的孩子打生长激素，这个方法好吗？"}, {"from": "assistant", "value": "您好！打生长激素的方法并不适用于所有的孩子，是否有具体的情况需要我了解一下呢？"}, {"from": "user", "value": "我家孩子身高一直没有长，我担心他会比同龄人矮小，所以想给他打生长激素。"}, {"from": "assistant", "value": "明白了，生长激素主要适用于因生长激素缺乏而导致的矮小症治疗。首先，我建议您带孩子去儿科医生那里做详细的检查，以确定是否存在生长激素缺乏的情况。"}, {"from": "user", "value": "好的，那如果确实是生长激素缺乏，打生长激素会有哪些副作用吗？"}, {"from": "assistant", "value": "确定了生长激素缺乏后，打生长激素在使用过程中有一定的副作用风险。通常，生长激素可能会引起血糖升高、骨质疏松等问题，并偶尔会增加肿瘤的风险。因此，在决定使用生长激素之前，医生会从多个方面评估您孩子的病情，以确保安全性和有效性。"}, {"from": "user", "value": "如果我孩子是由于特发性矮小症导致的，打生长激素能够增高吗？"}, {"from": "assistant", "value": "对于特发性矮小症，如果在骨骺闭合之前正确使用生长激素，通常可以达到一定的增高效果。然而，每个孩子的情况都不尽相同，所以在使用生长激素之前，医生会详细评估孩子的生长发育情况并权衡利弊。"}, {"from": "user", "value": "那什么情况下是不适合使用生长激素的呢？"}, {"from": "assistant", "value": "如果孩子没有明确的适应证，或者他的身高已经处于正常范围内，通常不建议滥用生长激素以免出现副作用。因此，在决定使用生长激素之前，务必在医生的指导下评估孩子的具体情况，避免不必要的风险。"}]},

{"id": "j26564", "conversations": [{"from": "user", "value": "好的，我明白了，我会带宝宝去儿科医生那里做个详细检查的。谢谢医生的帮助！"}, {"from": "assistant", "value": "不用客气，希望宝宝早日康复。如果还有其他问题，随时可以向我咨询。祝你和宝宝健康快乐！"}, {"from": "user", "value": "医生你好，我刚刚生下的宝宝鼻子上有一点黄点点，已经持续好几天了，这是什么东西啊？"}, {"from": "assistant", "value": "你好！对于新生儿鼻子上的黄点点，可能是黄疸的表现。黄疸是一种常见的新生儿现象，它是由于新生儿血液中胆红素水平增高造成的。可以进一步观察宝宝是否有以下症状：黄疸在其他部位，如眼睛、脸上出现；宝宝吃奶、睡觉和尿布情况是否正常；宝宝是否活动正常、有精神等。"}, {"from": "user", "value": "嗯，宝宝除了鼻子上有黄点点，其他地方没有发现黄疸的迹象。他的吃奶、睡觉和尿布情况都很正常，活动也很正常。这个黄点点有什么影响吗？"}, {"from": "assistant", "value": "如果宝宝只有鼻子上有黄点点，而其他地方没有黄疸迹象，并且宝宝的吃奶、睡觉等一切正常，一般来说是没有大问题的。但为了确认宝宝的健康状况，建议你带宝宝去当地的儿科医生那里做一个检查。医生会根据宝宝的具体情况给出更为准确的建议和诊断。"}]}
]
</code></pre> 
<h4 id="%E6%95%B0%E6%8D%AE%E9%85%8D%E7%BD%AE">数据配置</h4> 
<p>使用自定义数据集时，请更新 <code>data/dataset_info.json</code> 文件，该文件的格式请参考 <code>data/README_zh.md</code>。</p> 
<p>在<code>data/dataset_info.json</code>中加入这个配置</p> 
<pre><code class="language-python"> "wyp_cmtqa_erke": {
  	"file_name": "/home/caofeng/llm_chat/part_of_data_wyp.json",
  	"formatting":"sharegpt",
	  "columns": {
	    "messages": "conversations",
	    "tools":"id"
	  },
	  "tags": {
	    "role_tag": "from",
	    "content_tag": "value",
	    "user_tag": "user",
	    "assistant_tag": "assistant"
	  }
}</code></pre> 
<h3 id="%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA">环境搭建</h3> 
<pre><code class="language-bash">git clone https://github.com/hiyouga/LLaMA-Factory.git
conda create -n llama_factory python=3.10
conda activate llama_factory
cd LLaMA-Factory
pip install -r requirements.txt</code></pre> 
<h3 id="%E6%A8%A1%E5%9E%8B%E5%BE%AE%E8%B0%83%E8%AE%AD%E7%BB%83">模型微调训练</h3> 
<pre><code class="language-bash">CUDA_VISIBLE_DEVICES=1 python src/train_bash.py \
    --stage sft \
    --do_train \
    --model_name_or_path "/mnt/sdd/Qwen-7B-Chat" \
    --dataset wyp_cmtqa_erke \
    --template default \
    --finetuning_type lora \
    --output_dir "/home/wangyp/Big_Model/llama_factory_sft300" \
    --overwrite_cache \
    --per_device_train_batch_size 2 \
    --gradient_accumulation_steps 2 \
    --lr_scheduler_type cosine \
    --logging_steps 300 \
    --save_steps 56850 \
    --learning_rate 3e-4 \
    --num_train_epochs 150.0 \
    --plot_loss \
    --fp16</code></pre> 
<h3 id="%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B">模型预测</h3> 
<pre><code class="language-python">"""
调用微调以后的模型代码
"""
import warnings
warnings.filterwarnings("ignore")
import time

from peft import AutoPeftModelForCausalLM
from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig

sft_path = "/home/wangyp/Big_Model/sft150_based_sft_again_whoareyou2"
# sft_path = "/home/wangyp/Big_Model/sft150_based_sft_again_whoareyou_merge"
tokenizer = AutoTokenizer.from_pretrained(sft_path, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(sft_path, device_map="auto", trust_remote_code=True).eval()
import gradio as gradio


# 合并微调模型
# src_model_path="/home/wangyp/Big_Model/multi_chat_erke_output_qwen_30poch/checkpoint-7102"
# trg_model_path="/home/wangyp/Big_Model/multi_chat_erke_output_qwen_30poch_sft/checkpoint-7102"
# merge_model(src_model_path, trg_model_path)
def merge_model(src_model_path, trg_model_path):
    model = AutoPeftModelForCausalLM.from_pretrained(
        src_model_path, # path to the output directory
        device_map="auto",
        trust_remote_code=True
    ).eval()
    merged_model = model.merge_and_unload()
    merged_model.save_pretrained(trg_model_path, max_shard_size="2048MB", safe_serialization=True)
    print("merge_and_unload 保存成功！")

    tokenizer = AutoTokenizer.from_pretrained(src_model_path, trust_remote_code=True)
    tokenizer.save_pretrained(trg_model_path)
    print("tikenizer 保存成功！")



"""
预测
"""
def predict():
    s = ""
    q_list = [
        "我听说断掉夜奶也有助于减少牙菌斑的形成，是真的吗？",
        "还有其他预防和减少牙菌斑的方法吗？",
        "好的，我明白了。非常感谢您的建议！",


        "我想给我的孩子打生长激素，这个方法好吗？",
        "我家孩子身高一直没有长，我担心他会比同龄人矮小，所以想给他打生长激素。",
        "好的，那如果确实是生长激素缺乏，打生长激素会有哪些副作用吗？",
        "如果我孩子是由于特发性矮小症导致的，打生长激素能够增高吗？",
        "那什么情况下是不适合使用生长激素的呢？",
        "明白了，谢谢医生的解答。我会带孩子去医院咨询专业医生的意见。",
              ]
    history = None
    for q in (q_list):
        response, history = model.chat(tokenizer, q, history=history, system="你是一名医生角色，用有幽默的口吻对话询问")
        s += q + "\n" + response.strip() + "\n" + "================================================"+ "\n"

    with open("output.txt", "w", encoding="utf-8") as f:
        f.write(s)



def multi_chat_gr(message, history):
    response, history = model.chat(tokenizer, message, history=history)
    print(len(history))
    print((history))
    print("++++++++++++++++++++++++++++++++++++")
    for i in range(len(response)):
        time.sleep(0.05)
        yield response[: i + 1]



if __name__ == '__main__':
    # src_model_path="/home/wangyp/Big_Model/sft150_based_sft_again_whoareyou"
    # trg_model_path="/home/wangyp/Big_Model/sft150_based_sft_again_whoareyou_merge"
    # merge_model(src_model_path, trg_model_path)

    # predict()


    gr_instance = gradio.ChatInterface(fn=multi_chat_gr,
                                   title="这是一个大专家打造的医疗对话机器人，使用儿科对话数据进行训练，欢迎您的使用！结果仅供参考，不构成严谨的医疗建议。",
                                   chatbot=gradio.Chatbot(height=700, label="大专家AI医生", show_copy_button=True, avatar_images=["/home/wangyp/Big_Model/LLaMA-Factory-main/user.jpg","/home/wangyp/Big_Model/LLaMA-Factory-main/doctor.jpg"],render_markdown=True),
                                   textbox=gradio.Textbox(placeholder="请在这里输入您的问题", container=False, scale=7)

                                   )
    gr_instance.launch(share=True, server_name='0.0.0.0', server_port=6062)

</code></pre> 
<p></p> 
<p>tips:</p> 
<p>计算steps的方法</p> 
<pre><code class="language-python">data_size = 100
batch_size = 4
epoch = 30

total_steps = (data_size / batch_size) * epoch
print("Total steps: ", total_steps)</code></pre> 
<h3 id="%E8%BF%90%E8%A1%8C%E6%88%90%E5%8A%9F%E7%9A%84web%20UI">运行成功的web UI</h3> 
<p><img alt="" height="937" src="https://images2.imgbox.com/a9/7e/AqE5d7I8_o.png" width="1200"></p> 
<p><a href="https://github.com/HeiBoWang/NLG-evaluation" title="NLG-evaluation ： ">NLG-evaluation ： </a><a href="https://github.com/HeiBoWang/NLG-evaluation" title="GitHub - HeiBoWang/NLG-evaluation: A toolkit for evaluation of natural language generation (NLG), including BLEU, ROUGE, METEOR, and CIDEr.">GitHub - HeiBoWang/NLG-evaluation: A toolkit for evaluation of natural language generation (NLG), including BLEU, ROUGE, METEOR, and CIDEr.</a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/ae1b47be47e6fc82baa036f7b2c28a95/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">vue3面试题：2024 最新前端 Vue 3</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/13e054e7cdfa992cc8285cd538ba59db/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Macos 13 用 xcode 15 调试 ios 17 .4</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>