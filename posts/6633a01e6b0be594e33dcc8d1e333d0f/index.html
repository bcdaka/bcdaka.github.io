<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>李开复：所有应用都应该 AI-First、大模型要更关注 TC-PMF - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/6633a01e6b0be594e33dcc8d1e333d0f/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="李开复：所有应用都应该 AI-First、大模型要更关注 TC-PMF">
  <meta property="og:description" content="作者 | 唐小引
出品丨AI 科技大本营（ID：rgznai100）
时间过得很快，中国大模型之战已经度过了百模大战的阶段，进入了许多人称为「大模型应用落地的元年」。时逢五月，零一万物也迎来了成立一周年。5 月 13 日， 赶在 OpenAI 发布会和 Google I/O 之前，在创新工场、零一万物所在的中关村鼎好大厦，李开复博士久违地露面，带来了零一万物最新的产品矩阵发布，以及他对于模型之战从狂奔进入长跑的思考。
在产品矩阵方面，有四大关键点：
千亿参数的闭源模型 Yi-Large 来了，在斯坦福最新的 AlpacaEval 2.0 达到全球大模型 Win Rate 第一，其 API 开放可用，据李开复从各项指标表示，目前 Yi-Large 在多项指标上已经超过了 GPT-4；
过去一年里，以开源构建生态，零一万物的全球化布局成果很是显著，笔者在常浏览的国外诸多榜单中，经常能看到 Yi 大模型的身影。而今天，李开复现场宣布将 Yi-34B、Yi-9B/6B 中小尺寸开源模型版本升级为 Yi-1.5 系列。其从数据对比来看，Yi-34B 模型已全方面达到了超越 Google 的 Gemma、Mistral 以及 Meta 的 Llama 的表现；
更大的模型 Yi-XLarge 正在训练中，基于 MoE 架构，已经有了初步的训练结果，预计晚些时候会正式发布这一模型；
颇值得关注的是，零一正式宣告投身 AI 应用开发，带来一站式 AI 工作平台“AI-First 版 Office”——万知，已全面接入 Yi-Large 大模型。万知支持小程序和 Web 端，当前用户均可直接免费使用。
为什么会带来模型&#43;应用这样的产品组合？这背后的种种，是李开复带领着零一万物对于模型、应用、商业化的思考，他将其称为开闭源的双轨策略，即用闭源探索商业化做 AI-First，开源构建生态。在发布会现场，「全球化」、「AI-First」是他高频提及的词汇，李开复博士定义了零一万物的四大发展原则 —— 全球化布局、模基共建、模应一体、AI-First。
全球化布局和 AI-First 很好理解，模基共建和模应一体如何理解？">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-05-21T13:28:58+08:00">
    <meta property="article:modified_time" content="2024-05-21T13:28:58+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">李开复：所有应用都应该 AI-First、大模型要更关注 TC-PMF</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div id="js_content"> 
 <p style="text-align:center;"><img alt="7d7f20cf6c4b6522fac182f112c38bea.gif" height="280" src="https://images2.imgbox.com/83/81/52WxUZnE_o.jpg" width="1200"></p> 
 <p style="text-align:left;">作者 | 唐小引</p> 
 <p style="text-align:left;">出品丨AI 科技大本营（ID：rgznai100）</p> 
 <p>时间过得很快，中国大模型之战已经度过了百模大战的阶段，进入了许多人称为「大模型应用落地的元年」。时逢五月，零一万物也迎来了成立一周年。5 月 13 日， 赶在 OpenAI 发布会和 Google I/O 之前，在创新工场、零一万物所在的中关村鼎好大厦，李开复博士久违地露面，带来了零一万物最新的产品矩阵发布，以及他对于模型之战从狂奔进入长跑的思考。</p> 
 <p style="text-align:center;"><img alt="940ceaec2154f8a39a071cd1a182b5ac.jpeg" src="https://images2.imgbox.com/6a/fd/9MewvWwu_o.jpg"></p> 
 <p>在产品矩阵方面，有四大关键点：</p> 
 <ul><li> <p>千亿参数的闭源模型 Yi-Large 来了，在斯坦福最新的 AlpacaEval 2.0 达到全球大模型 Win Rate 第一，其 API 开放可用，据李开复从各项指标表示，目前 Yi-Large 在多项指标上已经超过了 GPT-4；</p> </li><li> <p>过去一年里，以开源构建生态，零一万物的全球化布局成果很是显著，笔者在常浏览的国外诸多榜单中，经常能看到 Yi 大模型的身影。而今天，李开复现场宣布将 Yi-34B、Yi-9B/6B 中小尺寸开源模型版本升级为 Yi-1.5 系列。其从数据对比来看，Yi-34B 模型已全方面达到了超越 Google 的 Gemma、Mistral 以及 Meta 的 Llama 的表现；</p> </li><li> <p>更大的模型 Yi-XLarge 正在训练中，基于 MoE 架构，已经有了初步的训练结果，预计晚些时候会正式发布这一模型；</p> </li><li> <p>颇值得关注的是，零一正式宣告投身 AI 应用开发，带来一站式 AI 工作平台“AI-First 版 Office”——万知，已全面接入 Yi-Large 大模型。万知支持小程序和 Web 端，当前用户均可直接免费使用。</p> </li></ul> 
 <p style="text-align:center;"><img alt="8294a34561f354806ee6130ddb06b00d.jpeg" src="https://images2.imgbox.com/6c/f5/xLwd8Cbv_o.jpg"></p> 
 <p>为什么会带来模型+应用这样的产品组合？这背后的种种，是李开复带领着零一万物对于模型、应用、商业化的思考，他将其称为开闭源的双轨策略，即用闭源探索商业化做 AI-First，开源构建生态。在发布会现场，「全球化」、「AI-First」是他高频提及的词汇，李开复博士定义了<strong>零一万物的四大发展原则 —— 全球化布局、模基共建、模应一体、AI-First。</strong></p> 
 <p>全球化布局和 AI-First 很好理解，模基共建和模应一体如何理解？</p> 
 <p>李开复表示，模基共建意指模型的训练、服务、推理设计，与底层 Infra 架构和模型结构必须高度适配，这核心在于中国大模型公司没有美国大厂的 GPU 数量，所以必须采取更务实的战术和战略。AI Infra 主要涵盖大模型训练和部署提供各种底层技术设施，在李开复博士看来，自研 AI Infra 是零一万物必然要走过的路。而模应一体的背后则是在大模型之战后，用户会按照应用侧所展现的能力，用脚投票。基于此，李开复提出了「TC-PMF」（Product-Market-Technology-Cost Fit，技术成本 X 产品市场契合度）的理论，以真实用户体验，和模型迭代形成正循环。</p> 
 <p>除了这些之外，李开复博士有着不少金句，在此摘取供朋友们速览：</p> 
 <ul><li> <p>我一年前跟我的投资人做出过承诺 —— <strong>我十年不套现。我觉得最好的套现方式是赶快上市</strong>，这是我们未来两年会努力的。</p> </li><li> <p>我非常认可 PMF（Product Market Fit，产品/市场契合度）的理论，因为没有任何一种技术可以在长期的时间里只靠技术领跑所有的竞争，最终产品的胜出，一定要靠非技术的优势达到口碑的传播。但有了 PMF 本身这个理论是不够的，除了 PMF 之外，<strong>AI 2.0 时代，我们还要考虑 TC-PMF，T 代表技术，C 代表成本。</strong></p> </li><li> <p>今天的模型在非常快速地基于 Scaling Law 演进、进化，如果只是针对一年多前的 GPT-3.5 优化应用，GPT-4 出来已经改写了应用所具有的能力，所以要不断预测未来技术会怎么走，不是基于今天的技术能做什么，而是能做半年后、一年后。</p> </li><li> <p>我们整个行业应该用更务实的方法，一方面做一个务实的 AGI 信仰者，另一方面要务实地把模型尺寸压缩下来，把推理成本降低下来。</p> </li><li> <p>国内的初创公司，相对硅谷公司的差异，是我们能够仰望星空，但也能脚踏实地。我们会同时考虑非常复杂的题目，首先是预备技术的进步，能力所及产生什么样的模型。其次，如何把推理成本做到最低，让我们点燃普惠点。第三还有传统的 PMF，找到用户需求。</p> </li><li> <p>人类的需求是固定的，我们需要工作、娱乐、沟通、社交、电商、购买，这些什么时候才能有 AI-Frist 应用出来？这个真实带来的价值就是谁会打造一个 AI 抖音、AI 微信、AI 淘宝，我们希望我们有可能作为这样一个点燃者。如果我们不能做到，我们也希望一个很好的开发者，能用我们的 API 做到。</p> </li><li> <p>谈大模型之战的行业洗牌：中国市场还在发酵、成长中，我很看好中国的创业者，中国创业者的生命力会超过简单的想象洗牌就死掉多少，当然会有一家又一家慢慢地转型甚至退场，但千万不要低估中国创业的生命力。</p> </li></ul> 
 <p style="text-align:center;"><strong><img alt="52d81611ef3bfdd07c17b0e76a96bf46.png" src="https://images2.imgbox.com/09/47/QM07EoR8_o.png"></strong></p> 
 <p><strong>零一万物做起了应用，李开复直言<strong>所有的应用都应该 AI-First</strong></strong></p> 
 <p>今时今日，以模型技术起家的创业公司，做应用的并不多。这也是为什么，当最开始听到零一发布了自己的生产力应用时，不少开发者有点讶然。</p> 
 <p>万知这款应用，李开复在演讲中将其定义为「AI-First 版 Office」，是集问答、阅读、创作于一身的一站式 AI 工作平台。它有两个呈现模式，一是如果将其作为 ChatGPT 或其他应用，打开万知小程序，一切问题皆可询问；二是作为工作中密切使用的一个工作站，在 Web 端访问 wanzhi.com。它可以在十几秒内阅读海量文字，速读 PDF 等文档内容，能够对图片内容进行解析。不仅能够生成文字，还支持生成图表以及 PPT。这和当前已经被大量使用的 Office Copilot、WPS AI 很是类似，但相比之下，至少在当前状态，万知无需付费订阅，可以直接丝滑使用。</p> 
 <p style="text-align:center;"><img alt="313602ff37e9f6458dd102de2ea5e6ea.png" src="https://images2.imgbox.com/f9/fe/tsIUr2Pw_o.png"></p> 
 <p style="text-align:center;">使用万知生成一份「人工智能简史」PPT 的测试</p> 
 <p>据李开复博士现场演示，如果你想要做某个主题的 PPT，可以由它生成大纲，进而带来一份看起来相当不错的 PPT，内容、样式一应俱全。当然，笔者使用万知想要生成一份「人工智能简史」的 PPT，如上图所示，大纲内容倒是看着详实，但 PPT 生成的结果却只有标题和图片，没有详细的内容。而比如笔者也想将零一此次发布会、李开复博士的演讲资料都抛给万知，写一篇可用的文章，亲测之后一如使用 GPT-4 等的体验，是很好的助手，但还不能让人类直接躺平。当然，在可期的时间内，正如李开复博士所讲，「所有的应用都应该是 AI-First、AI-Native，有了这么聪明的大模型，我们不用再去打开空白文件手动输入内容，95% 的制作都由 AI 来做」，希望早日成真。</p> 
 <p style="text-align:center;"><strong><img alt="0f46897a09f62c544f8ac97d13f613fc.png" src="https://images2.imgbox.com/b8/74/iN32jauh_o.png"></strong></p> 
 <p><strong>AI 2.0 时代，我们需要考虑 TC-PMF</strong></p> 
 <p>对于做大模型奉为圭臬的 PMF 理论，李开复表示非常认可 PMF 理论，但有了 PMF 是不够的，在 AI 2.0 时代我们需要考虑 TC-PMF。其中，T 表示技术，C 表示成本。为什么我们需要将这两个元素考虑进来？</p> 
 <p style="text-align:center;"><img alt="cc536179bb3a400dbe7ee668246f958d.jpeg" src="https://images2.imgbox.com/b8/93/nEpL6wmk_o.jpg"></p> 
 <p>李开复分享了自己的思考：今天的模型在非常快速地基于 Scaling Law 推进和演进，如果只是针对一年三个月前的 GPT-3.5 优化应用，那么 GPT-4 出来已经改写了应用所具有的能力。所以，我们需要不断预测未来技术会怎么走，不是基于今天的技术能做什么，而是能做半年后、一年后。开始做一款产品时，假如半年以后能做出来，那个时刻你的技术有多强大。</p> 
 <p>但还有很大的问题，是我们整个行业推理成本过高，所以很多的应用，今天大家耳熟能详的社交、电商、广告、短视频，还不能全面嵌入 AI，即便 Yi-Large 这么便宜的 API，今天开发一个社交应用，每次和人聊天都要调用，帮你画各种东西，最后这个 API 的成本还是会让你直接破产。</p> 
 <p>所以我们作为一个行业要不断降低推理成本，训练和推理都很重要。有些特别顶尖的应用需要顶级的模型才能实现，但也有些应用的爆发并不需要最顶级的模型，也许小一点的模型就可以。我们需要预测推理成本，API 的成本什么时候低廉到大家都可以用，为什么我们还没有像移动互联网那么好用的应用？一方面我们的时间还不长，另外一方面就是很多的应用普惠，因为有特别多的 API 调用，如果用今天的推理成本做不出来，绝对会破产的。所以我们整个行业应该用更务实的方法，一方面做一个务实的 AGI 的信仰者，另一方面我们要务实地把模型尺寸压缩下来，把推理成本降低下来，行业在进步，我们作为零一万物能不能独特地加速比别人的成本更降一步。</p> 
 <p style="text-align:center;"><strong><img alt="91cf54f8d811a7b43de38ceecd05dd03.png" src="https://images2.imgbox.com/26/d7/UtKlAywZ_o.png"></strong></p> 
 <p><strong>结语</strong></p> 
 <p>在模型之战后，我们迎来了诸多对于 AI Native 应用的尝试与探索。李开复博士久违的露面带来了很多极具启发性的思考，尤其对于 AI-First 的应用而言，是我们众多开发者正在苦思冥想的一大问题。对比往昔 PC、移动互联网时代的超级应用特征，李开复博士提出了 AI 2.0 时代的 Super App 究竟将会如何到来：</p> 
 <ul><li> <p>When：能否前瞻地判断 TC-PMF 的时间点；</p> </li><li> <p>How：能否以独家技术能力加速抢跑；</p> </li><li> <p>Who：团队是否有执行力、能利用先发优势。</p> </li></ul> 
 <p>期待我们迎来属于 AI 时代的超级应用。</p> 
 <p style="text-align:center;"><img alt="30d2be502c4d57c38b9cfa4d8fd41a91.gif" src="https://images2.imgbox.com/a3/21/J7FqhKWU_o.gif"></p> 
 <p style="text-align:center;"><img alt="f7cfa421b592a17a1d60a0856652cc73.jpeg" src="https://images2.imgbox.com/06/5d/58n6ZnAx_o.jpg"></p> 
</div>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/14edd1e5cba4d3ed3a2e7b1893a092d5/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">JavaScript异步编程模型</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/5bd316eeda4ee34e01481a06a53a6c59/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">废物回收机构|基于SprinBoot&#43;vue的地方废物回收机构管理系统(源码&#43;数据库&#43;文档)</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>