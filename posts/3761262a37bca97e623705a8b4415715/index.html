<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Hadoop 2.0：主流开源云架构（二） - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/3761262a37bca97e623705a8b4415715/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="Hadoop 2.0：主流开源云架构（二）">
  <meta property="og:description" content="目录 二、Hadoop 2.0简述（一）Hadoop 2.0由来（二）Hadoop 2.0相关项目（三）Hadoop应用 三、Hadoop 2.0部署（一）部署综述（二）传统解压包部署 二、Hadoop 2.0简述 （一）Hadoop 2.0由来 工业界称Hadoop 1.X及其以前的版本（0.23.X除外）为Hadoop 1.0，称Hadoop 2.X及其以后版本为Hadoop 2.0。
Hadoop 2.0提供分布式存储（HDFS）和分布式操作系统（Yarn）两大功能软件包。
将Hadoop 2.0部署至集群后，通过调用Hadoop 2.0程序库，能够用简单的编程模型来处理分布在不同机器上的大规模数据集。由于采用客户-服务器模式，Hadoop 2.0很容易从一台机器扩展至成千上万台机器，并且每台机器都能提供本地计算存储和本地计算。考虑到集群中每台机器都可能会出问题（如硬件失效），Hadoop 2.0本身从设计上就在程序层规避了这些问题。
Hadoop至少应当包含分布式存储和分布式计算两个模块，下面给出Hadoop1.0项目模块。
（1）Hadoop Common：联系HDFS和MapReduce的纽带，它一方面为另外两组件提供一些公用jar包，另一方面也是程序员访问其他两模块的接口。
（2）HDFS：Hadoop的分布式文件系统。主要提供分布式存储服务。
（3）Hadoop MapReduce：分布式计算框架。主要负责资源管理、任务调度和MapReduce算法实现。
（二）Hadoop 2.0相关项目 Google云计算组件和Hadoop及其相关项目之间的对应关系：
Hadoop云计算系统Google云计算系统Hadoop HDFSGoogle GFSHadoop MapReduceGoogle MapReduceHBaseGoogle BigTableZooKeeperGoogle ChubbyPigGoogle Sawzall 近几年工业界围绕Hadoop进行了大量的外围产品开发，下图描述了各个产品项目之间的层次关系。
（三）Hadoop应用 1、构建大型分布式集群
Hadoop最直接的应用就是构建大型分布式集群，提供海量存储和计算服务，像国内的中国移动“大云”、淘宝“云梯”等，都已是大型甚至超大型分布式集群。
2、数据仓库
很多公司的log日志文件、其他半结构化业务数据并不适合存入关系型数据库，却特别适合存入半结构化的HDFS，然后应用其他工具（如Hive、Hbase）提供报表查询之类的服务。
3、数据挖掘
大数据环境下的数据挖掘其实并没有太大改变，但大数据却给数据挖掘的预处理工具出了难题。受限于硬盘性能和内存大小限制，普通服务器读取1TB数据需要至少二十分钟，但Hadoop却是每台机器读取1/n TB，加上共享集群内存和CPU，实际处理时间何止n倍。
Hadoop己广泛应用于分布式集群构建、数据存储、数据挖掘等领域。随着大数据和云计算时代的到来，相信Hadoop 的应用将更加广泛。
三、Hadoop 2.0部署 （一）部署综述 1、部署方式
（1）安装方式：
传统解压包方式：烦琐易错；有助于读者深入理解Hadoop。Linux标准方式：简单易用；隐藏了太多细节。 （2）部署环境：
单机模式：不需要与其他节点交互，不需要使用HDFS，直接读写本地的文件系统。伪分布模式：在一台单机上运行，用不同的进程模仿分布式运行中的各类节点。分布式模式：在不同的机器上部署系统。 2、部署步骤
3、准备环境
（1）硬件环境
由于分布式计算需要用到很多机器，部署时用户须提供多台机器，至于提供几台，须根据 “部署规划”确定。
实际上，完全模式部署Hadoop时，最低需要两台机器（一个主节点，一个从节点），此外，硬件方面，每台机器最低要求有1GB内存，20GB硬盘空间。
（2）软件环境
大量的实践证明，在Linux环境下使用Hadoop则更加稳定高效。须注意的是新装系统（CentOS）的机器不可以直接部署Hadoop，需要设置：修改机器名，添加域名映射，关闭防火墙，安装JDK。
【例2】 现有一台CentOS系统机器，且装机时用户名为joe，要求将此机器名修改为cMaster，添加域名映射，关闭防火墙，安装JDK。">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-06-20T10:15:08+08:00">
    <meta property="article:modified_time" content="2024-06-20T10:15:08+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Hadoop 2.0：主流开源云架构（二）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>目录</h4> 
 <ul><li><ul><li><a href="#Hadoop_20_3" rel="nofollow">二、Hadoop 2.0简述</a></li><li><ul><li><a href="#Hadoop_20_4" rel="nofollow">（一）Hadoop 2.0由来</a></li><li><a href="#Hadoop_20_18" rel="nofollow">（二）Hadoop 2.0相关项目</a></li><li><a href="#Hadoop_32" rel="nofollow">（三）Hadoop应用</a></li></ul> 
   </li><li><a href="#Hadoop_20_48" rel="nofollow">三、Hadoop 2.0部署</a></li><li><ul><li><a href="#_49" rel="nofollow">（一）部署综述</a></li><li><a href="#_124" rel="nofollow">（二）传统解压包部署</a></li></ul> 
  </li></ul> 
 </li></ul> 
</div> 
<p></p> 
<hr> 
<h3><a id="Hadoop_20_3"></a>二、Hadoop 2.0简述</h3> 
<h4><a id="Hadoop_20_4"></a>（一）Hadoop 2.0由来</h4> 
<p><img src="https://images2.imgbox.com/fe/f8/MsjmpxYS_o.png" alt="在这里插入图片描述" width="600"><br>   工业界称Hadoop 1.X及其以前的版本（0.23.X除外）为Hadoop 1.0，称Hadoop 2.X及其以后版本为Hadoop 2.0。</p> 
<p><img src="https://images2.imgbox.com/e3/de/DjtwGzDn_o.png" alt="在这里插入图片描述" width="500"><br>   Hadoop 2.0提供分布式存储（HDFS）和分布式操作系统（Yarn）两大功能软件包。</p> 
<p>  将Hadoop 2.0部署至集群后，通过调用Hadoop 2.0程序库，能够用简单的编程模型来处理分布在不同机器上的大规模数据集。由于采用客户-服务器模式，Hadoop 2.0很容易从一台机器扩展至成千上万台机器，并且每台机器都能提供本地计算存储和本地计算。考虑到集群中每台机器都可能会出问题（如硬件失效），Hadoop 2.0本身从设计上就在程序层规避了这些问题。</p> 
<p>  Hadoop至少应当包含分布式存储和分布式计算两个模块，下面给出Hadoop1.0项目模块。<br> （1）Hadoop Common：联系HDFS和MapReduce的纽带，它一方面为另外两组件提供一些公用jar包，另一方面也是程序员访问其他两模块的接口。<br> （2）HDFS：Hadoop的分布式文件系统。主要提供分布式存储服务。<br> （3）Hadoop MapReduce：分布式计算框架。主要负责资源管理、任务调度和MapReduce算法实现。</p> 
<h4><a id="Hadoop_20_18"></a>（二）Hadoop 2.0相关项目</h4> 
<p>  Google云计算组件和Hadoop及其相关项目之间的对应关系：</p> 
<table><thead><tr><th>Hadoop云计算系统</th><th>Google云计算系统</th></tr></thead><tbody><tr><td>Hadoop HDFS</td><td>Google GFS</td></tr><tr><td>Hadoop MapReduce</td><td>Google MapReduce</td></tr><tr><td>HBase</td><td>Google BigTable</td></tr><tr><td>ZooKeeper</td><td>Google Chubby</td></tr><tr><td>Pig</td><td>Google Sawzall</td></tr></tbody></table> 
<p>  近几年工业界围绕Hadoop进行了大量的外围产品开发，下图描述了各个产品项目之间的层次关系。</p> 
<p><img src="https://images2.imgbox.com/b0/7a/CD3IoHyh_o.png" alt="在这里插入图片描述" width="600"></p> 
<h4><a id="Hadoop_32"></a>（三）Hadoop应用</h4> 
<p><img src="https://images2.imgbox.com/f9/af/0kPZqSQj_o.png" alt="在这里插入图片描述" width="600"><br> <strong>1、构建大型分布式集群</strong></p> 
<p>  Hadoop最直接的应用就是构建大型分布式集群，提供海量存储和计算服务，像国内的中国移动“大云”、淘宝“云梯”等，都已是大型甚至超大型分布式集群。</p> 
<p><strong>2、数据仓库</strong></p> 
<p>  很多公司的log日志文件、其他半结构化业务数据并不适合存入关系型数据库，却特别适合存入半结构化的HDFS，然后应用其他工具（如Hive、Hbase）提供报表查询之类的服务。</p> 
<p><strong>3、数据挖掘</strong></p> 
<p>  大数据环境下的数据挖掘其实并没有太大改变，但大数据却给数据挖掘的预处理工具出了难题。受限于硬盘性能和内存大小限制，普通服务器读取1TB数据需要至少二十分钟，但Hadoop却是每台机器读取1/n TB，加上共享集群内存和CPU，实际处理时间何止n倍。</p> 
<p>  Hadoop己广泛应用于分布式集群构建、数据存储、数据挖掘等领域。随着大数据和云计算时代的到来，相信Hadoop 的应用将更加广泛。</p> 
<h3><a id="Hadoop_20_48"></a>三、Hadoop 2.0部署</h3> 
<h4><a id="_49"></a>（一）部署综述</h4> 
<p><strong>1、部署方式</strong></p> 
<p><strong>（1）安装方式：</strong></p> 
<ul><li>传统解压包方式：烦琐易错；有助于读者深入理解Hadoop。</li><li>Linux标准方式：简单易用；隐藏了太多细节。</li></ul> 
<p><strong>（2）部署环境：</strong></p> 
<ul><li>单机模式：不需要与其他节点交互，不需要使用HDFS，直接读写本地的文件系统。</li><li>伪分布模式：在一台单机上运行，用不同的进程模仿分布式运行中的各类节点。</li><li>分布式模式：在不同的机器上部署系统。</li></ul> 
<p><strong>2、部署步骤</strong><br> <img src="https://images2.imgbox.com/ff/e7/WZQmvCuP_o.png" alt="在这里插入图片描述" width="600"><br> <strong>3、准备环境</strong></p> 
<p><strong>（1）硬件环境</strong></p> 
<p>  由于分布式计算需要用到很多机器，部署时用户须提供多台机器，至于提供几台，须根据 “部署规划”确定。<br>   实际上，完全模式部署Hadoop时，最低需要两台机器（一个主节点，一个从节点），此外，硬件方面，每台机器最低要求有1GB内存，20GB硬盘空间。</p> 
<p><strong>（2）软件环境</strong></p> 
<p><img src="https://images2.imgbox.com/1f/4b/VC3WKzHH_o.png" alt="在这里插入图片描述" width="300"><br>   大量的实践证明，在Linux环境下使用Hadoop则更加稳定高效。须注意的是新装系统（CentOS）的机器不可以直接部署Hadoop，需要设置：修改机器名，添加域名映射，关闭防火墙，安装JDK。</p> 
<p><strong>【例2】</strong> 现有一台CentOS系统机器，且装机时用户名为joe，要求将此机器名修改为cMaster，添加域名映射，关闭防火墙，安装JDK。</p> 
<p><strong>① 修改机器名</strong></p> 
<pre><code>[joe@localhost ~]$ su-root                            #切换成root用户修改机器名
[root@localhost ~]# vim /etc/sysconfig/network        #编辑存储机器名文件
</code></pre> 
<p>  将“<code>HOSTNAME=localhost.localdomain</code>”中的“<code>localhost.localdomain</code>”替换成需要使用的机器名，按要求，此处应为cMaster，即此行内容为：</p> 
<pre><code>HOSTNAME=CMaster                                     #指定本机名为cMaster 
</code></pre> 
<p>  注意重启机器后更名操作才会生效，用户须通过此命令修改集群中所有机器的机器名，重启后，本机将有自己唯一的机器名cMaster了。</p> 
<p><strong>② 添加域名映射</strong></p> 
<p>  首先使用如下命令查看本机IP地址，这里以cMaster机器为例。</p> 
<pre><code>[root@cMaster ~]# ifconfig                            #查看cMaster机器IP地址
</code></pre> 
<p>假如看到此机器的IP地址为“<code>192.168.1.100</code>”，机器名为cMaster，则域名映射应为：</p> 
<pre><code>192.168.1.100cMaster 
</code></pre> 
<p>  接着编辑域名映射文件“<code>/etc/hosts</code>”，将上述内容加入此文件。</p> 
<pre><code>[root@cMaster ~]# vim /etc/hosts                      #编辑域名映射文件
</code></pre> 
<p><strong>③ 关闭防火墙</strong></p> 
<p>  CentOS的防火墙iptables默认情况下会阻止机器间通信，编者建议系统管理员开启Hadoop使用的端口，也可以暂时关闭或永久关闭iptables（不建议），为简单起见， 永久关闭防火墙，其关闭命令如下（执行命令后务必重启机器才可生效）：</p> 
<pre><code>[root@cMaster ~]# chkconfig --level 35 iptables off              #永久关闭iptables，重启后生效
</code></pre> 
<p><strong>④ 安装JDK</strong></p> 
<p>  Hadoop部署前须安装JDK，而且Hadoop只能使用Oracle的1.6及以上版本的JDK，不能使用openjdk。用户须首先下载<code>jdk-x.rpm</code>包，如<code>jdk-7u40-linux-x64.rpm</code>。打开刚才己经安装的CentOS机器，将<code>jdk-7u40-linux-x64.rpm</code>复制至虚拟机下某位置， Termianl下执行（此方式安装的JDK无须配置java_home）如下命令:</p> 
<pre><code>[root@cMaster ~]# java                                           #查看java是否安装
[root@cMaster ~]# rpm -ivh /home/joe/jdk-7u40-linux-x64.rpm      #以root权限，rpm方式安装JDK
[root@cMaster ~]# java                                           #验证java是否安装成功
</code></pre> 
<p><strong>4、关于Hadoop依赖软件</strong></p> 
<ul><li>SSH只是给<code>sbin/start-yarn.sh</code>等几个<code>start-x.sh</code>与<code>stop-x.sh</code>脚本使用。</li><li>Hadoop本身是一堆Java代码，而Java代码并不依赖SSH。</li><li>本节使用的Hadoop版本为稳定版<code>Hadoop-2.2.0.tar.gz</code>。</li><li>CentOS版本为64位CentOS-6.5。</li><li>JDK版本为<code>jdk-7u40-linux-x64.rpm</code>。</li></ul> 
<h4><a id="_124"></a>（二）传统解压包部署</h4> 
<p><strong>【例3】</strong> 现有三台机器，且它们都刚装好64位CentOS-6.5，安装系统时用户名为joe，请按要求完成：<br> ① 修改三台机器名为cMaster，cSlave0和cSlave1，并添加域名映射、关闭防火墙和安装JDK。<br> ② 以cMaster作为主节点，cSlave0和cSlave1作为从节点，部署Hadoop。</p> 
<p><strong>（1）制定部署规划</strong></p> 
<p>  此Hadoop集群需三台机器（cMaster，cSlave0和cSlave1），其中cMaster作为主节点，cSlave0和cSlave1作为从节点。</p> 
<p><strong>（2）准备机器</strong></p> 
<p>  准备三台机器，它们可以是实体机也可以是虚拟机，若使用虚拟机。</p> 
<p><strong>（3）准备机器软件环境</strong></p> 
<p>  三台机器都要完成：修改机器名、添加域名映射、关闭防火墙和安装JDK。</p> 
<p><strong>（4）下载Hadoop</strong></p> 
<p>  谷歌搜索“Hadoop download”并下载，以joe用户身份，将Hadoop分别复制到三台机器上。</p> 
<p><strong>（5）解压Hadoop</strong></p> 
<p>  分别以joe用户登录三台机器，每台都执行如下命令解压Hadoop文件：</p> 
<pre><code>[joe@cMaster ~]# tar -zxvf /home/joe/Hadoop-2.2.0.tar.gz
[joe@cSlave0 ~]# tar -zxvf /home/joe/Hadoop-2.2.0.tar.gz
[joe@cSlave1 ~]# tar -zxvf /home/joe/Hadoop-2.2.0.tar.gz
</code></pre> 
<p><strong>（6）配置Hadoop</strong></p> 
<p>  三台机器都要配置，且配置相同。</p> 
<p>  首先，编辑文件“<code>/home/joe/Hadoop-2.2.0/etc/Hadoop/Hadoop-env.sh</code>”，找到如下行：</p> 
<pre><code>export JAVA_HOME=${JAVA_HOME}
</code></pre> 
<p>将这行内容修改为：</p> 
<pre><code>export JAVA_HOME=/usr/java/jdk1.7.0_40
</code></pre> 
<p>这里的“<code>/usr/java/jdk1.7.0_40</code>”就是JDK安装位置，如果不同，读者须根据实际情况更改之，需要注意的是，三台机器都要执行此操作。</p> 
<p>  其次，编辑文件“<code>/home/joe/Hadoop-2.2.0/etc/Hadoop/core-site.xml</code>”，并将如下内容嵌入此文件里<code>configuration</code>标签间，和上一个操作相同，三台机器都要执行此操作：</p> 
<pre><code>&lt;property&gt;&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;&lt;value&gt;/home/joe/cloudData&lt;/value&gt;&lt;/property&gt;
&lt;property&gt;&lt;name&gt;fs.defaultFS&lt;/name&gt;&lt;value&gt;hdfs://cMaster:8020&lt;/value&gt;&lt;/property&gt;
</code></pre> 
<p>编辑文件“<code>/home/joe/Hadoop-2.2.0/etc/Hadoop/yarn-site.xml</code>”，并将如下内容嵌入此文件里<code>configuration</code>标签间，同样，三台机器都要执行此操作：</p> 
<pre><code>&lt;property&gt;&lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;&lt;value&gt;cMaster&lt;/value&gt;&lt;/property&gt;
&lt;property&gt;&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;&lt;value&gt;mapreduce_shuffle&lt;/value&gt;&lt;/property&gt;
</code></pre> 
<p>  最后，将文件“<code>/home/joe/Hadoop-2.2.0/etc/Hadoop/mapred-site.xml.template</code>”重命名为“ <code>/home/joe/Hadoop-2.2.0/etc/Hadoop/mapred-site.xml</code>”，接着编辑此文件并将如下内容嵌入此文件的<code>configuration</code>标签间，同样，三台机器都要执行此操作：</p> 
<pre><code>&lt;property&gt;&lt;name&gt;mapreduce.framework.name&lt;/name&gt;&lt;value&gt;yarn&lt;/value&gt;&lt;/property&gt;
</code></pre> 
<p><strong>（7）启动Hadoop</strong></p> 
<p>  首先，在主节点cMaster上格式化主节点命名空间：</p> 
<pre><code>[joe@cMaster ~]# Hadoop-2.2.0/bin/hdfs namenode -format
</code></pre> 
<p>  其次，在主节点cMaster上启动存储主服务namenode和资源管理主服务resourcemanager。</p> 
<pre><code>[joe@cMaster ~]# hadoop-2.2.0/sbin/Hadoop-daemon.sh start namenode         #cMaster启动存储主服务
[joe@cMaster ~]# hadoop-2.2.0/sbin/yarn-daemon.sh start resourcemanager        #启动资源管理主服务
</code></pre> 
<p>  最后，在从节点上启动存储从服务datanode和资源管理从服务nodemanager，注意，CSlave0和cSlavel 这两台机器上都要执行，对应命令如下：</p> 
<pre><code>[joe@cSlave0 ~]# hadoop-2.2.0/sbin/Hadoop-daemon.sh start datanode        #cSlave0启动存储从服务
[joe@cSlave0 ~]# hadoop-2.2.0/sbin/yarn-daemon.sh start nodemanager       #cSlave0启动资源管理从服务
[joe@cSlave1 ~]# hadoop-2.2.0/sbin/Hadoop-daemon.sh start datanode        #cSlavel 启动存储从服务
[joe@cSlave1 ~]# hadoop-2.2.0/sbin/yarn-daemon.sh start nodemanager       #cSlavel启动资源管理从服务
</code></pre> 
<p><strong>（8）测试Hadoop</strong></p> 
<p>  可以分别在三台机器上执行如下命令，查看Hadoop服务是否己启动。</p> 
<pre><code>$ /usr/java/jdk1.7.0_40/bin/jps           #jps查看java进程
$ ps -ef | grep java                      #ps查看java进程
</code></pre> 
<p>  会在cMaster上看到类似的如下信息：</p> 
<pre><code>3056 ResourceManager                      #资源管理主服务
2347 NameNode                             #存储主服务
</code></pre> 
<p>  而cSlave0和cSlave1上看到类似的如下信息：</p> 
<pre><code>4021 DataNode                             #存储从服务
2761 NodeManager                          #资源管理从服务
</code></pre> 
<p>  此外，还可以任选一台机器，如cMaster，打开CentOS默认浏览器Firefox，地址栏输入“<code>cMaster:50070</code>”，即可在Web界面看到HDFS相关信息；同理，地址栏输入“<code>cMaster:8088</code>”，即可在Web界面看到 Yarn相关信息。</p> 
<p>  通过上述单机部署和集群部署，可以看出，Hadoop本身部署起来很简单，其大量工作其实都是前期的Linux环境配置，Hadoop安装只是解压、修改配置文件、格式化、启动和验证，关于Linux命令问题，请参考Linux专业书籍。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/bdde8ccf0fa83db82ca7a694af57c05a/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">详解Qt中connect()函数</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/fea089880e83f2d1c8d1f374a1bcea74/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【PyQt5】python可视化开发：PyQt5介绍，开发环境搭建快速入门</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>