<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>多目标跟踪MOT技术总结（持续更新） - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/b0663cc3c5f27b6b3b79b710a4dbf70d/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="多目标跟踪MOT技术总结（持续更新）">
  <meta property="og:description" content="前言：本人作为MOT领域新人，目前已经阅读一定量和质量的paper，尽可能的将这些MOT算法按照不同的技术路径进行分类（2016 SORT之后），并且只对论文的方法做一个大概的总结，具体细节请参照原文，如果有理解不到位的地方欢迎指出，同时也希望同方向的小伙伴一起学习交流~~
什么是MOT？ 为了完成目标跟踪任务，首先需要将目标定位在一帧中，给每个目标分配一个单独的唯一id，然后在连续帧中的同一个目标将生成一条轨迹。当跟踪多个目标时，称为多目标跟踪。
MOT在应用场景上分为二维多目标跟踪和三维多目标跟踪；其中，三维较二维多增加了深度信息和角度信息。在传感器方面，三维分为单目、双目（图像，伪点云）以及激光雷达（点云），二维为相机。在算法技术方面，多数三维MOT依赖于现有的二维MOT算法进行优化改进。
MOT 是一项关键的视觉感知任务，需要解决不同的问题，例如拥挤场景中的长短时遮挡、相似外观、小目标检测困难、ID切换、速度突变等。为了应对这些挑战，研究人员尝试利用transformer的注意力机制、利用图卷积神经网络获得轨迹的相关性、不同帧中目标与Siamese网络的外观相似性，还尝试了基于简单 IOU 匹配的 CNN 网络、运动预测的 LSTM等方法。
本篇技术总结主要是针对主流的CNN网络这一条脉络，对主流算法进行分类，并按照相关性顺序进行总结。由于大多数二维、三维MOT算法思想大同小异，且可以迁移使用，本文将一并做介绍，为后续研究提供发散性的参考思路。
一、评价指标（目前还没总结完，之后会补充） 1、二维评价指标 MT：Mostly Tracked trajectories，成功跟踪的帧数占总帧数的80%以上的GT轨迹数量
Fragments：碎片数，成功跟踪的帧数占总帧数的80%以下的预测轨迹数量
ML：Mostly Lost trajectories，成功跟踪的帧数占总帧数的20%以下的GT轨迹数量
False trajectories：预测出来的轨迹匹配不上GT轨迹，相当于跟踪了个寂寞
ID switches：因为跟踪的每个对象都是有ID的，一个对象在整个跟踪过程中ID应该不变，但是由于跟踪算法不强大，总会出现一个对象的ID发生切换，这个指标就说明了ID切换的次数，指前一帧和后一帧中对于相同GT轨迹的预测轨迹ID发生切换，跟丢的情况不计算在ID切换中。
FP：总的误报数量，即整个视频中的FP数量，即对每帧的FP数量求和
FN：总的漏报数量，即整个视频中的FN数量，即对每帧的FN数量求和
Fragm（FM）：总的fragmentation数量，every time a ground truth object tracking is interrupted and later resumed is counted as a fragmentation，注意这个指标和Fragments有点不一样
IDSW：总的ID Switch数量，即整个视频中的ID Switch数量，即对每帧发生的ID Switch数量求和，这个和Classical metrics中的ID switches基本一致
MOTA：注意MOTA最大为1，由于IDSW的存在，MOTA最小可以为负无穷。
MOTP：衡量跟踪的位置误差，其中t表示第t帧，Ct表示第t帧中预测轨迹和GT轨迹成功匹配上的数目，dt,i表示t帧中第i个匹配对的距离。这个距离可以用IOU或欧式距离来度量，IOU大于某阈值或欧氏距离小于某阈值视为匹配上了。可以看出来MOTP这个指标相比于评估跟踪效果，更注重检测质量。
IDP：识别精确度 (Identification Precision) 是指每个行人框中行人 ID 识别的精确度。
IDR：识别召回率 (Identification Recall) 是指每个行人框中行人 ID 识别的召回率
IDF1：Identification F1，是IDP和IDR的调和均值，表示的是一条轨迹正确跟踪的时间
FPS：Frames Per Second，每秒处理的帧数。">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2023-09-18T09:59:57+08:00">
    <meta property="article:modified_time" content="2023-09-18T09:59:57+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">多目标跟踪MOT技术总结（持续更新）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>        <strong>前言：本人作为MOT领域新人，目前已经阅读一定量和质量的paper，尽可能的将这些MOT算法按照不同的技术路径进行分类（2016 SORT之后），并且只对论文的方法做一个大概的总结，具体细节请参照原文，如果有理解不到位的地方欢迎指出，同时也希望同方向的小伙伴一起学习交流~~</strong></p> 
<p></p> 
<h2>什么是MOT？</h2> 
<p style="margin-left:0;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#333333;">        为了完成目标跟踪任务，首先需要将目标定位在一帧中，给每个目标分配一个单独的唯一id</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">，然后在连续帧中的同一个目标将生成一条轨迹。当跟踪多个目标时，称为</span></span><strong><u><span style="background-color:#ffffff;"><span style="color:#ff0000;">多目标跟踪。</span></span></u></strong></p> 
<p style="margin-left:0;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#333333;">        MOT在应用场景上分为<strong>二维</strong>多目标跟踪和<strong>三维</strong>多目标跟踪；其中，三维较二维多增加了<strong>深度信息和角度信息</strong>。在传感器方面，三维分为单目、双目（图像，伪点云）以及激光雷达（点云），二维为相机。在算法技术方面，多数三维</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">MOT</span></span><strong><span style="background-color:#ffffff;"><span style="color:#333333;">依赖于现有的二维</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#333333;">MOT</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#333333;">算法</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">进行优化改进。</span></span></p> 
<p style="text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#333333;">        MOT 是一项关键的视觉感知任务，需要解决不同的问题，例如拥挤场景中的<strong>长短时遮挡、相似外观、小目标检测困难、</strong></span></span><strong><span style="background-color:#ffffff;"><span style="color:#333333;">ID</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">切换、速度突变</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">等。为了应对这些挑战，研究人员尝试利用</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">transformer</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">的注意力机制、利用图卷积神经网络获得轨迹的相关性、不同帧中目标与</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Siamese</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">网络的外观相似性，还尝试了</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">基于简单</span></span><span style="background-color:#ffffff;"><span style="color:#ff0000;"> IOU </span></span><span style="background-color:#ffffff;"><span style="color:#ff0000;">匹配的</span></span><span style="background-color:#ffffff;"><span style="color:#ff0000;"> CNN </span></span><span style="background-color:#ffffff;"><span style="color:#ff0000;">网络</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">、运动预测的</span></span><span style="background-color:#ffffff;"><span style="color:#333333;"> LSTM</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">等方法。</span></span></p> 
<p class="img-center"><img alt="" height="444" src="https://images2.imgbox.com/c9/b9/P02IlOEn_o.png" width="865"></p> 
<p>         <span style="background-color:#ffffff;"><span style="color:#333333;">本篇技术总结主要是针对</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">主流的</span></span><span style="background-color:#ffffff;"><span style="color:#ff0000;">CNN</span></span><span style="background-color:#ffffff;"><span style="color:#ff0000;">网络</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">这一条脉络，对主流算法进行分类，并按照相关性顺序进行总结。由于大多数二维、三维</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">MOT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">算法思想大同小异，且可以迁移使用，本文将一并做介绍，为后续研究提供发散性的参考思路。</span></span></p> 
<hr> 
<h2><span style="color:#333333;">一、</span><span style="background-color:#ffffff;"><span style="color:#333333;">评价指标（目前还没总结完，之后会补充）</span></span> </h2> 
<h3 style="text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#333333;"> 1、二维评价指标</span></span></h3> 
<p></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">MT</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">Mostly Tracked trajectories</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">，成功跟踪的帧数占总帧数的80%以上的GT轨迹数量</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">Fragments</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">碎片数，成功跟踪的帧数占总帧数的80%以下的预测轨迹数量</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">ML</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">Mostly Lost trajectories</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">，成功跟踪的帧数占总帧数的20%以下的GT轨迹数量</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">False trajectories</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">预测出来的轨迹匹配不上GT轨迹，相当于跟踪了个寂寞</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">ID switches</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">因为跟踪的每个对象都是有ID的，一个对象在整个跟踪过程中ID应该不变，但是由于跟踪算法不强大，总会出现一个对象的ID发生切换，这个指标就说明了ID切换的次数，指前一帧和后一帧中对于相同GT轨迹的预测轨迹ID发生切换，跟丢的情况不计算在ID切换中。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">FP</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">总的误报数量，即整个视频中的FP数量，即对每帧的FP数量求和</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">FN</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">总的漏报数量，即整个视频中的FN数量，即对每帧的FN数量求和</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">Fragm</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">（FM）：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">总的fragmentation数量，every time a ground truth object tracking is interrupted and later resumed is counted as a fragmentation，注意这个指标和Fragments有点不一样</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">IDSW</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">总的ID Switch数量，即整个视频中的ID Switch数量，即对每帧发生的ID Switch数量求和，这个和Classical metrics中的ID switches基本一致</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">MOTA</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">注意MOTA最大为1，由于IDSW的存在，MOTA最小可以为负无穷。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><img alt="" height="32" src="https://images2.imgbox.com/e2/08/mik7xvxe_o.png" width="188"></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">MOTP</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">衡量跟踪的位置误差，其中t表示第t帧，Ct表示第t帧中预测轨迹和GT轨迹成功匹配上的数目，dt,i表示t帧中第i个匹配对的距离。这个距离可以用IOU或欧式距离来度量，IOU大于某阈值或欧氏距离小于某阈值视为匹配上了。可以看出来MOTP这个指标相比于评估跟踪效果，更注重检测质量。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><img alt="" height="35" src="https://images2.imgbox.com/b1/41/p94BlCTt_o.png" width="99"></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">IDP</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">识别精确度 (Identification Precision) 是指每个行人框中行人 ID 识别的精确度。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><img alt="" height="32" src="https://images2.imgbox.com/15/39/kWn3xBfq_o.png" width="124"></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">IDR</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">识别召回率 (Identification Recall) 是指每个行人框中行人 ID 识别的召回率</span></span></p> 
<p style="margin-left:0;text-align:justify;"><img alt="" height="32" src="https://images2.imgbox.com/d6/40/lm7ahY7g_o.png" width="126"></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">IDF1</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">Identification F1</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">，是IDP和IDR的调和均值，表示的是一条轨迹正确跟踪的时间</span></span></p> 
<p style="margin-left:0;text-align:justify;"><img alt="" height="45" src="https://images2.imgbox.com/74/8e/zhsFRFZp_o.png" width="273"></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">FPS</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">Frames Per Second</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">，每秒处理的帧数。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">HOTA</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#000000;">高阶跟踪精度，它明确地将执行精确检测、关联和定位的效果平衡到一个统一的用于比较跟踪器的度量中。有好几个子度量</span></span></p> 
<h3 style="text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#333333;"> 2、三维评价指标</span></span></h3> 
<hr> 
<h2><span style="background-color:#ffffff;"><span style="color:#333333;">二、二维</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">MOT</span></span></h2> 
<h3><span style="background-color:#ffffff;"><span style="color:#333333;">  1、多目标跟踪</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">TBD</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">tracking by detection</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span></h3> 
<h4><span style="background-color:#ffffff;"><span style="color:#333333;"> （</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">1</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2016</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">年</span></span><span style="background-color:#ffffff;"><span style="color:#333333;"> ICIP</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">《</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Simple online and Realtime tracking</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">》（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">SORT）</span></span></h4> 
<p class="img-center"><img alt="" height="405" src="https://images2.imgbox.com/45/b9/Wb4vPLYX_o.png" width="865"></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">创新点：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">提出了一种</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">简单、实时</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">的数据关联方法，并可用于在线目标跟踪。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">为什么：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">现有的跟踪算法过分追求算法复杂度以增强跟踪器的鲁棒性，导致检测速度很慢，不能实时进行。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">怎么做：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">根据上一帧的跟踪结果，利用</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">卡尔曼滤波</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">预测当前帧每个目标的状态量（预测值），再利用</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">匈牙利算法</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">与目标检测器的检测结果对当前帧的检测状态（观测值）进行</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">数据关联</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">(IOU)</span></span></strong><span style="background-color:#ffffff;"><span style="color:#000000;">，实现跟踪</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">总结：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">该论文</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">沿用了</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">tracking-by-detection</span></span></strong><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">框架</span></span>，且后续<span style="background-color:#ffffff;"><span style="color:#4d4d4d;">TBD</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">范式的</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">MOT</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">多数基于</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">SORT</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">进行改进</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">。但对</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">IDs</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">和轨迹碎片化处理效果不好。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ff0000;"><span style="color:#000000;">注：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">主要关注点在高效地</span></span>实现<strong><u><span style="background-color:#ffffff;"><span style="color:#ff0000;"><a href="https://so.csdn.net/so/search?q=frame&amp;spm=1001.2101.3001.7020" title="frame">frame</a>-to-frame</span></span></u></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;"> associate objects</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">，使其能支持</span></span><strong><span style="color:#ff0000;">online</span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">、</span></span><strong><span style="color:#ff0000;">realtime</span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">的应用</span></span>，而忽略了其他组件（比如遮挡问题、外观、轨迹重连），避免引入复杂性使模型无法<span style="background-color:#ffffff;"><span style="color:#333333;">realtime</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">。</span></span></p> 
<p></p> 
<h4><span style="background-color:#ffffff;"><span style="color:#333333;"> （</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2017</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">年</span></span><span style="background-color:#ffffff;"><span style="color:#333333;"> ICIP</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">《</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Simple online and Realtime tracking with a deep association metric</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">》（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">DeepSORT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span></h4> 
<p style="margin-left:0;text-align:justify;"><a name="_Hlk128753542"></a></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">创新点：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">在</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Association</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">阶段，引入了</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">re-ID</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">匹配</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">，并改进了匹配策略（级联匹配）</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">为什么：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">SORT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">仅仅采用了运动模型并且只关注于帧与帧之间的关联，准确率相对而言不是很高，在发生遮挡的情况下，很容易发生</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">ID</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">变换。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">怎么做：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">具体做法与</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">SORT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">类似，在关联阶段，引入了</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">re-ID</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">信息</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">，并使用级联匹配；</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">分配策略：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">先通过马氏距离过滤掉一些框，再用</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">re-id</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">计算余弦距离进行匈牙利分配。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">级联匹配：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">根据轨迹丢失观测的次数，优先匹配丢失次数少的轨迹</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">总结：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">仍然是一种基于检测的跟踪算法，与</span></span><span style="background-color:#ffffff;"><span style="color:#333333;"> SORT </span></span><span style="background-color:#ffffff;"><span style="color:#333333;">类似，不过改进了匹配策略，加入了外观信息来提高</span></span><span style="background-color:#ffffff;"><span style="color:#333333;"> SORT </span></span><span style="background-color:#ffffff;"><span style="color:#333333;">的性能。经过改进后，</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Deep SORT </span></span><span style="background-color:#ffffff;"><span style="color:#333333;">能够跟踪到遮挡时间更长的目标，并且显著减少了</span></span><span style="background-color:#ffffff;"><span style="color:#333333;"> ID </span></span><span style="background-color:#ffffff;"><span style="color:#333333;">互换的数量。</span></span></p> 
<p><span style="background-color:#ff0000;"><span style="color:#000000;">注：</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">re-ID</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">re-identification</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">），利用计算机视觉技术判断图像或者视频序列中是否存在特定行人的技术，抽取一个低维的</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">embedding</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">向量进行不同帧间的外观匹配</span></span></p> 
<p></p> 
<h4><span style="background-color:#ffffff;"><span style="color:#333333;"> （</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">3</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2018</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">年</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">ICME</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">《</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Real-time Multiple People Tracking with Deeply Learned Candidate Selection and Person Re-Identification</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">》（MOTDT）</span></span></h4> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">创新点：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">设计一种</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">统一的评分函数</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">，用于在</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">跟踪器和检测器生成的候选框</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">上进行最优选择，并使用外观和空间信息来进行轨迹关联</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">（分层关联）</span></span></strong></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">为什么：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">现有的方法在数据关联时，与现有轨迹关联的候选框仅有检测结果构成，但作者认为应该将跟踪器和检测器看作</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">两个互相独立的部件</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">，并将其结果均作为候选框（跟踪器解决漏检遮挡等问题，检测器解决漂移问题），同时前人设计候选框基于手工特征费时且精度低。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">怎么做：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">1</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">、评估所有的候选框采用一个统一的评分函数，这个函数由一个判别训练的</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">目标分类器</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">和一个精心设计的</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">轨迹段置信度</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">计算模块构成；2、NMS用来基于候选框的评分进行冗余候选框消除；3、在消除冗余的候选框的基础上，使用外观表示和空间信息来分层关联候选框和已有轨迹（先对来自检测的候选框与轨迹进行re-id匹配，再剩下没匹配成功的候选框与轨迹进行IoU匹配。）</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">总结：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">本文使用的是</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">“轨迹混合匹配”</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">的机制，即将当前帧检测器的检测值和轨迹的kalman滤波预测值进行比较，筛选出来的结果作为当前帧的候选目标，并与前一帧的轨迹进行匹配关联。更新：上一帧的后验轨迹和当前帧的候选</span></span></p> 
<p style="margin-left:0;text-align:justify;"><span style="background-color:#ff0000;"><span style="color:#333333;">注：</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">可以这么理解先用re-id对没有被遮挡的框进行匹配然后用IOU对遮挡的目标进行匹配。因为没有被遮挡情况下，一般检测器的分数高；遮挡或漏检情况下，预测框的分数高</span></span></p> 
<p style="margin-left:0;text-align:justify;"></p> 
<h4 style="margin-left:0px;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#333333;">  （</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">4</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2022</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">年</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">ECCV</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">《</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">ByteTrack: Multi-Object Tracking by Associating Every Detection Box</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">》（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">ByteTrack</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span></h4> 
<p style="text-align:center;"><img alt="" height="469" src="https://images2.imgbox.com/1e/ba/1P1kHG1C_o.png" width="498"></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">创新点：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">提出一种</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">二阶段关联</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">方法，充分利用了低置信度检测框（作者认为可能低分框可能有遮挡的目标产生）。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">为什么：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">目前大部分的做法是关联高置信度的检测框，导致一些由</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">遮挡</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">或模糊等原因产生的弱小目标被过滤掉，导致</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">轨迹消失或碎片化</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">。但直接把第低分检测框当高分来用也不合理。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">怎么做：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">在第一阶段，高置信度的目标先和轨迹进行关联；在第二阶段，通过</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">IoU</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">，将没有匹配上的轨迹和低置信度的弱小目标进行关联</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">总结：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">算法核心在于二阶段关联法，因此可以套用在任何检测器上，可以很大程度上改善一些现有算法漏检、轨迹碎片化等情况；</span></span></p> 
<p style="margin-left:0;text-align:justify;"></p> 
<h4><span style="background-color:#ffffff;"><span style="color:#333333;"> （</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">5</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2022</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">年</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">TMM</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">《</span></span>StrongSORT: Make DeepSORT Great Again<span style="background-color:#ffffff;"><span style="color:#333333;">》（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">StrongSORT++</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span></h4> 
<p class="img-center"><img alt="" height="482" src="https://images2.imgbox.com/ef/b1/zEAe8b1J_o.png" width="865"></p> 
<p class="img-center"><img alt="" height="331" src="https://images2.imgbox.com/24/0c/f1GRE5iz_o.png" width="1111"></p> 
<p class="img-center"><img alt="" height="393" src="https://images2.imgbox.com/d9/46/f5qGT1o2_o.png" width="476"></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">创新点：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">用最新的组件和训练</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">trick</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">来优化</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">DeepSORT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">；</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">提出了一种无外观链接模型</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;"> (AFLink)</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">，仅用时空信息将短轨迹关联到完整的轨迹中；其次提出了高斯平滑插值</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;"> (GSI) </span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">来补偿缺失的检测</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">为什么：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">JDE</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">和</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">JDT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">精度往往不如</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">TBD</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">（不同任务的竞争关系和有限的训练数据），</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">DeepSORT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">表现不佳是因为过时的技术；有些算法仅利用运动信息在复杂环境下鲁棒性差</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">怎么做：</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">StrongSORT</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">训练</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">更好</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">的检测器</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">YOLO-X</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">；采用指数移动平均</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">EMA</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Exponential Moving Average</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">更新</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">re-id</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">；</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">CMC</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">进行相机位置补偿（两帧图像对齐配准）；将传统</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">KF</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">替换为</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">NSA Kalman</span></span></strong><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">（能根据目标检测的质量自适应调整噪声尺度）；</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">cost matrix</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">是</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">运动模型和</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">re-id</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">的加权</span></span></strong><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">；最后用</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">Vanilla</span></span></strong><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">全局线性赋值匹配代替匹配级联（没懂这个匹配策略）。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">AFLink :</span></span></strong><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">由两个轨道的时空信息作为输入，然后预测他们是同一条轨迹的置信度。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">GSI</span></span></strong><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">（</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">Gaussian-smoothed interpolation</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">）：平滑的补偿缺失的轨迹（一种带高斯平滑的插值方式，没懂）</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">总结：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">对</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">DeepSORT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">各模组的优化，新增了</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">AFlink</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">和</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">GSI</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">用于补偿缺失的轨迹，整体来说精度相对上升，但速度较慢，是否可以轻量化具体模块，提升速度？</span></span></p> 
<p><span style="background-color:#ffffff;"><span style="color:#333333;"><strong><span style="background-color:#ff0000;"><span style="color:#333333;">注：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">实验部分很详细很充实，在秀</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">SOTA</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">指标的同时，也对自身存在的问题做了反思和改进</span></span></span></span></p> 
<p></p> 
<h4>  <span style="background-color:#ffffff;"><span style="color:#333333;">（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">6</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2022</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">年</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">CVPR</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">《</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">BoT-SORT: Robust Associations Multi-Pedestrian Tracking</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">》（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">BoT-SORT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span></h4> 
<p class="img-center"><img alt="" height="346" src="https://images2.imgbox.com/7a/f8/3WpHk0JR_o.png" width="865"></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">创新点：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">提出</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">相机运动补偿</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">和</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">更准确的</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">卡尔曼滤波器</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">状态向量</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">实现更好的边界框定位；提出一种基于</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">IoU</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">和</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">re-id</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">的余弦距离</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">新的融合方式</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">；</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">为什么：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">SORT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">中</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">KF</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">使用的状态参数用纵横比和面积导致对宽度的估计不准确，同时</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">IoU</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">匹配是基于预测后的边界框位置，而预测边界框的正确位置可能会由于相机运动而失败，导致跟踪性能低下；由遮挡等引起的外观低得分不适合现有的</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">cost distance</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">加权融合方法</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">怎么做：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#000000;">1</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">、修改</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">KF</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">的</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">状态参数</span></span></strong><span style="background-color:#ffffff;"><span style="color:#000000;">为</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">[x,y,w,h,x(•),y(•),w(•),h(•)];2</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">、在</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">KF</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">对预测后的轨迹进行更新前，用</span><span style="color:#fe2c24;"><strong>G</strong></span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">MC</span></span></strong><span style="background-color:#ffffff;"><span style="color:#000000;">对预测轨迹进行</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">矫正</span></span></strong><span style="background-color:#ffffff;"><span style="color:#000000;">；</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">3</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">、依然使用</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">EMA</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">更新</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">reid</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">的分数，在</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">cost matrix</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">中使用</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">新的融合方式</span></span></strong><span style="background-color:#ffffff;"><span style="color:#000000;">融合运动信息</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">IoU</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">和外观信息</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">re-id</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">而不是用加权求和的方式</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">总结：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">作者针对卡尔曼滤波次优估计、相机运动问题和指标权衡问题提出了新的追踪器，并整合到了</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">ByteTrack</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">。除遮挡外，</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">IDs</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">和</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">FN</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">的问题还可能是由于不规则的运动导致检测框和预测框无法很好的重叠，更别提模糊环境下，G</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">MC</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">可以优化这一点，是不是还有其他方法？（这个方法</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">非常耗时的，暂在端侧应用不太可行）另外，这篇的引言讲的比较透彻</span></span></p> 
<p style="margin-left:0;text-align:justify;"></p> 
<h4 style="margin-left:0px;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#333333;">（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">7</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2022</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">年</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">CVPR</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">《</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Observation-Centric SORT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">：</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Rethinking SORT for Robust Multi-Object Tracking</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">》（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">OC SORT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span></h4> 
<p class="img-center"><img alt="" height="463" src="https://images2.imgbox.com/82/1a/MzSQj6m6_o.png" width="865"></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">创新点：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">提出了</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">OC-SORT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">，适用于在遮挡和非线性运动下进行鲁棒跟踪，针对基于</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">KF</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">的</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">SORT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">三个局限提出了：</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">OOS</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">、</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">OCM</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">和</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">OCR</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">为什么：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">SORT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">有三个局限性：</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">对状态噪声敏感、随时间累积的误差、以估计为中心</span></span></strong></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">怎么做：</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">OOS(Observation-centric Online Smoothing)</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">：</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">结合当前的观测和最后一次匹配的观测</span></span></strong><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">构建一条</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">虚拟轨迹</span></span></strong><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">，对</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">KF</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">的状态噪声参数<strong>做一个平滑处理。</strong></span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">                OCM(Observation-Centric Momentum)：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">建立</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">cost matrix</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">的时候除了位置特征和外观特征外，</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">额外增加了速度方向一致性</span></span></strong><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">（动量）</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">                OCR(Observation-Centric Recovery)：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">若一条轨迹在正常关联阶段后仍然没有被匹配成功，尝试将这条轨迹的</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">最后一次观测与当前帧最新的观测</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">进行关联，来恢复被中断的轨迹。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">总结：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">目前基于</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">KF</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">的</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">运动模型对</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">遮挡、非线性运动、低帧率视频</span></span></strong> <span style="background-color:#ffffff;"><span style="color:#4d4d4d;">的情况并不鲁棒。</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">OC-SORT</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">尝试优化运动模型（即</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">KF</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">滤波），并强调了检测（</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">Observation</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">）对恢复丢失的轨迹和减少丢失期间</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">KF</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">模型的误差累积的作用，提高了对遮挡和非线性运动等情况的鲁棒性。</span></span></p> 
<p style="margin-left:0;text-align:justify;"></p> 
<h4> <span style="background-color:#ffffff;"><span style="color:#333333;">（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">8</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2023</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">年</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">CVPR</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">《</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">DEEP OC-SORT: MULTI-PEDESTRIAN TRACKING BY ADAPTIVE RE-IDENTIFICATION</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">》（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Deep OC-SORT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span></h4> 
<p style="margin-left:0px;text-align:center;"><img alt="" height="367" src="https://images2.imgbox.com/67/38/mzOGVQPF_o.png" width="865"></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">创新点：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">提出了一种基于</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">动态和自适应</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">启发式的模型，以将视觉外观与基于运动的线索结合在单个阶段中进行轨迹关联，在</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">OC-SORT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">的基础上新增了</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">CMC</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">，</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">DA</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">，</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">AW</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">三个模块。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">为什么：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">re-id</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">提取器仍然包含由于遮挡、运动模糊或类似外观的对象而产生的显著噪声。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">怎么做：</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">CMC</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">（</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">Camera Motion Compensation</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">）：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">在</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">OOS</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">，</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">OCM,OCR</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">中逐帧使用相机运动补偿以提高目标位置精准度（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">KF</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">更新前）。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">                DA（Dynamic Appearance</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">）：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">提出一种</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">自适应的加权因子</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">，根据检测结果的置信度，来调整外观的得分。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">                AW（Adaptive Weighting</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">）：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">提出一种</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">自适应的加权因子</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">，用来平衡</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">cost distance</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">中</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">IoU</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">和</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">re-ID</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">的权重</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">总结：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">将动态视觉外观和相机运动补偿引入</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">OC-SORT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">，并在轨迹关联阶段添加自适应加权因子平衡运动模型和外观模型的权重以此构建合理的</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">cost distance</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">。</span></span></p> 
<p style="margin-left:0;text-align:justify;"></p> 
<h4> <span style="background-color:#ffffff;"><span style="color:#333333;">（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">9</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2021</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">年《</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Simpletrack: Understanding and rethinking 3d multi-object tracking</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">》（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">SimpleTrack</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）（这篇是讲3D的，但个人觉得放在这里也很合适）</span></span></h4> 
<p></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">创新点：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">将</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">TBD</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">范式分为四个模块，并基于目前的基准分析了每个模块目前存在的不足以及改进</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">为什么：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">基于</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">TBD</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">范式的哪些组件对性能起着重要作用</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">?</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">如何改进他们以提升</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">MOT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">性能</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">怎么做：</span></span></strong><strong> </strong><span style="background-color:#ffffff;"><span style="color:#333333;">（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">1</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）<strong>检测模块：</strong>相对于传统设置阈值，作者对</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">detection</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">采用</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">NMS</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">（非极大值抑制），来消除冗余框，并减小漏检的概率</span></span></p> 
<p style="margin-left:0;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#333333;">​</span></span>              <span style="background-color:#ffffff;"><span style="color:#333333;">（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）<strong>运动预测：</strong>高帧率下更适合</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">KF</span></span></p> 
<p style="margin-left:0;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#333333;">​</span></span>              <span style="background-color:#ffffff;"><span style="color:#333333;">（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">3</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）<strong>关联匹配模块：</strong>相对于传统基于</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">IOU</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">或距离的关联方式，作者采用了</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">GIOU</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">的关联方式，依然使用匈牙利算法</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">or</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">贪婪算法来匹配轨迹和检测结果</span></span></p> 
<p style="margin-left:0;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#333333;">​</span></span>              <span style="background-color:#ffffff;"><span style="color:#333333;">（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">4</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）<strong>轨迹管理模块：</strong>提出</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">两阶段关联</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">，与</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">ByteTrack</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">类似。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">总结：</span></span></strong><strong> </strong><span style="background-color:#ffffff;"><span style="color:#333333;">属于是对</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">标准TBD范式</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">进行优化的一篇文章</span></span></p> 
<h4 style="background-color:transparent;margin-left:0px;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#333333;">（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">10</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2022</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">年</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Arxiv</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">《</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">SMILEtrack: SiMIlarity LEarning for Multiple Object Tracking</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">》</span></span></h4> 
<p style="margin-left:0;text-align:justify;"><img alt="" height="306" src="https://images2.imgbox.com/a2/17/koQdgVgc_o.png" width="1030"></p> 
<p style="margin-left:0;text-align:justify;"><img alt="" height="192" src="https://images2.imgbox.com/c2/11/s94Dbobz_o.png" width="364"><img alt="" height="237" src="https://images2.imgbox.com/fc/bb/HJU1LNpC_o.png" width="307"></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">创新点：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">提出了</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">基于</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">Siamese</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">网络的</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">SLM</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Similarity Learning Module</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）来用进行外观相似度学习，其中包含了一个使用</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">Attention</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">的</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">图像切片注意力模块</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">ISA</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Image Slicing Attention Block</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）用来提取具有判别性的</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">appearance feature</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">。最后设计</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">二级匹配策略</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">SMC</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">进行关联匹配。（作者说设计了一个</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Gate</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">函数，我没找到）</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">为什么：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">因为</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">JDT</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">的精度达不到要求</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">，</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">JDE</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">又存在检测</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">re-id</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">任务冲突的问题</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">，</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">SDE</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">中的经典跟踪器</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">ByteTrack</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">只用</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">IOU</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">匹配也能</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">work</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">的原因作者认为是数据集的运动场景比较简单。因此作者的目的就是为</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">ByteTrack</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">加上高性能</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">re-id</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">模块。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">怎么做：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#000000;">1</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">、首先通过</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">PRB</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">进行</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">detection</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">，得到</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">box</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">，根据置信度大小分为</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">高分</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">Box</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">和低分</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">Box</span></span></strong><span style="background-color:#ffffff;"><span style="color:#000000;">；</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">2</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">、在第一次关联中，</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">高分</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">box</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">和轨迹预测</span></span></strong><span style="background-color:#ffffff;"><span style="color:#000000;">通过</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">SLM</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">提取外观特征并计算外观相似度，通过一个</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">Gate</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">函数联合</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">IOU</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">和</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">appearance</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">构建</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">cost matrix</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">，并用匈牙利算法进行全局匹配；</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">3</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">、在第二次关联中，计算</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">低分</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">box</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">与未匹配上轨迹预测</span></span></strong><span style="background-color:#ffffff;"><span style="color:#000000;">的</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">feature bank</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">的最大外观相似度（文中称之为</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">Multi-Template-SLM</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">），并用</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">Gate</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">函数计算</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">costmatrix</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">（同第一次关联），并用匈牙利算法进行全局匹配。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">总结：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">在</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">MOT17</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">上达到了</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">SOTA</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">的要求，简单来说，就是在</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">ByteTrack</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">基础上设计了一个</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">re-id</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">模块；</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">SLM</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">其实也没有特别多的东西，就是一个</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Attention</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">模块提取</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">appearance feature</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">，然后加了个</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">fc</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">层，最后算一下余弦距离。由于是初稿，整个工作的工作量、公式完整性（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Gate</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）以及论文细节都不是很饱满。（猜测</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">sota</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">的原因也是选了一个很好的</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">baseline</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">加上自己网络对</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">MOT17</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">的进行充分训练。）</span></span></p> 
<h4 style="margin-left:0px;text-align:justify;"><span style="background-color:#FFFFFF;"><span style="color:#333333;">（</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">11</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">）</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">2022</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">年</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">Arxiv</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">《</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">MAT: Motion-Aware Multi-Object Tracking</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">》</span></span></h4> 
<p style="margin-left:0;text-align:justify;"><img alt="" height="509" src="https://images2.imgbox.com/f5/b6/Q3Ev43Gi_o.png" width="1200"></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#FFFF00;"><span style="color:#333333;">创新点：</span></span></strong><span style="background-color:#FFFFFF;"><span style="color:#333333;">针对相机运动和目标非刚性运动问题</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">, </span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">提出了一个</span></span><strong><span style="background-color:#FFFFFF;"><span style="color:#FF0000;">集成运动定位</span></span></strong><strong><span style="background-color:#FFFFFF;"><span style="color:#FF0000;">(Integrated motion localization, IML)</span></span></strong><strong><span style="background-color:#FFFFFF;"><span style="color:#FF0000;">模块</span></span></strong><span style="background-color:#FFFFFF;"><span style="color:#333333;">；针对长期遮挡后目标重连接问题</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">, </span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">提出了</span></span><strong><span style="background-color:#FFFFFF;"><span style="color:#FF0000;">动态重连接上下文模块</span></span></strong><strong><span style="background-color:#FFFFFF;"><span style="color:#FF0000;">(Dynamic reconnection context, DRC)</span></span></strong><span style="background-color:#FFFFFF;"><span style="color:#333333;">；对于关联阶段</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">, </span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">利用</span></span><strong><span style="background-color:#FFFFFF;"><span style="color:#FF0000;">3D integral image(3DII)</span></span></strong><strong><span style="background-color:#FFFFFF;"><span style="color:#FF0000;">模块</span></span></strong><span style="background-color:#FFFFFF;"><span style="color:#333333;">来去除冗余的轨迹和检测的关联。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#FFFF00;"><span style="color:#333333;">为什么：</span></span></strong><span style="background-color:#FFFFFF;"><span style="color:#333333;">作者认为在相机运动、遮挡等情况很难对一些目标进行准确的长期关联，同时</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">Re-id</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">虽然能恢复身份，但是无法恢复遮挡期间的跟踪轨迹；传统的全局关联在目标多的情况下，很多都是无效关联，浪费时间成本。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#FFFF00;"><span style="color:#333333;">怎么做：</span></span></strong></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#FFFFFF;"><span style="color:#FF0000;">IML</span></span></strong><strong><span style="background-color:#FFFFFF;"><span style="color:#FF0000;">：</span></span></strong><span style="background-color:#FFFFFF;"><span style="color:#333333;">在</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">KF</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">预测步后，利用基于仿射变换的</span></span><strong><span style="background-color:#FFFFFF;"><span style="color:#FF0000;">最大化增强相关系数（</span></span></strong><strong><span style="background-color:#FFFFFF;"><span style="color:#FF0000;">ECC</span></span></strong><span style="background-color:#FFFFFF;"><span style="color:#333333;">,08</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">年的方法）来矫正相机位姿，并将矫正后的预测框位置进行</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">KF</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">更新；</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#FFFFFF;"><span style="color:#FF0000;">DRC</span></span></strong><strong><span style="background-color:#FFFFFF;"><span style="color:#FF0000;">：</span></span></strong><span style="background-color:#FFFFFF;"><span style="color:#333333;">分为两部分：</span></span></p> 
<p style="margin-left:0;text-align:justify;"><span style="background-color:#FFFFFF;"><span style="color:#333333;">（</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">1</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">）、</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">Dynamic Motion-Based Reconnection Mechanism:</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">利用相机和行人的</span></span><strong><span style="background-color:#FFFFFF;"><span style="color:#FF0000;">运动剧烈程度</span></span></strong><span style="background-color:#FFFFFF;"><span style="color:#333333;">来自适应调整丢失目标的最大保留时间；</span></span></p> 
<p style="margin-left:0;text-align:justify;"><span style="background-color:#FFFFFF;"><span style="color:#333333;">（</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">2</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">）、</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">Cyclic Pseudo-Observation Trajectory Filling</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">：</span></span><strong><span style="background-color:#FFFFFF;"><span style="color:#FF0000;">生成伪观测来进行循环更新</span></span></strong><span style="background-color:#FFFFFF;"><span style="color:#333333;">，并对遮挡期间的丢失轨迹进行填充；</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#FFFFFF;"><span style="color:#FF0000;">3DII</span></span></strong><strong><span style="background-color:#FFFFFF;"><span style="color:#FF0000;">：</span></span></strong><span style="background-color:#FFFFFF;"><span style="color:#333333;">对观测位置进行编码映射，用于</span></span><strong><span style="background-color:#FFFFFF;"><span style="color:#FF0000;">限定局部区域进行关联</span></span></strong><span style="background-color:#FFFFFF;"><span style="color:#333333;">，避免了全局关联，减少了冗余计算。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#FFFF00;"><span style="color:#333333;">总结：</span></span></strong><span style="background-color:#FFFFFF;"><span style="color:#333333;">基于运动模型，对运动补偿、长时遮挡以及加速关联三个方面进行优化改进，想法比较新颖，在</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">MOT16</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">数据集上达到了</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">SOTA</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">，文章中提到的动态调整最大存活时间在消融实验中证明有效，但是很难究其原因，是否可以在这个上面进行优化改进？循环伪观测轨迹填充没表述清楚，没开源，很多细节无从得知，整体算法模块比较复杂。</span></span></p> 
<h4 style="margin-left:0px;text-align:justify;"><span style="background-color:#FFFFFF;"><span style="color:#333333;">（</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">12</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">）</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">2023</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">年</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;"> Arxiv</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">《</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">Hybrid-SORT: Weak Cues Matter for Online Multi-Object Tracking</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">》</span></span></h4> 
<p style="margin-left:0;text-align:justify;"><img alt="" height="444" src="https://images2.imgbox.com/8b/b5/yfv3lSYw_o.png" width="1032"></p> 
<p style="margin-left:0;text-align:justify;"><a name="_Hlk142326835"><strong><span style="background-color:#FFFF00;"><span style="color:#333333;">创新点：</span></span></strong></a><strong> </strong><span style="background-color:#FFFFFF;"><span style="color:#333333;">可以通过</span></span><strong><span style="background-color:#FFFFFF;"><span style="color:#FF0000;">结合弱线索</span></span></strong><span style="background-color:#FFFFFF;"><span style="color:#333333;">来补偿强线索来有效解决遮挡问题。随着</span></span><strong><span style="background-color:#FFFFFF;"><span style="color:#FF0000;">速度方向</span></span></strong><span style="background-color:#FFFFFF;"><span style="color:#333333;">的变化，引入了</span></span><strong><span style="background-color:#FFFFFF;"><span style="color:#FF0000;">置信状态</span></span></strong><span style="background-color:#FFFFFF;"><span style="color:#333333;">和</span></span><strong><span style="background-color:#FFFFFF;"><span style="color:#FF0000;">高度状态</span></span></strong><span style="background-color:#FFFFFF;"><span style="color:#333333;">作为潜在的弱信号。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#FFFF00;"><span style="color:#333333;">为什么：</span></span></strong> <span style="background-color:#FFFFFF;"><span style="color:#333333;">物体在遮挡或拥挤场景下，由于物体之间的高度重叠，空间和外观信息同时变得模糊，强线索（</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">IOU/REID</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">）无法有效区分不同的</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">ID</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">。置信状态可以明确地指示聚类对象之间的遮挡</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">/</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">被遮挡关系，高度状态是物体的一种稳定属性，通常对不同的物体姿态具有鲁棒性（并且反应深度信息）。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#FFFF00;"><span style="color:#333333;">怎么做：</span></span></strong><strong><span style="background-color:#FFFFFF;"><span style="color:#FF0000;">Tracklet Confidence Modeling (TCM)</span></span></strong><strong><span style="background-color:#FFFFFF;"><span style="color:#FF0000;">：</span></span></strong><span style="background-color:#FFFFFF;"><span style="color:#333333;">Byte</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">一阶段将置信度和置信度速度变化引入</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">KF</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">状态向量，用</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">KF</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">更新</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">confidence</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">；</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">Byte</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">二阶段使用线性预测轨迹</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">confidence</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">；在计算</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">cost matrix</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">的时候也会同时计算一个有关</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">confidence</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">的</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">cost</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#FFFFFF;"><span style="color:#FF0000;">Height Modulated IoU</span></span></strong><strong><span style="background-color:#FFFFFF;"><span style="color:#FF0000;">（</span></span></strong><strong><span style="background-color:#FFFFFF;"><span style="color:#FF0000;">HMIOU</span></span></strong><strong><span style="background-color:#FFFFFF;"><span style="color:#FF0000;">）：</span></span></strong><span style="background-color:#FFFFFF;"><span style="color:#333333;">IOU</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">和</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">HIOU</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">相乘结果</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#FFFFFF;"><span style="color:#FF0000;">Robust OCM</span></span></strong><strong><span style="background-color:#FFFFFF;"><span style="color:#FF0000;">：</span></span></strong><span style="background-color:#FFFFFF;"><span style="color:#333333;">OCM</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">使用固定的三帧时间间隔来计算速度方向；作者则对时间窗口使用了</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">1</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">到</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">3</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">帧的叠加，使之更有鲁棒性；使用四个角的速度方向来代替中心点的速度方向</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#FFFF00;"><span style="color:#333333;">总结：</span></span></strong> <span style="background-color:#FFFFFF;"><span style="color:#333333;">基于</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">OC-SORT+ByteTrack</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">对关联部分进行改进，在</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">cost matrix</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">中引入了置信度、高度、速度方向各自的</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">cost</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">。</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">主要是针对</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">DanceTrack</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">这个数据集，并且在</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">baseline</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">上得到了很大的提升，同时这些针对于高度非线性和遮挡情况的改进，在</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">MOT</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">数据集上也能达到</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">SOTA</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">（因为就是基于</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">SOTA</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">去改的，提升不大，不过没有出现负优化）。文章对各个改进部分都对</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;"> how&amp; why</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">做了详细的解释说明，是一项比较有价值的工作。</span></span></p> 
<h4 style="margin-left:0px;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#333333;">TBD</span></span><strong><span style="background-color:#ffffff;"><span style="color:#333333;">总结：</span></span></strong></h4> 
<p style="margin-left:0;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#333333;">        two-stage最大缺点就是</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">速度慢</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">，因为将物体检测和轨迹关联分开，而物体检测阶段，生成检测框和</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">re-ID</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">特征提取又分开，导致</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">整体</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">MOT</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">的时间</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">=</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">检测框生成时间</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">+</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">提取</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">re-ID</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">特征时间</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">+</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">轨迹匹配时间</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">，检测速度自然就下去了。</span></span></p> 
<p style="margin-left:0;text-align:justify;">        其次，re-id的提出让<span style="background-color:#ffffff;"><span style="color:#333333;">大家都有这样一个共识，也就是说</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">MOT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">是主要依靠</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">detection</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">和</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">re-ID信息，大多数论文的</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">performance</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">提升其实主要靠</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">detection</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">和</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">re-id</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">的提升，而</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">motion</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">信</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">息只是作为一个辅助。但实际上，motion信息对遮挡或者说检测器漏检导致的轨迹碎片化，断裂消失等情况往往有很大“弥补”作用，毕竟预测的轨迹是连续且渐进的。</span></span></p> 
<h3 style="margin-left:0px;text-align:justify;"></h3> 
<h3 style="margin-left:0px;text-align:justify;"></h3> 
<h3 style="margin-left:0px;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#333333;">2</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">、多目标跟踪</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">JDE</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Jointly learns the Detector and Embedding model</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span></h3> 
<h4><span style="background-color:#ffffff;"><span style="color:#333333;">（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">1</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span><span style="background-color:#ffffff;"><span style="color:#333333;"> 2020</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">年</span></span><span style="background-color:#ffffff;"><span style="color:#333333;"> ECCV </span></span><span style="background-color:#ffffff;"><span style="color:#333333;">《</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Towards Real-Time Multi-Object Tracking</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">》（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">JDE</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span></h4> 
<p class="img-center"><img alt="" height="179" src="https://images2.imgbox.com/87/24/WsoritPt_o.png" width="865"></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">创新点：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">创新性地将</span><strong><span style="color:#fe2c24;">目标检测环节和</span></strong></span><strong><span style="color:#fe2c24;"><span style="background-color:#ffffff;">re-id</span></span></strong><span style="background-color:#ffffff;"><strong><span style="color:#fe2c24;">提取环节</span></strong><span style="color:#333333;">两部分融合设计为一个网络</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">为什么：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">基于</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">TBD</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">的</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">MOT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">算法将目标检测和特征提取分开，速度太慢，不适合在线跟踪</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">怎么做：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">在检测器的输出（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">head</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">），</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">多输出一个分支</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">用来学习物体的</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">embedding</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">总结：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">JDE</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">只是同时输出了检测框和</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">embedding</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">信息，后面还是要进行目标与轨迹关联。因此还是分为检测和匹配双阶段。</span></span></p> 
<p style="margin-left:0;text-align:justify;"></p> 
<h4 style="margin-left:0px;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#333333;">（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2020</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">年</span></span><span style="background-color:#ffffff;"><span style="color:#333333;"> IJCV </span></span><span style="background-color:#ffffff;"><span style="color:#333333;">《</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">A Simple Baseline for Multi-Object Tracking</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">》（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">FairMOT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span></h4> 
<p class="img-center"><img alt="" height="382" src="https://images2.imgbox.com/09/61/rxMqNeZV_o.png" width="865"></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">创新点：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">将</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">JDE</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">应用在</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">anchor-free</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">的检测器下，并采用多层要素聚合的方式融合低维特征</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">为什么</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#333333;">J</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">DE</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">是</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">基于</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">anchor</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">提取</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">re-id</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">特征容易导致</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">ambiguities for the network</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">，并且</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">anchor</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">中心和物体中心有偏差，从而导致精度太低</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">怎么做：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">采用了基于</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">anchor-free</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">的框架，用</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">关键点</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">估计目标中心（如</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">centernet</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）并提取</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">re-id</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">的</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">低维特征</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">（高维容易导致过拟合），并采用</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">多层要素聚合</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">的方式融合特征（浅层特征包含细节特征，深层特征包含语义特征）</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">总结：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">优化</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">JDE</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">范式，性能指标很好，但是针对</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">MOT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">的一些难题比如遮挡、模糊、运动突变等问题依然没有很好的解决办法</span></span></p> 
<h4 style="margin-left:0px;text-align:justify;"><span style="background-color:#FFFFFF;"><span style="color:#333333;">（</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">3</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">）</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">2021</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">年</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">CVPR</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">《</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">Multiple Object Tracking with Correlation Learning</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">》</span></span></h4> 
<p style="margin-left:0;text-align:justify;"><img alt="" height="367" src="https://images2.imgbox.com/6d/59/fVnGuEKq_o.png" width="1157"></p> 
<p style="margin-left:0;text-align:justify;"><img alt="" height="514" src="https://images2.imgbox.com/1f/08/x5QUxAMr_o.png" width="839">  <img alt="" height="444" src="https://images2.imgbox.com/d0/0b/0bwHCBL8_o.png" width="816"></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#FFFF00;"><span style="color:#333333;">创新点：</span></span></strong><strong> </strong><span style="background-color:#FFFFFF;"><span style="color:#4d4d4d;">提出了</span></span><span style="background-color:#FFFFFF;"><span style="color:#4d4d4d;">CorrTracker</span></span><span style="background-color:#FFFFFF;"><span style="color:#4d4d4d;">，利用</span></span><strong><span style="background-color:#FFFFFF;"><span style="color:#FF0000;">时空相关性</span></span></strong><span style="background-color:#FFFFFF;"><span style="color:#4d4d4d;">对目标及其周围环境之间的关系进行建模；采用</span></span><strong><span style="background-color:#FFFFFF;"><span style="color:#FF0000;">自监督学习</span></span></strong><span style="background-color:#FFFFFF;"><span style="color:#4d4d4d;">的方法来</span></span><strong><span style="background-color:#FFFFFF;"><span style="color:#FF0000;">训练局部相关性模块</span></span></strong><span style="background-color:#FFFFFF;"><span style="color:#4d4d4d;">，使得模型对相似物体的判别能力更强；拓展空间局部相关性模块到时间维度，</span></span><strong><span style="background-color:#FFFFFF;"><span style="color:#FF0000;">提取时序信息</span></span></strong><span style="background-color:#FFFFFF;"><span style="color:#4d4d4d;">。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#FFFF00;"><span style="color:#333333;">为什么：</span></span></strong> <span style="background-color:#FFFFFF;"><span style="color:#333333;">仅仅使用目标外观</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">re-id</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">特征来匹配是不够的，因为外观信息很容易相似或受到噪声干扰，同时</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">CNN</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">有个天然的特性，就是感受野是局部的，无法捕捉长程的时空信息。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#FFFF00;"><span style="color:#333333;">怎么做：</span></span></strong> <strong><span style="background-color:#FFFFFF;"><span style="color:#FF0000;">(1)</span></span></strong><span style="background-color:#FFFFFF;"><span style="color:#333333;">feature map</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">提取；</span></span><strong><span style="background-color:#FFFFFF;"><span style="color:#FF0000;">(2)</span></span></strong><span style="background-color:#FFFFFF;"><span style="color:#333333;">根据相关性在局部时空信息中进行</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">embedding</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">特征提取；</span></span><strong><span style="background-color:#FFFFFF;"><span style="color:#FF0000;">(3)</span></span></strong><span style="background-color:#FFFFFF;"><span style="color:#333333;">将检测结果关联到最接近的轨迹上。其中阶段</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">(1)</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">和阶段</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">(2)</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">是可微的，并组成了一个端到端的可训练结构。关联方面，作者用了通用的匹配策略（如同</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">DeepSORT</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">）</span></span></p> 
<p style="margin-left:0;text-align:justify;"><span style="background-color:#FFFFFF;"><span style="color:#333333;">因此，</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">CorrTracker</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">的</span></span><strong><span style="background-color:#FFFFFF;"><span style="color:#FF0000;">主要贡献</span></span></strong><span style="background-color:#FFFFFF;"><span style="color:#333333;">是对特征图上的密集位置和其上下文之间的相关性进行高效建模，这有助于抑制复杂场景中的干扰因素。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#FFFF00;"><span style="color:#333333;">总结：</span></span></strong> <span style="background-color:#FFFFFF;"><span style="color:#333333;">作者设计了一个</span></span><strong><span style="background-color:#FFFFFF;"><span style="color:#FF0000;">相关性网络来学习目标与周围环境之间的信息</span></span></strong><span style="background-color:#FFFFFF;"><span style="color:#333333;">，并提出了</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">correlation volume</span></span><span style="background-color:#FFFFFF;"><span style="color:#333333;">来限制在每一个特征金字塔级别中的搜索范围，维护了实时性。这种相关性学习</span></span><strong><span style="background-color:#FFFFFF;"><span style="color:#FF0000;">关注的不仅只是目标之间的信息，背景信息也会被捕获来加强模型对目标的识别和判别能力</span></span></strong><span style="background-color:#FFFFFF;"><span style="color:#333333;">。同时作者</span></span><strong><span style="background-color:#FFFFFF;"><span style="color:#FF0000;">将相关性的计算扩展到时间维度</span></span></strong><span style="background-color:#FFFFFF;"><span style="color:#333333;">，更有效地提取了时序信息，使模型在面对遮挡等问题时鲁棒性更好（这处设计没看明白）。</span></span></p> 
<h4 style="background-color:transparent;margin-left:0px;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#333333;">（4</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2023</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">年</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">TCSVT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">《</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Multi-Object Tracking: Decoupling Features to Solve the Contradictory Dilemma of Feature Requirements</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">》</span></span></h4> 
<p><img alt="" height="480" src="https://images2.imgbox.com/36/44/FDlqT0Jb_o.png" width="865"></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">创新点：</span></span></strong><strong> </strong><span style="background-color:#ffffff;"><span style="color:#333333;">本文设计了一个特征解耦模块，相互抑制解耦(DMI)和自约束模块（SCM）有效地</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">解耦共同特征和个体特征</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">，分别用于检测和ID嵌入。提出一个简单的</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">三阶段数据关联</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">为什么：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">检测需要具有较强表达能力的公共特征，re-id则需要具有高分辨率能力的个体特征，因此训练阶段检测和re-id对特征的</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">需求冲突</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">将导致特征提取偏离最优结果</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">怎么做：</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;"> 1、</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">FDTrack</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">在骨干网之后增加了</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">特征解耦模块DMI</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">。针对检测与ReID之间的特征矛盾，DMI利用检测与ReID的相互抑制信息权重(即W1和W2)对骨干网中提取的特征进行解耦。</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">2</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">、</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">在Detection Head和ID Embedding之前加入了</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">自约束模块SCM</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">，以弱化去耦引起的特定偏差，稳定检测特征和ReID特征。</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">3</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">、</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">MLA</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">将检测结果分层，并使用</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">三级匹配策略</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">完成数据关联。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">总结：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">三级匹配有一定合理性，选择合适的阈值很重要；对FairMOT改进进一步缓和了Detection和ReID的矛盾。</span></span></p> 
<p></p> 
<h4 style="margin-left:0px;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#333333;">JDE</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">总结：</span></span></h4> 
<p style="margin-left:0px;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#333333;">        实质上任然是双阶段算法，且精度不如TBD，胜在速度</span></span></p> 
<p style="margin-left:0px;text-align:justify;"></p> 
<p style="margin-left:0px;text-align:justify;"></p> 
<h3 style="margin-left:0px;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#333333;">3</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">、目标跟踪</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">JDT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">joint tracking and detection</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span></h3> 
<h4><span style="background-color:#ffffff;"><span style="color:#333333;">（1</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2019</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">年</span></span><span style="background-color:#ffffff;"><span style="color:#333333;"> ICCV</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">《</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Tracking without bells and whistles</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">》（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Trackor++）</span></span></h4> 
<p class="img-center"><img alt="" height="338" src="https://images2.imgbox.com/f1/26/GzQXFrP8_o.png" width="865"></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">创新点：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">提出了</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Tractor</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">，</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">利用一些耦合的检测与判别模块，将</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">track</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">融合进</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">detection</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">；增加了两个</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">extensions</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">，分别是</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">基于</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">Siamese CNN</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">的</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">re-ID</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">网络</span></span></strong><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">，以及</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">基于</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">CMC</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">和</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">CVA</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">（</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">constant velocity assumption</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">）的</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">motion model</span></span></strong><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">来处理遮挡问题和相机抖动、低帧率下目标高速运动的问题</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">为什么</span></span></strong><strong><span style="background-color:#ffff00;"><span style="color:#333333;">：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">TBD</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">速度太慢，且后期</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">id</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">增多时，复杂的关联阶段会产生巨大的计算负担</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">怎么做：</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">蓝色线：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">用来对</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">t-1</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">帧已有的框进行重新回归判定，利用</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Regression</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">模块获取</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">t</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">帧时候的新位置，同时用</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Classification</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">模块对这个新的位置进行判断目标是否仍然存在；</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">红色线：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">用来检测新产生的目标，保留那些与</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">t-1</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">帧没有足够</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">IOU</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">的框，作为新目标参与到下一帧的迭代。</span></span></p> 
<p><strong><span style="background-color:#ffff00;"><span style="color:#333333;">总结：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">利用现有的目标检测方法、孪生</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">re-id</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">方法和相机运动估计法，重新组合而得到一套可以实现端到端输出的新架构，使</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">detection</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">拥有</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">track</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">功能；有</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">classification</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">模块，是个面向特定类群的跟踪器，要先进行离线训练。（当年达到了SOTA，但毕竟是个tracking的问题，做法是否有点作弊了？）</span></span></p> 
<p></p> 
<h4><span style="background-color:#ffffff;"><span style="color:#333333;">（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2020</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">年</span></span><span style="background-color:#ffffff;"><span style="color:#333333;"> ECCV</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">《</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Tracking Objects as Points</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">》（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">CenterTrack</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span></h4> 
<p class="img-center"><img alt="" height="136" src="https://images2.imgbox.com/fb/8c/xx89lv36_o.png" width="865"></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">创新点：</span></span></strong>提出了一个基于点的范式，类似于光流法。它可以将检测和跟踪网络结合一起学习，是<strong><span style="color:#ff0000;">一阶段跟踪算法</span></strong>。</p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">为什么：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">二阶段跟踪算法的关联策略过于复杂和缓慢，导致整个模型推理速度慢。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">怎么做：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">CenterTrack</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">的输入是连续的</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">两帧图像</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">，以及由首帧图像的检测结果高斯渲染出的</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">heatmap</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">，模型会输出一个从当前帧目标中心点到前一帧目标中心的</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">偏移量，</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">heatmap</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">和检测框</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">。同时，在训练中使用了一些激进的</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">数据增强</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">策略，提高训练的准确性，甚至能在静止的单帧图片上预测目标的运动轨迹（通过随机缩放和变换当前图像，来生成先前帧，从而达到模拟目标运动的目的）。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">总结：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">基于</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Centernet</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">的推广，一阶段加上忽略外观信息，</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">推理速度极快</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">；能扩展到三维空间；缺点是速度预测不适用在低帧率的数据上，并且只适合在连续帧之间传递</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">ID</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">，没有考虑如何给时间上有较大间隔的对象重新建立联系的问题（遮挡）。</span></span></p> 
<p style="margin-left:0;text-align:justify;"></p> 
<h3 style="margin-left:0px;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#333333;">4</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">、目标跟踪其他方法</span></span></h3> 
<h4><span style="background-color:#ffffff;"><span style="color:#333333;">（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">1</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2021</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">年</span></span><span style="background-color:#ffffff;"><span style="color:#333333;"> CVPR</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">《</span></span>Probabilistic Tracklet Scoring and Inpainting for Multiple Object Tracking<span style="background-color:#ffffff;"><span style="color:#333333;">》（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">ArTIST</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span></h4> 
<p class="img-center"><img alt="" height="333" src="https://images2.imgbox.com/74/43/TMpFhda3_o.png" width="853"></p> 
<p class="img-center"><img alt="" height="467" src="https://images2.imgbox.com/b6/ef/kmW1iM2L_o.png" width="864"></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">创新点：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">提出一个</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">概率自回归</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">的运动模型，学习并生成运动轨迹的</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">多模态分布</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">，根据轨迹的似然度对其进行评分并联合检测框匹配。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">为什么：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">过分依赖检测器和</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">re-id</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">并长期忽略运动信息导致无法处理长时间的遮挡等问题</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">怎么做：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">通过概率分布，对轨迹运动进行建模，联合当前时刻所求轨迹和同时刻其余轨迹的运动模型（通过</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">MA-Net</span></span></strong> <span style="background-color:#ffffff;"><span style="color:#333333;">重建出一个</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">tracklet motion velocity</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">），通过</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">ArTIST</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">预测出下一时刻轨迹出现概率最大的位置，并和检测器的检测结果进行一个最优匹配，实现对某一轨迹的</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">ID</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">赋予。（</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">Inpainting</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">也是通过这个模型一帧一帧预测，取</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">S</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">个轨迹）</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">总结：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">各大数据集上表现很好；不仅可以为现有的轨迹分配新的检测，而且允许在物体丢失很长时间（例如由于遮挡）时通过采样轨迹来</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Inpainting</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">轨迹，以填补错误检测造成的空白。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#333333;">（检测器会漏检、误检从而导致</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">轨迹消失和碎片化</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">；真实轨迹一定是</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">连续</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">的，运动预测不会产生轨迹中断，因此运动信息对维持一条轨迹十分必要。人脑是识别不同目标的轨迹的？）</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">备注：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">没公开源码，很多细节都是靠猜的。。不是很读得懂</span></span></p> 
<p style="margin-left:0;text-align:justify;"></p> 
<h4 style="margin-left:0px;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#333333;">（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2021</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">年</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">CVPR</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">《</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Multiple People Tracking by Lifted Multicut and Person Re-identificatio》</span></span></h4> 
<p style="margin-left:0;text-align:justify;"><img alt="" height="550" src="https://images2.imgbox.com/15/4f/UxPUje75_o.png" width="847"></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">创新点：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">将</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">multi-persontracking</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">问题看成最小化代价</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">lifted multicut</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">问题。在</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">regular edges</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">的基础上引入</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">lifted edges</span></span></strong><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">；设计并训练融合行人</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">人体姿势信息</span></span></strong><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">的深度神经网络来进行行人重识别。</span></span></p> 
<p style="margin-left:0;text-align:left;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">为什么：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">传统的做法将一条单独的轨迹与观测</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">box</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">进行关联，而任何的轨迹的生成所带来的错误很可能会被传播到最终解，用来解决</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">遮挡问题</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">和</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">基于</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">re-id</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">的跨帧间匹配</span></span></strong></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">怎么做：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">将多人跟踪转换为最小成本提升的多边跟踪问题。为跟踪图引入了两种类型的边（规则边和提升边）。</span></span> <span style="background-color:#ffffff;"><span style="color:#333333;">规则边定义了图中可行解的集合，即哪个节点应该被连接</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">/</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">切割。在不修改可行解集的情况下，</span></span> <span style="background-color:#ffffff;"><span style="color:#333333;">提升的</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">(lifted)</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">边为目标增加了“哪个节点应该被连接</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">/</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">切割”的额外长程信息。新公式对远距信息进行了编码，且通过强制可行解中的有效路径，以统一和严格的方式惩罚了长期的假连接（例如，看起来相似的人）。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">总结：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">不懂</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">multi-cut</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">。。大概就是说通过聚类得到规则边，而</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">lifted edge</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">引入长距离信息，用于加强惩罚</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">cost</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">，</span></span><span style="background-color:#ffffff;"><span style="color:#333333;"> regular edges</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">和</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">lifted edge</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">一起决定哪些节点应该被</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">joint or cut</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">。其次引入一个融合了姿态信息的</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">re-id</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">网络（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">CNNs</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）。</span></span></p> 
<p style="margin-left:0;text-align:justify;"></p> 
<h4 style="margin-left:0px;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#333333;">（3）2015</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">年</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">ICCV</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">《</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Multiple Hypothesis Tracking Revisited</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">》</span></span></h4> 
<p><img alt="" height="385" src="https://images2.imgbox.com/f7/62/qHGBxSd5_o.png" width="780"></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">创新点：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">提出了优化的</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">MHT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">，一种针对每个轨迹假设训练在线外观模型的方法，且该方法能大幅度削减假设分支的数量，在线训练外观模型的运算量与分支数无关，减少了运算量。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">为什么：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">MHT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">在视频跟踪中很少应用，原因是</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">运算量太大</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">。作者认为目前检测器的新进展以及用于对象外观有效特征表示的发展为</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">MHT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">方法创造了新的机会。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">怎么做：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">在每一帧，从观察中更新轨道树，并对树中的每个轨道进行</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">评分</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">（评分规则看论文）。然后可以通过</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">解决最大加权独立集</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">MWIS</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">，没了解过）问题来找到</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">最佳的非冲突轨迹集</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">（最佳全局假设）。然后，从树中</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">修剪</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">出偏离全局假设太多的分支（标准的</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">N</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">扫描修剪方法</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">，并且算法前进到下一帧。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">在线外观训练模型：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">采用</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">多输出正则化最小二乘框架</span></span></strong><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">(multioutput regularized least squares framework, MORLS)</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">来学习场景中目标的外观模型</span></span></p> 
<p><strong><span style="background-color:#ffff00;"><span style="color:#333333;">总结：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">MHT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">的性能取决于</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">能否快速可靠地修剪搜索树中的分支</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">，以保持跟踪假设的数量可管理。本文提出的</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">MHT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">，将每帧中的有效分支数削减到所有分支的约</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">50</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">％，且通过正则化最小二乘框架高效地学习外观模型，该模型的计算成本与假设分支的数量几乎没有依赖性（MHT其实个人不是很了解，有错误欢迎提出）</span></span></p> 
<p></p> 
<h4><span style="background-color:#ffffff;"><span style="color:#333333;">（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">4</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2021</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">年</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">ICRA</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">《</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">DOT: Dynamic Object Tracking for Visual SLAM</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">》</span></span></h4> 
<p><img alt="" height="221" src="https://images2.imgbox.com/0c/10/heIKo2ic_o.png" width="865"></p> 
<p><img alt="" height="172" src="https://images2.imgbox.com/f2/59/hub3fRmx_o.png" width="865"></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">创新点：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">提出了</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">DOT</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">（动态对象跟踪）</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">，结合</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">实例分割和多视图几何学</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">为动态对象生成掩码，使基于刚性场景模型的SLAM系统在优化时避开此类图像区域，提高其在高动态环境中的鲁棒性和准确性。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">为什么：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">通常基于</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">静止环境</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">进行建图和定位，将</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">动态区域作为outliers</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">并将其忽略。通常做法需要通过多帧来进行判断是否为outliers，导致</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">引入误差以及一致性问题</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">；如果将全部潜在动态区域去除也会导致</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">精度较低</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">怎么做：</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">1</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">、实例分割</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">出所有</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">潜在的运动目标</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">；</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">2</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">、</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">image Processing</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">部分提取和分类在静止区域的点和在动态目标上的点，其中</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">相机姿态跟踪仅利用静态区域</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">的信息，依据相机位姿，对每一个潜在动态物体进行单独的估计（object tracking）</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">3</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">、</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">利用几何原则判断</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">物体是否在运动</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">，物体运动与否的信息将用来更新每一帧的动态区域与静态区域的掩码</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">4</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">、</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">依据物体运动估计</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">生成新的掩码</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">（传播），因此不需要每一帧都分割</span></span></p> 
<p><strong><span style="background-color:#ffff00;"><span style="color:#333333;">总结：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">将DOT加入到ORB-SLAM2中发现</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">在静止或者运动的场景，性能都有提升，如果不提出运动目标，那么会造成轨迹的误差，如果将所有目标的掩码区域都抛弃掉，将丢失大量的信息；</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">DOT</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">可以通过掩码的传播校正神经网络的错误分割</span></span></p> 
<p></p> 
<h4 style="margin-left:0px;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#333333;">（5</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2021年</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">CVPR</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">《</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Quasi-Dense Similarity Learning for Multiple Object Tracking</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">》（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Qdtrack</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span></h4> 
<p><img alt="" height="296" src="https://images2.imgbox.com/40/1d/nXMD0Kwz_o.png" width="865"></p> 
<p><img alt="" height="309" src="https://images2.imgbox.com/72/57/ZXWj49QM_o.png" width="865"></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">创新点：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">作者提出了一种</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">基于稠密GT</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">提取re-id特征并用</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">Bi-softmax</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">进行双向匹配的匹配方法，</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">没有使用位置和运动信息</span></span></strong></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">为什么：</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">位置运动匹配</span></span></strong><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">只适合一些简单的场景，当目标拥挤遮挡下，位置信息很</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">容易产生误导</span></span></strong><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">；</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">之前的</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">Re-id</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">匹配</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">只用</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">稀疏gt</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">样本训练提取embedding特征，</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">没有充分利用</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">可能的gt</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">样本多样性</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">（rigion proposal），作者认为如果能有一堆正样本和负样本参与训练优化的话，这样可能会使提取的embedding特征更具备判别性。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">怎么做：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">训练流程图如上，输入两张图片，使用RPN生成ROI，再进行feature extract，</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">联合正样本和负样本进行损失计算</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">；推理阶段将提取到的特征输入到</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">bi-softmax</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">进行双向匹配</span></span></strong></p> 
<ol><li style="text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#333333;">训练reid feature时，多个正样本和多个负样本同时参与计算损失。利用rpn产生的roi，根据roi和gt的iou&gt;0.7就认为是正样本roi,iou&lt;0.5时认为是负样本roi。这样在前后帧的（关键帧和参考帧）图片中，和具有同一个id的gt的正样本之间会计算损失，同时关键帧的正样本和参考帧的负样本之间也会计算损失。</span></span></li></ol> 
<p><strong><span style="background-color:#ffff00;"><span style="color:#333333;">总结：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">纯用外观特征做匹配，效果不错，BDD100k数据集上top 1，方法也比较简单。而且，2D多目标跟踪对自动驾驶领域帮助不大，但是3D多目标跟踪往往基于点云来做，reid特征做匹配在低帧率或者高速运动条件下还是要优于运动位置信息做匹配的。如果可以</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">把2D的外观表示特征优势和3D的位置运动信息结合起来，或许对3D MOT会有更大的帮助</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">。</span></span></p> 
<p></p> 
<h4><span style="background-color:#ffffff;"><span style="color:#333333;">（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">6</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2016</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">年</span></span><span style="background-color:#ffffff;"><span style="color:#333333;"> ICCE</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">《</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Online Multiple Object Tracking with the Hierarchically Adopted GM-PHD Filter using Motion and Appearance</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">》</span></span></h4> 
<p><img alt="" height="291" src="https://images2.imgbox.com/ea/d5/xx1d6lEZ_o.png" width="865"></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">创新点：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">使用了</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">GM-PHD</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">进行数据关联，并提出了</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">双层关联方法</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">用于处理遮挡漏检等情况。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">为什么：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">传统的MOT方法容易出现IDs和fragmented tracklets，</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">GM-PHD</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">对存在噪声干扰的观测具有鲁棒性</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">怎么做：</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">1</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">、GM-PHD：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">初始化、预测、更新、剪枝、状态估计（label传递）；</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">2</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">、数据关联；</span></span></strong></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">3</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">、双层关联：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">（1）low-level：无漏检情况，直接用GM-PHD数据关联；</span></span></p> 
<p style="margin-left:0;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#333333;">（2）mid-level：第一步将存活时间小于阈值的轨迹删除；第二步，将轨迹分为dead和 alive，将dead最后一帧目标和alive第一帧目标根据颜色直方图和位置大小等信息进行关联</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">总结：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">MOT 15</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">表现并不好，将雷达MTT领域的RFS引入visual MOT是一种可尝试的新方法，但还没找到其性能指标不理想的原因（可能是RFS适合处理杂波漏检等情况，但MOT更大的挑战来源于遮挡而非检测器）</span></span></p> 
<p style="margin-left:0;text-align:justify;"></p> 
<h4 style="margin-left:0px;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#333333;">（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">7</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2023</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">年</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Arxiv</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">《</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Track Anything: Segment Anything Meets Videos</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">》</span></span></h4> 
<p><img alt="" height="386" src="https://images2.imgbox.com/08/34/Rz39PMrZ_o.png" width="865"></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">创新点：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">将SAM推广到video，不是每帧单独使用SAM，而是将SAM集成到时间相关性的架构中（XMem）</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">为什么：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">SAM</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">难以对视频进行实时目标分割；Xmem在长视频中需要精确的分割掩码</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">怎么做：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">结合</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">SAM</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">和XMEM</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">；先通过交互的方式初始化SAM（通过点击需要跟踪的目标）；然后，利用XMEM根据时空信息给出下一帧对象的掩码预测；其次，利用SAM给出更精确的掩码描述；在跟踪过程中，用户可以在发现跟踪失败的情况下立即暂停并及时进行更正</span></span></p> 
<p><strong><span style="background-color:#ffff00;"><span style="color:#333333;">总结：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">SAM</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">的应用，相当于是一个Detection</span></span></p> 
<hr> 
<p></p> 
<p></p> 
<p></p> 
<h2 style="margin-left:0px;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#333333;">三、三维</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">MOT</span></span></h2> 
<h3><span style="background-color:#ffffff;"><span style="color:#333333;">1</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">、</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">3D</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">多目标跟踪</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">TBD</span></span></h3> 
<h4 style="margin-left:0px;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#333333;">（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">1</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2020</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">年</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">ECCV</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">《</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">3D Multi-Object Tracking: A Baseline and New Evaluation Metrics</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">》（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">AB3DMOT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span></h4> 
<p><span style="background-color:#ffffff;"><span style="color:#333333;">该论文是</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">3D MOT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">的</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">baseline</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">和</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">TBD</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">范式。将</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">SORT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">算法应用在</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">3D</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">场景下，依然是基于</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">KF</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">滤波和匈牙利匹配的目标跟踪算法，同时状态变量增加了偏航角和三维尺寸。具体不展开了</span></span></p> 
<p></p> 
<h4 style="margin-left:0px;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#333333;">（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2）2021年IROS《Score refinement for confidence-based 3D multi-object tracking》</span></span></h4> 
<p class="img-center"><img alt="" height="342" src="https://images2.imgbox.com/42/54/I4x8sqLO_o.png" width="733"></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">创新点：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">提</span></span>出一种<strong><span style="color:#ff0000;">confidence-based</span></strong>的方法对轨迹和匹配过程进行生命周期管理。并针对于先前基于检测置信度的轨迹得分的不足，提出了一种<strong><span style="color:#ff0000;">新的分数更新函数</span></strong>，使一条轨迹的分数是渐进且连续的。<span style="background-color:#ffffff;"><span style="color:#333333;"> </span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">为什么：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">目前轨迹管理模块是用</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">count-based</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">方法，但难以设置阈值，容易出现提前死亡或漏检误检等情况。同时作者认为仅仅使用单帧的检测结果为轨迹打分是不合理的，一条轨迹的质量变化是渐进和和连续的，应该考虑该轨迹长期的分数情况进行匹配和终止管理。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">怎么做：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">新生轨迹分数为检测目标的得分。</span></span>若轨迹没有与目标匹配上，会根据<strong><span style="color:#ff0000;">衰减因子</span></strong>不断衰减得分，若实现了匹配，会根据<strong><span style="color:#ff0000;">新的分数更新函数</span></strong>更新得分。</p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">总结：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">整体改变较小，将原本二值化的</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">count</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">平滑为了可微的累加。</span></span></p> 
<p style="margin-left:0;text-align:justify;"></p> 
<h4 style="margin-left:0px;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#333333;">（3</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2021</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">年</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">ICRA</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">《</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">EagerMOT: 3D Multi-Object Tracking via Sensor Fusion》</span></span></h4> 
<p class="img-center"><img alt="" height="302" src="https://images2.imgbox.com/95/a5/mtFRPjZY_o.png" width="972"></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">创新点：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">提出了一个简单而有效的</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">多传感器数据关联方法</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">，可以处理并融合不同目标检测算法的结果，可以处理不同模态的数据。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">为什么：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">2D</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">图像上的检测可以看得更远，而且检测更准，但是缺乏距离信息。</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">3D</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">点云有精确的距离测量，但远距离的点较稀疏，经常出现漏检，故考虑融合</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">3D</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">和</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2D</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">检测结果，提高</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">3D</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">目标跟踪对遮挡、远距离目标跟踪的效果。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">怎么做：</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">（</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">1</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">）</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">首先将</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">3D</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">检测器和</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2D</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">检测器的检测结果关联（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">3D_2D</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">、</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2dIt</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">、</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">3dIt)</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">。</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">（</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">2</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">）</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">第一阶段将</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">3D</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">检测结果和轨迹进行匹配，卡尔曼更新</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">（</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">3</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">）</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">没匹配上的轨迹和</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2dIt </span></span><span style="background-color:#ffffff;"><span style="color:#333333;">进行匹配。</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">（</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">4</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">）</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">航迹管理与</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">AB3DMOT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">类似</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">总结：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">效果很好，利用现有的</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2D</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">检测器和</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">3D</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">检测器就行，无需额外训练模型。利用了</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2D</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">检测信息提高了精度，相当于跟踪更稳定（无</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">3D</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">检测匹配时）和加强（同时有</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">3D</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">检测和</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2D</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">检测和跟踪匹配）改善了</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">3D</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">检测失败（距离较远或者遮挡）时的跟踪性能，但是同时也导致</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">IDs</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">比较高（没有相对应的措施）。</span></span></p> 
<p style="margin-left:0;text-align:justify;"></p> 
<h4 style="margin-left:0px;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#333333;">（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">4</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2022</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">年《</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Sensor Fusion Based Weighted Geometric Distance Data Association Method for 3D Multi-object Tracking</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">》（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">WGDMOT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span></h4> 
<h4 style="text-align:center;"><img alt="" height="433" src="https://images2.imgbox.com/f6/3d/Ndx4CSxc_o.png" width="865"></h4> 
<p class="img-center"><img alt="" height="223" src="https://images2.imgbox.com/99/fc/m1v4ihgf_o.png" width="710"></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">创新点：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">设计了一种</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">基于加权几何特征的代价距离</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">进行数据关联，利用不同几何特征之间的关系，提高了数据关联的准确性。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">为什么：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">传感器方面与</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">EagerMOT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">类似，大多数</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">3D MOT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">框架倾向于使用</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">3D</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">框之间的联合交集（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">IoU</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）进行数据关联，但容易出现检测和预测没有重叠的情况影响跟踪效果；同时</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">EagerMOT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">提出的</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">scaled distance</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">考虑了</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">dimensions</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">和坐标具有相同的权重（重要性），但实际上不同跟踪目标的属性不同，因此</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">dimensions</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">和坐标</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">应不能承受同等的权重</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">怎么做：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">大体技术路径与</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">EagerMOT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">相似，</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">EagerMOT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">匹配时使用的是代价距离是</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">scaled distance</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">，而</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">WGDMOT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">使用的是</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">加权几何特征的代价距离</span></span></strong></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">总结：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">检测效果优于</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">baseline(EagerMOT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）。通过调整</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">w1</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">、</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">w2</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">和</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">w3</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">的大小来调整它们的重要性，这导致小目标跟踪的效果显著改善。总体而言该篇论文只是针对如何优化检测和预测的关联问题上做了改进（且改进不大），整体框架与</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">EagerMOT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">差不多。</span></span></p> 
<p><strong><span style="background-color:#ffff00;"><span style="color:#333333;">备注：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">查询不到发表的会议（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">International Conference on Cognitive Systems and Signal Processing Springer, Singapore</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）的水平，有大佬可以给我科普一下吗？</span></span></p> 
<p></p> 
<h4><span style="background-color:#ffffff;"><span style="color:#333333;">（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">5</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2023</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">年《</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">DFR-FastMOT: Detection Failure Resistant Tracker for Fast Multi-Object Tracking Based on Sensor Fusion</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">》（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">DFR-FastMOT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span></h4> 
<p style="text-align:center;"> <img alt="" height="235" src="https://images2.imgbox.com/ab/8f/4AFB0bNe_o.png" width="997"></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">创新点：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">提出一种</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">代数公式</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">融合来自多传感器的数据并进行数据关联</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">提高了计算时间</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">和允许保留遮挡时的</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">长时记忆</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">；在发生遮挡情况下，用</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">box</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">的</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">质心距离</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">衡量</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">cost distance</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">，更好的关联遮挡的目标和轨迹</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">为什么：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">当前的</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">MOT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">方法将目标信息（如目标的轨迹）存储在记忆中，以在遮挡后恢复目标。然而，它们为了节省算力</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">只保留了短期记忆</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">，这对</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">MOT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">的跟踪性能会产生影响。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">怎么做：</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">1</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">、</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">先进行</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">3D</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">检测和</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2D</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">检测的</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">匹配融合</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">，保留一些高置信度的框（由于遮挡或远距离的低质量检测框应该被淘汰？）</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">2</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">、</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">保留的框（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2D</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">、</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">3D</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）根据各自的代价函数与经过</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">KF</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">预测后的轨迹（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2D</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">、</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">3D</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">分别</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">构建一个</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">cost matric</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">3</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">、加权融合</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">两个</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">cost matrix</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">进行匈牙利匹配，完成关联</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">4</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">、</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">更新轨迹（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">3D</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">、</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2D</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">一起更新，分别生成</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2D</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">跟踪图和</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">3D</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">跟踪图）</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">总结：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">前面的工作使用了目标的短期记忆，处理某些遮挡场景，这最终会影响整体跟踪性能。本文通过引入关联和融合步骤的代数公式来解决这个问题。性能指标在</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">baseline</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">基础上提升了很多，</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">idea</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">有启发性，写作水平额，未开源。</span></span></p> 
<p style="margin-left:0;text-align:justify;"></p> 
<h4 style="margin-left:0px;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#333333;">（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">6</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2022 RAL</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">《</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">DeepFusionMOT: A 3D Multi-Object Tracking Framework Based on Camera-LiDAR Fusion With Deep Association</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">》</span></span></h4> 
<p><img alt="" height="288" src="https://images2.imgbox.com/ca/fe/YzkDtUYS_o.png" width="865"></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">创新点：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">提出了一种基于</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">LiDAR-</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">相机融合</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">的</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">四级深度匹配</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">策略，并新增了一种轨迹状态</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">为什么：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">单传感器有局限性，优化目前的Fusion匹配策略</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">怎么做：</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">（1）</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">将LiDAR和相机共同检测到的目标优先匹配3D轨迹</span></span></p> 
<p style="margin-left:0;text-align:justify;">    <strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">（2）</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">将只有3D检测的目标与剩下未匹配的3D轨迹进行匹配（前提连续匹配到三帧，单传感器出现误检概率大）</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">    （3）</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">将只有2D检测的目标跟2D轨迹进行匹配</span></span></p> 
<p style="margin-left:0;text-align:justify;">    <strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">（4）</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">将第二步骤中的未匹配轨迹（未匹配或待匹配三帧）的3D投影到2D平面，通过box的IOU进行关联融合（并将2D的id、帧数、轨迹替换到3D）</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">总结：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">reappearance</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">的设置没有理解，是否可以理解为如何判定一个被遮挡目标是否死亡？引入了一个深度匹配策略，HOTA达到SOTA，速度也不慢（感觉因为四级匹配拉慢了速度）整体思想就是通过融合相机和雷达将范围内的目标做到应检尽检，</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">如何优化关联阶段让尽可能多的目标参与匹配</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">是一个值得思考的问题。</span></span></p> 
<p style="margin-left:0;text-align:justify;"></p> 
<h4 style="margin-left:0px;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#333333;">（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">7</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2023 </span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Arxiv</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">《</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">3D Multi-Object Tracking Based on Uncertainty-Guided Data Association</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">》</span></span></h4> 
<p></p> 
<p><img alt="" height="351" src="https://images2.imgbox.com/66/91/vCqfTeN8_o.png" width="865"></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">创新点：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">提出了UG3DMOT，该方法在数据关联阶段摒弃了常用的确定性轨迹和确定性检测，而是将轨迹和检测建模为</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">随机向量进行数据关联</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">。这些随机向量的分量是单独的</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">高斯随机变量</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">，代表不同的轨迹和检测随机性</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">为什么：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">大多数基于TBD的MOT方法，在数据关联阶段采用确定性跟踪和检测进行相似度计算，即</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">忽略</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">了轨道和探测中存在的</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">固有不确定性</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">，在复杂环境下（遮挡、漏检）轨迹的不确定性变得相当大，传统关联方法在一定程度上降低了相似度计算的有效性和可靠性。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">怎么做：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">将检测和轨迹建模为</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">单独的高斯随机变量</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">，使用</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">JS</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">散度结合航向惩罚项</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">来测量轨迹和检测之间的相似性，并将</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">跟踪不确定性引入成本函数</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">以消除“多重关联问题”（匹配范围越大，距离惩罚越大）。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">JS</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">散度</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">：用于评估两个分布之间的相似程度；</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">惩罚项</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">：轨迹和检测的方向不相似度</span></span></p> 
<p><strong><span style="background-color:#ffff00;"><span style="color:#333333;">总结：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">将检测和轨迹预测扩展为单个的高斯分量进行数据关联，以此来处理弱小目标、遮挡目标等情况的发生，相当于</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">扩大了匹配范围</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">，效果达到SOTA。Detection的协方差要如何计算？</span></span> </p> 
<h4 style="margin-left:0px;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#333333;">（8</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2023</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">年</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Arxiv</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">《</span></span>ByteTrackV2: 2D and 3D Multi-Object Tracking by Associating Every Detection Box<span style="background-color:#ffffff;"><span style="color:#333333;">》（</span></span>ByteTrackV2<span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span></h4> 
<p style="margin-left:0;text-align:justify;"><img alt="" height="652" src="https://images2.imgbox.com/cc/62/DvNpWaxJ_o.png" width="969"></p> 
<p style="margin-left:0;text-align:justify;"><img alt="" height="417" src="https://images2.imgbox.com/c9/58/p6jJyVv1_o.png" width="768"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">创新点：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">将二维的</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">ByteTrack</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">衍生到三维场景，并且融合了速度预测和卡尔曼滤波状态预测提出了</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">互补运动预测策略</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">以实现更准确的帧间关联。</span></span><strong>       </strong></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">为什么：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">目前大部分的做法是关联高置信度的检测框，导致一些由</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">遮挡</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">或模糊等原因产生的弱小目标被过滤掉，导致</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">轨迹消失或碎片化</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">。但直接把低分检测框当高分来用也会引入额外的</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">False Positive</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">。同时作者认为，速度预测模型可以提高短期运动的鲁棒性，而卡尔曼滤波则提供了平滑的长期运动预测。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">怎么做：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">在第一阶段，高置信度的目标先和轨迹进行关联；在第二阶段，将没有匹配上的轨迹和低置信度的弱小目标进行关联；</span></span></p> 
<p style="margin-left:0;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#333333;">在匹配上面，利用检测到的速度进行</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">反向预测</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">，实现短期关联；利用卡尔曼滤波进行</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">前向预测</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">，平滑的延续轨迹状态，实现在遮挡后的长期关联。成功匹配后将检测和</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">KF</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">预测进行状态更新融合</span></span></p> 
<p style="margin-left:0px;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">总结：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">在</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">ByteTrack</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">框架下提出了新的互补运动预测策略，相当于结合了</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">JDT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">和</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">TBD</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">的主流运动模型，应对在三维场景下容易速度突变或者帧率较低的情况，同时利用</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">KF</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">预测可以应对短时遮挡的情况。思路很新颖，并且可以对接不同模态的输入，在</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">nuScenes</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">上达到了</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">SOTA</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">成绩。</span></span></p> 
<p></p> 
<h3 style="margin-left:0px;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#333333;">2</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">、</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">3D</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">多目标跟踪</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">JDT</span></span></h3> 
<h4><span style="background-color:#ffffff;"><span style="color:#333333;">（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">1</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2021</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">年</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">ICCV </span></span><span style="background-color:#ffffff;"><span style="color:#333333;">《</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Exploring Simple 3D Multi-Object Tracking for Autonomous Driving</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">》（</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">SimTrack</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span></h4> 
<p class="img-center"><img alt="" height="353" src="https://images2.imgbox.com/7c/fd/NIXtP5ZH_o.png" width="926"></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">创新点：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">提出一种</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">新的混合时间中心点映射</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">，直接将检测和轨迹关联起来，并提供一个置信度，取消了传统匹配阶段，能通过阈值将</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">ID</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">传递、新生创建和轨迹删除集成于一体。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">为什么：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">TBD</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">范式需要</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">人工设计</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">匹配规则和调试相关参数，超参数的设置依赖于大量实验和先验经验，费时费力，并且针对特定场景需要重新调参，</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">泛化能力差</span></span></strong></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">怎么做：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">输入两帧点云数据通过一个</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">backbone</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">，输出三个分支：</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">（</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">1</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">）</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">Hybrid-Time Centerness Map</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">用于记录目标在输入帧中最早出现的位置（若</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">t-1</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">帧出现，</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">t</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">帧消失则视为负样本），并赋予置信度，</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">t-1</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">帧轨迹通过</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Ego-Motion</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">与</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Centerness Map</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">融合，通过预先设置的阈值，实现轨迹管理一体化；</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">（</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">2</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">）</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">Motion</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">用于预测</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">t-1</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">帧到</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">t</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">帧目标的运动，并更新融合后</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Centerness Map Zt-1</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">中目标的位置</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Zt</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">；</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">（</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">3</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">）</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">Regression </span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">用于回归三维尺寸</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">总结：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">将</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">MOT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">模型实现端到端的训练以及用数据驱动的方式将目标关联，新生目标创建和消失轨迹删除集成于一体，可以提高模型的推理速度并降低模型的训练成本，还有全局信息的引入可以处理遮挡等问题。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">Question</span></span></strong><strong><span style="background-color:#ffff00;"><span style="color:#333333;">：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">ego-motion</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">后将</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">t-1</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">帧目标转换到当前坐标系下与</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Yt</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">融合，由于</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">ego-motion</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">有误差，会不会出现两个不同的目标位于同一位置，直接读取</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">id</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">的方法导致两个不同的目标共享同一个</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">id</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">？</span></span></p> 
<h4 style="margin-left:0px;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#333333;">（2</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2023</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">年</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Arxiv </span></span><span style="background-color:#ffffff;"><span style="color:#333333;">《</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">You Only Need Two Detectors to Achieve Multi-Modal 3D</span></span></h4> 
<h4 style="margin-left:0px;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#333333;">Multi-Object Tracking</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">》</span></span></h4> 
<p><img alt="" height="388" src="https://images2.imgbox.com/e4/6a/xRiFnjTk_o.png" width="865"></p> 
<p></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">创新点：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">提出了基于</span></span><strong><span style="background-color:#ffffff;"><span style="color:#333333;">JDT</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">的多传感器融合</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">MOT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">，</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">通过网络回归出轨迹位置以及置信度</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">，设计了</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">置信度融合模块</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">，分析了当前框架下轨迹的可能状态</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">(</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">弱目标或强目标</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">)</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">，用来</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">对轨迹进行</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">NMS</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">和有序关联检测</span></span></strong></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">为什么：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">作者认为单模态的</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">MOT</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">信息不充分，目前的多模态方法无法有效整合</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">3D</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">和</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2D</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">信息，同时基于</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">TBD</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">需要设计复杂的数据关联模式（其实就是想将</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Trackor</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">用在</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">3D</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">上）</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">怎么做：</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">3D:</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">作者使用</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">two-stage</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">网络</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">用来生成轨迹位置和</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">confidence</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">，其中将上一帧的轨迹通过</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">KF</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">和</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">CMC</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">生成</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">Proposal Rigion</span></span></strong> <span style="background-color:#ffffff;"><span style="color:#333333;">用于产生当前帧的检测结果；</span></span></p> 
<p style="margin-left:0;text-align:justify;">              <strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">2D:</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">将上一帧的</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">3D</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">轨迹投影到</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2D</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">平面上生成</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Proposal Rigion</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">，用来产生当前帧</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2D</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">的轨迹位置和置信度；</span></span></p> 
<p style="margin-left:0;text-align:justify;">              <strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">置信度融合：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">融合</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2D</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">、</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">3D</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">和轨迹历史置信度（原文中用的是平均，每一个传感器每一帧的置信度权重都一样）；</span></span></p> 
<p style="margin-left:0;text-align:justify;">              <span style="background-color:#ffffff;"><span style="color:#333333;">根据置信度融合后的结果，将目标分为强目标和弱目标，</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">强目标先优先进行有序关联检测；</span></span></strong></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">总结：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">实验结果还可以，没怎么明白</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">NMS</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">和消融实验当中的</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">Ascending</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">排序的意义；其次对于针对</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">confidence fusion</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">中每一帧每一类传感器的</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">confidence</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">权重一样表示有点不合理。</span></span></p> 
<p style="margin-left:0;text-align:justify;"></p> 
<p style="margin-left:0;text-align:justify;"></p> 
<h3 style="margin-left:0px;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#333333;">3</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">、</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">3D</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">多目标跟踪其他方法</span></span></h3> 
<h4 style="margin-left:0px;text-align:justify;"><a name="_Hlk132013824"><span style="background-color:#ffffff;"><span style="color:#333333;">（</span></span></a><span style="background-color:#ffffff;"><span style="color:#333333;">1</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">）</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">2023</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">年</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">CVPR </span></span><span style="background-color:#ffffff;"><span style="color:#333333;">《</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">GeoMAE: Masked Geometric Target Prediction for Self-supervised Point Cloud Pre-Training</span></span><span style="background-color:#ffffff;"><span style="color:#333333;">》</span></span></h4> 
<p style="margin-left:0;text-align:justify;"><img alt="" height="290" src="https://images2.imgbox.com/e9/08/bAq9ZvGx_o.png" width="1200"></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">创新点：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">提出一种基于</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">几何感知</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">的自监督模型用于</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">点云预训练</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">。用细粒度点统计和曲面属性来实现有效的表示学习</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">为什么：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">基于点云的三维目标检测和跟踪需要大量标注，较难获得。目前与二维图像处理方法类似的基于pretext task的自监督模型无法为下游任务带来足够的改进。原因是忽略了点云与图像的根本区别：</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">点云提供场景几何</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">，而图像提供亮度。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">怎么做：</span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">首先，</span></span></strong><span style="background-color:#ffffff;"><span style="color:#000000;">对原始点云进行体素化，将体素转换为对应的特征token，并按照预定义的比例</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">随机屏蔽（mask）部分特征token</span></span></strong><span style="background-color:#ffffff;"><span style="color:#000000;">，类似于MEA的方式，为这些mask token定义一组可学习的标记，将这些</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">可见token（未mask）送入Transformer进行编码</span></span><span style="background-color:#ffffff;"><span style="color:#000000;">。以编码后的未mask token为标签和mask token一起，通过一个分离的解码器处理可学习 mask token，以</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">预测点统计（质心和占用率），和表面属性（法线和曲率）</span></span></strong></p> 
<p style="margin-left:0;text-align:justify;"><strong><span style="background-color:#ffff00;"><span style="color:#333333;">总结：</span></span></strong><span style="background-color:#ffffff;"><span style="color:#333333;">是一个自监督学习的pretext task模型<strong>，</strong></span></span><span style="background-color:#ffffff;"><span style="color:#000000;">关键是</span></span><strong><span style="background-color:#ffffff;"><span style="color:#ff0000;">几何特征为模型预测对象和场景提供了强大的信息</span></span></strong><span style="background-color:#ffffff;"><span style="color:#000000;">，从而提高了下游识别性能。</span></span></p> 
<p style="margin-left:0;text-align:justify;"><span style="color:#ff0000;">注：</span>在自监督学习中，用于预训练的任务被称为前置/代理任务(pretext task)，用于微调的任务被称为下游任务(downstream task)。</p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/63b5901abc414f36c1216ebaeb3a329a/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【初阶数据结构】树结构与二叉树的基础概念</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/f3b0340396594a6bf0e05e24ec50473b/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">腾讯轻联：带你创造属于自己的AI小助手</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>