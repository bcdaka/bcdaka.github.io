<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>五个优秀的免费 Ollama WebUI 客户端推荐 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/e2f020de462793ef4490c4923b68090b/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="五个优秀的免费 Ollama WebUI 客户端推荐">
  <meta property="og:description" content="认识 Ollama 本地模型框架，并简单了解它的优势和不足，以及推荐了 5 款开源免费的 Ollama WebUI 客户端，以提高使用体验。
什么是 Ollama？ Ollama 是一款强大的本地运行大型语言模型（LLM）的框架，它允许用户在自己的设备上直接运行各种大型语言模型，包括 Llama 2、Mistral、Dolphin Phi 等多种模型，无需依赖网络连接。此外，Ollama 还提供跨平台的支持，包括 macOS、Windows、Linux 以及 Docker， 几乎覆盖了所有主流操作系统。详细信息请访问 [Ollama 官方开源社区]
Ollama 的使用 你可访问 [Ollama 官方网站] 下载 Ollama 运行框架，并利用命令行启动本地模型。以下以运行 llama2 模型为例：
ollama run llama2 基于您的计算机配置，各种模型可能呈现出不同的性能特征。
Ollama 的优势 Ollama 的模型运行在本地，以及用户产生的所有数据均存储在本地，因此可以不受审查，并且足够安全和私密，能够有效地满足数据隐私保护的需求。此外，对于在本地运行的应用程序而言，这种方式不仅可以提高效率，而且还能够消除对网络环境的依赖。
Ollama 的不足 尽管 Ollama 能够在本地部署模型服务，以供其他程序调用，但其原生的对话界面是在命令行中进行的，用户无法方便与 AI 模型进行交互，因此，通常推荐利用第三方的 WebUI 应用来使用 Ollama， 以获得更好的体验。
五款开源 Ollama GUI 客户端推荐 1. LobeChat [Github 链接]
LobeChat 作为一款开源的 LLMs WebUI 框架，支持全球主流的大型语言模型，并提供精美的用户界面及卓越的用户体验。该框架支持通过本地 Docker 运行，亦可在 Vercel、Zeabur 等多个平台上进行部署。用户可通过配置本地 Ollama 接口地址，轻松实现 Ollama 以及其他本地模型的集成。查看 [在 LobeChat 中如何使用 Ollama]">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-07-29T10:40:08+08:00">
    <meta property="article:modified_time" content="2024-07-29T10:40:08+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">五个优秀的免费 Ollama WebUI 客户端推荐</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>认识 Ollama 本地模型框架，并简单了解它的优势和不足，以及推荐了 5 款开源免费的 Ollama WebUI 客户端，以提高使用体验。</p> 
<p><img src="https://images2.imgbox.com/cd/25/xmd02SQI_o.png" alt="Claude 3 对比 GPT-4"></p> 
<h3><a id="_Ollama_6"></a>什么是 Ollama？</h3> 
<p>Ollama 是一款强大的本地运行大型语言模型（LLM）的框架，它允许用户在自己的设备上直接运行各种大型语言模型，包括 Llama 2、Mistral、Dolphin Phi 等多种模型，无需依赖网络连接。此外，Ollama 还提供跨平台的支持，包括 macOS、Windows、Linux 以及 Docker， 几乎覆盖了所有主流操作系统。详细信息请访问 [Ollama 官方开源社区]</p> 
<h4><a id="Ollama__11"></a>Ollama 的使用</h4> 
<p>你可访问 [Ollama 官方网站] 下载 Ollama 运行框架，并利用命令行启动本地模型。以下以运行 llama2 模型为例：</p> 
<pre><code>ollama run llama2

</code></pre> 
<p>基于您的计算机配置，各种模型可能呈现出不同的性能特征。</p> 
<h4><a id="Ollama__22"></a>Ollama 的优势</h4> 
<p>Ollama 的模型运行在本地，以及用户产生的所有数据均存储在本地，因此可以不受审查，并且足够安全和私密，能够有效地满足数据隐私保护的需求。此外，对于在本地运行的应用程序而言，这种方式不仅可以提高效率，而且还能够消除对网络环境的依赖。</p> 
<h4><a id="Ollama__26"></a>Ollama 的不足</h4> 
<p>尽管 Ollama 能够在本地部署模型服务，以供其他程序调用，但其原生的对话界面是在命令行中进行的，用户无法方便与 AI 模型进行交互，因此，通常推荐利用第三方的 WebUI 应用来使用 Ollama， 以获得更好的体验。</p> 
<hr> 
<h3><a id="_Ollama_GUI__32"></a>五款开源 Ollama GUI 客户端推荐</h3> 
<h4><a id="1_LobeChat_35"></a>1. LobeChat</h4> 
<p>[Github 链接]</p> 
<p><img src="https://images2.imgbox.com/ab/49/ckfCOO2o_o.png" alt="LobeChat"></p> 
<p>LobeChat 作为一款开源的 LLMs WebUI 框架，支持全球主流的大型语言模型，并提供精美的用户界面及卓越的用户体验。该框架支持通过本地 Docker 运行，亦可在 Vercel、Zeabur 等多个平台上进行部署。用户可通过配置本地 Ollama 接口地址，轻松实现 Ollama 以及其他本地模型的集成。查看 [在 LobeChat 中如何使用 Ollama]</p> 
<p><img src="https://images2.imgbox.com/27/24/0uuaJZ3x_o.png" alt="image.png"></p> 
<h5><a id="_45"></a>推荐理由</h5> 
<ul><li>除 Ollama 所有本地模型外，LobeChat 还支持几乎所有主流的大语言模型，包括 ChatGPT、Google Gemini、Claude、Groq 等；</li><li>支持多模态 AI 能力；</li><li>提供了一个多样的 AI 助手市场，可以方便访问社区提供的各种 Prompt；</li><li>拥有独特的智能会话管理功能，轻松管理对话；</li><li>具备丰富的插件生态系统，能够利用 Function Call 实现诸如访问互联网等更多能力；</li></ul> 
<p><img src="https://images2.imgbox.com/1e/02/Uyi7ef84_o.png" alt="LobeChat 功能特性"></p> 
<hr> 
<h4><a id="2_Open_WebUI_57"></a>2. Open WebUI</h4> 
<p>[Github 链接]</p> 
<p>Open WebUI 是一个可扩展、功能丰富且用户友好的开源自托管 AI 界面，旨在完全离线运行。它支持各种 LLM 运行器，包括 Ollama 和 OpenAI 兼容的 API。</p> 
<h5><a id="_65"></a>推荐理由</h5> 
<ul><li>对本地模型均有很好的支持；</li><li>支持通过 RLHF 注释来对消息进行评级，以达到对本地模型微调的作用；</li><li>支持对话标记，轻松分类和定位特定聊天；</li><li>支持直接通过界面下载或删除模型；</li><li>可以通过 <code>@</code> 来指定不同的模型进行会话；</li></ul> 
<hr> 
<h4><a id="3_Enchanted_75"></a>3. Enchanted</h4> 
<p>[Github 链接]</p> 
<p>Enchanted 是一款专门为 MacOS/iOS/iPadOS 平台开发的应用程序，支持 Llama、Mistral、Vicuna、Starling 等多种私人托管模型。该应用致力于在苹果的全生态系统中为用户提供一个未经过滤、安全、保护隐私以及多模态的人工智能体验。</p> 
<p><img src="https://images2.imgbox.com/1f/e9/BZd6HBmc_o.png" alt="Enchanted"></p> 
<h5><a id="_83"></a>推荐理由</h5> 
<ul><li>Apple 生态原生应用，支持 iOS 生态系统（macOS、iOS、Watch、Vision Pro）的所有设备；</li><li>界面简洁直观，开箱即用，Mac 粉丝的喜爱；</li><li>基于原生系统开发的应用程序，在性能方面有非常出色的表现；</li></ul> 
<hr> 
<h4><a id="4_Chatbox_91"></a>4. Chatbox</h4> 
<p>[Github 链接]</p> 
<p>Chatbox 是一个老牌的跨平台开源客户端应用，基于 Tauri 开发，简洁易用。除了 Ollama 以外他还能够通过 API 提供另外几种流行大模型的支持。</p> 
<p><img src="https://images2.imgbox.com/7b/78/7SkNFTOH_o.png" alt="Chatbox"></p> 
<h5><a id="_99"></a>推荐理由</h5> 
<ul><li>跨平台的客户端应用，支持 Windows/MacOS/Linux/iOS/Android；</li><li>除了 Ollama 外还支持多种大语言模型；</li><li>本地应用无需部署，开箱即用</li></ul> 
<hr> 
<h4><a id="5_NextJS_Ollama_LLM_UI_107"></a>5. NextJS Ollama LLM UI</h4> 
<p>[Github 链接]</p> 
<p>NextJS Ollama LLM UI 是一款专为 Ollama 设计的极简主义用户界面。虽然关于本地部署的文档较为有限，但总体上安装过程并不复杂。该界面设计简洁美观，非常适合追求简约风格的用户。</p> 
<p><img src="https://images2.imgbox.com/90/52/AzFPnXna_o.png" alt="NextJS Ollama LLM UI"></p> 
<h5><a id="_115"></a>推荐理由</h5> 
<ul><li>基于浏览器的全平台支持；</li><li>本地模型的核心功能均能较好支持；</li><li>界面美观，干净整洁，没有太多复杂的 UI，对于喜欢极简的用户来说是一种享受；</li></ul> 
<hr> 
<p>[<img src="https://images2.imgbox.com/34/50/4xV2pI9a_o.png" alt=""></p> 
<h3><a id="AI_125"></a>如何学习AI大模型？</h3> 
<p>我在一线互联网企业工作十余年里，指导过不少同行后辈。帮助很多人得到了学习和成长。</p> 
<p>我意识到有很多经验和知识值得分享给大家，也可以通过我们的能力和经验解答大家在人工智能学习中的很多困惑，所以在工作繁忙的情况下还是坚持各种整理和分享。但苦于知识传播途径有限，很多互联网行业朋友无法获得正确的资料得到学习提升，故此将并将重要的AI大模型资料包括AI大模型入门学习思维导图、精品AI大模型学习书籍手册、视频教程、实战学习等录播视频免费分享出来。</p> 
<p><img src="https://images2.imgbox.com/03/ba/5LXJ9suQ_o.png" alt="在这里插入图片描述"></p> 
<p>第一阶段： 从大模型系统设计入手，讲解大模型的主要方法；</p> 
<p>第二阶段： 在通过大模型提示词工程从Prompts角度入手更好发挥模型的作用；</p> 
<p>第三阶段： 大模型平台应用开发借助阿里云PAI平台构建电商领域虚拟试衣系统；</p> 
<p>第四阶段： 大模型知识库应用开发以LangChain框架为例，构建物流行业咨询智能问答系统；</p> 
<p>第五阶段： 大模型微调开发借助以大健康、新零售、新媒体领域构建适合当前领域大模型；</p> 
<p>第六阶段： 以SD多模态大模型为主，搭建了文生图小程序案例；</p> 
<p>第七阶段： 以大模型平台应用与开发为主，通过星火大模型，文心大模型等成熟大模型构建大模型行业应用。</p> 
<p><img src="https://images2.imgbox.com/63/7d/2YOo4tEv_o.jpg" alt="在这里插入图片描述"></p> 
<p>👉学会后的收获：👈<br> • 基于大模型全栈工程实现（前端、后端、产品经理、设计、数据分析等），通过这门课可获得不同能力；</p> 
<p>• 能够利用大模型解决相关实际项目需求： 大数据时代，越来越多的企业和机构需要处理海量数据，利用大模型技术可以更好地处理这些数据，提高数据分析和决策的准确性。因此，掌握大模型应用开发技能，可以让程序员更好地应对实际项目需求；</p> 
<p>• 基于大模型和企业数据AI应用开发，实现大模型理论、掌握GPU算力、硬件、LangChain开发框架和项目实战技能， 学会Fine-tuning垂直训练大模型（数据准备、数据蒸馏、大模型部署）一站式掌握；</p> 
<p>• 能够完成时下热门大模型垂直领域模型训练能力，提高程序员的编码能力： 大模型应用开发需要掌握机器学习算法、深度学习框架等技术，这些技术的掌握可以提高程序员的编码能力和分析能力，让程序员更加熟练地编写高质量的代码。</p> 
<p><img src="https://images2.imgbox.com/f8/8c/kjOXEC1a_o.jpg" alt="在这里插入图片描述"></p> 
<blockquote> 
 <p><em><strong>1.AI大模型学习路线图<br> 2.100套AI大模型商业化落地方案<br> 3.100集大模型视频教程<br> 4.200本大模型PDF书籍<br> 5.LLM面试题合集<br> 6.AI产品经理资源合集</strong></em></p> 
</blockquote> 
<p>👉获取方式：<br> 😝有需要的小伙伴，可以保存图片到wx扫描二v码免费领取【保证100%免费】🆓</p> 
<p><img src="https://images2.imgbox.com/86/c4/oVIP6YZi_o.jpg" alt="在这里插入图片描述"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/177ba9aa462fed4ad50b88bd84bd5a6a/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">C&#43;&#43; --＞ string类模拟实现（附源码）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/9722ae1499a86a6373045738698b9a27/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Linux初学基本命令</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>