<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>大数据-98 Spark 集群 Spark Streaming 基础概述 架构概念 执行流程 优缺点 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/81fc4313db23478ca91e0cfa644d5e8c/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="大数据-98 Spark 集群 Spark Streaming 基础概述 架构概念 执行流程 优缺点">
  <meta property="og:description" content="点一下关注吧！！！非常感谢！！持续更新！！！ 目前已经更新到了： Hadoop（已更完）HDFS（已更完）MapReduce（已更完）Hive（已更完）Flume（已更完）Sqoop（已更完）Zookeeper（已更完）HBase（已更完）Redis （已更完）Kafka（已更完）Spark（正在更新！） 章节内容 上节我们完成了如下的内容：
Spark SQL JOINBoardcast JOINShuffle JOINSQL解析过程SparkSQL 常见的优化逻辑 背景概述 随着大数据技术的不断发展，人们对于大数据的实时性处理要求也不断提高，传统的MapReduce等批处理框架在某些特定领域，例如实时用户推荐、用户行为分析这些应用场景上逐渐不能满足人们对实时性的需求，因为诞生了一批如 S3、Samza、Storm、Flink等流式分析、实时计算框架。
Spark Streaming 是 Spark 核心组件之一，用于实时数据处理。它能够将实时数据流分批处理，转换为可操作的分布式数据集 (RDDs)，从而实现流数据的实时处理和分析。
基本概念 DStream: DStream（离散流）是 Spark Streaming 中的核心抽象，代表一个连续的数据流。它可以来自 Kafka、Flume、HDFS、Socket 等数据源，或者由现有的 RDD 经过转换产生。Batch Interval: 数据流被划分为多个小批次，每个批次在指定的时间间隔（例如 1 秒或 10 秒）内进行处理，这个时间间隔称为 Batch Interval。 架构概念 Spark Streaming 的架构主要包括如下组件：
输入源: Spark Streaming 支持多种输入源，如 Kafka、Flume、HDFS、S3 等。处理引擎: 核心是 Spark Core 的 RDD 处理引擎，利用它来执行批处理操作。输出操作: 处理后的数据可以输出到文件系统、数据库、仪表板等。 编程模型 Spark Streaming 使用与 Spark 相同的编程模型，支持常见的 Map、Reduce、Join、Window 等操作。你可以通过在 DStream 上调用这些操作来进行实时数据处理。
Transformation: 如 map、flatMap、filter 等。Window Operations: Spark Streaming 提供了基于时间窗口的操作，例如窗口化计算，通过 window 和 slide 函数实现。">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-08-23T09:39:29+08:00">
    <meta property="article:modified_time" content="2024-08-23T09:39:29+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">大数据-98 Spark 集群 Spark Streaming 基础概述 架构概念 执行流程 优缺点</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_0"></a>点一下关注吧！！！非常感谢！！持续更新！！！</h2> 
<h2><a id="_1"></a>目前已经更新到了：</h2> 
<ul><li>Hadoop（已更完）</li><li>HDFS（已更完）</li><li>MapReduce（已更完）</li><li>Hive（已更完）</li><li>Flume（已更完）</li><li>Sqoop（已更完）</li><li>Zookeeper（已更完）</li><li>HBase（已更完）</li><li>Redis （已更完）</li><li>Kafka（已更完）</li><li>Spark（正在更新！）</li></ul> 
<h2><a id="_14"></a>章节内容</h2> 
<p>上节我们完成了如下的内容：</p> 
<ul><li>Spark SQL JOIN</li><li>Boardcast JOIN</li><li>Shuffle JOIN</li><li>SQL解析过程</li><li>SparkSQL 常见的优化逻辑</li></ul> 
<p><img src="https://images2.imgbox.com/15/7f/f4YykN6j_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="_23"></a>背景概述</h2> 
<p>随着大数据技术的不断发展，人们对于大数据的实时性处理要求也不断提高，传统的MapReduce等批处理框架在某些特定领域，例如实时用户推荐、用户行为分析这些应用场景上逐渐不能满足人们对实时性的需求，因为诞生了一批如 S3、Samza、Storm、Flink等流式分析、实时计算框架。</p> 
<p>Spark Streaming 是 Spark 核心组件之一，用于实时数据处理。它能够将实时数据流分批处理，转换为可操作的分布式数据集 (RDDs)，从而实现流数据的实时处理和分析。</p> 
<h2><a id="_28"></a>基本概念</h2> 
<ul><li>DStream: DStream（离散流）是 Spark Streaming 中的核心抽象，代表一个连续的数据流。它可以来自 Kafka、Flume、HDFS、Socket 等数据源，或者由现有的 RDD 经过转换产生。</li><li>Batch Interval: 数据流被划分为多个小批次，每个批次在指定的时间间隔（例如 1 秒或 10 秒）内进行处理，这个时间间隔称为 Batch Interval。</li></ul> 
<h2><a id="_32"></a>架构概念</h2> 
<p>Spark Streaming 的架构主要包括如下组件：</p> 
<ul><li>输入源: Spark Streaming 支持多种输入源，如 Kafka、Flume、HDFS、S3 等。</li><li>处理引擎: 核心是 Spark Core 的 RDD 处理引擎，利用它来执行批处理操作。</li><li>输出操作: 处理后的数据可以输出到文件系统、数据库、仪表板等。</li></ul> 
<h2><a id="_38"></a>编程模型</h2> 
<p>Spark Streaming 使用与 Spark 相同的编程模型，支持常见的 Map、Reduce、Join、Window 等操作。你可以通过在 DStream 上调用这些操作来进行实时数据处理。</p> 
<ul><li>Transformation: 如 map、flatMap、filter 等。</li><li>Window Operations: Spark Streaming 提供了基于时间窗口的操作，例如窗口化计算，通过 window 和 slide 函数实现。<br> <img src="https://images2.imgbox.com/40/2b/P73VoRz9_o.png" alt="在这里插入图片描述"></li></ul> 
<h2><a id="_43"></a>容错性</h2> 
<ul><li>检查点机制: 为了处理故障和保证数据一致性，Spark Streaming 提供了检查点机制，可以将中间状态保存到可靠的存储系统（如 HDFS），从而在故障恢复时重建这些状态。</li><li>数据重放: 在 Kafka 等消息队列中，消息是基于偏移量的，这使得 Spark Streaming 可以在故障发生时重新处理未处理的消息，确保数据的可靠性和一致性。</li></ul> 
<h2><a id="_Spark_Streaming_47"></a>什么是 Spark Streaming</h2> 
<ul><li> <p>Spark Streaming 类似于 Apache Storm（来一条处理一条、延迟低、响应快、吞吐量低），用于流式数据的处理。</p> </li><li> <p>Spark Streaming 具有高吞吐量和容错能力强的特点。</p> </li><li> <p>Spark Streaming 支持的数据输入源很多，例如：Kafka（最重要的数据源）、Flume、TCP套接字等。</p> </li><li> <p>数据输入后可用高度抽象API：map reduce join window等进行运算</p> </li><li> <p>处理结果可存 HDFS、数据库等</p> </li><li> <p>Spark Streaming 可以与 MLib、GraphX融合</p> <p><img src="https://images2.imgbox.com/72/e3/mqsIJlw6_o.png" alt="在这里插入图片描述"><br> Spark Streaming 与 Spark 基于RDD的概念比较类似，Spark Streaming 使用离散化流（Discretized Stream）作为抽象表示，成为 DStream。<br> DStream是随着时间推移而收到的数据的序列，在内部，每个时间区间收到的数据都作为RDD存在，DStream是由这些RDD所组成的序列。<br> <img src="https://images2.imgbox.com/4a/d5/Ax7EG5lX_o.png" alt="在这里插入图片描述"></p> </li></ul> 
<p>DStream 可以从各种输入源创建，比如 Flume、Kafka或者HDFS，创建出来的DStream支持两种操作：</p> 
<ul><li>转化操作，会生成一个新的DStream</li><li>输出操作（output operation），把数据写入外部系统中</li></ul> 
<p>DStream 提供了许多与RDD所支持的操作相类似的操作支持，还增加了与时间相关的的新操作，比如滑动窗口。</p> 
<h2><a id="Spark_Streaming__66"></a>Spark Streaming 架构</h2> 
<p>Spark Streaming 使用 mini-batch 架构，把流式计算当作一系列连续的小规模批处理来对待。<br> Spark Streaming 从各种输入源中读取数据，并把数据分组小批次，新的批次按均匀的时间间隔创建出来。<br> 在每个时间区间开始的时候，一个新的批次就创建出来，在该区间内收到的数据都会被添加到这个批次中，在时间区间结束时，批次停止增长。</p> 
<p>时间区间的大小是由批次间隔这个参数决定的，批次间隔一般设置在500ms到几秒之间，由开发者配置。<br> 每个输入批次都形成一个RDD，以Spark作业的方式处理并生成其他的RDD，处理的结果可以批处理的方式传给外部的系统。</p> 
<p><img src="https://images2.imgbox.com/f8/f4/ZFRuXECi_o.png" alt="在这里插入图片描述"><br> Spark Streaming的编程抽象是离散化流，也就是DStream。它是一个RDD序列，每个RDD代表数据流中的一个时间片内的编程。</p> 
<p><img src="https://images2.imgbox.com/96/06/KBDSJKVN_o.png" alt="在这里插入图片描述"></p> 
<p>应用于DStream上的转换操作都会转换为底层RDD上的操作。如对行DStream中的每个RDD应用FlatMap操作以生成单词DStream的RDD。</p> 
<p><img src="https://images2.imgbox.com/fa/8b/Tz4bO564_o.png" alt="在这里插入图片描述"></p> 
<p>这些底层RDD转换是Spark引擎完成的，DStream操作隐藏了大部分的细节，为开发人员提供了更高级的API以方便使用。</p> 
<p>Spark Streaming为每个输入源启动对应的接收器，接收器运行在Executor中，从输入源收集数据并保存为RDD。<br> 默认情况下接收到数据后会复制到另一个Executor中，进行容错。<br> Driver中的 StreamingContext 会周期性的运行 Spark作业来处理这些数据。<br> <img src="https://images2.imgbox.com/90/7a/tp03xdnN_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="Spark_Streaming_89"></a>Spark Streaming运行流程</h2> 
<ul><li>客户端提交Spark Streaming作业后启动Driver，Driver启动Receiver，Receiver接收数据源的数据</li><li>每个作业包含多个Executor，每个Executor以线程的方式运行Task，Spark Streaming至少包含一个Receive Task（一般情况下）</li><li>Receive接收数据后生成Block，并把BlockId汇报给Driver，然后备份到另一个Executor上</li><li>ReceiveTracker维护Receiver汇报的BlockId</li><li>Driver定时启动JobGenerator，根据DStream的关系生成逻辑RDD，然后创建JobSet，交给JobScheduler。</li><li>JobScheduler 负责调度JobSet，交给DAGScheduler，DAGScheduler根据逻辑RDD，生成Stages，每个Stage包含一到多个Task，将Task提交给TaskScheduler。</li><li>TaskScheduler负责把Task调度到Executor上，并维护Task的运行状态</li></ul> 
<h2><a id="Spark_Streaming__98"></a>Spark Streaming 优缺点</h2> 
<p>与传统流式框架相比，Spark Streaming 最大的不同点在与它对待数据是粗粒度的处理方式，即一次处理一小批数据，而其他框架往往采用细粒度的处理模式，即依次处理一条数据，Spark Streaming这样的设计实现既为其带来了显而易见的优点，又引入了不少不可避免的缺点。</p> 
<h3><a id="_101"></a>优点概括</h3> 
<ul><li>Spark Streaming 内部的实现和调度方式高度依赖Spark的DAG调度器和RDD，这就决定了Spark Streaming的设计初衷必须是粗粒度的方式的。同时，由于Spark内部调度器足够快速和高效，可以快速地处理小批量数据，这就获得准实时的特性</li><li>Spark Streaming 的粗粒度执行方式使其确保 “处理且仅处理一次”的特性（EOS），同时也可以更方便地实现容错恢复机制</li><li>由于Spark Streaming的DStream本质上RDD在流式数据上的抽象，因为基于RDD的各种操作也有相应的基本DStream的版本，这样就大大降低了用户对于新框架的学习成本，在了解Spark的情况下用户将很容易使用Spark Streaming。</li><li>由于 DStream 是在RDD上的抽象，那么也就更容易与RDD进行交互操作，在需要将流式数据和批处理数据结合进行分析的情况下，将会变得方便。</li></ul> 
<h3><a id="_107"></a>缺点概括</h3> 
<ul><li>Spark Streaming 的粗粒度处理方式也造成了不可避免的延迟，在细粒度处理方式下，理想情况下每一条记录都会被实时处理，而在Spark Streaming中，数据需要汇总到一定量都再一次性处理，这么增加了数据处理的延迟，这种延迟是由框架设计引入的，并不是由网络或其他情况造成的。</li></ul> 
<h2><a id="Structured_Streaming_110"></a>Structured Streaming</h2> 
<p>Spark Streaming 计算逻辑是把数据按时间划分为DStream，存在以下问题：</p> 
<ul><li>框架自身只能根据BatchTime单元进行数据处理，很难处理基于EventTime（即时间戳）的数据，很难处理延迟，乱序的数据</li><li>流式和批量处理的API不完全一致，两种使用场景中，程序代码还是需要一定的转换</li><li>端到端的数据容错保障逻辑需要用户自己构建，难以处理增量更新和持久化存储等一致性问题</li></ul> 
<p>基于以上问题，提出了下一代 Structure Streaming。将数据源映射为一张无界长度的表，通过表的计算，输出结果映射为另一张表。<br> 以结构化的方式去操作流式数据，简化了实时计算过程，同时还复用Catalyst引擎来优化SQL操作，此外还能支持增量计算和基于EventTime的计算。</p> 
<h2><a id="_Kafka__119"></a>与 Kafka 集成</h2> 
<p>Kafka 是 Spark Streaming 最常用的消息队列之一。通过 Kafka 与 Spark Streaming 的紧密集成，可以实现高吞吐量、低延迟的流数据处理。</p> 
<ul><li>Direct Approach: 直接从 Kafka 读取数据，不需要中间的 Receiver，确保了精确一次的语义。</li><li>Offset 管理: 可以手动管理 Kafka 的偏移量，保证在出错时可以继续处理上次未处理的消息。</li></ul> 
<h2><a id="_125"></a>应用场景</h2> 
<ul><li>实时监控: 使用 Spark Streaming 可以实现系统和应用程序的实时监控与报警系统。</li><li>日志处理: 处理实时生成的日志数据，进行在线分析和异常检测。</li><li>金融分析: 用于实时处理股票交易、风险评估等金融数据。<br> -社交媒体分析: 实时分析社交媒体数据，监测舆情和用户行为。</li></ul> 
<h2><a id="_132"></a>性能调优</h2> 
<ul><li>并行度: 通过增加并行度来提高吞吐量。</li><li>内存管理: 需要合理设置内存参数，防止 OOM 错误。</li><li>反压机制: Spark Streaming 提供了背压机制，可以动态调整数据处理速率，防止系统过载。</li></ul>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/02cc7f3f6c222e1788f4a8b5c23dc3e8/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">CyberScraper-2077&#43;simple-one-api：使用大模型爬虫</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/95be61dcaaf63639b0e583c7a30dd7c2/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【数据结构】总结二叉树的概念以及存储结构</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>