<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>langchain 入门指南 - 让 AI 记住你说过的话 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/dab85cd759ab3d76a615ce4c2657cecf/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="langchain 入门指南 - 让 AI 记住你说过的话">
  <meta property="og:description" content="前些天发现了一个巨牛的人工智能学习网站，通俗易懂，风趣幽默，忍不住分享一下给大家。点击跳转到网站。
在我们通过 web 端的聊天界面与 AI 对话时，AI 会记住你说过的话。这样，你可以在对话中引用之前的话语，或者在之后的对话中提到之前的话语。
但是如果我们像下面这样调用 API 的时候，就会发现 AI 不会记住我们之前说过的话：
from langchain_openai import ChatOpenAI chat = ChatOpenAI( model=&#34;yi-large&#34;, temperature=0.3, max_tokens=200, api_key=&#39;your key&#39;, base_url=&#34;https://api.lingyiwanwu.com/v1&#34;, ) response = chat.invoke(&#39;今天广州天气晴朗，26~35摄氏度。&#39;) print(response.content) response = chat.invoke(&#39;今天广州适合穿什么？&#39;) print(response.content) 输出：
这句话的意思是今天广州的天气非常好，晴朗无云，气温在26摄氏度到35摄氏度之间。这是一个适合户外活动的好天气，但也要注意防晒和补水，因为气温较高。 很抱歉，我无法提供实时天气信息或建议。要了解今天的广州适合穿什么，您可以查看当地的天气预报，了解当前的气温、湿度和天气状况，然后根据这些信息选择合适的衣物。 通常，广州属于亚热带季风气候，夏季炎热潮湿，冬季温和，春秋季节宜人。根据季节和天气预报，您可以选择穿短袖、长袖、薄外套或厚外套等。 别忘了查看是否需要携带雨具，因为广州的降雨量也比较丰富。 虽然我们告诉了 LLM 今天广州的天气，但是在第二次调用的时候，AI 并没有记住我们之前说过的话，所以不能依据当前的天气状况给我提供穿衣建议。
为什么 AI 不会记住我说过的话 这是因为大模型本身并不具备记忆功能。在我们每次使用大模型的 API 的时候，它都是基于训练模型时候的数据以及我们传递的信息来进行推理的。
如果让大模型记住我们说过的话，那么它需要存储的信息量会非常庞大，这样的成本是非常高昂的。
同时，如果每一次调用的时候，都在一个庞大的上下文中进行推理，那么推理的时间也会非常长，消耗的资源会非常多。
所以，大模型通常是不会记住我们说过的话的。
解决办法：我们自己记住 既然大模型记不住我们说过的话，那唯一的办法就是我们自己记住，然后下次调用的时候，将之前的话语传递给 AI。
from langchain_openai import ChatOpenAI from langchain_core.messages import HumanMessage, AIMessage chat = ChatOpenAI( model=&#34;yi-large&#34;, temperature=0.3, max_tokens=200, api_key=&#39;your key&#39;, base_url=&#34;">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-07-23T02:45:00+08:00">
    <meta property="article:modified_time" content="2024-07-23T02:45:00+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">langchain 入门指南 - 让 AI 记住你说过的话</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>前些天发现了一个巨牛的<a href="https://www.captainbed.cn/rubys" rel="nofollow">人工智能学习网站</a>，通俗易懂，风趣幽默，忍不住分享一下给大家。<a href="https://www.captainbed.cn/rubys" rel="nofollow">点击跳转到网站</a>。</p> 
<p>在我们通过 web 端的聊天界面与 AI 对话时，AI 会记住你说过的话。这样，你可以在对话中引用之前的话语，或者在之后的对话中提到之前的话语。</p> 
<p>但是如果我们像下面这样调用 API 的时候，就会发现 AI 不会记住我们之前说过的话：</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> langchain_openai <span class="token keyword">import</span> ChatOpenAI

chat <span class="token operator">=</span> ChatOpenAI<span class="token punctuation">(</span>
    model<span class="token operator">=</span><span class="token string">"yi-large"</span><span class="token punctuation">,</span>
    temperature<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">,</span>
    max_tokens<span class="token operator">=</span><span class="token number">200</span><span class="token punctuation">,</span>
    api_key<span class="token operator">=</span><span class="token string">'your key'</span><span class="token punctuation">,</span>
    base_url<span class="token operator">=</span><span class="token string">"https://api.lingyiwanwu.com/v1"</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

response <span class="token operator">=</span> chat<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token string">'今天广州天气晴朗，26~35摄氏度。'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>content<span class="token punctuation">)</span>

response <span class="token operator">=</span> chat<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token string">'今天广州适合穿什么？'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>content<span class="token punctuation">)</span>
</code></pre> 
<p>输出：</p> 
<pre><code>这句话的意思是今天广州的天气非常好，晴朗无云，气温在26摄氏度到35摄氏度之间。这是一个适合户外活动的好天气，但也要注意防晒和补水，因为气温较高。

很抱歉，我无法提供实时天气信息或建议。要了解今天的广州适合穿什么，您可以查看当地的天气预报，了解当前的气温、湿度和天气状况，然后根据这些信息选择合适的衣物。
通常，广州属于亚热带季风气候，夏季炎热潮湿，冬季温和，春秋季节宜人。根据季节和天气预报，您可以选择穿短袖、长袖、薄外套或厚外套等。
别忘了查看是否需要携带雨具，因为广州的降雨量也比较丰富。
</code></pre> 
<p>虽然我们告诉了 LLM 今天广州的天气，但是在第二次调用的时候，AI 并没有记住我们之前说过的话，所以不能依据当前的天气状况给我提供穿衣建议。</p> 
<h3><a id="_AI__36"></a>为什么 AI 不会记住我说过的话</h3> 
<p>这是因为大模型本身并不具备记忆功能。在我们每次使用大模型的 API 的时候，它都是基于训练模型时候的数据以及我们传递的信息来进行推理的。</p> 
<p>如果让大模型记住我们说过的话，那么它需要存储的信息量会非常庞大，这样的成本是非常高昂的。<br> 同时，如果每一次调用的时候，都在一个庞大的上下文中进行推理，那么推理的时间也会非常长，消耗的资源会非常多。</p> 
<p>所以，大模型通常是不会记住我们说过的话的。</p> 
<h3><a id="_45"></a>解决办法：我们自己记住</h3> 
<p>既然大模型记不住我们说过的话，那唯一的办法就是我们自己记住，然后下次调用的时候，将之前的话语传递给 AI。</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> langchain_openai <span class="token keyword">import</span> ChatOpenAI
<span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>messages <span class="token keyword">import</span> HumanMessage<span class="token punctuation">,</span> AIMessage

chat <span class="token operator">=</span> ChatOpenAI<span class="token punctuation">(</span>
    model<span class="token operator">=</span><span class="token string">"yi-large"</span><span class="token punctuation">,</span>
    temperature<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">,</span>
    max_tokens<span class="token operator">=</span><span class="token number">200</span><span class="token punctuation">,</span>
    api_key<span class="token operator">=</span><span class="token string">'your key'</span><span class="token punctuation">,</span>
    base_url<span class="token operator">=</span><span class="token string">"https://api.lingyiwanwu.com/v1"</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

messages <span class="token operator">=</span> <span class="token punctuation">[</span>
    HumanMessage<span class="token punctuation">(</span><span class="token string">'今天广州天气晴朗，26~35摄氏度。'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span>

response <span class="token operator">=</span> chat<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>messages<span class="token punctuation">)</span>

messages<span class="token punctuation">.</span>append<span class="token punctuation">(</span>AIMessage<span class="token punctuation">(</span>response<span class="token punctuation">.</span>content<span class="token punctuation">)</span><span class="token punctuation">)</span>
messages<span class="token punctuation">.</span>append<span class="token punctuation">(</span>HumanMessage<span class="token punctuation">(</span><span class="token string">'今天广州适合穿什么？'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>messages<span class="token punctuation">)</span>

response <span class="token operator">=</span> chat<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span>messages<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>content<span class="token punctuation">)</span>
</code></pre> 
<p>输出：</p> 
<pre><code>[
  HumanMessage(content='今天广州天气晴朗，26~35摄氏度。'), 
  AIMessage(content='这句话的意思是，今天广州的天气非常好，晴朗无云，气温在26摄氏度到35摄氏度之间。这是一个非常适合户外活动的天气，既不太热也不太冷。'), 
  HumanMessage(content='今天广州适合穿什么？')
]

根据您提供的信息，今天广州的天气晴朗，气温在26到35摄氏度之间。这个温度范围适合穿着轻薄、透气的衣物。以下是一些建议：

1. 上衣：可以选择短袖T恤、薄衬衫或棉质衣物，以保持凉爽。
2. 下装：可以穿短裤、七分裤或轻薄的牛仔裤。
3. 鞋子：舒适的凉鞋、帆布鞋或运动鞋都是不错的选择。
4. 配件：如果需要外出，可以戴上一顶遮阳帽和太阳镜，以保护皮肤和眼睛不受紫外线伤害。
5. 防晒：由于天气晴朗，紫外线可能较强，建议涂抹防晒霜以保护皮肤。

请根据您的个人舒适度和活动需求来调整着装。如果您的活动包括室内外结合，可以准备一件轻薄的外套或披肩，以
</code></pre> 
<p>输出的第一部分是我们问第二个问题的上下文，第二部分是 AI 的回答。</p> 
<p>在这个例子中，我们将之前的对话保存在了 <code>messages</code> 中，然后在下一次调用的时候，将之前的对话传递给 AI。</p> 
<p>当然，这里只是举个例子。真实使用中，我们可能会将一大段信息交给 LLM，然后让它来帮我们进行分析推理，然后可以问它问题从而得到答案。</p> 
<h3><a id="_102"></a>对话内容记忆的抽象</h3> 
<p>上一个例子中，我们是每一次请求和响应的内容都保存在了 <code>messages</code> 中，然后传递给 AI。<br> 这样操作可能会比较麻烦，因为消息历史会逐渐增长，直到达到 LLM 的最大上下文长度。<br> 这个时候，我们就需要删除一部分历史消息，从而保证 LLM 可以正常处理我们的请求。</p> 
<p>除了最大上下文限制的原因，太长的上下文也会带来大量的 <code>token</code> 消耗，这样会增加我们的成本。</p> 
<p>因此，我们非常需要<strong>定期对历史消息进行处理，删除一部分意义不大的历史消息，或者删除那些最久远的消息</strong>，只保留最近的消息。</p> 
<blockquote> 
 <p>这跟人类的记忆一样，我们对近期发生的事情记忆深刻，而对很久远的事情记忆模糊。</p> 
</blockquote> 
<h4><a id="ConversationBufferWindowMemory_114"></a>ConversationBufferWindowMemory</h4> 
<p>为了解决这个问题，<code>langchain</code> 提供了一些处理历史消息的工具。</p> 
<p>比如适合我上面说的这个场景的 <code>RunnableWithMessageHistory</code>，它可以记住指定次数的消息，然后在超过指定次数的时候，删除最早的消息。</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>chat_history <span class="token keyword">import</span> InMemoryChatMessageHistory
<span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>messages <span class="token keyword">import</span> AIMessage
<span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>runnables <span class="token keyword">import</span> RunnableWithMessageHistory
<span class="token keyword">from</span> langchain_openai <span class="token keyword">import</span> ChatOpenAI
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>memory <span class="token keyword">import</span> ConversationBufferWindowMemory

llm <span class="token operator">=</span> ChatOpenAI<span class="token punctuation">(</span>
    model<span class="token operator">=</span><span class="token string">"yi-large"</span><span class="token punctuation">,</span>
    temperature<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">,</span>
    max_tokens<span class="token operator">=</span><span class="token number">200</span><span class="token punctuation">,</span>
    api_key<span class="token operator">=</span><span class="token string">'your key'</span><span class="token punctuation">,</span>
    base_url<span class="token operator">=</span><span class="token string">"https://api.lingyiwanwu.com/v1"</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

store <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span>  <span class="token comment"># memory is maintained outside the chain</span>
<span class="token keyword">def</span> <span class="token function">get_session_history</span><span class="token punctuation">(</span>session_id<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> InMemoryChatMessageHistory<span class="token punctuation">:</span>
    <span class="token keyword">if</span> session_id <span class="token keyword">not</span> <span class="token keyword">in</span> store<span class="token punctuation">:</span>
        store<span class="token punctuation">[</span>session_id<span class="token punctuation">]</span> <span class="token operator">=</span> InMemoryChatMessageHistory<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> store<span class="token punctuation">[</span>session_id<span class="token punctuation">]</span>

    memory <span class="token operator">=</span> ConversationBufferWindowMemory<span class="token punctuation">(</span>
        chat_memory<span class="token operator">=</span>store<span class="token punctuation">[</span>session_id<span class="token punctuation">]</span><span class="token punctuation">,</span>
        k<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>
        return_messages<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span>
    <span class="token keyword">assert</span> <span class="token builtin">len</span><span class="token punctuation">(</span>memory<span class="token punctuation">.</span>memory_variables<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">1</span>
    key <span class="token operator">=</span> memory<span class="token punctuation">.</span>memory_variables<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    messages <span class="token operator">=</span> memory<span class="token punctuation">.</span>load_memory_variables<span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">[</span>key<span class="token punctuation">]</span>
    store<span class="token punctuation">[</span>session_id<span class="token punctuation">]</span> <span class="token operator">=</span> InMemoryChatMessageHistory<span class="token punctuation">(</span>messages<span class="token operator">=</span>messages<span class="token punctuation">)</span>
    <span class="token keyword">return</span> store<span class="token punctuation">[</span>session_id<span class="token punctuation">]</span>

chain <span class="token operator">=</span> RunnableWithMessageHistory<span class="token punctuation">(</span>llm<span class="token punctuation">,</span> get_session_history<span class="token punctuation">)</span>

conf <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">"configurable"</span><span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">"session_id"</span><span class="token punctuation">:</span> <span class="token string">"1"</span><span class="token punctuation">}</span><span class="token punctuation">}</span>
response <span class="token operator">=</span> chain<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token string">'今天广州天气晴朗，26~35摄氏度。'</span><span class="token punctuation">,</span> config<span class="token operator">=</span>conf<span class="token punctuation">)</span> <span class="token comment"># type: AIMessage</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"response 1: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>response<span class="token punctuation">.</span>content<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

response <span class="token operator">=</span> chain<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token string">'今天广州适合穿什么？'</span><span class="token punctuation">,</span> config<span class="token operator">=</span>conf<span class="token punctuation">)</span> <span class="token comment"># type: AIMessage</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"response 2: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>response<span class="token punctuation">.</span>content<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
</code></pre> 
<p>输出：</p> 
<pre><code>response 1: 这句话的意思是今天广州的天气非常好，晴朗无云，气温在26摄氏度到35摄氏度之间。这个温度范围对于夏天来说是比较舒适的，适合户外活动。
response 2: 根据您提供的信息，今天广州的天气晴朗，气温在26到35摄氏度之间。这个温度范围适合穿着轻薄、透气的衣物。以下是一些建议：

1. 上衣：可以选择短袖T恤、薄衬衫或棉质衣物，避免穿得过多导致出汗后衣服湿透。
2. 下装：可以穿短裤、七分裤或轻薄的牛仔裤。如果是在室内或者空调环境中，可以考虑带一件长裤以防着凉。
3. 鞋子：舒适的凉鞋、帆布鞋或运动鞋都是不错的选择。
4. 配件：可以戴一顶遮阳帽和太阳镜来保护皮肤和眼睛免受紫外线伤害。如果需要长时间在户外，可以考虑涂抹防晒霜。
5. 携带物品：由于气温较高，建议随身携带水瓶以保持水分，同时可以携带
</code></pre> 
<p>相比之下，现在我们并不需要每次都手动保存历史消息，而是交给 <code>ConversationBufferWindowMemory</code> 来处理。<br> 这样，我们就可以更加专注于对话的内容，而不用担心历史消息的处理。</p> 
<p>在上面这个例子中，我们指定了 <code>k=10</code>，也就是说，只保存最近的 20 条消息，<br> 超过 20 条的消息之后会删除最早的消息（这是因为在底层实现中，会使用 <code>k * 2</code>，而不是 <code>k</code>）。</p> 
<p>我们可以指定 <code>k=1</code> 来验证一下（）：</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>chat_history <span class="token keyword">import</span> InMemoryChatMessageHistory
<span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>messages <span class="token keyword">import</span> AIMessage
<span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>runnables <span class="token keyword">import</span> RunnableWithMessageHistory
<span class="token keyword">from</span> langchain_openai <span class="token keyword">import</span> ChatOpenAI
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>memory <span class="token keyword">import</span> ConversationBufferWindowMemory

llm <span class="token operator">=</span> ChatOpenAI<span class="token punctuation">(</span>
    model<span class="token operator">=</span><span class="token string">"yi-large"</span><span class="token punctuation">,</span>
    temperature<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">,</span>
    max_tokens<span class="token operator">=</span><span class="token number">200</span><span class="token punctuation">,</span>
    api_key<span class="token operator">=</span><span class="token string">'your key'</span><span class="token punctuation">,</span>
    base_url<span class="token operator">=</span><span class="token string">"https://api.lingyiwanwu.com/v1"</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

store <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span>  <span class="token comment"># memory is maintained outside the chain</span>
<span class="token keyword">def</span> <span class="token function">get_session_history</span><span class="token punctuation">(</span>session_id<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> InMemoryChatMessageHistory<span class="token punctuation">:</span>
    <span class="token keyword">if</span> session_id <span class="token keyword">not</span> <span class="token keyword">in</span> store<span class="token punctuation">:</span>
        store<span class="token punctuation">[</span>session_id<span class="token punctuation">]</span> <span class="token operator">=</span> InMemoryChatMessageHistory<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> store<span class="token punctuation">[</span>session_id<span class="token punctuation">]</span>

    memory <span class="token operator">=</span> ConversationBufferWindowMemory<span class="token punctuation">(</span>
        chat_memory<span class="token operator">=</span>store<span class="token punctuation">[</span>session_id<span class="token punctuation">]</span><span class="token punctuation">,</span>
        k<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
        return_messages<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span>
    <span class="token keyword">assert</span> <span class="token builtin">len</span><span class="token punctuation">(</span>memory<span class="token punctuation">.</span>memory_variables<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">1</span>
    key <span class="token operator">=</span> memory<span class="token punctuation">.</span>memory_variables<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    <span class="token comment"># 返回最新的 k * 2 条消息</span>
    messages <span class="token operator">=</span> memory<span class="token punctuation">.</span>load_memory_variables<span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">[</span>key<span class="token punctuation">]</span>
    store<span class="token punctuation">[</span>session_id<span class="token punctuation">]</span> <span class="token operator">=</span> InMemoryChatMessageHistory<span class="token punctuation">(</span>messages<span class="token operator">=</span>messages<span class="token punctuation">)</span>
    <span class="token keyword">return</span> store<span class="token punctuation">[</span>session_id<span class="token punctuation">]</span>

chain <span class="token operator">=</span> RunnableWithMessageHistory<span class="token punctuation">(</span>llm<span class="token punctuation">,</span> get_session_history<span class="token punctuation">)</span>

conf <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">"configurable"</span><span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">"session_id"</span><span class="token punctuation">:</span> <span class="token string">"1"</span><span class="token punctuation">}</span><span class="token punctuation">}</span>
response <span class="token operator">=</span> chain<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token string">'今天广州天气晴朗，26~35摄氏度。'</span><span class="token punctuation">,</span> config<span class="token operator">=</span>conf<span class="token punctuation">)</span> <span class="token comment"># type: AIMessage</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"response 1: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>response<span class="token punctuation">.</span>content<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

response <span class="token operator">=</span> chain<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token string">'这是一条无用的消息，请你忽略。'</span><span class="token punctuation">,</span> config<span class="token operator">=</span>conf<span class="token punctuation">)</span> <span class="token comment"># type: AIMessage</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"response 2: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>response<span class="token punctuation">.</span>content<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

response <span class="token operator">=</span> chain<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token string">'今天广州适合穿什么？'</span><span class="token punctuation">,</span> config<span class="token operator">=</span>conf<span class="token punctuation">)</span> <span class="token comment"># type: AIMessage</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"response 3: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>response<span class="token punctuation">.</span>content<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
</code></pre> 
<p>输出：</p> 
<pre><code>response 1: 这句话的意思是，今天广州的天气非常好，晴朗无云，气温在26摄氏度到35摄氏度之间。这是一个非常适合户外活动的天气，既不太热也不太冷。
response 2: 好的，我会忽略这条消息。如果您有其他问题或需要帮助，请随时告诉我！
response 3: 很抱歉，我无法提供实时数据或当前的天气情况。........&lt;一大堆&gt;
</code></pre> 
<p>因为我们使用了 <code>k=1</code>，所以当我们交谈了三次之后，第一次发送的内容就会被删除了。<br> 所以当我们问第三个问题的时候，AI 并没有记住我们之前说过的话。</p> 
<h3><a id="_240"></a>本文例子用到的一些类的介绍</h3> 
<h4><a id="InMemoryChatMessageHistory_242"></a>InMemoryChatMessageHistory</h4> 
<p>没有特殊功能，只有一个 <code>messages</code> 属性，用于保存消息，是 <code>list</code> 类型。</p> 
<h4><a id="ConversationBufferWindowMemory_246"></a>ConversationBufferWindowMemory</h4> 
<ul><li>它有一个 <code>chat_memory</code> 属性，用于保存历史消息。</li><li>当我们从它的实例中获取消息的时候（调用它的 <code>load_memory_variables</code> 方法的时候），它只会返回最近的 <code>k * 2</code> 条历史消息。</li></ul> 
<h3><a id="ConversationSummaryBufferMemory_251"></a>ConversationSummaryBufferMemory</h3> 
<p>除了 <code>ConversationBufferWindowMemory</code>，<code>langchain</code> 还提供了 <code>ConversationSummaryBufferMemory</code>，它会将历史消息进行摘要（当超过了指定长度的时候），然后保存摘要：</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">prune</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Prune buffer if it exceeds max token limit"""</span>
    <span class="token builtin">buffer</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>chat_memory<span class="token punctuation">.</span>messages
    curr_buffer_length <span class="token operator">=</span> self<span class="token punctuation">.</span>llm<span class="token punctuation">.</span>get_num_tokens_from_messages<span class="token punctuation">(</span><span class="token builtin">buffer</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> curr_buffer_length <span class="token operator">&gt;</span> self<span class="token punctuation">.</span>max_token_limit<span class="token punctuation">:</span>
        pruned_memory <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">while</span> curr_buffer_length <span class="token operator">&gt;</span> self<span class="token punctuation">.</span>max_token_limit<span class="token punctuation">:</span>
            pruned_memory<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token builtin">buffer</span><span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            curr_buffer_length <span class="token operator">=</span> self<span class="token punctuation">.</span>llm<span class="token punctuation">.</span>get_num_tokens_from_messages<span class="token punctuation">(</span><span class="token builtin">buffer</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>moving_summary_buffer <span class="token operator">=</span> self<span class="token punctuation">.</span>predict_new_summary<span class="token punctuation">(</span>
            pruned_memory<span class="token punctuation">,</span> self<span class="token punctuation">.</span>moving_summary_buffer
        <span class="token punctuation">)</span>
</code></pre> 
<p><code>prune</code> 方法会在超过指定长度的时候，将历史消息进行摘要，然后保存摘要。</p> 
<h4><a id="_272"></a>优缺点</h4> 
<p>优点：</p> 
<ul><li>控制了缓存内容大小</li><li>尽量记忆了对话的内容</li></ul> 
<p>缺点：</p> 
<ul><li>在缓存内容超出限制后，为控制缓存的大小，会持续通过大模型来总结较早的内容。</li><li>相应延迟增加很多</li><li>成本增加</li></ul> 
<h3><a id="_285"></a>总结</h3> 
<p>在使用 LLM 的时候，我们需要注意到 LLM 并不会记住我们之前说过的话。</p> 
<p>但是我们可以自行保存历史消息，然后在下一次调用的时候，将之前的消息传递给 AI。</p> 
<p>为了方便处理历史消息，<code>langchain</code> 提供了 <code>ConversationBufferWindowMemory</code> 这个工具，可以帮助我们保存历史消息，并在超过指定数量的时候删除最早的消息。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/01aa7a4ab4ee29c97aa3d5b317a0cb34/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">数据挖掘-数据预处理</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/839b230ed3d10a7c018b03486fd77ac0/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【Python】Pandas简要教程</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>