<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Spark概述及Scala搭建操作步骤 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/504ce31b6b44ffea58a3b635da29808d/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="Spark概述及Scala搭建操作步骤">
  <meta property="og:description" content="目录
一：Spark概述
a：定义
b:创始和服务公司
c:spark发展历史
二：spark特点
三.认识spark的生态圈
a.定义：
b.spark生态圈中重要组件的简要介绍：
四.spark作业工作运行流程
五.spark核心数据RDD
六.Scala
a.定义
b.scala特性
七:spark部署与安装：
搭建Hadoop伪分布式集群：
d.搭建完全分布式集群。
八.scala搭建
在Linux和macOS系统上安装Scala https://www.scala-lang.org/html(1)上传并解压安装scala安装包
在Windows系统上安装Scala https://www.scala-lang.org/html
spark对比MapReduce框架
spark内置模块
图解Scala和Java的关系
一：Spark概述 a：定义 spark是一种基于内存的快速，通用，可扩展的大数据分析计算引擎。
b:创始和服务公司 是加州大学伯克利分校AMP实验室（Algorithms, Machines, and People Lab）开发的通用内存并行计算框架Spark得到了众多大数据公司的支持，这些公司包括Hortonworks、IBM、Intel、Cloudera、MapR、Pivotal、百度、阿里、腾讯、京东、携程、优酷土豆。当前百度的Spark已应用于大搜索、直达号、百度大数据等业务；阿里利用GraphX构建了大规模的图计算和图挖掘系统，实现了很多生产系统的推荐算法；腾讯Spark集群达到8000台的规模，是当前已知的世界上最大的Spark集群。
c:spark发展历史 1、2009年，Spark诞生于伯克利大学AMPLab，属于伯克利大学的研究性项目；
2、2010 年，通过BSD 许可协议正式对外开源发布；
3、2012年，Spark第一篇论文发布，第一个正式版（Spark 0.6.0）发布；
4、2013年，成为了Aparch基金项目；发布Spark Streaming、Spark Mllib（机器学习）、Shark（Spark on Hadoop）；
5、2014 年，Spark 成为 Apache 的顶级项目； 5 月底 Spark1.0.0 发布；发布 Spark Graphx（图计算）、Spark SQL代替Shark；
6、2015年，推出DataFrame（大数据分析）；2015年至今，Spark在国内IT行业变得愈发火爆，大量的公司开始重点部署或者使用Spark来替代MapReduce、Hive、Storm等传统的大数据计算框架；
7、2016年，推出dataset（更强的数据分析手段）；
8、2017年，structured streaming 发布；
9、2018年，Spark2.4.0发布，成为全球最大的开源项目。
而后spark的发展主要针对spark的可用性、稳定性进行改进，并持续进行润色代码。
二：spark特点 1.快速：逻辑回归算法一般需要多次迭代。分别使用Hadoop，mapreduce,spark运行逻辑回归算法。spark的运行速度是Hadoop mapreduce运行速度的100多倍，spark在内存中运行速度是Hadoop mapreduce运行速度的100多倍，spark在磁盘上的运行速度是Hadoop mapreduce运行速度的10多倍。">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-03-07T18:28:03+08:00">
    <meta property="article:modified_time" content="2024-03-07T18:28:03+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Spark概述及Scala搭建操作步骤</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p id="main-toc"><strong>目录</strong></p> 
<p id="%E4%B8%80%EF%BC%9ASpark%E6%A6%82%E8%BF%B0-toc" style="margin-left:0px;"><a href="#%E4%B8%80%EF%BC%9ASpark%E6%A6%82%E8%BF%B0" rel="nofollow">一：Spark概述</a></p> 
<p id="a%EF%BC%9A%E5%AE%9A%E4%B9%89-toc" style="margin-left:40px;"><a href="#a%EF%BC%9A%E5%AE%9A%E4%B9%89" rel="nofollow">a：定义</a></p> 
<p id="b%3A%E5%88%9B%E5%A7%8B%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%85%AC%E5%8F%B8-toc" style="margin-left:40px;"><a href="#b%3A%E5%88%9B%E5%A7%8B%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%85%AC%E5%8F%B8" rel="nofollow">b:创始和服务公司</a></p> 
<p id="c%3Aspark%E5%8F%91%E5%B1%95%E5%8E%86%E5%8F%B2-toc" style="margin-left:40px;"><a href="#c%3Aspark%E5%8F%91%E5%B1%95%E5%8E%86%E5%8F%B2" rel="nofollow">c:spark发展历史</a></p> 
<p id="%E4%BA%8C%EF%BC%9Aspark%E7%89%B9%E7%82%B9-toc" style="margin-left:0px;"><a href="#%E4%BA%8C%EF%BC%9Aspark%E7%89%B9%E7%82%B9" rel="nofollow">二：spark特点</a></p> 
<p id="%E4%B8%89.%E8%AE%A4%E8%AF%86spark%E7%9A%84%E7%94%9F%E6%80%81%E5%9C%88-toc" style="margin-left:0px;"><a href="#%E4%B8%89.%E8%AE%A4%E8%AF%86spark%E7%9A%84%E7%94%9F%E6%80%81%E5%9C%88" rel="nofollow">三.认识spark的生态圈</a></p> 
<p id="a.%E5%AE%9A%E4%B9%89%EF%BC%9A-toc" style="margin-left:40px;"><a href="#a.%E5%AE%9A%E4%B9%89%EF%BC%9A" rel="nofollow">a.定义：</a></p> 
<p id="b.spark%E7%94%9F%E6%80%81%E5%9C%88%E4%B8%AD%E9%87%8D%E8%A6%81%E7%BB%84%E4%BB%B6%E7%9A%84%E7%AE%80%E8%A6%81%E4%BB%8B%E7%BB%8D%EF%BC%9A-toc" style="margin-left:40px;"><a href="#b.spark%E7%94%9F%E6%80%81%E5%9C%88%E4%B8%AD%E9%87%8D%E8%A6%81%E7%BB%84%E4%BB%B6%E7%9A%84%E7%AE%80%E8%A6%81%E4%BB%8B%E7%BB%8D%EF%BC%9A" rel="nofollow">b.spark生态圈中重要组件的简要介绍：</a></p> 
<p id="%E5%9B%9B.spark%E4%BD%9C%E4%B8%9A%E5%B7%A5%E4%BD%9C%E8%BF%90%E8%A1%8C%E6%B5%81%E7%A8%8B-toc" style="margin-left:0px;"><a href="#%E5%9B%9B.spark%E4%BD%9C%E4%B8%9A%E5%B7%A5%E4%BD%9C%E8%BF%90%E8%A1%8C%E6%B5%81%E7%A8%8B" rel="nofollow">四.spark作业工作运行流程</a></p> 
<p id="%E4%BA%94.spark%E6%A0%B8%E5%BF%83%E6%95%B0%E6%8D%AERDD-toc" style="margin-left:0px;"><a href="#%E4%BA%94.spark%E6%A0%B8%E5%BF%83%E6%95%B0%E6%8D%AERDD" rel="nofollow">五.spark核心数据RDD</a></p> 
<p id="%E5%85%AD.Scala-toc" style="margin-left:0px;"><a href="#%E5%85%AD.Scala" rel="nofollow">六.Scala</a></p> 
<p id="a.%E5%AE%9A%E4%B9%89-toc" style="margin-left:40px;"><a href="#a.%E5%AE%9A%E4%B9%89" rel="nofollow">a.定义</a></p> 
<p id="b.scala%E7%89%B9%E6%80%A7-toc" style="margin-left:40px;"><a href="#b.scala%E7%89%B9%E6%80%A7" rel="nofollow">b.scala特性</a></p> 
<p id="%E4%B8%83%3Aspark%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%AE%89%E8%A3%85%EF%BC%9A-toc" style="margin-left:0px;"><a href="#%E4%B8%83%3Aspark%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%AE%89%E8%A3%85%EF%BC%9A" rel="nofollow">七:spark部署与安装：</a></p> 
<p id="%E6%90%AD%E5%BB%BAHadoop%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%EF%BC%9A-toc" style="margin-left:40px;"><a href="#%E6%90%AD%E5%BB%BAHadoop%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%EF%BC%9A" rel="nofollow">搭建Hadoop伪分布式集群：</a></p> 
<p id="d.%E6%90%AD%E5%BB%BA%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E3%80%82-toc" style="margin-left:40px;"><a href="#d.%E6%90%AD%E5%BB%BA%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E3%80%82" rel="nofollow">d.搭建完全分布式集群。</a></p> 
<p id="%E5%85%AB.scala%E6%90%AD%E5%BB%BA-toc" style="margin-left:0px;"><a href="#%E5%85%AB.scala%E6%90%AD%E5%BB%BA" rel="nofollow">八.scala搭建</a></p> 
<p id="%E5%9C%A8Linux%E5%92%8CmacOS%E7%B3%BB%E7%BB%9F%E4%B8%8A%E5%AE%89%E8%A3%85Scala%C2%A0%C2%A0https%3A%2F%2Fwww.scala-lang.org%2Fhtml(1)%E4%B8%8A%E4%BC%A0%E5%B9%B6%E8%A7%A3%E5%8E%8B%E5%AE%89%E8%A3%85scala%E5%AE%89%E8%A3%85%E5%8C%85-toc" style="margin-left:40px;"><a href="#%E5%9C%A8Linux%E5%92%8CmacOS%E7%B3%BB%E7%BB%9F%E4%B8%8A%E5%AE%89%E8%A3%85Scala%C2%A0%C2%A0https%3A%2F%2Fwww.scala-lang.org%2Fhtml%281%29%E4%B8%8A%E4%BC%A0%E5%B9%B6%E8%A7%A3%E5%8E%8B%E5%AE%89%E8%A3%85scala%E5%AE%89%E8%A3%85%E5%8C%85" rel="nofollow">在Linux和macOS系统上安装Scala  https://www.scala-lang.org/html(1)上传并解压安装scala安装包</a></p> 
<p id="%E5%9C%A8Windows%E7%B3%BB%E7%BB%9F%E4%B8%8A%E5%AE%89%E8%A3%85Scala%C2%A0%20%C2%A0%C2%A0https%3A%2F%2Fwww.scala-lang.org%2Fhtml-toc" style="margin-left:40px;"><a href="#%E5%9C%A8Windows%E7%B3%BB%E7%BB%9F%E4%B8%8A%E5%AE%89%E8%A3%85Scala%C2%A0%20%C2%A0%C2%A0https%3A%2F%2Fwww.scala-lang.org%2Fhtml" rel="nofollow">在Windows系统上安装Scala    https://www.scala-lang.org/html</a></p> 
<p id="spark%E5%AF%B9%E6%AF%94MapReduce%E6%A1%86%E6%9E%B6-toc" style="margin-left:0px;"><a href="#spark%E5%AF%B9%E6%AF%94MapReduce%E6%A1%86%E6%9E%B6" rel="nofollow">spark对比MapReduce框架</a></p> 
<p id="spark%E5%86%85%E7%BD%AE%E6%A8%A1%E5%9D%97-toc" style="margin-left:0px;"><a href="#spark%E5%86%85%E7%BD%AE%E6%A8%A1%E5%9D%97" rel="nofollow">spark内置模块</a></p> 
<p id="%E5%9B%BE%E8%A7%A3Scala%E5%92%8CJava%E7%9A%84%E5%85%B3%E7%B3%BB-toc" style="margin-left:80px;"><a href="#%E5%9B%BE%E8%A7%A3Scala%E5%92%8CJava%E7%9A%84%E5%85%B3%E7%B3%BB" rel="nofollow">图解Scala和Java的关系</a></p> 
<hr id="hr-toc"> 
<p></p> 
<h2><strong>一：Spark概述</strong></h2> 
<h3 id="a%EF%BC%9A%E5%AE%9A%E4%B9%89"><strong>a：定义</strong></h3> 
<p>spark是一种基于内存的快速，通用，可扩展的大数据分析计算引擎。</p> 
<h3 id="b%3A%E5%88%9B%E5%A7%8B%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%85%AC%E5%8F%B8"><strong>b:创始和服务公司</strong></h3> 
<p>是加州大学伯克利分校AMP实验室（Algorithms, Machines, and People Lab）开发的通用内存并行计算框架Spark得到了众多大数据公司的支持，这些公司包括Hortonworks、IBM、Intel、Cloudera、MapR、Pivotal、百度、阿里、腾讯、京东、携程、优酷土豆。当前百度的Spark已应用于大搜索、直达号、百度大数据等业务；阿里利用GraphX构建了大规模的图计算和图挖掘系统，实现了很多生产系统的推荐算法；腾讯Spark集群达到8000台的规模，是当前已知的世界上最大的Spark集群。</p> 
<h3 id="c%3Aspark%E5%8F%91%E5%B1%95%E5%8E%86%E5%8F%B2"><strong>c:spark发展历史</strong></h3> 
<p>1、<strong>2009年</strong>，Spark诞生于伯克利大学AMPLab，属于伯克利大学的研究性项目；</p> 
<p>2、<strong>2010 年</strong>，通过BSD 许可协议正式对外开源发布；</p> 
<p>3、<strong>2012年</strong>，Spark第一篇论文发布，第一个正式版（Spark 0.6.0）发布；</p> 
<p>4、<strong>2013年</strong>，成为了Aparch基金项目；发布Spark Streaming、Spark Mllib（机器学习）、Shark（Spark on Hadoop）；</p> 
<p>5、<strong>2014 年</strong>，Spark 成为 Apache 的顶级项目； 5 月底 Spark1.0.0 发布；发布 Spark Graphx（<a href="https://cloud.tencent.com/product/tkg?from_column=20065&amp;from=20065" rel="nofollow" title="图计算">图计算</a>）、Spark SQL代替Shark；</p> 
<p>6、<strong>2015年</strong>，推出DataFrame（大数据分析）；2015年至今，Spark在国内IT行业变得愈发火爆，大量的公司开始重点部署或者使用Spark来替代MapReduce、Hive、Storm等传统的大数据计算框架；</p> 
<p>7、<strong>2016年</strong>，推出dataset（更强的数据分析手段）；</p> 
<p>8、<strong>2017年</strong>，structured streaming 发布；</p> 
<p>9、<strong>2018年</strong>，Spark2.4.0发布，成为全球最大的开源项目。</p> 
<p>而后spark的发展主要针对spark的可用性、稳定性进行改进，并持续进行润色代码。</p> 
<h2 id="%E4%BA%8C%EF%BC%9Aspark%E7%89%B9%E7%82%B9">二：spark特点</h2> 
<p>1.快速：逻辑回归算法一般需要多次迭代。分别使用Hadoop，mapreduce,spark运行逻辑回归算法。spark的运行速度是Hadoop mapreduce运行速度的100多倍，spark在内存中运行速度是Hadoop mapreduce运行速度的100多倍，spark在磁盘上的运行速度是Hadoop mapreduce运行速度的10多倍。</p> 
<p>2.易用：Spark的版本已经更新到了Spark3.1.2（截止日期2021.06.01），支持了包括Java、Scala、Python、R和SQL语言在内的多种语言。为了兼容Spark2.x企业级应用场景，Spark仍然持续更新Spark2版本。</p> 
<p>3.通用：在Spark的基础上，Spark还提供了包括Spark SQL、Spark Streaming、MLib及GraphX在内的多个工具库，我们可以在一个应用中无缝的使用这些工具库。</p> 
<p>4.随处运行：用户可以使用spark的独立集群模式运行spark，也可以在亚马逊弹性计算云，Hadoop yarn 资源管理器或apache mesos上运行spark。spark作为一个分布式计算框架，本身并没有存储功能，但是spark可以从hdfs,cassandra,hbase,hive,alluxio等数据源中读取数据。</p> 
<p>5.代码简洁：spark支持使用Scala、python等语言编写代码。Scala和python的代码相对Java的代码而言相对简洁。</p> 
<h2 id="%E4%B8%89.%E8%AE%A4%E8%AF%86spark%E7%9A%84%E7%94%9F%E6%80%81%E5%9C%88">三.认识spark的生态圈</h2> 
<h3 id="a.%E5%AE%9A%E4%B9%89%EF%BC%9A">a.定义：</h3> 
<p>现在Apache Spark已经形成一个丰富的生态圈，包括官方和第三方开发的组件或工具。Spark生态圈也称为伯克利数据分析栈，由AMPLab打造，是致力于在算法，机器，人之间通过大规模集成展现大数据应用的平台。</p> 
<h3 id="b.spark%E7%94%9F%E6%80%81%E5%9C%88%E4%B8%AD%E9%87%8D%E8%A6%81%E7%BB%84%E4%BB%B6%E7%9A%84%E7%AE%80%E8%A6%81%E4%BB%8B%E7%BB%8D%EF%BC%9A">b.spark生态圈中重要组件的简要介绍：</h3> 
<p>1.Spark Core：spark的核心，提供底层框架及核心支持。</p> 
<p>2.BlinkDB:一个用于在海量数据上进行交互式SQL查询的大规模并进行查询引擎，允许用户通过权衡数据精度缩短查询响应时间，数据的精度将被控制在允许的误差范围内。</p> 
<p>3.spark SQL：应用于数据查询,数据存储.Spark SQL可以对接Hive,实现Spark查询Hive仓库数据的功能,底层走的是Spark core.</p> 
<p>4.Spark Streaming：可以进行实时数据流式计算。</p> 
<p>5.MLbase:MLbase是Spark生态圈的一部分，专注于机器学习领域，学习门槛较低。</p> 
<p>6.GraphX:图计算的应用在很多情况下处理的数据量都是很庞大的。</p> 
<p>7.SparkR:SparkR是AMPLab发布的一个R语言开发包，使得R语言编写的程序不只可以在单机运行，也可以作为spark的作业运行在集群上，极大地提升R语言的数据处理能力。</p> 
<h2 id="%E5%9B%9B.spark%E4%BD%9C%E4%B8%9A%E5%B7%A5%E4%BD%9C%E8%BF%90%E8%A1%8C%E6%B5%81%E7%A8%8B">四.spark作业工作运行流程</h2> 
<p>三种运行模式：Standalone、YARN、Mesos.,在Mesos模式和 YARN模式下，Spark作业的运行流程类似</p> 
<p>Standalone模式是spark自带的资源管理器。在Standalone模式下，Driver既可以运行在主节点上，也可以运行在本地客户端上。</p> 
<p>YARN：在YARN模式下有两种运行方式：Driver运行在集群NodeManager和Driver运行在客户端。</p> 
<h2 id="%E4%BA%94.spark%E6%A0%B8%E5%BF%83%E6%95%B0%E6%8D%AERDD">五.spark核心数据RDD</h2> 
<p>弹性分布式数据集是spark中非常重要的概念，可以简单地理解成一个提供了许多操作接口的数据集合。<strong>RDD是spark core的底层核心</strong>。</p> 
<p>RDD支持两种数据的操作，分别为转换操作和行动操作，也称为转换算子和行动算子。</p> 
<p>转换操作主要是指将原始数据集加载为RDD数据或将一个RDD转换为另一个RDD的操作。</p> 
<p>行动操作主要指将RDD存储至硬盘中或触发转换操作一个新的RDD作为结果。</p> 
<p>窄依赖是指子RDD的一个分区只依赖于某个父RDD中的一个分区。</p> 
<p>宽依赖是指子RDD的每一个分区都依赖于某个父RDD中的一个以上的分区。</p> 
<h2 id="%E5%85%AD.Scala">六.Scala</h2> 
<h3 id="a.%E5%AE%9A%E4%B9%89">a.定义</h3> 
<p><span style="color:#000000;">Scala是</span><span style="color:#000000;">Scalable Language</span><span style="color:#000000;">的缩写，是一种多范式的编程语言，由洛桑联邦理工学院的马丁</span><span style="color:#000000;">·</span><span style="color:#000000;">奥德斯在</span><span style="color:#000000;">2001</span><span style="color:#000000;">年基于</span><span style="color:#000000;">Funnel</span><span style="color:#000000;">的工作开始设计，设计初衷是想集成面向对象编程和函数式编程的各种特性。</span></p> 
<p><span style="color:#000000;">Scala 是一种纯粹的面向对象的语言，每个值都是对象。</span></p> 
<p><span style="color:#000000;">Scala</span><span style="color:#000000;">也是一种函数式语言，因此函数可以当成值使用。</span></p> 
<p><span style="color:#000000;">由于Scala</span><span style="color:#000000;">整合了面向对象编程和函数式编程的特性，因此</span><span style="color:#000000;">Scala</span><span style="color:#000000;">相对于</span><span style="color:#000000;">Java</span><span style="color:#000000;">、</span><span style="color:#000000;">C#</span><span style="color:#000000;">、</span><span style="color:#000000;">C++</span><span style="color:#000000;">等其他语言更加简洁。</span></p> 
<p><span style="color:#000000;">Scala源代码会被编译成</span><span style="color:#000000;">Java</span><span style="color:#000000;">字节码，因此</span><span style="color:#000000;">Scala</span><span style="color:#000000;">可以运行于</span><span style="color:#000000;">Java</span><span style="color:#000000;">虚拟机（</span><span style="color:#000000;">Java Virtual Machine</span><span style="color:#000000;">，</span><span style="color:#000000;">JVM</span><span style="color:#000000;">）之上，并可以调用现有的</span><span style="color:#000000;">Java</span><span style="color:#000000;">类库。</span></p> 
<h3 id="b.scala%E7%89%B9%E6%80%A7"><span style="color:#000000;">b.scala特性</span></h3> 
<p><span style="color:#000000;">面向对象、函数式编程、静态类型 、可扩展。</span></p> 
<h2 id="%E4%B8%83%3Aspark%E9%83%A8%E7%BD%B2%E4%B8%8E%E5%AE%89%E8%A3%85%EF%BC%9A"><span style="color:#000000;">七:spark部署与安装：</span></h2> 
<p>spark搭建需要在Hadoop集群上面搭建，如果搭建单机版集群需要在Hadoop伪分布式环境的基础上进行搭建，判断spark是否搭建好需要查看进程是否有Master进程和Work进程。如果要搭建完全分布式集群则需要在Hadoop完全分布式集群的基础下进行搭建。<span style="color:#fe2c24;"><strong>本文将进行完全分布式集群的部署与安装。</strong></span></p> 
<h3 id="%E6%90%AD%E5%BB%BAHadoop%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%EF%BC%9A"><span style="color:#fe2c24;"><strong>搭建Hadoop伪分布式集群：</strong></span></h3> 
<p><span style="color:#a2e043;">卸载电脑自带jdk</span><br> 查看 rpm -qa | grep java<br> rpm -e --nodeps + 已装java版本 <br> java -version （查看是否删除成功） </p> 
<p><span style="color:#a2e043;"><strong>安装jdk操作步骤</strong></span><br><strong>tar zxvf /root/Downloads/jdk-8u171-linux-x64.tar.gz -C /opt/<br> vim /etc/profile<br> export JAVA_HOME=/opt/jdk1.8.0_171<br> export PATH=$PATH:$JAVA_HOME/bin<br> java -version</strong><br><span style="color:#a2e043;"><strong>安装hadoop操作步骤</strong></span><br><strong>tar zxvf /root/Downloads/hadoop-2.7.5.tar.gz -C /opt/<br> export HADOOP_HOME=/opt/hadoop-2.7.5<br> export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin<br> source /etc/profile<br> hadoop<br> hadoop version</strong><br><span style="color:#a2e043;"><strong>ssh免密登录</strong></span><br><strong>ifconfig查询ip地址<br> ssh-keygen<br> ssh-copy-id ip地址<br> ssh ip地址</strong></p> 
<p><span style="color:#a2e043;"><strong>配置hadoop文件</strong></span><br><strong>vim /opt/hadoop-2.7.5/etc/hadoop/core-site.xml<br> &lt;configuration&gt;<br> &lt;property&gt;<br> &lt;name&gt;ds.defaultFS&lt;/name&gt;<br> &lt;value&gt;://192.168.67.128:9000&lt;/value&gt;<br> &lt;/property&gt;<br> &lt;property&gt;<br> &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;<br> &lt;value&gt;file:/opt/hadoop-2.7.5/tmp&lt;/value&gt;<br> &lt;/property&gt;<br> &lt;/configuration&gt;</strong></p> 
<p><strong>vim /opt/hadoop-2.7.5/etc/hadoop/hadoop-env.sh<br> export JAVA_HOME=/opt/jdk1.8.0_171</strong></p> 
<p><strong>vim /opt/hadoop-2.7.5/etc/hadoop/hdfs-site.xml<br> &lt;configuration&gt;<br> &lt;property&gt;<br> &lt;name&gt;dfs.replication&lt;/name&gt;<br> &lt;value&gt;1&lt;/value&gt;<br> &lt;/property&gt;<br> &lt;property&gt;<br> &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;<br> &lt;value&gt;file:/opt/hadoop-2.7.5/tmp/dfs/name&lt;/value&gt;<br> &lt;/property&gt;<br> &lt;property&gt;<br> &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;<br> &lt;value&gt;file:/opt/hadoop-2.7.5/tmp/dfs/data&lt;/value&gt;<br> &lt;/property&gt;<br> &lt;/configuration&gt;</strong><br><span style="color:#a2e043;"><strong>格式化 </strong></span><br><strong>cd /opt/hadoop-2.7.5/bin<br> hdfs namenode -format<br> cd  /opt/hadoop-2.7.5/sbin<br> . /start-all.sh</strong></p> 
<p><span style="color:#a2e043;"><strong>查看进程</strong></span><br><strong>jps</strong></p> 
<p><span style="color:#fe2c24;">判断Hadoop伪分布式集群是否搭建好的依据</span></p> 
<p><span style="color:#0d0016;">datanode,namenode</span></p> 
<p><span style="color:#0d0016;">c.搭建单机版集群</span></p> 
<p><span style="color:#0d0016;">在spark官网选择对应版本的spark安装包并下载至Windows本地路径下。</span></p> 
<p><span style="color:#0d0016;">将spark安装包上传至Linux虚拟机的/opt/目录下</span></p> 
<p><span style="color:#0d0016;">将spark安装包解压至/usr/local目录下。</span></p> 
<h3 id="d.%E6%90%AD%E5%BB%BA%E5%AE%8C%E5%85%A8%E5%88%86%E5%B8%83%E5%BC%8F%E9%9B%86%E7%BE%A4%E3%80%82"><span style="color:#0d0016;">d.搭建完全分布式集群。</span></h3> 
<p style="margin-left:0;">(1)上传并解压安装spark安装包</p> 
<p style="margin-left:0;"><span style="background-color:#dbdbdb;"><a name="df4f-1709650729296"></a><span style="color:#000000;">tar -zxvf / export/ software/ spark-3.0.3-bin-hadoop2.7.tgz </span></span></p> 
<p style="margin-left:0;"><a name="BuKE-1709650628942"></a>（2）设置环境变量</p> 
<p style="margin-left:0;"><span style="background-color:#dbdbdb;"><a name="OTSP-1709650743100"></a><span style="color:#000000;">vim /etc/profile</span></span></p> 
<p style="margin-left:0;"><a name="Egh2-1709650628946"></a>#SPARK</p> 
<p style="margin-left:0;"><a name="X7Ke-1709650628950"></a>export SPARK_HOME=/usr/local/soft/spark-3.0.3</p> 
<p style="margin-left:0;"><a name="73Hh-1709650628952"></a>export PATH=$PATH:${SPARK_HOME}/bin</p> 
<p style="margin-left:0;"><a name="OCti-1709650628954"></a>export PATH=$PATH:${SPARK_HOME}/sbin</p> 
<p style="margin-left:0;"><a name="566G-1709650780494"></a></p> 
<p style="margin-left:0;"><a name="GlRh-1709650782808"></a><img alt="" height="114" src="https://images2.imgbox.com/ee/c4/OabQtFPs_o.png" width="576"></p> 
<p style="margin-left:0;"><a name="L6pR-1709650830073"></a></p> 
<p style="margin-left:0;"><span style="background-color:#dbdbdb;"><a name="Ix9f-1709650830071"></a><span style="color:#000000;">source /etc/profile</span><span style="color:#000000;">使环境变量生效</span></span></p> 
<p style="margin-left:0;"><a name="p7Cz-1709650805413"></a>（3）修改配置文件.</p> 
<p style="margin-left:0;"><a name="x5J7-1709650806649"></a>cd spark/ conf/</p> 
<p style="margin-left:0;"><a name="wYd2-1709650806651"></a>先备份文件cp spark env.sh.template spark env.sh</p> 
<p style="margin-left:0;"><a name="v1WO-1709650806653"></a>cp slaves. template slaves</p> 
<p style="margin-left:0;"><span style="background-color:#dbdbdb;"><a name="NBaU-1709651352817"></a><span style="color:#000000;">vim spark-env.sh</span></span></p> 
<p style="margin-left:0;"><a name="zgzc-1709650868323"></a></p> 
<p style="margin-left:0;"><a name="FCVn-1709650870084"></a><img alt="" height="226" src="https://images2.imgbox.com/d6/8b/xJ1vqNQ4_o.png" width="890"></p> 
<p style="margin-left:0;"><a name="asz2-1709650870088"></a>加一些环境变量:</p> 
<p style="margin-left:0;"><a name="ioQD-1709651006426"></a>修改spark- env.sh文件，加以下内容:</p> 
<p style="margin-left:0;"><span style="background-color:#dbdbdb;"><span style="color:#000000;">export SCALA_HOME=/usr/local/soft/scala-2.12.12</span></span></p> 
<p style="margin-left:0;"><span style="background-color:#dbdbdb;"><span style="color:#000000;">export JAVA_HOME=/usr/local/soft/jdk1.8.0_202</span></span></p> 
<p style="margin-left:0;"><span style="background-color:#dbdbdb;"><span style="color:#000000;">export SPARK_MASTER_IP=master</span></span></p> 
<p style="margin-left:0;"><span style="background-color:#dbdbdb;"><span style="color:#000000;">export SPARK_WOKER_CORES=2</span></span></p> 
<p style="margin-left:0;"><span style="background-color:#dbdbdb;"><span style="color:#000000;">export SPARK_WOKER_MEMORY=2g</span></span></p> 
<p style="margin-left:0;"><span style="background-color:#dbdbdb;"><span style="color:#000000;">export HADOOP_CONF_DIR=/usr/local/soft/hadoop-3.1.3/etc/hadoop</span></span></p> 
<p style="margin-left:0;"><span style="background-color:#dbdbdb;"><span style="color:#000000;">#export SPARK_MASTER_WEBUI_PORT=8080</span></span></p> 
<p style="margin-left:0;"><span style="background-color:#dbdbdb;"><a name="Kqjs-1709651343993"></a><span style="color:#000000;">#export SPARK_MASTER_PORT=7070</span></span></p> 
<p style="margin-left:0;"><a name="0Sqi-1709651017928"></a></p> 
<p style="margin-left:0;"><a name="VBAm-1709651021130"></a><img alt="" height="233" src="https://images2.imgbox.com/0d/5c/xzpC7ZzN_o.png" width="865"></p> 
<p style="margin-left:0;"><a name="0iJa-1709651021133"></a>修改从节点ip</p> 
<p style="margin-left:0;"><a name="Rw81-1709651029596"></a>   vi slaves 修改内容为slave1 slave2(我的子机分别为是slave1 slave2)</p> 
<p style="margin-left:0;"><a name="UPo3-1709651041900"></a></p> 
<p style="margin-left:0;"><a name="Ptqy-1709651043159"></a><img alt="" height="114" src="https://images2.imgbox.com/fe/2b/aOwDV1Md_o.png" width="865"></p> 
<p style="margin-left:0;"><a name="HpcM-1709651043162"></a>(4)分发文件</p> 
<p style="margin-left:0;"><span style="background-color:#dbdbdb;"><span style="color:#000000;">scp -r /usr/local/soft/spark-3.0.3/ slave1:/usr/local/soft/</span></span></p> 
<p style="margin-left:0;"><span style="background-color:#dbdbdb;"><a name="0Svr-1709651578965"></a><span style="color:#000000;">scp -r /usr/local/soft/spark-3.0.3/ slave2:/usr/local/soft/</span></span></p> 
<p style="margin-left:0;"><a name="5E0q-1709651055122"></a>(5)分别在slave1 slave2上设置环境变量</p> 
<p style="margin-left:0;"><span style="background-color:#dbdbdb;"><a name="6csd-1709651604256"></a><span style="color:#000000;">vim /etc/profile</span></span></p> 
<p style="margin-left:0;"><a name="ixjO-1709651055126"></a>#SPARK</p> 
<p style="margin-left:0;"><a name="KeGk-1709651055128"></a>export SPARK_HOME=/usr/local/soft/spark-3.0.3</p> 
<p style="margin-left:0;"><a name="YqhL-1709651587094"></a>export PATH=$PATH:${SPARK_HOME}/binexport               PATH=$PATH:${SPARK_HOME}/sbin</p> 
<p style="margin-left:0;"><a name="gNiE-1709651067170"></a><img alt="" height="114" src="https://images2.imgbox.com/6e/db/KwdKCwyV_o.png" width="576"></p> 
<p style="margin-left:0;"><a name="1cU8-1709652043569"></a></p> 
<p style="margin-left:0;"><span style="background-color:#dbdbdb;"><a name="phDr-1709652043567"></a><span style="color:#000000;">source /etc/profile</span><span style="color:#000000;">使环境变量生效</span></span></p> 
<p style="margin-left:0;"><a name="IKKX-1709651102464"></a>(6)启动集群：spark目录下：./start-all.sh</p> 
<p style="margin-left:0;"><a name="fvKP-1709651112535"></a></p> 
<p style="margin-left:0;"><a name="Af2o-1709651118189"></a><img alt="" height="91" src="https://images2.imgbox.com/26/4f/bcheO8ZQ_o.png" width="951"></p> 
<p style="margin-left:0;"><a name="r07b-1709651118193"></a>查看节点：</p> 
<p style="margin-left:0;"><a name="715m-1709651132636"></a>Master:</p> 
<p style="margin-left:0;"><a name="HGAN-1709651137983"></a></p> 
<p style="margin-left:0;"><a name="IS25-1709651141206"></a><img alt="" height="171" src="https://images2.imgbox.com/e6/55/N3VU8jan_o.png" width="544"></p> 
<p style="margin-left:0;"><a name="ENPU-1709651141209"></a>Slave1：</p> 
<p style="margin-left:0;"><a name="5wSK-1709651249462"></a></p> 
<p style="margin-left:0;"><a name="1kNN-1709651250503"></a><img alt="" height="171" src="https://images2.imgbox.com/fb/e0/QLm05TPz_o.png" width="390"></p> 
<p style="margin-left:0;"><a name="3yQ1-1709651250507"></a>Scala2：</p> 
<p style="margin-left:0;"><a name="dP3Z-1709651259070"></a><img alt="" height="171" src="https://images2.imgbox.com/d7/23/6vhVPtG9_o.png" width="390"></p> 
<p style="margin-left:0;"><a name="c9Eh-1709651259074"></a>在主节点master上出现Master 在s1上出现Worker在s2上出现Worker</p> 
<p style="margin-left:0;"><a name="mYtp-1709651301354"></a></p> 
<p style="margin-left:0;"><a name="lrnt-1709651301356"></a>Spark-shell</p> 
<p style="margin-left:0;"><a name="QNQQ-1709651306646"></a></p> 
<p style="margin-left:0;"><a name="TUQX-1709651308235"></a><img alt="" height="216" src="https://images2.imgbox.com/e9/e8/5tYtQeQl_o.png" width="952"></p> 
<p style="margin-left:0;"><a name="PWKY-1709651308239"></a>浏览器查看192.168.10.100:8080</p> 
<p style="margin-left:0;"><a name="IKvI-1709651319960"></a></p> 
<p style="margin-left:0;"><a name="5qt8-1709651321256"></a><img alt="" height="505" src="https://images2.imgbox.com/9d/ae/7DB2fQLy_o.png" width="950"></p> 
<h2 id="%E5%85%AB.scala%E6%90%AD%E5%BB%BA">八.scala搭建</h2> 
<h3 id="%E5%9C%A8Linux%E5%92%8CmacOS%E7%B3%BB%E7%BB%9F%E4%B8%8A%E5%AE%89%E8%A3%85Scala%C2%A0%C2%A0https%3A%2F%2Fwww.scala-lang.org%2Fhtml(1)%E4%B8%8A%E4%BC%A0%E5%B9%B6%E8%A7%A3%E5%8E%8B%E5%AE%89%E8%A3%85scala%E5%AE%89%E8%A3%85%E5%8C%85" style="margin-left:0in;text-align:left;"><span style="color:#000000;">在</span><span style="color:#000000;">Linux</span><span style="color:#000000;">和</span><span style="color:#000000;">macOS</span><span style="color:#000000;">系统上安装Scala  </span><a class="link-info" href="https://www.scala-lang.org/" rel="nofollow" title="https://www.scala-lang.org/html">https://www.scala-lang.org/html</a><br> (1)上传并解压安装scala安装包</h3> 
<p style="margin-left:0;"><span style="background-color:#dbdbdb;"><a name="5HgE-1709650403631"></a><span style="color:#000000;">tar -zxvf scala-2.2.12.12.tgz</span></span></p> 
<p style="margin-left:0;"><a name="LkKS-1709650403634"></a></p> 
<p style="margin-left:0;"><a name="2yQL-1709650358686"></a><img alt="" height="52" src="https://images2.imgbox.com/84/bf/fAZEFmoC_o.png" width="864"></p> 
<p style="margin-left:0;"><a name="90wP-1709649748766"></a>（2）设置环境变量</p> 
<p style="margin-left:0;"><span style="background-color:#dbdbdb;"><a name="mJGr-1709650413337"></a><span style="color:#000000;">vim /etc/profile</span></span></p> 
<p style="margin-left:0;"><a name="vNih-1709650384404"></a>#SCALA</p> 
<p style="margin-left:0;"><a name="adDz-1709650384406"></a>export SCALA_HOME=/usr/local/soft/scala-2.12.12</p> 
<p style="margin-left:0;"><a name="2faB-1709650384408"></a>export PATH=$PATH:${SCALA_HOME}/bin</p> 
<p style="margin-left:0;"><a name="20tW-1709650439289"></a></p> 
<p style="margin-left:0;"><a name="k373-1709650440895"></a><img alt="" height="92" src="https://images2.imgbox.com/14/fd/pLn0e8Qq_o.png" width="804"></p> 
<p style="margin-left:0;"><a name="XarH-1709650484591"></a></p> 
<p style="margin-left:0;"><span style="background-color:#dbdbdb;"><a name="vmBh-1709650484590"></a><span style="color:#000000;">source /etc/profile</span><span style="color:#000000;">使环境变量生效</span></span></p> 
<p style="margin-left:0;"><a name="Q77q-1709650484593"></a>（3）验证scala 启动成功</p> 
<p style="margin-left:0;"><a name="ug7T-1709650528407"></a></p> 
<p style="margin-left:0;"><a name="NHIP-1709650547919"></a><img alt="" height="39" src="https://images2.imgbox.com/0b/0e/si5AJdIm_o.png" width="833"></p> 
<p style="margin-left:0;"><a name="rdW9-1709650547922"></a>scala启动成功</p> 
<h3 id="%E5%9C%A8Windows%E7%B3%BB%E7%BB%9F%E4%B8%8A%E5%AE%89%E8%A3%85Scala%C2%A0%20%C2%A0%C2%A0https%3A%2F%2Fwww.scala-lang.org%2Fhtml" style="margin-left:0px;text-align:center;"><span style="color:#000000;">在Windows系统上安装Scala    </span>https://www.scala-lang.org/html</h3> 
<figure class="image"> 
 <img alt="" src="https://images2.imgbox.com/9e/5d/COZsZKcI_o.png"> 
 <figcaption> 
  <strong>点击allreleases</strong> 
 </figcaption> 
</figure> 
<p style="margin-left:0;"><span style="color:#000000;">从Scala官网下载</span><span style="color:#000000;">Scala</span><span style="color:#000000;">安装包，安装包名称为“</span><span style="color:#000000;">scala.msi</span><span style="color:#000000;">”</span><span style="color:#000000;">。</span></p> 
<figure class="image"> 
 <img alt="" src="https://images2.imgbox.com/3b/c7/eFW9hBRF_o.png"> 
 <figcaption> 
  <strong>点击所需要的版本</strong> 
 </figcaption> 
</figure> 
<p style="text-align:center;"></p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/bf/cb/ibdXFJwo_o.png"></p> 
<p style="margin-left:0;"><span style="color:#000000;">双击scala.msi安装包，开始安装软件。</span></p> 
<p style="margin-left:0;"><span style="color:#000000;">进入欢迎界面，单击右下角的“</span><span style="color:#000000;">Next”</span><span style="color:#000000;">按钮后出现许可协议选择提示框，选择接受许可协议中的条款并单击右下角的“</span><span style="color:#000000;">Next”</span><span style="color:#000000;">按钮。</span></p> 
<p style="margin-left:0;"><span style="color:#000000;">选择安装路径，本文Scala</span><span style="color:#000000;">的安装路径选择在非系统盘的“</span><span style="color:#000000;">D:\Program Files (</span><span style="color:#000000;">x86</span><span style="color:#000000;">)\spark\</span><span style="color:#000000;">scala</span><span style="color:#000000;">\”</span><span style="color:#000000;"> ，单击“OK”按钮进入安装界面。</span><img alt="" height="592" src="https://images2.imgbox.com/5d/96/j4e9ciEc_o.png" width="752"></p> 
<div style="margin-left:.4in;text-align:left;"> 
 <span style="color:#000000;">在安装界面中单击右下角的“</span> 
 <span style="color:#000000;">Install”</span> 
 <span style="color:#000000;">按钮进行安装，安装完成时单击“</span> 
 <span style="color:#000000;">Finish”</span> 
 <span style="color:#000000;">按钮完成安装。</span> 
</div> 
<p style="margin-left:0;"><span style="color:#000000;">右键单击“此电脑”图标，选择“属性”选项，在弹出的窗口中选择“高级系统设置”选项。在弹出的对话框中选择“高级”选项卡，并单击“环境变量”按钮，在环境变量对话框中，选择“</span><span style="color:#000000;">Path”</span><span style="color:#000000;">变量并单击“编辑”按钮，在</span><span style="color:#000000;">Path</span><span style="color:#000000;">变量中添加</span><span style="color:#000000;">Scala</span><span style="color:#000000;">安装目录的</span><span style="color:#000000;">bin</span><span style="color:#000000;">文件夹所在路径，如“</span><span style="color:#000000;">D:\Program Files (</span><span style="color:#000000;">x86</span><span style="color:#000000;">)\spark\</span><span style="color:#000000;">scala</span><span style="color:#000000;">\bin”</span></p> 
<p style="margin-left:0;"><a name="zwjK-1709651321260"></a></p> 
<p><img alt="" src="https://images2.imgbox.com/da/2c/C24bgLIU_o.png"><img alt="" src="https://images2.imgbox.com/99/1f/Bci0IRhg_o.png"></p> 
<p>八.</p> 
<h2 id="spark%E5%AF%B9%E6%AF%94MapReduce%E6%A1%86%E6%9E%B6" style="margin-left:0px;">spark对比MapReduce框架</h2> 
<p style="margin-left:0;"><a name="tdpA-1709649830069"></a></p> 
<p><img alt="" height="473" src="https://images2.imgbox.com/f1/fc/AKT6Qjnu_o.png" width="864"></p> 
<p style="margin-left:0;"><a name="dFsm-1709649708444"></a></p> 
<h2 id="spark%E5%86%85%E7%BD%AE%E6%A8%A1%E5%9D%97" style="margin-left:0;"><a name="HC1d-1709649708446"></a>spark内置模块</h2> 
<p style="margin-left:0;"><a name="wpNs-1709649859613"></a></p> 
<p><img alt="" height="421" src="https://images2.imgbox.com/01/ee/VsHtf7Zq_o.png" width="864"></p> 
<p style="margin-left:0;"><a name="bkWa-1709649708448"></a>Spark Core：实现了Spark的基本功能，包含任务调度、内存管理、错误恢复、与存储系统交互等模块。Spark Core中还包含了对弹性分布式数据集(Resilient Distributed DataSet，简称RDD)的API定义。</p> 
<p style="margin-left:0;"><a name="gtqO-1709649708450"></a>Spark SQL：是Spark用来操作结构化数据的程序包。通过Spark SQL，我们可以使用 SQL或者Apache Hive版本的HQL来查询数据。Spark SQL支持多种数据源，比如Hive表、Parquet以及JSON等。</p> 
<p style="margin-left:0;"><a name="XHMK-1709649708452"></a>Spark Streaming：是Spark提供的对实时数据进行流式计算的组件。提供了用来操作数据流的API，并且与Spark Core中的 RDD API高度对应。</p> 
<p style="margin-left:0;"><a name="tpFD-1709649708454"></a>Spark MLlib：提供常见的机器学习功能的程序库。包括分类、回归、聚类、协同过滤等，还提供了模型评估、数据 导入等额外的支持功能。</p> 
<p style="margin-left:0;"><a name="rrDb-1709649708456"></a>Spark GraphX：主要用于图形并行计算和图挖掘系统的组件。</p> 
<p style="margin-left:0;"><a name="rvEn-1709649708458"></a>集群管理器：Spark设计为可以高效地在一个计算节点到数千个计算节点之间伸缩计算。为了实现这样的要求，同时获得最大灵活性，Spark支持在各种集群管理器(Cluster Manager)上运行，包括Hadoop YARN、Apache Mesos，以及Spark自带的一个简易调度器，叫作独立调度器。</p> 
<h4 id="%E5%9B%BE%E8%A7%A3Scala%E5%92%8CJava%E7%9A%84%E5%85%B3%E7%B3%BB" style="margin-left:0px;">图解Scala和Java的关系</h4> 
<p style="margin-left:0;"><a name="Wlwk-1709652230700"></a></p> 
<p><img alt="" height="486" src="https://images2.imgbox.com/59/e3/Vrkx2E7N_o.png" width="864"></p> 
<p>Hadoop完全分布式搭建代码 </p> 
<p>安装jdk 和hadoop的步骤<br> 1.解压缩<br> jdk:tar zxvf /root/Downloads/jdk-8u171-linux-x64.tar.gz -C /opt/<br> hadoop:tar zxvf /root/Downloads/hadoop-2.7.5.tar.gz -C /opt/</p> 
<p>2.编辑vim命令<br> vim /etc/profile</p> 
<p>3.写入文件<br> export JAVA_HOME=/opt/jdk1.8.0_171<br> export HADOOP_HOME=/opt/hadoop-2.7.5<br> export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</p> 
<p>4.保存写入的文件<br> source /etc/profile</p> 
<p>5.检查版本号<br> jdk：java -version<br> hadoop:hadoop<br>        hadoop version</p> 
<p><br> 配置Hadoop的免密登录<br> 1.ifconfig 查询ip地址 192.168.242.134<br> 2.ssh-keygen <br>   ssh-copy-id IP地址<br>   ssh ip地址</p> 
<p>完全分布式搭建<br> 1.首先克隆两个节点：slave1 slave2<br> 2.修改名称：hostnamectl set-hostname master<br>           hostnamectl set-hostname slave1<br>       hostnamectl set-hostname slave2<br> 3.查询两个节点的ip地址：ifconfig</p> 
<p>返回master</p> 
<p>4.设置免密登录  ssh-keygen</p> 
<p>    1、删除原来使用伪分布式创建的ssh的密码（公钥和私钥）</p> 
<p>        cd ~/.ssh/<br>         <br>         rm id_rsa*  (回车后要加yes)</p> 
<p>    2、删除认证的钥匙</p> 
<p>        rm ./authorized_keys  (回车后要加yes)</p> 
<p>    3、生产新的公钥和私钥<br>         如果没有设置免密登入<br>         则</p> 
<p>        ssh-keygen -t rsa<br>         <br>     4、将公钥当做认证文件进行认证<br>               追加首先要进入（./ssh）    cd ~/.ssh/    <br>             cat ./id_rsa.pub &gt;&gt; ./authorized_keys</p> 
<p>    5、产生的授权后的钥匙要发送给s1和s2节点<br>         #scp 发送命令<br>         scp ./authorized_keys root@slave1:/.ssh<br>         scp ./authorized_keys root@slave2:/.ssh</p> 
<p>        ssh-copy-id slave1的ip<br>         ssh-copy-id slave2的ip</p> 
<p>        ssh-add 启动ssh的服务<br>         ssh slave1的ip/slave2的ip<br> 配置Hadoop的文件</p> 
<p>1.vim /opt/hadoop-2.7.5/etc/hadoop/hadoop-env.sh<br>      export JAVA_HOME=/opt/jdk1.8.0_171</p> 
<p>2.vim /opt/hadoop-2.7.5/etc/hadoop/core-site.xml<br> &lt;property&gt;<br>              &lt;name&gt;fs.defaultFS&lt;/name&gt;<br>              &lt;value&gt;hdfs://master:9000&lt;/value&gt;<br>     &lt;/property&gt;<br>     &lt;property&gt;<br>          &lt;name&gt;io.file.buffer.size&lt;/name&gt;<br>          &lt;value&gt;131072&lt;/value&gt;<br>      &lt;/property&gt;<br>     &lt;property&gt;<br>         &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;<br>         &lt;value&gt;file:/opt/hadoop-2.7.5/tmp&lt;/value&gt;<br>     &lt;/property&gt;<br> 3.vim /opt/hadoop-2.7.5/etc/hadoop/hdfs-site.xml<br> &lt;property&gt;<br>         &lt;name&gt;dfs.replication&lt;/name&gt;<br>         &lt;value&gt;3&lt;/value&gt;<br>     &lt;/property&gt;<br>     &lt;property&gt;<br>         &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;<br>         &lt;value&gt;file:/opt/hadoop-2.7.5/tmp/dfs/name&lt;/value&gt;<br>     &lt;/property&gt;<br>     &lt;property&gt;<br>         &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;<br>         &lt;value&gt;file:/opt/hadoop-2.7.5/tmp/dfs/data&lt;/value&gt;<br>     &lt;/property&gt;<br> 4.cd /root/opt/hadoop-2.7.5/etc/hadoop<br> cp mapred-site.xml.template mapred-site.xml<br> ls<br> vim /opt/hadoop-2.7.5/etc/hadoop/yarn-site.xml<br> &lt;property&gt;<br>                 &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;<br>                 &lt;value&gt;mapreduce_shuffle&lt;/value&gt;<br>          &lt;/property&gt;<br>           &lt;property&gt;<br>                &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;<br>                 &lt;value&gt;master&lt;/value&gt;<br>           &lt;/property&gt;</p> 
<p>5.vim /opt/hadoop-2.7.5/etc/hadoop/mapred-site.xml<br>     &lt;property&gt;<br>         &lt;name&gt;mapreduce.framework.name&lt;/name&gt;<br>         &lt;value&gt;yarn&lt;/value&gt;<br>     &lt;/property&gt;<br> 添加三个节点的IP映射<br> vim /etc/hosts</p> 
<p>192.168.67.128  master</p> 
<p>192.168.67.129  slave1</p> 
<p>192.168.67.130  slave2<br> scp /etc/hosts/ root@slave1:/etc<br> scp /etc/hosts/ root@slave1的IP地址代替:/etc<br> scp /etc/hosts/ root@slave2:/etc<br> scp /etc/hosts/ root@slave2的IP地址代替:/etc</p> 
<p><br> 复制传输hadoop文件至slave1<br> scp -r /opt/hadoop-2.7.5/ root@slave1:/opt/<br> 输入 yes</p> 
<p>复制传输hadoop文件至slave2<br> scp -r /opt/hadoop-2.7.5/ root@slave2:/opt/<br> 输入 yes</p> 
<p>格式化namenode<br> 进入sbin目录<br> cd  /opt/hadoop-2.7.5/sbin  </p> 
<p>hdfs namenode -format</p> 
<p>启动hadoop<br> cd  /opt/hadoop-2.7.5/sbin<br> start-all.sh</p> 
<p>节点查看启动情况<br> jps</p> 
<p style="margin-left:0;"><a name="IpBT-1709652113191"></a></p> 
<p></p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/98deae2ebc2334c24d802aa74314a3f6/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">websocket 实现后端主动前端推送数据、及时通讯(vue3 &#43; springboot)</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/97b50c9af3da3c001281ee60b3a3bfc3/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【C语言】深入理解指针（一篇让你完全搞懂指针）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>