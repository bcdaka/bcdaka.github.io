<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【机器学习】基于YOLOv10实现你的第一个视觉AI大模型 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/efb4eea5aa66c7672abe107e6ba3f44b/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="【机器学习】基于YOLOv10实现你的第一个视觉AI大模型">
  <meta property="og:description" content="目录
一、引言
二、YOLOv10视觉目标检测—原理概述
2.1 什么是YOLO 2.2 YOLO的网络结构 三、YOLOv10视觉目标检测—训练推理
3.1 YOLOv10安装 3.1.1 克隆项目 3.1.2 创建conda环境
3.1.3 下载并编译依赖 3.2 YOLOv10模型推理
3.2.1 模型下载
3.2.2 WebUI推理
3.2.3 命令行推理
3.2.4 推理格式转换
3.3 YOLOv10模型训练 四、YOLOv10实战：20行代码构建基于YOLOv10的实时视频监控
五、总结
一、引言 人工智能的终极形态，应该就是“具身机器人”——像人一样有眼睛（视觉）、耳朵（听觉）、嘴巴（语言）、舌头（味觉）、鼻子（嗅觉）等器官，味觉、嗅觉目前没有大的进展，视觉、听觉、语言能力在科学界与工程界已经取得重大突破：
视觉模型：YOLOv10、LLaVA、Qwen-VL等大语言模型的Vision版本听觉模型：TTS（文字转语音）、Whisper（ASR，语音转文字）语言模型：GPT4、LLaMA、Qwen、文心一言等等大语言模型 今天我们讲一下最近大火的YOLOv10（You Only Look Once v10），由清华大学5月23日发布，比YOLOv9在相同性能下延迟减少了46%，参数减少了25%。 二、YOLOv10视觉目标检测—原理概述 2.1 什么是YOLO YOLO（You Only Look Once）是基于深度神经网络的目标检测算法，用在图像或视频中实时识别和定位多个对象。YOLO的主要特点是速度快且准确度较高，能够在实时场景下实现快速目标检测，被广泛应用于计算机视觉领域，包括实时视频分析、自动驾驶、智能医疗等。
在YOLO出现前，主流算法为R-CNN，可以称之为“二阶段算法”：先锚框，再预测框内的物体。YOLO出现后，可以“一阶段”直接端到端的输出物料和位置。
一阶段算法：模型直接做回归任务，输出目标的概率值和位置坐标。例如：SSD, YOLO，MTCNN等二阶段算法：首先生成多个锚框，然后利用卷积神经网络输出概率值和位置坐标。例如：R-CNN系列 2.2 YOLO的网络结构 YOLOv10是YOLOv8的改进，这里简单看一下YOLOv8的网络结构：
图片来源：yolov8网络结构详解（逐行解析）_yolov8网络架构-CSDN博客 三、YOLOv10视觉目标检测—训练推理 3.1 YOLOv10安装 3.1.1 克隆项目 git clone https://github.com/THU-MIG/yolov10.git 3.1.2 创建conda环境 conda create -n yolov10 python=3.9 conda activate yolov10 3.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-06-01T14:49:37+08:00">
    <meta property="article:modified_time" content="2024-06-01T14:49:37+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【机器学习】基于YOLOv10实现你的第一个视觉AI大模型</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2><a id="_0"></a></h2> 
<p id="main-toc"><strong>目录</strong></p> 
<p id="-toc" style="margin-left:0px;"></p> 
<p id="%E4%B8%80%E3%80%81%E5%BC%95%E8%A8%80-toc" style="margin-left:0px;"><a href="#%E4%B8%80%E3%80%81%E5%BC%95%E8%A8%80" rel="nofollow">一、引言</a></p> 
<p id="%E4%BA%8C%E3%80%81YOLOv10%E8%A7%86%E8%A7%89%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E2%80%94%E5%8E%9F%E7%90%86%E6%A6%82%E8%BF%B0-toc" style="margin-left:0px;"><a href="#%E4%BA%8C%E3%80%81YOLOv10%E8%A7%86%E8%A7%89%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E2%80%94%E5%8E%9F%E7%90%86%E6%A6%82%E8%BF%B0" rel="nofollow">二、YOLOv10视觉目标检测—原理概述</a></p> 
<p id="2.1%20%E4%BB%80%E4%B9%88%E6%98%AFYOLO%C2%A0-toc" style="margin-left:40px;"><a href="#2.1%20%E4%BB%80%E4%B9%88%E6%98%AFYOLO%C2%A0" rel="nofollow">2.1 什么是YOLO </a></p> 
<p id="2.2%20YOLO%E7%9A%84%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%C2%A0-toc" style="margin-left:40px;"><a href="#2.2%20YOLO%E7%9A%84%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%C2%A0" rel="nofollow">2.2 YOLO的网络结构 </a></p> 
<p id="%E4%B8%89%E3%80%81YOLOv10%E8%A7%86%E8%A7%89%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E2%80%94%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86-toc" style="margin-left:0px;"><a href="#%E4%B8%89%E3%80%81YOLOv10%E8%A7%86%E8%A7%89%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E2%80%94%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86" rel="nofollow">三、YOLOv10视觉目标检测—训练推理</a></p> 
<p id="3.1%20YOLOv10%E5%AE%89%E8%A3%85%C2%A0-toc" style="margin-left:40px;"><a href="#3.1%20YOLOv10%E5%AE%89%E8%A3%85%C2%A0" rel="nofollow">3.1 YOLOv10安装 </a></p> 
<p id="3.1.1%20%E5%85%8B%E9%9A%86%E9%A1%B9%E7%9B%AE%C2%A0-toc" style="margin-left:80px;"><a href="#3.1.1%20%E5%85%8B%E9%9A%86%E9%A1%B9%E7%9B%AE%C2%A0" rel="nofollow">3.1.1 克隆项目 </a></p> 
<p id="3.1.2%C2%A0%20%E5%88%9B%E5%BB%BAconda%E7%8E%AF%E5%A2%83-toc" style="margin-left:80px;"><a href="#3.1.2%C2%A0%20%E5%88%9B%E5%BB%BAconda%E7%8E%AF%E5%A2%83" rel="nofollow">3.1.2  创建conda环境</a></p> 
<p id="3.1.3%20%E4%B8%8B%E8%BD%BD%E5%B9%B6%E7%BC%96%E8%AF%91%E4%BE%9D%E8%B5%96%C2%A0-toc" style="margin-left:80px;"><a href="#3.1.3%20%E4%B8%8B%E8%BD%BD%E5%B9%B6%E7%BC%96%E8%AF%91%E4%BE%9D%E8%B5%96%C2%A0" rel="nofollow">3.1.3 下载并编译依赖 </a></p> 
<p id="3.2%20YOLOv10%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86-toc" style="margin-left:40px;"><a href="#3.2%20YOLOv10%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86" rel="nofollow">3.2 YOLOv10模型推理</a></p> 
<p id="3.2.1%20%E6%A8%A1%E5%9E%8B%E4%B8%8B%E8%BD%BD-toc" style="margin-left:80px;"><a href="#3.2.1%20%E6%A8%A1%E5%9E%8B%E4%B8%8B%E8%BD%BD" rel="nofollow">3.2.1 模型下载</a></p> 
<p id="3.2.2%20WebUI%E6%8E%A8%E7%90%86-toc" style="margin-left:80px;"><a href="#3.2.2%20WebUI%E6%8E%A8%E7%90%86" rel="nofollow">3.2.2 WebUI推理</a></p> 
<p id="3.2.3%20%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%8E%A8%E7%90%86-toc" style="margin-left:80px;"><a href="#3.2.3%20%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%8E%A8%E7%90%86" rel="nofollow">3.2.3 命令行推理</a></p> 
<p id="3.2.4%20%E6%8E%A8%E7%90%86%E6%A0%BC%E5%BC%8F%E8%BD%AC%E6%8D%A2-toc" style="margin-left:80px;"><a href="#3.2.4%20%E6%8E%A8%E7%90%86%E6%A0%BC%E5%BC%8F%E8%BD%AC%E6%8D%A2" rel="nofollow">3.2.4 推理格式转换</a></p> 
<p id="3.3%20YOLOv10%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%C2%A0-toc" style="margin-left:40px;"><a href="#3.3%20YOLOv10%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%C2%A0" rel="nofollow">3.3 YOLOv10模型训练 </a></p> 
<p id="%E5%9B%9B%E3%80%81YOLOv10%E5%AE%9E%E6%88%98%EF%BC%9A20%E8%A1%8C%E4%BB%A3%E7%A0%81%E6%9E%84%E5%BB%BA%E5%9F%BA%E4%BA%8EYOLOv10%E7%9A%84%E5%AE%9E%E6%97%B6%E8%A7%86%E9%A2%91%E7%9B%91%E6%8E%A7-toc" style="margin-left:0px;"><a href="#%E5%9B%9B%E3%80%81YOLOv10%E5%AE%9E%E6%88%98%EF%BC%9A20%E8%A1%8C%E4%BB%A3%E7%A0%81%E6%9E%84%E5%BB%BA%E5%9F%BA%E4%BA%8EYOLOv10%E7%9A%84%E5%AE%9E%E6%97%B6%E8%A7%86%E9%A2%91%E7%9B%91%E6%8E%A7" rel="nofollow">四、YOLOv10实战：20行代码构建基于YOLOv10的实时视频监控</a></p> 
<p id="%E4%BA%94%E3%80%81%E6%80%BB%E7%BB%93-toc" style="margin-left:0px;"><a href="#%E4%BA%94%E3%80%81%E6%80%BB%E7%BB%93" rel="nofollow">五、总结</a></p> 
<hr id="hr-toc"> 
<p></p> 
<h2 id="%E4%B8%80%E3%80%81%E5%BC%95%E8%A8%80">一、引言</h2> 
<p>人工智能的终极形态，应该就是“具身机器人”——像人一样有眼睛（视觉）、耳朵（听觉）、嘴巴（语言）、舌头（味觉）、鼻子（嗅觉）等器官，味觉、嗅觉目前没有大的进展，视觉、听觉、语言能力在科学界与工程界已经取得重大突破：</p> 
<blockquote> 
 <ul><li>视觉模型：YOLOv10、LLaVA、Qwen-VL等大语言模型的Vision版本</li><li>听觉模型：TTS（文字转语音）、Whisper（ASR，语音转文字）</li><li>语言模型：GPT4、LLaMA、Qwen、文心一言等等大语言模型</li></ul> 
</blockquote> 
<p>今天我们讲一下最近大火的YOLOv10（You Only Look Once v10），由清华大学5月23日发布，比YOLOv9在相同性能下延迟减少了46%，参数减少了25%。 </p> 
<p><img alt="" height="712" src="https://images2.imgbox.com/e7/4f/UzYkIJwF_o.png" width="1200"></p> 
<h2 id="%E4%BA%8C%E3%80%81YOLOv10%E8%A7%86%E8%A7%89%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E2%80%94%E5%8E%9F%E7%90%86%E6%A6%82%E8%BF%B0">二、YOLOv10视觉目标检测—原理概述</h2> 
<h3 id="2.1%20%E4%BB%80%E4%B9%88%E6%98%AFYOLO%C2%A0">2.1 什么是YOLO </h3> 
<blockquote> 
 <p><span style="color:#0d0016;">YOLO（You Only Look Once）是基于深度神经网络的目标检测算法，用在图像或视频中实时识别和定位多个对象。YOLO的主要特点是速度快且准确度较高，能够在实时场景下实现快速目标检测，被广泛应用于计算机视觉领域，包括<strong>实时视频分析</strong>、<strong>自动驾驶</strong>、<strong>智能医疗</strong>等。</span></p> 
 <p><span style="color:#0d0016;">在YOLO出现前，主流算法为R-CNN，可以称之为“二阶段算法”：先锚框，再预测框内的物体。YOLO出现后，可以“一阶段”直接端到端的输出物料和位置。</span></p> 
 <ul><li><strong>一阶段算法</strong>：模型直接做回归任务，输出目标的概率值和位置坐标。例如：SSD, YOLO，MTCNN等</li><li><strong>二阶段算法</strong>：首先生成多个锚框，然后利用卷积神经网络输出概率值和位置坐标。例如：R-CNN系列</li></ul> 
</blockquote> 
<h3 id="2.2%20YOLO%E7%9A%84%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%C2%A0">2.2 YOLO的网络结构 </h3> 
<p><span style="color:#0d0016;">YOLOv10是YOLOv8的改进，这里简单看一下YOLOv8的网络结构：</span></p> 
<p><img alt="" height="620" src="https://images2.imgbox.com/e6/b7/zetKLkIi_o.png" width="1200"></p> 
<p></p> 
<p><em>图片来源：<a href="https://blog.csdn.net/lzy2766/article/details/132304440?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522171705101416800215042887%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fblog.%2522%257D&amp;request_id=171705101416800215042887&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_ecpm_v1~rank_v31_ecpm-1-132304440-null-null.nonecase&amp;utm_term=lzy2766&amp;spm=1018.2226.3001.4450" title="yolov8网络结构详解（逐行解析）_yolov8网络架构-CSDN博客">yolov8网络结构详解（逐行解析）_yolov8网络架构-CSDN博客</a> </em> </p> 
<h2 id="%E4%B8%89%E3%80%81YOLOv10%E8%A7%86%E8%A7%89%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E2%80%94%E8%AE%AD%E7%BB%83%E6%8E%A8%E7%90%86">三、YOLOv10视觉目标检测—训练推理</h2> 
<h3 id="3.1%20YOLOv10%E5%AE%89%E8%A3%85%C2%A0">3.1 YOLOv10安装 </h3> 
<h4 id="3.1.1%20%E5%85%8B%E9%9A%86%E9%A1%B9%E7%9B%AE%C2%A0">3.1.1 克隆项目 </h4> 
<pre><code class="language-bash">git clone https://github.com/THU-MIG/yolov10.git</code></pre> 
<h4 id="3.1.2%C2%A0%20%E5%88%9B%E5%BB%BAconda%E7%8E%AF%E5%A2%83">3.1.2  创建conda环境</h4> 
<pre><code class="language-bash">conda create -n yolov10 python=3.9
conda activate yolov10</code></pre> 
<h4 id="3.1.3%20%E4%B8%8B%E8%BD%BD%E5%B9%B6%E7%BC%96%E8%AF%91%E4%BE%9D%E8%B5%96%C2%A0">3.1.3 下载并编译依赖 </h4> 
<p>这里推荐使用腾讯pip源，真的很快</p> 
<pre><code class="language-bash">pip install -r requirements.txt -i https://mirrors.cloud.tencent.com/pypi/simple
pip install -e . -i https://mirrors.cloud.tencent.com/pypi/simple</code></pre> 
<h3 id="3.2%20YOLOv10%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86">3.2 YOLOv10模型推理</h3> 
<h4 id="3.2.1%20%E6%A8%A1%E5%9E%8B%E4%B8%8B%E8%BD%BD">3.2.1 模型下载</h4> 
<p>可以直接点击链接下载：</p> 
<blockquote> 
 <p>YOLOv10-N:https://github.com/THU-MIG/yolov10/releases/download/v1.1/yolov10n.pt<br> YOLOv10-S:https://github.com/THU-MIG/yolov10/releases/download/v1.1/yolov10s.pt<br> YOLOv10-M:https://github.com/THU-MIG/yolov10/releases/download/v1.1/yolov10m.pt<br> YOLOv10-B:https://github.com/THU-MIG/yolov10/releases/download/v1.1/yolov10b.pt<br> YOLOv10-L:https://github.com/THU-MIG/yolov10/releases/download/v1.1/yolov10l.pt<br> YOLOv10-X:https://github.com/THU-MIG/yolov10/releases/download/v1.1/yolov10x.pt</p> 
</blockquote> 
<h4 id="3.2.2%20WebUI%E6%8E%A8%E7%90%86">3.2.2 WebUI推理</h4> 
<p>项目根目录下运行：</p> 
<pre><code class="language-python">python app.py</code></pre> 
<p>执行成功后显示： </p> 
<p><img alt="" height="170" src="https://images2.imgbox.com/ed/dc/WCTXBAJy_o.png" width="1200"></p> 
<p>报错解决： </p> 
<blockquote> 
 <p>我在执行时出现了报错：ImportError: libGL.so.1: cannot open shared object file: No such file or dir</p> 
 <p>在启动前出现了这个错误，主要因为opencv-python-headless版本导致，重新安装解决</p> 
 <pre><code class="language-python">pip uninstall opencv-python -y
pip install opencv-python-headless -i https://mirrors.cloud.tencent.com/pypi/simple</code></pre> 
</blockquote> 
<p>在浏览器输入127.0.0.1:7861，见证奇迹的时刻： <img alt="" height="1200" src="https://images2.imgbox.com/87/1f/JlvWtIfB_o.png" width="1200"></p> 
<ul><li> 上传图片检测：毫秒级瞬间级就检测出来了</li></ul> 
<p><img alt="" height="1200" src="https://images2.imgbox.com/9d/9c/4GqeR0H4_o.png" width="1200"></p> 
<ul><li>摄像头拍照检测： 人、手机、表均不完整，但可以快速识别，nice！</li></ul> 
<p><img alt="" height="1200" src="https://images2.imgbox.com/8a/bd/1SOaArsv_o.png" width="1200">  </p> 
<h4 id="3.2.3%20%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%8E%A8%E7%90%86">3.2.3 命令行推理</h4> 
<p>conda环境内用yolo启动，predict参数预测，model用于指定下载好的模型，device指定GPU，source指定要检测的图片。</p> 
<pre><code class="language-bash">yolo predict model=yolov10n.pt device=2 source=/aigc_dev/yolov10/ultralytics/assets</code></pre> 
<p>默认待检测图片存放在yolov10/ultralytics/assets目录下，检测后存放于yolov10/runs/detect/predictxx目录<img alt="" height="258" src="https://images2.imgbox.com/8d/a8/SkoEo7I9_o.png" width="1200"></p> 
<p>可以看到，yolov10n在V100显卡下，平均检测时长为78.7ms</p> 
<p>官方采用COCO数据集对每种模型进行评测，仅供参考。<img alt="" height="572" src="https://images2.imgbox.com/2c/a8/Q3bVlFpP_o.png" width="1200"></p> 
<p>检测结果展示：</p> 
<p><img alt="" height="1080" src="https://images2.imgbox.com/56/35/83mwyLox_o.jpg" width="810"></p> 
<h4 id="3.2.4%20%E6%8E%A8%E7%90%86%E6%A0%BC%E5%BC%8F%E8%BD%AC%E6%8D%A2">3.2.4 推理格式转换</h4> 
<p>项目可以方便的转换为ONNX和TensorRT格式，用于跨平台推理与部署。</p> 
<pre><code class="language-bash">yolo export model=yolov10n.pt format=onnx opset=13 simplify device=2
yolo predict model=yolov10n.onnx device=2</code></pre> 
<blockquote> 
 <ul><li>ONNX（Open Neural Network Exchange）是一个开放的格式，用于表示深度学习模型，使得模型可以在不同的框架之间轻松迁移。它支持多种深度学习框架，如PyTorch、TensorFlow、MXNet等，允许开发者在不同的生态系统中选择最合适的工具进行模型训练，然后导出到ONNX格式，以便在其他支持ONNX的平台上进行部署。</li><li>TensorRT是NVIDIA开发的一个高性能的深度学习推理（Inference）优化器和运行时，专为NVIDIA GPU设计。它接收训练好的模型（支持ONNX等格式），并对其进行优化，生成针对特定GPU硬件的高效执行代码。</li></ul> 
</blockquote> 
<h3 id="3.3%20YOLOv10%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%C2%A0">3.3 YOLOv10模型训练 </h3> 
<p>yolo不仅提供推理服务，还支持引入数据集进行训练：</p> 
<pre><code class="language-bash">yolo detect train data=coco.yaml model=yolov10s.yaml epochs=100 batch=128 imgsz=640 device=2</code></pre> 
<p>detect train为检测训练命令，data指定数据集，默认数据集下载并存放在../datasets/coco，model指定训练模型配置，epochs代表迭代次数，imgsz代表图片缩放大小，batch代表批处理，device为指定GPU设备。</p> 
<p>启动后进行COCO数据集的下载，非常庞大，由于服务器无法科学上网，需要下很久，这里不投入时间了，如果感兴趣可以前往<a href="https://cocodataset.org/#download" rel="nofollow" title="COCO - Common Objects in Context">COCO - Common Objects in Context</a> 下载。也可以执行上面命令后自动下载。</p> 
<h2 id="%E5%9B%9B%E3%80%81YOLOv10%E5%AE%9E%E6%88%98%EF%BC%9A20%E8%A1%8C%E4%BB%A3%E7%A0%81%E6%9E%84%E5%BB%BA%E5%9F%BA%E4%BA%8EYOLOv10%E7%9A%84%E5%AE%9E%E6%97%B6%E8%A7%86%E9%A2%91%E7%9B%91%E6%8E%A7">四、YOLOv10实战：20行代码构建基于YOLOv10的实时视频监控</h2> 
<p>在根目录下建立run_python.py： </p> 
<pre><code class="language-python">import cv2
from ultralytics import YOLOv10
model = YOLOv10("yolov10s.pt")
cap = cv2.VideoCapture(0)
while True:
        ret, frame = cap.read()
        if not ret:
                break  # 如果没有读取到帧，退出循环
        results = model.predict(frame)
        # 遍历每个预测结果
        for result in results:
                # 结果中的每个元素对应一张图片的预测
                boxes = result.boxes  # 获取边界框信息
                for box in boxes:
                        x1,y1,x2,y2 = map(int, box.xyxy[0])
                        cls = int(box.cls[0])
                        conf = float(box.conf[0])
                        cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)
                        cv2.putText(frame, f'{model.names[cls]} {conf:.2f}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)
        # 显示带有检测结果的帧
        cv2.imshow('YOLOv10实时检测', frame)
        # 按'q'键退出
        if cv2.waitKey(1) &amp; 0xFF == ord('q'):
                break

# 释放资源
cap.release()
cv2.destroyAllWindows()</code></pre> 
<p>运行后电脑摄像头自动开启，实时检测摄像头内的目标：</p> 
<p><img alt="" height="1200" src="https://images2.imgbox.com/61/13/z6qkWbsV_o.png" width="1200"></p> 
<p>感受：由于使用个人mac笔记本，推理性能较差，取中等尺寸的yolov10b.pt模型，推理耗时达到了300-400ms，而对于很多物体，也很难有效识别，比如拿了盒烟，他会判定成一本书。真正应用到生产环境还需要在推理性能和模型训练上深耕。</p> 
<p><img alt="" height="512" src="https://images2.imgbox.com/29/71/HjtjQ0kl_o.png" width="1200"></p> 
<h2 id="%E4%BA%94%E3%80%81%E6%80%BB%E7%BB%93">五、总结</h2> 
<p>本文​​​​首先介绍视觉模型在人工智能领域的位置，其次对原理概念初步进行说明，之后对推理与训练过程进行详细阐述，最后通过一个实战例子，用极少的代码行数将笔记本电脑的摄像头改装为实时视频监控，目标是让读者通过读完此文，快速上手YOLOv10技术进行物体目标检测，</p> 
<ul><li>从应用角度讲，YOLO非常贴合实际应用，很多人基于YOLO创业并产生收益，比如智能驾驶、安全监控、医疗检测等</li><li>从研究角度讲，YOLO供发布10个版本，围绕效果和速度进行了频繁的迭代与优化，知识体系非常深入。</li></ul> 
<p>如果读者对YOLO有兴趣，我后期会持续更新，也可以通过站内搜索持续了解。</p> 
<p>如果您还有时间，可以看看我的其他文章：</p> 
<p>《AI—工程篇》</p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/138583814?spm=1001.2014.3001.5501" title="AI智能体研发之路-工程篇（一）：Docker助力AI智能体开发提效">AI智能体研发之路-工程篇（一）：Docker助力AI智能体开发提效</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/138543709?spm=1001.2014.3001.5501" title="AI智能体研发之路-工程篇（二）：Dify智能体开发平台一键部署">AI智能体研发之路-工程篇（二）：Dify智能体开发平台一键部署</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/138506272?spm=1001.2014.3001.5501" title="AI智能体研发之路-工程篇（三）：大模型推理服务框架Ollama一键部署">AI智能体研发之路-工程篇（三）：大模型推理服务框架Ollama一键部署</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/138531565?spm=1001.2014.3001.5501" title="AI智能体研发之路-工程篇（四）：大模型推理服务框架Xinference一键部署">AI智能体研发之路-工程篇（四）：大模型推理服务框架Xinference一键部署</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/138673899?spm=1001.2014.3001.5501" title="AI智能体研发之路-工程篇（五）：大模型推理服务框架LocalAI一键部署">AI智能体研发之路-工程篇（五）：大模型推理服务框架LocalAI一键部署</a></p> 
<p>《AI—模型篇》</p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/138819599?spm=1001.2014.3001.5501" title="AI智能体研发之路-模型篇（一）：大模型训练框架LLaMA-Factory在国内网络环境下的安装、部署及使用">AI智能体研发之路-模型篇（一）：大模型训练框架LLaMA-Factory在国内网络环境下的安装、部署及使用</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139131558?spm=1001.2014.3001.5501" title="AI智能体研发之路-模型篇（二）：DeepSeek-V2-Chat 训练与推理实战">AI智能体研发之路-模型篇（二）：DeepSeek-V2-Chat 训练与推理实战</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139219617?spm=1001.2014.3001.5501" title="AI智能体研发之路-模型篇（三）：中文大模型开、闭源之争">AI智能体研发之路-模型篇（三）：中文大模型开、闭源之争</a> </p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139237430?csdn_share_tail=%7B%22type%22%3A%22blog%22%2C%22rType%22%3A%22article%22%2C%22rId%22%3A%22139237430%22%2C%22source%22%3A%22weixin_48007632%22%7D" title="AI智能体研发之路-模型篇（四）：一文入门pytorch开发">AI智能体研发之路-模型篇（四）：一文入门pytorch开发</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139249095?spm=1001.2014.3001.5502" title="AI智能体研发之路-模型篇（五）：pytorch vs tensorflow框架DNN网络结构源码级对比">AI智能体研发之路-模型篇（五）：pytorch vs tensorflow框架DNN网络结构源码级对比</a>​​​​​​​ </p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139263131?spm=1001.2014.3001.5501" title="AI智能体研发之路-模型篇（六）：【机器学习】基于tensorflow实现你的第一个DNN网络">AI智能体研发之路-模型篇（六）：【机器学习】基于tensorflow实现你的第一个DNN网络</a>​​​​​​​</p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/85d4bb1f7ad7130dc7ed506e1361cead/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">AI大模型探索之路-实战篇12： 构建互动式Agent智能数据分析平台：实现多轮对话控制</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/be28ce657805549624048abca8dea232/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">HDTune和CrystalDiskInfo硬盘检测S.M.A.R.T.参数当前值最差值阈值</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>