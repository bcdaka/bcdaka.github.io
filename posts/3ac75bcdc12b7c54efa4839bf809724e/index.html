<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>AI学习笔记之七：探秘无监督学习的原理、常用算法及实现解析 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/3ac75bcdc12b7c54efa4839bf809724e/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="AI学习笔记之七：探秘无监督学习的原理、常用算法及实现解析">
  <meta property="og:description" content="无监督学习也称为无监督机器学习，是机器学习领域中的重要分支之一，它使用机器学习算法来分析未标记的数据集并进行聚类。
与有监督学习和强化学习不同，无监督学习的数据集中不包含任何人工标注的目标值或反馈信号。
无监督学习算法需要从原始数据中自主发现内在结构、模式或知识。这种“自主学习”的范式更贴近人类自主学习的方式，使得无监督学习在许多应用场景都有独特的优势，这种方法能够发现信息的相似性和差异性，因而是探索性数据分析、交叉销售策略、客户细分和图像识别的理想解决方案。
1. 无监督学习的原理 无监督学习的核心思想是通过对数据的统计特征、相似度等进行分析和挖掘，利用密度估计、聚类和降维等技术来捕获和发现数据隐藏的内在结构和模式。
无监督学习的主要原理可以概括为:
密度估计(Density Estimation)
密度估计是无监督学习的一个基本问题。它旨在估计样本数据的概率密度函数，从而刻画数据的整体分布特征。常用的密度估计方法包括核密度估计、高斯混合模型、K-近邻等。掌握了数据分布，就能发现异常数据点、检测新观测值等。
聚类(Clustering)
聚类是将数据集中的样本划分为若干个类别的过程，使得同一类别内的样本相似度较高，不同类别之间的样本相似度较低。在聚类过程中，每个样本点都被视为一个向量，聚类算法通过计算样本之间的距离或相似度，将相似的样本归为同一类别。常见的聚类算法包括K均值聚类、层次聚类、DBSCAN、高斯混合模型等。聚类分析有助于发现数据的内在组织结构。
降维(Dimensionality Reduction)
数据常常存在维度灾难的问题，即特征空间过高导致计算复杂度和数据稀疏性增加。降维技术通过数学上的投影等方式将高维数据映射到一个低维空间，在减少数据的维度的同时保留数据的原始结构和特征关系，从而简化后续处理。主成分分析(PCA)、t-SNE等都是常用的无监督降维方法。
表示学习(Representation Learning)
表示学习旨在从原始数据中自动学习出良好的特征表示，使得表示空间中相似的样本更易于被区分和聚类。自编码器(AutoEncoder)就是一种常用的无监督神经网络模型，能够有效地学习出高质量的数据表示。
无监督学习算法通常会以无约束或少量约束的方式优化某些目标函数，如最大化数据对数似然、最小化重构误差等，从而捕获数据的本质结构和模式。得益于深度学习技术的发展，无监督表示学习逐渐成为研究的热点。
2. 无监督学习的常用核心算法 2.1. K-Means聚类算法（K均值聚类）
K-Means是最常用和最简单的聚类算法之一，它是一种基于中心点的聚类方法，它将样本分配给离其最近的K个中心点所对应的簇。该算法的核心步骤包括初始化中心点、分配样本到最近的中心点所在的簇、更新中心点位置，使得簇内样本间的平方和最小。K均值聚类适用于数据集中各个簇的形状近似球形、大小相似的情况。
一般算法步骤如下:
随机初始化k个聚类中心重复以下步骤直到收敛: 将每个样本分配到与之最近的聚类中心重新计算每个簇的聚类中心 K-Means具有简单高效的优点，但也存在一些缺陷,如对噪声和异常值敏感、需要预先指定簇数k等。
2.2 层次聚类算法
层次聚类算法通过逐步合并或分裂簇来构建一个层次化的聚类树状结构。主要分为两种策略:
凝聚层次聚类(底至顶)：从每个样本作为一个簇开始,逐步合并最相似的簇分裂层次聚类(顶至底)：从所有样本作为一个簇开始,逐步将离散程度最高的簇进行分裂 常用的相似性度量包括最小距离、最大距离、平均距离等。需要事先确定一个合理的terminated条件来决定最终的聚类数目。
2.3. 高斯混合模型(GMM)
GMM假设整个数据服从一个由多个高斯分布混合而成的概率分布模型。可以使用期望最大化(EM)算法来估计每个高斯分布的参数(均值、协方差)和所占的混合权重。模型估计完成后，每个样本可以基于后验概率被&#34;软分配&#34;到不同的高斯分布中。GMM广泛应用于聚类、密度估计等任务。
2.4. 主成分分析(PCA)
PCA是一种常用的无监督降维和数据表示技术。其主要思想是将原始数据通过线性变换投影到一组相互正交的低维空间中，使得投影后数据的方差最大化。PCA的主要思想是找到数据中最主要的特征，即主成分，以降低数据的维度。具体步骤包括:中心化数据、计算协方差矩阵、求解特征值和特征向量、选取方差贡献度最大的前k个主成分等。PCA常被用于数据可视化、压缩和特征提取的预处理步骤。
2.5. t-SNE
t-SNE(t-分布随机邻域嵌入)是一种较新的非线性降维技术，能够有效地保留原始高维数据的局部邻域结构。首先计算高维空间样本之间的相似度，然后在低维空间中最小化相似度与映射后距离之间的KL散度。t-SNE常用于可视化高维数据，辅助探索数据的内在分布和聚类结构。
2.6. 自编码器(AutoEncoder)
自编码器是一种基于人工神经网络的无监督表示学习模型。其由编码器和解码器组成，编码器将输入数据映射到隐含层的低维表示,解码器则试图重构原始输入。通过最小化输入和重构之间的损失函数，自编码器能够自动学习出对应问题的良好特征表示。堆叠自编码器、变分自编码器等都是基于这一思想的扩展。
3. 无监督学习的实现 3.1 K均值聚类的实现
下面我们通过一个基于Python的K-Means聚类算法实例，来更直观地理解无监督学习。
import numpy as np import matplotlib.pyplot as plt from sklearn.cluster import KMeans from sklearn.datasets import make_blobs # 生成样本数据 X, y = make_blobs(n_samples=500, centers=4, n_features=2, random_state=0) # 初始化K-Means模型 kmeans = KMeans(n_clusters=4, random_state=0) # 训练K-Means模型 kmeans.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-03-20T20:16:46+08:00">
    <meta property="article:modified_time" content="2024-03-20T20:16:46+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">AI学习笔记之七：探秘无监督学习的原理、常用算法及实现解析</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-tomorrow-night">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>无监督学习也称为无监督机器学习，是机器学习领域中的重要分支之一，它使用机器学习算法来分析未标记的数据集并进行聚类。</p> 
<p><img src="https://images2.imgbox.com/b5/85/bAOUcoy4_o.png" alt="在这里插入图片描述"><br> 与有监督学习和强化学习不同，无监督学习的数据集中不包含任何人工标注的目标值或反馈信号。</p> 
<p><img src="https://images2.imgbox.com/0a/cc/TamEC6y0_o.png" alt="在这里插入图片描述"><br> 无监督学习算法需要从原始数据中自主发现内在结构、模式或知识。这种“自主学习”的范式更贴近人类自主学习的方式，使得无监督学习在许多应用场景都有独特的优势，这种方法能够发现信息的相似性和差异性，因而是探索性数据分析、交叉销售策略、客户细分和图像识别的理想解决方案。</p> 
<h4><a id="1__10"></a>1. 无监督学习的原理</h4> 
<p>无监督学习的核心思想是通过对数据的统计特征、相似度等进行分析和挖掘，利用密度估计、聚类和降维等技术来捕获和发现数据隐藏的内在结构和模式。</p> 
<p>无监督学习的主要原理可以概括为:</p> 
<p><img src="https://images2.imgbox.com/9b/02/z7HuQ5rf_o.png" alt="在这里插入图片描述"><br> <strong>密度估计(Density Estimation)</strong></p> 
<p>密度估计是无监督学习的一个基本问题。它旨在估计样本数据的概率密度函数，从而刻画数据的整体分布特征。常用的密度估计方法包括核密度估计、高斯混合模型、K-近邻等。掌握了数据分布，就能发现异常数据点、检测新观测值等。</p> 
<p><strong>聚类(Clustering)</strong></p> 
<p>聚类是将数据集中的样本划分为若干个类别的过程，使得同一类别内的样本相似度较高，不同类别之间的样本相似度较低。在聚类过程中，每个样本点都被视为一个向量，聚类算法通过计算样本之间的距离或相似度，将相似的样本归为同一类别。常见的聚类算法包括K均值聚类、层次聚类、DBSCAN、高斯混合模型等。聚类分析有助于发现数据的内在组织结构。</p> 
<p><strong>降维(Dimensionality Reduction)</strong></p> 
<p>数据常常存在维度灾难的问题，即特征空间过高导致计算复杂度和数据稀疏性增加。降维技术通过数学上的投影等方式将高维数据映射到一个低维空间，在减少数据的维度的同时保留数据的原始结构和特征关系，从而简化后续处理。主成分分析(PCA)、t-SNE等都是常用的无监督降维方法。</p> 
<p><strong>表示学习(Representation Learning)</strong></p> 
<p>表示学习旨在从原始数据中自动学习出良好的特征表示，使得表示空间中相似的样本更易于被区分和聚类。自编码器(AutoEncoder)就是一种常用的无监督神经网络模型，能够有效地学习出高质量的数据表示。</p> 
<p>无监督学习算法通常会以无约束或少量约束的方式优化某些目标函数，如最大化数据对数似然、最小化重构误差等，从而捕获数据的本质结构和模式。得益于深度学习技术的发展，无监督表示学习逐渐成为研究的热点。</p> 
<h4><a id="2__35"></a>2. 无监督学习的常用核心算法</h4> 
<p>2.1. <strong>K-Means聚类算法（K均值聚类）</strong></p> 
<p>K-Means是最常用和最简单的聚类算法之一，它是一种基于中心点的聚类方法，它将样本分配给离其最近的K个中心点所对应的簇。该算法的核心步骤包括初始化中心点、分配样本到最近的中心点所在的簇、更新中心点位置，使得簇内样本间的平方和最小。K均值聚类适用于数据集中各个簇的形状近似球形、大小相似的情况。<br> <img src="https://images2.imgbox.com/20/bf/HLeEMvW5_o.png" alt="K均值聚类算法步骤"></p> 
<p>一般算法步骤如下:</p> 
<ul><li>随机初始化k个聚类中心</li><li>重复以下步骤直到收敛: 
  <ul><li>将每个样本分配到与之最近的聚类中心</li><li>重新计算每个簇的聚类中心</li></ul> </li></ul> 
<p>K-Means具有简单高效的优点，但也存在一些缺陷,如对噪声和异常值敏感、需要预先指定簇数k等。</p> 
<p>2.2 <strong>层次聚类算法</strong></p> 
<p><img src="https://images2.imgbox.com/90/b6/Rj6ZOYPq_o.png" alt="层次聚类算法"></p> 
<p>层次聚类算法通过逐步合并或分裂簇来构建一个层次化的聚类树状结构。主要分为两种策略:</p> 
<ul><li>凝聚层次聚类(底至顶)：从每个样本作为一个簇开始,逐步合并最相似的簇</li><li>分裂层次聚类(顶至底)：从所有样本作为一个簇开始,逐步将离散程度最高的簇进行分裂</li></ul> 
<p>常用的相似性度量包括最小距离、最大距离、平均距离等。需要事先确定一个合理的terminated条件来决定最终的聚类数目。</p> 
<p>2.3. <strong>高斯混合模型(GMM)</strong></p> 
<p><img src="https://images2.imgbox.com/6d/58/HUxLCArJ_o.png" alt="高斯混合模型(GMM)"></p> 
<p>GMM假设整个数据服从一个由多个高斯分布混合而成的概率分布模型。可以使用期望最大化(EM)算法来估计每个高斯分布的参数(均值、协方差)和所占的混合权重。模型估计完成后，每个样本可以基于后验概率被"软分配"到不同的高斯分布中。GMM广泛应用于聚类、密度估计等任务。</p> 
<p>2.4. <strong>主成分分析(PCA)</strong></p> 
<p><img src="https://images2.imgbox.com/ca/13/mruF87xJ_o.png" alt="主成分分析(PCA)"></p> 
<p>PCA是一种常用的无监督降维和数据表示技术。其主要思想是将原始数据通过线性变换投影到一组相互正交的低维空间中，使得投影后数据的方差最大化。PCA的主要思想是找到数据中最主要的特征，即主成分，以降低数据的维度。具体步骤包括:中心化数据、计算协方差矩阵、求解特征值和特征向量、选取方差贡献度最大的前k个主成分等。PCA常被用于数据可视化、压缩和特征提取的预处理步骤。</p> 
<p>2.5. <strong>t-SNE</strong></p> 
<p><img src="https://images2.imgbox.com/4d/8c/dFh5xFIH_o.png" alt="t-分布随机邻域嵌入"></p> 
<p>t-SNE(t-分布随机邻域嵌入)是一种较新的非线性降维技术，能够有效地保留原始高维数据的局部邻域结构。首先计算高维空间样本之间的相似度，然后在低维空间中最小化相似度与映射后距离之间的KL散度。t-SNE常用于可视化高维数据，辅助探索数据的内在分布和聚类结构。</p> 
<p>2.6. <strong>自编码器(AutoEncoder)</strong></p> 
<p><img src="https://images2.imgbox.com/97/69/B52CJ5pZ_o.png" alt="在这里插入图片描述"></p> 
<p>自编码器是一种基于人工神经网络的无监督表示学习模型。其由编码器和解码器组成，编码器将输入数据映射到隐含层的低维表示,解码器则试图重构原始输入。通过最小化输入和重构之间的损失函数，自编码器能够自动学习出对应问题的良好特征表示。堆叠自编码器、变分自编码器等都是基于这一思想的扩展。</p> 
<h4><a id="3__96"></a>3. 无监督学习的实现</h4> 
<p><strong>3.1 K均值聚类的实现</strong></p> 
<p>下面我们通过一个基于Python的K-Means聚类算法实例，来更直观地理解无监督学习。</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>cluster <span class="token keyword">import</span> KMeans
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> make_blobs

<span class="token comment"># 生成样本数据</span>
X<span class="token punctuation">,</span> y <span class="token operator">=</span> make_blobs<span class="token punctuation">(</span>n_samples<span class="token operator">=</span><span class="token number">500</span><span class="token punctuation">,</span> centers<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> n_features<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

<span class="token comment"># 初始化K-Means模型</span>
kmeans <span class="token operator">=</span> KMeans<span class="token punctuation">(</span>n_clusters<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

<span class="token comment"># 训练K-Means模型</span>
kmeans<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">)</span>

<span class="token comment"># 预测每个样本的簇标签</span>
labels <span class="token operator">=</span> kmeans<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X<span class="token punctuation">)</span>

<span class="token comment"># 可视化结果</span>
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span>labels<span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">'viridis'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>kmeans<span class="token punctuation">.</span>cluster_centers_<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> kmeans<span class="token punctuation">.</span>cluster_centers_<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> marker<span class="token operator">=</span><span class="token string">'x'</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'red'</span><span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'K-Means Clustering'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Feature 1'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Feature 2'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p>这段代码首先使用make_blobs函数生成一个包含500个样本的数据集X和y。这些样本被划分为4个不同的簇，每个样本有2个特征。</p> 
<p>接下来,我们初始化一个KMeans对象，将聚类数n_clusters设置为4。random_state参数用于控制随机种子，确保每次运行结果一致。</p> 
<p>调用fit方法使用X训练K-Means模型。模型会迭代调整聚类中心的位置，最小化簇内样本到中心的平方距离之和。</p> 
<p>使用predict方法为每个样本预测一个簇标签。</p> 
<p>最后，我们使用Matplotlib绘制可视化结果。通过plt.scatter函数绘制样本点，不同颜色代表不同的簇。plt.scatter的第二次调用绘制聚类中心,使用红色加号标记。</p> 
<p>设置图像标题、x轴和y轴标签，完成可视化。</p> 
<p><img src="https://images2.imgbox.com/5e/ed/csybKEEk_o.png" alt="代码可视化输出"><br> 我们在 Jupyter Notebook 环境中运行上述代码后，可以看到一个可视化的2维散点图，展示了K-Means在这个人工数据集上的聚类效果。不同颜色的点代表属于不同簇的样本，红色加号标记表示估计出的4个聚类中心。</p> 
<p>从图中还可以看到，K-Means算法能够较好地将数据划分为4个紧密的簇。但是，由于数据分布并不是严格球形，有一些样本仍被错误分类到其他簇中。<strong>这也体现了K-Means对初始中心选择和数据分布假设的敏感性</strong>。</p> 
<p>K-Means聚类算法通过优化某些目标函数，比如最小化聚类内的方差，从而将相似的样本聚集到同一个簇中，算法会迭代地调整聚类中心的位置，使每个样本与离它最近的中心之间的平方距离之和最小化。</p> 
<p><strong>3.2 层次聚类的实现</strong></p> 
<p>我们将使用SciPy库中的层次聚类模块，实现一个基于Ward’s最小方差准则的聚类算法。该算法采取自底向上的策略，初始时将每个样本作为一个单独的簇，然后在每一步中合并两个最相近的簇，直到所有样本聚合为一个簇或满足指定的终止条件。</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> load_iris
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>cluster <span class="token keyword">import</span> AgglomerativeClustering
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">from</span> mpl_toolkits<span class="token punctuation">.</span>mplot3d <span class="token keyword">import</span> Axes3D

<span class="token comment"># 加载鸢尾花数据集</span>
iris <span class="token operator">=</span> load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span>
X <span class="token operator">=</span> iris<span class="token punctuation">.</span>data

<span class="token comment"># 初始化层次聚类模型</span>
clustering <span class="token operator">=</span> AgglomerativeClustering<span class="token punctuation">(</span>n_clusters<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> linkage<span class="token operator">=</span><span class="token string">'ward'</span><span class="token punctuation">)</span>

<span class="token comment"># 训练模型</span>
clustering<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">)</span>

<span class="token comment"># 获取样本的聚类标签</span>
labels <span class="token operator">=</span> clustering<span class="token punctuation">.</span>labels_

<span class="token comment"># 可视化结果</span>
fig <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
ax <span class="token operator">=</span> fig<span class="token punctuation">.</span>add_subplot<span class="token punctuation">(</span><span class="token number">111</span><span class="token punctuation">,</span> projection<span class="token operator">=</span><span class="token string">'3d'</span><span class="token punctuation">)</span>

<span class="token comment"># 设置不同颜色表示不同簇</span>
colors <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'r'</span><span class="token punctuation">,</span> <span class="token string">'g'</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">]</span>

<span class="token comment"># 绘制每个簇的样本点</span>
<span class="token keyword">for</span> label<span class="token punctuation">,</span> color <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span><span class="token builtin">set</span><span class="token punctuation">(</span>labels<span class="token punctuation">)</span><span class="token punctuation">,</span> colors<span class="token punctuation">)</span><span class="token punctuation">:</span>
    data <span class="token operator">=</span> X<span class="token punctuation">[</span>labels <span class="token operator">==</span> label<span class="token punctuation">]</span>
    ax<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span>color<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string-interpolation"><span class="token string">f'Cluster </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>label<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>

<span class="token comment"># 设置图例、坐标轴标签和标题</span>
ax<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
ax<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span><span class="token string">'Sepal Length'</span><span class="token punctuation">)</span>
ax<span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span><span class="token string">'Sepal Width'</span><span class="token punctuation">)</span>
ax<span class="token punctuation">.</span>set_zlabel<span class="token punctuation">(</span><span class="token string">'Petal Length'</span><span class="token punctuation">)</span>
ax<span class="token punctuation">.</span>set_title<span class="token punctuation">(</span><span class="token string">'Hierarchical Clustering on Iris Dataset'</span><span class="token punctuation">)</span>

<span class="token comment"># 调整视角角度</span>
ax<span class="token punctuation">.</span>view_init<span class="token punctuation">(</span><span class="token number">30</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p>这段代码首先使用从scikit-learn库中加载鸢尾花数据集iris。该数据集包含150个样本，每个样本有4个特征：花萼长度、花萼宽度、花瓣长度和花瓣宽度。<br> <img src="https://images2.imgbox.com/03/3f/5pci2BMg_o.png" alt="鸢尾花数据集iris"></p> 
<p>接下来，我们初始化AgglomerativeClustering类，使用Ward’s最小方差准则作为链接标准，并设置簇数为3。</p> 
<p>调用fit方法在数据X上训练层次聚类模型。该算法会自底向上地将相似的样本合并为簇。</p> 
<p>从模型中获取每个样本的聚类标签labels。</p> 
<p>使用Matplotlib创建一个3D图像,并添加一个3D子图。</p> 
<p>设置不同的颜色表示不同的簇。</p> 
<p>遍历每个簇的样本点，使用ax.scatter在3D图中绘制,同一簇的样本使用相同颜色。</p> 
<p>设置图例、坐标轴标签和标题。</p> 
<p>调用ax.view_init(30, 30)调整3D图像的视角角度,使其更加容易观察。</p> 
<p>最后调用plt.show()展示可视化结果。</p> 
<p><img src="https://images2.imgbox.com/1f/e4/qX9pyHBI_o.png" alt="代码可视化输出"></p> 
<p>运行上述代码后，我们将看到一个3D散点图，展示了层次聚类算法在鸢尾花数据集上的聚类效果。不同颜色的点代表属于不同簇的样本。从图中我们可以直观地看到，层次聚类算法能较好地将鸢尾花数据集划分为3个簇，每个簇对应一种鸢尾花品种。</p> 
<p>层次聚类的主要优势在于能够很直观地呈现数据的层次结构，同时不需要预先指定聚类数目。</p> 
<p>但它也存在一些缺点，比如对于大规模数据计算复杂度较高，一旦发生错误合并也无法回退等。总的来说，层次聚类是一种解释性很强且实用的无监督学习算法。</p> 
<p><strong>3.3 高斯混合模型(GMM)的实现</strong><br> 我们使用Python中的scikit-learn库，通过一个1000个样本的示例，来详细说明高斯混合模型(GMM)算法的原理和实现。</p> 
<p>GMM是一种基于概率模型的无监督学习算法，它假设整个数据集由多个高斯分布混合而成。算法的目标是通过期望最大化(EM)算法估计每个高斯成分的参数(均值、协方差和混合权重)，从而对数据进行软聚类。</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>mixture <span class="token keyword">import</span> GaussianMixture
<span class="token keyword">from</span> scipy<span class="token punctuation">.</span>stats <span class="token keyword">import</span> multivariate_normal
<span class="token keyword">from</span> mpl_toolkits<span class="token punctuation">.</span>mplot3d <span class="token keyword">import</span> Axes3D

<span class="token comment"># 生成样本数据</span>
np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
n_samples <span class="token operator">=</span> <span class="token number">1000</span>
mu1<span class="token punctuation">,</span> mu2 <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>
cov1<span class="token punctuation">,</span> cov2 <span class="token operator">=</span> np<span class="token punctuation">.</span>eye<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>eye<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">2</span>
data1 <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>multivariate_normal<span class="token punctuation">(</span>mu1<span class="token punctuation">,</span> cov1<span class="token punctuation">,</span> n_samples <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">)</span>
data2 <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>multivariate_normal<span class="token punctuation">(</span>mu2<span class="token punctuation">,</span> cov2<span class="token punctuation">,</span> n_samples <span class="token operator">-</span> n_samples <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">)</span>
X <span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">(</span>data1<span class="token punctuation">,</span> data2<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

<span class="token comment"># 初始化GMM模型</span>
gmm <span class="token operator">=</span> GaussianMixture<span class="token punctuation">(</span>n_components<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> covariance_type<span class="token operator">=</span><span class="token string">'full'</span><span class="token punctuation">)</span>

<span class="token comment"># 训练GMM模型</span>
gmm<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">)</span>

<span class="token comment"># 获取模型参数</span>
means <span class="token operator">=</span> gmm<span class="token punctuation">.</span>means_
covariances <span class="token operator">=</span> gmm<span class="token punctuation">.</span>covariances_
weights <span class="token operator">=</span> gmm<span class="token punctuation">.</span>weights_

<span class="token comment"># 预测每个样本的簇标签</span>
labels <span class="token operator">=</span> gmm<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X<span class="token punctuation">)</span>

<span class="token comment"># 可视化结果</span>
fig <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
ax <span class="token operator">=</span> fig<span class="token punctuation">.</span>add_subplot<span class="token punctuation">(</span><span class="token number">111</span><span class="token punctuation">,</span> projection<span class="token operator">=</span><span class="token string">'3d'</span><span class="token punctuation">)</span>

colors <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'navy'</span><span class="token punctuation">,</span> <span class="token string">'turquoise'</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> i<span class="token punctuation">,</span> color <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>colors<span class="token punctuation">)</span><span class="token punctuation">:</span>
    x <span class="token operator">=</span> X<span class="token punctuation">[</span>labels <span class="token operator">==</span> i<span class="token punctuation">]</span>
    ax<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span>color<span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>
    
    <span class="token comment"># 绘制高斯分布等高面和协方差椭球</span>
    u<span class="token punctuation">,</span> s<span class="token punctuation">,</span> vh <span class="token operator">=</span> np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>svd<span class="token punctuation">(</span>covariances<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
    radii <span class="token operator">=</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>s<span class="token punctuation">)</span>
    u <span class="token operator">=</span> u<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span>
    phi <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>pi<span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span>
    theta <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>pi<span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span>
    x_plot <span class="token operator">=</span> radii<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>outer<span class="token punctuation">(</span>np<span class="token punctuation">.</span>cos<span class="token punctuation">(</span>phi<span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>sin<span class="token punctuation">(</span>theta<span class="token punctuation">)</span><span class="token punctuation">)</span>
    y_plot <span class="token operator">=</span> radii<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>outer<span class="token punctuation">(</span>np<span class="token punctuation">.</span>sin<span class="token punctuation">(</span>phi<span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>sin<span class="token punctuation">(</span>theta<span class="token punctuation">)</span><span class="token punctuation">)</span>
    z_plot <span class="token operator">=</span> radii<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>outer<span class="token punctuation">(</span>np<span class="token punctuation">.</span>ones_like<span class="token punctuation">(</span>phi<span class="token punctuation">)</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>cos<span class="token punctuation">(</span>theta<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>x_plot<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> k <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>x_plot<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token punctuation">[</span>x_plot<span class="token punctuation">[</span>k<span class="token punctuation">,</span> j<span class="token punctuation">]</span><span class="token punctuation">,</span> y_plot<span class="token punctuation">[</span>k<span class="token punctuation">,</span> j<span class="token punctuation">]</span><span class="token punctuation">,</span> z_plot<span class="token punctuation">[</span>k<span class="token punctuation">,</span> j<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span><span class="token punctuation">[</span>x_plot<span class="token punctuation">[</span>k<span class="token punctuation">,</span> j<span class="token punctuation">]</span><span class="token punctuation">,</span> y_plot<span class="token punctuation">[</span>k<span class="token punctuation">,</span> j<span class="token punctuation">]</span><span class="token punctuation">,</span> z_plot<span class="token punctuation">[</span>k<span class="token punctuation">,</span> j<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> vh<span class="token punctuation">.</span>T<span class="token punctuation">)</span> <span class="token operator">+</span> means<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
    ax<span class="token punctuation">.</span>plot_surface<span class="token punctuation">(</span>x_plot<span class="token punctuation">,</span> y_plot<span class="token punctuation">,</span> z_plot<span class="token punctuation">,</span> color<span class="token operator">=</span>color<span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">)</span>

ax<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>means<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> means<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> means<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'black'</span><span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> marker<span class="token operator">=</span><span class="token string">'*'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'Means'</span><span class="token punctuation">)</span>
ax<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
ax<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span><span class="token string">'Feature 1'</span><span class="token punctuation">)</span>
ax<span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span><span class="token string">'Feature 2'</span><span class="token punctuation">)</span>
ax<span class="token punctuation">.</span>set_zlabel<span class="token punctuation">(</span><span class="token string">'Feature 3'</span><span class="token punctuation">)</span>
ax<span class="token punctuation">.</span>set_title<span class="token punctuation">(</span><span class="token string">'GMM Clustering'</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

</code></pre> 
<p>代码首先使用 np.random.multivariate_normal 函数生成了包含两个高斯分布的3维样本数据集，其中一个高斯分布的均值为(-2, -2, -2)，协方差矩阵为单位矩阵，另一个高斯分布的均值为(5, 5, 5)，协方差矩阵为2倍的单位矩阵。</p> 
<p>接下来，我们使用<code>GaussianMixture</code>类初始化了一个GMM模型，指定了要拟合的簇数为2，协方差矩阵类型为’full’。</p> 
<p>然后，我们训练GMM模型：调用fit方法对样本数据进行拟合，得到模型参数，包括每个高斯分布的均值、协方差矩阵和权重，调用predict方法预测每个样本所属的簇。</p> 
<p>最后,我们可视化结果：创建一个3D图形窗口，并将每个簇的样本数据用散点图表示出来。然后，对于每个高斯分布，使用其均值和协方差矩阵构造协方差椭球，并绘制在图中，以表示高斯分布的形状。最后，将每个高斯分布的均值用星号标记出来，以便于观察。</p> 
<p><img src="https://images2.imgbox.com/b6/61/CYVZDWY6_o.png" alt="代码可视化输出"></p> 
<p>在 Jupyter Notebook 环境中运行上述代码，从输出的3D可视化结果可以看出，GMM算法成功地将数据聚类为两个簇，并较好地捕捉到了每个簇的分布特征。</p> 
<p>GMM模型的主要优点是能同时进行聚类和概率密度估计，可以较好地拟合非高斯分布的数据。</p> 
<p>但它也存在一些缺陷，例如对离群点敏感、需要预先指定成分数等。通过调整协方差类型、增加稳健性等策略，可以进一步提升GMM的性能。</p> 
<p>总的来说，GMM是一种在聚类、异常检测、信号处理等领域都有广泛应用的无监督学习算法。</p> 
<p>得益于其能自动从原始数据挖掘隐藏知识的强大能力，无监督学习在诸多行业得到了广泛的应用，包括但不限于：生物信息学、金融、零售、网络安全、推荐系统等。无监督学习还是构建通用人工智能(AGI)的关键技术之一。</p> 
<p>随着算力和数据的不断增长，无监督学习无疑将在未来发挥越来越重要的作用，让人工智能系统能像人类一样，从海量原始数据中自主探索和学习，发现更多隐藏的规律和知识。</p> 
<p>正是凭借这种"隐形探索者"般的能力，无监督学习将持续为各行业的数据分析和决策注入新的活力，实现AI赋能、释放数据金矿的真正价值。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/0dc1c50225666bd2f564454410a1246c/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">彻底讲透：高并发场景下，MySQL处理并发修改同一行数据的安全方法</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/0097de95b8ecf722eb14541fca815b96/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Flink RocksDB状态后端优化总结</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>