<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>脑启发设计：人工智能的进化之路 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/c2153551f94f4c9911d741993fab7e3f/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="脑启发设计：人工智能的进化之路">
  <meta property="og:description" content="编者按：你可以用左手（不常用的那只手）的小指与食指拿起一件物品么？
试完你是不是发现自己竟然可以毫不费力地用自己不常用的手中，两根使用频率相对较低的手指，做一个不常做的动作。这就是人类大脑不可思议之处——无需经过特别的训练，大脑就能够在短时间内以低功耗的方式控制身体完成各种复杂行为，甚至是全新的动作。相比之下，人工智能虽然是人类智慧的产物，但在很多方面还远不及人类大脑。
为此，微软亚洲研究院（上海）团队的研究员们从理解大脑结构与活动中获得灵感，开发了一系列涵盖大脑学习、计算过程不同层级的创新技术，包括模仿脑神经回路连接方式，可高效处理众多任务的 CircuitNet 神经回路网络；可应用于时间序列预测，更适配神经拟态芯片的新型 SNN（脉冲神经网络）框架和策略；以及可为具身智能提供理论指导的贝叶斯行为框架。这些探索为未来的人工智能技术发展提供了新的可能。
从能耗的角度来看，人类大脑只需要大约20瓦的功率即可维持运转，这约等于一个节能灯泡的功耗。但随着人工智能大模型参数和规模的增大，其能源需求远高于传统的数据中心。主流的大语言模型训练过程预计会消耗上千兆瓦的电力，相当于数百个家庭一年的用电量。这种能源消耗的增长趋势显然不利于人工智能技术的可持续发展。那么如何通过新的处理机制解决能耗问题，就成了信息科学领域一个紧迫且前沿的挑战。
《千脑智能》一书为我们提供了启示：“要创造出真正智能的机器，我们首先需要对大脑进行逆向工程。我们研究大脑，不仅是为了理解它的工作原理，更是为了探索智能的本质。”
其实，人工智能本身就是人类对大脑探索的产物，在计算机诞生之初，人们就已经利用神经连接模式&#43;数字计算的方式模拟大脑。但受限于当时的算力和人们对大脑粗浅的认知，人工智能发展非常缓慢，甚至一度被束之高阁。近几十年来，随着神经科学家对大脑结构的深入理解和计算资源及相关技术的增强，以脑启发为核心的“人工智能文艺复兴”也掀起了新一轮热潮，促使科研人员重新定位大脑机制对人工智能的作用。
来自微软亚洲研究院（上海）的研究员们跨越计算机和脑科学专业知识，深入理解大脑的结构与行为活动，针对大脑学习和计算过程，从神经元、网络层和更高级别的系统层出发，分别设计研发了高性能的脉冲神经网络（SNN）、参数效率更高的回路神经网络（CircuitNet），以及提升决策效率的贝叶斯行为框架，促进了人工智能网络向着更低功耗、更高效率、更好性能的方向良性发展，同时也为具身智能发展提供了理论和方法。
CircuitNet：模拟大脑神经元连接，实现更低功耗与更高性能 人工神经网络（ANN）已经被广泛应用于人工智能的众多领域，包括自然语言处理、机器学习、语音识别和控制系统等。这些应用的成功，很大程度上得益于它们对大脑神经元工作模式的模仿。神经元是大脑最基本的单元，它们之间通过复杂的连接模式相互作用来传递和处理信息。但早期的人工神经网络设计相对简单，仅能模拟一两种连接模式。
随着神经科学的发展，人们发现大脑神经元的连接方式多种多样，其中有四种常见模式：前馈激励和抑制、反馈抑制、侧抑制和相互抑制。然而，现有的许多人工神经网络，如具有残差连接的网络，只能模拟前馈激励和抑制模式。即便是能够模拟循环模式的递归神经网络（RNN），在信息传入前也无法处理上游神经元间的复杂相互作用，从而影响了神经网络在不同机器学习任务中的表现。
图1：大脑神经元的四种连接模式
生物神经网络与人工神经网络的整体连接模式也大不相同。生物神经网络的一个显著特点是局部密集连接与全局稀疏连接的结合。尽管单个神经元可以有数千个突触，但它们大多数位于一个脑区内，形成针对特定任务的功能集群。只有少数突触作为不同脑区之间的桥梁，延伸到其它功能集群，而人工神经网络通常不具备这样的特性。此外，人工神经网络中的许多参数也被证实是冗余的，增加了网络的复杂性。
基于对大脑神经连接的新理解，研究员们提出了新的回路神经网络 CircuitNet，它能够模拟包括反馈和侧向模式在内的多种神经元连接模式。CircuitNet 的设计还借鉴了大脑神经元局部密集和全局稀疏连接的特性，通过不同电路模式单元（Circuit Motif Unit, CMU）的输入端和输出端的稀疏连接，实现了信号在不同 CMU 之间的多轮传输。
图2：CircuitNet 架构
实验结果表明，CircuitNet 在函数逼近、强化学习、图像分类和时间序列预测等任务中的表现超越了当前流行的神经网络架构。而且，在各种类型的任务中，CircuitNet 在达到与其它神经网络相同性能的同时，具有相当或更少的参数，展示了其在机器学习任务中的有效性和强大的泛化能力。
CircuitNet: A Generic Neural Network to Realize Universal Circuit Motif Modeling
https://openreview.net/pdf?id=Fl9q5z40e3
让SNN网络更适用于时间序列预测任务的新框架 脉冲神经网络（SNN）因其能效高、事件驱动范式和生物学上的合理性，正逐渐受到业内的重视。SNN 的设计灵感来源于生物神经网络中神经元间的信息传递方式——神经元不是在每次迭代传播中都被激活，只有膜电位达到特定阈值时才被激活，进行信号传递。这种事件驱动机制使得 SNN 只在接收到有效刺激时才进行信息处理，从而避免了无效计算，极大地提高了运算效率和能效比。
然而，研究员们发现，现有的 SNN 设计大多聚焦于其离散的事件驱动特性，有的会忽略其时间属性，有的则为了适应事件驱动范式过程，过度简化序列数据模式。这些方法虽然让 SNN 在图像分类、文本分类和序列图像分类任务上实现了与人工神经网络接近的性能，但并未充分发挥 SNN 在处理时间信号方面的潜力。
研究员们认为，时间序列预测是 SNN 一个理想的应用场景。作为现实数据分析的重要组成部分，时间序列预测广泛应用于交通、能源、医疗等领域，旨在基于按时间顺序排列的历史数据来预测未来。但是，将 SNN 应用于时间序列预测还面临两大挑战：
SNN 中脉冲值的离散特性与时间序列数据的浮点属性之间存在巨大的差异，需要一种有效的机制来减少在将浮点值转换为脉冲序列时的信息丢失和噪声。如何选择用于时序数据的 SNN 标准化模型目前还缺少一个指导方针，进而加剧了任务的复杂性，这就需要对 SNN 架构及其参数进行深入探索，以适应不同时间序列数据的特定特征。 研究员们提出了一个用于时间序列预测任务的 SNN 框架。该框架充分利用了脉冲神经元在处理时间序列信息上的高效性，成功实现了时间序列数据与 SNN 之间的时间同步。研究员们还设计了两种编码层，可以将连续时间序列数据转换为有意义的脉冲序列。这之后，研究员们又利用多种脉冲化的时间序列模型对脉冲序列进行了建模，得到了最终的预测结果。
图3：SNN 用于时间序列预测的新框架">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-07-04T17:53:15+08:00">
    <meta property="article:modified_time" content="2024-07-04T17:53:15+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">脑启发设计：人工智能的进化之路</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>编者按：你可以用左手（不常用的那只手）的小指与食指拿起一件物品么？</p> 
<p>试完你是不是发现自己竟然可以毫不费力地用自己不常用的手中，两根使用频率相对较低的手指，做一个不常做的动作。这就是人类大脑不可思议之处——无需经过特别的训练，大脑就能够在短时间内以低功耗的方式控制身体完成各种复杂行为，甚至是全新的动作。相比之下，人工智能虽然是人类智慧的产物，但在很多方面还远不及人类大脑。</p> 
<p>为此，微软亚洲研究院（上海）团队的研究员们从理解大脑结构与活动中获得灵感，开发了一系列涵盖大脑学习、计算过程不同层级的创新技术，包括模仿脑神经回路连接方式，可高效处理众多任务的 CircuitNet 神经回路网络；可应用于时间序列预测，更适配神经拟态芯片的新型 SNN（脉冲神经网络）框架和策略；以及可为具身智能提供理论指导的贝叶斯行为框架。这些探索为未来的人工智能技术发展提供了新的可能。</p> 
<hr> 
<p></p> 
<p class="img-center"><img alt="brain-inspired-ai-1-1024x576" height="576" src="https://images2.imgbox.com/3f/69/lwW0sr9y_o.jpg" width="1024"></p> 
<p>从能耗的角度来看，人类大脑只需要大约20瓦的功率即可维持运转，这约等于一个节能灯泡的功耗。但随着人工智能大模型参数和规模的增大，其能源需求远高于传统的数据中心。主流的大语言模型训练过程预计会消耗上千兆瓦的电力，相当于数百个家庭一年的用电量。这种能源消耗的增长趋势显然不利于人工智能技术的可持续发展。那么如何通过新的处理机制解决能耗问题，就成了信息科学领域一个紧迫且前沿的挑战。</p> 
<p>《千脑智能》一书为我们提供了启示：“要创造出真正智能的机器，我们首先需要对大脑进行逆向工程。我们研究大脑，不仅是为了理解它的工作原理，更是为了探索智能的本质。”</p> 
<p>其实，人工智能本身就是人类对大脑探索的产物，在计算机诞生之初，人们就已经利用神经连接模式+数字计算的方式模拟大脑。但受限于当时的算力和人们对大脑粗浅的认知，人工智能发展非常缓慢，甚至一度被束之高阁。近几十年来，随着神经科学家对大脑结构的深入理解和计算资源及相关技术的增强，以脑启发为核心的“人工智能文艺复兴”也掀起了新一轮热潮，促使科研人员重新定位大脑机制对人工智能的作用。</p> 
<p>来自微软亚洲研究院（上海）的研究员们跨越计算机和脑科学专业知识，深入理解大脑的结构与行为活动，针对大脑学习和计算过程，从神经元、网络层和更高级别的系统层出发，分别设计研发了高性能的脉冲神经网络（SNN）、参数效率更高的回路神经网络（CircuitNet），以及提升决策效率的贝叶斯行为框架，促进了人工智能网络向着更低功耗、更高效率、更好性能的方向良性发展，同时也为具身智能发展提供了理论和方法。</p> 
<h3>CircuitNet：模拟大脑神经元连接，实现更低功耗与更高性能</h3> 
<p>人工神经网络（ANN）已经被广泛应用于人工智能的众多领域，包括自然语言处理、机器学习、语音识别和控制系统等。这些应用的成功，很大程度上得益于它们对大脑神经元工作模式的模仿。神经元是大脑最基本的单元，它们之间通过复杂的连接模式相互作用来传递和处理信息。但早期的人工神经网络设计相对简单，仅能模拟一两种连接模式。</p> 
<p>随着神经科学的发展，人们发现大脑神经元的连接方式多种多样，其中有四种常见模式：前馈激励和抑制、反馈抑制、侧抑制和相互抑制。然而，现有的许多人工神经网络，如具有残差连接的网络，只能模拟前馈激励和抑制模式。即便是能够模拟循环模式的递归神经网络（RNN），在信息传入前也无法处理上游神经元间的复杂相互作用，从而影响了神经网络在不同机器学习任务中的表现。</p> 
<p></p> 
<p class="img-center"><img alt="图1：大脑神经元的四种连接模式" height="225" src="https://images2.imgbox.com/ff/d9/uQeNv0NH_o.png" width="854"></p> 
<p id="caption-attachment-47715"><em>图1：大脑神经元的四种连接模式</em></p> 
<p>生物神经网络与人工神经网络的整体连接模式也大不相同。生物神经网络的一个显著特点是局部密集连接与全局稀疏连接的结合。尽管单个神经元可以有数千个突触，但它们大多数位于一个脑区内，形成针对特定任务的功能集群。只有少数突触作为不同脑区之间的桥梁，延伸到其它功能集群，而人工神经网络通常不具备这样的特性。此外，人工神经网络中的许多参数也被证实是冗余的，增加了网络的复杂性。</p> 
<p>基于对大脑神经连接的新理解，研究员们提出了新的回路神经网络 CircuitNet，它能够模拟包括反馈和侧向模式在内的多种神经元连接模式。CircuitNet 的设计还借鉴了大脑神经元局部密集和全局稀疏连接的特性，通过不同电路模式单元（Circuit Motif Unit, CMU）的输入端和输出端的稀疏连接，实现了信号在不同 CMU 之间的多轮传输。</p> 
<p></p> 
<p class="img-center"><img alt="图2：CircuitNet 架构" height="205" src="https://images2.imgbox.com/98/e5/v8RcWXCi_o.png" width="696"></p> 
<p id="caption-attachment-47716"><em>图2：CircuitNet 架构</em></p> 
<p>实验结果表明，CircuitNet 在函数逼近、强化学习、图像分类和时间序列预测等任务中的表现超越了当前流行的神经网络架构。而且，在各种类型的任务中，CircuitNet 在达到与其它神经网络相同性能的同时，具有相当或更少的参数，展示了其在机器学习任务中的有效性和强大的泛化能力。</p> 
<p>CircuitNet: A Generic Neural Network to Realize Universal Circuit Motif Modeling</p> 
<p>https://openreview.net/pdf?id=Fl9q5z40e3</p> 
<h3>让SNN网络更适用于时间序列预测任务的新框架</h3> 
<p>脉冲神经网络（SNN）因其能效高、事件驱动范式和生物学上的合理性，正逐渐受到业内的重视。SNN 的设计灵感来源于生物神经网络中神经元间的信息传递方式——神经元不是在每次迭代传播中都被激活，只有膜电位达到特定阈值时才被激活，进行信号传递。这种事件驱动机制使得 SNN 只在接收到有效刺激时才进行信息处理，从而避免了无效计算，极大地提高了运算效率和能效比。</p> 
<p>然而，研究员们发现，现有的 SNN 设计大多聚焦于其离散的事件驱动特性，有的会忽略其时间属性，有的则为了适应事件驱动范式过程，过度简化序列数据模式。这些方法虽然让 SNN 在图像分类、文本分类和序列图像分类任务上实现了与人工神经网络接近的性能，但并未充分发挥 SNN 在处理时间信号方面的潜力。</p> 
<p>研究员们认为，时间序列预测是 SNN 一个理想的应用场景。作为现实数据分析的重要组成部分，时间序列预测广泛应用于交通、能源、医疗等领域，旨在基于按时间顺序排列的历史数据来预测未来。但是，将 SNN 应用于时间序列预测还面临两大挑战：</p> 
<ul><li>SNN 中脉冲值的离散特性与时间序列数据的浮点属性之间存在巨大的差异，需要一种有效的机制来减少在将浮点值转换为脉冲序列时的信息丢失和噪声。</li><li>如何选择用于时序数据的 SNN 标准化模型目前还缺少一个指导方针，进而加剧了任务的复杂性，这就需要对 SNN 架构及其参数进行深入探索，以适应不同时间序列数据的特定特征。</li></ul> 
<p>研究员们提出了一个用于时间序列预测任务的 SNN 框架。该框架充分利用了脉冲神经元在处理时间序列信息上的高效性，成功实现了时间序列数据与 SNN 之间的时间同步。研究员们还设计了两种编码层，可以将连续时间序列数据转换为有意义的脉冲序列。这之后，研究员们又利用多种脉冲化的时间序列模型对脉冲序列进行了建模，得到了最终的预测结果。</p> 
<p></p> 
<p class="img-center"><img alt="图3：SNN 用于时间序列预测的新框架" height="331" src="https://images2.imgbox.com/e9/37/rgNhuNAn_o.png" width="746"></p> 
<p id="caption-attachment-47717"><em>图3：SNN 用于时间序列预测的新框架</em></p> 
<p>通过在多个时间序列预测基准集上的测试，研究员们证实了 SNN 方法在时间序列预测中的有效性。该方法不仅展现出与传统时间序列预测方法相媲美或更优的性能，而且显著降低了能耗。</p> 
<p>此外，在分析实验中，研究员们还展示了 SNN 如何捕获时间序列数据中的时间依赖性，并发现 SNN 确实能够模拟时间序列数据的内在动态。这项研究为 SNN 领域提供了一个既节能，又符合生物学原理的时间序列预测新方案。</p> 
<p>Efficient and Effective Time-Series Forecasting with Spiking Neural Networks</p> 
<p>https://arxiv.org/pdf/2402.01533</p> 
<h3>大脑中枢模式发生器与位置编码双加持，让SNN序列预测更上一层楼</h3> 
<p>尽管 SNN 在多个领域取得了显著进展，但它们在适应不同类型任务时仍面临挑战。SNN 作为事件驱动的系统，缺乏有效机制来捕获索引信息、节奏模式和周期性数据，从而限制了它们处理自然语言和时间序列等数据模式的能力。而且，SNN 依赖于脉冲形式的通信，这使得并非所有适用于人工神经网络的深度学习技术都能直接迁移到 SNN 上。</p> 
<p>为了克服这些限制，研究员们进一步从生物神经学机制中汲取灵感，基于人类大脑中枢模式发生器（Central Pattern Generator, CPG）和位置编码（Positional Encoding，PE）技术，开发了针对 SNN 的新型位置编码技术 CPG-PE。</p> 
<p><em>中枢模式发生器（CPG）：在神经科学中，CPG 是一组能够在不需要节奏输入的情况下，产生有节奏的模式输出的神经元。这些神经回路位于脊髓和脑干中，负责产生控制运动、呼吸和咀嚼等重要活动的有节奏信号。</em></p> 
<p><em>位置编码（PE）：PE 是人工神经网络中的一项关键技术，尤其在序列处理任务中尤为重要。通过为输入序列的每个元素赋予位置信息，PE 使神经网络能够识别序列中元素的顺序和相对位置。</em></p> 
<p>CPG 和 PE 都能产生周期性输出，CPG 是相对于时间的输出，而 PE 则是相对于位置的输出。研究员们将两者类比，使 CPG-PE 可以编码时间或空间的位置信息，预测神经信号的来源或位置。</p> 
<p></p> 
<p class="img-center"><img alt="图4：CPG-PE 在 SNN 中的应用。X、X′ 和 Xoutput 是脉冲矩阵。" height="289" src="https://images2.imgbox.com/d0/f5/5ezes3uM_o.png" width="980"></p> 
<p id="caption-attachment-47718"><em>图4：CPG-PE 在 SNN 中的应用。X、X′ 和 Xoutput 是脉冲矩阵。</em></p> 
<p>在 Metr-la（洛杉矶高速公路平均交通速度数据）、Pems-bay（湾区平均交通速度数据）、Electricity（以千瓦时 kWh 测量的每小时电力消耗数据）和 Solar（太阳能发电数据）四个真实世界数据集上进行的时间序列预测实验表明，采用 CPG-PE 策略的 SNN 在时间序列分析方面显著优于没有 PE 特性的神经网络。同时，CPG-PE 可以无缝集成到任何能够处理序列的 SNN 中，理论上可以实现与 SNN 硬件的兼容，适配各类神经拟态芯片。</p> 
<p></p> 
<p class="img-center"><img alt="表1：CPG-PE 在具有不同预测的4个基准集上的时间序列预测实验结果，预测长度为6，24，48，96。“PE”代表位置编码。“w/o”表示“没有”，“w/”表示“有”。粗体格式显示 SNN 的最佳结果。↑（↓）表示越高（越低）越好。" height="401" src="https://images2.imgbox.com/2d/d0/KaitjHYf_o.png" width="1026"></p> 
<p id="caption-attachment-47719">表1：CPG-PE 在具有不同预测的4个基准集上的时间序列预测实验结果，预测长度为6，24，48，96。“PE”代表位置编码。“w/o”表示“没有”，“w/”表示“有”。粗体格式显示 SNN 的最佳结果。↑（↓）表示越高（越低）越好。</p> 
<p>Advancing Spiking Neural Networks for Sequential Modeling with Central Pattern Generators</p> 
<p>https://arxiv.org/pdf/2405.14362</p> 
<h3>贝叶斯行为框架：为具身智能提供理论指导</h3> 
<p>在心理学和认知神经科学领域，以人类为代表的智能生物群体被认为会执行两类行为：习惯性行为和目标导向行为。习惯性行为是指为了最大化利益而自动执行的动作，无需意识思考或意图的参与，例如寻找食物和避免危险。目标导向行为是指为了实现特定目标而执行的动作，例如有计划地前往某个地点。传统上认为，在认知科学和机器学习中，习惯性行为和目标导向行为由两套独立的系统控制，因此在建模时，研究人员通常会为这两种行为设计独立的模型。</p> 
<p>然而，微软亚洲研究院的研究员们认为，这两种系统应该更紧密地结合，实现协同学习和工作。尽管在大脑中这两种系统之间的相互作用尚未完全明了，但习惯性行为和目标导向行为共享着诸如脑干这样的下游神经回路。两种行为共享低级运动技能，且每个系统都可能利用对方学习到的高级动作。例如，习惯性行为虽然缺乏灵活性，但通过练习可以提供熟练的运动技能，这些技能可以被目标导向行为用于更复杂的任务规划。那么如何在保持两种行为差异的同时实现协同？</p> 
<p>为此，研究员们提出了一个基于变分贝叶斯方法的理论框架——贝叶斯行为（Bayesian Behavior）框架，用于理解感知运动学习中的行为。其核心创新在于引入了一个贝叶斯“意图”（intention）变量，从而有效地连接了习惯性行为与目标导向行为。</p> 
<p>习惯性行为由感官输入计算的意图先验分布驱动，无需具体目标。目标导向行为则由一个通过最小化变分自由能推断（active inference）的目标条件意图后验分布引导。</p> 
<p></p> 
<p class="img-center"><img alt="图5：（a）贝叶斯行为框架概述；（b）和（c）学习过程和行为过程框架图" height="633" src="https://images2.imgbox.com/95/22/Usg4c7uj_o.png" width="1198"></p> 
<p id="caption-attachment-47720">图5：（a）贝叶斯行为框架概述；（b）和（c）学习过程和行为过程框架图</p> 
<p>在视觉引导的感知运动任务中进行模拟实验的测试结果显示，贝叶斯行为框架所得出的结论与神经科学和心理学实验的观察数据相吻合。这一发现不仅为认知科学中“行为”的理解提供了新的视角，也为具身智能的构建提供了理论基础。例如，人类能够轻松地用左手食指和小指拿起东西，或者原地转圈，未来的具身智能也可能完成这种未曾学习过的动作，展现出更高的适应性和灵活性。</p> 
<p>Synergizing Habits and Goals with Variational Bayes</p> 
<p>https://www.nature.com/articles/s41467-024-48577-7</p> 
<p>*该论文已在《自然-通讯》（Nature Communications）杂志上发表。</p> 
<h3>跨领域研究让人工智能向节能高效进化</h3> 
<p>从达尔文进化论的角度来看，现在的主流人工智能模型在未来可能会面临淘汰。在生物进化的过程中，物种的基因变异是繁殖下一代时的常态。那些有利于生物适应环境的变异，将通过环境的筛选，以“适者生存”的原则被保留下来。然而，将这一概念应用于人工智能时，我们会发现能耗问题并不利于人工智能的发展和“进化”。</p> 
<p>借鉴人脑的工作原理，构建脑启发的人工智能，不失为促进人工智能技术向节能高效方向发展的有效途径。这一趋势已经引发了新的研究热潮，包括对大脑理解的研究、基于神经元构建新的语言模型、根据不同脑区功能设计的 MoE 架构等脑启发人工智能正蓬勃发展。</p> 
<p>在微软亚洲研究院进行脑启发式人工智能研究的过程中，研究员们更加体会到跨学科、跨领域专家协作支持的重要性。CircuitNet、SNN 时间序列框架、贝叶斯行为框架等创新成果的背后，凝聚了来自复旦大学、上海交通大学及日本冲绳科学技术大学院大学等机构的神经科学和脑科学专家的专业知识和贡献。</p> 
<p>未来，随着对大脑机理的深入理解和技术的不断创新，我们有望增进对智能本质的理解，构建出更加智能、高效且环保的人工智能技术，更好地服务于人类社会。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/86676fb5cf12b6638e57bace1004f7d5/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">elementUI中table组件固定列时会渲染两次模板内容问题</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/3c309cd0dcd3df3ae9157ae5f5964833/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">信创产业政策，信创测试方面</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>