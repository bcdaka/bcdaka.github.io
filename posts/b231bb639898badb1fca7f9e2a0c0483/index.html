<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>python绘制三国演义词云图 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/b231bb639898badb1fca7f9e2a0c0483/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="python绘制三国演义词云图">
  <meta property="og:description" content="导入模块 1.jieba的安装与使用
pip install jieba conda install -c conda-forge jieba Python2.X版
全自动安装：easy_install jieba 或者 pip install jieba半自动安装：先下载http://pypi.python.org/pypi/jieba/ ，解压后运行python setup.py install手动安装：将jieba目录放置于当前目录或者site-packages目录通过import jieba 来引用 Python3.X版
目前master分支是只支持Python2.x 的
Python3.x 版本的分支也已经基本可用： https://github.com/fxsjy/jieba/tree/jieba3k
git clone https://github.com/fxsjy/jieba.git git checkout jieba3k python setup.py install 使用国人开发的jieba（结巴的拼音）库来进行智能分词，并加入空格，才能被wordcloud库所用。
中文智能分词：‘西安全城下大雨’，应该分成‘西安’，‘全城’，‘下大雨’。而不是‘西’，‘安全’，‘城下’，‘大雨’
(1)jieba分词的三种模式：精确模式、全模式、搜索引擎模式
- 精确模式：把文本精确的切分开，不存在冗余单词
- 全模式：把文本中所有可能的词语都扫描出来，有冗余
- 搜索引擎模式：在精确模式基础上，对长词再次切分
(2)jieba库常用函数
①分词
jieba.cut方法接受两个输入参数: 1) 第一个参数为需要分词的字符串 2）cut_all参数用来控制是否采用全模式jieba.cut_for_search方法接受一个参数：需要分词的字符串,该方法适合用于搜索引擎构建倒排索引的分词，粒度比较细注意：待分词的字符串可以是gbk字符串、utf-8字符串或者unicodejieba.cut以及jieba.cut_for_search返回的结构都是一个可迭代的generator，可以使用for循环来获得分词后得到的每一个词语(unicode)，也可以用list(jieba.cut(...))转化为list ②词性标注 标注句子分词后每个词的词性，采用和ictclas兼容的标记法
&gt;&gt;&gt; import jieba.posseg as pseg &gt;&gt;&gt; words = pseg.cut(&#34;我爱北京天安门&#34;) &gt;&gt;&gt; for w in words: ... print w.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2023-12-01T11:08:28+08:00">
    <meta property="article:modified_time" content="2023-12-01T11:08:28+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">python绘制三国演义词云图</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2><strong>导入模块</strong></h2> 
<p style="margin-left:.0001pt;text-align:justify;"><strong>1.jieba的安装与使用</strong></p> 
<pre><code class="language-python">pip install jieba
conda install -c conda-forge jieba</code></pre> 
<p style="margin-left:.0001pt;text-align:justify;"><strong>Python2.X版</strong></p> 
<ul><li>全自动安装：<code>easy_install jieba</code> 或者 <code>pip install jieba</code></li><li>半自动安装：先下载<a href="https://gitee.com/link?target=http%3A%2F%2Fpypi.python.org%2Fpypi%2Fjieba%2F" rel="nofollow" title="http://pypi.python.org/pypi/jieba/">http://pypi.python.org/pypi/jieba/</a> ，解压后运行python setup.py install</li><li>手动安装：将jieba目录放置于当前目录或者site-packages目录</li><li>通过import jieba 来引用</li></ul> 
<p><strong>Python3.X版</strong></p> 
<ul><li> <p>目前master分支是只支持Python2.x 的</p> </li><li> <p>Python3.x 版本的分支也已经基本可用： <a href="https://gitee.com/link?target=https%3A%2F%2Fgithub.com%2Ffxsjy%2Fjieba%2Ftree%2Fjieba3k" title="https://github.com/fxsjy/jieba/tree/jieba3k">https://github.com/fxsjy/jieba/tree/jieba3k</a></p> </li><li> <pre><code class="language-python"> git clone https://github.com/fxsjy/jieba.git
 git checkout jieba3k
 python setup.py install</code></pre> </li></ul> 
<p style="margin-left:.0001pt;text-align:justify;">        使用国人开发的jieba（结巴的拼音）库来进行智能分词，并加入空格，才能被wordcloud库所用。</p> 
<p style="margin-left:.0001pt;text-align:justify;">        中文智能分词：‘西安全城下大雨’，应该分成‘西安’，‘全城’，‘下大雨’。而不是‘西’，‘安全’，‘城下’，‘大雨’</p> 
<p style="margin-left:.0001pt;text-align:justify;"><strong>(1)jieba分词的三种模式：精确模式、全模式、搜索引擎模式</strong></p> 
<p style="margin-left:.0001pt;text-align:justify;">        - 精确模式：把文本精确的切分开，不存在冗余单词</p> 
<p style="margin-left:.0001pt;text-align:justify;">        - 全模式：把文本中所有可能的词语都扫描出来，有冗余</p> 
<p style="margin-left:.0001pt;text-align:justify;">        - 搜索引擎模式：在精确模式基础上，对长词再次切分</p> 
<p style="margin-left:.0001pt;text-align:justify;"><strong>(2)jieba库常用函数</strong></p> 
<p style="margin-left:.0001pt;text-align:justify;"><strong>①分词</strong></p> 
<ul><li><code>jieba.cut</code>方法接受两个输入参数: 1) 第一个参数为需要分词的字符串 2）cut_all参数用来控制是否采用全模式</li><li><code>jieba.cut_for_search</code>方法接受一个参数：需要分词的字符串,该方法适合用于搜索引擎构建倒排索引的分词，粒度比较细</li><li>注意：待分词的字符串可以是gbk字符串、utf-8字符串或者unicode</li><li><code>jieba.cut</code>以及<code>jieba.cut_for_search</code>返回的结构都是一个可迭代的generator，可以使用for循环来获得分词后得到的每一个词语(unicode)，也可以用list(jieba.cut(...))转化为list</li></ul> 
<p><strong>②词性标注 </strong></p> 
<ul><li> <p>标注句子分词后每个词的词性，采用和ictclas兼容的标记法</p> </li><li> <pre><code class="language-python">  &gt;&gt;&gt; import jieba.posseg as pseg
  &gt;&gt;&gt; words = pseg.cut("我爱北京天安门")
  &gt;&gt;&gt; for w in words:
  ...    print w.word, w.flag
  ...
  我 r
  爱 v
  北京 ns
  天安门 ns</code></pre> <p></p> </li></ul> 
<p><strong>2.词云wordcloud库的安装与使用</strong></p> 
<p style="margin-left:.0001pt;text-align:justify;">        词云（Word Cloud）是对文本中出现频率较高的词语给予视觉化展示的图形, 是一种常见的文本挖掘的方法。wordcloud是优秀的词云展示第三方库，wordcloud能够将一段文本变成一个词云。词云在我们的生活中经常能够看到，无论是中文的词云还是英文的词云。   </p> 
<p style="margin-left:.0001pt;text-align:justify;"><strong>（1）wordcloud库的安装</strong></p> 
<pre><code class="language-python">pip install wordcloud 

conda install -c conda-forge wordcloud</code></pre> 
<p style="margin-left:.0001pt;text-align:justify;"><strong>（2）wordcloud库的使用</strong></p> 
<p style="margin-left:.0001pt;text-align:justify;">        wordcloud库把词云当做一个WordCloud对象，</p> 
<p style="margin-left:.0001pt;text-align:justify;">        即wordcloud.WordCloud()是一个代表文本对应词云的对象，一个词云就是一个WordCloud对象。wordcloud库可以根据文本中词语出现的频率等一系列参数来绘制词云，在绘制词云时，词云的形状、尺寸、颜色包括字体都是可以设定的。</p> 
<p style="margin-left:.0001pt;text-align:justify;">        由文本变为词云，wordcloud库大概做了4件事：1.wordcloud库以空格为分隔符，将文本分割成单词；2.wordcloud库会在文本中统计每一个单词出现的次数，单词出现次数越多，那么单词显示的词云效果的字体越大，反之则反。并且将只有1到2个字符的单词过滤掉；3.wordcloud库会根据统计单词出现的次数，为不同的单词配置显示的字号；4.进行布局。</p> 
<h2 style="margin-left:.0001pt;text-align:justify;"><strong>一.实验步骤 </strong></h2> 
<h3 style="margin-left:.0001pt;text-align:justify;"><strong>Step1）安装jieba库，wordcloud库</strong></h3> 
<p style="margin-left:.0001pt;text-align:justify;"><strong>1.</strong><strong>PyCharm</strong><strong>环境安装</strong></p> 
<p style="margin-left:.0001pt;text-align:justify;"><strong>①安装jieba库</strong></p> 
<p style="margin-left:.0001pt;text-align:center;"><img alt="" src="https://images2.imgbox.com/96/d2/Y0xIs9oU_o.png"></p> 
<p style="margin-left:.0001pt;text-align:justify;"><strong>②安装wordcloud库</strong></p> 
<p style="margin-left:.0001pt;text-align:center;"><img alt="" src="https://images2.imgbox.com/93/ac/lbnOmqDg_o.png"></p> 
<p></p> 
<p style="margin-left:.0001pt;text-align:justify;"><strong>2.检查环境安装</strong></p> 
<p style="margin-left:.0001pt;text-align:justify;"><strong>①检查jieba库</strong></p> 
<p style="margin-left:.0001pt;text-align:justify;"><img alt="" height="52" src="https://images2.imgbox.com/85/71/JzlYe4BJ_o.png" width="1200"></p> 
<p><strong> ②检查wordcloud库</strong></p> 
<p><img alt="" height="341" src="https://images2.imgbox.com/b3/88/CJD4JydN_o.png" width="1200"></p> 
<h3 style="margin-left:.0001pt;text-align:justify;"><strong>Step2）导入jieba、wordcloud模块</strong></h3> 
<pre><code class="language-python"># 导入模块
import jieba  # 分词
import wordcloud as wc  # 词云
import jieba.posseg as pseg</code></pre> 
<h3 style="margin-left:.0001pt;text-align:justify;"><strong>Step3）导入“三国演义.txt”文件</strong></h3> 
<p style="margin-left:.0001pt;text-align:justify;">文件操作的步骤为：</p> 
<p style="margin-left:.0001pt;text-align:justify;"><img alt="" height="466" src="https://images2.imgbox.com/55/81/YKi82w3B_o.png" width="790"></p> 
<p style="margin-left:.0001pt;text-align:justify;">为了简便操作，本实验选用with语句导入文件。</p> 
<pre><code class="language-python"># 导入文件“三国演义”
with open(r'C:\Users\ROG\Desktop\三国演义.txt', 'r',encoding='utf-8') as f:
    tf = f.read()</code></pre> 
<h3 style="margin-left:.0001pt;text-align:justify;"><strong>Step4）对文件对象精选分词和词性标注</strong></h3> 
<p style="margin-left:.0001pt;text-align:justify;">        由于jieba库中，jieba.lcut方法只能分词，不能标注词语的词性，本实验采用jieba库中pseg模块，利用pseg.lcut方法，完成分词并标注词性。</p> 
<pre><code class="language-python"># 分词
seg_list = pseg.lcut(tf)</code></pre> 
<h3 style="margin-left:.0001pt;text-align:justify;"><strong>Step5）词频统计</strong></h3> 
<p style="margin-left:.0001pt;text-align:justify;">        由于实验目的是为了将《三国演义》中常见人名进行去重后生成词云，所以，本实验对词语进行了筛选，分别进行了以下三种筛选操作：</p> 
<p style="margin-left:.0001pt;text-align:justify;"><img alt="" height="741" src="https://images2.imgbox.com/2e/f7/5dhabUf8_o.png" width="897"></p> 
<p style="text-align:justify;"><strong>①词语长度筛选</strong></p> 
<pre><code class="language-python">if len(word.word) &gt;= 2</code></pre> 
<p><strong>②词语词性筛选</strong></p> 
<p style="margin-left:.0001pt;text-align:justify;">查询jieba词性标注表：</p> 
<p style="margin-left:.0001pt;text-align:justify;"><img alt="" height="132" src="https://images2.imgbox.com/b6/4d/Ib2ZpkY6_o.png" width="1200"></p> 
<pre><code class="language-python">word.flag == 'nrfg' or word.flag == 'nr'</code></pre> 
<p><strong> ③人名去重</strong></p> 
<pre><code class="language-python">        if word.word in ('玄德','玄德曰','刘皇叔','皇叔'):
            rword = '刘备'
        elif word.word in ('乱世奸雄','治世能臣','阿瞒','乱世枭雄','孟德','丞相'):
            rword = '曹操'
        elif word.word in ('碧眼小儿','紫髯鼠辈','孙仲谋'):
            rword = '孙权'
        elif word.word in ('诸葛亮','卧龙先生','伏龙','军师','孔明曰'):
            rword = '孔明'
        elif word.word in ('关公','云长'):
            rword = '关羽'
        else:
            rword = word.word</code></pre> 
<p style="margin-left:.0001pt;text-align:justify;">统计词频本实验采用字典get（）方法</p> 
<pre><code class="language-python">counts[rword] = counts.get(rword,0) + 1</code></pre> 
<p style="margin-left:.0001pt;text-align:justify;">词频统计完整代码：</p> 
<pre><code class="language-python"># 词频统计
counts = {}
for word in seg_list:
    if len(word.word) &gt;= 2 and ( word.flag == 'nrfg' or word.flag == 'nr' ):
        if word.word in ('玄德','玄德曰','刘皇叔','皇叔'):
            rword = '刘备'
        elif word.word in ('乱世奸雄','治世能臣','阿瞒','乱世枭雄','孟德','丞相'):
            rword = '曹操'
        elif word.word in ('碧眼小儿','紫髯鼠辈','孙仲谋'):
            rword = '孙权'
        elif word.word in ('诸葛亮','卧龙先生','伏龙','军师','孔明曰'):
            rword = '孔明'
        elif word.word in ('关公','云长'):
            rword = '关羽'
        else:
            rword = word.word
        counts[rword] = counts.get(rword,0) + 1</code></pre> 
<h3 style="margin-left:.0001pt;text-align:justify;"><strong>Step6）词频排序</strong></h3> 
<p style="margin-left:.0001pt;text-align:justify;">        本实验采用列表sort（）函数排序，sort() 函数用于对原列表进行排序，key参数采用匿名函数lambda x:x[1]，reverse参数选择True。</p> 
<pre><code class="language-python"># 词频排序
items = list(counts.items())
items.sort(key= lambda x:x[1],reverse=True)</code></pre> 
<h3 style="margin-left:.0001pt;text-align:justify;"><strong>Step7）输出词频前20个人名</strong></h3> 
<pre><code class="language-python"># 输出词频前20个人名
for i in range(20):
    word, count = items[i]
    print("{}:{}".format(word,count))</code></pre> 
<h3 style="margin-left:.0001pt;text-align:justify;"><strong>Step8）绘制词云图</strong></h3> 
<p style="margin-left:.0001pt;text-align:justify;">        本实验采用wordcloud库WordCloud方法绘制词云图，参数设置如下：</p> 
<p style="margin-left:.0001pt;text-align:justify;">        图片背景颜色：background_color='white'</p> 
<p style="margin-left:.0001pt;text-align:justify;">        图片宽：width=2000</p> 
<p style="margin-left:.0001pt;text-align:justify;">        图片高：height=1600</p> 
<p style="margin-left:.0001pt;text-align:justify;">        最多显示词语数量：max_words=1000</p> 
<p style="margin-left:.0001pt;text-align:justify;">        字体：font_path="C:/Windows/Fonts/simhei.ttf"</p> 
<p style="margin-left:.0001pt;text-align:justify;">        采用wordcloud库generate_from_frequencies方法根据词频字典，依据词频数，绘制词云图。</p> 
<p style="margin-left:.0001pt;text-align:justify;">        将图片保存至C:/Users/ROG/Desktop，命名为：三国演义词云图.jpg</p> 
<p style="margin-left:.0001pt;text-align:justify;">        绘制词云图完整代码如下：</p> 
<pre><code class="language-python"># 绘制词云图
w = wc.WordCloud( background_color='white',
                  width=2000 ,
                  height=1600 ,
                  max_words=1000 ,
                  font_path="C:/Windows/Fonts/simhei.ttf"  )
w.generate_from_frequencies(counts)

# 保存图片
w.to_file("C:/Users/ROG/Desktop/三国演义词云图.jpg")</code></pre> 
<p style="margin-left:.0001pt;text-align:justify;">全过程代码如下：</p> 
<pre><code class="language-python"># 导入模块
import jieba  # 分词
import wordcloud as wc  # 词云
import jieba.posseg as pseg

# 导入文件“三国演义”
with open(r'C:\Users\ROG\Desktop\三国演义.txt', 'r',encoding='utf-8') as f:
    tf = f.read()

# 分词
seg_list = pseg.lcut(tf)

# 词频统计
counts = {}
for word in seg_list:
    if len(word.word) &gt;= 2 and ( word.flag == 'nrfg' or word.flag == 'nr' ):
        if word.word in ('玄德','玄德曰','刘皇叔','皇叔'):
            rword = '刘备'
        elif word.word in ('乱世奸雄','治世能臣','阿瞒','乱世枭雄','孟德','丞相'):
            rword = '曹操'
        elif word.word in ('碧眼小儿','紫髯鼠辈','孙仲谋'):
            rword = '孙权'
        elif word.word in ('诸葛亮','卧龙先生','伏龙','军师','孔明曰'):
            rword = '孔明'
        elif word.word in ('关公','云长'):
            rword = '关羽'
        else:
            rword = word.word
        counts[rword] = counts.get(rword,0) + 1


# 词频排序
items = list(counts.items())
items.sort(key= lambda x:x[1],reverse=True)

# 输出词频前20个人名
for i in range(20):
    word, count = items[i]
    print("{}:{}".format(word,count))

# 绘制词云图
w = wc.WordCloud( background_color='white',
                  width=2000 ,
                  height=1600 ,
                  max_words=1000 ,
                  font_path="C:/Windows/Fonts/simhei.ttf"  )
w.generate_from_frequencies(counts)

# 保存图片
w.to_file("C:/Users/ROG/Desktop/三国演义词云图.jpg")</code></pre> 
<h2 style="margin-left:.0001pt;text-align:justify;">二．数据记录与处理</h2> 
<h3 style="margin-left:.0001pt;text-align:justify;">1.词频排名前20的人名</h3> 
<p><img alt="" height="655" src="https://images2.imgbox.com/c7/7a/Ega6Mgk3_o.png" width="369"></p> 
<h3 style="margin-left:.0001pt;text-align:justify;">2.三国演义人名词云图</h3> 
<p><img alt="" height="962" src="https://images2.imgbox.com/15/c0/7y7x0sjP_o.png" width="1200"></p> 
<h2 style="margin-left:.0001pt;text-align:justify;">三．结果分析</h2> 
<p style="margin-left:.0001pt;text-align:justify;">           根据词云图结合词频统计表分析可知：</p> 
<p style="margin-left:.0001pt;text-align:justify;">        《三国演义》中出现频率最高的人物是刘备，出乎很多资深读者意料地，刘皇叔力压「三绝」排名榜首。其次是孔明，从出山后就是演义核心看点，曹刘死后一段故事的当然主角。紧接着是曹操，乱世枭雄，天下英雄谁敌手？三国演义前半部分，讲的就是曹刘的故事。</p> 
<p style="margin-left:.0001pt;text-align:justify;">        由此也可以反映出作者罗贯中“尊刘抑曹”的态度。“尊刘”的原因是刘备代表汉朝皇室正统，反映了广大人民渴望统一，反对分裂、拥护仁政，反对暴政的根本要求；他把诸葛亮塑造为智慧的化身，极大地鼓舞了人们对自身能力的信心，促使人们在斗争实践中不断丰富和发展自己的智慧；</p> 
<h2>四.实验改进 </h2> 
<h3 style="margin-left:.0001pt;text-align:justify;"><strong><strong>Step1）提高分词精确度</strong></strong></h3> 
<p style="margin-left:.0001pt;text-align:justify;">        可以发现，在词频统计时，程序把“魏兵”、“曹兵”误认为人名，程序精确度还需进一步提升。</p> 
<p style="margin-left:.0001pt;text-align:justify;">        通过建立去除词库，利用遍历的思想，去除错误识别词。</p> 
<pre><code class="language-python"># 去除停用词
list_tf2 = tf2.split()
for i in list_tf2:
    del(counts[i])

# 词频排序
items = list(counts.items())
items.sort(key= lambda x:x[1],reverse=True)</code></pre> 
<p style="margin-left:.0001pt;text-align:justify;">        去除后的词频统计结果为：</p> 
<p style="margin-left:.0001pt;text-align:justify;"><img alt="" height="709" src="https://images2.imgbox.com/b4/99/9xQ5Pit4_o.png" width="249"><img alt="" height="528" src="https://images2.imgbox.com/b0/d3/HQbCe60k_o.png" width="879"></p> 
<p style="margin-left:.0001pt;text-align:justify;">可以看出，去除后的词频统计均为人名。</p> 
<h3 style="margin-left:.0001pt;text-align:justify;"><strong><strong>Step2）改变词云图形状</strong></strong></h3> 
<p style="margin-left:.0001pt;text-align:justify;">导入模块</p> 
<pre><code class="language-python">import numpy as np
from PIL import Image</code></pre> 
<p style="margin-left:.0001pt;text-align:justify;">读取底板图形文件：</p> 
<pre><code class="language-python">pic = np.array(Image.open('C:/Users/ROG/Desktop/图片3.png'))</code></pre> 
<p style="margin-left:.0001pt;text-align:justify;">调整词云图参数：</p> 
<pre><code class="language-python">w = wc.WordCloud( background_color='white',
                  mask=pic,
                  width=2000 ,
                  height=1600 ,
                  max_words=1000 ,
                  font_path="C:/Windows/Fonts/simhei.ttf"  )
w.generate_from_frequencies(counts)</code></pre> 
<p style="margin-left:.0001pt;text-align:justify;">改变形状后的词云图展示：</p> 
<p style="margin-left:.0001pt;text-align:justify;"><img alt="" height="779" src="https://images2.imgbox.com/09/3a/yzoAxG7q_o.png" width="940"></p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;"><img alt="" height="1042" src="https://images2.imgbox.com/9c/f5/xZElEKnh_o.png" width="465"></p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<p style="margin-left:.0001pt;text-align:justify;"><img alt="" height="686" src="https://images2.imgbox.com/45/08/gbHe46ii_o.png" width="1119"></p> 
<p style="margin-left:.0001pt;text-align:justify;"><strong><img alt="" height="830" src="https://images2.imgbox.com/7b/0e/rXSOEIhL_o.png" width="1200"></strong></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/e15ec73a3b4edb00d7d5a384d6c30b83/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Python中的iloc是什么？Python中的iloc该怎么去使用</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/81132840517500abc6c6f3ccd161449e/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">安卓小技巧：如何查看一个 apk 的包信息</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>