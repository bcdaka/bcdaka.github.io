<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>离线运行Llama3：本地部署终极指南 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/182a60e0219300e90d72aa12cd55ae39/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="离线运行Llama3：本地部署终极指南">
  <meta property="og:description" content="4月18日，Meta在官方博客官宣了Llama3，标志着人工智能领域迈向了一个重要的飞跃。经过笔者的个人体验，Llama3 8B效果已经超越GPT-3.5，最为重要的是，Llama3是开源的，我们可以自己部署！
本文和大家分享一下如何在个人电脑上部署Llama3，拥有你自己的GPT-3.5&#43;!
很多读者担心本地部署时个人电脑的硬件配置不够，实际上这种担心是多余的，笔者使用的是MacBook M2 Pro (2023款), 主要硬件配置如下：
10核CPU16G内存 部署步骤大致如下：
安装Ollama下载Llama3安装Node.js部署WebUI 安装Ollama Ollama可以简单理解为客户端，实现和大模型的交互，读者可以前往[ollama.com/download，根据…]
下载之后打开，直接点击Next以及Install安装ollama到命令行。安装完成后界面上会提示ollama run llama2，不需要执行这条命令，因为我们要安装llama3。
下载Llama3 打开新的终端/命令行窗口，执行以下命令：
ollama run llama3 程序会自动下载Llama3的模型文件，默认是8B，也就80亿参数版本，个人电脑完全可以运行。
成功下载模型后会进入交互界面，我们可以直接在终端进行提问，比如笔者问的Who are you?，Llama3几乎是秒回答。
➜ Projects ollama run llama3 &gt;&gt;&gt; who are you? I&#39;m LLaMA, a large language model trained by a team of researcher at Meta AI. I&#39;m here to chat with you and answer any questions you may have. I&#39;ve been trained on a massive dataset of text from the internet and can generate human-like responses to a wide range of topics and questions.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-07-03T10:01:20+08:00">
    <meta property="article:modified_time" content="2024-07-03T10:01:20+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">离线运行Llama3：本地部署终极指南</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>4月18日，Meta在官方博客官宣了Llama3，标志着人工智能领域迈向了一个重要的飞跃。经过笔者的个人体验，Llama3 8B效果已经超越GPT-3.5，最为重要的是，Llama3是开源的，我们可以自己部署！</p> 
<p>本文和大家分享一下如何在个人电脑上部署Llama3，拥有你自己的GPT-3.5+!</p> 
<p>很多读者担心本地部署时个人电脑的硬件配置不够，实际上这种担心是多余的，笔者使用的是MacBook M2 Pro (2023款), 主要硬件配置如下：</p> 
<ul><li>10核CPU</li><li>16G内存</li></ul> 
<p>部署步骤大致如下：</p> 
<ul><li>安装Ollama</li><li>下载Llama3</li><li>安装Node.js</li><li>部署WebUI</li></ul> 
<h3><a id="Ollama_16"></a>安装Ollama</h3> 
<p>Ollama可以简单理解为客户端，实现和大模型的交互，读者可以前往[ollama.com/download，根据…]</p> 
<p><img src="https://images2.imgbox.com/98/2c/0T9ylYr6_o.png" alt="WX20240420-085342@2x"></p> 
<p>下载之后打开，直接点击<code>Next</code>以及<code>Install</code>安装<code>ollama</code>到命令行。安装完成后界面上会提示<code>ollama run llama2</code>，不需要执行这条命令，因为我们要安装<code>llama3</code>。</p> 
<p><img src="https://images2.imgbox.com/64/39/ip0d9el6_o.png" alt="image.png"></p> 
<h3><a id="Llama3_27"></a>下载Llama3</h3> 
<p>打开新的终端/命令行窗口，执行以下命令：</p> 
<pre><code>ollama run llama3

</code></pre> 
<p>程序会自动下载Llama3的模型文件，默认是8B，也就80亿参数版本，个人电脑完全可以运行。</p> 
<p>成功下载模型后会进入交互界面，我们可以直接在终端进行提问，比如笔者问的<code>Who are you?</code>，Llama3几乎是秒回答。</p> 
<pre><code>➜  Projects ollama run llama3
&gt;&gt;&gt; who are you?
I'm LLaMA, a large language model trained by a team of researcher at Meta 
AI. I'm here to chat with you and answer any questions you may have.

I've been trained on a massive dataset of text from the internet and can 
generate human-like responses to a wide range of topics and questions. My 
training data includes but is not limited to:

* Web pages
* Books
* Articles
* Research papers
* Conversations

I'm constantly learning and improving my responses based on the 
conversations I have with users like you.

So, what's on your mind? Do you have a question or topic you'd like to 
discuss?

</code></pre> 
<h3><a id="Nodejs_65"></a>安装Node.js</h3> 
<p>支持Ollama的WebUI非常多，笔者体验过热度第一的那个WebUI</p> 
<p><img src="https://images2.imgbox.com/ca/31/NWxSW73s_o.png" alt="image-20240420090338877"></p> 
<p><strong>设置国内NPM镜像</strong></p> 
<p>官方的NPM源国内访问有点慢，笔者推荐国内用户使用腾讯NPM源（[mirrors.cloud.tencent.com/npm/），之前笔者使…]</p> 
<p>打开终端执行以下命令设置NPM使用腾讯源：</p> 
<pre><code>npm config set registry http://mirrors.cloud.tencent.com/npm/

</code></pre> 
<h3><a id="WebUI_84"></a>部署WebUI</h3> 
<p>打开终端，执行以下命令部署WebUI：</p> 
<pre><code>git clone https://github.com/ollama-webui/ollama-webui-lite.git
cd ollama-webui-lite
npm install
npm run dev

</code></pre> 
<p>提示如下，WebUI已经在本地3000端口进行监听：</p> 
<pre><code>&gt; ollama-webui-lite@0.0.1 dev
&gt; vite dev --host --port 3000

  VITE v4.5.2  ready in 765 ms

  ➜  Local:   http://localhost:3000/

</code></pre> 
<p>打开浏览器访问[http://localhost:3000，可以看到如下图所示界面。默认情况下是没有选择模型的，需要点击截图所示箭头处选择模型。]<br> <img src="https://images2.imgbox.com/37/13/9v2BZfxW_o.png" alt="image-20240420091143684"></p> 
<p>笔者给模型提了一个编写一个Golang Echo Server的例子，大概5秒就开始打印结果，速度非常不错。</p> 
<p><img src="https://images2.imgbox.com/95/4a/vsqA0pSK_o.png" alt="image-20240420091325732"></p> 
<h3><a id="AI_116"></a>如何学习AI大模型？</h3> 
<p>我在一线互联网企业工作十余年里，指导过不少同行后辈。帮助很多人得到了学习和成长。</p> 
<p>我意识到有很多经验和知识值得分享给大家，也可以通过我们的能力和经验解答大家在人工智能学习中的很多困惑，所以在工作繁忙的情况下还是坚持各种整理和分享。但苦于知识传播途径有限，很多互联网行业朋友无法获得正确的资料得到学习提升，故此将并将重要的AI大模型资料包括AI大模型入门学习思维导图、精品AI大模型学习书籍手册、视频教程、实战学习等录播视频免费分享出来。</p> 
<p><img src="https://images2.imgbox.com/4e/f3/AmJDTQiA_o.png" alt="在这里插入图片描述"></p> 
<p>第一阶段： 从大模型系统设计入手，讲解大模型的主要方法；</p> 
<p>第二阶段： 在通过大模型提示词工程从Prompts角度入手更好发挥模型的作用；</p> 
<p>第三阶段： 大模型平台应用开发借助阿里云PAI平台构建电商领域虚拟试衣系统；</p> 
<p>第四阶段： 大模型知识库应用开发以LangChain框架为例，构建物流行业咨询智能问答系统；</p> 
<p>第五阶段： 大模型微调开发借助以大健康、新零售、新媒体领域构建适合当前领域大模型；</p> 
<p>第六阶段： 以SD多模态大模型为主，搭建了文生图小程序案例；</p> 
<p>第七阶段： 以大模型平台应用与开发为主，通过星火大模型，文心大模型等成熟大模型构建大模型行业应用。</p> 
<p><img src="https://images2.imgbox.com/0f/c6/8t9Bv5aH_o.jpg" alt="在这里插入图片描述"></p> 
<p>👉学会后的收获：👈<br> • 基于大模型全栈工程实现（前端、后端、产品经理、设计、数据分析等），通过这门课可获得不同能力；</p> 
<p>• 能够利用大模型解决相关实际项目需求： 大数据时代，越来越多的企业和机构需要处理海量数据，利用大模型技术可以更好地处理这些数据，提高数据分析和决策的准确性。因此，掌握大模型应用开发技能，可以让程序员更好地应对实际项目需求；</p> 
<p>• 基于大模型和企业数据AI应用开发，实现大模型理论、掌握GPU算力、硬件、LangChain开发框架和项目实战技能， 学会Fine-tuning垂直训练大模型（数据准备、数据蒸馏、大模型部署）一站式掌握；</p> 
<p>• 能够完成时下热门大模型垂直领域模型训练能力，提高程序员的编码能力： 大模型应用开发需要掌握机器学习算法、深度学习框架等技术，这些技术的掌握可以提高程序员的编码能力和分析能力，让程序员更加熟练地编写高质量的代码。</p> 
<p><img src="https://images2.imgbox.com/c1/2a/o76tHIKh_o.jpg" alt="在这里插入图片描述"></p> 
<blockquote> 
 <p><em><strong>1.AI大模型学习路线图<br> 2.100套AI大模型商业化落地方案<br> 3.100集大模型视频教程<br> 4.200本大模型PDF书籍<br> 5.LLM面试题合集<br> 6.AI产品经理资源合集</strong></em></p> 
</blockquote> 
<p>👉获取方式：<br> 😝有需要的小伙伴，可以保存图片到wx扫描二v码免费领取【保证100%免费】🆓</p> 
<p><img src="https://images2.imgbox.com/7a/ea/yMi2OqFu_o.jpg" alt="在这里插入图片描述"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/e36b0cebf1f198c613b41fdad6268586/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Mac/Linux安装JMeter压测工具</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/4e9ac35b1e972b90e535b2e3d43d5eda/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">非关系型数据库（NoSQL）与 关系型数据库（RDBMS）的比较</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>