<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Spark&#43;Kafka构建实时分析Dashboard案例 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/a323c0d1333b90190a48150e3b2943b5/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="Spark&#43;Kafka构建实时分析Dashboard案例">
  <meta property="og:description" content="目录
一、环境准备
Ubuntu安装
Hadoop安装
Spark安装
Kafka安装
Python安装
Python依赖库安装
vscode安装
Python工程目录结构
二、数据处理和Python操作Kafka
数据集
数据预处理
运行
三、 Structured Streaming实时处理数据
建立pyspark项目
运行
四、结果展示
环境准备
app.py文件源码
index.html文件源码
效果展示
五、补充说明
案例来自林子雨老师的团队案例网站
一、环境准备 Ubuntu: 22.10
Hadoop: 3.1.3
Spark: 3.3.1
Scala: 2.12.15
Kafka: 3.4.0
Python: 3.10.7
Flask: 2.3.2
Flask-SocketIO: 5.3.4
Kafka-python： 2.0.2
pyspark：3.4.0
Ubuntu安装 VMware官方下载地址 Ubuntu安装教程
Hadoop安装 apache软件下载地址 Hadoop安装教程
PS：在Apache软件下载地址里选择文件夹 hadoop -&gt; common -&gt; 所需版本 -&gt; 选择后缀仅有.tar.gz的文件
Spark安装 Spark官方下载地址 Spark安装教程
PS：在Spark官方下载地址选择所需版本后在Choose a package type选择栏里选择Pre-built with user-provided Apache Hadoop之后再点击下方链接下载即可">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2023-06-03T12:46:51+08:00">
    <meta property="article:modified_time" content="2023-06-03T12:46:51+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Spark&#43;Kafka构建实时分析Dashboard案例</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p id="main-toc"><strong>目录</strong></p> 
<p id="%E4%B8%80%E3%80%81%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87-toc" style="margin-left:0px;"><a href="#%E4%B8%80%E3%80%81%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87" rel="nofollow">一、环境准备</a></p> 
<p id="Ubuntu%E5%AE%89%E8%A3%85%EF%BC%9AVMware%E5%AE%98%E6%96%B9%E4%B8%8B%E8%BD%BD%E5%9C%B0%E5%9D%80%C2%A0Ubuntu%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B-toc" style="margin-left:40px;"><a href="#Ubuntu%E5%AE%89%E8%A3%85%EF%BC%9AVMware%E5%AE%98%E6%96%B9%E4%B8%8B%E8%BD%BD%E5%9C%B0%E5%9D%80%C2%A0Ubuntu%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B" rel="nofollow">Ubuntu安装</a></p> 
<p id="Hadoop%E5%AE%89%E8%A3%85%EF%BC%9Aapache%E8%BD%AF%E4%BB%B6%E4%B8%8B%E8%BD%BD%E5%9C%B0%E5%9D%80%C2%A0Hadoop%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B-toc" style="margin-left:40px;"><a href="#Hadoop%E5%AE%89%E8%A3%85%EF%BC%9Aapache%E8%BD%AF%E4%BB%B6%E4%B8%8B%E8%BD%BD%E5%9C%B0%E5%9D%80%C2%A0Hadoop%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B" rel="nofollow">Hadoop安装</a></p> 
<p id="Spark%E5%AE%89%E8%A3%85%EF%BC%9ASpark%E5%AE%98%E6%96%B9%E4%B8%8B%E8%BD%BD%E5%9C%B0%E5%9D%80%C2%A0Spark%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B-toc" style="margin-left:40px;"><a href="#Spark%E5%AE%89%E8%A3%85%EF%BC%9ASpark%E5%AE%98%E6%96%B9%E4%B8%8B%E8%BD%BD%E5%9C%B0%E5%9D%80%C2%A0Spark%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B" rel="nofollow">Spark安装</a></p> 
<p id="Kafka%E5%AE%89%E8%A3%85%EF%BC%9AKafka%E5%AE%98%E6%96%B9%E4%B8%8B%E8%BD%BD%E5%9C%B0%E5%9D%80%C2%A0Kafka%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B-toc" style="margin-left:40px;"><a href="#Kafka%E5%AE%89%E8%A3%85%EF%BC%9AKafka%E5%AE%98%E6%96%B9%E4%B8%8B%E8%BD%BD%E5%9C%B0%E5%9D%80%C2%A0Kafka%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B" rel="nofollow">Kafka安装</a></p> 
<p id="Python%E5%AE%89%E8%A3%85%EF%BC%9APython%E4%B8%8B%E8%BD%BD%E5%9C%B0%E5%9D%80-toc" style="margin-left:40px;"><a href="#Python%E5%AE%89%E8%A3%85%EF%BC%9APython%E4%B8%8B%E8%BD%BD%E5%9C%B0%E5%9D%80" rel="nofollow">Python安装</a></p> 
<p id="Python%E4%BE%9D%E8%B5%96%E5%BA%93%E5%AE%89%E8%A3%85%EF%BC%9A-toc" style="margin-left:40px;"><a href="#Python%E4%BE%9D%E8%B5%96%E5%BA%93%E5%AE%89%E8%A3%85%EF%BC%9A" rel="nofollow">Python依赖库安装</a></p> 
<p id="vscode%E5%AE%89%E8%A3%85-toc" style="margin-left:40px;"><a href="#vscode%E5%AE%89%E8%A3%85" rel="nofollow">vscode安装</a></p> 
<p id="%C2%A0Python%E5%B7%A5%E7%A8%8B%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84-toc" style="margin-left:40px;"><a href="#%C2%A0Python%E5%B7%A5%E7%A8%8B%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84" rel="nofollow"> Python工程目录结构</a></p> 
<p id="%E4%BA%8C%E3%80%81%E4%BD%BF%E7%94%A8%E6%AD%A5%E9%AA%A4-toc" style="margin-left:0px;"><a href="#%E4%BA%8C%E3%80%81%E4%BD%BF%E7%94%A8%E6%AD%A5%E9%AA%A4" rel="nofollow">二、数据处理和Python操作Kafka</a></p> 
<p id="1.%E5%BC%95%E5%85%A5%E5%BA%93-toc" style="margin-left:40px;"><a href="#1.%E5%BC%95%E5%85%A5%E5%BA%93" rel="nofollow">数据集</a></p> 
<p id="%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86-toc" style="margin-left:40px;"><a href="#%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86" rel="nofollow">数据预处理</a></p> 
<p id="%E8%BF%90%E8%A1%8C-toc" style="margin-left:40px;"><a href="#%E8%BF%90%E8%A1%8C" rel="nofollow">运行</a></p> 
<p id="%E4%B8%89%E3%80%81%C2%A0Structured%20Streaming%E5%AE%9E%E6%97%B6%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE-toc" style="margin-left:0px;"><a href="#%E4%B8%89%E3%80%81%C2%A0Structured%20Streaming%E5%AE%9E%E6%97%B6%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE" rel="nofollow">三、 Structured Streaming实时处理数据</a></p> 
<p id="%E5%BB%BA%E7%AB%8Bpyspark%E9%A1%B9%E7%9B%AE-toc" style="margin-left:40px;"><a href="#%E5%BB%BA%E7%AB%8Bpyspark%E9%A1%B9%E7%9B%AE" rel="nofollow">建立pyspark项目</a></p> 
<p id="%E8%BF%90%E8%A1%8C-toc" style="margin-left:40px;"><a href="#%E8%BF%90%E8%A1%8C" rel="nofollow">运行</a></p> 
<p id="%C2%A0%E5%9B%9B%E3%80%81%E7%BB%93%E6%9E%9C%E5%B1%95%E7%A4%BA-toc" style="margin-left:0px;"><a href="#%C2%A0%E5%9B%9B%E3%80%81%E7%BB%93%E6%9E%9C%E5%B1%95%E7%A4%BA" rel="nofollow"> 四、结果展示</a></p> 
<p id="%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87-toc" style="margin-left:40px;"><a href="#%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87" rel="nofollow">环境准备</a></p> 
<p id="app.py%E6%96%87%E4%BB%B6%E6%BA%90%E7%A0%81-toc" style="margin-left:40px;"><a href="#app.py%E6%96%87%E4%BB%B6%E6%BA%90%E7%A0%81" rel="nofollow">app.py文件源码</a></p> 
<p id="index.html%E6%96%87%E4%BB%B6%E6%BA%90%E7%A0%81-toc" style="margin-left:40px;"><a href="#index.html%E6%96%87%E4%BB%B6%E6%BA%90%E7%A0%81" rel="nofollow">index.html文件源码</a></p> 
<p id="%E6%95%88%E6%9E%9C%E5%B1%95%E7%A4%BA-toc" style="margin-left:40px;"><a href="#%E6%95%88%E6%9E%9C%E5%B1%95%E7%A4%BA" rel="nofollow">效果展示</a></p> 
<p id="%E4%BA%94%E3%80%81%E8%A1%A5%E5%85%85%E8%AF%B4%E6%98%8E-toc" style="margin-left:0px;"><a href="#%E4%BA%94%E3%80%81%E8%A1%A5%E5%85%85%E8%AF%B4%E6%98%8E" rel="nofollow">五、补充说明</a></p> 
<hr> 
<blockquote> 
 <p>案例来自<strong>林子雨老师的团队</strong><a class="link-info" href="https://dblab.xmu.edu.cn/post/spark-kafka-dashboard/" rel="nofollow" title="案例网站">案例网站</a></p> 
</blockquote> 
<h2 id="%E4%B8%80%E3%80%81%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87">一、环境准备</h2> 
<blockquote> 
 <p><strong>Ubuntu: </strong>22.10</p> 
 <p><strong>Hadoop: </strong>3.1.3<br><strong>Spark: </strong>3.3.1</p> 
 <p><strong>Scala: </strong>2.12.15<br><strong>Kafka: </strong>3.4.0<br><strong>Python: </strong>3.10.7<br><strong>Flask: </strong>2.3.2<br><strong>Flask-SocketIO: </strong>5.3.4<br><strong>Kafka-python：</strong> 2.0.2</p> 
 <p><strong>pyspark：</strong>3.4.0</p> 
</blockquote> 
<ul><li> <h3 id="Ubuntu%E5%AE%89%E8%A3%85%EF%BC%9AVMware%E5%AE%98%E6%96%B9%E4%B8%8B%E8%BD%BD%E5%9C%B0%E5%9D%80%C2%A0Ubuntu%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B"><a id="_19"></a>Ubuntu安装</h3> </li></ul> 
<p>        <a class="link-info" href="https://www.vmware.com/cn/products/workstation-pro/workstation-pro-evaluation.html" rel="nofollow" title="VMware官方下载地址">VMware官方下载地址</a> <a class="link-info" href="https://dblab.xmu.edu.cn/blog/4124/" rel="nofollow" title="Ubuntu安装教程">Ubuntu安装教程</a></p> 
<ul><li> <h3 id="Hadoop%E5%AE%89%E8%A3%85%EF%BC%9Aapache%E8%BD%AF%E4%BB%B6%E4%B8%8B%E8%BD%BD%E5%9C%B0%E5%9D%80%C2%A0Hadoop%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B">Hadoop安装</h3> </li></ul> 
<p>        <a class="link-info" href="https://dlcdn.apache.org/" rel="nofollow" title="apache软件下载地址">apache软件下载地址</a> <a class="link-info" href="https://dblab.xmu.edu.cn/blog/2441/" rel="nofollow" title="Hadoop安装教程">Hadoop安装教程</a></p> 
<blockquote> 
 <p><strong>PS：</strong>在Apache软件下载地址里选择文件夹 <strong>hadoop -&gt; common -&gt; 所需版本 -&gt; 选择后缀仅有.tar.gz的文件</strong></p> 
</blockquote> 
<ul><li> <h3 id="Spark%E5%AE%89%E8%A3%85%EF%BC%9ASpark%E5%AE%98%E6%96%B9%E4%B8%8B%E8%BD%BD%E5%9C%B0%E5%9D%80%C2%A0Spark%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B">Spark安装</h3> </li></ul> 
<p>        <a class="link-info" href="https://spark.apache.org/downloads.html" rel="nofollow" title="Spark官方下载地址">Spark官方下载地址</a> <a class="link-info" href="https://dblab.xmu.edu.cn/blog/2501/" rel="nofollow" title="Spark安装教程">Spark安装教程</a></p> 
<blockquote> 
 <p><strong>PS：</strong>在Spark官方下载地址<strong>选择所需版本</strong>后在<strong>Choose a package type</strong>选择栏里选择<strong>Pre-built with user-provided Apache Hadoop</strong>之后再点击下方链接下载即可</p> 
</blockquote> 
<ul><li> <h3 id="Kafka%E5%AE%89%E8%A3%85%EF%BC%9AKafka%E5%AE%98%E6%96%B9%E4%B8%8B%E8%BD%BD%E5%9C%B0%E5%9D%80%C2%A0Kafka%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B">Kafka安装</h3> </li></ul> 
<p>        <a class="link-info" href="https://kafka.apache.org/downloads" rel="nofollow" title="Kafka官方下载地址">Kafka官方下载地址</a> <a class="link-info" href="https://dblab.xmu.edu.cn/blog/1096/" rel="nofollow" title="Kafka安装教程">Kafka安装教程</a></p> 
<blockquote> 
 <p><strong>PS：</strong>在Kafka官方下载地址里<strong>选择对应Scala版本</strong></p> 
 <p>在教程里的代码可能会出现报错的情况</p> 
 <pre><code class="language-bash">cd /usr/local/kafka
bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic dblab</code></pre> 
 <p>若下载的Kafka版本为<span style="color:#fe2c24;">2.2+</span><span style="color:#0d0016;">，</span><span style="color:#0d0016;">需要使用下列代码</span></p> 
 <pre><code class="language-bash">cd /usr/local/kafka
bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic dblab</code></pre> 
 <p>若后面依照教程仍出错可以考虑将 <span style="color:#fe2c24;">--zookeeper</span> <span style="color:#fe2c24;">localhost:2181</span> 改为 <span style="color:#fe2c24;">--bootstrap-server localhost:9092</span></p> 
</blockquote> 
<ul><li> <h3 id="Python%E5%AE%89%E8%A3%85%EF%BC%9APython%E4%B8%8B%E8%BD%BD%E5%9C%B0%E5%9D%80">Python安装</h3> </li></ul> 
<p>        <a class="link-info" href="https://www.python.org/downloads/source/" rel="nofollow" title="Python下载地址">Python下载地址</a></p> 
<blockquote> 
 <p><strong>PS：</strong>在安装<span style="color:#4da8ee;">Ubuntu</span>时系统会自带<span style="color:#4da8ee;">Python</span>，但考虑到可能出现Spark和自带的Python版本<strong>不兼容</strong>导致一些内容无法使用（如<strong>RDD编程</strong>），下面提供一种方法（<span style="color:#fe2c24;">强烈建议在执行下方操作时克隆虚拟机或快照！</span>）：</p> 
 <p>在Python下载地址里选择所需的Python版本（<span style="color:#fe2c24;">Stable Releases</span>列表里的）版本选择<span style="color:#fe2c24;">Gzipped source tarball</span></p> 
 <pre><code class="language-bash">#更新apt
sudo apt update

#下载和安装python 3的依赖包
sudo apt install build-essential zlib1g-dev libncurses5-dev libgdbm-dev libnss3-dev libssl-dev libreadline-dev libffi-dev libsqlite3-dev wget libbz2-dev

cd /home/hadoop/下载 #假设安装包位于/home/hadoop/下载，如果是其它路径，则更改此命令的目录

sudo tar -xvf Python-3.8.16.tgz -C /usr/local #解压缩到 /usr/local

cd /usr/local/Python-3.8.16

#以下3个步骤依次执行

sudo ./configure --enable-optimizations --prefix=/usr/local/Python-3.8.16

sudo make -j 2

sudo make altinstall

#建立软链接，将系统python3的命令链接到我们自己安装的python3.8版本

sudo rm -r /usr/bin/python3

sudo ln -s /usr/local/Python-3.8.16/bin/python3.8 /usr/bin/python3

sudo ln -s /usr/local/Python-3.8.16/bin/python3.8 /usr/bin/pip3</code></pre> 
</blockquote> 
<ul><li> <h3 id="Python%E4%BE%9D%E8%B5%96%E5%BA%93%E5%AE%89%E8%A3%85%EF%BC%9A">Python依赖库安装</h3> </li></ul> 
<blockquote> 
 <p><strong>PS：</strong>如果无法使用pip install但确有安装Python，可以尝试到Python解释器所在的文件夹运行或者使用sudo apt-get install python3-pip。</p> 
 <pre><code class="language-bash">pip install pyspark
pip install flask
pip install flask-socketio
pip install kafka-python</code></pre> 
</blockquote> 
<ul><li> <h3 id="vscode%E5%AE%89%E8%A3%85">vscode安装</h3> </li></ul> 
<blockquote> 
 <p>在Ubuntu系统自带的<span style="color:#4da8ee;">Ubuntu Software</span>里搜索下载即可</p> 
 <p>PS:使用<span style="color:#fe2c24;">相对路径找不到文件</span>，解决：设置Python插件 搜索execute in file dir 打勾</p> 
</blockquote> 
<p><img alt="" height="792" src="https://images2.imgbox.com/fa/b9/VEt4SXy3_o.png" width="1194"></p> 
<ul><li> <h3 id="%C2%A0Python%E5%B7%A5%E7%A8%8B%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84"> Python工程目录结构</h3> </li></ul> 
<p><img alt="" height="928" src="https://images2.imgbox.com/2f/ba/R4FC4kHm_o.png" width="1200"></p> 
<blockquote> 
 <ol><li>data目录存放的是用户日志数据；</li><li>scripts目录存放的是Kafka生产者和消费者；</li><li>static/js目录存放的是前端所需要的js框架；</li><li>templates目录存放的是html页面；</li><li>app.py为web服务器，接收Structed Streaming处理后的结果，并推送实时数据给浏览器；</li></ol> 
</blockquote> 
<h2 id="%E4%BA%8C%E3%80%81%E4%BD%BF%E7%94%A8%E6%AD%A5%E9%AA%A4">二、数据处理和Python操作Kafka</h2> 
<ul><li> <h3 id="1.%E5%BC%95%E5%85%A5%E5%BA%93"><a id="1_20"></a>数据集</h3> </li></ul> 
<p>        <a class="link-info" href="https://pan.baidu.com/s/1cs02Nc" rel="nofollow" title="数据集下载">数据集下载</a></p> 
<ul><li> <h3 id="%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86">数据预处理</h3> </li></ul> 
<p>       <strong> 文件目录：</strong>./scripts/producer.py</p> 
<pre><code class="language-python"># coding: utf-8
import csv
import time
from kafka import KafkaProducer
 
# 实例化一个KafkaProducer示例，用于向Kafka投递消息
producer = KafkaProducer(bootstrap_servers='localhost:9092')
# 打开数据文件
csvfile = open("../data/user_log.csv","r")
# 生成一个可用于读取csv文件的reader
reader = csv.reader(csvfile)
 
for line in reader:
    gender = line[9] # 性别在每行日志代码的第9个元素
    if gender == 'gender':
        continue # 去除第一行表头
    time.sleep(0.1) # 每隔0.1秒发送一行数据
    # 发送数据，topic为'sex'
    producer.send('sex',line[9].encode('utf8'))</code></pre> 
<p>        <strong>文件目录：</strong>./scripts/consumer.py</p> 
<pre><code class="language-python">from kafka import KafkaConsumer
 
consumer = KafkaConsumer('sex')
for msg in consumer:
    print((msg.value).decode('utf8'))</code></pre> 
<ul><li> <h3 id="%E8%BF%90%E8%A1%8C">运行</h3> </li></ul> 
<p>        <strong>开启Kafka</strong>：</p> 
<pre><code class="language-bash">cd /usr/local/kafka
bin/zookeeper-server-start.sh config/zookeeper.properties</code></pre> 
<pre><code class="language-bash">cd /usr/local/kafka
bin/kafka-server-start.sh config/server.properties</code></pre> 
<p>        <strong>使用vscode启动生产者和消费者：</strong></p> 
<blockquote> 
 <p><strong>PS：</strong>由于vscode运行文件时通常只会在一个终端上运行，这无法满足同时运行生产者和消费者的需求，所以需要在vscode里<strong>使用两个终端</strong>来运行。</p> 
</blockquote> 
<p>    <strong>    运行结果：</strong></p> 
<p style="text-align:center;"><strong><img alt="" src="https://images2.imgbox.com/61/ed/EX5prADf_o.png"></strong></p> 
<h2 id="%E4%B8%89%E3%80%81%C2%A0Structured%20Streaming%E5%AE%9E%E6%97%B6%E5%A4%84%E7%90%86%E6%95%B0%E6%8D%AE">三、 Structured Streaming实时处理数据</h2> 
<ul><li> <h3 id="%E5%BB%BA%E7%AB%8Bpyspark%E9%A1%B9%E7%9B%AE"><strong>建立pyspark项目</strong></h3> </li></ul> 
<pre><code class="language-bash">cd /usr/local/spark/mycode
mkdir kafka</code></pre> 
<p>        <strong>修改Spark配置文件</strong></p> 
<pre><code class="language-bash">cd /usr/local/spark/conf
sudo vim spark-env.sh</code></pre> 
<p>        <strong>配置Spark开发Kafka环境 <a class="link-info" href="https://pan.baidu.com/s/12JCw8L0kt4x0rZFoTWIGAw?pwd=b5wl#list/path=%2F" rel="nofollow" title="下载">下载</a></strong></p> 
<p>        <strong>把下载的代码库放到目录/usr/local/spark/jars目录下</strong></p> 
<pre><code class="language-bash">sudo mv ~/下载/spark-streaming_2.12-3.2.0.jar /usr/local/spark/jars
sudo mv ~/下载/spark-streaming-kafka-0-10_2.12-3.2.0.jar /usr/local/spark/jars</code></pre> 
<p>        <strong>把 Kafka 相关 jar 包的路径信息增加到 spark-env.sh</strong></p> 
<pre><code class="language-bash">export SPARK_DIST_CLASSPATH=$(/usr/local/hadoop/bin/hadoopclasspath):/usr/local/spark/jars/kafka/*:/usr/local/kafka/libs/*</code></pre> 
<p><strong>        在当前目录创建kafka_test.py文件</strong></p> 
<pre><code class="language-python">from kafka import KafkaProducer
from pyspark.streaming import StreamingContext
#from pyspark.streaming.kafka import KafkaUtils
from pyspark import SparkConf, SparkContext
import json
import sys
from pyspark.sql import DataFrame
from pyspark.sql import SparkSession
from pyspark.sql.functions import window
from pyspark.sql.types import StructType, StructField
from pyspark.sql.types import TimestampType, StringType
from pyspark.sql.functions import col, column, expr
 
def KafkaWordCount(zkQuorum, group, topics, numThreads):
 
    spark = SparkSession \
    .builder \
    .appName("KafkaWordCount") \
    .getOrCreate()
 
    spark.sparkContext.setLogLevel("ERROR")
 
    topicAry = topics.split(",")
        # 将topic转换为hashmap形式，而python中字典就是一种hashmap
    topicMap = {}
    for topic in topicAry:
        topicMap[topic] = numThreads
    #lines = KafkaUtils.createStream(ssc, zkQuorum, group, topicMap).map(lambda x : x[1])
 
    df = spark \
      .readStream \
      .format("kafka") \
      .option("kafka.bootstrap.servers", "localhost:9092") \
      .option("subscribe", "sex") \
      .load()
    df.selectExpr( "CAST(timestamp AS timestamp)","CAST(value AS STRING)")
    #lines = df.selectExpr("CAST(value AS STRING)")
 
    windowedCounts = df \
        .withWatermark("timestamp", "1 seconds") \
        .groupBy(
            window(col("timestamp"), "1 seconds" ,"1 seconds"),
            col("value")) \
        .count()
    wind = windowedCounts.selectExpr( "CAST(value AS STRING)","CAST(count AS STRING)")
 
    query = wind.writeStream.option("checkpointLocation", "/check").outputMode("append").foreach(sendmsg).start()
 
    query.awaitTermination()
    query.stop()
 
 
# 格式转化，将格式变为[{1: 3}]
def Get_dic(row):
    res = []
    #for elm in row:
    tmp = {row[0]: row[1]}
    res.append(tmp)
    print(res)
    return json.dumps(res)
 
 
def sendmsg(row):
    print(row)
    if row.count != 0:
        msg = Get_dic(row)
        # 实例化一个KafkaProducer示例，用于向Kafka投递消息
        producer = KafkaProducer(bootstrap_servers='localhost:9092')
        producer.send("result", msg.encode('utf8'))
        # 很重要，不然不会更新
        producer.flush()
 
 
if __name__ == '__main__':
    # 输入的四个参数分别代表着
    # 1.zkQuorum为zookeeper地址
    # 2.group为消费者所在的组
    # 3.topics该消费者所消费的topics
    # 4.numThreads开启消费topic线程的个数
    if (len(sys.argv) &lt; 5):
        print("Usage: KafkaWordCount &lt;zkQuorum&gt; &lt;group&gt; &lt;topics&gt; &lt;numThreads&gt;")
        exit(1)
    zkQuorum = sys.argv[1]
    group = sys.argv[2]
    topics = sys.argv[3]
    numThreads = int(sys.argv[4])
    print(group, topics)
    KafkaWordCount(zkQuorum, group, topics, numThreads)
 
 </code></pre> 
<p>        <strong>在当前目录创建脚本文件startup.sh</strong></p> 
<pre><code class="language-bash">/usr/local/spark/bin/spark-submit  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.2.0 /usr/local/spark/mycode/kafka/kafka_test.py 127.0.0.1:2181 1 sex 1</code></pre> 
<ul><li> <h3>运行</h3> </li></ul> 
<p>       <strong> 启动HDFS</strong></p> 
<pre><code class="language-bash">cd /usr/local/hadoop  #这是hadoop的安装目录
./sbin/start-dfs.sh</code></pre> 
<p>      <strong>  启动Kafka</strong></p> 
<pre><code class="language-bash">cd /usr/local/kafka
bin/zookeeper-server-start.sh config/zookeeper.properties</code></pre> 
<pre><code class="language-bash">cd /usr/local/kafka
bin/kafka-server-start.sh config/server.properties</code></pre> 
<p>        <strong>运行脚本</strong></p> 
<pre><code class="language-bash">sh startup.sh</code></pre> 
<p>        <strong>更改consumer.py文件</strong></p> 
<pre><code class="language-python">from kafka import KafkaConsumer
 
consumer = KafkaConsumer('result')
for msg in consumer:
    print((msg.value).decode('utf8'))</code></pre> 
<p>        <strong>运行生产者消费者程序</strong></p> 
<blockquote> 
 <p>vscode运行生产者和消费者文件</p> 
</blockquote> 
<p>        <strong>运行结果</strong></p> 
<figure class="image"> 
 <img alt="" src="https://images2.imgbox.com/13/bd/49lRLcTu_o.png"> 
 <figcaption>
   脚本运行效果图 
 </figcaption> 
</figure> 
<p style="text-align:center;"></p> 
<figure class="image"> 
 <img alt="" src="https://images2.imgbox.com/ba/dd/u0A9akiE_o.png"> 
 <figcaption>
   消费者终端运行效果图 
 </figcaption> 
</figure> 
<h2 id="%C2%A0%E5%9B%9B%E3%80%81%E7%BB%93%E6%9E%9C%E5%B1%95%E7%A4%BA"> 四、结果展示</h2> 
<ul><li> <h3 id="%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87">环境准备</h3> </li></ul> 
<p>        <a class="link-info" href="https://pan.baidu.com/s/1Vg_Zvk5LsbywbHx_L9XrTA?pwd=ziyu#list/path=%2F" rel="nofollow" title="源码下载">源码下载</a></p> 
<blockquote> 
 <p><strong>PS：</strong>解压下载文件，将里面有关<span style="color:#fe2c24;">js库的文件</span>导入到项目中</p> 
</blockquote> 
<ul><li> <h3 id="app.py%E6%96%87%E4%BB%B6%E6%BA%90%E7%A0%81"><strong>app.py文件源码</strong></h3> </li></ul> 
<pre><code class="language-python">import json
from flask import Flask, render_template
from flask_socketio import SocketIO
from kafka import KafkaConsumer
 
# 因为第一步骤安装好了flask，所以这里可以引用
 
app = Flask(__name__)
app.config['SECRET_KEY'] = 'secret!'
socketio = SocketIO(app)
thread = None
# 实例化一个consumer，接收topic为result的消息
consumer = KafkaConsumer('result')
 
 
# 一个后台线程，持续接收Kafka消息，并发送给客户端浏览器
def background_thread():
    girl = 0
    boy = 0
    for msg in consumer:
        data_json = msg.value.decode('utf8')
        data_list = json.loads(data_json)
        for data in data_list:
            if '0' in data.keys():
                girl = data['0']
            elif '1' in data.keys():
                boy = data['1']
            else:
                continue
        result = str(girl) + ',' + str(boy)
        print(result)
        socketio.emit('test_message', {'data': result})
 
 
# 客户端发送connect事件时的处理函数
@socketio.on('test_connect')
def connect(message):
    print(message)
    global thread
    if thread is None:
        # 单独开启一个线程给客户端发送数据
        thread = socketio.start_background_task(target=background_thread)
    socketio.emit('connected', {'data': 'Connected'})
 
 
# 通过访问http://127.0.0.1:5000/访问index.html
@app.route("/")
def handle_mes():
    return render_template("index.html")
 
 
# main函数
if __name__ == '__main__':
    socketio.run(app, debug=True)</code></pre> 
<ul><li> <h3 id="index.html%E6%96%87%E4%BB%B6%E6%BA%90%E7%A0%81">index.html文件源码</h3> </li></ul> 
<pre><code class="language-html">&lt;!DOCTYPE html&gt;
&lt;html lang="en"&gt;
&lt;head&gt;
    &lt;meta charset="UTF-8"&gt;
    &lt;title&gt;DashBoard&lt;/title&gt;
    &lt;script src="static/js/socket.io.js"&gt;&lt;/script&gt;
    &lt;script src="static/js/jquery-3.1.1.min.js"&gt;&lt;/script&gt;
    &lt;script src="static/js/highcharts.js"&gt;&lt;/script&gt;
    &lt;script src="static/js/exporting.js"&gt;&lt;/script&gt;
    &lt;script type="text/javascript" charset="utf-8"&gt;
    var socket = io.connect('http://' + document.domain + ':' + location.port);
    socket.on('connect', function() {
        socket.emit('test_connect', {data: 'I\'m connected!'});
    });
 
    socket.on('test_message',function(message){
        console.log(message);
        var obj = eval(message);
        var result = obj["data"].split(",");
        $('#girl').html(result[0]);
        $('#boy').html(result[1]);
    });
 
    socket.on('connected',function(){
        console.log('connected');
    });
 
    socket.on('disconnect', function () {
        console.log('disconnect');
    });
    &lt;/script&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;div&gt;
    &lt;b&gt;Girl: &lt;/b&gt;&lt;b id="girl"&gt;&lt;/b&gt;
    &lt;b&gt;Boy: &lt;/b&gt;&lt;b id="boy"&gt;&lt;/b&gt;
&lt;/div&gt;
&lt;div id="container" style="width: 600px;height:400px;"&gt;&lt;/div&gt;
 
&lt;script type="text/javascript"&gt;
    $(document).ready(function () {
    Highcharts.setOptions({
        global: {
            useUTC: false
        }
    });
 
    Highcharts.chart('container', {
        chart: {
            type: 'spline',
            animation: Highcharts.svg, // don't animate in old IE
            marginRight: 10,
            events: {
                load: function () {
 
                    // set up the updating of the chart each second
                    var series1 = this.series[0];
                    var series2 = this.series[1];
                    setInterval(function () {
                        var x = (new Date()).getTime(), // current time
                        count1 = $('#girl').text();
                        y = parseInt(count1);
                        series1.addPoint([x, y], true, true);
 
                        count2 = $('#boy').text();
                        z = parseInt(count2);
                        series2.addPoint([x, z], true, true);
                    }, 1000);
                }
            }
        },
        title: {
            text: '男女生购物人数实时分析'
        },
        xAxis: {
            type: 'datetime',
            tickPixelInterval: 50
        },
        yAxis: {
            title: {
                text: '数量'
            },
            plotLines: [{
                value: 0,
                width: 1,
                color: '#808080'
            }]
        },
        tooltip: {
            formatter: function () {
                return '&lt;b&gt;' + this.series.name + '&lt;/b&gt;&lt;br/&gt;' +
                    Highcharts.dateFormat('%Y-%m-%d %H:%M:%S', this.x) + '&lt;br/&gt;' +
                    Highcharts.numberFormat(this.y, 2);
            }
        },
        legend: {
            enabled: true
        },
        exporting: {
            enabled: true
        },
        series: [{
            name: '女生购物人数',
            data: (function () {
                // generate an array of random data
                var data = [],
                    time = (new Date()).getTime(),
                    i;
 
                for (i = -19; i &lt;= 0; i += 1) {
                    data.push({
                        x: time + i * 1000,
                        y: Math.random()
                    });
                }
                return data;
            }())
        },
        {
            name: '男生购物人数',
            data: (function () {
                // generate an array of random data
                var data = [],
                    time = (new Date()).getTime(),
                    i;
 
                for (i = -19; i &lt;= 0; i += 1) {
                    data.push({
                        x: time + i * 1000,
                        y: Math.random()
                    });
                }
                return data;
            }())
        }]
    });
});
&lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;</code></pre> 
<ul><li> <h3 id="%E6%95%88%E6%9E%9C%E5%B1%95%E7%A4%BA">效果展示</h3> </li></ul> 
<p>        <strong>启动Kafka</strong></p> 
<pre><code class="language-bash">cd /usr/local/kafka
bin/zookeeper-server-start.sh config/zookeeper.properties</code></pre> 
<pre><code class="language-bash">cd /usr/local/kafka
bin/kafka-server-start.sh config/server.properties</code></pre> 
<p>     <strong>   启动HDFS</strong></p> 
<pre><code class="language-bash">cd /usr/local/hadoop  #这是hadoop的安装目录
./sbin/start-dfs.sh</code></pre> 
<p>        <strong>启动脚本</strong></p> 
<pre><code class="language-bash">sh startup.sh</code></pre> 
<p>        <strong>运行生产者和消费者程序</strong></p> 
<blockquote> 
 <p>vscode运行生产者和消费者文件</p> 
</blockquote> 
<p>        <strong>运行app.py程序</strong></p> 
<p><img alt="" height="189" src="https://images2.imgbox.com/d4/a1/Q6JDd4l3_o.png" width="588"></p> 
<p>         <strong>最终效果展示</strong></p> 
<p style="text-align:center;"><strong>        </strong></p> 
<figure class="image"> 
 <img alt="" src="https://images2.imgbox.com/b9/77/XKs2CXcD_o.gif"> 
 <figcaption>
   网页端效果图 
 </figcaption> 
</figure> 
<figure class="image"> 
 <img alt="" height="395" src="https://images2.imgbox.com/fc/26/CNKXcF1w_o.png" width="1200"> 
 <figcaption>
   在HDFS的WEB页面可以看到check的文件 
 </figcaption> 
</figure> 
<h2 id="%E4%BA%94%E3%80%81%E8%A1%A5%E5%85%85%E8%AF%B4%E6%98%8E">五、补充说明</h2> 
<p>        如果想<strong>多次运行</strong>这个程序，但出现运行脚本时报错可以考虑以下几个方面</p> 
<blockquote> 
 <ul><li><strong>出现如下图所示错误：即<span style="color:#fe2c24;">Name node is in safe mode.</span></strong></li></ul> 
 <p><img alt="" height="54" src="https://images2.imgbox.com/5b/db/F9MTwUiB_o.png" width="715"></p> 
 <p> HDFS处于安全模式时无法对文件进行修改，可以<span style="color:#fe2c24;">等待一段时间再运行脚本</span><span style="color:#0d0016;">（上图并非本人提供）</span></p> 
 <ul><li><strong><span style="color:#0d0016;">若无上述的错误，但运行仍然失败</span></strong></li></ul> 
 <p>考虑将<strong>kafka_test.py</strong>的下图代码里的<span style="color:#98c091;">"/check"</span>更改为其他名称，例如：<span style="color:#98c091;">"/check1"</span>，这可能是因为<span style="color:#ff9900;">HDFS里文件重复导致的问题</span>。</p> 
 <pre><code class="language-python">query = wind.writeStream.option("checkpointLocation", "/check").outputMode("append").foreach(sendmsg).start()</code></pre> 
</blockquote>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/8ca35625074cfbca3f8eb52c6ce72f7f/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">使用Anomalib项目的padim无监督算法 进行自制工业缺陷数据集的模型训练和ONNX部署（一）——模型训练篇</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/8400583a61f285490a3ee40f4ed88d70/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">算法数据结构基础——哈希表（Hash Table）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>