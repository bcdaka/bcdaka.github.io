<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Python爬虫:下载4K壁纸 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/c64cf1b22a2fb2920a50ed20829c25e8/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="Python爬虫:下载4K壁纸">
  <meta property="og:description" content="🎁🎁创作不易，关注作者不迷路🎀🎀
目录
🌸完整代码
🌸分析
🎁基本思路
🎁需要的库
🎁提取图片的链接和标题
👓寻找Cookie和User-Agent
👓图片链接和标题
🎁下载保存图片
🎁获取目录页面图片和翻页提取
👓目录页图片的提取
👓翻页规律寻找
🌸运行效果
🌸文末彩蛋🎀
我们经常想要寻找一些高清的壁纸，图片作为素材（为CSDN博客找一张吸引读者的封面🤣），然而一张一张的下载太慢了，因此为了提高工作效率， 我们可以采用爬虫的方式，快速下载图片。
🌸完整代码 import os#导入操作系统的库 import requests #导入HTTP库 from lxml import etree#导入lxml库，数据解析 global num num=1 #请求头,伪装爬虫 header={ &#39;user-agent&#39;: &#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36 Edg/127.0.0.0&#39;, &#39;cookie&#39;: &#39;zkhanecookieclassrecord=%2C66%2C70%2C&#39; } #获取具体的图片的地址和名字信息 # url=&#39;https://pic.netbian.com/tupian/34694.html&#39; def get_pic(url,header): re=requests.get(url,headers=header) re.encoding=re.apparent_encoding#获取html文本时用网页原有的编码方式，防止乱码 #print(re.apparent_encoding) #返回的编码 html=etree.HTML(re.text) link=html.xpath(&#39;//div[@class=&#34;photo-pic&#34;]/a/img/@src&#39;)[0]#获取图片链接 link=&#39;https://pic.netbian.com&#39;&#43;link print(link) title=html.xpath(&#39;//div[@class=&#34;photo-pic&#34;]/a/img/@title&#39;)[0]#获取图片名称 print(title) return title,link #下载保存图片 def download_pic(url,header): global num title,link=get_pic(url,header) if not os.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-08-10T15:41:11+08:00">
    <meta property="article:modified_time" content="2024-08-10T15:41:11+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Python爬虫:下载4K壁纸</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <blockquote> 
 <p>🎁🎁创作不易，关注作者不迷路🎀🎀</p> 
</blockquote> 
<p id="main-toc"><strong>目录</strong></p> 
<p id="%F0%9F%8C%B8%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81-toc" style="margin-left:40px;"><a href="#%F0%9F%8C%B8%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81" rel="nofollow">🌸完整代码</a></p> 
<p id="%F0%9F%8C%B8%E5%88%86%E6%9E%90-toc" style="margin-left:40px;"><a href="#%F0%9F%8C%B8%E5%88%86%E6%9E%90" rel="nofollow">🌸分析</a></p> 
<p id="%C2%A0%F0%9F%8E%81%E5%9F%BA%E6%9C%AC%E6%80%9D%E8%B7%AF-toc" style="margin-left:80px;"><a href="#%C2%A0%F0%9F%8E%81%E5%9F%BA%E6%9C%AC%E6%80%9D%E8%B7%AF" rel="nofollow"> 🎁基本思路</a></p> 
<p id="%F0%9F%8E%81%E9%9C%80%E8%A6%81%E7%9A%84%E5%BA%93-toc" style="margin-left:80px;"><a href="#%F0%9F%8E%81%E9%9C%80%E8%A6%81%E7%9A%84%E5%BA%93" rel="nofollow">🎁需要的库</a></p> 
<p id="%F0%9F%8E%81%E6%8F%90%E5%8F%96%E5%9B%BE%E7%89%87%E7%9A%84%E9%93%BE%E6%8E%A5%E5%92%8C%E6%A0%87%E9%A2%98-toc" style="margin-left:80px;"><a href="#%F0%9F%8E%81%E6%8F%90%E5%8F%96%E5%9B%BE%E7%89%87%E7%9A%84%E9%93%BE%E6%8E%A5%E5%92%8C%E6%A0%87%E9%A2%98" rel="nofollow">🎁提取图片的链接和标题</a></p> 
<p id="%F0%9F%91%93%E5%AF%BB%E6%89%BECookie%E5%92%8CUser-Agent-toc" style="margin-left:120px;"><a href="#%F0%9F%91%93%E5%AF%BB%E6%89%BECookie%E5%92%8CUser-Agent" rel="nofollow">👓寻找Cookie和User-Agent</a></p> 
<p id="%F0%9F%91%93%E5%9B%BE%E7%89%87%E9%93%BE%E6%8E%A5%E5%92%8C%E6%A0%87%E9%A2%98-toc" style="margin-left:120px;"><a href="#%F0%9F%91%93%E5%9B%BE%E7%89%87%E9%93%BE%E6%8E%A5%E5%92%8C%E6%A0%87%E9%A2%98" rel="nofollow">👓图片链接和标题</a></p> 
<p id="%F0%9F%8E%81%E4%B8%8B%E8%BD%BD%E4%BF%9D%E5%AD%98%E5%9B%BE%E7%89%87-toc" style="margin-left:80px;"><a href="#%F0%9F%8E%81%E4%B8%8B%E8%BD%BD%E4%BF%9D%E5%AD%98%E5%9B%BE%E7%89%87" rel="nofollow">🎁下载保存图片</a></p> 
<p id="%F0%9F%8E%81%E8%8E%B7%E5%8F%96%E7%9B%AE%E5%BD%95%E9%A1%B5%E9%9D%A2%E5%9B%BE%E7%89%87%E5%92%8C%E7%BF%BB%E9%A1%B5%E6%8F%90%E5%8F%96-toc" style="margin-left:80px;"><a href="#%F0%9F%8E%81%E8%8E%B7%E5%8F%96%E7%9B%AE%E5%BD%95%E9%A1%B5%E9%9D%A2%E5%9B%BE%E7%89%87%E5%92%8C%E7%BF%BB%E9%A1%B5%E6%8F%90%E5%8F%96" rel="nofollow">🎁获取目录页面图片和翻页提取</a></p> 
<p id="%F0%9F%91%93%E7%9B%AE%E5%BD%95%E9%A1%B5%E5%9B%BE%E7%89%87%E7%9A%84%E6%8F%90%E5%8F%96-toc" style="margin-left:120px;"><a href="#%F0%9F%91%93%E7%9B%AE%E5%BD%95%E9%A1%B5%E5%9B%BE%E7%89%87%E7%9A%84%E6%8F%90%E5%8F%96" rel="nofollow">👓目录页图片的提取</a></p> 
<p id="%F0%9F%91%93%E7%BF%BB%E9%A1%B5%E8%A7%84%E5%BE%8B%E5%AF%BB%E6%89%BE-toc" style="margin-left:120px;"><a href="#%F0%9F%91%93%E7%BF%BB%E9%A1%B5%E8%A7%84%E5%BE%8B%E5%AF%BB%E6%89%BE" rel="nofollow">👓翻页规律寻找</a></p> 
<p id="%F0%9F%8C%B8%E8%BF%90%E8%A1%8C%E6%95%88%E6%9E%9C-toc" style="margin-left:40px;"><a href="#%F0%9F%8C%B8%E8%BF%90%E8%A1%8C%E6%95%88%E6%9E%9C" rel="nofollow">🌸运行效果</a></p> 
<p id="%C2%A0%F0%9F%8C%B8%E6%96%87%E6%9C%AB%E5%BD%A9%E8%9B%8B%F0%9F%8E%80-toc" style="margin-left:40px;"><a href="#%C2%A0%F0%9F%8C%B8%E6%96%87%E6%9C%AB%E5%BD%A9%E8%9B%8B%F0%9F%8E%80" rel="nofollow"> 🌸文末彩蛋🎀</a></p> 
<p></p> 
<p><img alt="" height="901" src="https://images2.imgbox.com/94/e2/Xrkj6CDy_o.jpg" width="1200"></p> 
<blockquote> 
 <p>我们经常想要寻找一些高清的壁纸，图片作为素材（为CSDN博客找一张吸引读者的封面🤣），然而一张一张的下载太慢了，因此为了提高工作效率， 我们可以采用爬虫的方式，快速下载图片。</p> 
</blockquote> 
<h3 id="%F0%9F%8C%B8%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81">🌸完整代码</h3> 
<pre><code class="language-python">import os#导入操作系统的库
import requests  #导入HTTP库
from lxml import etree#导入lxml库，数据解析


global num
num=1
#请求头,伪装爬虫
header={
'user-agent':
'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36 Edg/127.0.0.0',
'cookie':
'zkhanecookieclassrecord=%2C66%2C70%2C'

}

#获取具体的图片的地址和名字信息
# url='https://pic.netbian.com/tupian/34694.html'
def get_pic(url,header):
    re=requests.get(url,headers=header)
    re.encoding=re.apparent_encoding#获取html文本时用网页原有的编码方式，防止乱码
    #print(re.apparent_encoding) #返回的编码
    html=etree.HTML(re.text)
    link=html.xpath('//div[@class="photo-pic"]/a/img/@src')[0]#获取图片链接
    link='https://pic.netbian.com'+link
    print(link)
    title=html.xpath('//div[@class="photo-pic"]/a/img/@title')[0]#获取图片名称
    print(title)
    return title,link

#下载保存图片
def download_pic(url,header):
    global num
    title,link=get_pic(url,header)
    if not os.path.exists(r"C:\Users\liu\Desktop\图片\4K壁纸"):#未找到文件夹则创建文件夹
        os.mkdir(r"C:\Users\liu\Desktop\图片\4K壁纸")
    content=requests.get(link,headers=header).content
    with open(rf"C:\Users\liu\Desktop\图片\4K壁纸\{str(num)}.jpg",'wb') as f:#以二进制编码写入文件
        f.write(content)
    num += 1

#目录翻页提取链接
def get_content_link(url,header):
    # url='https://pic.netbian.com/pingban/index.html'
    re=requests.get(url,headers=header)
    re.encoding=re.apparent_encoding
    # print(re.text)
    html=etree.HTML(re.text)
    links=html.xpath('//div[@class="slist"]//a/@href')
    for x in links:
        x='https://pic.netbian.com'+x
        download_pic(x,header)

#循环遍历网页，处理信息
for i in range(1,24):
    if i==1:
        url='https://pic.netbian.com/pingban/index.html'
    else :
        url=f'https://pic.netbian.com/pingban/index_{i}.html'
    get_content_link(url,header)</code></pre> 
<h3 id="%F0%9F%8C%B8%E5%88%86%E6%9E%90" style="background-color:transparent;">🌸分析</h3> 
<h4 id="%C2%A0%F0%9F%8E%81%E5%9F%BA%E6%9C%AC%E6%80%9D%E8%B7%AF"> 🎁基本思路</h4> 
<ul><li> 找到图片页网页源代码</li><li>提取所有图片的链接和标题</li><li>下载保存图片</li><li>爬取目录页的网页源代码</li><li>下载目录页的图片</li><li>分析不同页面的地址变化，找出规律实现翻页下载</li></ul> 
<h4 id="%F0%9F%8E%81%E9%9C%80%E8%A6%81%E7%9A%84%E5%BA%93">🎁需要的库</h4> 
<pre><code class="language-python">import os
import requests
from lxml import etree</code></pre> 
<p>requests和lxml库是第三方库，需要自己安装</p> 
<h4 id="%F0%9F%8E%81%E6%8F%90%E5%8F%96%E5%9B%BE%E7%89%87%E7%9A%84%E9%93%BE%E6%8E%A5%E5%92%8C%E6%A0%87%E9%A2%98">🎁提取图片的链接和标题</h4> 
<h5 id="%F0%9F%91%93%E5%AF%BB%E6%89%BECookie%E5%92%8CUser-Agent" style="background-color:transparent;">👓寻找Cookie和User-Agent</h5> 
<p>首先打开页面，打开开发者工具，按Ctrl+R刷新页面，点击开发者工具的“网络”选项，点击第一份文件，查看请求地址，Cookie和User-Agent</p> 
<p><img alt="" height="820" src="https://images2.imgbox.com/73/61/hergLPol_o.png" width="1200"></p> 
<p><img alt="" height="455" src="https://images2.imgbox.com/0e/35/C7AL8JAc_o.png" width="923"></p> 
<p><img alt="" height="255" src="https://images2.imgbox.com/e0/be/gB59Opif_o.png" width="880"></p> 
<p> 将Cookie和User-Agent作为请求头</p> 
<pre><code class="language-python">header={
'user-agent':
'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36 Edg/127.0.0.0',
'cookie':
'zkhanecookieclassrecord=%2C66%2C70%2C'

}</code></pre> 
<h5 id="%F0%9F%91%93%E5%9B%BE%E7%89%87%E9%93%BE%E6%8E%A5%E5%92%8C%E6%A0%87%E9%A2%98" style="background-color:transparent;">👓图片链接和标题</h5> 
<p><img alt="" height="484" src="https://images2.imgbox.com/81/08/HToCjGLD_o.png" width="1156"></p> 
<p>这里需要用到<strong>lxml库以及xpath</strong>的知识，看图说话，链接和地址存在&lt;div class="photo-pic"&gt;下的a元素中img元素中的src属性和title属性</p> 
<p><strong>图片链接</strong></p> 
<pre><code class="language-python">link=html.xpath('//div[@class="photo-pic"]/a/img/@src')[0]#获取图片链接</code></pre> 
<p><strong>图片标题</strong></p> 
<pre><code class="language-python">title=html.xpath('//div[@class="photo-pic"]/a/img/@title')[0]#获取图片名称</code></pre> 
<p><strong>写成函数方便调用</strong></p> 
<pre><code class="language-python">#获取具体的图片的地址和名字信息
# url='https://pic.netbian.com/tupian/34694.html'
def get_pic(url,header):
    re=requests.get(url,headers=header)
    re.encoding=re.apparent_encoding#获取html文本时用网页原有的编码方式，防止乱码
    #print(re.apparent_encoding) #返回的编码
    html=etree.HTML(re.text)
    link=html.xpath('//div[@class="photo-pic"]/a/img/@src')[0]#获取图片链接
    link='https://pic.netbian.com'+link
    print(link)
    title=html.xpath('//div[@class="photo-pic"]/a/img/@title')[0]#获取图片名称
    print(title)
    return title,link</code></pre> 
<h4 id="%F0%9F%8E%81%E4%B8%8B%E8%BD%BD%E4%BF%9D%E5%AD%98%E5%9B%BE%E7%89%87" style="background-color:transparent;">🎁下载保存图片</h4> 
<p>存储到一个新的文件夹“4K壁纸”，如果文件夹不存在，需要创建，这里要用到os库</p> 
<pre><code class="language-python">#未找到文件夹则创建文件夹
if not os.path.exists(r"C:\Users\liu\Desktop\图片\4K壁纸"):        
    os.mkdir(r"C:\Users\liu\Desktop\图片\4K壁纸")</code></pre> 
<p>写入文件</p> 
<pre><code class="language-python">content=requests.get(link,headers=header).content
with open(rf"C:\Users\liu\Desktop\图片\4K壁纸\{str(num)}.jpg",'wb') as f:#以二进制编码写入文件
    f.write(content)</code></pre> 
<p>写成函数方便调用</p> 
<pre><code class="language-python">#下载保存图片
def download_pic(url,header):
    global num
    title,link=get_pic(url,header)
    if not os.path.exists(r"C:\Users\liu\Desktop\图片\4K壁纸"):#未找到文件夹则创建文件夹
        os.mkdir(r"C:\Users\liu\Desktop\图片\4K壁纸")
    content=requests.get(link,headers=header).content
    with open(rf"C:\Users\liu\Desktop\图片\4K壁纸\{str(num)}.jpg",'wb') as f:#以二进制编码写入文件
        f.write(content)
    num += 1</code></pre> 
<h4 id="%F0%9F%8E%81%E8%8E%B7%E5%8F%96%E7%9B%AE%E5%BD%95%E9%A1%B5%E9%9D%A2%E5%9B%BE%E7%89%87%E5%92%8C%E7%BF%BB%E9%A1%B5%E6%8F%90%E5%8F%96">🎁获取目录页面图片和翻页提取</h4> 
<p>上面我们实现一张图片的保存，写了十几行代码算是成功保存了🤣🤣🤣，一张图片干嘛这么麻烦捏😂，直接点击“图片另存为”不就行了吗，那如果是很多图片吗，那肯定是爬虫更快了呗</p> 
<h5 id="%F0%9F%91%93%E7%9B%AE%E5%BD%95%E9%A1%B5%E5%9B%BE%E7%89%87%E7%9A%84%E6%8F%90%E5%8F%96">👓目录页图片的提取</h5> 
<p>依然用到lxml库，利用xpath语法提取</p> 
<p><img alt="" height="600" src="https://images2.imgbox.com/a0/34/l2Lc4zwO_o.png" width="793"></p> 
<pre><code class="language-python">#目录翻页提取链接
def get_content_link(url,header):
    # url='https://pic.netbian.com/pingban/index.html'
    re=requests.get(url,headers=header)
    re.encoding=re.apparent_encoding
    # print(re.text)
    html=etree.HTML(re.text)
    links=html.xpath('//div[@class="slist"]//a/@href')
    for x in links:
        x='https://pic.netbian.com'+x
        download_pic(x,header)</code></pre> 
<h5 id="%F0%9F%91%93%E7%BF%BB%E9%A1%B5%E8%A7%84%E5%BE%8B%E5%AF%BB%E6%89%BE">👓翻页规律寻找</h5> 
<p>📕找到第一页目录页</p> 
<pre><code class="language-python">https://pic.netbian.com/pingban/index.html</code></pre> 
<p>📕找到第二页目录页</p> 
<pre><code class="language-python">https://pic.netbian.com/pingban/index_2.html</code></pre> 
<p>📕找到第三页目录页</p> 
<pre><code class="language-python">https://pic.netbian.com/pingban/index_3.html</code></pre> 
<p>发现规律:第一页单独列出来，其他页通过for循环改变index_{i}即可</p> 
<pre><code class="language-python">#循环遍历网页，处理信息
for i in range(1,24):
    if i==1:
        url='https://pic.netbian.com/pingban/index.html'
    else :
        url=f'https://pic.netbian.com/pingban/index_{i}.html'
    get_content_link(url,header)</code></pre> 
<p>通过for循环遍历，最终可以实现所有图片的下载</p> 
<h3 id="%F0%9F%8C%B8%E8%BF%90%E8%A1%8C%E6%95%88%E6%9E%9C" style="background-color:transparent;">🌸运行效果</h3> 
<p>成功下载4K壁纸，耗时两分半🐔，下载400多张图片，爬虫提取就是快，手动提取预估一坤时左右🐔</p> 
<p><img alt="" height="466" src="https://images2.imgbox.com/1b/b8/7b2oU4t4_o.png" width="904"></p> 
<p><img alt="" height="620" src="https://images2.imgbox.com/27/5b/wZ4Cqi2T_o.png" width="1200"> </p> 
<h3 id="%C2%A0%F0%9F%8C%B8%E6%96%87%E6%9C%AB%E5%BD%A9%E8%9B%8B%F0%9F%8E%80"> 🌸文末彩蛋🎀</h3> 
<p><img alt="" height="901" src="https://images2.imgbox.com/0e/68/KbVC5aPC_o.jpg" width="1200"></p> 
<p><img alt="" height="901" src="https://images2.imgbox.com/77/24/Gwe9IQqt_o.jpg" width="1200"> <img alt="" height="901" src="https://images2.imgbox.com/61/43/XvFLRhc0_o.jpg" width="1200"></p> 
<p><img alt="" height="901" src="https://images2.imgbox.com/79/b1/uz8w2Sdh_o.jpg" width="1200"> </p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/3fdb119998068694d767c38ca6d74c29/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">深入探索：【人工智能】、【机器学习】与【深度学习】的全景视觉之旅</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/435e636c223d7827aee260921cc4f308/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">C&#43;&#43; | list</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>