<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>摸鱼大数据——Kafka——Kafka的shell命令使用 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/abe1a6ffa4f786477e386131e405ea80/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="摸鱼大数据——Kafka——Kafka的shell命令使用">
  <meta property="og:description" content="Kafka本质上就是一个消息队列的中间件的产品，主要负责消息数据的传递。也就说学习Kafka 也就是学习如何使用Kafka生产数据，以及如何使用Kafka来消费数据
topics操作 注意:
创建topic不指定分区数和副本数,默认都是1个
分区数可以后期通过alter增大,但是不能减小
副本数一旦确定,不能修改!
参数如下:
cd /export/server/kafka/bin
./kafka-topics.sh 参数说明:
--bootstrap-server: Kafka集群中broker服务器
--topic: 指定Topic名称
--partitions: 设置Topic的分区数,可以省略不写
--replication-factor: 设置Topic分区的副本数,可以省略不写
--create: 指定操作类型。这里是新建Topic
--delete: 指定操作类型。这里是删除Topic
--alter: 指定操作类型。这里是修改Topic
--list: 指定操作类型。这里是查看所有Topic列表
--describe: 指定操作类型。这里是查看详细且具体的Topic信息
1- 创建Topic
# 创建topic,默认1个分区,1个副本 /export/server/kafka/bin/kafka-topics.sh --bootstrap-server node1:9092 --create --topic itcast # 注意: 如果副本数超过了集群broker节点个数，就会报错 /export/server/kafka/bin/kafka-topics.sh --bootstrap-server node1:9092 --create --topic itheima --partitions 4 --replication-factor 4 # 把replication-factor改成3以内就能创建成功了 /export/server/kafka/bin/kafka-topics.sh --bootstrap-server node1:9092 --create --topic itheima --partitions 4 --replication-factor 3 2- 查看Topic
# --list查看所有topic /export/server/kafka/bin/kafka-topics.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-07-12T07:15:00+08:00">
    <meta property="article:modified_time" content="2024-07-12T07:15:00+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">摸鱼大数据——Kafka——Kafka的shell命令使用</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>Kafka本质上就是一个消息队列的中间件的产品，主要负责消息数据的传递。也就说学习Kafka 也就是学习如何使用Kafka生产数据，以及如何使用Kafka来消费数据</p> 
<h5>topics操作</h5> 
<blockquote> 
 <p>注意:</p> 
 <p>创建topic不指定分区数和副本数,默认都是1个</p> 
 <p>分区数可以后期通过alter增大,但是不能减小</p> 
 <p>副本数一旦确定,不能修改!</p> 
</blockquote> 
<p>参数如下:</p> 
<p>cd /export/server/kafka/bin</p> 
<p>./kafka-topics.sh 参数说明:<br>     --bootstrap-server: Kafka集群中broker服务器<br>     --topic: 指定Topic名称<br>     --partitions: 设置Topic的分区数,可以省略不写<br>     --replication-factor: 设置Topic分区的副本数,可以省略不写<br>     <br>     --create: 指定操作类型。这里是新建Topic<br>     --delete: 指定操作类型。这里是删除Topic<br>     --alter: 指定操作类型。这里是修改Topic<br>     --list: 指定操作类型。这里是查看所有Topic列表<br>     --describe: 指定操作类型。这里是查看详细且具体的Topic信息<br>     </p> 
<p></p> 
<p></p> 
<ul><li> <p>1- 创建Topic</p> </li></ul> 
<pre> # 创建topic,默认1个分区,1个副本
 /export/server/kafka/bin/kafka-topics.sh --bootstrap-server node1:9092 --create --topic itcast </pre> 
<pre> # 注意: 如果副本数超过了集群broker节点个数，就会报错
 /export/server/kafka/bin/kafka-topics.sh --bootstrap-server node1:9092 --create --topic itheima --partitions 4 --replication-factor 4</pre> 
<p></p> 
<p><img alt="" height="230" src="https://images2.imgbox.com/41/dd/v2cVy7e6_o.png" width="1164"></p> 
<p></p> 
<pre> # 把replication-factor改成3以内就能创建成功了
 /export/server/kafka/bin/kafka-topics.sh --bootstrap-server node1:9092 --create --topic itheima --partitions 4 --replication-factor 3</pre> 
<p></p> 
<ul><li> <p>2- 查看Topic</p> </li></ul> 
<pre> # --list查看所有topic
 /export/server/kafka/bin/kafka-topics.sh --bootstrap-server node1:9092 --list</pre> 
<pre> # --describe 可以查看详细Topic信息
 /export/server/kafka/bin/kafka-topics.sh --bootstrap-server node1:9092 --describe 
 ​
 # --describe 可以查看具体Topic信息
 /export/server/kafka/bin/kafka-topics.sh --bootstrap-server node1:9092 --describe --topic itheima</pre> 
<p><img alt="" height="140" src="https://images2.imgbox.com/27/5f/Kzg4RQbW_o.png" width="1188"></p> 
<p></p> 
<p>当然也可使用zookeeper客户端查看</p> 
<p></p> 
<p><img alt="" height="531" src="https://images2.imgbox.com/c0/81/kiVm0agC_o.png" width="1091"></p> 
<p></p> 
<p></p> 
<ul><li> <p>3- 修改Topic</p> </li></ul> 
<pre> # 增大topic分区
 /export/server/kafka/bin/kafka-topics.sh --bootstrap-server node1:9092 --alter --topic itcast --partitions 4</pre> 
<pre> # 注意: partitions分区,只能增大，不能减小。而且没有数量限制
 /export/server/kafka/bin/kafka-topics.sh --bootstrap-server node1:9092 --alter --topic itcast --partitions 1</pre> 
<p></p> 
<p><img alt="" height="458" src="https://images2.imgbox.com/f5/f1/dTvDVM3V_o.png" width="1200"></p> 
<p></p> 
<p># 注意: 副本既不能增大，也不能减小<br> /export/server/kafka/bin/kafka-topics.sh --bootstrap-server node1:9092 --alter --topic itcast --partitions 4 --replication-factor 2</p> 
<p></p> 
<p><img alt="" height="55" src="https://images2.imgbox.com/ca/22/PPvyNwnj_o.png" width="1200"></p> 
<p></p> 
<ul><li> <p>4- 删除Topic</p> </li></ul> 
<pre> # 再创建一个spark主题
 /export/server/kafka/bin/kafka-topics.sh --bootstrap-server node1:9092 --create --topic spark
 ​
 /export/server/kafka/bin/kafka-topics.sh --bootstrap-server node1:9092 --list
 ​
 # 删除spark主题
 ​
 /export/server/kafka/bin/kafka-topics.sh --bootstrap-server node1:9092 --delete --topic spark
 ​
 /export/server/kafka/bin/kafka-topics.sh --bootstrap-server node1:9092 --list
 ​</pre> 
<p></p> 
<h5>producer和consumer操作</h5> 
<blockquote> 
 <p>消费者要和生产者指定是同一个topic主题,才能接收到消息</p> 
</blockquote> 
<p>参数如下:</p> 
<pre> cd /export/server/kafka/bin
 ​
 ./kafka-console-producer.sh 参数说明
     --broker-list: Kafka集群中broker服务器
     --topic: 指定Topic
     
 ./kafka-console-consumer.sh 参数说明
     --bootstrap-server: Kafka集群中broker连接信息
     --topic: 指定Topic
     latest: 消费者（默认）从最新的地方开始消费
     --from-beginning: 指定该参数以后，会从最旧的地方开始消费
     --max-messages: 最多消费的条数。</pre> 
<p></p> 
<ul><li> <p>1- 模拟生产者Producer</p> </li></ul> 
<pre> # 为了方便演示再创建一个spark
 /export/server/kafka/bin/kafka-topics.sh --bootstrap-server node1:9092 --create --topic spark
 ​
 # 模拟生产者给spark发送消息
 /export/server/kafka/bin/kafka-console-producer.sh --broker-list node1:9092 --topic spark</pre> 
<p></p> 
<ul><li> <p>2- 模拟消费者Consumer</p> </li></ul> 
<pre> # 模拟消费者从spark获取消息,默认每次拿最新的
 /export/server/kafka/bin/kafka-console-consumer.sh --bootstrap-server node1:9092 --topic spark 
 ​
 # --from-beginning 会从最旧的地方开始消费
 /export/server/kafka/bin/kafka-console-consumer.sh --bootstrap-server node1:9092 --topic spark --from-beginning
 ​
 # --max-messages x 可以设置从最旧的地方最大消费次数x
 /export/server/kafka/bin/kafka-console-consumer.sh --bootstrap-server node1:9092 --topic spark --from-beginning --max-messages 5</pre> 
<blockquote> 
 <p>注意：</p> 
 <p>我们有时候发现消费者打印出来的消息和生产者生产的顺序不一致，是乱序的。原因如下：</p> 
 <p>topic有多个分区，底层是多线程来读取数据并进行打印输出。因此会存在乱序现象</p> 
</blockquote> 
<p></p> 
<p></p> 
<h5>bootstrap-server和zookeeper以及broker-list的区别:</h5> 
<pre> 旧版（&lt;v2.2）: kafka-topics.sh --zookeeper node1:2181,node2:2181,node3:2181/kafka --create --topic ..
 注意: 旧版用--zookeeper参数，主机名（或IP）和端口用ZooKeeper的2181，也就是server.properties文件中zookeeper.connect属性的配置值.
 ​
 新版(&gt;v2.2): kafka-topics.sh --bootstrap-server node1:9092 --create --topic ..
 注意: 新版用--bootstrap-server参数，主机名（或IP）和端口用某个节点的即可，即主机名（或主机IP）:9092。9092是Kafka的监听端口
 ​
 ​
 ​
 broker-list:broker指的是kafka的服务端，可以是一个服务器也可以是一个集群。producer和consumer都相当于这个服务端的客户端。一般我们再使用console producer的时候，broker-list参数是必备参数，另外一个必备的参数是topic
 ​
 bootstrap-servers: 指的是kafka集群的服务器地址，这个和broker-list功能是一样的，只不过我们在console producer要求用broker-list,其他地方都采用bootstrap-servers。</pre> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/9013da1aa1c5123716bba672e2d2ed10/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">PostgreSQL 怎样处理数据仓库中维度表和事实表的关联性能？</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/81aac31851d1442a8b481e755016e4c9/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Python酷库之旅-第三方库Pandas(018)</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>