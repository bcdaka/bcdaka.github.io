<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>滤波笔记一：卡尔曼滤波（Kalman Filtering）详解 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/daae0c0e30223f712faea224146c32ba/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="滤波笔记一：卡尔曼滤波（Kalman Filtering）详解">
  <meta property="og:description" content="本笔记是总结了B站DR_CAN的卡尔曼滤波器的课程，他的B站主页为：DR_CAN的个人空间_哔哩哔哩_bilibili
PS:虽然我不是学自控的，但是老师真的讲的很好！ 一个补充的参考链接，能够帮助进一步了解Q、R对这个实验的影响：
关于卡尔曼滤波中协方差矩阵Q,R的一些思考,卡尔曼原理讲解
目录
Lesson1 递归算法
Lesson2 数学基础_数据融合_协方差矩阵_状态空间方程
Lesson3 卡尔曼增益的详细推导
Lesson4 误差的协方差矩阵Pe的数学推导
Lesson5 直观理解卡尔曼滤波以及一个实例
当计算误差Wk大于测量误差Vk时
当计算误差Wk小于测量误差Vk时
本例的python代码
突然想到一个问题：如何确定卡尔曼滤波要迭代多少次呢？
总结一下
1.算法迭代的五个步骤
2.算法的python代码实现
Lesson1 递归算法 Lesson2 数学基础_数据融合_协方差矩阵_状态空间方程 Lesson3 卡尔曼增益的详细推导 Lesson4 误差的协方差矩阵Pe的数学推导 Lesson5 直观理解卡尔曼滤波以及一个实例 下面具体看一下，之前反复提到过：如果模型计算误差Wk小，最终的估计值就更偏向计算值；
如果测量误差Vk小，最终的估计值就更偏向于测量值。
而在这个示例中，Wk/Vk的偏差是以其协方差矩阵来反映的（主对角线是方差）。
当计算误差Wk大于测量误差Vk时 Wk的协方差矩阵为Q，Vk的协方差矩阵为R:
结果图：
结果分析：
真实的实际速度是蓝色曲线，最终的估计速度即为后验估计速度，是黄色曲线。对比它们之间的偏差能够看出估计值与实际值之间的误差，从而判断算法的准确度。
在最优化方法中我们知道：最优估计有不同的准则，比如：最小二乘估计、最小方差估计、极大后验估计等等。具体内容不赘述。
我们要知道，如果没有不确定性（即Wk和Vk）,那么估计值就是实际值（精准估计）。
卡尔曼滤波中采用的就是使得误差的方差最小为最优估计准则：因为如果后验估计值和真实值越接近，那么误差ek的变化就很小，即误差ek的方差很小。
进一步推导，考虑到误差ek会有很多不同的分量（因为状态量不同，比如说此例子中就是有状态量X1表示位置，状态量X2表示速度，那么它们就分别有误差e1和e2）。要使得总误差方差最小，那么误差各个分量的方差之和加起来就要最小。而“误差各分量的方差之和”正好是误差的协方差矩阵的主对角线之和——迹。
故此我们引入了Wk的协方差矩阵为Q，Vk的协方差矩阵为R。然后其方差越大时，说明误差越大，即越不可以相信。所以此处计算误差较大，可以看到先验估计速度（灰色）偏离实际速度（蓝色）的程度要大于测量速度（红色）偏离实际速度（蓝色的程度）。
所以最后的估计值——后验估计速度（黄色）曲线也是更为接近测量速度（红色）曲线。
一种通俗的理解方式就是：建模计算值和测量值都是不准确的，两者的不准确程度分别以计算误差的方差和测量误差的方差来衡量，方差越大越不可以相信。在两个不准确的值的基础上尽量准确估计，就是谁方差越小，越相信谁，越靠近谁。
当计算误差Wk小于测量误差Vk时 结果分析：
由于此时测量误差的方差较大，导致测量值很不可信，其变化的程度可以看到也很离谱。但是由于后验估计值（黄色）更为依赖模型计算值（灰色），所以后验估计值也没离实际值（蓝色）太远。
而这，正是卡尔曼滤波的作用：在不准确之中得到最准确的估计值。
本例的python代码 源代码来源：B站用户东爱北的GitHub​​​​​​https://github.com/liuchangji/2D-Kalman-Filter-Example_Dr_CAN_in_python
我对其中的源码做了注释，以及对一个小错误进行了修改（产生符合高斯分布的变量时，scale输入的应该是标准差，而协方差矩阵里面主对角线上面是方差，所以要开根号，要注意开完根号要保证其类型仍为np.float） import numpy as np import math import matplotlib.pyplot as plt plt.rcParams[&#39;font.sans-serif&#39;]=[&#39;SimHei&#39;] #用来正常显示中文标签 plt.rcParams[&#39;axes.unicode_minus&#39;]=False #用来正常显示负号 #定义一个产生符合高斯分布的函数,均值为loc=0.0,标准差为scale=sigma,输出的大小为size def gaussian_distribution_generator(sigma): return np.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2023-05-13T16:50:08+08:00">
    <meta property="article:modified_time" content="2023-05-13T16:50:08+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">滤波笔记一：卡尔曼滤波（Kalman Filtering）详解</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>本笔记是总结了B站DR_CAN的卡尔曼滤波器的课程，他的B站主页为：<a href="https://space.bilibili.com/230105574" rel="nofollow" title="DR_CAN的个人空间_哔哩哔哩_bilibili">DR_CAN的个人空间_哔哩哔哩_bilibili</a></p> 
<p>PS:虽然我不是学自控的，但是老师真的讲的很好！ </p> 
<p>一个补充的参考链接，能够帮助进一步了解Q、R对这个实验的影响：</p> 
<p><a href="https://www.cnblogs.com/laozhu1234/p/14932627.html" rel="nofollow" title="关于卡尔曼滤波中协方差矩阵Q,R的一些思考,卡尔曼原理讲解">关于卡尔曼滤波中协方差矩阵Q,R的一些思考,卡尔曼原理讲解</a></p> 
<p id="main-toc"><strong>目录</strong></p> 
<p id="Lesson1%20%E9%80%92%E5%BD%92%E7%AE%97%E6%B3%95-toc" style="margin-left:0px;"><a href="#Lesson1%20%E9%80%92%E5%BD%92%E7%AE%97%E6%B3%95" rel="nofollow">Lesson1 递归算法</a></p> 
<p id="Lesson2%C2%A0%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80_%E6%95%B0%E6%8D%AE%E8%9E%8D%E5%90%88_%E5%8D%8F%E6%96%B9%E5%B7%AE%E7%9F%A9%E9%98%B5_%E7%8A%B6%E6%80%81%E7%A9%BA%E9%97%B4%E6%96%B9%E7%A8%8B-toc" style="margin-left:0px;"><a href="#Lesson2%C2%A0%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80_%E6%95%B0%E6%8D%AE%E8%9E%8D%E5%90%88_%E5%8D%8F%E6%96%B9%E5%B7%AE%E7%9F%A9%E9%98%B5_%E7%8A%B6%E6%80%81%E7%A9%BA%E9%97%B4%E6%96%B9%E7%A8%8B" rel="nofollow">Lesson2 数学基础_数据融合_协方差矩阵_状态空间方程</a></p> 
<p id="Lesson3%20%E5%8D%A1%E5%B0%94%E6%9B%BC%E5%A2%9E%E7%9B%8A%E7%9A%84%E8%AF%A6%E7%BB%86%E6%8E%A8%E5%AF%BC-toc" style="margin-left:0px;"><a href="#Lesson3%20%E5%8D%A1%E5%B0%94%E6%9B%BC%E5%A2%9E%E7%9B%8A%E7%9A%84%E8%AF%A6%E7%BB%86%E6%8E%A8%E5%AF%BC" rel="nofollow">Lesson3 卡尔曼增益的详细推导</a></p> 
<p id="Lesson4%20%E8%AF%AF%E5%B7%AE%E7%9A%84%E5%8D%8F%E6%96%B9%E5%B7%AE%E7%9F%A9%E9%98%B5Pe%E7%9A%84%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC-toc" style="margin-left:0px;"><a href="#Lesson4%20%E8%AF%AF%E5%B7%AE%E7%9A%84%E5%8D%8F%E6%96%B9%E5%B7%AE%E7%9F%A9%E9%98%B5Pe%E7%9A%84%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC" rel="nofollow">Lesson4 误差的协方差矩阵Pe的数学推导</a></p> 
<p id="%C2%A0Lesson5%20%E7%9B%B4%E8%A7%82%E7%90%86%E8%A7%A3%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E4%BB%A5%E5%8F%8A%E4%B8%80%E4%B8%AA%E5%AE%9E%E4%BE%8B-toc" style="margin-left:0px;"><a href="#%C2%A0Lesson5%20%E7%9B%B4%E8%A7%82%E7%90%86%E8%A7%A3%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E4%BB%A5%E5%8F%8A%E4%B8%80%E4%B8%AA%E5%AE%9E%E4%BE%8B" rel="nofollow"> Lesson5 直观理解卡尔曼滤波以及一个实例</a></p> 
<p id="%E5%BD%93%E8%AE%A1%E7%AE%97%E8%AF%AF%E5%B7%AEWk%E5%A4%A7%E4%BA%8E%E6%B5%8B%E9%87%8F%E8%AF%AF%E5%B7%AEVk%E6%97%B6-toc" style="margin-left:40px;"><a href="#%E5%BD%93%E8%AE%A1%E7%AE%97%E8%AF%AF%E5%B7%AEWk%E5%A4%A7%E4%BA%8E%E6%B5%8B%E9%87%8F%E8%AF%AF%E5%B7%AEVk%E6%97%B6" rel="nofollow">当计算误差Wk大于测量误差Vk时</a></p> 
<p id="%E5%BD%93%E8%AE%A1%E7%AE%97%E8%AF%AF%E5%B7%AEWk%E5%B0%8F%E4%BA%8E%E6%B5%8B%E9%87%8F%E8%AF%AF%E5%B7%AEVk%E6%97%B6-toc" style="margin-left:40px;"><a href="#%E5%BD%93%E8%AE%A1%E7%AE%97%E8%AF%AF%E5%B7%AEWk%E5%B0%8F%E4%BA%8E%E6%B5%8B%E9%87%8F%E8%AF%AF%E5%B7%AEVk%E6%97%B6" rel="nofollow">当计算误差Wk小于测量误差Vk时</a></p> 
<p id="%E6%9C%AC%E4%BE%8B%E7%9A%84python%E4%BB%A3%E7%A0%81-toc" style="margin-left:40px;"><a href="#%E6%9C%AC%E4%BE%8B%E7%9A%84python%E4%BB%A3%E7%A0%81" rel="nofollow">本例的python代码</a></p> 
<p id="%E7%AA%81%E7%84%B6%E6%83%B3%E5%88%B0%E4%B8%80%E4%B8%AA%E9%97%AE%E9%A2%98%EF%BC%9A%E5%A6%82%E4%BD%95%E7%A1%AE%E5%AE%9A%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E8%A6%81%E8%BF%AD%E4%BB%A3%E5%A4%9A%E5%B0%91%E6%AC%A1%E5%91%A2%EF%BC%9F-toc" style="margin-left:80px;"><a href="#%E7%AA%81%E7%84%B6%E6%83%B3%E5%88%B0%E4%B8%80%E4%B8%AA%E9%97%AE%E9%A2%98%EF%BC%9A%E5%A6%82%E4%BD%95%E7%A1%AE%E5%AE%9A%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E8%A6%81%E8%BF%AD%E4%BB%A3%E5%A4%9A%E5%B0%91%E6%AC%A1%E5%91%A2%EF%BC%9F" rel="nofollow">突然想到一个问题：如何确定卡尔曼滤波要迭代多少次呢？</a></p> 
<p id="%E6%80%BB%E7%BB%93%E4%B8%80%E4%B8%8B-toc" style="margin-left:40px;"><a href="#%E6%80%BB%E7%BB%93%E4%B8%80%E4%B8%8B" rel="nofollow">总结一下</a></p> 
<p id="1.%E7%AE%97%E6%B3%95%E8%BF%AD%E4%BB%A3%E7%9A%84%E4%BA%94%E4%B8%AA%E6%AD%A5%E9%AA%A4-toc" style="margin-left:80px;"><a href="#1.%E7%AE%97%E6%B3%95%E8%BF%AD%E4%BB%A3%E7%9A%84%E4%BA%94%E4%B8%AA%E6%AD%A5%E9%AA%A4" rel="nofollow">1.算法迭代的五个步骤</a></p> 
<p id="2.%E7%AE%97%E6%B3%95%E7%9A%84python%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0-toc" style="margin-left:80px;"><a href="#2.%E7%AE%97%E6%B3%95%E7%9A%84python%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0" rel="nofollow">2.算法的python代码实现</a></p> 
<hr id="hr-toc"> 
<p></p> 
<h2 id="Lesson1%20%E9%80%92%E5%BD%92%E7%AE%97%E6%B3%95">Lesson1 递归算法</h2> 
<h2 id="%E2%80%8B%E7%BC%96%E8%BE%91"><img alt="" height="1200" src="https://images2.imgbox.com/83/77/t248bmST_o.jpg" width="1200"></h2> 
<p><img alt="" height="1200" src="https://images2.imgbox.com/9f/70/ClBUk0s0_o.jpg" width="1200"> <img alt="" height="1200" src="https://images2.imgbox.com/fc/23/7kmfdF6c_o.jpg" width="1200"></p> 
<p> <img alt="" height="1200" src="https://images2.imgbox.com/44/5c/FdILxf7p_o.jpg" width="1200"></p> 
<p></p> 
<h2 id="Lesson2%C2%A0%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80_%E6%95%B0%E6%8D%AE%E8%9E%8D%E5%90%88_%E5%8D%8F%E6%96%B9%E5%B7%AE%E7%9F%A9%E9%98%B5_%E7%8A%B6%E6%80%81%E7%A9%BA%E9%97%B4%E6%96%B9%E7%A8%8B">Lesson2 数学基础_数据融合_协方差矩阵_状态空间方程</h2> 
<p><img alt="" height="1200" src="https://images2.imgbox.com/92/17/EzNhTbuC_o.png" width="1200"><img alt="" height="1200" src="https://images2.imgbox.com/75/91/jhtgRA4G_o.png" width="1200"></p> 
<p> <img alt="" height="1200" src="https://images2.imgbox.com/50/2d/oil6Kp2d_o.png" width="1200"></p> 
<p><img alt="" height="1200" src="https://images2.imgbox.com/43/de/ndPzgd9u_o.png" width="1200"></p> 
<p> <img alt="" height="1200" src="https://images2.imgbox.com/03/59/iFhjpXAn_o.png" width="1200"></p> 
<p></p> 
<p></p> 
<h2 id="Lesson3%20%E5%8D%A1%E5%B0%94%E6%9B%BC%E5%A2%9E%E7%9B%8A%E7%9A%84%E8%AF%A6%E7%BB%86%E6%8E%A8%E5%AF%BC">Lesson3 卡尔曼增益的详细推导</h2> 
<h2><img alt="" height="1200" src="https://images2.imgbox.com/fd/0b/5dpKmoJe_o.png" width="1200"></h2> 
<p> <img alt="" height="1200" src="https://images2.imgbox.com/59/2f/WMslgqUu_o.png" width="1200"></p> 
<p> <img alt="" height="1200" src="https://images2.imgbox.com/fc/80/vfaojS4z_o.png" width="1200"></p> 
<p> <img alt="" height="1200" src="https://images2.imgbox.com/44/38/Iysy84WP_o.png" width="1200"><img alt="" height="1200" src="https://images2.imgbox.com/58/3f/0DtADFma_o.png" width="1200"></p> 
<p><img alt="" height="1200" src="https://images2.imgbox.com/7d/dc/7ZoZSTwn_o.png" width="1200"></p> 
<h2 id="Lesson4%20%E8%AF%AF%E5%B7%AE%E7%9A%84%E5%8D%8F%E6%96%B9%E5%B7%AE%E7%9F%A9%E9%98%B5Pe%E7%9A%84%E6%95%B0%E5%AD%A6%E6%8E%A8%E5%AF%BC">Lesson4 误差的协方差矩阵Pe的数学推导</h2> 
<p><img alt="" height="1200" src="https://images2.imgbox.com/a5/e8/f88itK6N_o.png" width="1200"></p> 
<p> <img alt="" height="1200" src="https://images2.imgbox.com/9e/f6/lvXiX0I7_o.png" width="1200"></p> 
<p> <img alt="" height="1200" src="https://images2.imgbox.com/b6/d9/IhbqsEL1_o.png" width="1200"></p> 
<h2 id="%C2%A0Lesson5%20%E7%9B%B4%E8%A7%82%E7%90%86%E8%A7%A3%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E4%BB%A5%E5%8F%8A%E4%B8%80%E4%B8%AA%E5%AE%9E%E4%BE%8B"> Lesson5 直观理解卡尔曼滤波以及一个实例</h2> 
<p><img alt="" height="1200" src="https://images2.imgbox.com/3f/29/KxThSxgv_o.png" width="1200"></p> 
<p> <img alt="" height="1200" src="https://images2.imgbox.com/52/1e/5UWCRihx_o.png" width="1200"></p> 
<p> <img alt="" height="1200" src="https://images2.imgbox.com/b0/8d/khI5h1VA_o.png" width="1200"></p> 
<p> <img alt="" height="1200" src="https://images2.imgbox.com/5e/a4/p3wHhBBL_o.png" width="1200"></p> 
<p> 下面具体看一下，之前反复提到过：如果模型计算误差Wk小，最终的估计值就更偏向计算值；</p> 
<p>                                                           如果测量误差Vk小，最终的估计值就更偏向于测量值。</p> 
<p>而在这个示例中，Wk/Vk的偏差是以其协方差矩阵来反映的（主对角线是方差）。</p> 
<h3 id="%E5%BD%93%E8%AE%A1%E7%AE%97%E8%AF%AF%E5%B7%AEWk%E5%A4%A7%E4%BA%8E%E6%B5%8B%E9%87%8F%E8%AF%AF%E5%B7%AEVk%E6%97%B6">当计算误差Wk大于测量误差Vk时</h3> 
<p>Wk的协方差矩阵为Q，Vk的协方差矩阵为R:</p> 
<p class="img-center"><img alt="" height="166" src="https://images2.imgbox.com/9d/7e/jN8vXewf_o.png" width="331"></p> 
<p> 结果图：</p> 
<p class="img-center"><img alt="" height="314" src="https://images2.imgbox.com/79/fc/mlvEVldg_o.png" width="504"></p> 
<p><span style="color:#fe2c24;">结果分析：</span></p> 
<p>真实的实际速度是蓝色曲线，最终的估计速度即为后验估计速度，是黄色曲线。对比它们之间的偏差能够看出估计值与实际值之间的误差，从而判断算法的准确度。</p> 
<p>在最优化方法中我们知道：最优估计有不同的准则，比如：最小二乘估计、最小方差估计、极大后验估计等等。具体内容不赘述。</p> 
<p>我们要知道，如果没有不确定性（即Wk和Vk）,那么估计值就是实际值（精准估计）。</p> 
<p>卡尔曼滤波中采用的就是使得<span style="color:#fe2c24;">误差的方差最小为最优估计准则</span>：<strong><span style="background-color:#f9eda6;">因为如果后验估计值和真实值越接近，那么误差ek的变化就很小，即误差ek的方差很小。</span></strong></p> 
<p><strong><span style="background-color:#f9eda6;">进一步推导，考虑到误差ek会有很多不同的分量（因为状态量不同，比如说此例子中就是有状态量X1表示位置，状态量X2表示速度，那么它们就分别有误差e1和e2）。要使得总误差方差最小，那么误差各个分量的方差之和加起来就要最小。而“误差各分量的方差之和”正好是误差的协方差矩阵的主对角线之和——迹。</span></strong></p> 
<p>故此我们引入了Wk的协方差矩阵为Q，Vk的协方差矩阵为R。然后其方差越大时，说明误差越大，即越不可以相信。所以此处计算误差较大，可以看到先验估计速度（灰色）偏离实际速度（蓝色）的程度要大于测量速度（红色）偏离实际速度（蓝色的程度）。</p> 
<p>所以最后的估计值——后验估计速度（黄色）曲线也是更为接近测量速度（红色）曲线。</p> 
<p>一种通俗的理解方式就是：建模计算值和测量值都是不准确的，两者的不准确程度分别以<span style="color:#fe2c24;">计算误差的方差</span>和<span style="color:#a2e043;">测量误差的方差</span>来衡量，方差越大越不可以相信。在两个不准确的值的基础上尽量准确估计，就是谁方差越小，越相信谁，越靠近谁。</p> 
<h3 id="%E5%BD%93%E8%AE%A1%E7%AE%97%E8%AF%AF%E5%B7%AEWk%E5%B0%8F%E4%BA%8E%E6%B5%8B%E9%87%8F%E8%AF%AF%E5%B7%AEVk%E6%97%B6">当计算误差Wk小于测量误差Vk时</h3> 
<p class="img-center"><img alt="" height="145" src="https://images2.imgbox.com/b8/53/N8ubqZWz_o.png" width="313"></p> 
<p class="img-center"><img alt="" height="286" src="https://images2.imgbox.com/6f/cd/J3c5kfvy_o.png" width="446"></p> 
<p><span style="color:#fe2c24;"> 结果分析：</span></p> 
<p>由于此时测量误差的方差较大，导致测量值很不可信，其变化的程度可以看到也很离谱。但是由于后验估计值（黄色）更为依赖模型计算值（灰色），所以后验估计值也没离实际值（蓝色）太远。</p> 
<p>而这，正是卡尔曼滤波的作用：<span style="background-color:#fbd4d0;">在不准确之中得到最准确的估计值。</span></p> 
<h3 id="%E6%9C%AC%E4%BE%8B%E7%9A%84python%E4%BB%A3%E7%A0%81">本例的python代码</h3> 
<p>源代码来源：B站用户东爱北的GitHub<a href="https://github.com/liuchangji/2D-Kalman-Filter-Example_Dr_CAN_in_python" title="​​​​​​https://github.com/liuchangji/2D-Kalman-Filter-Example_Dr_CAN_in_python">​​​​​​https://github.com/liuchangji/2D-Kalman-Filter-Example_Dr_CAN_in_python</a></p> 
<p>我对其中的源码做了注释，以及对一个小错误进行了修改（产生符合高斯分布的变量时，scale输入的应该是标准差，而协方差矩阵里面主对角线上面是方差，所以要开根号，要注意开完根号要保证其类型仍为np.float） </p> 
<div> 
 <pre><code class="language-python">

import numpy as np
import math
import matplotlib.pyplot as plt
plt.rcParams['font.sans-serif']=['SimHei'] #用来正常显示中文标签
plt.rcParams['axes.unicode_minus']=False #用来正常显示负号


#定义一个产生符合高斯分布的函数,均值为loc=0.0,标准差为scale=sigma,输出的大小为size
def gaussian_distribution_generator(sigma):
    return np.random.normal(loc=0.0,scale=sigma,size=None)

# 状态转移矩阵，上一时刻的状态转移到当前时刻
A = np.array([[1,1],[0,1]])

# 过程噪声w协方差矩阵Q，P(w)~N(0,Q)，噪声来自真实世界中的不确定性
Q = np.array([[0.01,0],[0,0.01]])

# 测量噪声协方差矩阵R，P(v)~N(0,R)，噪声来自测量过程的误差
R = np.array([[1,0],[0,1]])

# 传输矩阵/状态观测矩阵H
H = np.array([[1,0],[0,1]])

# 控制输入矩阵B
B = None

# 初始位置和速度
X0 = np.array([[0],[1]])

# 状态估计协方差矩阵P初始化
P =np.array([[1,0],[0,1]])

if __name__ == "__main__":
    #---------------------初始化-----------------------------
    #真实值初始化 这里还要再写一遍np.array是保证它的类型是数组array
    X_true = np.array(X0)
    #后验估计值Xk的初始化
    X_posterior = np.array(X0)
    #第k次误差的协方差矩阵的初始化
    P_posterior = np.array(P)

    #创建状态变量的真实值的矩阵 状态变量1：速度 状态变量2：位置
    speed_true = []
    position_true = []

    #创建测量值矩阵
    speed_measure = []
    position_measure = []

    #创建状态变量的先验估计值
    speed_prior_est = []
    position_prior_est = []

    #创建状态变量的后验估计值
    speed_posterior_est = []
    position_posterior_est = []

    #---------------------循环迭代-----------------------------
    #设置迭代次数为30次

    for i in range(30):
        #--------------------建模真实值-----------------------------

        # 生成过程噪声w w=[w1,w2].T(列向量)
        # Q[0,0]是过程噪声w的协方差矩阵的第一行第一列，即w1的方差，Q[1,1]是协方差矩阵的第二行第二列，即为w2的方差
        # python的np.random.normal(loc,scale,size)函数中scale输入的是标准差，所以要开方
        Q_sigma = np.array([[math.sqrt(Q[0,0]),Q[0,1]],[Q[1,0],math.sqrt(Q[1,1])]])
        w = np.array([[gaussian_distribution_generator(Q_sigma[0, 0])],
                      [gaussian_distribution_generator(Q_sigma[1, 1])]])
        # print('00',Q[0,0],'它的类型是',type(Q[0,0]))
        # print('开根号的00', Q_sigma[0, 0], '它的类型是', type(Q_sigma[0, 0]))
        # print('00的平方根',math.sqrt(Q[0,0]),"它的类型是",type(math.sqrt(Q[0,0])))
        # print('w[',i,']=',w)

        # 真实值X_true 得到当前时刻的状态;之前我一直在想它怎么完成从Xk-1到Xk的更新，实际上在代码里面直接做迭代就行了，这里是不涉及数组下标的！！！
        #dot函数用于矩阵乘法，对于二维数组，它计算的是矩阵乘积
        X_true = np.dot(A, X_true) + w

        # 速度的真实值是speed_true 使用append函数可以把每一次循环中产生的拼接在一起，形成一个新的数组speed_true
        speed_true.append(X_true[1,0])
        position_true.append(X_true[0,0])
        #print(speed_true)


        # --------------------生成观测值-----------------------------
        # 生成过程噪声
        R_sigma = np.array([[math.sqrt(R[0,0]),R[0,1]],[R[1,0],math.sqrt(R[1,1])]])
        v = np.array([[gaussian_distribution_generator(R_sigma[0,0])],[gaussian_distribution_generator(R_sigma[1,1])]])

        # 生成观测值Z_measure 取H为单位阵
        Z_measure = np.dot(H, X_true) + v
        speed_measure.append(Z_measure[1,0]),
        position_measure.append(Z_measure[0,0])

        # --------------------进行先验估计-----------------------------
        # 开始时间更新
        # step1:基于k-1时刻的后验估计值X_posterior建模预测k时刻的系统状态先验估计值X_prior
        # 此时模型控制输入U=0
        X_prior = np.dot(A, X_posterior)
        # 把k时刻先验预测值赋给两个状态分量的先验预测值 speed_prior_est = X_prior[1,0];position_prior_est=X_prior[0,0]
        # 再利用append函数把每次循环迭代后的分量值拼接成一个完整的数组
        speed_prior_est.append(X_prior[1,0])
        position_prior_est.append(X_prior[0,0])

        # step2:基于k-1时刻的误差ek-1的协方差矩阵P_posterior和过程噪声w的协方差矩阵Q 预测k时刻的误差的协方差矩阵的先验估计值 P_prior
        P_prior_1 = np.dot(A, P_posterior)
        P_prior = np.dot(P_prior_1, A.T) + Q

        # --------------------进行状态更新-----------------------------
        # step3:计算k时刻的卡尔曼增益K
        k1 = np.dot(P_prior, H.T)
        k2 = np.dot(H, k1) + R
        #k3 = np.dot(np.dot(H, P_prior), H.T) + R  k2和k3是两种写法，都可以
        K = np.dot(k1, np.linalg.inv(k2))

        # step4:利用卡尔曼增益K 进行校正更新状态，得到k时刻的后验状态估计值 X_posterior
        X_posterior_1 = Z_measure -np.dot(H, X_prior)
        X_posterior = X_prior + np.dot(K, X_posterior_1)
        # 把k时刻后验预测值赋给两个状态分量的后验预测值 speed_posterior_est = X_posterior[1,0];position_posterior_est = X_posterior[0,0]
        speed_posterior_est.append(X_posterior[1,0])
        position_posterior_est.append(X_posterior[0,0])

        # step5:更新k时刻的误差的协方差矩阵 为估计k+1时刻的最优值做准备
        P_posterior_1 = np.eye(2) - np.dot(K, H)
        P_posterior = np.dot(P_posterior_1, P_prior)

    # ---------------------再从step5回到step1 其实全程只要搞清先验后验 k的自增是隐藏在循环的过程中的 然后用分量speed和position的append去记录每一次循环的结果-----------------------------

    # 可视化显示 画出速度比较和位置比较
    if True:
        # 画出1行2列的多子图
        fig, axs = plt.subplots(1,2)
        #速度
        axs[0].plot(speed_true,"-",color="blue",label="速度真实值",linewidth="1")
        axs[0].plot(speed_measure,"-",color="grey",label="速度测量值",linewidth="1")
        axs[0].plot(speed_prior_est,"-",color="green",label="速度先验估计值",linewidth="1")
        axs[0].plot(speed_posterior_est,"-",color="red",label="速度后验估计值",linewidth="1")
        axs[0].set_title("speed")
        axs[0].set_xlabel('k')
        axs[0].legend(loc = 'upper left')


        #位置
        axs[1].plot(position_true,"-",color="blue",label="位置真实值",linewidth="1")
        axs[1].plot(position_measure,"-",color="grey",label="位置测量值",linewidth="1")
        axs[1].plot(position_prior_est,"-",color="green",label="位置先验估计值",linewidth="1")
        axs[1].plot(position_posterior_est,"-",color="red",label="位置后验估计值",linewidth="1")
        axs[1].set_title("position")
        axs[1].set_xlabel('k')
        axs[1].legend(loc = 'upper left')

        #     调整每个子图之间的距离
        plt.tight_layout()
        plt.figure(figsize=(60, 40))
        plt.show()</code></pre> 
</div> 
<p> 结果图1（迭代30次）：</p> 
<p><img alt="" height="480" src="https://images2.imgbox.com/ff/16/39tXNSA1_o.png" width="640"></p> 
<p>图2（迭代60次）：</p> 
<p><img alt="" height="480" src="https://images2.imgbox.com/38/24/E3p4IuUh_o.png" width="640"></p> 
<p></p> 
<p></p> 
<p><span style="color:#fe2c24;"> 图1结果分析：</span></p> 
<p>本次实例中，取了过程噪声的协方差矩阵为Q=[0.01,0;0,0.01]，即过程噪声的方差为0.01。取了测量噪声的协方差矩阵为R=[1,0;0,1]，即测量噪声的方差为1。根据最小方差估计准则，此时过程噪声方差小于测量噪声的误差，则先验估计值比测量值更可靠。</p> 
<p>我们看图：</p> 
<p>在速度的分析图中，明显看到速度测量值（灰色）偏离速度真实值（蓝色）的程度大于速度先验估计值（绿色）偏离速度真实值（蓝色）的程度，而经过卡尔曼滤波之后，后验估计值（红色）并没有非常偏离真实值（蓝色）。这就是因为此时卡尔曼滤波更为相信先验估计值。</p> 
<p>位置分析同理。</p> 
<h4 id="%E7%AA%81%E7%84%B6%E6%83%B3%E5%88%B0%E4%B8%80%E4%B8%AA%E9%97%AE%E9%A2%98%EF%BC%9A%E5%A6%82%E4%BD%95%E7%A1%AE%E5%AE%9A%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E8%A6%81%E8%BF%AD%E4%BB%A3%E5%A4%9A%E5%B0%91%E6%AC%A1%E5%91%A2%EF%BC%9F">突然想到一个问题：如何确定卡尔曼滤波要迭代多少次呢？</h4> 
<p>网上说不一定是迭代越多次越准确，由于采用最小方差估计准则，所以我想到了去看误差ek的协方差矩阵的迹，迹越小越好（误差分量的方差之和越小）。然后我又加了几行代码：</p> 
<pre><code class="language-python"># 创建误差的协方差矩阵的迹
    tr_P_posterior = []

# 误差的协方差矩阵的迹，迹越小说明估计越准确
        # print('ek1的方差:',P_posterior[0,0],'ek2的方差',P_posterior[1,1])

        tr_P_posterior.append(P_posterior[0,0]+P_posterior[1,1])

 #误差的协方差的迹
        axs[2].plot(tr_P_posterior,"-",color="blue",label="误差的迹",linewidth="1")
</code></pre> 
<p>60次迭代的图： </p> 
<p><img alt="" height="480" src="https://images2.imgbox.com/a5/dc/E2HKmdBd_o.png" width="640"></p> 
<p>可以看到，基本上在20次左右，误差的迹就已经收敛至min值了。</p> 
<p>于是我把迭代次数调整成20次：</p> 
<p><img alt="" height="480" src="https://images2.imgbox.com/86/da/3IZaBJcz_o.png" width="640"></p> 
<p>可以看到，大约在十几次的时候，误差的迹就收敛至极限值（约为0.38左右）</p> 
<p>那么就是说，刚开始迭代时，卡尔曼滤波器的误差还是挺大的（方差之和大约为1） ，随着迭代的进行，滤波器误差逐步减少至最低点，此后的误差维持在这个点（误差无法完全消除，只存在最小误差），即预测精度达到最优值。</p> 
<p></p> 
<h3 id="%E6%80%BB%E7%BB%93%E4%B8%80%E4%B8%8B">总结一下</h3> 
<h4 id="1.%E7%AE%97%E6%B3%95%E8%BF%AD%E4%BB%A3%E7%9A%84%E4%BA%94%E4%B8%AA%E6%AD%A5%E9%AA%A4">1.算法迭代的五个步骤</h4> 
<p><img alt="" height="1200" src="https://images2.imgbox.com/43/3e/IMGdd34k_o.png" width="1200"></p> 
<p><img alt="" height="957" src="https://images2.imgbox.com/62/d8/C1k0xWHj_o.png" width="1200"></p> 
<h4 id="2.%E7%AE%97%E6%B3%95%E7%9A%84python%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0">2.算法的python代码实现</h4> 
<p>我自己从头开始写的时候最难受的点应该就是因为太久不碰后端，逻辑上会很卡，然后忘记了append函数的作用，搞得我一直在纠结怎么从k-1时刻更新到k时刻，在想是不是要对矩阵做下标的更新什么的，循环迭代这里卡了很久。还有就是对状态变量、先验估计量、后验估计量、协方差矩阵的先验估计量和后验估计量以及它们之间的关系、它们与时刻k、k-1之间的关系不熟。</p> 
<p>其实在代码中，我们看一下这五个公式，对于当前时刻k：</p> 
<p>step1中的（k-1）时刻的后验估计就是上一次step4估计得到的结果,它们是<span style="color:#fe2c24;">同一个变量X_posterior；</span></p> 
<p>step2中的 Pk-1就是上一次step5计算得到的结果，它们是<span style="color:#a2e043;">同一个变量P_posterior;</span></p> 
<p>step3中的Pk先验，就是<span style="background-color:#f9eda6;">本次的</span>step2计算得到的结果，它们是<span style="color:#4da8ee;">同一个变量P_prior；</span></p> 
<p>step4中的Xk先验，就是<span style="background-color:#f9eda6;">本次的</span>step1计算得到的结果，它们是<span style="color:#ff9900;">同一个变量X_prior；</span></p> 
<p></p> 
<p>其次就是，我们要画图表示出速度、位置的迭代变化，就需要记录下每一次迭代产生的速度值和变量值，然后对它们进行可视化。</p> 
<p>最后就是，如果你对先验、后验、时刻搞不清，<span style="color:#fe2c24;">用英文写清楚变量意思</span>！！不要光贪图简洁！</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/d209cd685bc8a0e19c6f55b20400efc5/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Nacos的简介及安装和使用</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/82e2cf485c9616db58298bb70889ef07/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【peft】huggingface大模型加载多个LoRA并随时切换</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>