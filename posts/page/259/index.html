<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Posts - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="Posts">
  <meta property="og:description" content="编程大咖的博客">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="website">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	
	<link rel="alternate" type="application/rss+xml" href="/posts/index.xml" title="编程大咖">

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main list" role="main">
	<header class="main__header">
		<h1 class="main__title">Posts</h1>
	</header><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/8ae725f3d2232dbcba075feff6aa7478/" rel="bookmark">
			在Apache Flink中，Java UDF（用户自定义函数）的使用涉及几个关键步骤
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		在Apache Flink中，Java UDF（用户自定义函数）的使用涉及几个关键步骤：创建UDF类、注册UDF、以及在Flink作业中使用UDF。以下是一些具体的使用案例：
### 1. 创建项目和配置POM
首先，创建一个Maven项目，并配置`pom.xml`以包含Flink的依赖。例如，你可以配置Flink 1.11版的依赖：
```xml
&lt;dependencies&gt;
&lt;dependency&gt;
&lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
&lt;artifactId&gt;flink-streaming-java_2.12&lt;/artifactId&gt;
&lt;version&gt;1.11.0&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
&lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
&lt;artifactId&gt;flink-table&lt;/artifactId&gt;
&lt;version&gt;1.11.0&lt;/version&gt;
&lt;/dependency&gt;
&lt;/dependencies&gt;
```
### 2. 开发UDF
定义一个Java类实现所需的UDF。例如，创建一个简单的标量函数（ScalarFunction）来截取字符串的一部分：
```java
package ASI_UDF;
import org.apache.flink.table.functions.ScalarFunction;
public class SubstringUDF extends ScalarFunction {
public String eval(String s, int beginIndex, int endIndex) {
return s.substring(beginIndex, endIndex);
}
}
```
### 3. 本地测试
在本地创建测试类以验证UDF的行为是否符合预期：
```java
public class UDFTest {
@Test
public void testSubstringUDF() {
SubstringUDF udf = new SubstringUDF();
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/8ae725f3d2232dbcba075feff6aa7478/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/ff9a0b2433eb65b73462c2cea3dd2027/" rel="bookmark">
			UE5 发射物目标追踪
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		UE5 发射物目标追踪 思路
求出需要旋转的角度，然后每帧旋转，再更新速度
实现：
求出发射物当前方向和目标方向的旋转后，插值求每帧的旋转。
//向目标旋转 float Speed = MovementComponent-&gt;Velocity.Length(); //获取发射物坐标到目标几何中心的方向向量 FVector Origin, BoxExtent; TraceTarget-&gt;GetActorBounds(false, Origin, BoxExtent); FVector TargetVector = Origin - GetActorLocation(); TargetVector.Normalize(); //获取发射物速度到目标几何中心的方向向量的旋转四元数 FQuat RotationQuat = FQuat::FindBetweenVectors(MovementComponent-&gt;Velocity, TargetVector); FQuat TargetRotationQuat = FQuat::Slerp(FQuat::Identity, RotationQuat, RotateSpeed * DeltaTime); //更新速度 MovementComponent-&gt;Velocity = TargetRotationQuat.RotateVector(MovementComponent-&gt;Velocity).GetSafeNormal() * Speed; 但是这样写有个致命的缺点：每帧旋转的角度与需要旋转的角度正相关，角度越小旋转越小，角度越大旋转越大，我们不能接受
直接旋转固定角度
计算出需要的角度，然后每帧旋转固定角度。
发射物旋转我们需要注意的地方就是，在发射物的速度和旋转角度都很大且达到某一个平衡时，如果离目标足够近就可能导致变成绕着目标旋转。
我们可以选择设定当需要旋转的角度大于90度（或者设定的角度）后，就不再旋转。或者避免发射速度和旋转角度达成那个关系。
//向目标旋转 float Speed = MovementComponent-&gt;Velocity.Length(); //获取发射物坐标到目标几何中心的方向向量 FVector Origin, BoxExtent; TraceTarget-&gt;GetActorBounds(false, Origin, BoxExtent); FVector TargetVector = Origin - GetActorLocation(); TargetVector.Normalize(); FQuat RotationQuat = FQuat::FindBetweenVectors(MovementComponent-&gt;Velocity, TargetVector); float Angle = RotationQuat.
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/ff9a0b2433eb65b73462c2cea3dd2027/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/783040611bf38e992328b6651abc3adc/" rel="bookmark">
			GaussDB技术解读——GaussDB架构介绍（四）
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		目录
11 GaussDB云原生架构
11.1 云原生关键技术架构
11.2 关键技术方案
11.2.1 通信组件
11.2.2 集群管理组件
11.2.3 多租组件
GaussDB架构介绍（三）从智能关键技术方案、驱动接口关键技术方案等方面对GaussDB架构进行了解读，本篇将从云原生关键技术架构&amp;关键技术方案两方面对GaussDB云原生架构展开介绍。
11 GaussDB云原生架构 11.1 云原生关键技术架构 图1 云原生数据库1层逻辑模型
1. 分层原则。整体层次分为三层，分别为Application Layer，Computer Layer和Storage Layer。Application Layer应用层主要是客户端各种语言的驱动，这些驱动通过通信与计算层Computer Layer进行交互，对数据库进行操作。下面是Computer Layer计算层，计算层负责SQL处理和事务处理，数据库的备份处理，集群内和集群间的消息通信，整个集群的管理，与公有云基础服务（认证，计费，运维）的对接。最下面是Storage Layer存储层，存储层负责数据库数据的日志存储，数据存储，数据库的备份存储。
2. 分平面原则。管理面，控制面和用户面。管理面主要包括操作维护子系统，控制面主要包括资源调度子系统，用户面主要包括数据库服务子系统。
3. 适配器原则。底层存储支持本地文件系统，Dorado 存储，Ceph分布式文件系统和DFV存储。这些存储的操作接口统一封装为文件系统接口。
4. 负荷分担。所有子系统的服务节点对等，一个节点故障，其他节点可以接管。
5. 数据存储多副本存储。Dorado 支持多种Raid级别，PLOG存储支持数据存储为3副本。
11.2 关键技术方案 11.2.1 通信组件 云原生数据库采用shared disk架构，各个计算节点对等，计算节点之间通过页面交换实现缓存数据的一致性，为了提高页面传递的效率，需要利用RDMA或UB单边读写的能力；云原生数据库为了管理动态资源，需要对动态资源的owner分配进行加锁，分布式锁管理需要利用原子操作和RPC消息对资源进行加解锁；多租户资源管理服务需要下发调度信息，并从计算节点读取资源状态，需要RPC消息；集群管理组件进行故障检测、发送消息需要使用RPC消息。因此，通信组件需要能够支持原子操作、单边读写、双边RPC和RPC通信。
目前市场上有三种RDMA网络，分别是Infiniband、RoCE(RDMA over Converged Ethernet)、iWARP，如下图所示。其中，Infiniband是专为RDMA设计的网络，从硬件级别保证可靠传输 ，但是成本高昂。而RoCE 和 iWARP都是基于以太网实现的RDMA技术，在目前最广泛使用的以太网上实现了高速、超低延时、极低CPU使用率的RDMA通信。
图2 RDMA网络种类
RoCE协议有RoCEv1和RoCEv2两个版本，RoCEv1是基于以太网链路层实现的RDMA协议(交换机需要支持PFC等流控技术，在物理层保证可靠传输)，允许在同一个广播域下的任意两台主机直接访问；而RoCEv2是以太网TCP/IP协议中UDP层实现，即可以实现路由功能。
表1 InfinieBand和RoCE对比
InfiniBand：设计之初就考虑了 RDMA，从硬件级别保证可靠传输，提供更高的带宽和更低的时延。但是成本高，需要IB网卡和交换机支持。
RoCE：基于Ethernet 做RDMA，消耗的资源比 iWARP 少，支持的特性比 iWARP 多。可以使用普通的以太网交换机，但是需要支持RoCE的网卡。
iWARP：基于TCP的RDMA网络，利用TCP达到可靠传输。相比RoCE，在大型组网的情况下，iWARP的大量TCP连接会占用大量的内存资源，对系统规格要求更高。可以使用普通的以太网交换机，但是需要支持iWARP的网卡。
为了支持各种网卡类型的RDMA协议和实现低时延的网络通信，云原生数据库的节点通信组件的整体架构图如下:
图3 通信组件整体架构图
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/783040611bf38e992328b6651abc3adc/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/9940abe0d7c9919a64f1028f53eb49fc/" rel="bookmark">
			android studio 模拟器文件查找
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		 android studio 模拟器文件查找 使用安卓模拟器下载文件后通常无法在系统硬盘上找到下载的文件，安卓 studio studio 其实提供了文件浏览工具，找到后可以直接使用 Android studio 打开
打开 Android studioview 菜单view &gt; Tool Windows &gt; Device Explorer 或者 Device Explorer android studio developer page 
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/4d2cd148ec2ab09f6bffcbb8a301e023/" rel="bookmark">
			LLaMA-Factory环境安装-重点总结
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		问题：在使用官网介绍的博客，进行安装，比较顺利。只不过，在需要推理加速时，UI界面上，给出的选项所支持的FlashAttention-2和Unsloth，不好实现。在进行一系列的调整，总结如下：
想要同时实现FlashAttention-2和Unsloth推理加速的环境安装方式：
以Ubuntu22.04 RTX4090 24GB为例：
1. 系统配置：CUDA版本选择12.2.x，因为高版本的flash-attn库不提供12.1版本的安装包：
## cuda export PATH=/usr/local/cuda-12.2/bin:$PATH export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-12.2/lib64 2. 虚拟环境创建：python版本选择3.10.x，使用官方推荐的安装方式：
conda create -n llama_factory python=3.10 -y 3. 首先安装LLaMA-Factory官方提供的环境安装内容：
pip install -e .[torch,metrics,bitsandbytes] 备注：torch版本为2.3.x，后续根据变化调整为对应版本
4. 然后安装flash-attn库，版本号含有cu122torch2.3cxx11abiFALSE：
pip install flash_attn-2.5.8+cu122torch2.3cxx11abiFALSE-cp310-cp310-linux_x86_64.whl 备注：安装版本号含TRUE会报错。
5. 最后安装unsloth库，根据官方的安装内容，仅选取部分即可：
pip install "unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git" …… Installing collected packages: unsloth, protobuf Attempting uninstall: protobuf Found existing installation: protobuf 5.26.1 Uninstalling protobuf-5.26.1: Successfully uninstalled protobuf-5.26.1 Successfully installed protobuf-3.20.3 unsloth-2024.5 备注：有colab-new标识的，其他标识的安装额外库会报错。其次，这一步会将protobuf版本号降低导致FlashAttention-2方式的模型加速报错，但是将其版本号恢复为原先版本不会导致Unsloth方式模型加速报错，所以重新安装原先版本的protobuf库，此处根据实际进行恢复版本号：
pip install protobuf==5.26.1 6. 至此，安装完毕。不过还需要注意，在由Unsloth加速方式切换到其他方式的时候，会导致其他加速方式的模型加载失败，重启UI服务即可。
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/087a4774f3441a084ae5a177e8ff2a26/" rel="bookmark">
			Matlab r2023a v23.2.0 解锁版安装步骤 （工程计算商业数学软件）
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		 前言 Matlab（矩阵实验室）是全球领先的数学计算软件开发商美国 MathWorks 公司研发的一款面向科学与工程计算的高级语言的商业数学软件，集算法开发、数据分析、可视化和数值计算于一体的编程环境，其核心是仿真交互式矩阵计算，广泛应用于科学计算、数据分析、算法开发和绘图设计等科研领域应用环境。
一、下载地址 下载链接：http://dygod/source 点击搜索：Matlab
二、安装步骤 1、下载解压后会得到下图的文件 2、运行IOS挂载驱动文件选择setup.exe对Matlab进行安装 3、在软件的安装界面选择高级选项-&gt;我有文件安装密钥 4、接受条款并进行下一步操作 5、将软件安装密钥填入 6、导入软件的许可证文件 7、设置软件的安装位置，默认安装位置是 C:\Program Files\MATLAB\R2023b 8、其他安装自己需求设置，直接默认下一步直到软件安装完成 9、添加桌面快捷方式 10、安装中，大概2~10分钟，耐心等待… 11、安装完成，点击关闭 12、最后将补丁包覆盖到软件安装lmgrimpl目录即可。 默认：C:\Program Files\MATLAB\R2023b\bin\win64\matlab_startup_plugins\lmgrimpl
我的软件安装在D盘：D:\Program Files\MATLAB\R2023b\bin\win64\matlab_startup_plugins\lmgrimpl
13、启动桌面图标 14、启动成功 
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/52e4e11ca2d61d07bb4a05695daa0cdd/" rel="bookmark">
			Pytorch深度解析：Transformer嵌入层源码逐行解读
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		前言 本部分博客需要先阅读博客：
《Transformer实现以及Pytorch源码解读（一）-数据输入篇》
作为知识储备。
Embedding使用方式 如下面的代码中所示，embedding一般是先实例化nn.Embedding(vocab_size, embedding_dim)。实例化的过程中输入两个参数：vocab_size和embedding_dim。其中的vocab_size是指输入的数据集合中总共涉及多少个去重后的单词；embedding_dim是指，每个单词你希望用多少维度的向量表示。随后，实例化的embedding在forward中被调用self.embeddings(inputs)。
class Transformer(nn.Module): def __init__(self, vocab_size, embedding_dim, hidden_dim, num_class, dim_feedforward=512, num_head=2, num_layers=2, dropout=0.1, max_len=512, activation: str = "relu"): super(Transformer, self).__init__() # 词嵌入层 self.embedding_dim = embedding_dim self.embeddings = nn.Embedding(vocab_size, embedding_dim) self.position_embedding = PositionalEncoding(embedding_dim, dropout, max_len) # 编码层：使用Transformer encoder_layer = nn.TransformerEncoderLayer(hidden_dim, num_head, dim_feedforward, dropout, activation) self.transformer = nn.TransformerEncoder(encoder_layer, num_layers) # 输出层 self.output = nn.Linear(hidden_dim, num_class) def forward(self, inputs, lengths): inputs = torch.transpose(inputs, 0, 1) hidden_states = self.
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/52e4e11ca2d61d07bb4a05695daa0cdd/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/2b40b2664a5c3870a9f26471750638e6/" rel="bookmark">
			详解各种LLM系列｜（5）LLaMA 3模型解析（Meta重磅发布！）
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		一、引言 Blog链接：https://ai.meta.com/blog/meta-llama-3/
MODEL CARD: https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md
体验链接：https://meta.ai/ or https://huggingface.co/chat/
4月18日，Meta突然发布Llama 3， 在Llama 2的基础上进行了进一步的升级，包括使用更高质量的数据集、模型架构的改进、引入新的信任和安全工具（如Llama Guard 2、Code Shield和CyberSec Eval 2）等；
这次Llama 3 的发布包括了8B 和 70B 两种规模的预训练和指令微调生成文本模型。
Llama 3型号将很快在AWS、Databricks、Google Cloud、huggingFace、Kaggle、IBM WatsonX、微软Azure、NVIDIA NIM和Snowflake上推出，并得到AMD、AWS、戴尔、英特尔、NVIDIA和高通提供的硬件平台的支持
二、卓越的性能 2.1 标准测试 这次的 Llama 在性能上展现了大幅度提升，包括最直接的 8k 上下文（之前是4k），以及可以更好地完成输出任务。
通过pre-training和post-training的改进，Llama 3的预训练和指令微调模型是目前在8B和70B参数尺度上存在的最好的模型（截止至发布日期）。
Post-training的改进大大降低了错误拒绝率，改善了一致性，增加了模型响应的多样性；Llama 3在推理、代码生成和指令跟踪等功能上有极大的提升，具体看一下对比数据：
(Llama 3 Pretrained模型)
(Llama 3 Instruct模型) （这里再附一张 Llama 2 和 3 的对比）
2.2 人类偏好测试 在Llama 3的开发过程中，为了优化实际场景的性能，Meta开发了一个新的高质量的人类评价集。这个评估集包含1800个提示，涵盖了12个关键用例：征求建议、头脑风暴、分类、封闭式问题回答、编码、创造性写作、提取、作为一个角色/角色中、开放式问题回答、推理、重写和总结。
下面的图表显示了模型对这些类别的人类评估的汇总结果：
根据人类评估者的偏好排名，Llama 的 70B 参数模型在实际应用场景中的表现，尤其是在指令跟随方面，相较于其他相当规模的模型表现出了显著的优势。
三、优化之处 3.1 模型架构 3.1.1 Tokenzier 分词器：与Llama 2不同的是，Llama 3将tokenizer由sentencepiece换成tiktoken，词汇量从 的32K增加到 128K，增加了 4 倍 （更大的词汇库能够更高效地编码文本，增加编码效率，可以实现更好的下游性能。不过这也会导致嵌入层的输入和输出矩阵尺寸增大，模型参数量也会增大）。
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/2b40b2664a5c3870a9f26471750638e6/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/0075ebed4ce4c016c8370afbc2156b4f/" rel="bookmark">
			java本地缓存(map,Guava,echcache,caffeine)优缺点，以及适用场景
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		前言 在高并发系统环境下，jvm本地缓存扮演着至关重要的角色，合理的应用能够使系统响应迅速，提高用户体验感，而分布式缓存redis则存在着网络io，以及流量消耗问题，需要和本地缓存搭配使用，才能使系统请求更快，下面我们分别介绍一下四种本地缓存
ConcurrentHashMap (Java 标准库) 介绍
ConcurrentHashMap 是 Java 标准库中的线程安全的哈希表实现，它支持并发访问和修改。通过锁分段机制（segment locking）实现高并发访问，允许多个线程并发地读取和写入。
优点
线程安全：内部实现了细粒度的锁，允许高并发访问。
简单易用：Java 标准库类，无需额外依赖。
性能优越：适用于高并发场景，读写性能较好。
缺点
缺少高级功能：没有内置的过期策略、最大容量控制、缓存统计等高级功能。
没有持久化：数据仅存在于内存中，程序结束后数据丢失。
适用场景
简单的缓存需求，例如会话缓存、短期数据缓存等。
高并发环境下的基本缓存使用
Guava Cache 介绍
Guava 是 Google 提供的一个开源 Java 库，其中的 Cache 类提供了一个轻量级的本地缓存实现，支持各种缓存策略。
优点
简单易用：API 设计简洁明了，易于使用。
灵活配置：支持多种缓存策略，如基于时间、基于大小的过期和自动刷新。
高效：适用于中等规模的缓存需求，性能良好。
缺点
功能有限：不支持持久化和分布式缓存，仅限于本地内存缓存。
依赖库：需要引入 Guava 库。
适用场景
中等规模的应用程序，适合需要灵活过期策略的缓存需求。
缓存配置较简单，不需要持久化存储
Ehcache 介绍
Ehcache 是一个广泛使用的开源 Java 缓存库，功能丰富，支持多种缓存策略，并且可以持久化到磁盘，还提供高可用性和分布式缓存支持。
优点
功能丰富：支持多种缓存策略、持久化到磁盘、分布式缓存等高级功能。
高度可配置：提供丰富的配置选项，能精细调整缓存行为。
持久化支持：数据可以持久化到磁盘，适合长期数据缓存需求。
与 Spring 和 Hibernate 集成良好：提供与这些框架的无缝集成。
缺点
配置复杂：配置选项繁多，初学者需要一定的学习成本。
性能开销：功能丰富带来的性能开销，不适合极高性能要求的场景。
适用场景
企业级应用，需要高级功能如持久化、分布式缓存、复杂缓存策略的场景。
与 Spring 和 Hibernate 集成的项目，缓存数据库查询结果、会话数据等
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/0075ebed4ce4c016c8370afbc2156b4f/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/7462d5ba202971a0a3c5d1377ba518f7/" rel="bookmark">
			华为 huawei 交换机配置 Dot1q 终结子接口接入 L3VPN 示例
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		组网需求 如 图 7-13 ， CE1 、 CE3 属于 VPN-A ， CE2 、 CE4 属于 VPN-B ； VPN-A 使用的 VPN-target 属性为 111:1 ， VPN-B 使用的 VPN-target 属性为 222:2 。不同 VPN 用户之间不能互相访 问。 图 7-13 配置 Dot1q 终结子接口接入 L3VPN 组网图 配置思路 采用如下的思路配置 Dot1q 子接口接入 L3VPN ： 1. 骨干网中，与 CE 相连的 PE 上需配置 VPN 实例，并把与 CE 相连的接口和相应的 VPN 实例绑定；绑定之后配置与 CE 相连的接口的 IP 地址。 2. PE 与 PE 之间配置 OSPF 实现 PE 之间的互通。 3.
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/7462d5ba202971a0a3c5d1377ba518f7/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/2fd06f00bb3a5b1774a728ca144a389a/" rel="bookmark">
			Django从入门到精通：First [Django版本.Python面向对象.Web基础.创建Django项目]
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		文章目录 Django初学者指南1 Django简介1.1 Django的历史1.2 使用Django的知名网站1.4 Django的主要特点1.5 Django的工作原理 2 Django 版本选择2.1 Django 支持的 Python 版本2.2 Django 版本 3 Django 开发 Web 程序3.1 Python知识点3.1.1 Python 函数3.1.2 Python 面向对象 3.2 Web 基础知识3.3 安装Django3.4 创建Django项目3.4.1 用命令行创建Django项目3.4.2 用PyCharm创建Django项目 4 Django 部分常用参数、插件4.1 path() 视图函数4.2 models.py模型参数4.3 模板插件、技术4.3.1 Bootstrap4.3.2 jQuery4.3.2 AJAX 小结 Django初学者指南 欢迎进入Django的世界！如果你对开发数据库驱动的网站感兴趣，Django是一个非常有用的框架。在这篇博文中，我们将介绍Django的基础知识，包括它的历史、特点、如何开始学习，以及一些使用Django的知名网站。
1 Django简介 Django 是一个用于构建 Web 应用程序的高级 Python Web 框架。
Django 提供了一套强大的工具和约定，处理了Web开发中的许多繁琐事务，使得开发者可以专注于编写网站独特的业务逻辑部分，快速构建功能齐全且易于维护的网站。
Django 遵守 BSD 版权，初次发布于 2005 年 7 月, 并于 2008 年 9 月发布了第一个正式版本 1.
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/2fd06f00bb3a5b1774a728ca144a389a/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/7956d9846fbb86e6d20bba10aab5589b/" rel="bookmark">
			爬虫初学篇——看完这些还怕自己入门不了？
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		初次学习爬虫，知识笔记小分享
学scrapy框架可看：孤寒者博主的【Python爬虫必备—＞Scrapy框架快速入门篇——上】
目录🌟 一、🍉基础知识二、🍉http协议：三、🍉解析网页(1) xpath的用法：(2) bs4解析器的解释：(3) python字符编码的错误：(4) 正则表达式：(5) 拓展知识 四、🍉Requests库(1) Requests(2) Response对象的属性(3) 理解Requests库的异常：(4) 请求数据 (** kwargs参数) 五、🍉网络爬虫的“盗亦有道”(1) 网络爬虫的尺寸(2) 网络爬虫引发的问题(3) 网络爬虫的限制(4) Robots协议(5) 对Robots协议的理解 六、🍉实战案例(1) 京东商品页面的爬取(2) 亚马逊商品页面的爬取(3) 百度360搜索关键词提交(4) 网络图片的爬取和存储(5) ip地址归属地的自动获取 七、🍉Beautiful Soup库入门(1) 标签基本元素(2) 标签树下的下行遍历(3) 标签树的上行遍历(4) 标签树的平衡遍历 八、🍉信息组织与提取方法(1) 信息标记的三种形式(2) 信息提取的一般方法(3) find_all()方法 九、🍉实例：中国大学排名爬虫(1) 程序的结构设计(2) 中文对齐的问题的原因 十、🍉正则表达式(1) 正则表达式的概述(2) 正则表达式的语法和使用(3) 正则表达式的常用操作符(4) re库主要功能函数 十一、🍉实例：淘宝商品信息定向爬虫(1) 功能描述(2) 程序的结构设计 十二、🍉实例：股票数据定向爬虫(1) 功能描述：(2) 程序的结构设计 十三、🍉网络爬虫框架(1) Scrapy爬虫框架结构1. 爬虫框架2. 5+2结构3. requests库和scrapy库的比较4. Scrapy 命令行：大部分操作都是通过命令行来实现 (2) Scrapy爬虫基本使用1. 步骤1：建立一个Scrapy爬虫工程2. 步骤2：在工程中产生一个Scrapy爬虫3. 步骤3：配置产生的spider 爬虫4. 步骤4：运行爬虫，获取网页5. `yield` 关键字【生成器】6. Scrapy爬虫的数据类型 (3) 实例：股票数据Scrapy实例1.
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/7956d9846fbb86e6d20bba10aab5589b/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/1468b88cdb75a8bfc77b16aae65b0d40/" rel="bookmark">
			【python】pandas常见文件读取方法
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		pandas是一个强大的Python数据分析库，它提供了多种读取文件的方法，支持多种文件格式。以下是pandas中常见的一些文件读取方法及其详细说明、常用参数、代码示例和数据示例。
1. read_csv() （1）用途： 读取 CSV（Comma Separated Values）文件。
（2）常用参数： filepath_or_buffer：文件路径或类似文件的对象。sep 或 delimiter：字段分隔符，默认为逗号,。header：用作列名的行号，默认为0（即第一行）。index_col：用作行索引的列编号或列名。dtype：每列的数据类型。nrows：需要读取的行数。 （3）代码示例： import pandas as pd # 读取 CSV 文件 df = pd.read_csv('data.csv') # 显示数据的前几行 print(df.head()) （4）数据示例 (data.csv): Name,Age,City Alice,25,New York Bob,30,San Francisco Charlie,35,Los Angeles （5）header参数基本用法 在Pandas库中，read_csv函数的header参数用于指定用作列名的行号或处理表头的方式。关于header参数的详细解释：
默认行为：当不指定header参数时，其默认值为0，表示将CSV文件中的第一行（索引为0的行）作为列名（表头）。
指定行号：如果CSV文件中的列名不在第一行，而是位于其他行，可以通过设置header参数为相应的行号（从0开始计数）来指定。例如，header=1表示将第二行作为列名。
多行表头：在某些情况下，CSV文件可能使用多行来定义列名。此时，可以将header参数设置为一个列表，例如header=[0,1]，表示将第一行和第二行的内容合并作为列名。但请注意，这种方式在Pandas中并不常用，因为它可能会导致列名变得复杂且难以理解。
无表头：如果CSV文件没有包含列名，可以将header参数设置为None。在这种情况下，Pandas将自动生成默认的列名，如0, 1, 2,…。
示例1：无表头，自定义列名 假设CSV文件内容如下（没有列名）：
Alice,25,New York Bob,30,Los Angeles 我们可以设置header=None并自定义列名：
df = pd.read_csv('example_without_header.csv', header=None, names=['Name', 'Age', 'City']) print(df.head()) 输出：
Name Age City 0 Alice 25 New York 1 Bob 30 Los Angeles 示例2：无表头，不自定义列名 使用 header=None 但是不自定义列名：
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/1468b88cdb75a8bfc77b16aae65b0d40/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/1a4cba24362a54498cc4e3d07a99ca14/" rel="bookmark">
			详解 HBase 的架构和基本原理
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		一、基本架构 StoreFile：保存实际数据的物理文件，StoreFile 以 HFile 的格式 (KV) 存储在 HDFS 上。每个 Store 会有一个或多个 StoreFile（HFile），数据在每个 StoreFile 中都是有序的MemStore：写缓存，由于 HFile 中的数据要求是有序的，所以数据是先存储在 MemStore 中，排好序后，等到达刷写时机才会刷写到 HFile，每次刷写都会形成一个新的 HFileWAL：由于数据要经 MemStore 排序后才能刷写到 HFile，但把数据保存在内存中会有很高的概率导致数据丢失，为了解决这个问题，数据会先写在一个叫做 Write-Ahead logfile 的文件中，然后再写入 MemStore 中。所以在系统出现故障的时候，数据可以通过这个日志文件重建 二、写流程原理 HBase 的读操作比写操作慢，且读写流程没有 master 参与
老版本：Zookeeper 中存储的是 -root- 表的位置信息，-root- 表存储的 meta 表的位置信息(防止 meta 表进行切分)Client 先访问 Zookeeper，获取 hbase:meta 表位于哪个 Region Server访问对应的 Region Server，获取 hbase:meta 表数据，根据写请求的 namespace:table/rowkey 信息查询出目标数据位于哪个 Region Server 中的哪个 Region 中，并将该 table 的 region 信息以及 meta 表的位置信息缓存在客户端的 meta cache，方便下次快速访问与目标表所在的 Region Server 进行通讯将写请求命令顺序写入（追加）到内存的 WAL，此时 wal 没有同步到 HDFS将数据写入对应的 MemStore，数据会在 MemStore 进行排序同步 wal 到 HDFS，若失败则回滚清空 MemStore 写入的数据向客户端发送 ack，此时的写请求已经完成等达到 MemStore 的刷写时机后，将数据刷写到 HFile 三、MemStore Flush MemStore Flush：刷写，将 Region 中存储在内存中的数据刷写到 HDFS 的磁盘中Flush 时机： RegionServer 级别： 当 RegionServer 中 memstore 的总大小达到 javaHeapSize × hbase.
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/1a4cba24362a54498cc4e3d07a99ca14/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/fd1c90e6f6b9b72c2e3ed06e550814c9/" rel="bookmark">
			Linux下Apache与Nginx服务器配置与优化
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		在Linux环境下，Apache和Nginx是两种广泛使用的Web服务器软件，它们各有优势，并且在配置与优化方面有一些共通之处以及各自的独特考量点。以下是一些基础的配置与优化建议：Apache配置与优化基础配置1. 安装Apache：在大多数Linux发行版中，可以通过包管理器安装Apache，如Debian/Ubuntu系统使用
apt-get install apache2 󠁪
，CentOS/RHEL使用
yum install httpd 󠁪
。2. 配置文件：Apache的主要配置文件通常位于
/etc/apache2/apache2.conf 󠁪
（Debian/Ubuntu）或
/etc/httpd/conf/httpd.conf 󠁪
（CentOS/RHEL）。可以在此处设置监听端口、服务器根目录、日志文件位置等。优化建议1. 启用模块化：只加载必要的模块，减少内存占用。2. 调整KeepAlive设置：适当设置
KeepAliveTimeout 󠁪
和
MaxKeepAliveRequests 󠁪
以平衡连接效率与资源消耗。3. 使用mod_deflate：压缩响应内容，减小传输数据量。4. 开启HTTP/2：对于现代浏览器，启用HTTP/2可以提高页面加载速度。5. 调整Worker进程数：根据服务器硬件和网站流量，合理设置
ServerLimit 󠁪
和
MaxRequestWorkers 󠁪
参数。Nginx配置与优化基础配置1. 安装Nginx：同样通过包管理器安装，如
apt-get install nginx 󠁪
（Debian/Ubuntu），
yum install nginx 󠁪
（CentOS/RHEL）。2. 配置文件：Nginx的主要配置文件位于
/etc/nginx/nginx.conf 󠁪
，网站的具体配置则通常在
/etc/nginx/sites-available/ 󠁪
目录下。优化建议1. 利用反向代理：Nginx常作为前端负载均衡器，可以有效分发请求到后端Apache或其他应用服务器。2. 静态文件处理：Nginx擅长处理静态文件，应配置直接由Nginx提供服务，减轻后端服务器压力。3. Gzip压缩：同Apache，开启Gzip压缩减少传输体积。4. 调整worker_processes：根据服务器CPU核心数设定，一般等于CPU核心数。5. 优化缓冲区：调整
client_body_buffer_size 󠁪
、
proxy_buffer_size 󠁪
等参数，以提高处理大请求的能力并防止缓冲溢出。6. 启用SSL/TLS并优化：使用HTTPS并配置SSL优化，如使用更安全的协议版本和合适的密钥交换算法。共同优化策略• 访问日志优化：合理设置日志级别和滚动策略，避免日志文件过大影响磁盘空间和I/O性能。• 安全加固：定期更新软件版本，限制不必要的访问权限，使用防火墙规则保护服务器。• 监控与日志分析：使用如Nagios、Prometheus等工具监控服务器状态，分析日志发现并解决性能瓶颈。综上所述，Apache和Nginx的配置与优化需要根据实际应用场景、流量大小、硬件配置等因素综合考虑，持续监控和调整以达到最佳性能。
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/76d3e61a28fe165a7b895bee38c4c635/" rel="bookmark">
			机械臂抓取物体整体的开发流程
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		开发一个机械臂抓取物体的系统涉及多个步骤和不同领域的知识，包括机械设计、控制系统、传感器集成、软件开发等。以下是一个全面的开发流程概述：
1. 需求分析与系统设计 需求分析： 明确机械臂需要抓取的物体类型（大小、重量、材质等）。确定工作环境（工业生产线、实验室、户外等）。定义系统的性能指标（精度、速度、负载能力等）。 其中的环境考虑尤为重要
系统设计： 确定机械臂的自由度（DoF，Degrees of Freedom）。选择合适的机械结构（关节类型、传动方式等）。确定控制架构（中央控制、分布式控制）。 2. 机械设计与制造 机械设计： 使用CAD软件（如SolidWorks、AutoCAD）设计机械臂的各个部件。
进行运动学和动力学分析，确保机械臂能完成预期的运动。（一般厂商可以提供）
制造与装配： 制造或采购各个机械部件。
组装机械臂，进行初步的机械调试。
3. 控制系统开发 硬件选型： 选择合适的控制器（如PLC、嵌入式控制器、工控机等）。
选择合适的电机和驱动器（步进电机、伺服电机等）。
传感器集成： 选择并集成各种传感器（位置传感器、力传感器、视觉传感器等）。确保传感器的数据能够准确地反馈给控制系统。 控制算法设计： 设计机械臂的运动控制算法（如PID控制、模型预测控制等）。开发路径规划算法（如A*算法、Dijkstra算法等）。 4. 软件开发与集成 软件架构设计：
设计系统的软件架构，包括各模块的接口和通信方式。
运动控制软件开发：
开发机械臂的底层驱动程序，确保电机和传感器的正常工作。
开发运动控制算法，实现机械臂的精确控制。
人机界面（HMI）开发：
开发用户操作界面，使操作人员能够方便地控制和监视机械臂的工作状态。
这是一张人机界面（HMI）开发示例图，展示了用于机械臂控制系统的界面。界面包含以下元素：
机械臂的3D模型，显示其当前位置。控制按钮，用于移动机械臂。实时数据展示，显示传感器读数（如位置、速度和力）。错误日志面板，用于记录和显示错误信息。编程路径的图形表示。 5. 系统调试与优化 初步调试：
在实验室环境下对机械臂进行初步调试，确保基本功能正常。
调整机械和控制参数，优化系统性能。
现场调试：
将机械臂安装到实际工作环境中，进行现场调试。
根据现场情况进行进一步优化和调整。
6. 验收与维护 系统验收：
根据需求分析阶段定义的指标对系统进行验收测试。
确保系统满足所有功能和性能要求。
维护与升级：
制定系统的维护计划，定期进行检查和保养。
根据需求进行系统升级和功能扩展。
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/1490cf9e2af1e59594f12ac9f0eee1ed/" rel="bookmark">
			让你的网页动起来 - 轻松实现 JavaScript 拖拽功能
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		效果展示 实现 要实现该效果需要运用 HTML5 的 dragstart 拖放操作事件
通过去开启dragstart监听拖放操作事件就能实现图片的拖动
&lt;div class="empty"&gt; &lt;div class="fill" draggable="true"&gt;&lt;/div&gt; &lt;/div&gt; 本例子中我们对fill盒子开启了draggable事件，fill盒子是用来存照片的
但是这样并不能形成一个反馈，只有单纯的拖动效果，效果如下图所示
如果想要实现在拖动了图片后有一个反馈效果，我们就需要使用JavaScript去监听draggable的开始拖动和结束拖动事件
.hold { border: 5px solid #00ff00; } const fill = document.querySelector(".fill"); // 拖拽开始事件 fill.addEventListener("dragstart", DragStart); function DragStart(e) { this.classList.add("hold"); } // 拖拽结束事件 fill.addEventListener("dragend", DragEnd); function DragEnd(e) { this.classList.remove("hold"); } 通过在拖动时给他添加边框，结束时取消以实现一个反馈的效果
最后去监听empty盒子的即可根据不同事件触发时，实现不同的效果
const empty = document.querySelectorAll(".empty"); empty.forEach((item) =&gt; { // 经过事件 item.addEventListener("dragover", DragOver); // 进入事件 item.addEventListener("dragenter", DragEnter); // 离开事件 item.addEventListener("dragleave", DragLeave); // 拖拽结束事件 item.
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/1490cf9e2af1e59594f12ac9f0eee1ed/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/831203d38bb83ae5269ee6755f50f8c6/" rel="bookmark">
			AI部署以及工业落地学习之路（文章较长，建议收藏）
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		计算机视觉研究院专栏
作者：Edison_G
最近在复盘今年上半年做的一些事情，不管是训练模型、部署模型搭建服务，还是写一些组件代码，零零散散是有一些产出。 本文主要转自知乎《链接：https://zhuanlan.zhihu.com/p/386488468》
公众号ID｜ComputerVisionGzq
学习群｜扫码在主页获取加入方式
深感还有很多很多需要学习的地方。既然要学习，那么学习路线就显得比较重要了。
本文重点谈谈学习AI部署的一些基础和需要提升的地方。这也是老潘之前学习、或者未来需要学习的一些点，这里抛砖引玉下，也希望大家能够提出一点意见。
1
AI部署
AI部署这个词儿大家肯定不陌生，可能有些小伙伴还不是很清楚这个是干嘛的，但总归是耳熟能详了。
2
主题：聊聊AI部署
作为AI算法部署工程师，你要做的就是将训练好的模型部署到线上，根据任务需求，速度提升2-10倍不等，还需要保证模型的稳定性。
是不是很有挑战性？
3
需要什么技术？
需要一些算法知识以及扎实的工程能力。
老潘认为算法部署落地这个方向是比较踏实务实的方向，相比设计模型提出新算法，对于咱们这种并不天赋异禀来说，只要肯付出，收获是肯定有的(不像设计模型，那些巧妙的结果设计不出来就是设计不出来你气不气)。
其实算法部署也算是开发了，不仅需要和训练好的模型打交道，有时候也会干一些粗活累活(也就是dirty work)，自己用C++、cuda写算子(预处理、op、后处理等等)去实现一些独特的算子。也需要经常调bug、联合编译、动态静态库混搭等等。
算法部署最常用的语言是啥，当然是C++了。如果想搞深度学习AI部署这块，C++是逃离不了的。
所以，学好C++很重要，起码能看懂各种关于部署精巧设计的框架(再列一遍：Caffe、libtorch、ncnn、mnn、tvm、OpenVino、TensorRT，不完全统计，我就列过我用过的)。当然并行计算编程语言也可以学一个，针对不同的平台而不同，可以先学学CUDA，资料更多一些，熟悉熟悉并行计算的原理，对以后学习其他并行语言都有帮助。
系统的知识嘛，还在整理，还是建议实际中用到啥再看啥，或者有项目在push你，这样学习的更快一些。
可以选择上手的项目：
好用的开源推理框架：Caffe、NCNN、MNN、TVM、OpenVino
好用的半开源推理框架：TensorRT
好用的开源服务器框架：triton-inference-server
基础知识：计算机原理、编译原理等
需要的深度学习基础知识 AI部署当然也需要深度学习的基础知识，也需要知道怎么训练模型，怎么优化模型，模型是怎么设计的等等。不然你怎会理解这个模型的具体op细节以及运行细节，有些模型结构比较复杂，也需要对原始模型进行debug。
常用的框架 这里介绍一些部署常用到的框架，毕竟对于某些任务来说，自己造轮子不如用别人造好的轮子。并且大部分大厂的轮子都有很多我们可以学习的地方，因为开源我们也可以和其他开发者一同讨论相关问题；同样，虽然开源，但用于生产环境也几乎没有问题，我们也可以根据自身需求进行魔改。
这里介绍一些值得学习的推理框架，不瞒你说，这些推理框架已经被很多公司使用于生成环境了。
CaffeLibtorch (torchscript) libtorch是Pytorch的C++版，有着前端API和与Pytorch一样的自动求导功能，可以用于训练或者推理。Pytorch训练出来的模型经过torch.jit.trace或者torch.jit.scrpit可以导出为.pt格式，随后可以通过libtorch中的API加载然后运行，因为libtorch是纯C++实现的，因此libtorch可以集成在各种生产环境中，也就实现了部署
TensorRTOpenVINO 在英特尔CPU端(也就是我们常用的x86处理器)部署首选它！开源且速度很快，文档也很丰富，更新很频繁，代码风格也不错，很值得学习。
NCNN/MNN/TNN/TVM 有移动端部署需求的，即模型需要运行在手机或者嵌入式设备上的需求可以考虑这些框架。
PaddlePaddle PaddlePaddle作为国内唯一一个用户最多的深度学习框架。很多任务都有与训练模型可以使用，不论是GPU端还是移动端，大部分的模型都很优秀很好用。如果想快速上手深度学习，飞浆是不错的选择，官方提供的示例代码都很详细，一步一步教你教到你会为止。
海康开放平台
4
AI部署中提速的方法
我的看法是，部署不光是从研究环境到生产环境的转换，更多的是模型速度的提升和稳定性的提升。稳定性这个可能要与服务器框架有关了，网络传输、负载均衡等等。不过速度的话，从模型训练出来，到部署推理这一步，有什么优化空间呢？
上到模型层面，下到底层硬件层面，其实能做的有很多。如果我们将各种方法都用一遍(大力出奇迹)，最终模型提升10倍多真的不是梦！
有哪些能做的呢？
模型结构
剪枝
蒸馏
稀疏化训练
量化训练
算子融合、计算图优化、底层优化
主要说说最后两个模块。
量化训练 这里指的量化训练是在INT8精度的基础上对模型进行量化。简称QAT(Quantization Aware Training)。
量化后的模型在特定CPU或者GPU上相比FP32、FP16有更高的速度和吞吐，也是部署提速方法之一。
PS：FP16量化一般都是直接转换模型权重从FP32-&gt;FP16，不需要校准或者finetune。 量化训练是在模型训练中量化的，与PTQ(训练后量化)不同，这种量化方式对模型的精度影响不大，量化后的模型速度基本与量化前的相同(另一种量化方式PTQ，TensorRT或者NCNN中使用交叉熵进行校准量化的方式，在一些结构中会对模型的精度造成比较大的影响)。
举个例子，我个人CenterNet训练的一个网络，使用ResNet-34作为backbone，利用TensorRT进行转换后，使用1024x1024作为测试图像大小的指标：
精度/指标FP32INT8(PTQ)INT8(QAT) 精度不降反升(可以由于之前FP32的模型训练不够彻底，finetune后精度又提了一些)，还是值得一试的。
目前我们常用的Pytorch当然也是支持QAT量化的。
不过Pytorch量化训练出来的模型，官方目前只支持CPU。即X86和Arm，具有INT8指令集的CPU可以使用：
x86 CPUs with AVX2 support or higher (without AVX2 some operations have inefficient implementations)
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/831203d38bb83ae5269ee6755f50f8c6/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/51dcc8c675ec198f2fcca0f18d02df2b/" rel="bookmark">
			DC/AC电源模块：提升光伏发电系统的能源利用率
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		BOSHIDA DC/AC电源模块：提升光伏发电系统的能源利用率
随着环境保护意识的提高和能源需求的增加，光伏发电系统作为一种清洁能源的代表，受到了越来越多的关注。然而，光伏发电系统在实际应用中还存在一些问题，如发电效率低、能源利用率不高等。为了解决这些问题，DC/AC电源模块应运而生。
DC/AC电源模块可以用于将太阳能电池板产生的直流电转换成交流电，以满足家庭、工业和商业等场景的用电需求。通过将直流电转换成交流电，可以有效提高光伏发电系统的能源利用率。
一，DC/AC电源模块具有高效的能源转换效率。传统的光伏发电系统由于采用的是直流电，而大部分电器设备需要交流电才能正常工作，因此需要将直流电转换成交流电。而传统的转换方式如逆变器等的转换效率较低，导致能源浪费。而DC/AC电源模块采用先进的转换技术，可以大幅提高能源转换效率，减少能源损耗，从而提升光伏发电系统的能源利用率。
二，DC/AC电源模块具有较高的输出质量。光伏发电系统在发电过程中，由于太阳辐射的不稳定性和环境温度的变化等原因，产生的直流电质量可能存在一定的波动。而DC/AC电源模块可以对直流电进行稳定的转换，输出质量稳定，不受外界因素的影响，从而提供高质量的交流电，为电器设备的正常运行提供保障。
三，DC/AC电源模块还具有智能控制功能。通过智能控制系统，可以实现对光伏发电系统的监测和控制，对发电功率、电压等进行实时调节和优化，从而进一步提高能源利用率。智能控制功能还可以实现对电能的分配和管理，根据电器设备的需求进行智能调度，最大程度地利用光伏发电系统的能源。
总结，DC/AC电源模块作为提升光伏发电系统能源利用率的关键技术之一，具有高效能源转换、高质量输出和智能控制等优势。它可以有效解决光伏发电系统存在的问题，提高能源利用效率，为清洁能源的可持续发展做出贡献。随着技术的不断进步和应用的推广，相信DC/AC电源模块将在光伏发电系统中发挥越来越重要的作用。
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/6da5b2843b053d8c5c7c13413d7dec20/" rel="bookmark">
			深度分析：React Native、Flutter、UniApp、Taro、Vue的差异
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		深度分析：React Native、Flutter、UniApp、Taro、Vue React Native 优势: 跨平台代码共享：使用JavaScript和React，可以为iOS和Android开发应用，代码复用率高。活跃社区和生态系统：React和React Native有庞大的社区，提供了大量的第三方库和插件。热重载：开发效率高，修改代码后几乎即时可见效果。 缺点: 性能瓶颈：在处理复杂动画或高性能需求时，性能可能不如原生应用。原生模块开发：虽然可以调用原生模块，但开发和维护这些模块可能增加复杂度。 适合场景: 需要快速迭代和发布的产品。已有React或JavaScript经验的团队。 不适合场景: 对性能有极高要求的游戏或图形密集型应用。 Flutter 优势: 高性能：使用Dart语言，自有的渲染引擎，性能接近原生。统一的UI：提供丰富的Material和Cupertino组件，易于实现一致的UI设计。热重载：快速迭代，提升开发效率。 缺点: Dart语言：学习新语言对团队可能是个挑战。社区相对小：尽管在增长，但与React的生态系统相比仍较小。 适合场景: 高性能需求的应用。对UI一致性要求较高的项目。 不适合场景: 团队已熟练掌握其他跨平台技术，如React Native。 UniApp 优势: 多平台支持：不仅支持iOS和Android，还支持微信小程序、支付宝小程序等多种平台。基于Vue.js：对于Vue开发者友好，学习曲线平缓。 缺点: 性能：在某些平台上的性能可能不如原生应用。限制：某些功能可能受限于平台API。 适合场景: 需要在多个平台发布的小程序或轻量级应用。 不适合场景: 高性能或图形密集型应用。 Taro 优势: 多框架支持：支持React、Vue、Nerv等框架。多平台发布：支持小程序、H5、RN等平台。 缺点: 性能：在某些平台可能不如原生应用。生态：相比React Native和Flutter，生态较小。 适合场景: 多平台统一开发需求。 不适合场景: 需要高度定制化或高性能的项目。 Vue（纯Vue.js） 优势: 高效和灵活：强大的模板系统和组件化设计。学习曲线：相对于其他框架，学习成本较低。 缺点: 非原生应用：仅限于Web应用，需配合其他工具打包成原生应用。 适合场景: Web应用开发。 不适合场景: 需要高性能或访问原生API的移动应用。 总结 选择框架时，应根据项目需求、团队技能、性能要求和维护成本综合考虑。React Native和Flutter在跨平台开发中表现出色，适用于大多数移动应用场景。UniApp和Taro在多平台统一开发方面有独特优势，适合小程序和多平台发布需求。Vue.js作为Web开发的主力，可通过额外工具转化为原生应用。
	</div>
</article>
</main>

<div class="pagination">
	<a class="pagination__item pagination__item--prev btn" href="/posts/page/258/">«</a>
	<span class="pagination__item pagination__item--current">259/621</span>
	<a class="pagination__item pagination__item--next btn" href="/posts/page/260/">»</a>
</div>

			</div>
			

		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>