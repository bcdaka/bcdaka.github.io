<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Posts - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="Posts">
  <meta property="og:description" content="编程大咖的博客">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="website">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	
	<link rel="alternate" type="application/rss+xml" href="/posts/index.xml" title="编程大咖">

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main list" role="main">
	<header class="main__header">
		<h1 class="main__title">Posts</h1>
	</header><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/74391c35e6f52b77ca9acb37dc6f2ddb/" rel="bookmark">
			全民上手大模型--ollama&#43;langchain&#43;通义千问零费用java&#43;python跑通本机大模型
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		前言 写本篇文章是因为我经历过了各种付费+测试之后很艰难想入手大模型，国内的同学学技术还是太困难了，但是看到市面上各种火爆，实在有按捺不住想体验,终于迎来了一个契机。
在此之前，应该大家都了解OpenAPI，确实强大，但是国内用户来说，有以下问题：
一、网络不通，这里还不是简单的翻墙的问题，是他的网站都不对中国大陆开放，政治因素就不谈了
二、贵这玩意其实是按调用次数收费的，厉害点的功能其实都要收费，还是美元
三、其实中文方面还是没有那么强了
基于这些因素，导致大模型的事情总是少数人在玩，没意思，今天我们要把价格打到零！！
契机 开源大模型运行平台 Ollama，这是是一个开源的大语言模型平台，它允许用户在本地环境中运行、创建和共享大型语言模型。Ollama提供了丰富的功能和特性，使得用户可以在自己的计算机上轻松地部署和运行大型语言模型。注意啦，是自己的机器就可以哦！
上链接 https://ollama.com/
中文大模型 阿里巴巴的通义千问，开源国产的，听得懂中文
上链接 https://github.com/QwenLM
用户友好API接口 langchain其实是一套规范化的API，实现了标准化对模型的集成、接入、组件化等工作，通过langchain用户可以很轻松打造属于自己的大模型产品。langchain很早就出来了，大模型出来的时候，因为对使用大模型的定制做了封装，也是一下子火爆起来了。
上链接 https://github.com/langchain-ai/langchain
到此为止，其实万事俱备，我们就是要通过ollama+langchain+通义千问搞一把自己的大模型。
安装ollama 下载并安装 现在官网其实没有那么多乱七八糟的，直接一进去就是一个下载按钮，点就是了
点进去下载安装包，即可mac,linux,windows都行
我的是苹果系统，上面提到说要升级macOS 11,我的是10.15.7没影响，可以运行。下载之后就是安装了，没啥门槛。
下载模型 进入终端
ollama run + 模型名 模型在官网上直接罗列了一批，每个模型都要点硬盘，大家按照自己的需求下载，没有列出来的，可以在模型仓库里面找
https://ollama.com/library
我们这次是要下载通义千问，可以去仓库里面搜索到
ollama run qwen 这个命令其实是运行对应模型的意思。在运行之前，如果本机没有下载的话会去仓库上下载模型，需要等等。
使用模型-调戏大模型 下载之后会帮我们运行起来，是一个命令行模式的交互式接口,我们就可以开始调戏我们的大模型啦。大概就是下面这样，
B:~ zhuxuemin$ ollama run qwen &gt;&gt;&gt; 你是谁呀 我是通义千问，是由阿里云开发的语言模型。我被设计成能够回答各种问题、提供信息和进行对话。如果您有任何问题或需要帮助，请随时告诉我，我会尽力提供支持。 &gt;&gt;&gt; 给我做一首关于春天的诗，要求是7言律诗 春天的阳光明媚， 绿草如茵，鲜花盛开。 春风吹过田野， 稻谷摇曳生姿。 小鸟在树梢上欢快地歌唱， 春风轻轻地吹拂着它们的羽毛 不满意，再来一下
&gt;&gt;&gt; 给我做一首关于春天的诗，要求是7言律诗 春风拂面轻， 绿草如茵春意浓。 桃花笑映朝霞红， 小鸟欢歌春色正。 春风吹过田野广， 稻谷摇曳生姿显。 春天是希望的季节， 让我们一起感受春的气息，感受生活的美好。 使用langchain跑起来 langchain是python的库，我们其实是希望按照我们的程序跑起来啦，这样子我们才可以放到微信里面，钉钉里面，或者嵌入到网站上面，变成美女客服啦。
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/74391c35e6f52b77ca9acb37dc6f2ddb/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/4a625635c378c2889f9cd4808f90780b/" rel="bookmark">
			Node.js -- 包管理工具
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		文章目录 1. 概念介绍2. npm2.1 npm 下载2.2 npm 初始化包2.3 npm 包(1) npm 搜索包(2) npm 下载安装包(3) require 导入npm 包的基本流程 2.4 开发依赖和生产依赖2.5 npm 全局安装(1) 修改windows 执行策略(2) 环境变量Path 2.6 安装包依赖2.7 安装指定版本的包2.8 删除依赖2.9 配置命令别名 3. cnpm3.1 cnpm 介绍与安装3.2 操作命令 4. npm 配置淘宝镜像4.1 直接配置4.2 ==工具配置== 5. yarn5.1 介绍5.2 特点5.3 yarn 常用命令5.4 yarn 配置淘宝镜像5.5 npm 和yarn 选择 6. npm 发布一个包7. 扩展内容8. nvm 介绍和使用 1. 概念介绍 包是什么？
『包』英文单词是package,代表了一组特定功能的源码集合
包管理工具
管理『包』的应用软件，可以对「包」进行下载安装，更新，删除，上传等操作
借助包管理工具，可以快速开发项目，提升开发效率
包管理工具是一个通用的概念，很多编程语言都有包管理工具，所以掌握好包管理工具非常重要
常用的包管理工具
npmyarncnpm 2. npm 2.1 npm 下载 npm全称Node Package Manager,翻译为中文意思是『Node的包管理工具』
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/4a625635c378c2889f9cd4808f90780b/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/8c4a820ef9e7b2fa10bdff30a09f4946/" rel="bookmark">
			springboot3使用自定义注解&#43;AOP&#43;redis优雅实现防重复提交
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		⛰️个人主页: 蒾酒
🔥系列专栏：《spring boot实战》
目录
写在前面
实现思路
实现步骤
1.定义防重复提交注解
2.编写一个切面去发现该注解然后执行防重复提交逻辑
3.测试
依赖条件
1.接口上标记防重复提交注解
2.接口测试
写在最后
写在前面 本文介绍了springboot开发后端服务中，防重复提交功能的设计与实现，坚持看完相信对你有帮助。
同时欢迎订阅springboot系列专栏，持续分享spring boot的使用经验。
实现思路 通过定义一个防重复提交的自定义注解，再通过AOP的前置通知拦截带有该注解的方法，执行防重复提交逻辑，需要拼接一个唯一的key,如果redis中不存在则代表第一次请求，将这个key存入redis，设置注解类中指定的过期时间，遇到下次重复提交请求，直接抛出对应异常，全局异常处理返回对应信息即可。
需要注意
这个key的生成需要考虑有token和无token情况，同时满足唯一性。
有 token;可以用 token+请求参数，做为唯一值!无 token:可以用请求路径+请求参数，做为唯一值! 实现步骤 1.定义防重复提交注解 import java.lang.annotation.*; import java.util.concurrent.TimeUnit; /** * @author mijiupro */ @Inherited @Target({ElementType.METHOD}) @Retention(RetentionPolicy.RUNTIME) @Documented public @interface RepeatSubmit { /** * 锁定时间，默认5000毫秒 */ int interval() default 5000; /** * 锁定时间单位，默认毫秒 */ TimeUnit timeUnit() default TimeUnit.MILLISECONDS; /** * 提示信息 */ String message() default "
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/8c4a820ef9e7b2fa10bdff30a09f4946/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/08030a2c7f9c3459a5e6cab6bbc4983b/" rel="bookmark">
			spring boot3token拦截器链的设计与实现
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		⛰️个人主页: 蒾酒
🔥系列专栏：《spring boot实战》
目录
写在前面
流程分析
需要清楚的
实现步骤
1.定义拦截器
2.创建拦截器链配置类
3.配置拦截器链顺序
4.配置拦截排除项
最后
写在前面 本文介绍了spring boot后端服务开发中有关如何设计拦截器的思路，坚持看完相信对你有帮助。
同时欢迎订阅springboot系列专栏，持续分享spring boot的使用经验。
流程分析 用户在进行登陆后服务器会发放token等信息一起返回给前端，前端会进行保存，那么token里面是携带一些有关用户的身份等信息的，用户端在请求后端时需要在请求头携带token，请求先被拦截器截获，只有经过多重拦截器校验通过后才可以执行对应功能接口，否则会抛出异常返回对应错误信息。
需要清楚的 每次登录都要刷新token信息，不能在用户访问的过程中token过期，只要用户访问，token就要刷新有效期。如果token正确解析token中的用户id,根据用户id查询用户信息。 实现步骤 总的来说大致分为4步：
1定义拦截器---&gt;2创建拦截器链配置类---&gt;3配置拦截器链顺序---&gt;4配置拦截排除项
1.定义拦截器 首先，需要定义第一个拦截器类，该拦截器类需要实现 Spring 框架提供的 HandlerInterceptor 接口。该拦截器只做一件事就是刷新token。
import cn.hutool.json.JSONUtil; import com.mijiu.commom.util.JwtUtils; import com.mijiu.commom.util.UserHolder; import com.mijiu.entity.User; import io.jsonwebtoken.Claims; import jakarta.servlet.http.HttpServletRequest; import jakarta.servlet.http.HttpServletResponse; import lombok.extern.slf4j.Slf4j; import org.apache.commons.lang3.StringUtils; import org.springframework.data.redis.core.StringRedisTemplate; import org.springframework.lang.Nullable; import org.springframework.stereotype.Component; import org.springframework.web.servlet.HandlerInterceptor; import java.util.Objects; import java.util.concurrent.TimeUnit; /** * @author mijiupro */ @Slf4j @Component public class RefreshTokenInterceptor implements HandlerInterceptor { private final JwtUtils jwtUtils; private final StringRedisTemplate stringRedisTemplate; public RefreshTokenInterceptor(JwtUtils jwtUtils, StringRedisTemplate stringRedisTemplate) { this.
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/08030a2c7f9c3459a5e6cab6bbc4983b/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/c89a3c7931f88f84e4b2245dffa28212/" rel="bookmark">
			spring boot3解决跨域的几种方式
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		⛰️个人主页: 蒾酒
🔥系列专栏：《spring boot实战》
目录
1.前言
2.何为跨域
3.跨域问题出现特征
4.方式一：使用 @CrossOrigin 注解
5.方式二：自定义 WebMvcConfigurer
6.方式3：使用 Filter 进行跨域配置
7.最后
1.前言 本文介绍了spring boot中三种解决跨域问题的方式，坚持看完相信对你有帮助。
同时欢迎订阅springboot系列专栏，持续分享spring boot的使用经验。
2.何为跨域 跨域问题是指在 Web 开发中，一个网页的 JavaScript 代码通过 AJAX 请求后端服务器接口时，如果请求的目标地址与当前页面的地址不在同一个域（域名、端口或协议任何一项不同），就会产生跨域问题。这种情况下，根据浏览器的安全机制（同源策略）就会会限制页面的跨域请求，以防止恶意网站对其他网站的访问和操作，保护用户信息安全。
3.跨域问题出现特征 1.没有状态码信息
如果你看到某个请求似乎“失败了”，但并没有具体的HTTP状态码，这可能是因为浏览器出于安全原因阻止了对响应的访问。在开发者工具的网络(Network)面板中，这样的请求可能会被标记为“cancelled”或者没有显示状态码。
2.控制台报错
浏览器通常会在控制台(Console)中打印一条错误消息，说明因为CORS策略，请求被阻止了
4.方式一：使用 @CrossOrigin 注解 这是最直接简单的方式，可以精确控制所有接口
使用方法：在你的控制器类或者控制器方法上添加 @CrossOrigin 注解，可以精确控制某个控制器类、以及下面的某个方法的允许跨域的来源、允许的请求头、允许的请求方法等配置。
示例代码：
@RestController @RequestMapping("/user") @CrossOrigin(origins = "*")//允许所有来源的请求跨域 @Tag(name = "用户模块") public class UserController { private final UserService userService; public UserController(UserService userService) { this.userService = userService; } @PostMapping("/login") @Operation(summary = "
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/c89a3c7931f88f84e4b2245dffa28212/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/f91cdc0939efb87de2e1cd0d11ce3731/" rel="bookmark">
			Spring Boot3自定义异常及全局异常捕获
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		⛰️个人主页: 蒾酒
🔥系列专栏：《spring boot实战》
目录
前置条件
目的
主要步骤
定义自定义异常类
创建全局异常处理器
手动抛出自定义异常
前置条件 已经初始化好一个spring boot项目且版本为3X，项目可正常启动。
作者版本为3.2.2
初始化教程：
新版idea(2023)创建spring boot3项目-CSDN博客https://blog.csdn.net/qq_62262918/article/details/135785412?spm=1001.2014.3001.5501
目的 Spring Boot应用程序开发中，会遇到各种异常有可预知的也有不可预知的，我们很少会每个过程做单独异常处理，通常会将各种类型的异常处理过程解耦出来，保证业务逻辑单一、相关异常处理单一。
通常将异常进行处理，封装一下对应错误信息返回友好信息。避免把异常直接给前端、用户。
反例：异常直接返回(不友好)
正例：处理后返回提示信息(友好)
主要步骤 自定义异常类 下面我们举例定义几种常用异常类：
第一种：通用业务异常类
有一些业务异常可能仅仅是返回的错误提示信息的不同，并不需要额外的特殊逻辑处理，我们仅仅在业务代码里面将它抛出来触发对应返回处理。
如图：
代码如下：
import lombok.Getter; import lombok.Setter; /** * @author mijiupro * 通用业务异常类 */ @Getter @Setter public class GeneralBusinessException extends RuntimeException{ private int code=0; private String message; public GeneralBusinessException(String message) { this.message = message; } } 第二种：特殊处理业务异常类
可能处于安全性考虑，通常会进行密码错误次数限制，每次出现密码错误异常就需要进行累加
对于这种需要进行特殊处理的业务异常，我们就需要单独定义出对应异常类。
代码如下：
import com.
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/f91cdc0939efb87de2e1cd0d11ce3731/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/fb5937f5cf78703aa19a4a2dd89e0425/" rel="bookmark">
			密度峰值聚类(DPC)算法（Python3实现）
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		一、密度峰值算法简介 1、密度峰值聚类算法 密度峰值聚类（Density peaks clustering, DPC）算法是由Rodriguez和Laio于2014年提出的一种聚类分析算法。其原始文献名是在在 Science上发表的，论文名称为“Clustering by Fast Search and Find of Density Peaks”。这种聚类方法该算法是一种基于密度的聚类算法，可以自动确定聚类中心和聚类的数量并适用于处理各种形状和分布的数据集
2、密度峰值聚类算法基本思想 密度峰值聚类算法要具备两个基本假设条件
聚类中心的局部密度要远远大于其临近区域数据的局部密度；密度较高的数据对象，聚类中心离它的距离相对较远。 密度峰值聚类的核心是找出最佳聚类中心，为此密度峰值聚类算法引入了
局部密度ρ 和相对距离δ两个概念。
局部密度ρ：数据点xi的局部密度为在截断距离(dc)内其他数据点的数量，其中dc是截断距离，通常取数据集样本总数1%至2%作为dc的设定值。
这就意味着如果在这个距离内有更多的数据点，那么数据点i的局部密度就会更大。常见的局部密度的计算方式有很两种，分别为使用截断核计算方式（离散）和使用高斯核函数计算（连续）。
两种方式的计算公式分别如下：
（1）截断核
ρ ( i ) = ∑ j = 1 , j ≠ i n χ ( d i j − d c ) \rho(i) = \sum_{j=1,j \neq i}^n \chi(d_{ij} - d_{c}) ρ(i)=j=1,j=i∑n​χ(dij​−dc​)
χ ( x ) = { 1 , x &lt; 0 0 , x ≥ 0 \chi(x)=\left\{ \begin{aligned} 1 &amp; ,\ x&lt;0 \\ 0 &amp; ,\ x\geq 0 \end{aligned} \right.
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/fb5937f5cf78703aa19a4a2dd89e0425/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/4390850074a889153703782c1059f900/" rel="bookmark">
			Android基础入门：dataBinding的简单使用
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		2.DataBinding的使用
2.1属性更新
2.2``标签
2.2.1简单数据的定义与绑定
2.2.2复杂数据的定义与绑定
2.3事件绑定
2.3.1点击事件绑定
2.3.2点击事件回传数据
2.3.3动态改变对象数据在控件上显示
2.3.4动态改变基本数据在控件上显示
2.4与输入控件结合
2.5与图片控件结合
dataBinding是实现 view 和 data 绑定的工具，把数据映射到 view 的 xml中，可以在 xml 布局文件中实现 view 的赋值，方法调用。使用 DataBinding 后，我们不用再写 findViewById，不用再获取控件对象，不用再设置监听，可以节省我们 activity 中的很多获取控件，赋值，添加监听所需要的代码。
可以说MVP + DataBinding就是MVVC（关于MVC，MVP，MVVC的区别可看往期文章）
1.前期准备
=========================================================================
1.1打开dataBinding
1.2修改布局文件
选中布局文件的第一行，按alter+enter就会弹出提示，默认选中data binding layout
改造好的的新的布局文件里最大的变化就是多了一对&lt;data&gt;&lt;/data&gt;标签；很容易想到这是为了实现布局文件里数据和布局的分离，以及更好的实现数据与视图的双向绑定（这里文章后面会慢慢介绍）
1.3修改Activity方法
修改好布局文件之后，还需要对Activity文件做修改
使用了dataBinding之后，编译器会自动帮我们生成一个类名+Binding的新类，这其实是编译器帮我们把布局文件转换成了一个java文件，可以看到我们通过ctrl+鼠标左键点击这个类可以直接访问到布局文件
除此之外还需要为mainBinding这个对象赋初值，同样是通过setContentView方法，不过要传入两个参数，前者是Activity类，后者是布局文件的id
mainBinding=DataBindingUtil.setContentView(this,R.layout.activity_main); 2.DataBinding的使用
===================================================================================
2.1属性更新
那么如何使用dataBingding呢？
我们先在布局文件中新建几个控件，这里我的两个控件：文本控件的id是textview，按钮控件的id是button
回到Activity中，我们通过mainBInding对象可以看到，其下有两个值，textView和button，这正是我们刚刚两个组件的id，所以通过mainBinding对象我们可以轻松的取到我们布局文件里的组件，不再需要findViewById了
通过mainBinding获取到组件同样的可以设置这些控件的各种属性
2.2&lt;data&gt;标签
之前有提到在&lt;data&gt;&lt;/data&gt;标签中定义数据
在&lt;androidx.constraintlayout.widget.ConstraintLayout&gt;中定义布局并且绑定数据，这类似于前端vue框架中的数据视图双向绑定
2.2.1简单数据的定义与绑定 那么如何在data标签中定义数据呢？
通过标签，定义数据的名字name和类型type，这个类型可以是java中的所有基本类型
然后到布局中，用插值表达式将数据替代掉
不过现在什么也不会显示，因为这两个变量只定义了，没有赋值
看到这，我们也明白data标签的好处之一了，数据的定义都在data标签中，而constraint中就只管布局，通过插值表达式来绑定数据，不会出现数据。
那么data标签里的数据又如何初始化赋值呢？
这部分逻辑操作就交给Activity了。每定义一个varible，在布局的Binding类中都会生成此变量的get和set方法，通过这两个方法我们对数据进行初始化和更新。
所以有了dataBinding我们极大的减轻了Activity所要做的操作，Activity可以更专注于对数据与逻辑的处理，而UI的获取与数据和UI的绑定都交给了布局文件。
2.2.2复杂数据的定义与绑定 我们尝试一下类类型的数据的定义与绑定
先定义一个简单的实体类，简单的写两个属性
在data中定义一个类变量，name属性的同样是这个变量的名字，type属性就是这个包名.类名
数据的绑定也是一样的，通过类变量的名字.属性，所以我们可以把类变量person看成Person类new 出来的一个对象
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/4390850074a889153703782c1059f900/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/c297114af13f1e1193b3107f5c54d891/" rel="bookmark">
			Stable Diffusion Windows本地部署超详细教程（手动&#43;自动&#43;整合包三种方式）
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		一、 Stable Diffusion简介 2022年作为AIGC（Artificial Intelligence Generated Content）时代的元年，各个领域的AIGC技术都有一个迅猛的发展，给工业界、学术界、投资界甚至竞赛界都注入了新的“AI活力”与“AI势能”。
其中在AI绘画领域，Stable Diffusion当仁不让地成为了开源社区中持续繁荣的AI绘画核心模型，并且快速破圈，让AIGC的ToC可能性比肩移动互联网时代的产品，每个人都能感受到AI带来的力量与影响。Stable Diffusion由CompVis研究人员创建的主要用于文本生成图像的深度学习模型，与初创公司StabilityAI、Runway合作开发，并得到EleutherAI和LAION的支持，它主要用于根据文本的描述产生详细图像，也就是常说的txt2img的应用场景中：通过给定文本提示词（text prompt），该模型会输出一张匹配提示词的图片。例如输入文本提示词：A cute cat，Stable Diffusion会输出一张带有可爱猫咪的图片（如下图）。
Stable Diffusion（简称SD）是AI绘画领域的一个核心模型，与Midjourney不同的是，Stable Diffusion是一个完全开源的项目（模型、代码、训练数据、论文、生态等全部开源），可拓展性强、 出图效率高、 数据安全保障，这使得其能快速构建强大繁荣的上下游生态，并且吸引了越来越多的AI绘画爱好者加入其中，与AI行业从业者一起推动AIGC领域的发展与普惠。可以说，AI绘画的ToC普惠在AIGC时代的早期就已经显现，这是之前的传统深度学习时代从未有过的。
Stable Diffusion模型基于一个扩散过程，逐步从噪声中恢复出图像信息。在训练阶段，模型会学习如何逐步将噪声转化为真实的图像数据；而在生成阶段，模型则可以从随机噪声出发，通过反向的扩散过程，生成出与训练数据分布相似的图像。Stable Diffusion主要由变分自编码器（VAE）、U-Net和一个文本编码器三个部分组成。在前向扩散过程中，高斯噪声被迭代地应用于压缩的潜在表征。每个去噪步骤都由一个包含残差神经网络（ResNet）的U-Net架构完成，通过从前向扩散往反方向去噪而获得潜在表征。最后，VAE解码器通过将表征转换回像素空间来生成输出图像。
我们可以通过官方网站 Stability AI，以及Dream Studio、Replicate、Playground AI、Baseten等网站在线体验Stable Diffusion的巨大威力。但是，一方面国外的网站访问毕竟还是不方便（经常需要科学上网，你懂的），另一方面也不想让自己的一些“幼稚”想法被他们“窃取”。相比于集成在网络平台的SD或者其他AI绘画平台来说，自部署平台没有生成数量的限制，不用花钱，不用被NSFW约束，生成时间快，不用排队，自由度高，而且功能完整，插件丰富，可以调试和个性化的地方也更多；更稳定，也更容易让SD变成生产力或者商业化使用。既然这样，那就自力更生，在本机上自己部署一个，可以随心所欲地玩图、玩图...。
二、Stable Diffusion v2安装 1. 安装前的准备 现有深度学习训练和部署环境在硬件上一般基于Nvidia GPU，在底层需要显卡驱动和CUDA工具包（需要包含配套版本的cuDNN），在应用软件层面需要Python编译和解释器，以及基于Python的深度学习框架（如Pytorch、TensorFlow等）。同时，为了方便代码自动下载和程序模块化管理，通常还需要安装git和conda软件。笔者（Sheex2012）主机配备了RTX 4070Ti 12G显卡，并事先安装了CUDA 12.1，Python 3.11.6，git 2.44，Pytorch 2.1.2，能够满足Stable Diffusion环境要求。本文重点聚焦Stable Diffusion推理程序的部署，硬件需求确认和基础软件的安装这里不再赘述。
2. 下载和部署Stable Diffusion 我们从Stability.AI的github官方开源Stability.AI Stablediffusion下载源码：
git clone https://github.com/Stability-AI/stablediffusion.git 当然，也可以从网页上以下载源码ZIP包，解压缩到本地。
源码下载完成后，接下来需要安装项目的依赖项：
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple 然后从huggingface下载预训练模型v2-1_768-ema-pruned.ckpt，并存放到checkpoints文件夹中。
3. 运行Stable Diffusion 部署完成后，运行下述脚本，生成图片：
python ./scripts/txt2img.py --prompt "a professional photograph of an astronaut riding a horse"
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/c297114af13f1e1193b3107f5c54d891/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/1225dc80f5b4591c20ebe631d4ceb82d/" rel="bookmark">
			人工智能---什么是Transformer?
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		1 背景 随着这两年AI的兴起，又卷起了一股时代的浪潮，“大模型”这几个字似乎每天都能看到，给人的感觉：每个领域都在使用自己的模型。比如AI写作，AI画图，AI编曲，AI制作视频，与人类竞争的岗位将越来越多，就在前不久，苹果宣布放弃造车，将重点投入AI领域，可见未来AI有一个巨大的发展空间。
因此，本篇博客给大家介绍AI的一个基础研究：Transformer，主要是以普及知识为主。
2 Transformer内容介绍 Transformer是一种强大的神经网络架构，最初由Google的研究人员在论文《Attention is All You Need》中提出，用于自然语言处理任务，特别是在机器翻译方面取得了巨大成功。
Transformer的核心思想是完全基于自注意力机制(self-attention mechanism)来实现序列到序列(sequence-to-sequence)的学习。它在自然语言处理（NLP）和其他序列到序列任务中表现出色，逐渐成为该领域的主流模型，例如句子或者文本。
以下是对Transformer架构的详细介绍。
2.1 自注意力机制 自注意力机制（Self-Attention Mechanism）是Transformer的核心。在传统的循环神经网络（RNN）或卷积神经网络（CNN）中，每个单元只能关注到输入序列中的一个特定位置。而自注意力机制允许模型同时考虑输入序列中所有位置的信息，从而更好地捕捉长距离依赖关系。
自注意力机制允许模型在编码和解码过程中对不同位置的信息进行加权，使模型能够更好地理解上下文，并将重要的信息加权汇聚起来。通过多层的自注意力机制和前馈神经网络，Transformer模型能够学习到输入序列的表示，并生成与任务相关的输出。
2.2 Transformer架构的组成部分 整体架构可以用下图来描述：
其中Encoder和Decoder主要的子模块如下图所示：
输入嵌入（Input Embeddings）：将输入序列中的词或符号转换为向量表示。位置编码（Positional Encodings）：为输入序列中的每个位置添加位置信息，以便模型能够区分不同位置的词。编码器（Encoder）：由多个相同的层堆叠而成，每一层包含两个子层：多头自注意力机制和前馈神经网络。解码器（Decoder）：也由多个相同的层堆叠而成，每一层包含三个子层：多头自注意力机制、编码器-解码器注意力机制和前馈神经网络。多头注意力机制（Multi-Head Attention）：通过将注意力机制应用于多个投影版本的查询、键和值来捕捉不同表示空间中的信息。前馈神经网络（Feed-Forward Neural Network）：两个全连接层之间的ReLU激活函数，用于每个位置独立地处理输入。残差连接（Residual Connections）：在每个子层中添加残差连接，并进行层归一化（Layer Normalization）以避免梯度消失或爆炸问题。位置编码合并（Position-wise Feed-Forward Networks）：在每个位置独立地应用前馈神经网络，以增加模型的非线性建模能力。 2.3 特点与优势 相比于传统的循环神经网络（RNN）和卷积神经网络（CNN），Transformer模型具有以下优势：
并行计算能力强：由于自注意力机制可以同时考虑序列中的所有位置，因此Transformer可以实现并行化计算，从而提高处理长序列的效率。捕捉长距离依赖更加有效：RNN在处理长序列时容易出现梯度消失或爆炸的问题，而Transformer通过自注意力机制可以更有效地捕捉长距离依赖关系。模型结构简单且易于训练：Transformer的架构相对简洁，避免了RNN的复杂循环结构，因此更易于进行训练和优化。 2.4 Transformer的训练 Transformer的训练是一个涉及多个步骤和关键技术的复杂过程。以下是对Transformer训练的一个全面介绍。
数据准备 首先，数据准备是训练过程中的第一步。这包括对原始数据的预处理，例如文本清洗、分词、token化等，以便将原始数据转换为模型可以理解和处理的格式。同时，还需要为模型准备训练集、验证集和测试集，以便在训练过程中评估模型的性能。
模型设计 Transformer模型的核心是自注意力机制，它使得模型能够捕捉输入序列中的长距离依赖关系。模型通常由多个编码器和解码器层构成，每个编码器层包含自注意力子层和前馈神经网络子层，而解码器层则包含自注意力子层、编码器-解码器注意力子层和前馈神经网络子层。这种结构使得Transformer模型在处理序列数据时具有强大的能力。
设置训练的超参数 在模型设计完成后，需要配置优化器和学习率调度器，并设置训练的超参数，如学习率、批次大小、迭代次数等。这些参数的选择对模型的训练速度和最终性能具有重要影响。
训练循环 训练循环是Transformer训练的核心部分。在每个训练迭代中，模型首先通过前向传播处理输入数据，得到预测结果。然后，计算预测结果与真实标签之间的损失，并根据损失进行反向传播，更新模型的参数。这个过程需要重复多次，直到模型在验证集上的性能达到预设的停止准则或达到最大迭代次数。
在训练过程中，还可以采用一些技巧来提高模型的性能。例如，使用预训练的Transformer模型作为起点，可以加快训练速度并提高模型的性能。此外，精细调优也是关键的一步，包括选择合适的优化器、调整学习率、设置合适的批次大小等。同时，注意数据质量也至关重要，因为高质量的数据可以使模型学习到更好的特征表示。
评估和微调 最后，当训练完成后，可以对模型进行评估和微调。评估可以通过在测试集上测试模型的性能来完成，而微调则可以在特定任务上进行，以进一步提高模型在特定任务上的性能。
总之，Transformer的训练是一个涉及多个步骤和关键技术的复杂过程，需要仔细设计和调整以获得最佳性能。
3 Transformer的应用 Transformer不仅在机器翻译任务中表现出色，还被成功应用于文本生成、问答系统、语言建模等多个自然语言处理任务。此外，Transformer的思想也被用于计算机视觉任务中，例如图像描述生成和图像分类等领域。Transformer模型的应用场景相当广泛，包括但不限于以下领域。
自然语言处理（NLP）领域 Transformer模型的应用尤为突出。它可以用于机器翻译，通过处理不同语言之间的语义和词序信息，显著提升翻译质量。此外，Transformer模型在文本生成方面也有广泛应用，如生成对话、文本摘要、代码等。在文本分类任务中，如情感分析、垃圾邮件检测、情报分类等，Transformer模型也展现出强大的性能。同时，它还可以用于问答系统，如阅读理解、问答对话系统等。
语音识别领域 Transformer模型同样具有出色的表现。它可以用于语音转文本、语音合成等任务，其高效的推断能力使得语音识别速度更快。Transformer系列语音识别技术具有较高的通用性，便于在不同的平台和环境中应用，且其开源的特性也使得研究者可以轻松地共享和优化模型。智能客服、电话会议、新闻播报和无障碍沟通等场景都是Transformer系列语音识别技术的典型应用。
计算机视觉领域 Transformer模型也展现出了强大的能力。它可以应用于图像分类、目标检测、图像生成等任务，有效处理视觉数据。
此外，Transformer模型还可以通过迁移学习的方式，应用于多语言情感分类和命名实体识别等任务。通过联合训练多种语言的语料数据，实现模型参数的共享，从而提高模型的性能和效果。Transformer模型在处理序列数据方面有着广泛的应用场景，不仅可以应用于各种自然语言处理任务，还可以扩展到计算机视觉和语音识别等其他领域。随着技术的不断进步，相信Transformer模型未来还会有更多的应用场景被发掘。
4 自动驾驶中的Transformer 在自动驾驶领域中，Transformer模型也逐渐发挥着越来越重要的作用。以下是对自动驾驶中Transformer模型的详细介绍。
感知 首先，Transformer模型在自动驾驶的感知模块中扮演着关键角色。感知是自动驾驶系统的基础，它涉及到对周围环境的识别和理解。通过使用Transformer模型，自动驾驶系统可以更好地处理复杂的感知任务，如车辆、行人、障碍物等的识别和跟踪。Transformer模型的自注意力机制使其能够捕捉输入序列中各个位置的上下文关联，这对于理解复杂的交通环境至关重要。
决策规划 其次，Transformer模型在自动驾驶的决策规划模块中也发挥着重要作用。决策规划是自动驾驶系统的核心，它需要根据感知到的信息做出合理的驾驶决策。Transformer模型能够学习序列到序列的映射关系，这使得它非常适合处理决策规划中的序列决策问题。例如，在面对复杂的交通路口或突发情况时，Transformer模型可以根据历史数据和实时感知信息，预测其他车辆的行驶轨迹，从而做出准确的驾驶决策。
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/1225dc80f5b4591c20ebe631d4ceb82d/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/36dd50071d6aac52134ce9d822195d89/" rel="bookmark">
			WebStorm开发插件：提升开发效率的利器
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		作为一款功能强大的JavaScript集成开发环境（IDE），WebStorm提供了丰富的插件生态系统，可以帮助开发者提高工作效率、增强代码质量和提供更好的开发体验。本文将介绍一些常用的WebStorm开发插件，帮助你更好地利用这些插件来提升你的开发效率。
1. ESLint插件 ESLint是一个广泛使用的JavaScript代码检查工具，可以帮助你发现潜在的代码问题、规范代码风格和提高代码质量。WebStorm内置了ESLint插件，你可以轻松配置和使用它来进行代码检查和修复。
2. Prettier插件 Prettier是一个代码格式化工具，可以帮助你自动化地格式化代码，使其更加规范和易读。WebStorm的Prettier插件可以与ESLint插件无缝集成，让你在编写代码时保持一致的代码风格。
3. React插件 如果你正在使用React进行前端开发，WebStorm提供了一系列的React插件，可以帮助你更好地开发和调试React组件。这些插件包括React代码提示、组件结构浏览器、React调试器等，可以大大提高你的开发效率。
4. Git插件 WebStorm内置了Git插件，可以帮助你进行版本控制和代码管理。你可以直接在编辑器中查看和提交代码变更、比较代码差异、创建分支等，无需切换到命令行界面。
5. REST Client插件 如果你需要与后端API进行交互，REST Client插件可以帮助你方便地发送HTTP请求、查看响应结果和调试API。你可以直接在编辑器中编写和发送请求，并且支持多种请求格式和参数设置。
6. Material Theme UI插件 为了提供更好的视觉体验，你可以使用Material Theme UI插件来美化WebStorm的界面。这个插件提供了多种主题和配色方案，可以让你的编辑器看起来更加现代和美观。
以上只是一小部分WebStorm开发插件的介绍，实际上还有很多其他的插件可以满足不同的开发需求。通过合理地使用这些插件，你可以大大提高你的开发效率、减少代码错误和提供更好的开发体验。希望这篇博客能够帮助你更好地了解和利用WebStorm的开发插件。
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/b8fb2aef59f03ba3209da430e334fe2f/" rel="bookmark">
			探索Flutter Barcode Scanner：一款高效的二维码/条形码扫描库
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		探索Flutter Barcode Scanner：一款高效的二维码/条形码扫描库 项目地址:https://gitcode.com/AmolGangadhare/flutter_barcode_scanner
在数字化时代，二维码和条形码已经成为日常生活中不可或缺的一部分，它们简化了信息交换、支付流程等众多操作。对于移动应用开发者来说，集成二维码和条形码扫描功能是提升用户体验的关键。今天，我们要介绍的是一款强大的Flutter插件——Flutter Barcode Scanner，它可以帮助您轻松地在Flutter应用中实现这一功能。
项目简介 Flutter Barcode Scanner是由Amol Gangadhare开发的开源库，旨在为Flutter应用程序提供流畅、可靠的二维码和条形码扫描解决方案。该项目基于Android的ZXING库和iOS的AVFoundation框架，确保在两大主流移动平台上都能实现高效稳定的扫描效果。
技术分析 跨平台兼容性：作为Flutter插件，Flutter Barcode Scanner利用Flutter的特性，可以无缝地在Android和iOS上运行，减少了开发不同平台版本的工作量。
实时扫描：该库支持摄像头实时预览并自动检测二维码或条形码，无需用户手动对焦或调整，提高了用户体验。
自定义选项：您可以自定义扫描框大小、颜色，甚至设置扫描区域，以适应不同的应用设计需求。
简单易用的API：调用该库非常直观，只需几行代码即可完成二维码/条形码扫描功能的集成。
错误处理：当扫描失败或无可用相机时，库会返回相应的错误信息，方便开发者处理异常情况。
应用场景 Flutter Barcode Scanner适用于各种需要扫描二维码或条形码的应用场景，如：
电子商务：快速添加商品到购物车，查看产品详情。票务应用：扫描电子门票进入活动。支付应用：扫描二维码进行转账或收款。信息录入：读取设备上的数据，如Wi-Fi配置、联系人信息等。营销推广：通过扫描二维码访问优惠券、视频或其他促销内容。 特点概览 原生性能：基于Android和iOS的原生扫描库，保证了优秀的扫描速度和准确度。全面的扫码类型：支持多种二维码和条形码格式，包括QR Code, EAN, UPC等。易于集成：在Flutter项目中添加依赖，简单的API使得集成变得简单快捷。高度可定制：允许自定义界面元素和扫描行为。良好的社区支持：开源项目，有活跃的社区支持和定期更新。 要开始使用Flutter Barcode Scanner，请参考其官方文档或直接查看GitHub仓库中的示例代码。
总的来说，无论您是初学者还是经验丰富的开发者，Flutter Barcode Scanner都是一个值得尝试的工具，它将帮助您快速构建具有专业级扫描功能的应用。赶快来体验一下吧！
项目地址:https://gitcode.com/AmolGangadhare/flutter_barcode_scanner
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/47e494b839e5ce4bdc8a5bc051445179/" rel="bookmark">
			使用es必须要知道的一些知识点：索引篇_es创建索引
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		一、索引创建 在Elasticsearch（ES）中，index操作和create操作是用于创建新文档的两种不同方式。下面是它们的区别：
Index操作：
Index操作用于在指定的索引中创建新的文档。如果指定的索引不存在，Elasticsearch将自动创建该索引。如果执行index操作时指定的文档ID已经存在，则会更新该文档。如果没有指定文档ID，Elasticsearch会自动生成一个唯一的ID，并将其分配给新创建的文档。Index操作是幂等的，即多次执行相同的index操作不会创建重复的文档，而是更新现有的文档。 Create操作：
Create操作也用于在指定的索引中创建新的文档。但是，与index操作不同，如果指定的文档ID已经存在，则会引发一个错误。如果没有指定文档ID，Elasticsearch会自动生成一个唯一的ID，并将其分配给新创建的文档。Create操作是非幂等的，即多次执行相同的create操作会导致错误。 总结：
Index操作用于创建或更新文档，如果文档ID已存在，则更新该文档；而Create操作只能用于创建新文档，如果文档ID已存在，则会引发错误。
二、经验篇 使用动态模板（Dynamic Template）优化索引 在业务系统中，字符串类型的数据，一般被用作精确查询或模糊查询。
当Elasticsearch被用作大数据量存储中心时，尤其是从Mysql迁移数据进来的情况下，我们很多场景下其实无需对字符串分词，也就是说字符串存储不使用es中的text，我们可以设置属性的类型为keyword。
但是，如果数据结构中的字符串非常多，有没有一种方式，可以使字符串属性自动用keyword方式存储呢？这时候我们可以使用索引动态模板（Dynamic Template）来实现。
动态模板（Dynamic Template） 无需分词的情况下，可以在Elasticsearch动态模板中，设置所有字符串数据都用"type": "keyword"来存储。举个例子，我们可以创建一个适当的动态模板规则。
以下是一个示例：
{ "mappings": { "dynamic\_templates": [ { "strings\_as\_keyword": { "match\_mapping\_type": "string", "mapping": { "type": "keyword" } } } ] } } 这个动态模板规则将会把所有字符串字段映射为keyword类型。
动态模板常见设置：https://blog.csdn.net/liuwenqiang1314/article/details/125861920
使用动态模板时，如何防止子属性溢出 使用动态模板时，class属性要i禁用Map结构。原因：es索引key数量默认不能超过1000。
es数据底层存储的时候是按照json结构的，Map结构的数据存储到es，key是不固定的，随着数据量的扩张，key的数量可能超过1000，此时es会抛出异常。
illegal_argument_exception, reason=Limit of total fields [1000] in index [fcs_biz_bill_body_dev] has been exceeded
这个错误是由于Elasticsearch索引中的字段数超过了默认限制（1000个字段）所导致的。当我们尝试在一个索引中创建太多字段时，Elasticsearch会抛出这个异常。
解决此问题有两种方法：
增加索引的index.mapping.total_fields.limit设置值。我们可以通过更新索引设置来增加允许的最大字段数。例如，将其更改为2000： PUT /fcs_biz_bill_body_dev/_settings { "index": { "mapping": { "total\_fields": { "
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/47e494b839e5ce4bdc8a5bc051445179/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/51b3d7c5211029932c2ef18e16f099a9/" rel="bookmark">
			Java常见的技术场景面试题
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		一、单点登录这块怎么实现的？ 单点登录概述 单点登录：Single Sign On（简称SSO）,只需要登录一次，就可以访问所有信任的应用系统
在以前的时候，一般我们就单系统，所有的功能都在同一个系统上。 后来，我们为了 合理利用资源和降低耦合性 ，于是把单系统 拆分 成多个子系统。 现在有一个微服务的简单架构，如图： 使用jwt解决单点登录的流程如下：
参考回答
二、权限认证是如何实现的？ 权限认证： RBAC
模型表
三、上传数据的安全性你们怎么控制？ 回答：
使用非对称加密（或对称加密），给前端一个公钥让他把数据加密传到后台，后台负责解密后处理
文件很大建议使用对称加密，不过不能保存敏感信息文件较小，要求安全性高，建议采用非对称加密 四、你负责项目的时候遇到了哪些比较棘手的问题？ 回答思路 1，什么背景（技术问题） 2，过程（解决问题的过程） 3，最终落地方案 有4个方面可以回答，只要挑出一个回答就行了
举例：
①：介绍登录业务（一开始没有用设计模式，所有的登录方式都柔和在一个业 务类中，不过，发现需求经常改） ②：登录方式经常会增加或更换，每次都要修改业务层代码，所以，经过我的 设计，使用了工厂设计模式和策略模式，解决了，经常修改业务层代码的问题 ③：详细介绍一下工厂模式和策略模式（参考我前面设计模式的文章） 五、你们项目中日志怎么采集的？ 1、为什么要采集日志？ 日志是定位系统问题的重要手段，可以根据日志信息快速定位系统中的问题 2、采集日志的方式有哪些? ELK：即Elasticsearch、Logstash和Kibana三个软件的首字母 常规采集：按天保存到一个日志文件 2.1ELK基本架构 ELK即Elasticsearch、Logstash和Kibana三个开源软件的缩写 Elasticsearch：全文搜索和分析引擎，对大容量的数据进行接近实时的存储、搜索和分析操作。 Logstash：是一个数据收集引擎，它可以动态的从各种数据源搜集数据，并对数据进行过滤、分析和统一格式等操作，并将输出结果存储到指定位置上 Kibana：是一个数据分析和可视化平台，通常与Elasticsearch配合使用，用于对其中的数据进行搜索、分析，并且以统计图标的形式展示 配置文件 六、查看日志的命令？ 目前采集日志的方式：按天保存到一个日志文件
也可以在logback配置文件中设置日志的目录和名字 查看日志的命令 1、实时监控日志的变化 实时监控某一个日志文件的变化： tail -f xx.log 实时监控日志最后100行日志： tail –n 100 -f xx.log 2、按照行号查询 查询日志尾部最后100行日志：tail – n 100 xx.log
查询日志头部开始100行日志：head –n 100 xx.
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/51b3d7c5211029932c2ef18e16f099a9/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/f331f6524957d70024c006fc94680c87/" rel="bookmark">
			什么是请求参数、表单参数、url参数、header参数、Cookie参数？一文讲懂_前端请求参数
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		请求方式后面跟的是请求的路径，一般把这个叫 URI（统一资源标识符） 补充：URL 是统一资源定位符，见名知义，因为要定位，所以要指定协议甚至是位置，比如这样：http://localhost:5000/api/hello
请求路径后面跟的是 HTTP 的版本，比如这里是 HTTP/1.1 完整的第一行如下：
POST /api/hello HTTP/1.1 第二行的 User-Agent 则用于告诉对方发起请求的客户端是啥，比如咱们用 Postman 发起的请求，Postman 就会自动把这个参数设置为它自己：
User-Agent: PostmanRuntime/7.28.4 第三行的 Accept 用于告诉对方我们希望收到什么类型的数据，这里默认是能接受所有类型的数据：
Accept: */* 第四行就非常值得留意，Postman-Token 是 Postman 自己传的参数，这个我们放到下面讲！
Postman-Token: ddd72e1a-0d63-4bad-a18e-22e38a5de3fc 第五行是请求的主机，网络上的一个服务一般用 ip 加端口作为唯一标识：
Host: 127.0.0.1:5000 第六行指定的是咱们请求发起方可以理解的压缩方式：
Accept-Encoding: gzip, deflate, br 第七行告诉对方处理完当前请求后不要关闭连接：
Connection: keep-alive 第八行告诉对方咱们请求体的内容格式，这个是本文的侧重点啦！比如我们这里指定的是一般浏览器的原生表单格式：
Content-Type: application/x-www-form-urlencoded 前端面试 用前端面试题库 MST题宝库 好了，下面大家要留意了，第九行的 Content-Length 给出的是请求体的大小。
而请求体，会放在紧跟着的一个空行之后。比如本请求的请求体内容是以 key=value 形式填充的，也就是我们表单参数的内容了：
Content-Length: 23 name=%E9%98%BF%E8%8F%8C 看到这里我们先简单小结一下，想要告诉服务器我们发送的是表单数据，一共需要两步：
将 Content-Type 设置为 application/x-www-form-urlencoded在请求体中按照 key=value 的形式填写请求参数 什么是协议？进一步了解 http 好了，接下来我们进一步讲解，大家试想一下，网络应用，其实就是端到端的交互，最常见的就是服务端和客户端交互模型：客户端发一些参数数据给服务端，通过这些参数数据告诉服务端它想得到什么或想干什么，服务端根据客户端传递的参数数据作出处理。
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/f331f6524957d70024c006fc94680c87/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/bb52dcd9a4b07d1f8ebf4258fee1ccd7/" rel="bookmark">
			AI大模型探索之路-训练篇3：大语言模型全景解读
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		文章目录 前言一、语言模型发展历程1. 第一阶段：统计语言模型（Statistical Language Model, SLM）2. 第二阶段：神经语言模型（Neural Language Model, NLM）3. 第三阶段：预训练语言模型（Pre-trained Language Model, PLM）4. 第四阶段：大语言模型（Large Language Model, LLM） 二、大语言模型的能力特点三、大语言模型关键技术四、大语言模型的构建过程1.预训练阶段2.有监督微调阶段3.奖励建模阶段4.强化学习阶段 前言 大规模语言模型（Large Language Models，LLM），也称大语言模型或大型语言模型，是一种由包含数百亿以上参数的深度神经网络构建的语言模型，通常使用自监督学习方法通过大量无标注文本进行训练。
一、语言模型发展历程 语言模型旨在对于人类语言的内在规律进行建模，从而准确预测词序列中未来（或缺失）词的概率。语言模型分为以下四个主要发展阶段：
1. 第一阶段：统计语言模型（Statistical Language Model, SLM） 统计语言模型基于马尔可夫假设，通过n元（n-gram）方法预测下一个词的出现概率。这些模型在信息检索和自然语言处理中得到广泛应用。然而，它们受限于固定上下文长度，难以捕捉长距离依赖关系，且面临数据稀疏问题。
2. 第二阶段：神经语言模型（Neural Language Model, NLM） 神经语言模型利用循环神经网络（RNN）和词嵌入（Word Embedding）来建模文本序列。与n元模型相比，神经网络方法能够更好地处理数据稀疏问题，并且有助于捕捉长距离依赖关系。但是，早期的神经网络模型在长文本建模能力上存在局限性，且不易并行训练。
3. 第三阶段：预训练语言模型（Pre-trained Language Model, PLM） 预训练语言模型通过在大规模无标注数据上进行预训练，学习上下文感知的单词表示。代表性模型如ELMo、BERT和GPT-1，它们确立了“预训练-微调”范式，通过预训练建立基础能力，然后使用有标注数据进行特定任务的适配。这一阶段的模型改进了长文本建模能力，但仍存在优化空间，特别是在并行训练和硬件友好性方面。
4. 第四阶段：大语言模型（Large Language Model, LLM） 大语言模型通过“扩展法则”（增加模型参数规模或数据规模）进一步提升模型性能。同时，在尝试训练更大的预训练语言模型（例如 175B 参数的 GPT-3 和 540B 参数的 PaLM）来探索扩展语言模型所带来的性能极限过程中。这些大规模的预训练语言模型在解决复杂任务时表现出了与小型预训练语言模型（例如 330M 参数的 BERT 和 1.5B 参数的 GPT-2）不同的行为。例如，GPT-3 可以通过“上下文学习”（In-Context Learning, ICL）的方式来利用少样本数据解决下游任务，这种能力称为：涌现能力。为了区分这一能力上的差异，学术界将这些大型预训练语言模型命名为“大语言模型”，同时大规模模型的训练和应用带来了计算资源和环境影响等方面的挑战。
注意：大语言模型不一定比小型预训练语言模型具有更强的任务效果，而且某些大语言模型中也可能不具有某种涌现能力，和训练的数据质量和方式也有很大的关系。
涌现能力: 主要的涌现能力包括以下3种
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/bb52dcd9a4b07d1f8ebf4258fee1ccd7/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/f9fe4afab289b986d54011ebc765253d/" rel="bookmark">
			Mac安装telnet
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		一、安装Homebrew 1、打开官网：Homebrew — The Missing Package Manager for macOS (or Linux)
2、打开终端输入：
/usr/bin/ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)"
二、安装Telnet brew install telnet
三、执行Telnet命令 telnet api.evcoming.com 5131
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/ea1899cfc65325450c5ad18a1014edde/" rel="bookmark">
			9个日常实用的AI工具，不管是日常生活还是工作中都能用到！_可用的ai工具
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		一共有几十个功能，有的功能还挺有意思的。
操作也简单，比如AI问答，输入你问的问题，就能快速得到答案，它还会保存最近的聊天记录。
2、HuggingChat
一个开源的AI聊天模型，可以向它提问，也可以用它写邮件、写代码、执行任务等等，它使用的是使用的是最新的深度学习模型，可以在快速响应用户的同时，保证高准确率。
输入你想问的问题之后，就能快速得到答案，还可以开启搜索网页的功能，不过它的页面是英文的，需要搭配浏览器翻译插件使用 。
3、Chat助手
一款拥有Chat助手、AI创作私人助手功能的APP，功能还挺丰富的，有了它之后随时在手机上都能向AI提问。
Chat助手可以用来提问问题，创作功能有多种写作功能可以使用，私人助手有很多专业AI助手可以添加使用，不管是日常使用还是在工作中使用都可以。
二、AI绘画类 4、Vega AI
一个有多种绘画模式的AI绘画工具，它有文生图、图生图、条件生图和姿势生图功能，并且提供多种AI绘画风格，包括动漫、插画、人物、设计等等，这些风格直接收藏，就能在AI绘画功能中使用。
比较常用的就是文生图模式，输入文字之后，选择风格、尺寸、数量和画质之后，就可以生成图片了，生成的图片可以直接下载，也可以选择HD画质下载。
5、Draft
一个模型丰富的AI绘画网站，它里面不仅有官方模型、二次元、游戏、科技、摄影等模型可以使用，还有社区模型可以使用，每天都会有免费额度可以使用。
在AI绘画界面，输入文字后，选择模型、比例、尺寸后，就可以生成图片了，还有高级出图设置可选。
生成图片之后，可以直接下载图片，也可以分享到社区中，在社区中也可以看到其他人分享的图片，这些图片可以直接下载，也可以直接复刻生成类似的图片。
6、改图鸭
一个图片编辑处理APP，除了丰富的编辑处理功能之外，它里面还有AI绘画的功能可以使用，在AI绘画中级有多种风格的模型可选，二次元、插画、风景、真人等类型的图片都可以生成。
有两种模式，一键绘画就是图生图模式，妙笔生图就是文生图模式，选择你喜欢的模型后，点击做同款，在右侧输入文字，选择尺寸和数量后，就可以生成图片了，生成之后将图片保存到相册中就好了。
三、AI其他工具 7、ChatPPT
一个AI一键对话生成PPT的工具，输入你想要生成PPT的主题就可以快速生成PPT文档了，它还有不同的内容风格、色彩语言和文件转PPT可选。
生成PPT文档之后，就可以下载到本地进行编辑了。
8、腾讯智影
一个智能视频创作工具，它支持文本一键转视频，哪怕是不会视频剪辑，也能快速制作出一段不错的视频，还有智能配音、字幕识别、智能横转竖、数字人播报、文章转视频、去水印、视频解说等剪辑功能可以使用，不会视频又想制作视频的时候就可以用它。
9、ACE Studio
一个AI歌声合成软件，它采用用的是全流程Al技术，声线自然度与演唱表现力都很好，而且生成的速度也比较快。
有多种类型的AI歌手可选，有流行、民歌、童声、摇滚等十位精通中日英三语的高水平Al歌手可续那，可以满足不同的音乐制作需要，而且不仅能选择控制歌词和音高，还能控制呼吸气声、假声、张力、力度等演唱参数，让歌声更加真实。
好了，以上就是9个好用的AI工具，大家感兴趣的话，可以自己去试试！
关于AI绘画技术储备 学好 AI绘画 不论是就业还是做副业赚钱都不错，但要学会 AI绘画 还是要有一个学习规划。最后大家分享一份全套的 AI绘画 学习资料，给那些想学习 AI绘画 的小伙伴们一点帮助！
👉[[CSDN大礼包：《StableDiffusion安装包&amp;AI绘画入门学习资料》免费分享]]（安全链接，放心点击）
最后 🍅 硬核资料：关注即可领取PPT模板、简历模板、行业经典书籍PDF。
🍅 技术互助：技术群大佬指点迷津，你的问题可能不是问题，求资源在群里喊一声。
🍅 面试题库：由技术群里的小伙伴们共同投稿，热乎的大厂面试真题，持续更新中。
🍅 知识体系：含编程语言、算法、大数据生态圈组件（Mysql、Hive、Spark、Flink）、数据仓库、Python、前端等等。
网上学习资料一大堆，但如果学到的知识不成体系，遇到问题时只是浅尝辄止，不再深入研究，那么很难做到真正的技术提升。
需要这份系统化学习资料的朋友，可以戳这里无偿获取
一个人可以走的很快，但一群人才能走的更远！不论你是正从事IT行业的老鸟或是对IT行业感兴趣的新人，都欢迎加入我们的的圈子（技术交流、学习资源、职场吐槽、大厂内推、面试辅导），让我们一起学习成长！
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/1f830e05a7636b4def0e39cd24e7552b/" rel="bookmark">
			有没有佬知道、streamlit run webui.py的时候出现TypeError: ‘NoneType‘ object is not iterable咋解决哇
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		在阿里云服务器PAI上运行的，基于chatglm3-6b的langchain-chatglm具体错误如下：
# streamlit run webui.py --server.address 127.0.0.1
Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.
You can now view your Streamlit app in your browser.
URL: http://127.0.0.1:8501
/usr/local/lib/python3.10/dist-packages/langchain/chat_models/__init__.py:31: LangChainDeprecationWarning: Importing chat models from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:
`from langchain_community.chat_models import ChatOpenAI`.
To install langchain-community run `pip install -U langchain-community`.
warnings.warn(
/usr/local/lib/python3.10/dist-packages/langchain/llms/__init__.py:548: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated.
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/1f830e05a7636b4def0e39cd24e7552b/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/29c3eed759ab170363b71db8383d3a2f/" rel="bookmark">
			数据结构：线性表的链式储存
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		🌈个人主页：Rookie Maker
🔥 系列专栏：数据结构
🏆🏆关注博主，随时获取更多关于IT的优质内容！🏆🏆 😀欢迎来到我的代码世界~
😁 喜欢的小伙伴记得一键三连哦 ૮(˶ᵔ ᵕ ᵔ˶)ა
​
一.线性表的链式储存 链表：线性表的链式储存方式，逻辑结构不一定连续，物理结构不一定连续
描述：由数据域和指针域组成
​
二.单链表 介绍：
由指针域和数据域组成，头指针，头结点，头结点中存储的首元素的地址
可以用头指针命名
1.优缺点 🔥任意位置插入删除，时间复杂度小
🔥没有增容问题，插入一个开辟一个空间
🔥不支持随机访问
2.创建​ //定义链表 typedef int SLTDataType;//数值域 //链表是由节点组成 typedef struct SListNode { SLTDataType data;//int data struct SListNode* next;//它用来存储当前节点的下一个节点的地址 }SLTNode;// 3.打印 void SLTPrint(SLTNode* phead) { SLTNode* pcur = phead;//头指针 while (pcur)//pcur不为空！ { printf("%d-&gt;", pcur-&gt;data); pcur = pcur-&gt;next;//依次找到下一个结点 } printf("NULL\n"); } 4.申请空间 SLTNode* SLTBuyNode(SLTDataType x) { SLTNode* newnode = (SLTNode*)malloc(sizeof(SLTNode)); if (newnode == NULL) { perror("
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/29c3eed759ab170363b71db8383d3a2f/">Read more…</a>
	</div>
</article>
</main>

<div class="pagination">
	<a class="pagination__item pagination__item--prev btn" href="/posts/page/393/">«</a>
	<span class="pagination__item pagination__item--current">394/621</span>
	<a class="pagination__item pagination__item--next btn" href="/posts/page/395/">»</a>
</div>

			</div>
			

		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>