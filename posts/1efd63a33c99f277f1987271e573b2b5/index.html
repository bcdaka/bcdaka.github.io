<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>stable diffusion微调总结 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/1efd63a33c99f277f1987271e573b2b5/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="stable diffusion微调总结">
  <meta property="og:description" content="stable diffusion微调总结 stable diffusion模型类别：SDSD2SDXLSDXL LCM（潜在一致性模型）SDXL DistilledSDXL Turbo 安装accelerate通过pip安装配置 accelerate config查看配置 安装diffusers数据处理BLIP模型优化 微调方法Dreambooth微调准备数据：模型训练脚本：模型推理：模型转换脚本： Dream&#43;LORA微调模型训练脚本：模型推理脚本： Full FineTune数据格式：训练脚本：推理脚本 LORA微调数据格式：训练脚本：推理脚本： stable diffusion 模型类别： SD SD是一个基于latent的扩散模型，它在UNet中引入text condition来实现基于文本生成图像。SD的核心来源于Latent Diffusion这个工作，常规的扩散模型是基于pixel的生成模型，而Latent Diffusion是基于latent的生成模型，它先采用一个autoencoder将图像压缩到latent空间，然后用扩散模型来生成图像的latents，最后送入autoencoder的decoder模块就可以得到生成的图像。
SD2 SD 2.0相比SD 1.x版本的主要变动在于模型结构和训练数据两个部分。
首先是模型结构方面，SD 1.x版本的text encoder采用的是OpenAI的CLIP ViT-L/14模型，其模型参数量为123.65M；而SD 2.0采用了更大的text encoder：基于OpenCLIP在laion-2b数据集上训练的CLIP ViT-H/14模型，其参数量为354.03M，相比原来的text encoder模型大了约3倍。
SDXL Stable Diffusion XL (SDXL) 是一种强大的文本到图像生成模型，它以三种关键方式迭代以前的 Stable Diffusion 模型：
UNet 增大了 3 倍，SDXL 将第二个文本编码器 (OpenCLIP ViT-bigG/14) 与原始文本编码器相结合，显着增加了参数数量引入大小和裁剪调节，以防止训练数据被丢弃，并更好地控制生成图像的裁剪方式引入两阶段模型过程；基本模型（也可以作为独立模型运行）生成图像作为细化器模型的输入，该**模型添加了额外的高质量细节 SDXL LCM（潜在一致性模型） SDXL 潜在一致性模型 （LCM） 如“潜在一致性模型：使用几步推理合成高分辨率图像”中提出的那样，通过减少所需的步骤数彻底改变了图像生成过程。它将原始 SDXL 模型提炼成一个需要更少步骤（4 到 8 个而不是 25 到 50 个步骤）来生成图像的版本。该模型对于需要在不影响质量的情况下快速生成图像的应用特别有利。值得一提的是，它比原来的 SDXL 小 50%，快 60%。">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-02-02T17:51:50+08:00">
    <meta property="article:modified_time" content="2024-02-02T17:51:50+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">stable diffusion微调总结</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>stable diffusion微调总结</h4> 
 <ul><li><a href="#stable_diffusion_1" rel="nofollow">stable diffusion</a></li><li><ul><li><a href="#_3" rel="nofollow">模型类别：</a></li><li><a href="#SD_5" rel="nofollow">SD</a></li><li><a href="#SD2_9" rel="nofollow">SD2</a></li><li><ul><li><a href="#SDXL_15" rel="nofollow">SDXL</a></li><li><a href="#SDXL_LCM_23" rel="nofollow">SDXL LCM（潜在一致性模型）</a></li><li><a href="#SDXL_Distilled_27" rel="nofollow">SDXL Distilled</a></li><li><a href="#SDXL_Turbo_31" rel="nofollow">SDXL Turbo</a></li></ul> 
   </li><li><a href="#accelerate_35" rel="nofollow">安装accelerate</a></li><li><ul><li><a href="#pip_37" rel="nofollow">通过pip安装</a></li><li><a href="#_41" rel="nofollow">配置</a></li></ul> 
  </li></ul> 
  </li><li><a href="#accelerate_config_43" rel="nofollow">accelerate config</a></li><li><ul><li><ul><li><a href="#_60" rel="nofollow">查看配置</a></li></ul> 
   </li><li><a href="#diffusers_64" rel="nofollow">安装diffusers</a></li><li><a href="#_74" rel="nofollow">数据处理</a></li><li><ul><li><a href="#BLIP_80" rel="nofollow">BLIP</a></li><li><a href="#_101" rel="nofollow">模型优化</a></li></ul> 
   </li><li><a href="#_107" rel="nofollow">微调方法</a></li><li><a href="#Dreambooth_129" rel="nofollow">Dreambooth微调</a></li><li><ul><li><a href="#_131" rel="nofollow">准备数据：</a></li><li><a href="#_137" rel="nofollow">模型训练脚本：</a></li><li><a href="#_190" rel="nofollow">模型推理：</a></li><li><a href="#_208" rel="nofollow">模型转换脚本：</a></li></ul> 
   </li><li><a href="#DreamLORA_224" rel="nofollow">Dream+LORA微调</a></li><li><ul><li><a href="#_226" rel="nofollow">模型训练脚本：</a></li><li><a href="#_259" rel="nofollow">模型推理脚本：</a></li></ul> 
   </li><li><a href="#Full_FineTune_294" rel="nofollow">Full FineTune</a></li><li><ul><li><a href="#_296" rel="nofollow">数据格式：</a></li><li><a href="#_322" rel="nofollow">训练脚本：</a></li><li><a href="#_343" rel="nofollow">推理脚本</a></li></ul> 
   </li><li><a href="#LORA_357" rel="nofollow">LORA微调</a></li><li><ul><li><a href="#_359" rel="nofollow">数据格式：</a></li><li><a href="#_363" rel="nofollow">训练脚本：</a></li><li><a href="#_381" rel="nofollow">推理脚本：</a></li></ul> 
  </li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h2><a id="stable_diffusion_1"></a>stable diffusion</h2> 
<h3><a id="_3"></a>模型类别：</h3> 
<h3><a id="SD_5"></a>SD</h3> 
<blockquote> 
 <p>SD是一个<strong>基于latent的扩散模型</strong>，它在UNet中引入text condition来实现基于文本生成图像。SD的核心来源于<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2112.10752" rel="nofollow">Latent Diffusion</a>这个工作，常规的扩散模型是基于pixel的生成模型，而Latent Diffusion是基于latent的生成模型，它先采用一个autoencoder将图像压缩到latent空间，然后用扩散模型来生成图像的latents，最后送入autoencoder的decoder模块就可以得到生成的图像。</p> 
</blockquote> 
<h3><a id="SD2_9"></a>SD2</h3> 
<blockquote> 
 <p>SD 2.0相比SD 1.x版本的主要变动在于<strong>模型结构</strong>和<strong>训练数据</strong>两个部分。</p> 
 <p>首先是模型结构方面，SD 1.x版本的text encoder采用的是OpenAI的CLIP ViT-L/14模型，其模型参数量为123.65M；而SD 2.0采用了更大的text encoder：基于OpenCLIP在laion-2b数据集上训练的<a href="https://link.zhihu.com/?target=https%3A//huggingface.co/laion/CLIP-ViT-H-14-laion2B-s32B-b79K" rel="nofollow">CLIP ViT-H/14</a>模型，其参数量为354.03M，相比原来的text encoder模型大了约3倍。</p> 
</blockquote> 
<h4><a id="SDXL_15"></a>SDXL</h4> 
<blockquote> 
 <p>Stable Diffusion XL (SDXL) 是一种强大的文本到图像生成模型，它以三种关键方式迭代以前的 Stable Diffusion 模型：</p> 
</blockquote> 
<ol><li>UNet 增大了 3 倍，SDXL 将第二个文本编码器 (OpenCLIP ViT-bigG/14) 与原始文本编码器相结合，显着增加了参数数量</li><li>引入大小和裁剪调节，以防止训练数据被丢弃，并更好地控制生成图像的裁剪方式</li><li>引入两阶段模型过程；基本模型（也可以作为独立模型运行）生成图像作为<em>细化器模型的输入，该**模型</em>添加了额外的高质量细节</li></ol> 
<h4><a id="SDXL_LCM_23"></a>SDXL LCM（潜在一致性模型）</h4> 
<p><strong>SDXL 潜在一致性模型 （LCM） 如“潜在一致性模型</strong>：使用几步推理合成高分辨率图像”中提出的那样，通过减少所需的步骤数彻底改变了图像生成过程。它将原始 SDXL 模型提炼成一个需要更少步骤（4 到 8 个而不是 25 到 50 个步骤）来生成图像的版本。该模型对于需要在不影响质量的情况下快速生成图像的应用特别有利。值得一提的是，它比原来的 SDXL 小 50%，快 60%。</p> 
<h4><a id="SDXL_Distilled_27"></a>SDXL Distilled</h4> 
<p><strong>SDXL Distilled</strong> 是指为特定目的而“蒸馏”的 SDXL 模型版本。例如，Segmind 稳定扩散模型 （SSD-1B） 是 SDXL 的精炼版本，体积缩小了 50%，速度提高了 60%，同时保持了高质量的文本到图像生成功能。此版本对于速度至关重要但图像质量不能受到影响的场景特别有用。</p> 
<h4><a id="SDXL_Turbo_31"></a>SDXL Turbo</h4> 
<p><strong>SDXL Turbo 是 SDXL</strong> 1.0 的新版本，专为“实时合成”而开发。这意味着它可以非常快速地生成图像，这一功能由一种称为对抗扩散蒸馏 （ADD） 的新训练方法提供支持。这种变体是独一无二的，因为它具有有损自动编码组件，尽管在图像的编码和解码过程中会导致一些信息丢失，但可以更快地生成图像。</p> 
<h3><a id="accelerate_35"></a>安装accelerate</h3> 
<h4><a id="pip_37"></a>通过pip安装</h4> 
<blockquote> 
 <p>pip install accelerate</p> 
</blockquote> 
<h4><a id="_41"></a>配置</h4> 
<blockquote> 
 <h2><a id="accelerate_config_43"></a>accelerate config</h2> 
 <p>-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------In which compute environment are you running?（在本机服务器上就选择<strong>This machine</strong> ）<br> <strong>This machine</strong><br> -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------Which type of machine are you using?（单机多卡选择multi-GPU，单卡选第一个选项）<br> <strong>multi-GPU</strong><br> How many different machines will you use (use more than 1 for multi-node training)? [1]: <strong>1</strong> 几台机器用来训练<br> Do you wish to optimize your script with torch dynamo?[yes/NO]:<br> Do you want to use DeepSpeed? [yes/NO]:<br> Do you want to use FullyShardedDataParallel? [yes/NO]:<br> Do you want to use Megatron-LM ? [yes/NO]:<br> How many GPU(s) should be used for distributed training? [1]:<strong>2</strong> 用几张卡<br> What GPU(s) (by id) should be used for training on this machine as a comma-seperated list? [all]:<strong>all</strong> 全部都用来训练<br> -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------Do you wish to use FP16 or BF16 (mixed precision)?<br> <strong>fp16</strong> 选择训练精度类型<br> accelerate configuration saved at /root/.cache/huggingface/accelerate/default_config.yaml 配置文件保存位置，可修改</p> 
</blockquote> 
<h4><a id="_60"></a>查看配置</h4> 
<blockquote> 
 <p>accelerate env</p> 
</blockquote> 
<h3><a id="diffusers_64"></a>安装diffusers</h3> 
<p>注意必须从源码安装最新的版本，不然无法通过版本审核。</p> 
<pre><code>git clone https://github.com/huggingface/diffusers
cd diffusers
pip install -e .
</code></pre> 
<h3><a id="_74"></a>数据处理</h3> 
<blockquote> 
 <p>我们需要筛除分辨率较低，质量较差**（比如说768*768分辨率的图片&lt; 100kb）**，存在破损，以及和任务目标无关的数据，接着去除数据里面可能包含的水印，干扰文字等，最后就可以开始进行数据标注了。</p> 
</blockquote> 
<blockquote> 
 <p>数据标注可以分为<strong>自动标注和手动标注</strong>。自动标注主要依赖像BLIP和Waifu Diffusion 1.4这样的模型，手动标注则依赖标注人员。</p> 
</blockquote> 
<h4><a id="BLIP_80"></a>BLIP</h4> 
<blockquote> 
 <ol><li>图像字幕</li><li>开放式视觉问答</li><li>多模态/单模态特征提取</li><li>图文匹配</li></ol> 
</blockquote> 
<p>数据注意事项：</p> 
<ul><li> <p>当我们训练<strong>人物主题</strong>时，一般需要10-20张高质量数据；当我们训练<strong>画风主题</strong>时，需要100-200张高质量数据；当我们训练<strong>抽象概念</strong>时，则至少需要200张以上的数据。</p> </li><li> <p>不管是人物主题，画风主题还是抽象概念，<strong>一定要保证数据集中数据的多样性</strong>（比如说猫女姿态，角度，全身半身的多样性）。</p> </li><li> <p><strong>每个数据都要符合我们的审美和评判标准！</strong></p> </li></ul> 
<p>模型注意事项：</p> 
<blockquote> 
 <p><strong>1. 底模型的选择至关重要，SDXL LoRA的很多底层能力与基础概念的学习都来自于底模型的能力。</strong> 并且底模型的优秀能力需要与我们训练的主题，比如说人物，画风或者某个抽象概念相适配。如果我们要训练二次元LoRA，则需要选择二次元底模型，如果我们要训练三次元LoRA，则需要选择三次元底模型，以此类推。</p> 
 <ol start="2"><li>模型以savetensor为后缀的是加密的，ckpt是开源的。</li></ol> 
</blockquote> 
<h4><a id="_101"></a>模型优化</h4> 
<p>1.剪枝：剪枝后的模型pruned，泛化性好，存储空间小。</p> 
<p>2.ema: ema是一种常用的优化神经网络的方法，他可以平滑模型的参数更新，降低模型训练过程中的波动和震荡，增强模型的鲁棒性和泛化能力</p> 
<h3><a id="_107"></a>微调方法</h3> 
<p>目前主流训练 Stable Diffusion 模型的方法有 ：</p> 
<ul><li>Full FineTune</li></ul> 
<blockquote> 
 <p>全量训练，数据以图片+标注的形式。</p> 
</blockquote> 
<ul><li>Dreambooth：</li></ul> 
<blockquote> 
 <p>DreamBooth是一种训练技术，通过对某个主题或风格的几张图像进行训练来更新整个扩散模型。它的工作原理是将提示中的特殊单词与示例图像相关联。</p> 
</blockquote> 
<ul><li>Text Inversion：</li></ul> 
<blockquote> 
 <p><a href="https://hf.co/papers/2208.01618" rel="nofollow">文本反转</a>是一种训练技术，用于通过一些您希望其学习内容的示例图像来个性化图像生成模型。该技术的工作原理是学习和更新文本嵌入（新嵌入与您必须在提示中使用的特殊单词相关联）以匹配您提供的示例图像。</p> 
</blockquote> 
<ul><li>LoRA</li></ul> 
<blockquote> 
 <p><a href="https://hf.co/papers/2106.09685" rel="nofollow">LoRA（大型语言模型的低秩适应）</a>是一种流行的轻量级训练技术，可显着减少可训练参数的数量。它的工作原理是向模型中插入较少数量的新权重，并且仅对这些权重进行训练。这使得 LoRA 的训练速度更快、内存效率更高，并产生更小的模型权重（几百 MB），更容易存储和共享。LoRA 还可以与 DreamBooth 等其他训练技术相结合，以加速训练。</p> 
</blockquote> 
<h3><a id="Dreambooth_129"></a>Dreambooth微调</h3> 
<h4><a id="_131"></a>准备数据：</h4> 
<pre><code>https: //huggingface.co/datasets/diffusers/dog-example
</code></pre> 
<h4><a id="_137"></a>模型训练脚本：</h4> 
<pre><code>export MODEL_NAME="stable-diffusion-2"
export INSTANCE_DIR="dog"
export OUTPUT_DIR="path-to-save-model"

accelerate launch train_dreambooth.py \
  --pretrained_model_name_or_path=$MODEL_NAME  \
  --instance_data_dir=$INSTANCE_DIR \
  --output_dir=$OUTPUT_DIR \
  --instance_prompt="a photo of sks dog" \
  --resolution=768 \
  --train_batch_size=1 \
  --gradient_accumulation_steps=1 \
  --learning_rate=5e-6 \
  --lr_scheduler="constant" \
  --lr_warmup_steps=0 \
  --max_train_steps=400 \
</code></pre> 
<p><strong>train_dreambooth.py</strong>: 脚本位置为：https://github.com/huggingface/diffusers/blob/main/examples/dreambooth/train_dreambooth.py</p> 
<p><strong>pretrained_model_name_or_path</strong>: 模型的路径</p> 
<p><strong>instance_data_dir</strong>： 训练的图片位置</p> 
<p><strong>output_dir</strong>： 微调模型保存位置</p> 
<p><strong>instance_prompt</strong>：罕见字符，使用 Stable Diffusion 模型去生成一个已有相关主题（class） 的先验知识，并在训练中充分考虑原 class 和新 instance 的 prior preservation loss，从而避免新 instance 图片特征渗透到其他生成里。</p> 
<p><strong>resolution</strong>： 图片尺寸，和训练的模型相对应</p> 
<p><strong>train_batch_size</strong>： 训练批次</p> 
<p><strong>gradient_accumulation_steps</strong>：</p> 
<p>gradient_accumulation_steps通过累计梯度来解决本地显存不足问题。<br> 假设原来的batch_size=6，样本总量为24。<br> 那么参数更新次数=24/6=4。</p> 
<p>如果我的显存不够6batch，想调成3batch，那么我的参数更新次数就是=24/3=8次</p> 
<p>但是我设置了gradient_accumulation_steps=2，batch还是6，但是内部是按照batch=3来算的，计算两次batch=3后进行累计梯度，即batch_size=6/2=3，参数更新次数不变=24/3/2=4，在梯度反传时，每gradient_accumulation_steps次进行一次梯度更新，之前照常利用loss.backward()计算梯度。</p> 
<p><strong>learning_rate</strong>：学习率</p> 
<p><strong>lr_scheduler</strong>： 策略</p> 
<p><strong>lr_warmup_steps</strong>：预热的步数</p> 
<p><strong>max_train_steps</strong>：训练步数</p> 
<h4><a id="_190"></a>模型推理：</h4> 
<pre><code class="prism language-python"><span class="token keyword">from</span> diffusers <span class="token keyword">import</span> StableDiffusionPipeline
<span class="token keyword">import</span> torch

model_id <span class="token operator">=</span> <span class="token string">"stable_finetine/path-to-save-model"</span>
pipe <span class="token operator">=</span> StableDiffusionPipeline<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_id<span class="token punctuation">,</span> torch_dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float16<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">"cuda"</span><span class="token punctuation">)</span>

prompt <span class="token operator">=</span> <span class="token string">"A photo of dog in a bucket"</span>
image <span class="token operator">=</span> pipe<span class="token punctuation">(</span>prompt<span class="token punctuation">,</span> num_inference_steps<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span> guidance_scale<span class="token operator">=</span><span class="token number">7.5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>images<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

image<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string">"dog-bucket2.png"</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/01/c5/upGEu7bb_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="_208"></a>模型转换脚本：</h4> 
<pre><code>python  convert_diffusers_to_original_stable_diffusion.py --model_path path-to-save-model --checkpoint_path dreambooth_dog.safetensors --use_safetensors
</code></pre> 
<p><strong>convert_diffusers_to_original_stable_diffusion</strong>.py： 脚本位置在https://github.com/huggingface/diffusers/blob/main/scripts/convert_diffusers_to_original_stable_diffusion.py</p> 
<p><strong>model_path</strong>：经过dreambooth训练出来的模型</p> 
<p><strong>checkpoint_path</strong>： 自定义命名</p> 
<h3><a id="DreamLORA_224"></a>Dream+LORA微调</h3> 
<h4><a id="_226"></a>模型训练脚本：</h4> 
<pre><code class="prism language-python">export MODEL_NAME<span class="token operator">=</span><span class="token string">"stable-diffusion-2"</span>
export INSTANCE_DIR<span class="token operator">=</span><span class="token string">"dog"</span>
export OUTPUT_DIR<span class="token operator">=</span><span class="token string">"path-to-save-lora-model"</span>

accelerate launch train_dreambooth_lora<span class="token punctuation">.</span>py \
  <span class="token operator">-</span><span class="token operator">-</span>pretrained_model_name_or_path<span class="token operator">=</span>$MODEL_NAME  \
  <span class="token operator">-</span><span class="token operator">-</span>instance_data_dir<span class="token operator">=</span>$INSTANCE_DIR \
  <span class="token operator">-</span><span class="token operator">-</span>output_dir<span class="token operator">=</span>$OUTPUT_DIR \
  <span class="token operator">-</span><span class="token operator">-</span>instance_prompt<span class="token operator">=</span><span class="token string">"a photo of sks dog"</span> \
  <span class="token operator">-</span><span class="token operator">-</span>resolution<span class="token operator">=</span><span class="token number">768</span> \
  <span class="token operator">-</span><span class="token operator">-</span>train_batch_size<span class="token operator">=</span><span class="token number">1</span> \
  <span class="token operator">-</span><span class="token operator">-</span>gradient_accumulation_steps<span class="token operator">=</span><span class="token number">1</span> \
  <span class="token operator">-</span><span class="token operator">-</span>checkpointing_steps<span class="token operator">=</span><span class="token number">100</span> \
  <span class="token operator">-</span><span class="token operator">-</span>learning_rate<span class="token operator">=</span><span class="token number">1e-4</span> \
  <span class="token operator">-</span><span class="token operator">-</span>report_to<span class="token operator">=</span><span class="token string">"wandb"</span> \
  <span class="token operator">-</span><span class="token operator">-</span>lr_scheduler<span class="token operator">=</span><span class="token string">"constant"</span> \
  <span class="token operator">-</span><span class="token operator">-</span>lr_warmup_steps<span class="token operator">=</span><span class="token number">0</span> \
  <span class="token operator">-</span><span class="token operator">-</span>max_train_steps<span class="token operator">=</span><span class="token number">500</span> \
  <span class="token operator">-</span><span class="token operator">-</span>validation_prompt<span class="token operator">=</span><span class="token string">"A photo of sks dog in a bucket"</span> \
  <span class="token operator">-</span><span class="token operator">-</span>validation_epochs<span class="token operator">=</span><span class="token number">50</span> \
  <span class="token operator">-</span><span class="token operator">-</span>seed<span class="token operator">=</span><span class="token string">"0"</span> \
  <span class="token operator">-</span><span class="token operator">-</span>mixed_precision <span class="token string">"no"</span>
</code></pre> 
<p><strong>mixed_precision</strong>: 默认是fp16，会报错：ValueError: Attempting to unscale FP16gradients</p> 
<p>需要改成no，则是fp36。</p> 
<p><strong>train_dreambooth_lora.py</strong>：该脚本自带转换模型</p> 
<h4><a id="_259"></a>模型推理脚本：</h4> 
<pre><code class="prism language-python"><span class="token keyword">from</span> diffusers <span class="token keyword">import</span> DiffusionPipeline<span class="token punctuation">,</span> DPMSolverMultistepScheduler
<span class="token keyword">import</span> torch

pipe <span class="token operator">=</span> DiffusionPipeline<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"stable-diffusion-2"</span><span class="token punctuation">,</span> torch_dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float16<span class="token punctuation">)</span>
pipe<span class="token punctuation">.</span>scheduler <span class="token operator">=</span> DPMSolverMultistepScheduler<span class="token punctuation">.</span>from_config<span class="token punctuation">(</span>pipe<span class="token punctuation">.</span>scheduler<span class="token punctuation">.</span>config<span class="token punctuation">)</span>
pipe<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">"cuda"</span><span class="token punctuation">)</span>
<span class="token comment"># pipe.unet.load_attn_procs("path-to-save-lora-model")</span>
pipe<span class="token punctuation">.</span>load_lora_weights<span class="token punctuation">(</span><span class="token string">"path-to-save-lora-model"</span><span class="token punctuation">)</span>
image <span class="token operator">=</span> pipe<span class="token punctuation">(</span><span class="token string">"A picture of a sks dog in a bucket"</span><span class="token punctuation">,</span> num_inference_steps<span class="token operator">=</span><span class="token number">25</span><span class="token punctuation">)</span><span class="token punctuation">.</span>images<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
image<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string">"dog-bucket-lora.png"</span><span class="token punctuation">)</span>

</code></pre> 
<p>注意点：</p> 
<p>原文档中是:</p> 
<pre><code>pipe.unet.load_attn_procs("path-to-save-lora-model")
</code></pre> 
<p><img src="https://images2.imgbox.com/9c/9a/NhTEgHHo_o.png" alt="在这里插入图片描述"></p> 
<p>但是加载后的推理并没有明显的效果，怀疑根本没有加载到。作者后续更新了新方法，测试新方法有效果：</p> 
<pre><code>pipe.load_lora_weights("path-to-save-lora-model")
</code></pre> 
<p><img src="https://images2.imgbox.com/70/3f/1mJoysSb_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="Full_FineTune_294"></a>Full FineTune</h3> 
<h4><a id="_296"></a>数据格式：</h4> 
<pre><code>folder/train/metadata.jsonl
folder/train/0001.png
folder/train/0002.png
folder/train/0003.png
</code></pre> 
<p><strong>metadata.jsonl</strong></p> 
<pre><code>{"file_name": "0001.png", "additional_feature": "This is a first value of a text feature you added to your images"}
{"file_name": "0002.png", "additional_feature": "This is a second value of a text feature you added to your images"}
{"file_name": "0003.png", "additional_feature": "This is a third value of a text feature you added to your images"}
</code></pre> 
<p>或者用huggingface上现成的数据：</p> 
<pre><code>pokemon-blip-captions
├── data
│   └── train-00000-of-00001-566cc9b19d7203f8.parquet
└── dataset_infos.json
</code></pre> 
<h4><a id="_322"></a>训练脚本：</h4> 
<pre><code class="prism language-python">export MODEL_NAME<span class="token operator">=</span><span class="token string">"stable-diffusion-2"</span>
export DATASET_NAME<span class="token operator">=</span><span class="token string">"pokemon-blip-captions"</span>

accelerate launch <span class="token operator">-</span><span class="token operator">-</span>mixed_precision<span class="token operator">=</span><span class="token string">"fp16"</span>  train_full_finetune<span class="token punctuation">.</span>py \
  <span class="token operator">-</span><span class="token operator">-</span>pretrained_model_name_or_path<span class="token operator">=</span>$MODEL_NAME \
  <span class="token operator">-</span><span class="token operator">-</span>dataset_name<span class="token operator">=</span>$DATASET_NAME \
  <span class="token operator">-</span><span class="token operator">-</span>use_ema \
  <span class="token operator">-</span><span class="token operator">-</span>resolution<span class="token operator">=</span><span class="token number">768</span> <span class="token operator">-</span><span class="token operator">-</span>center_crop <span class="token operator">-</span><span class="token operator">-</span>random_flip \
  <span class="token operator">-</span><span class="token operator">-</span>train_batch_size<span class="token operator">=</span><span class="token number">1</span> \
  <span class="token operator">-</span><span class="token operator">-</span>gradient_accumulation_steps<span class="token operator">=</span><span class="token number">4</span> \
  <span class="token operator">-</span><span class="token operator">-</span>gradient_checkpointing \
  <span class="token operator">-</span><span class="token operator">-</span>max_train_steps<span class="token operator">=</span><span class="token number">15000</span> \
  <span class="token operator">-</span><span class="token operator">-</span>learning_rate<span class="token operator">=</span><span class="token number">1e-05</span> \
  <span class="token operator">-</span><span class="token operator">-</span>max_grad_norm<span class="token operator">=</span><span class="token number">1</span> \
  <span class="token operator">-</span><span class="token operator">-</span>lr_scheduler<span class="token operator">=</span><span class="token string">"constant"</span> <span class="token operator">-</span><span class="token operator">-</span>lr_warmup_steps<span class="token operator">=</span><span class="token number">0</span> \
  <span class="token operator">-</span><span class="token operator">-</span>output_dir<span class="token operator">=</span><span class="token string">"sd-pokemon-model"</span>
</code></pre> 
<h4><a id="_343"></a>推理脚本</h4> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> diffusers <span class="token keyword">import</span> StableDiffusionPipeline

model_path <span class="token operator">=</span> <span class="token string">"sd-pokemon-model"</span>
pipe <span class="token operator">=</span> StableDiffusionPipeline<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_path<span class="token punctuation">,</span> torch_dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float16<span class="token punctuation">)</span>
pipe<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">"cuda"</span><span class="token punctuation">)</span>

image <span class="token operator">=</span> pipe<span class="token punctuation">(</span>prompt<span class="token operator">=</span><span class="token string">"a drawing of a pokemon stuffed animal"</span><span class="token punctuation">,</span>num_inference_steps<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">.</span>images<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
image<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string">"yoda-pokemon.png"</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="LORA_357"></a>LORA微调</h3> 
<h4><a id="_359"></a>数据格式：</h4> 
<blockquote> 
 <p>同full Fine Tune</p> 
</blockquote> 
<h4><a id="_363"></a>训练脚本：</h4> 
<pre><code class="prism language-python">export MODEL_NAME<span class="token operator">=</span><span class="token string">"stable-diffusion-2"</span>
export DATASET_NAME<span class="token operator">=</span><span class="token string">"pokemon-blip-captions"</span>

accelerate launch <span class="token operator">-</span><span class="token operator">-</span>mixed_precision<span class="token operator">=</span><span class="token string">"no"</span> train_lora<span class="token punctuation">.</span>py \
  <span class="token operator">-</span><span class="token operator">-</span>pretrained_model_name_or_path<span class="token operator">=</span>$MODEL_NAME \
  <span class="token operator">-</span><span class="token operator">-</span>dataset_name<span class="token operator">=</span>$DATASET_NAME <span class="token operator">-</span><span class="token operator">-</span>caption_column<span class="token operator">=</span><span class="token string">"text"</span> \
  <span class="token operator">-</span><span class="token operator">-</span>resolution<span class="token operator">=</span><span class="token number">768</span> <span class="token operator">-</span><span class="token operator">-</span>random_flip \
  <span class="token operator">-</span><span class="token operator">-</span>train_batch_size<span class="token operator">=</span><span class="token number">2</span> \
  <span class="token operator">-</span><span class="token operator">-</span>num_train_epochs<span class="token operator">=</span><span class="token number">100</span> <span class="token operator">-</span><span class="token operator">-</span>checkpointing_steps<span class="token operator">=</span><span class="token number">5000</span> \
  <span class="token operator">-</span><span class="token operator">-</span>learning_rate<span class="token operator">=</span><span class="token number">1e-04</span> <span class="token operator">-</span><span class="token operator">-</span>lr_scheduler<span class="token operator">=</span><span class="token string">"constant"</span> <span class="token operator">-</span><span class="token operator">-</span>lr_warmup_steps<span class="token operator">=</span><span class="token number">0</span> \
  <span class="token operator">-</span><span class="token operator">-</span>seed<span class="token operator">=</span><span class="token number">42</span> \
  <span class="token operator">-</span><span class="token operator">-</span>output_dir<span class="token operator">=</span><span class="token string">"sd-pokemon-model-lora"</span> \
  <span class="token operator">-</span><span class="token operator">-</span>validation_prompt<span class="token operator">=</span><span class="token string">"cute dragon creature"</span>
</code></pre> 
<h4><a id="_381"></a>推理脚本：</h4> 
<pre><code class="prism language-python"><span class="token keyword">from</span> diffusers <span class="token keyword">import</span> StableDiffusionPipeline
<span class="token keyword">import</span> torch

model_path <span class="token operator">=</span> <span class="token string">"sd-pokemon-model-lora/checkpoint-10000"</span>
pipe <span class="token operator">=</span> StableDiffusionPipeline<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"stable-diffusion-2"</span><span class="token punctuation">,</span> torch_dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float16<span class="token punctuation">)</span>
pipe<span class="token punctuation">.</span>load_lora_weights<span class="token punctuation">(</span>model_path<span class="token punctuation">)</span>
pipe<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">"cuda"</span><span class="token punctuation">)</span>

prompt <span class="token operator">=</span> <span class="token string">"A pokemon with green eyes and red legs."</span>
image <span class="token operator">=</span> pipe<span class="token punctuation">(</span>prompt<span class="token punctuation">,</span> num_inference_steps<span class="token operator">=</span><span class="token number">30</span><span class="token punctuation">,</span> guidance_scale<span class="token operator">=</span><span class="token number">7.5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>images<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
image<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string">"pokemon.png"</span><span class="token punctuation">)</span>
</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/36cfa24e1485de311de39430ed9d7f59/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Java ByteBuffer使用全解析</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/953d95735d877e4b81648f7b5a9b9834/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">AI数字人训练数据集汇总</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>