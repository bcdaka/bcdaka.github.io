<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【机器学习】FFmpeg&#43;Whisper：二阶段法视频理解（video-to-text）大模型实战 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/99c772023130e505d048faf1631357a7/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="【机器学习】FFmpeg&#43;Whisper：二阶段法视频理解（video-to-text）大模型实战">
  <meta property="og:description" content="目录
一、引言
二、FFmpeg工具介绍
2.1 什么是FFmpeg
2.2 FFmpeg核心原理
2.3 FFmpeg使用示例
三、FFmpeg&#43;Whisper二阶段法视频理解实战
3.1 FFmpeg安装
3.2 Whisper模型下载
3.3 FFmpeg抽取视频的音频
3.3.1 方案一：命令行方式使用ffmpeg
3.3.2 方案二：ffmpeg-python库使用ffmpeg
3.4 Whisper将音频转为文本
3.5 视频理解完整代码
3.6 视频理解模型部署 四、总结
一、引言 上一篇对Whisper原理和实战进行了讲解，第7次拿到了热榜第一🏆。今天，我们在Whisper的基础上，引入ffmpeg工具对视频的音频进行抽取，再使用Whisper将音频转为文本，通过二阶段法实现视频内容的理解。
二、FFmpeg工具介绍 2.1 什么是FFmpeg FFmpeg是一个开源的跨平台多媒体处理工具，它可以处理音频/视频数据，包括转码、转换格式、分割、合并等操作。
2.2 FFmpeg核心原理 多媒体流的解析：FFmpeg能够解析各种常见的多媒体格式，包括MP4, MKV, AVI, MP3, OGG等，并将其转换为FFmpeg内部的统一表示格式，也就是所谓的复用格式（Container Format）和编码格式（Codec）。多媒体流的编码和解码：FFmpeg可以使用不同的编解码器来编码和解码音频/视频数据。例如，它可以使用H.264编码来压缩视频数据，使用AAC编码来压缩音频数据。过滤器（Filters）：FFmpeg提供了一个强大的过滤器系统，可以用来处理视频和音频的各种效果，例如裁剪、裁切、旋转、缩放等。流的复用和解复用：FFmpeg可以将多个音频/视频流合并为一个文件，也可以将一个文件分离成多个音频/视频流。并行处理：FFmpeg利用多线程技术，可以并行处理多个任务，比如同时进行多个转码操作。 2.3 FFmpeg使用示例 ffmpeg -i input.mp4 -vn -ar 44100 -ac 2 -ab 192k -f mp3 output.mp3 -i input.mp4 指定输入文件。-vn 表示禁用视频录制。-ar 44100 设置采样率为44.1kHz。-ac 2 设置声道数为2（立体声）。-ab 192k 设置比特率为192k。-f mp3 设置输出格式为MP3。output.mp3 是输出文件的名称。 三、FFmpeg&#43;Whisper二阶段法视频理解实战 3.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-07-01T20:39:26+08:00">
    <meta property="article:modified_time" content="2024-07-01T20:39:26+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【机器学习】FFmpeg&#43;Whisper：二阶段法视频理解（video-to-text）大模型实战</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p id="%E2%80%8B%E7%BC%96%E8%BE%91%E2%80%8B%E2%80%8B%E2%80%8B%E2%80%8B%E2%80%8B%E2%80%8B%E2%80%8B"><img alt="" height="754" src="https://images2.imgbox.com/f9/bb/Pu0mrinb_o.png" width="1200"></p> 
<p id="main-toc"><strong>目录</strong></p> 
<p id="%E4%B8%80%E3%80%81%E5%BC%95%E8%A8%80-toc" style="margin-left:0px;"><a href="#%E4%B8%80%E3%80%81%E5%BC%95%E8%A8%80" rel="nofollow">一、引言</a></p> 
<p id="%E4%BA%8C%E3%80%81%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B-toc" style="margin-left:0px;"><a href="#%E4%BA%8C%E3%80%81%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B" rel="nofollow">二、FFmpeg工具介绍</a></p> 
<p id="2.1%20VITS%20%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84-toc" style="margin-left:40px;"><a href="#2.1%20VITS%20%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84" rel="nofollow">2.1 什么是FFmpeg</a></p> 
<p id="2.2%20VITS%20%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83-toc" style="margin-left:40px;"><a href="#2.2%20VITS%20%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83" rel="nofollow">2.2 FFmpeg核心原理</a></p> 
<p id="2.3%C2%A0VITS%20%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86-toc" style="margin-left:40px;"><a href="#2.3%C2%A0VITS%20%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86" rel="nofollow">2.3 FFmpeg使用示例</a></p> 
<p id="%E4%B8%89%E3%80%81%E8%AE%AD%E7%BB%83%E4%B8%8E%E6%8E%A8%E7%90%86-toc" style="margin-left:0px;"><a href="#%E4%B8%89%E3%80%81%E8%AE%AD%E7%BB%83%E4%B8%8E%E6%8E%A8%E7%90%86" rel="nofollow">三、FFmpeg+Whisper二阶段法视频理解实战</a></p> 
<p id="3.1%20ChatTTS%20%E7%AE%80%E4%BB%8B-toc" style="margin-left:40px;"><a href="#3.1%20ChatTTS%20%E7%AE%80%E4%BB%8B" rel="nofollow">3.1 FFmpeg安装</a></p> 
<p id="3.2%20ChatTTS%20%E4%BA%AE%E7%82%B9-toc" style="margin-left:40px;"><a href="#3.2%20ChatTTS%20%E4%BA%AE%E7%82%B9" rel="nofollow">3.2 Whisper模型下载</a></p> 
<p id="3.3%20ChatTTS%20%E6%95%B0%E6%8D%AE%E9%9B%86%C2%A0-toc" style="margin-left:40px;"><a href="#3.3%20ChatTTS%20%E6%95%B0%E6%8D%AE%E9%9B%86%C2%A0" rel="nofollow">3.3 FFmpeg抽取视频的音频</a></p> 
<p id="3.3.1%C2%A0%E6%96%B9%E6%A1%88%E4%B8%80%EF%BC%9A%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%96%B9%E5%BC%8F%E4%BD%BF%E7%94%A8ffmpeg-toc" style="margin-left:80px;"><a href="#3.3.1%C2%A0%E6%96%B9%E6%A1%88%E4%B8%80%EF%BC%9A%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%96%B9%E5%BC%8F%E4%BD%BF%E7%94%A8ffmpeg" rel="nofollow">3.3.1 方案一：命令行方式使用ffmpeg</a></p> 
<p id="3.3.2%20%E6%96%B9%E6%A1%88%E4%BA%8C%EF%BC%9Affmpeg-python%E5%BA%93%E4%BD%BF%E7%94%A8ffmpeg-toc" style="margin-left:80px;"><a href="#3.3.2%20%E6%96%B9%E6%A1%88%E4%BA%8C%EF%BC%9Affmpeg-python%E5%BA%93%E4%BD%BF%E7%94%A8ffmpeg" rel="nofollow">3.3.2 方案二：ffmpeg-python库使用ffmpeg</a></p> 
<p id="3.4%C2%A0Whisper%20%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81-toc" style="margin-left:40px;"><a href="#3.4%C2%A0Whisper%20%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81" rel="nofollow">3.4 Whisper将音频转为文本</a></p> 
<p id="3.5%C2%A0Whisper%20%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2-toc" style="margin-left:40px;"><a href="#3.5%C2%A0Whisper%20%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2" rel="nofollow">3.5 视频理解完整代码</a></p> 
<p id="3.6%20%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2%C2%A0-toc" style="margin-left:40px;"><a href="#3.6%20%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2%C2%A0" rel="nofollow">3.6 视频理解模型部署 </a></p> 
<p id="%E5%9B%9B%E3%80%81%E6%80%BB%E7%BB%93-toc" style="margin-left:0px;"><a href="#%E5%9B%9B%E3%80%81%E6%80%BB%E7%BB%93" rel="nofollow">四、总结</a></p> 
<hr id="hr-toc"> 
<p></p> 
<h2 id="%E4%B8%80%E3%80%81%E5%BC%95%E8%A8%80">一、引言</h2> 
<p>上一篇对<a class="link-info" href="https://blog.csdn.net/weixin_48007632/article/details/140046145?spm=1001.2014.3001.5501" title="Whisper原理和实战">Whisper原理和实战</a>进行了讲解，第7次拿到了热榜第一🏆。今天，我们在Whisper的基础上，引入ffmpeg工具对视频的音频进行抽取，再使用Whisper将音频转为文本，通过二阶段法实现视频内容的理解。</p> 
<h2 id="%E4%BA%8C%E3%80%81%E6%A8%A1%E5%9E%8B%E7%AE%80%E4%BB%8B">二、FFmpeg工具介绍</h2> 
<h3 id="2.1%20VITS%20%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84">2.1 什么是FFmpeg</h3> 
<p>FFmpeg是一个开源的跨平台多媒体处理工具，它可以处理音频/视频数据，包括转码、转换格式、分割、合并等操作。</p> 
<h3 id="2.2%20VITS%20%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83">2.2 FFmpeg核心原理</h3> 
<blockquote> 
 <ul><li>多媒体流的解析：FFmpeg能够解析各种常见的多媒体格式，包括MP4, MKV, AVI, MP3, OGG等，并将其转换为FFmpeg内部的统一表示格式，也就是所谓的复用格式（Container Format）和编码格式（Codec）。</li><li>多媒体流的编码和解码：FFmpeg可以使用不同的编解码器来编码和解码音频/视频数据。例如，它可以使用H.264编码来压缩视频数据，使用AAC编码来压缩音频数据。</li><li>过滤器（Filters）：FFmpeg提供了一个强大的过滤器系统，可以用来处理视频和音频的各种效果，例如裁剪、裁切、旋转、缩放等。</li><li>流的复用和解复用：FFmpeg可以将多个音频/视频流合并为一个文件，也可以将一个文件分离成多个音频/视频流。</li><li>并行处理：FFmpeg利用多线程技术，可以并行处理多个任务，比如同时进行多个转码操作。</li></ul> 
</blockquote> 
<h3 id="2.3%C2%A0VITS%20%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86">2.3 FFmpeg使用示例</h3> 
<pre><code class="language-bash">ffmpeg -i input.mp4 -vn -ar 44100 -ac 2 -ab 192k -f mp3 output.mp3</code></pre> 
<blockquote> 
 <ul><li>-i input.mp4 指定输入文件。</li><li>-vn 表示禁用视频录制。</li><li>-ar 44100 设置采样率为44.1kHz。</li><li>-ac 2 设置声道数为2（立体声）。</li><li>-ab 192k 设置比特率为192k。</li><li>-f mp3 设置输出格式为MP3。</li><li>output.mp3 是输出文件的名称。 </li></ul> 
</blockquote> 
<h2 id="%E4%B8%89%E3%80%81%E8%AE%AD%E7%BB%83%E4%B8%8E%E6%8E%A8%E7%90%86">三、FFmpeg+Whisper二阶段法视频理解实战</h2> 
<h3 id="3.1%20ChatTTS%20%E7%AE%80%E4%BB%8B">3.1 FFmpeg安装</h3> 
<p>由于FFmpeg不支持pip安装，所以需要使用apt-get</p> 
<pre><code class="language-bash">sudo apt-get update &amp;&amp; apt-get install ffmpeg</code></pre> 
<h3 id="3.2%20ChatTTS%20%E4%BA%AE%E7%82%B9">3.2 Whisper模型下载</h3> 
<p>这里与上一篇一样，还是采用transformers的pipeline，首先创建conda环境以及安装transformers</p> 
<p>创建并激活conda环境：</p> 
<pre><code class="language-bash">conda create -n video2text python=3.11
conda activate video2text</code></pre> 
<p>安装transformers库： </p> 
<pre><code class="language-bash">pip install transformers -i https://mirrors.cloud.tencent.com/pypi/simple</code></pre> 
<p>基于transformers的pipeline会自动进行模型下载，当然，如果您的网速不行，请替换HF_ENDPOINT为国内镜像。</p> 
<pre><code class="language-python">os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"

transcriber = pipeline(task="automatic-speech-recognition", model="openai/whisper-medium")</code></pre> 
<p> 不同尺寸模型参数量、多语言支持情况、需要现存大小以及推理速度如下</p> 
<p><img alt="" height="490" src="https://images2.imgbox.com/70/a0/K9g9uR0X_o.png" width="1200"></p> 
<h3 id="3.3%20ChatTTS%20%E6%95%B0%E6%8D%AE%E9%9B%86%C2%A0">3.3 FFmpeg抽取视频的音频</h3> 
<h4 id="3.3.1%C2%A0%E6%96%B9%E6%A1%88%E4%B8%80%EF%BC%9A%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%96%B9%E5%BC%8F%E4%BD%BF%E7%94%A8ffmpeg">3.3.1 方案一：命令行方式使用ffmpeg</h4> 
<p>首先将ffmpeg命令放入ffmpeg_command，之后采用subprocess库的run方法执行ffmpeg_command内的命令。</p> 
<p>输入的视频文件为input_file，输出的音频文件为output_file。</p> 
<pre><code class="language-python">import subprocess
def extract_audio(input_file, output_file):
    """
    使用FFmpeg从MP4文件中提取音频并保存为MP3格式。

    :param input_file: 输入的MP4文件路径
    :param output_file: 输出的MP3文件路径
    """
    # 构建FFmpeg命令
    ffmpeg_command = [
        'ffmpeg', '-i', input_file, '-vn', '-acodec', 'libmp3lame', output_file
    ]

    try:
        # 执行命令
        subprocess.run(ffmpeg_command, check=True)
        print(f"音频已成功从 {input_file} 提取到 {output_file}")
    except subprocess.CalledProcessError as e:
        print(f"处理错误: {e}")</code></pre> 
<h4 id="3.3.2%20%E6%96%B9%E6%A1%88%E4%BA%8C%EF%BC%9Affmpeg-python%E5%BA%93%E4%BD%BF%E7%94%A8ffmpeg">3.3.2 方案二：ffmpeg-python库使用ffmpeg</h4> 
<p>首先安装ffmpeg-python：</p> 
<pre><code class="language-python"> pip install ffmpeg-python -i  https://mirrors.cloud.tencent.com/pypi/simple</code></pre> 
<p> 引入ffmpeg库，一行代码完成音频转文本</p> 
<pre><code class="language-python">import ffmpeg
def extract_audio(input_file, output_file):
    """
    使用FFmpeg从MP4文件中提取音频并保存为MP3格式。

    :param input_file: 输入的MP4文件路径
    :param output_file: 输出的MP3文件路径
    """

    try:
        # 执行命令
        ffmpeg.input(input_file).output(output_file, acodec="libmp3lame", ac=2, ar="44100").run()
        print(f"音频已成功从 {input_file} 提取到 {output_file}")
    except subprocess.CalledProcessError as e:
        print(f"处理错误: {e}")</code></pre> 
<h3 id="3.4%C2%A0Whisper%20%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81">3.4 Whisper将音频转为文本</h3> 
<pre><code class="language-python">from transformers import pipeline
def speech2text(speech_file):
    transcriber = pipeline(task="automatic-speech-recognition", model="openai/whisper-medium")
    text_dict = transcriber(speech_file)
    return text_dict</code></pre> 
<p>这里采用pipeline完成openai/whisper-medium的模型下载以及实例化，将音频文件输入实例化的transcriber对象即刻得到文本。</p> 
<h3 id="3.5%C2%A0Whisper%20%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2">3.5 视频理解完整代码</h3> 
<pre><code class="language-python">import os
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
os.environ["CUDA_VISIBLE_DEVICES"] = "2"
os.environ["TF_ENABLE_ONEDNN_OPTS"] = "0"

from transformers import pipeline
import subprocess

def speech2text(speech_file):
    transcriber = pipeline(task="automatic-speech-recognition", model="openai/whisper-medium")
    text_dict = transcriber(speech_file)
    return text_dict
def extract_audio(input_file, output_file):
    """
    使用FFmpeg从MP4文件中提取音频并保存为MP3格式。

    :param input_file: 输入的MP4文件路径
    :param output_file: 输出的MP3文件路径
    """
    # 构建FFmpeg命令
    ffmpeg_command = [
        'ffmpeg', '-i', input_file, '-vn', '-acodec', 'libmp3lame', output_file
    ]

    try:
        # 执行命令
        subprocess.run(ffmpeg_command, check=True)
        print(f"音频已成功从 {input_file} 提取到 {output_file}")
    except subprocess.CalledProcessError as e:
        print(f"处理错误: {e}")



import argparse
import json
def main():
    parser = argparse.ArgumentParser(description="视频转文本")
    parser.add_argument("--video","-v", type=str, help="输入视频文件路径")
    parser.add_argument("--audio","-a", type=str, help="输出音频文件路径")

    args = parser.parse_args()
    print(args) 

    extract_audio(args.video, args.audio)
    text_dict = speech2text(args.audio)
    print("视频内的文本是：\n" +  text_dict["text"])
    #print("视频内的文本是：\n"+ json.dumps(text_dict,indent=4))

if __name__=="__main__":
    main()</code></pre> 
<p>输出为：</p> 
<p><img alt="" height="1158" src="https://images2.imgbox.com/79/3d/ZOLfjBt9_o.png" width="1200"> </p> 
<h3 id="3.6%20%E8%A7%86%E9%A2%91%E7%90%86%E8%A7%A3%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2%C2%A0">3.6 视频理解模型部署 </h3> 
<p>如果想将该服务部署成语音识别API服务，可以参考之前的<a href="https://blog.csdn.net/weixin_48007632/article/details/139757328?spm=1001.2014.3001.5502" title="FastAPI相关文章">FastAPI相关文章</a>。</p> 
<h2 id="%E5%9B%9B%E3%80%81%E6%80%BB%E7%BB%93"><strong>四、总结</strong></h2> 
<p>本文在上一篇音频转文本的基础上，引入了视频转音频，这样可以采用二阶段法：先提取音频，再音频转文字的方法完成视频内容理解。之后可以配上LLM对视频内提取的文本进行一系列应用。</p> 
<p>希望可以帮到您，如果觉得有帮助的话，期待您的三连+投票！</p> 
<p></p> 
<p>如果您还有时间，可以看看我的其他文章：</p> 
<p>《AI—工程篇》</p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/138583814?spm=1001.2014.3001.5501" title="AI智能体研发之路-工程篇（一）：Docker助力AI智能体开发提效">AI智能体研发之路-工程篇（一）：Docker助力AI智能体开发提效</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/138543709?spm=1001.2014.3001.5501" title="AI智能体研发之路-工程篇（二）：Dify智能体开发平台一键部署">AI智能体研发之路-工程篇（二）：Dify智能体开发平台一键部署</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/138506272?spm=1001.2014.3001.5501" title="AI智能体研发之路-工程篇（三）：大模型推理服务框架Ollama一键部署">AI智能体研发之路-工程篇（三）：大模型推理服务框架Ollama一键部署</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/138531565?spm=1001.2014.3001.5501" title="AI智能体研发之路-工程篇（四）：大模型推理服务框架Xinference一键部署">AI智能体研发之路-工程篇（四）：大模型推理服务框架Xinference一键部署</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/138673899?spm=1001.2014.3001.5501" title="AI智能体研发之路-工程篇（五）：大模型推理服务框架LocalAI一键部署">AI智能体研发之路-工程篇（五）：大模型推理服务框架LocalAI一键部署</a></p> 
<p>《AI—模型篇》</p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/138819599?spm=1001.2014.3001.5501" title="AI智能体研发之路-模型篇（一）：大模型训练框架LLaMA-Factory在国内网络环境下的安装、部署及使用">AI智能体研发之路-模型篇（一）：大模型训练框架LLaMA-Factory在国内网络环境下的安装、部署及使用</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139131558?spm=1001.2014.3001.5501" title="AI智能体研发之路-模型篇（二）：DeepSeek-V2-Chat 训练与推理实战">AI智能体研发之路-模型篇（二）：DeepSeek-V2-Chat 训练与推理实战</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139219617?spm=1001.2014.3001.5502" title="AI智能体研发之路-模型篇（三）：中文大模型开、闭源之争">AI智能体研发之路-模型篇（三）：中文大模型开、闭源之争</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139237430?spm=1001.2014.3001.5502" title="AI智能体研发之路-模型篇（四）：一文入门pytorch开发">AI智能体研发之路-模型篇（四）：一文入门pytorch开发</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139249095?spm=1001.2014.3001.5502" title="AI智能体研发之路-模型篇（五）：pytorch vs tensorflow框架DNN网络结构源码级对比">AI智能体研发之路-模型篇（五）：pytorch vs tensorflow框架DNN网络结构源码级对比</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139263131?spm=1001.2014.3001.5502" title="AI智能体研发之路-模型篇（六）：【机器学习】基于tensorflow实现你的第一个DNN网络">AI智能体研发之路-模型篇（六）：【机器学习】基于tensorflow实现你的第一个DNN网络</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139307081?spm=1001.2014.3001.5502" title="AI智能体研发之路-模型篇（七）：【机器学习】基于YOLOv10实现你的第一个视觉AI大模型">AI智能体研发之路-模型篇（七）：【机器学习】基于YOLOv10实现你的第一个视觉AI大模型</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139422184?spm=1001.2014.3001.5501" title="AI智能体研发之路-模型篇（八）：【机器学习】Qwen1.5-14B-Chat大模型训练与推理实战">AI智能体研发之路-模型篇（八）：【机器学习】Qwen1.5-14B-Chat大模型训练与推理实战</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139497336?spm=1001.2014.3001.5502" title="AI智能体研发之路-模型篇（九）：【机器学习】GLM4-9B-Chat大模型/GLM-4V-9B多模态大模型概述、原理及推理实战">AI智能体研发之路-模型篇（九）：【机器学习】GLM4-9B-Chat大模型/GLM-4V-9B多模态大模型概述、原理及推理实战</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139564359?spm=1001.2014.3001.5501" title="AI智能体研发之路-模型篇（十）：【机器学习】Qwen2大模型原理、训练及推理部署实战">AI智能体研发之路-模型篇（十）：【机器学习】Qwen2大模型原理、训练及推理部署实战</a></p> 
<p>《AI—Transformers应用》</p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139478765?spm=1001.2014.3001.5502" title="【AI大模型】Transformers大模型库（一）：Tokenizer">【AI大模型】Transformers大模型库（一）：Tokenizer</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139481089?spm=1001.2014.3001.5502" title="【AI大模型】Transformers大模型库（二）：AutoModelForCausalLM">【AI大模型】Transformers大模型库（二）：AutoModelForCausalLM</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139481581?spm=1001.2014.3001.5502" title="【AI大模型】Transformers大模型库（三）：特殊标记（special tokens）">【AI大模型】Transformers大模型库（三）：特殊标记（special tokens）</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139483010?spm=1001.2014.3001.5502" title="【AI大模型】Transformers大模型库（四）：AutoTokenizer">【AI大模型】Transformers大模型库（四）：AutoTokenizer</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632?spm=1011.2415.3001.5343" title="【AI大模型】Transformers大模型库（五）：AutoModel、Model Head及查看模型结构">【AI大模型】Transformers大模型库（五）：AutoModel、Model Head及查看模型结构</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139584579?spm=1001.2014.3001.5501" title="【AI大模型】Transformers大模型库（六）：torch.cuda.OutOfMemoryError: CUDA out of memory解决">【AI大模型】Transformers大模型库（六）：torch.cuda.OutOfMemoryError: CUDA out of memory解决</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139607194?spm=1001.2014.3001.5501" title="【AI大模型】Transformers大模型库（七）：单机多卡推理之device_map">【AI大模型】Transformers大模型库（七）：单机多卡推理之device_map</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139611462?spm=1001.2014.3001.5501" title="【AI大模型】Transformers大模型库（八）：大模型微调之LoraConfig">【AI大模型】Transformers大模型库（八）：大模型微调之LoraConfig</a> </p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/955157d72d038f8ecce95c5dcb59bd0b/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">AI在创造还是毁掉音乐？</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/75991fe33085af10ca6d8f5c8a772ac0/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【Llama 2的使用方法】</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>