<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>无需抠图！AI绘画直接文本生成透明底图层，设计师必看的ComfyUI透明图层生成工作流教程！（附插件模型） - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/d1b34f428a262b74e775aa80fe8585cb/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="无需抠图！AI绘画直接文本生成透明底图层，设计师必看的ComfyUI透明图层生成工作流教程！（附插件模型）">
  <meta property="og:description" content="大家好，我是画画的小强
AI 绘画自出现以来一直都在不断发展完善，实现了很多我们在实际应用中迫切需要的功能，比如生成正确的手指、指定的姿势、准确的文本内容等。上周，又一个重磅新功能在开源的 SD 生态内实现了——直接通过文本直接生成透明底图像和图层！这将为 AI 绘画和设计领域带来了新的可能性，使图像形式更多样，也能给设计师带来更多便利。
今天我们就一起来了解实现这一新功能的技术 LayerDiffusion，以及如何在 ComfyUI 中利用 LayerDiffusion 生成透明底图片。
一、 LayerDiffusion 简介 LayerDiffusion 是由 @ lllyasviel （没错就是那个开发出 Controlnet、Fooocus 和 SD WebUI Forge 的大神）最新推出的一种透明图像生成技术，它的核心所在是“潜在透明度”，即将 Alpha 通道整合到预训练模型的潜在结构中，使模型能够生成带有透明度的图。
官方给出的演示案例效果非常好，不仅可以生成一般物体，而且对于玻璃、发光这种透明/半透明的对象，以及头发丝这种精细的内容，生成的效果依旧完美。本文章封面图的卷发女生就是我直接用 LayerDiffusion 生成的，极大提升了出图效率，而且真正做到了“毫无抠图痕迹”，再也不用担心有白边了。
除了直接生成透明底图像，LayerDiffusion 还支持生成分层图像。包括根据一个透明底图像生成完美融合的背景，并将该背景提取为完整独立的图层；以及根据背景图像&#43;提示词生成前景主体，并将该主体提取为透明底图层。
目前 SD WebUI Forge 和 ComfyUI 已经支持 LayerDiffusion 的透明底功能，并且在未来还将支持通过图像生成透明底图像，下面为大家介绍如何在这 2 款工具中实现对应的功能。
在 ComfyUI 中使用 LayerDiffusion ① 安装插件
ComfyUI-layerdiffuse 插件 git 网址： https://github.com/huchenlei/ComfyUI-layerdiffuse.git
（如无法下载，请扫描免费获取 Layerdiffuse 插件安装包哦）
首先将 ComfyUI 更新到最新版本。然后安装 layerdiffuse 插件，可以用过 manager 安装，也可以进入根目录的 custom_nodes 文件夹中，通过 git clone 命令安装；安装成功后，进入 ComfyUI-layerdiffuse 根目录，打开终端命令，运行 pip install -r requirements.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-07-23T14:16:18+08:00">
    <meta property="article:modified_time" content="2024-07-23T14:16:18+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">无需抠图！AI绘画直接文本生成透明底图层，设计师必看的ComfyUI透明图层生成工作流教程！（附插件模型）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>大家好，我是画画的小强</p> 
<p>AI 绘画自出现以来一直都在不断发展完善，实现了很多我们在实际应用中迫切需要的功能，比如生成正确的手指、指定的姿势、准确的文本内容等。上周，又一个重磅新功能在开源的 SD 生态内实现了——直接通过文本直接生成透明底图像和图层！这将为 AI 绘画和设计领域带来了新的可能性，使图像形式更多样，也能给设计师带来更多便利。</p> 
<p><strong>今天我们就一起来了解实现这一新功能的技术 LayerDiffusion，以及如何在 ComfyUI 中利用 LayerDiffusion 生成透明底图片。</strong></p> 
<h3><a id="_LayerDiffusion__7"></a>一、 LayerDiffusion 简介</h3> 
<p>LayerDiffusion 是由 @ lllyasviel （没错就是那个开发出 Controlnet、Fooocus 和 SD WebUI Forge 的大神）最新推出的一种透明图像生成技术，它的核心所在是“潜在透明度”，即将 Alpha 通道整合到预训练模型的潜在结构中，使模型能够生成带有透明度的图。</p> 
<p>官方给出的演示案例效果非常好，不仅可以生成一般物体，而且对于玻璃、发光这种透明/半透明的对象，以及头发丝这种精细的内容，生成的效果依旧完美。本文章封面图的卷发女生就是我直接用 LayerDiffusion 生成的，极大提升了出图效率，而且真正做到了“毫无抠图痕迹”，再也不用担心有白边了。</p> 
<p><img src="https://images2.imgbox.com/d8/14/l6pkQeH8_o.png" alt="在这里插入图片描述"></p> 
<p>除了直接生成透明底图像，LayerDiffusion 还支持生成分层图像。包括根据一个透明底图像生成完美融合的背景，并将该背景提取为完整独立的图层；以及根据背景图像+提示词生成前景主体，并将该主体提取为透明底图层。</p> 
<p><img src="https://images2.imgbox.com/4d/2b/liuCQ8Ko_o.png" alt="在这里插入图片描述"></p> 
<p>目前 SD WebUI Forge 和 ComfyUI 已经支持 LayerDiffusion 的透明底功能，并且在未来还将支持通过图像生成透明底图像，下面为大家介绍如何在这 2 款工具中实现对应的功能。</p> 
<h3><a id="_ComfyUI__LayerDiffusion_23"></a>在 ComfyUI 中使用 LayerDiffusion</h3> 
<p><strong>① 安装插件</strong></p> 
<p>ComfyUI-layerdiffuse 插件 git 网址： https://github.com/huchenlei/ComfyUI-layerdiffuse.git<br> （如无法下载，请扫描免费获取 Layerdiffuse 插件安装包哦）<br> <img src="https://images2.imgbox.com/9b/df/FTMIb7jZ_o.png"></p> 
<p>首先将 ComfyUI 更新到最新版本。然后安装 layerdiffuse 插件，可以用过 manager 安装，也可以进入根目录的 custom_nodes 文件夹中，通过 git clone 命令安装；安装成功后，进入 ComfyUI-layerdiffuse 根目录，打开终端命令，运行 pip install -r requirements.txt 命令，安装 python 依赖项。<br> <img src="https://images2.imgbox.com/cd/4d/4MZ6fjXH_o.png" alt="在这里插入图片描述"></p> 
<p><strong>② 安装模型</strong></p> 
<p>LayerDiffusion 处理模型下载： https://huggingface.co/LayerDiffusion/layerdiffusion-v1/tree/main （如无法下载，请看上方扫描免费获取 LayerDiffusion 的处理模型）</p> 
<p>ComfyUI-layerdiffuse 插件目前仅支持 SDXL 模型，选择大模型时需要注意；此外还需要下载 LayerDiffusion 处理模型，安装到根目录的 models\layer_model 文件夹中。<br> <img src="https://images2.imgbox.com/88/44/iGi9Ta8C_o.png" alt="在这里插入图片描述"><br> <strong>③ 加载工作流</strong></p> 
<p>插件官方提供了 7 种工作流，全部存放在 custom_nodes\ComfyUI-layerdiffuse\examples 文件夹中，可以实现生成透明底图像、通过背景图像生成透明底前景、通过透明底前景生成完整背景等操作；我也进一步整理了这些文件，打包资源在网盘内（请扫描免费获取哦）。</p> 
<p>启动 ComfyUI 界面后，可以用 workspace 插件一次性将整个工作流文件夹导入 ComfyUI 中。<br> <img src="https://images2.imgbox.com/af/41/rJANCkIi_o.png" alt="在这里插入图片描述"></p> 
<p><strong>④ 直接生成透明底图像</strong></p> 
<p>layer_diffusion_fg_example_rgba 和 layer_diffusion_fg_example 两个工作流都可以生成透明底图像，且第二个工作流可以额外生成一个 Alpha 通道蒙版。<br> <img src="https://images2.imgbox.com/72/ca/K3JQQ4tw_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/bd/51/EeJH3mul_o.png" alt="在这里插入图片描述"><br> <strong>⑤ 生成前景&amp;生成背景</strong></p> 
<p>layer_diffusion_cond_example 工作流可以同时实现 “根据透明底前景生成背景” 和 “根据背景透明底前景” ，使用时注意在 Layer Diffuse Cond Apply 节点中对应地将 layer_type 调节成 foreground 或者 background。<br> <img src="https://images2.imgbox.com/fb/40/a2l7P4yc_o.png" alt="在这里插入图片描述"></p> 
<p><strong>⑥ 提取完整背景</strong></p> 
<p>在根据一个透明底图像生成背景后，可以通过 layer_diffusion_diff_bg 工作流提取一个完整的背景图层。主体在提示词中完整描述背景内容，采样器需要选择 Euler A 或者 Uni_pc。<br> <img src="https://images2.imgbox.com/1e/8c/q9VBdnSY_o.png" alt="在这里插入图片描述"></p> 
<p><strong>⑦ 提取前景图层</strong></p> 
<p>在一个背景图中生成一个新的主体后，可以再通过 layer_diffusion_diff_fg 工作流将主体提取为透明底图层。注意修改提示词，采样器依旧选择 Euler A 或者 Uni_pc。<br> <img src="https://images2.imgbox.com/c9/d2/MU2oCr5a_o.png" alt="在这里插入图片描述"></p> 
<p><font face="幼圆" size="4" color="red">感兴趣的小伙伴，赠送全套AIGC学习资料，包含AI绘画、AI人工智能等前沿科技教程和软件工具，具体看这里。<br> </font><br> <img src="https://images2.imgbox.com/df/df/4SgdMODU_o.png"></p> 
<p>AIGC技术的未来发展前景广阔，随着人工智能技术的不断发展，AIGC技术也将不断提高。未来，AIGC技术将在游戏和计算领域得到更广泛的应用，使游戏和计算系统具有更高效、更智能、更灵活的特性。同时，AIGC技术也将与人工智能技术紧密结合，在更多的领域得到广泛应用，对程序员来说影响至关重要。未来，AIGC技术将继续得到提高，同时也将与人工智能技术紧密结合，在更多的领域得到广泛应用。<br>  <br> <img src="https://images2.imgbox.com/3e/27/xd9CpJhE_o.png" alt="在这里插入图片描述"></p> 
<p><strong>一、AIGC所有方向的学习路线</strong></p> 
<p>AIGC所有方向的技术点做的整理，形成各个领域的知识点汇总，它的用处就在于，你可以按照下面的知识点去找对应的学习资源，保证自己学得较为全面。</p> 
<p><img src="https://images2.imgbox.com/30/06/ilsbCdfL_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/6d/be/oSNNKHwV_o.png" alt="在这里插入图片描述"></p> 
<p><strong>二、AIGC必备工具</strong></p> 
<p>工具都帮大家整理好了，安装就可直接上手！<br> <img src="https://images2.imgbox.com/92/a0/RrrIha7o_o.png" alt="在这里插入图片描述"></p> 
<p><strong>三、最新AIGC学习笔记</strong></p> 
<p>当我学到一定基础，有自己的理解能力的时候，会去阅读一些前辈整理的书籍或者手写的笔记资料，这些笔记详细记载了他们对一些技术点的理解，这些理解是比较独到，可以学到不一样的思路。<br> <img src="https://images2.imgbox.com/85/84/tCW1Wnzq_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/cf/b8/LRTDl0Nt_o.png" alt="在这里插入图片描述"></p> 
<p><strong>四、AIGC视频教程合集</strong></p> 
<p>观看全面零基础学习视频，看视频学习是最快捷也是最有效果的方式，跟着视频中老师的思路，从基础到深入，还是很容易入门的。</p> 
<p><img src="https://images2.imgbox.com/c2/69/jXML2aXv_o.png" alt="在这里插入图片描述"></p> 
<p><strong>五、实战案例</strong></p> 
<p>纸上得来终觉浅，要学会跟着视频一起敲，要动手实操，才能将自己的所学运用到实际当中去，这时候可以搞点实战案例来学习。<br> <img src="https://images2.imgbox.com/e4/fa/sxC90LyO_o.png" alt="在这里插入图片描述"></p> 
<img src="https://images2.imgbox.com/9b/c6/XBoDIaMQ_o.png"> 若有侵权，请联系删除
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/10e5ec0603fe03ea7ccdcbfcea3262ed/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【自然语言处理（NLP）】基本概念和应用</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/4f2525b788138d053080f5e126c502ae/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">服务器选择租用还是托管？托管和租用哪个比较划算</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>