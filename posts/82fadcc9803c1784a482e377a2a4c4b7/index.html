<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>OpenAI Whisper 语音转文本实验 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/82fadcc9803c1784a482e377a2a4c4b7/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="OpenAI Whisper 语音转文本实验">
  <meta property="og:description" content="为了实现语音方式与大语言模型的对话，需要使用语音识别（Voice2Text）和语音输出（Text2Voice）。感觉这项技术已比较成熟了，国内也有许多的机构开发这项技术，但是像寻找一个方便测试的技术居然还不容易。Google 墙了，微软需要注册，而国内的资料很少，最后选择了OpenAI 的Whisper。
Whisper 简介 Whisper是OpenAI于2022年12月发布的语音处理系统。它以英语为主，支持99种语言，包括中文。
提供了从tiny到large，从小到大的五种规格模型，适合不同场景。
Large 模型有2.88G，Basic 模型大约几百M。测试下来，Large 模型比较慢，Basic比较快。
Whisper 安装 pip install openai-whisper 安装 ffmpeg whisper 要使用ffmpeg 程序，在windows 的PowerShell 下安装的方式：
choco install ffmpeg 其它一些模块的安装 测试的语音文件 在网络上找中文的语音文件好像不太容易，不是收费，就是文不对题，在github 上找了一个英文的语音样文件。
audio-samples.github.io
Whisper 语音转文本 import whisper print(&#34;Start....&#34;) whisper_model = whisper.load_model(&#34;large&#34;) print(&#34;Begine...&#34;) result = whisper_model.transcribe(&#34;E:/yao2024/sample-0.wav&#34;,language=&#39;en&#39;) print(&#34;, &#34;.join([i[&#34;text&#34;] for i in result[&#34;segments&#34;] if i is not None])) 程序运行时要下载相关的模型数据，花费一段时间 Langchain 语音助手 Langchain 有语音助手链，它使用pyttsx3和speech_recognition库分别将文本转换为语音和语音转换为文本。
speech_recognition 是一个语音识别引擎，它可以调用多个语音识别的API ，其中包括:
CMU Sphinx (works offline)
Google Speech Recognition">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-05-14T19:08:00+08:00">
    <meta property="article:modified_time" content="2024-05-14T19:08:00+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">OpenAI Whisper 语音转文本实验</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/3c/78/7iNYLYaM_o.png"></p> 
<p>           为了实现语音方式与大语言模型的对话，需要使用语音识别（Voice2Text）和语音输出（Text2Voice）。感觉这项技术已比较成熟了，国内也有许多的机构开发这项技术，但是像寻找一个方便测试的技术居然还不容易。Google 墙了，微软需要注册，而国内的资料很少，最后选择了OpenAI 的Whisper。</p> 
<h3> Whisper 简介</h3> 
<p>        Whisper是OpenAI于2022年12月发布的语音处理系统。它以英语为主，支持99种语言，包括中文。</p> 
<p>   提供了从tiny到large，从小到大的五种规格模型，适合不同场景。</p> 
<p>Large 模型有2.88G，Basic 模型大约几百M。测试下来，Large 模型比较慢，Basic比较快。</p> 
<h4>Whisper 安装</h4> 
<pre><code class="language-bash">pip install   openai-whisper</code></pre> 
<h4>安装 ffmpeg</h4> 
<p> whisper 要使用ffmpeg 程序，在windows 的PowerShell 下安装的方式：</p> 
<pre><code class="language-bash">choco install ffmpeg</code></pre> 
<h4>其它一些模块的安装</h4> 
<p></p> 
<h4>测试的语音文件</h4> 
<p>在网络上找中文的语音文件好像不太容易，不是收费，就是文不对题，在github 上找了一个英文的语音样文件。</p> 
<p><a class="link-info" href="https://github.com/audio-samples/audio-samples.github.io" title="audio-samples.github.io">audio-samples.github.io</a></p> 
<h3> Whisper 语音转文本</h3> 
<pre><code class="language-python">import whisper
print("Start....")
whisper_model = whisper.load_model("large")
print("Begine...")
result = whisper_model.transcribe("E:/yao2024/sample-0.wav",language='en')
print(", ".join([i["text"] for i in result["segments"] if i is not None]))</code></pre> 
<p>程序运行时要下载相关的模型数据，花费一段时间 </p> 
<h3>Langchain 语音助手</h3> 
<p>        Langchain 有语音助手链，它使用<code>pyttsx3</code>和<code>speech_recognition</code>库分别将文本转换为语音和语音转换为文本。</p> 
<h4><code>speech_recognition</code></h4> 
<p><code>是一个语音识别引擎，它可以调用多个语音识别的API ，其中包括:</code></p> 
<ul><li> <p><a href="http://cmusphinx.sourceforge.net/wiki/" rel="nofollow" title="CMU Sphinx">CMU Sphinx</a> (works offline)</p> </li><li> <p>Google Speech Recognition</p> </li><li> <p><a href="https://cloud.google.com/speech/" rel="nofollow" title="Google Cloud Speech API">Google Cloud Speech API</a></p> </li><li> <p><a href="https://wit.ai/" rel="nofollow" title="Wit.ai">Wit.ai</a></p> </li><li> <p><a href="https://azure.microsoft.com/en-us/services/cognitive-services/speech/" rel="nofollow" title="Microsoft Azure Speech">Microsoft Azure Speech</a></p> </li><li> <p><a href="https://www.microsoft.com/cognitive-services/en-us/speech-api" rel="nofollow" title="Microsoft Bing Voice Recognition (Deprecated)">Microsoft Bing Voice Recognition (Deprecated)</a></p> </li><li> <p><a href="https://houndify.com/" rel="nofollow" title="Houndify API">Houndify API</a></p> </li><li> <p><a href="http://www.ibm.com/smarterplanet/us/en/ibmwatson/developercloud/speech-to-text.html" rel="nofollow" title="IBM Speech to Text">IBM Speech to Text</a></p> </li><li> <p><a href="https://snowboy.kitt.ai/" rel="nofollow" title="Snowboy Hotword Detection">Snowboy Hotword Detection</a> (works offline)</p> </li><li> <p><a href="https://www.tensorflow.org/" rel="nofollow" title="Tensorflow">Tensorflow</a></p> </li><li> <p><a href="https://github.com/alphacep/vosk-api/" title="Vosk API">Vosk API</a> (works offline)</p> </li><li> <p><a href="https://github.com/openai/whisper" title="OpenAI whisper">OpenAI whisper</a> (works offline)</p> </li><li> <p><a href="https://platform.openai.com/docs/guides/speech-to-text" rel="nofollow" title="Whisper API">Whisper API</a></p> </li></ul> 
<p> 我们选择了OpenAI_whisper 离线方式。</p> 
<h3>实验程序</h3> 
<h4>pyttsx3 的实验</h4> 
<pre><code>import pyttsx3
#语音播放 
pyttsx3.speak("How are you?")
pyttsx3.speak("I am fine, thank you")
pyttsx3.speak("太行,王屋二山，方七百里，高万仞，本在冀州之南，河阳之北。")</code></pre> 
<p>对话程序</p> 
<pre><code class="language-python">import  speech_recognition  as sr
import pyttsx3
from langchain.chat_models import ErnieBotChat
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain.memory import ConversationBufferWindowMemory
llm= ErnieBotChat(model_name='ERNIE-Bot', #ERNIE-Bot
                    ernie_client_id='FAiHIjSQqH5gAhET3sHNTkiH',
                    ernie_client_secret='wlIBmWY4d2Zvrs0GyQbT3JeTXV6kdub4',
                    temperature=0.75,
                    )
template = """Assistant is a large language model trained by OpenAI.
Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.
Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.
Overall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.
Assistant is aware that human input is being transcribed from audio and as such there may be some errors in the transcription. It will attempt to account for some words being swapped with similar-sounding words or phrases. Assistant will also keep responses concise, because human attention spans are more limited over the audio channel since it takes time to listen to a response.
{history}
Human: {human_input}
Assistant:"""
prompt = PromptTemplate(
    input_variables=["history", "human_input"],
    template=template
)
chatgpt_chain = LLMChain(
    llm=llm,
    prompt=prompt,
    verbose=True,
    memory=ConversationBufferWindowMemory(k=2),
)

engine = pyttsx3.init()


# 定义一个函数用于监听麦克风输入并进行处理
def listen():
    r = sr.Recognizer()
    with sr.Microphone() as source:
        print('校准中...')
        r.adjust_for_ambient_noise(source, duration=10)
        # 可选参数，用于调整麦克风灵敏度
       #  r.energy_threshold = 200
        r.pause_threshold=0.5
        print('好的，开始吧！')
        while (1):
            text = ''
            print('正在倾听...')
            try:
                audio = r.listen(source, timeout=10)
                print('识别中...')
                # 进行语音识别
                text = r.recognize_whisper(audio)
                print(text)
            except Exception as e:
                unrecognized_speech_text = f'抱歉，我没听清楚。错误信息: {e}s'
                text = unrecognized_speech_text
            print(text)
            # 使用语言模型生成对话回复
            response_text = chatgpt_chain.predict(human_input=text)
            print(response_text)
            # 使用语音合成引擎将回复转换为语音并播放
            engine.say(response_text)
            engine.runAndWait()


listen()</code></pre> 
<p>讲英文，回答英文，讲中文它会回答中文，但是识别同音字效果并不好。不知道如何提高同音字识别效果</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/5ff9bcea55aeebc2db68105dff356e7b/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Mac M3 Pro 通过 VMWare Fusion 安装 Windows 11（UUP下载）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/8b1dfc2c015421b63619ed4aa8d1b9dc/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Kimi智能助手：你的全天候AI伙伴</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>