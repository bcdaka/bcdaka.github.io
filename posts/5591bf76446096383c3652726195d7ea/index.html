<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>从头开始搭建 Langchain-Chatchat 0.3x - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/5591bf76446096383c3652726195d7ea/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="从头开始搭建 Langchain-Chatchat 0.3x">
  <meta property="og:description" content="github代码库链接 Langchain-Chatchathttps://github.com/chatchat-space/Langchain-Chatchat
inferencehttps://github.com/xorbitsai/inference 本文将会用到两个代码库 第一个代码库是启动chatchat使用。 第二个代码库是加载推理模型使用。 安装Xinference 首先新建虚拟环境, 然后通过pip安装
pip install &#34;xinference[all]&#34; 启动方式 xinference-local --host 0.0.0.0 --port 8887 通过浏览器打开会看到这样一个界面
launch model 会自动下载模型文件，默认是从hugging face下载，如果网络不通可以更改到ModelScope。也可以添加本地模型 添加注册模型 点击resgister model 填写model name 自己随便起一个名字就好了 模型介绍 可写可不写 按照截图勾选即可 选择你下载到本地的大模型基座 填写本地大模型的实际路径 register mdoel 点击注册 glm4-chat模型下载国内可以去魔塔社区下载：
魔搭社区汇聚各领域最先进的机器学习模型，提供模型探索体验、推理、训练、部署和应用的一站式服务。https://www.modelscope.cn/models/ZhipuAI/glm-4-9b
打开网址复制名字，以glm4为例，按照下面代码操作可以指定下载目录。
pip install modelscope from modelscope import snapshot_download download_dir = r&#39;D:\mycode\MachineLearningPractice-main\modelscope_download&#39; model_dir = snapshot_download(&#34;ZhipuAI/glm-4-9b-chat&#34;, cache_dir=download_dir) 魔塔下载模型详细文档信息：魔搭社区汇聚各领域最先进的机器学习模型，提供模型探索体验、推理、训练、部署和应用的一站式服务。https://www.modelscope.cn/docs/%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%8B%E8%BD%BD
启动模型 点击launch model点击custom models点击language mdels 然后我们就会看到我们刚刚注册的大模型信息
点击卡片--右边弹出信息
选择推理模型引擎是否量化选择gpu or cpu小火箭启动模型API 点击Running ModelLANGUAGE MODELS 即可查看到我们启动的模型">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-07-04T20:43:14+08:00">
    <meta property="article:modified_time" content="2024-07-04T20:43:14+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">从头开始搭建 Langchain-Chatchat 0.3x</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h3></h3> 
<h3>github代码库链接</h3> 
<p></p> 
<p><a class="has-card" href="https://github.com/chatchat-space/Langchain-Chatchat" title="Langchain-Chatchat"><span class="link-card-box"><span class="link-title">Langchain-Chatchat</span><span class="link-link"><img class="link-link-icon" src="https://images2.imgbox.com/c5/5f/NeL2syJ2_o.png" alt="icon-default.png?t=N7T8">https://github.com/chatchat-space/Langchain-Chatchat</span></span></a></p> 
<h3><a class="has-card" href="https://github.com/xorbitsai/inference" title="inference"><span class="link-card-box"><span class="link-title">inference</span><span class="link-link"><img class="link-link-icon" src="https://images2.imgbox.com/a9/9b/5yQjWG5H_o.png" alt="icon-default.png?t=N7T8">https://github.com/xorbitsai/inference</span></span></a></h3> 
<blockquote> 
 <h3><strong>本文将会用到两个代码库</strong></h3> 
 <h3><strong>第一个代码库是启动chatchat使用。</strong></h3> 
 <h3><strong>第二个代码库是加载推理模型使用。</strong></h3> 
</blockquote> 
<h2>安装Xinference</h2> 
<p>首先新建虚拟环境, 然后通过pip安装</p> 
<pre><code class="language-python">pip install "xinference[all]"</code></pre> 
<h3>启动方式</h3> 
<pre><code class="language-python">xinference-local --host 0.0.0.0 --port 8887</code></pre> 
<p>通过浏览器打开会看到这样一个界面</p> 
<p><img alt="" height="872" src="https://images2.imgbox.com/dc/c5/BWftzWmD_o.png" width="1200"></p> 
<h3>launch model 会自动下载模型文件，默认是从hugging face下载，如果网络不通可以更改到ModelScope。也可以添加本地模型</h3> 
<h3>添加注册模型</h3> 
<p></p> 
<ol><li> <h6><strong>点击resgister model</strong></h6> </li><li> <h6><strong> 填写model name 自己随便起一个名字就好了</strong></h6> </li><li> <h6><strong>模型介绍 可写可不写</strong></h6> </li><li> <h6><strong>按照截图勾选即可</strong></h6> </li><li> <h6><strong>选择你下载到本地的大模型基座</strong></h6> </li><li> <h6><strong>填写本地大模型的实际路径</strong></h6> </li><li> <h6><strong>register mdoel 点击注册</strong></h6> </li></ol> 
<h3></h3> 
<p></p> 
<p><img alt="" height="858" src="https://images2.imgbox.com/c6/8c/abNEwtp3_o.png" width="1200"></p> 
<p><img alt="" height="742" src="https://images2.imgbox.com/c5/f3/MKpXsC1J_o.png" width="1200"></p> 
<p><img alt="" height="484" src="https://images2.imgbox.com/3f/f8/9I96Qatt_o.png" width="1200"></p> 
<p><strong>glm4-chat模型下载国内可以去魔塔社区下载：</strong></p> 
<p><a class="has-card" href="https://www.modelscope.cn/models/ZhipuAI/glm-4-9b" rel="nofollow" title="魔搭社区"><span class="link-card-box"><span class="link-title">魔搭社区</span><span class="link-desc">汇聚各领域最先进的机器学习模型，提供模型探索体验、推理、训练、部署和应用的一站式服务。</span><span class="link-link"><img class="link-link-icon" src="https://images2.imgbox.com/96/a0/LIxBJt63_o.png" alt="icon-default.png?t=N7T8">https://www.modelscope.cn/models/ZhipuAI/glm-4-9b</span></span></a><img alt="" height="568" src="https://images2.imgbox.com/7b/54/ymBMmnqn_o.png" width="1200"></p> 
<p>打开网址复制名字，以glm4为例，按照下面代码操作可以指定下载目录。</p> 
<pre><code class="language-bash">pip install modelscope</code></pre> 
<pre><code class="language-python">from modelscope import snapshot_download
download_dir = r'D:\mycode\MachineLearningPractice-main\modelscope_download'
model_dir = snapshot_download("ZhipuAI/glm-4-9b-chat", cache_dir=download_dir)
</code></pre> 
<p><img alt="" height="602" src="https://images2.imgbox.com/d4/a2/cnb7eCmu_o.png" width="674"></p> 
<p>魔塔下载模型详细文档信息：<a class="has-card" href="https://www.modelscope.cn/docs/%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%8B%E8%BD%BD" rel="nofollow" title="魔搭社区"><span class="link-card-box"><span class="link-title">魔搭社区</span><span class="link-desc">汇聚各领域最先进的机器学习模型，提供模型探索体验、推理、训练、部署和应用的一站式服务。</span><span class="link-link"><img class="link-link-icon" src="https://images2.imgbox.com/0e/f2/LYd1PYC5_o.png" alt="icon-default.png?t=N7T8">https://www.modelscope.cn/docs/%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%8B%E8%BD%BD</span></span></a></p> 
<p></p> 
<h3>启动模型</h3> 
<ol><li>点击launch model</li><li>点击custom models</li><li>点击language mdels</li></ol> 
<p>然后我们就会看到我们刚刚注册的大模型信息</p> 
<p><img alt="" height="810" src="https://images2.imgbox.com/bb/57/eWmK61tl_o.png" width="1200"></p> 
<p></p> 
<p>点击卡片--右边弹出信息</p> 
<ol><li>选择推理模型引擎</li><li>是否量化</li><li>选择gpu or cpu</li><li>小火箭启动模型API</li></ol> 
<p></p> 
<p><img alt="" height="891" src="https://images2.imgbox.com/60/eb/f9nkCkr5_o.png" width="1200"></p> 
<p></p> 
<ol><li>点击Running Model</li><li>LANGUAGE MODELS</li></ol> 
<p>即可查看到我们启动的模型</p> 
<p><img alt="" height="614" src="https://images2.imgbox.com/f5/ff/WESfDXdS_o.png" width="1200"></p> 
<ol><li>Actions-向上箭头 ↑即可打开模型推理界面</li><li>右边垃圾桶 即关闭运行的模型</li></ol> 
<p><img alt="" height="396" src="https://images2.imgbox.com/68/2a/FBUFMRUi_o.png" width="1200"></p> 
<p><img alt="" height="849" src="https://images2.imgbox.com/9d/76/Q1eiZuzd_o.png" width="1200"></p> 
<p></p> 
<h3>同理我们在注册一个embedding model</h3> 
<p><img alt="" height="778" src="https://images2.imgbox.com/80/b7/vDcbnwag_o.png" width="1200"></p> 
<p><img alt="" height="752" src="https://images2.imgbox.com/a9/87/lw3v9ZgI_o.png" width="1200"></p> 
<p><img alt="" height="852" src="https://images2.imgbox.com/65/ea/jo6bPeIS_o.png" width="1200"></p> 
<p><img alt="" height="521" src="https://images2.imgbox.com/5a/f6/H6auJQBD_o.png" width="1200"></p> 
<p>使用nohup方式启动xinference，这样我们关闭终端的时候，我们启动的API接口依然存在。</p> 
<pre><code class="language-bash">nohup xinference-local --host 0.0.0.0 --port 8887 &gt; logfile.log 2&gt;&amp;1 &amp;</code></pre> 
<p></p> 
<h2>安装chatchat3</h2> 
<p></p> 
<p>退出xinference虚拟环境，新建一个虚拟环境用来运行Langchain-Chatchat</p> 
<pre><code class="language-python">pip install "langchain-chatchat[xinference]" -U</code></pre> 
<p></p> 
<p>需要修改<code>默认llm模型</code>可执行：</p> 
<p>模型名字即为之前注册的模型ID，选择你所启动的模型的ID </p> 
<pre><code class="language-bash">chatchat-config model --default_llm_model autodl-tmp-glm-4-9b-chat</code></pre> 
<p><img alt="" height="543" src="https://images2.imgbox.com/2b/af/3jw1rhYg_o.png" width="1200"></p> 
<p></p> 
<p>需要修改<code>默认embedding模型</code>可执行：</p> 
<pre><code class="language-bash">chatchat-config model --DEFAULT_EMBEDDING_MODEL custom-embedding-bge</code></pre> 
<p><img alt="" height="485" src="https://images2.imgbox.com/c0/b7/yZ6P8P3M_o.png" width="1200"></p> 
<p></p> 
<h5>自定义模型接入配置</h5> 
<p>完成上述项目配置项可以通过MODEL_PLATFORMS这里配置</p> 
<pre><code class="language-bash">chatchat-config model --set_model_platforms "[{
    \"platform_name\": \"xinference\",
    \"platform_type\": \"xinference\",
    \"api_base_url\": \"http://127.0.0.1:9997/v1\",
    \"api_key\": \"EMPT\",
    \"api_concurrencies\": 5,
    \"llm_models\": [
        \"autodl-tmp-glm-4-9b-chat\"
    ],
    \"embed_models\": [
        \"custom-embedding-bge\"
    ],
    \"image_models\": [],
    \"reranking_models\": [],
    \"speech2text_models\": [],
    \"tts_models\": []
}]"</code></pre> 
<p>主要修改这两个选项</p> 
<p><img alt="" height="589" src="https://images2.imgbox.com/e1/e9/tiKD5zXl_o.png" width="947"></p> 
<p></p> 
<h3>初始化知识库</h3> 
<p>指定自己在xinference平台上启动的embedding模型ID</p> 
<pre><code class="language-bash">chatchat-kb -r --embed-model=custom-embedding-bge</code></pre> 
<pre><code class="language-bash">chatchat-config basic --show
</code></pre> 
<p>知识库路径为  <em>DATA_PATH</em> 变量指向的路径下的 knowledge_base 目录中:</p> 
<p><img alt="" height="219" src="https://images2.imgbox.com/f0/03/KUP8IqAU_o.png" width="885"></p> 
<h3>启动项目</h3> 
<pre><code class="language-bash">chatchat -a</code></pre> 
<p><img alt="" height="490" src="https://images2.imgbox.com/3e/e6/PEsNVSxp_o.png" width="1200"></p> 
<p>启动成功</p> 
<p><img alt="" height="723" src="https://images2.imgbox.com/f3/a8/eDcdFCWv_o.png" width="1200"></p> 
<p></p> 
<p>由于 chatchat-config server 配置默认监听地址 <code>DEFAULT_BIND_HOST</code> 为 127.0.0.1, 所以无法通过其他 ip 进行访问。</p> 
<p></p> 
<pre><code class="language-bash">chatchat-config server --show </code></pre> 
<pre><code class="language-bash">{
    "HTTPX_DEFAULT_TIMEOUT": 300.0,
    "OPEN_CROSS_DOMAIN": true,
    "DEFAULT_BIND_HOST": "127.0.0.1",
    "WEBUI_SERVER_PORT": 8501,
    "API_SERVER_PORT": 7861,
    "WEBUI_SERVER": {
        "host": "127.0.0.1",
        "port": 8501
    },
    "API_SERVER": {
        "host": "127.0.0.1",
        "port": 7861
    },
    "class_name": "ConfigServer"
}</code></pre> 
<pre><code class="language-bash">chatchat-config server --DEFAULT_BIND_HOST 0.0.0.0
</code></pre> 
<p>修改监听地址</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/f30a06abb9021a0a95caf5abd668b5dc/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">3个让你爽到爆炸的学习工具</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/21f3173443121602997ed5230bda1341/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【算法训练记录——Day41】</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>