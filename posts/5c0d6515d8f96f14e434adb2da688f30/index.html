<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Meta 发布Llama 3，能力直逼GPT-4,一己之力拉高开源大模型水位 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/5c0d6515d8f96f14e434adb2da688f30/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="Meta 发布Llama 3，能力直逼GPT-4,一己之力拉高开源大模型水位">
  <meta property="og:description" content="Meta麾下“羊驼”一路狂奔在开源的大道上。
在过去的一年里，Llama系列可以说开辟了开源LLM的半壁江山。
嫌弃开源模型能力只有GPT-3.5,不够用?
如今Llama 3发布，又是一石激起千层浪。粗看其基础benchmark，足以让国内外一众大模型公司瑟瑟发抖。借用一句业内人士的话，“性能上来说感觉就是GPT-3.7的水平。一己之力急速拉高了开源水位”。
首先从数据层面看，Llama 3 在15T tokens上进行了训练，践行了又一次堪称恐怖的大力出奇迹；再者从训练资源方面看，2.4万卡集群训练的部署也足以展示Meta的志在必得。
Llama 3让Meta重夺开源大模型的王位，且其性能无限接近甚至超过OpenAI GPT、Gemini和Claude等闭源大模型。
难怪Meta有底气放言，就各自的参数数量而言，经过两个定制的24000 GPU集群训练的Llama 3 8B和Llama 3 70B是目前可用的性能最佳的生成式AI模型之一。
更加劲爆的是。扎克伯格在最新访谈中透露，Llama3的三个版本中，是80亿参数、700亿参数的模型开源了，而超过 4000 亿个模型还在加紧训练的路上……
图片
有网友在访谈下调侃道，难怪扎克伯格看起来如此“人性化”，肯定是偷偷运行Llama 3了！
图片
让小扎都更加AGI的Llama 3，究竟为何能这么牛呢，不妨来一起看看其细节！ 一、性能 PK，刺刀见红：Llama3恐怖如斯 Meta力大砖飞确实有奇效！扎克伯格说，Llama3 80亿的模型几乎与此前发布的最大版本的Llama2（参数700亿）一样强大。
众所周知，诸如MMLU（旨在衡量知识）、ARC（试图衡量技能习得）和DROP（测试模型对文本片段的理解能力）等流行AI基准测试的有效性和实用性尚存争议。但无论好坏，它们仍是AI玩家评估其模型的少数标准化手段之一。
Llama 3 8B在至少九项基准测试中超越了其他开源模型，如Mistral的Mistral 7B和Google的Gemma 7B：MMLU、ARC、DROP、GPQA（一组涉及生物、物理和化学的问题）、HumanEval（一项代码生成测试）、GSM-8K（数学应用题）、MATH（另一项数学基准）、AGIEval（问题解决测试集）以及BIGbench Hard（常识推理评估）。
诚然，Mistral 7B和Gemma 7B并非处于最前沿（Mistral 7B于去年9月发布），并且在Meta引用的几项基准中，Llama 3 8B仅比二者高出几个百分点。但Meta声称，参数数量更大的Llama 3 70B模型，可与包括Google Gemini系列最新款Gemini 1.5 Pro在内的旗舰级生成式AI模型相媲美。 图片
Instruct-tuned模型与Gemma、Mistral、Gemini Pro 1.5、Claude 3 Sonnet在MMLU、GSM-8k等benchmark上的对比如下：
图片
Llama 3 70B在MMLU、HumanEval和GSM-8K三项测试中胜过Gemini 1.5 Pro。尽管它无法与Anthropic表现最为强劲的模型Claude 3 Opus匹敌，但在五个基准（MMLU、GPQA、HumanEval、GSM-8K及MATH）上，Llama 3 70B的成绩优于Claude 3系列中第二弱的模型Claude 3 Sonnet。 为了测试Llama 3在标准基准测试上的性能，Meta甚至特意开发了一个新的高质量人类评估集。这个评估集包含1800个提示，涵盖寻求建议、头脑风暴、角色扮演等12个关键用例。为了测试的公平，评估集不允许自己的建模团队访问。结果是，70B的Llama 3Instruct-tuned模型在人类评测中胜过Claude Sonnet和GPT 3.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-04-24T13:45:00+08:00">
    <meta property="article:modified_time" content="2024-04-24T13:45:00+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Meta 发布Llama 3，能力直逼GPT-4,一己之力拉高开源大模型水位</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>Meta麾下“羊驼”一路狂奔在开源的大道上。</p> 
<p></p> 
<p>在过去的一年里，Llama系列可以说开辟了开源LLM的半壁江山。</p> 
<p></p> 
<p>嫌弃开源模型能力只有GPT-3.5,不够用?</p> 
<p></p> 
<p>如今Llama 3发布，又是一石激起千层浪。粗看其基础benchmark，足以让国内外一众大模型公司瑟瑟发抖。借用一句业内人士的话，“性能上来说感觉就是GPT-3.7的水平。一己之力急速拉高了开源水位”。</p> 
<p></p> 
<p>首先从数据层面看，Llama 3 在15T tokens上进行了训练，践行了又一次堪称恐怖的大力出奇迹；再者从训练资源方面看，2.4万卡集群训练的部署也足以展示Meta的志在必得。</p> 
<p></p> 
<p>Llama 3让Meta重夺开源大模型的王位，且其性能无限接近甚至超过OpenAI GPT、Gemini和Claude等闭源大模型。</p> 
<p></p> 
<p>难怪Meta有底气放言，就各自的参数数量而言，经过两个定制的24000 GPU集群训练的Llama 3 8B和Llama 3 70B是目前可用的性能最佳的生成式AI模型之一。</p> 
<p></p> 
<p>更加劲爆的是。扎克伯格在最新访谈中透露，Llama3的三个版本中，是80亿参数、700亿参数的模型开源了，而超过 4000 亿个模型还在加紧训练的路上……</p> 
<p></p> 
<p></p> 
<p class="img-center"><img alt="图片" height="560" src="https://images2.imgbox.com/d5/56/azLfAVkK_o.png" width="1080"></p> 
<p>图片</p> 
<p></p> 
<p>有网友在访谈下调侃道，难怪扎克伯格看起来如此“人性化”，肯定是偷偷运行Llama 3了！</p> 
<p></p> 
<p></p> 
<p class="img-center"><img alt="图片" height="215" src="https://images2.imgbox.com/ad/0b/UCWHiT0d_o.png" width="923"></p> 
<p>图片</p> 
<p></p> 
<p>让小扎都更加AGI的Llama 3，究竟为何能这么牛呢，不妨来一起看看其细节！ </p> 
<h4>一、性能 PK，刺刀见红：Llama3恐怖如斯</h4> 
<p></p> 
<p>Meta力大砖飞确实有奇效！扎克伯格说，Llama3 80亿的模型几乎与此前发布的最大版本的Llama2（参数700亿）一样强大。</p> 
<p></p> 
<p>众所周知，诸如MMLU（旨在衡量知识）、ARC（试图衡量技能习得）和DROP（测试模型对文本片段的理解能力）等流行AI基准测试的有效性和实用性尚存争议。但无论好坏，它们仍是AI玩家评估其模型的少数标准化手段之一。</p> 
<p></p> 
<p>Llama 3 8B在至少九项基准测试中超越了其他开源模型，如Mistral的Mistral 7B和Google的Gemma 7B：MMLU、ARC、DROP、GPQA（一组涉及生物、物理和化学的问题）、HumanEval（一项代码生成测试）、GSM-8K（数学应用题）、MATH（另一项数学基准）、AGIEval（问题解决测试集）以及BIGbench Hard（常识推理评估）。</p> 
<p></p> 
<p>诚然，Mistral 7B和Gemma 7B并非处于最前沿（Mistral 7B于去年9月发布），并且在Meta引用的几项基准中，Llama 3 8B仅比二者高出几个百分点。但Meta声称，参数数量更大的Llama 3 70B模型，可与包括Google Gemini系列最新款Gemini 1.5 Pro在内的旗舰级生成式AI模型相媲美。   </p> 
<p></p> 
<p></p> 
<p class="img-center"><img alt="图片" height="473" src="https://images2.imgbox.com/cd/d2/j4X0wUlL_o.png" width="828"></p> 
<p>图片</p> 
<p></p> 
<p>Instruct-tuned模型与Gemma、Mistral、Gemini Pro 1.5、Claude 3 Sonnet在MMLU、GSM-8k等benchmark上的对比如下：</p> 
<p></p> 
<p></p> 
<p class="img-center"><img alt="图片" height="608" src="https://images2.imgbox.com/14/44/JAbsLrQ5_o.png" width="1080"></p> 
<p>图片</p> 
<p></p> 
<p>Llama 3 70B在MMLU、HumanEval和GSM-8K三项测试中胜过Gemini 1.5 Pro。尽管它无法与Anthropic表现最为强劲的模型Claude 3 Opus匹敌，但在五个基准（MMLU、GPQA、HumanEval、GSM-8K及MATH）上，Llama 3 70B的成绩优于Claude 3系列中第二弱的模型Claude 3 Sonnet。   </p> 
<p></p> 
<p>为了测试Llama 3在标准基准测试上的性能，Meta甚至特意开发了一个新的高质量人类评估集。这个评估集包含1800个提示，涵盖寻求建议、头脑风暴、角色扮演等12个关键用例。为了测试的公平，评估集不允许自己的建模团队访问。结果是，70B的Llama 3Instruct-tuned模型在人类评测中胜过Claude Sonnet和GPT 3.5：</p> 
<p></p> 
<p></p> 
<p class="img-center"><img alt="图片" height="677" src="https://images2.imgbox.com/b2/0e/JR019xVi_o.png" width="1080"></p> 
<p>图片</p> 
<p>然而，鉴于测试集由Meta自身设计，显然这些结果需要持保留态度看待。</p> 
<p></p> 
<p>从定性角度来说，Meta宣称新Llama模型的用户可以期待更高的“可控性”，即模型更愿意回答问题，并且在琐事问题、涉及历史和STEM（如工程与科学）领域的提问以及通用编码建议方面表现出更高的准确性。</p> 
<h4>二、Llama 3 技术细节，训练集是上代7倍大</h4> 
<p></p> 
<p>在模型架构方面，与Llama 2 基本一致，最关键的不同在于以下几点：</p> 
<p></p> 
<p>1.Llama 3使用了一个128K Token 的词汇表，而 Llama-2 的词汇量为 32K。</p> 
<p>2.训练数据使用了 15 万亿个 Token，而不是 Llama-2 的 2 万亿。</p> 
<p>3.8 亿参数的模型也使用了分组查询注意力（GQA）（与 Llama 2 7b 则没有）。</p> 
<p>4.代码数据是原来的 4 倍。</p> 
<p></p> 
<p>为了训练Llama 3，Meta在超过15Token的令牌上进行了预训练。所使用的训练数据集是Llama 2所使用的七倍。</p> 
<p></p> 
<p>在Llama 3的开发过程中，Meta对scaling law有了一些新体会。这次训练以Chinchilla做指导，但是他们发现虽然对于一个8B模型来说，对应的最优训练量约200B个令牌，即使在训练了700亿个Token后，模型性能仍在继续提高。</p> 
<p></p> 
<p>这些庞大的数据源自何处？Meta并未透露具体来源，仅表示数据来自“公开可用资源”，其中包含的代码量是Llama 2训练集的四倍，并且有5%的非英语数据（覆盖约30种语言），旨在提升除英语外其他语言的表现（不过仍然有大佬吐槽Llama 3的中文表现一般）。Meta还表示使用了合成数据（即AI生成的数据）来创建长篇文档供Llama 3模型训练，这一做法因可能带来性能弊端而颇具争议。</p> 
<p></p> 
<p>许多生成式AI供应商视训练数据为竞争优势，因此对其保密。但训练数据详情也是潜在的知识产权相关诉讼源头，这也成为不愿透露过多信息的另一个原因。近期报道显示，在与AI竞争对手保持同步的过程中，Meta曾不顾自家律师警告，使用受版权保护的电子书进行AI训练。</p> 
<p></p> 
<p>那么，对于生成式AI模型常见的毒性与偏见问题，Llama 3同样采取了措施。</p> 
<p></p> 
<p>Meta表示已开发新的数据过滤管道以提升模型训练数据质量，并更新了其生成式AI安全套件Llama Guard和CybersecEval，旨在防止Llama 3模型及其他模型被滥用以及产生有毒的文本生成。该公司还发布了一款名为Code Shield的新工具，用于检测生成式AI模型产生的可能引入安全漏洞的代码。然而，过滤并非万无一失。我们需要等待观察Llama 3模型在实际应用中的表现，包括学术界对其在替代基准上的测试。</p> 
<h4>三、抽干闭源模型的护城河：4000亿参数的“巨无霸”已经在路上    </h4> 
<p></p> 
<p>Meta指出，Llama 3模型已经可以下载。</p> 
<p></p> 
<p>Llama 3为Facebook、Instagram、WhatsApp、Messenger和网页版Meta AI助手提供支持。不久，其将在包括AWS、Databricks、Google Cloud、Hugging Face、Kaggle、IBM WatsonX、Microsoft Azure、Nvidia NIM和Snowflake在内的广泛云平台上以托管形式提供。</p> 
<p></p> 
<p>未来，针对AMD、AWS、Dell、Intel、Nvidia和Qualcomm硬件优化的模型版本也将发布。</p> 
<p></p> 
<p>尽管Llama 3模型可能广泛可用，但我们会将其描述为“开放”而非“开源”。这是因为，其Llama系列模型并非如其声称的那样无附加条件。</p> 
<p></p> 
<p>它们既可用于研究也可用于商业应用。然而，Meta禁止开发者使用Llama模型训练其他生成式模型，同时月活跃用户超过7亿的应用开发者必须向Meta申请特殊许可，Meta将根据其判断决定是否授予许可。</p> 
<p></p> 
<p>更强大的Llama模型已在筹备中。</p> 
<p></p> 
<p>Meta称正在训练规模达4000亿参数的Llama 3模型，这类模型能够进行多语言对话，处理更多类型的数据，理解图像和其他模态信息，与文本一样，这将使Llama 3系列与Hugging Face的Idefics2等开放发布版本保持一致。</p> 
<p></p> 
<p>“我们的近期目标是让Llama 3实现多语言和多模态，具备更长的上下文理解能力，并在诸如推理和编程等大型语言模型核心功能上继续提升整体性能，”Meta在其博客文章中写道。“未来还有许多值得期待的进步。”    </p> 
<p></p> 
<p>随着400B的“巨无霸”逐渐展露真容，大模型竞技场的氛围愈加焦灼。环视四周，我们可以发现，今天发布的Llama-3 70B，和Gemini 1.5 Pro，Cohere CMD R+，Claude Sonnet以及老版GPT-4差不多站在了同样的分界线里。</p> 
<p></p> 
<p>谷歌曾直言，我们没有护城河。OpenAI同样如此。面对 Llama-3 70B的当头一击，谷歌最先进的模型Gemini1.5 Pro也要避其锋芒。闭源模型的护城河每每挖深一点，似乎就会在猝不及防间被扎克伯格抽干一次。大模型的开源与闭源之争短时间内并不会有解，但Meta在开源立场上的坚持，却让这场旷日持久的Battle有了更多的可能性。</p> 
<p></p> 
<p>就像Yann LeCun在近期的演讲中所提到的，我们不能让少数几个AI助手掌控全世界每个公民的全部数字生活。这位AI界的泰斗从始至终坚持开源主张，“我们需要的不是一个AI助手，而是像Llama 2、Mistral和Gemma这样的基础模型，任何人都可以对其进行微调”，这样我们才可以避免回音室，避免让少数几家AI平台来控制人们的所见所思，真正获得多样化的信息来源。</p> 
<p></p> 
<p></p> 
<h4>四、 Llama 3开源，AI赛道玩家谁喜谁忧？</h4> 
<p></p> 
<p>朱啸虎在他的“中国现实主义AIGC故事”中谈论过一个非常现实的问题：即如果一家公司投入巨资去研发类似于GPT-4的大模型，而一旦其他组织开源了类似的技术，那么之前的投入可能会白费。</p> 
<p></p> 
<p>现在开源的王Llama 3横空出世，已经无限逼近这个预言。对于场上闭源大模型的玩家来说，必须得做到比最强开源大模型领先，才能证明自己的价值。   </p> 
<p></p> 
<p>而Llama 3这样急速拉高开源模型水位线的做法，无疑是打在其他大模型企业腹地上一记又快又狠的重拳。</p> 
<p></p> 
<p>但对于AI应用层的企业来说，“奶妈”Llama 3的表现着实让人惊喜。猎豹CEO傅盛在凌晨两点的视频中提到，绝大多数的模型都是基于Llama重新训练或者进行微调的，而最让人惊喜的点就在于Llama 3没有将目标一味聚焦在“大”上，而是让8B的小模型也跑出了强性能。</p> 
<p></p> 
<p></p> 
<p class="img-center"><img alt="傅盛发布视频截图" height="1200" src="https://images2.imgbox.com/5f/1a/OkLYbTq8_o.jpg" width="1080"></p> 
<p>傅盛发布视频截图</p> 
<p></p> 
<p>小扎在访谈中提到无法让人使用的AI与新技术的滥用一样糟糕，因此“拥有一个优秀且成为标准的开源人工智能，可能是缓解这种情况的最佳方法。”而Llama 3的优秀和强大，本身就是对“开源社区会越来越落后”论调的最强反击。</p> 
<p></p> 
<p>AI技术想要服务于人类福祉，就需要更多人能伸手摘到这颗树上的果实。Llama 3已经来了，企业和研究机构在强大底座上的二次开发和技术创新也就不远了。  </p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/555041083cb115f1f22e0e51e30ec7c8/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">IP-guard WebServer 权限绕过漏洞复现(QVD-2024-14103)</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/ac1e483ef7afbc33f4ae2d024691c991/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">LeetCode刷题指南 - 算法必读篇</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>