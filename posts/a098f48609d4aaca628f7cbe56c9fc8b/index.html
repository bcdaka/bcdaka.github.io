<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>如何查看Kafka的偏移量offset - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/a098f48609d4aaca628f7cbe56c9fc8b/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="如何查看Kafka的偏移量offset">
  <meta property="og:description" content="本文介绍三种方法查看Kafka的偏移量offset。
1. API：ConsumerRecord的offset()方法查看offset。
2. API：KafkaConsumer的position(TopicPartition partition)方法查看offset。
3. 命令行：kafka-consumer-groups.sh命令查看offset。
前提条件 Kafka安装及基本操作，可参考：Kafka安装及基本操作
Kafka API操作，可参考：Kafka API操作
三种方法查看Kafka的偏移量offset 1. API：ConsumerRecord的offset()方法查看offset。 生产者
import org.apache.kafka.clients.producer.KafkaProducer; import org.apache.kafka.clients.producer.ProducerRecord; import org.apache.kafka.clients.producer.RecordMetadata; import java.util.Properties; import java.util.concurrent.Future; public class MyProducer { public static void main(String[] args) { // 1.创建kafka生产者对象 Properties prop = new Properties(); prop.put(&#34;bootstrap.servers&#34;,&#34;node1:9092&#34;); prop.put(&#34;acks&#34;,&#34;all&#34;); prop.put(&#34;retries&#34;,&#34;0&#34;); // 16k一个批量 prop.put(&#34;batch.size&#34;, 16384); prop.put(&#34;linger.ms&#34;,5); prop.put(&#34;buffer.memory&#34;, 33554432); prop.put(&#34;key.serializer&#34;, &#34;org.apache.kafka.common.serialization.StringSerializer&#34;); prop.put(&#34;value.serializer&#34;, &#34;org.apache.kafka.common.serialization.StringSerializer&#34;); KafkaProducer&lt;Object, Object&gt; producer = new KafkaProducer&lt;&gt;(prop); // 2.使用send方法生产数据 for (int i = 0; i &lt; 10; i&#43;&#43;) { // producer.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-07-23T20:52:20+08:00">
    <meta property="article:modified_time" content="2024-07-23T20:52:20+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">如何查看Kafka的偏移量offset</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>本文介绍三种方法查看Kafka的偏移量offset。</p> 
<p>1. API：ConsumerRecord的offset()方法查看offset。</p> 
<p>2. API：KafkaConsumer的position(TopicPartition partition)方法查看offset。</p> 
<p>3. 命令行：kafka-consumer-groups.sh命令查看offset。</p> 
<p></p> 
<h3>前提条件</h3> 
<p>Kafka安装及基本操作，可参考：<a class="link-info" href="https://blog.csdn.net/qq_42881421/article/details/137127706" title="Kafka安装及基本操作">Kafka安装及基本操作</a></p> 
<p>Kafka API操作，可参考：<a class="link-info" href="https://blog.csdn.net/qq_42881421/article/details/124740409" title="Kafka API操作">Kafka API操作</a></p> 
<p></p> 
<h3>三种方法查看Kafka的偏移量offset</h3> 
<h4>1. API：ConsumerRecord的offset()方法查看offset。</h4> 
<p>生产者</p> 
<pre><code class="language-java">import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.clients.producer.RecordMetadata;

import java.util.Properties;
import java.util.concurrent.Future;

public class MyProducer {
    public static void main(String[] args) {
        // 1.创建kafka生产者对象
        Properties prop = new Properties();
        prop.put("bootstrap.servers","node1:9092");
        prop.put("acks","all");
        prop.put("retries","0");
        // 16k一个批量
        prop.put("batch.size", 16384);
        prop.put("linger.ms",5);
        prop.put("buffer.memory", 33554432);

        prop.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        prop.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");

        KafkaProducer&lt;Object, Object&gt; producer = new KafkaProducer&lt;&gt;(prop);


        // 2.使用send方法生产数据
        for (int i = 0; i &lt; 10; i++) {
//            producer.send(new ProducerRecord&lt;&gt;("Hello-Kafka", Integer.toString(i), Integer.toString(i)));
            producer.send(new ProducerRecord&lt;&gt;("bigdata12", Integer.toString(i), Integer.toString(i)));
        }

        // 3.关闭生产者
        producer.close();

    }
}
</code></pre> 
<p>消费者</p> 
<pre><code class="language-java">import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;

import java.time.Duration;
import java.util.Arrays;
import java.util.Properties;

public class MyConsumer {
    public static void main(String[] args) {
        //1.创建消费者对象
        Properties prop = new Properties();
        prop.put("bootstrap.servers","node1:9092");
        prop.put("group.id","test");
        prop.put("enable.auto.commit","true");
        prop.put("auto.commit.interval.ms","1000");
        prop.put("session.timeout.ms","30000");
        prop.put("key.deserializer",
                "org.apache.kafka.common.serialization.StringDeserializer");//注意不是StringSerializer
        prop.put("value.deserializer",
                "org.apache.kafka.common.serialization.StringDeserializer");

        KafkaConsumer&lt;Object, Object&gt; consumer = new KafkaConsumer&lt;&gt;(prop);
        //2.消费者订阅主题
        consumer.subscribe(Arrays.asList("bigdata12"));// 将数组转为List集合

        //3.使用poll方法消费数据
        while (true){
//            ConsumerRecords&lt;Object,Object&gt; records = consumer.poll(Duration.ofSeconds(5));
            ConsumerRecords&lt;Object, Object&gt; records = consumer.poll(Duration.ofSeconds(2));

            for (ConsumerRecord&lt;Object, Object&gt; record : records) {
                System.out.printf("offset=%d, key=%s, value=%s\n",
                        record.offset(),record.key(),record.value());
            }
        }

    }
}
</code></pre> 
<p><img alt="" height="243" src="https://images2.imgbox.com/b0/12/P27sGA3A_o.png" width="591"></p> 
<p></p> 
<p>测试：</p> 
<p>IDEA中，运行消费者，再运行生产者。提示<em>：没有topic，将自动创建。</em></p> 
<p></p> 
<p>返回IDEA的消费者控制台，输出类似如下数据</p> 
<p>...</p> 
<p>offset=30, key=8, value=8<br> offset=31, key=9, value=9</p> 
<p>这里显示的是最后一条数据的offset=31。</p> 
<p></p> 
<h4>2. API：KafkaConsumer的position(TopicPartition partition)方法查看offset。</h4> 
<pre><code class="language-java">import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.common.TopicPartition;

import java.util.Arrays;
import java.util.Properties;

public class KafkaOffsetViewer {
    public static void main(String[] args) {
        Properties props = new Properties();
        props.put("bootstrap.servers", "node1:9092");
        props.put("group.id", "test");
        props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
        props.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");

        KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;&gt;(props);
        String topic = "bigdata12";
        TopicPartition partition = new TopicPartition(topic, 0);

        try {
            consumer.assign(Arrays.asList(partition));
            consumer.seekToEnd(Arrays.asList(partition));
            long offset = consumer.position(partition);
            System.out.println("Offset of partition 0 is: " + offset);
        } finally {
            consumer.close();
        }
    }
}
</code></pre> 
<p>IDEA运行结果：</p> 
<p>Offset of partition 0 is: 32</p> 
<p><img alt="" height="472" src="https://images2.imgbox.com/16/d6/HMFTEHd9_o.png" width="1200"></p> 
<p>看到offset为32，是最新的offset值，也就是下一条数据从32开始。</p> 
<p></p> 
<h4>3. 命令行：kafka-consumer-groups.sh命令查看offset。</h4> 
<p></p> 
<p>在命令行中运行以下命令：</p> 
<pre>kafka-consumer-groups.sh --bootstrap-server &lt;kafka-broker-list&gt; --describe --group &lt;consumer-group-id&gt;</pre> 
<p>例如：</p> 
<pre>[hadoop@node1 ~]$ kafka-consumer-groups.sh --bootstrap-server node1:9092 --describe --group test
​
GROUP           TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID                                          HOST            CLIENT-ID
test            bigdata12       0          32              32              0               consumer-test-1-64d17e50-69e9-47e3-9380-f2441a09cae2 /117.189.125.24 consumer-test-1
​</pre> 
<p>看到offset为32，是最新的offset值。</p> 
<p></p> 
<p>感兴趣可以再使用生产者发送数据测试，看到三种查看offset方法，offset值的变化情况。</p> 
<p></p> 
<h3>总结</h3> 
<p>1. API：ConsumerRecord的offset()方法查看offset，查看到最后一条数据的offset，最新offset=最后一条数据offset+1。</p> 
<p>2. API：KafkaConsumer的position(TopicPartition partition)方法查看offset，查到最新offset。</p> 
<p>3. 命令行：kafka-consumer-groups.sh命令查看offset，查到最新offset。</p> 
<p></p> 
<p>完成！ enjoy it！</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/e2c492e961ec61afb23344ba77754d55/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">生成式 AI 的发展方向：Chat 还是 Agent？</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/fa60774432b042b237ce7b93aa71513b/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">STL 简介（标准模板库）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>