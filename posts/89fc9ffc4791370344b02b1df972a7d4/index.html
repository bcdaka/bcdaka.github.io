<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Datawhale X 魔搭 AI夏令营第四期 魔搭-AIGC方向 task02笔记 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/89fc9ffc4791370344b02b1df972a7d4/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="Datawhale X 魔搭 AI夏令营第四期 魔搭-AIGC方向 task02笔记">
  <meta property="og:description" content="理解baseline代码 在task01中，我们根据教程实现了AI生图。接下来我们来细读和理解baseline代码。
首先我们来直观感知下这个文生图代码的框架结构：
接着我们按照上图的部分细读代码。
1.环境准备 # 安装 Data-Juicer 和 DiffSynth-Studio !pip install simple-aesthetics-predictor # 安装simple-aesthetics-predictor !pip install -v -e data-juicer # 安装data-juicer !pip uninstall pytorch-lightning -y # 卸载pytorch-lightning !pip install peft lightning pandas torchvision # 安装 peft lightning pandas torchvision !pip install -e DiffSynth-Studio # 安装DiffSynth-Studio 使用 !pip 命令来安装或卸载 Python 包。包括：
simple-aesthetics-predictor, data-juicer, peft, lightning, pandas, torchvision, 和 DiffSynth-Studio 的安装。
卸载 pytorch-lightning（使用 -y 自动确认卸载）。
2. 数据集加载和预处理 # 从魔搭数据集中下载数据集AI-ModelScope/lowres_anime from modelscope.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-08-13T22:06:25+08:00">
    <meta property="article:modified_time" content="2024-08-13T22:06:25+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Datawhale X 魔搭 AI夏令营第四期 魔搭-AIGC方向 task02笔记</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h3>理解baseline代码</h3> 
<p>在task01中，我们根据教程实现了AI生图。接下来我们来细读和理解baseline代码。</p> 
<p>首先我们来直观感知下这个文生图代码的<span style="color:#4da8ee;">框架结构</span>：</p> 
<p style="text-align:center;"><img alt="" height="337" src="https://images2.imgbox.com/1d/08/az45XAwJ_o.png" width="509"></p> 
<p></p> 
<p> 接着我们按照上图的部分细读代码。</p> 
<h4><span style="color:#4da8ee;">1.环境准备</span></h4> 
<pre><code class="language-python"># 安装 Data-Juicer 和 DiffSynth-Studio
!pip install simple-aesthetics-predictor # 安装simple-aesthetics-predictor
!pip install -v -e data-juicer # 安装data-juicer
!pip uninstall pytorch-lightning -y # 卸载pytorch-lightning
!pip install peft lightning pandas torchvision # 安装 peft lightning pandas torchvision
!pip install -e DiffSynth-Studio # 安装DiffSynth-Studio</code></pre> 
<ul><li> <p>使用 <code>!pip</code> 命令来安装或卸载 Python 包。包括：</p> 
  <ul><li> <p><code>simple-aesthetics-predictor</code>, <code>data-juicer</code>, <code>peft</code>, <code>lightning</code>, <code>pandas</code>, <code>torchvision</code>, 和 <code>DiffSynth-Studio</code> 的安装。</p> </li><li> <p>卸载 <code>pytorch-lightning</code>（使用 <code>-y</code> 自动确认卸载）。</p> </li></ul></li></ul> 
<p></p> 
<h4><span style="color:#4da8ee;">2. 数据集加载和预处理</span></h4> 
<p></p> 
<pre><code class="language-python"># 从魔搭数据集中下载数据集AI-ModelScope/lowres_anime
from modelscope.msdatasets import MsDataset  #引入数据集模块msdatasets
ds = MsDataset.load(
    'AI-ModelScope/lowres_anime',
    subset_name='default',
    split='train',
    cache_dir="/mnt/workspace/kolors/data" # 指定缓存目录
) # 从魔搭数据集中下载数据集AI-ModelScope/lowres_anime，赋值给参数ds

# 生成数据集
import json, os # 导入json和os模块
from data_juicer.utils.mm_utils import SpecialTokens # 导入SpecialTokens
from tqdm import tqdm # 导入tqdm进度条管理
os.makedirs("./data/lora_dataset/train", exist_ok=True) # 创建文件夹./data/lora_dataset/train
os.makedirs("./data/data-juicer/input", exist_ok=True) # 创建文件夹./data/data-juicer/input
with open("./data/data-juicer/input/metadata.jsonl", "w") as f:
    for data_id, data in enumerate(tqdm(ds)): # 遍历数据集ds
        image = data["image"].convert("RGB") # 将数据集的图片转换为RGB
        image.save(f"/mnt/workspace/kolors/data/lora_dataset/train/{data_id}.jpg") # 保存数据集的图片
        metadata = {"text": "二次元", "image": [f"/mnt/workspace/kolors/data/lora_dataset/train/{data_id}.jpg"]} # 生成当前图片的索引数据
        f.write(json.dumps(metadata)) # 将索引数据写入文件./data/data-juicer/input/metadata.jsonl
        f.write("\n")

# 配置data-juicer，并进行数据筛选过滤
# 配置过滤的规则
data_juicer_config = """
# global parameters
project_name: 'data-process' # 名称
dataset_path: './data/data-juicer/input/metadata.jsonl'  # 你前面生成的数据的索引文件
np: 4  # 线程数

text_keys: 'text' # 文件./data/data-juicer/input/metadata.jsonl的描述的字段名
image_key: 'image' # 文件./data/data-juicer/input/metadata.jsonl的图片字段名
image_special_token: '&lt;__dj__image&gt;'

export_path: './data/data-juicer/output/result.jsonl' # 筛选通过的图片结果保存的的索引文件

# process schedule
# a list of several process operators with their arguments
# 过滤的规则
process:
    - image_shape_filter: # 图片尺寸过滤
        min_width: 1024 # 最小宽度1024
        min_height: 1024 # 最小高度1024
        any_or_all: any # 符合前面条件的图片才会被保留
    - image_aspect_ratio_filter: # 图片长宽比过滤
        min_ratio: 0.5 # 最小长宽比0.5
        max_ratio: 2.0 # 最大长宽比2.0
        any_or_all: any # 符合前面条件的图片才会被保留
"""

# 保存data-juicer配置到data/data-juicer/data_juicer_config.yaml
with open("data/data-juicer/data_juicer_config.yaml", "w") as file:
    file.write(data_juicer_config.strip())</code></pre> 
<ul><li> <p>使用 ModelScope 的 <code>MsDataset</code> 类加载名为 <code>AI-ModelScope/lowres_anime</code> 的数据集，并指定子集名称为 <code>default</code> 和分割为 <code>train</code>，缓存目录设置为 <code>/mnt/workspace/kolors/data</code>。</p> </li><li> <p>将数据集中的图像转换为 RGB 模式，并保存到指定目录。</p> </li><li> <p>创建包含图像路径和文本描述的元数据文件 <code>metadata.jsonl</code>。</p> </li><li> <p>编写并保存 <code>data_juicer_config.yaml</code> 配置文件，用于后续的数据过滤和处理。</p> </li></ul> 
<h4><span style="color:#4da8ee;">3.数据清洗与过滤 </span></h4> 
<p></p> 
<pre><code class="language-python"># data-juicer开始执行数据筛选
!dj-process --config data/data-juicer/data_juicer_config.yaml
</code></pre> 
<ul><li> <p>使用 <code>dj-process</code> 命令根据配置文件对数据进行过滤和处理，生成 <code>result.jsonl</code> 文件。</p> </li></ul> 
<p></p> 
<h4><span style="color:#4da8ee;">4. 模型微调</span></h4> 
<pre><code class="language-python"># 通过前面通过data-juicer筛选的图片索引信息./data/data-juicer/output/result.jsonl，生成数据集
import pandas as pd # 导入pandas
import os, json # 导入os和json
from PIL import Image # 导入Image
from tqdm import tqdm # 导入tqdm进度条管理
texts, file_names = [], [] # 定义两个空列表，分别存储图片描述和图片名称
os.makedirs("./data/lora_dataset_processed/train", exist_ok=True) # 创建文件夹./data/lora_dataset_processed/train
with open("./data/data-juicer/output/result.jsonl", "r") as file: # 打开前面data-juicer筛选的图片索引文件./data/data-juicer/output/result.jsonl
    for data_id, data in enumerate(tqdm(file.readlines())): # 遍历文件./data/data-juicer/output/result.jsonl
        data = json.loads(data) # 将json字符串转换为对象
        text = data["text"] # 获取对象中的text属性，也就是图片的描述信息
        texts.append(text) # 将图片的描述信息添加到texts列表中
        image = Image.open(data["image"][0]) # 获取对象中的image属性，也就是图片的路径,然后用这个路径打开图片
        image_path = f"./data/lora_dataset_processed/train/{data_id}.jpg" # 生成保存图片的路径
        image.save(image_path) # 将图片保存到./data/lora_dataset_processed/train文件夹中
        file_names.append(f"{data_id}.jpg") # 将图片名称添加到file_names列表中
data_frame = pd.DataFrame() # 创建空的DataFrame
data_frame["file_name"] = file_names # 将图片名称添加到data_frame中
data_frame["text"] = texts # 将图片描述添加到data_frame中
data_frame.to_csv("./data/lora_dataset_processed/train/metadata.csv", index=False, encoding="utf-8-sig") # 将data_frame保存到./data/lora_dataset_processed/train/metadata.csv
data_frame # 查看data_frame


# 下载可图模型
from diffsynth import download_models # 导入download_models
download_models(["Kolors", "SDXL-vae-fp16-fix"]) # 下载可图模型
# DiffSynth-Studio提供了可图的Lora训练脚本，查看脚本信息
!python DiffSynth-Studio/examples/train/kolors/train_kolors_lora.py -h
</code></pre> 
<ul><li> <p>读取 <code>result.jsonl</code> 文件中的数据，并将其转换为 Pandas DataFrame，然后保存为 CSV 文件，并且将图片保存到./data/lora_dataset_processed/train文件夹下。</p> </li><li> <p>下载模型download_models(["Kolors", "SDXL-vae-fp16-fix"])</p> </li></ul> 
<h4><span style="color:#4da8ee;">5.加载微调后的模型</span></h4> 
<pre><code class="language-python"># 执行可图Lora训练
import os
cmd = """
python DiffSynth-Studio/examples/train/kolors/train_kolors_lora.py \ # 选择使用可图的Lora训练脚本DiffSynth-Studio/examples/train/kolors/train_kolors_lora.py
  --pretrained_unet_path models/kolors/Kolors/unet/diffusion_pytorch_model.safetensors \ # 选择unet模型
  --pretrained_text_encoder_path models/kolors/Kolors/text_encoder \ # 选择text_encoder
  --pretrained_fp16_vae_path models/sdxl-vae-fp16-fix/diffusion_pytorch_model.safetensors \ # 选择vae模型
  --lora_rank 16 \ # lora_rank 16 表示在权衡模型表达能力和训练效率时，选择了使用 16 作为秩，适合在不显著降低模型性能的前提下，通过 LoRA 减少计算和内存的需求
  --lora_alpha 4.0 \ # 设置 LoRA 的 alpha 值，影响调整的强度
  --dataset_path data/lora_dataset_processed \ # 指定数据集路径，用于训练模型
  --output_path ./models \ # 指定输出路径，用于保存模型
  --max_epochs 1 \ # 设置最大训练轮数为 1
  --center_crop \ # 启用中心裁剪，这通常用于图像预处理
  --use_gradient_checkpointing \ # 启用梯度检查点技术，以节省内存
  --precision "16-mixed" # 指定训练时的精度为混合 16 位精度（half precision），这可以加速训练并减少显存使用
""".strip()
os.system(cmd) # 执行可图Lora训练


# 加载lora微调后的模型
from diffsynth import ModelManager, SDXLImagePipeline # 导入ModelManager和SDXLImagePipeline
from peft import LoraConfig, inject_adapter_in_model # 导入LoraConfig和inject_adapter_in_model
import torch # 导入torch
# 加载LoRA配置并注入模型
def load_lora(model, lora_rank, lora_alpha, lora_path):
    lora_config = LoraConfig(
        r=lora_rank, # 设置LoRA的秩(rank)
        lora_alpha=lora_alpha, # 设置LoRA的alpha值，控制LoRA的影响权重
        init_lora_weights="gaussian", # 初始化LoRA权重为高斯分布
        target_modules=["to_q", "to_k", "to_v", "to_out"], # 指定要应用LoRA的模块
    )
    model = inject_adapter_in_model(lora_config, model) # 将LoRA配置注入到模型中
    state_dict = torch.load(lora_path, map_location="cpu") # 加载LoRA微调后的权重
    model.load_state_dict(state_dict, strict=False) # 将权重加载到模型中，允许部分权重不匹配
    return model # 返回注入LoRA后的模型
# 加载预训练模型
model_manager = ModelManager(
    torch_dtype=torch.float16, # 设置模型的数据类型为float16，减少显存占用
    device="cuda", # 指定使用GPU进行计算
    file_path_list=[
        "models/kolors/Kolors/text_encoder", # 文本编码器的路径
        "models/kolors/Kolors/unet/diffusion_pytorch_model.safetensors", # UNet模型的路径
        "models/kolors/Kolors/vae/diffusion_pytorch_model.safetensors" # VAE模型的路径
    ]
)
# 初始化图像生成管道
pipe = SDXLImagePipeline.from_model_manager(model_manager) # 从模型管理器中加载模型并初始化管道
# 加载并应用LoRA权重到UNet模型
pipe.unet = load_lora(
    pipe.unet, 
    lora_rank=16, # 设置LoRA的秩(rank)，与训练脚本中的参数保持一致
    lora_alpha=2.0, # 设置LoRA的alpha值，控制LoRA对模型的影响权重
    lora_path="models/lightning_logs/version_0/checkpoints/epoch=0-step=500.ckpt" # 指定LoRA权重的文件路径
)
</code></pre> 
<ul><li> <p>在前面模型的基础上，执行Lora微调训练</p> </li><li> <p>加载微调后的模型</p> </li></ul> 
<h4><span style="color:#4da8ee;">6.图像生成</span></h4> 
<pre><code class="language-python"># 生成图像
torch.manual_seed(0) # 设置随机种子，确保生成的图像具有可重复性。如果想要每次生成不同的图像，可以将种子值改为随机值。
image = pipe(
    prompt="二次元，一个紫色短发小女孩，在家中沙发上坐着，双手托着腮，很无聊，全身，粉色连衣裙", # 设置正向提示词，用于指导模型生成图像的内容
    negative_prompt="丑陋、变形、嘈杂、模糊、低对比度", # 设置负向提示词，模型会避免生成包含这些特征的图像
    cfg_scale=4, # 设置分类自由度 (Classifier-Free Guidance) 的比例，数值越高，模型越严格地遵循提示词
    num_inference_steps=50, # 设置推理步数，步数越多，生成的图像细节越丰富，但生成时间也更长
    height=1024, width=1024, # 设置生成图像的高度和宽度，这里生成 1024x1024 像素的图像
)
image.save("1.jpg") # 将生成的图像保存为 "1.jpg" 文件


# 图像拼接，展示总体拼接大图
import numpy as np  # 导入numpy库，用于处理数组和数值计算
from PIL import Image  # 导入PIL库中的Image模块，用于图像处理
images = [np.array(Image.open(f"{i}.jpg")) for i in range(1, 9)]  # 读取1.jpg到8.jpg的图像，转换为numpy数组，并存储在列表images中
image = np.concatenate([  # 将四组图像在垂直方向上拼接
    np.concatenate(images[0:2], axis=1),  # 将第1组（images[0:2]）的两张图像在水平方向上拼接
    np.concatenate(images[2:4], axis=1),  # 将第2组（images[2:4]）的两张图像在水平方向上拼接
    np.concatenate(images[4:6], axis=1),  # 将第3组（images[4:6]）的两张图像在水平方向上拼接
    np.concatenate(images[6:8], axis=1),  # 将第4组（images[6:8]）的两张图像在水平方向上拼接
], axis=0)  # 将四组拼接后的图像在垂直方向上拼接
image = Image.fromarray(image).resize((1024, 2048))  # 将拼接后的numpy数组转换为图像对象，并调整大小为1024x2048像素
image  # 输出最终生成的图像对象，用于显示图像</code></pre> 
<ul><li> <p>设置正向提示词，反向提示词，执行次数，图片尺寸</p> </li><li> <p>设置随机种子，控制图片是否可以重复生成，并将图像保存为 <code>.jpg</code> 文件。</p> </li><li> <p>最后，将生成的多个图像合并成一个大图像，并调整大小。</p> </li></ul> 
<p></p> 
<h3>赛事演练一一基于话剧的连环画制作</h3> 
<h4><span style="color:#4da8ee;">提示词的构思</span></h4> 
<p>可图Kolors-LoRA风格故事挑战赛的赛事任务是基于LoRA模型生成 8 张图片组成连贯故事。</p> 
<p>所以，我们要构思八张图片的提示词，而且还要保证故事的连贯性。</p> 
<p></p> 
<p>对与我们没有经验的新手来说，这是一个大难题。下面是我在实践过程中使用方法：</p> 
<p></p> 
<h5>1.提示词生成器</h5> 
<p><a class="has-card" href="http://www.atoolbox.net/Tool.php?Id=1101" rel="nofollow" title="AI绘画提示词生成器 - 一个工具箱 - 好用的在线工具都在这里！ (atoolbox.net)"><span class="link-card-box"><span class="link-title">AI绘画提示词生成器 - 一个工具箱 - 好用的在线工具都在这里！ (atoolbox.net)</span><span class="link-link"><img class="link-link-icon" src="https://images2.imgbox.com/e6/9f/27aVUrbT_o.png" alt="icon-default.png?t=N7T8">http://www.atoolbox.net/Tool.php?Id=1101</span></span></a></p> 
<p> 这个网站收集常用的800多个AI绘画常用的提示词和标签，我们可以从中积累提示词和组合。</p> 
<p></p> 
<h5>2.用AI生成提示词</h5> 
<p>没有思路，不妨用“魔法”打败“魔法”。我们可以用AI助手根据我们的要求来生成提示词。</p> 
<p>不仅简单方便，而且可以避免AI理解不了提示词的情况。</p> 
<p></p> 
<p>而我使用的AI助手是通义千问——</p> 
<p><a class="has-card" href="https://tongyi.aliyun.com/qianwen/?st=null" rel="nofollow" title="通义tongyi.ai_你的全能AI助手 (aliyun.com)"><span class="link-card-box"><span class="link-title">通义tongyi.ai_你的全能AI助手 (aliyun.com)</span><span class="link-link"><img class="link-link-icon" src="https://images2.imgbox.com/78/e7/6ROakyF1_o.png" alt="icon-default.png?t=N7T8">https://tongyi.aliyun.com/qianwen/?st=null</span></span></a></p> 
<p> 询问提示词的文案例子如下：</p> 
<pre><code class="hljs">你是一个文生图专家，我们现在要做一个实战项目，就是要编排一个文生图话剧
话剧由8张场景图片生成，你需要输出每张图片的生图提示词

具体的场景图片
1、女主正在上课
2、开始睡着了
3、进入梦乡，梦到自己站在路旁
4、王子骑马而来
5、两人相谈甚欢
6、一起坐在马背上
7、下课了，梦醒了
8、又回到了学习生活中

生图提示词要求
1、风格为古风
2、根据场景确定是使用全身还是上半身
3、人物描述
4、场景描述
5、做啥事情

例子：
古风，水墨画，一个黑色长发少女，坐在教室里，盯着黑板，深思，上半身，红色长裙</code></pre> 
<p></p> 
<h4>执行baseline生成图片 </h4> 
<p></p> 
<p>将场景和提示词整理成表格</p> 
<table><tbody><tr><td colspan="1" rowspan="1"> <p><strong>图片编号</strong></p> </td><td colspan="1" rowspan="1"> <p><strong>场景描述</strong></p> </td><td colspan="1" rowspan="1"> <p><strong>正向提示词</strong></p> </td><td colspan="1" rowspan="1"> <p><strong>反向提示词</strong></p> </td></tr><tr><td colspan="1" rowspan="1"> <p>图片1</p> </td><td colspan="1" rowspan="1"> <p>男主正在上课</p> </td><td colspan="1" rowspan="1"> <p>古风，水墨画，一个黑发男生，坐在教室里，盯着黑板，深思，上半身，校服</p> </td><td colspan="1" rowspan="1"> <p>丑陋，变形，嘈杂，模糊，低对比度</p> </td></tr><tr><td colspan="1" rowspan="1"> <p>图片2</p> </td><td colspan="1" rowspan="1"> <p>开始睡着了</p> </td><td colspan="1" rowspan="1"> <p>古风，水墨画，一个黑发男生，坐在教室里，趴在桌子上睡着了，上半身，校服</p> </td><td colspan="1" rowspan="1"> <p>丑陋，变形，嘈杂，模糊，低对比度</p> </td></tr><tr><td colspan="1" rowspan="1"> <p>图片3</p> </td><td colspan="1" rowspan="1"> <p>进入梦乡，梦到自己成为大侠</p> </td><td colspan="1" rowspan="1">古风，水墨画，背影，一个黑色长发男生，站在屋檐上，古代服饰，手中拿着长剑</td><td colspan="1" rowspan="1"> <p>丑陋，变形，嘈杂，模糊，低对比度</p> </td></tr><tr><td colspan="1" rowspan="1"> <p>图片4</p> </td><td colspan="1" rowspan="1"> <p>一场大战来临</p> </td><td colspan="1" rowspan="1"> <p>古风，水墨画，全景，侧身，一个白衣黑发男生，站在屋檐上，古代服饰，手中拿着长剑，剑指一个黑衣男人</p> </td><td colspan="1" rowspan="1"> <p>丑陋，变形，嘈杂，模糊，低对比度</p> </td></tr><tr><td colspan="1" rowspan="1"> <p>图片5</p> </td><td colspan="1" rowspan="1"> <p>两人交锋</p> </td><td colspan="1" rowspan="1"> <p>古风，水墨画，集中于人脸，一个白衣黑发男生和一个黑衣男人，古代服饰，拿着剑，剑与剑碰撞出火花</p> </td><td colspan="1" rowspan="1"> <p>丑陋，变形，嘈杂，模糊，低对比度</p> </td></tr><tr><td colspan="1" rowspan="1"> <p>图片6</p> </td><td colspan="1" rowspan="1"> <p>获得胜利</p> </td><td colspan="1" rowspan="1"> <p>古风，水墨画，全景，一个白衣黑发男生，站在屋檐上，古代服饰，手中高举长剑，剑上沾着血</p> </td><td colspan="1" rowspan="1"> <p>丑陋，变形，嘈杂，模糊，低对比度</p> </td></tr><tr><td colspan="1" rowspan="1"> <p>图片7</p> </td><td colspan="1" rowspan="1"> <p>下课了，梦醒了</p> </td><td colspan="1" rowspan="1"> <p>古风，水墨画，一个黑发男生，坐在教室里，下课铃声响了，同学们开始走动，从睡梦中醒来，深思，上半身，校服</p> </td><td colspan="1" rowspan="1"> <p>丑陋，变形，嘈杂，模糊，低对比度</p> </td></tr><tr><td colspan="1" rowspan="1"> <p>图片8</p> </td><td colspan="1" rowspan="1"> <p>又回到了学习生活中</p> </td><td colspan="1" rowspan="1"> <p>古风，水墨画，上半身，一个黑发男生，坐在教室里，看着窗外，校服</p> </td><td colspan="1" rowspan="1"> <p>丑陋，变形，嘈杂，模糊，低对比度</p> </td></tr></tbody></table> 
<p></p> 
<h4>成品展示</h4> 
<p style="text-align:center;"></p> 
<p style="text-align:center;"></p> 
<p><img alt="" height="1200" src="https://images2.imgbox.com/ae/fe/4fUoiNfb_o.png" width="1024"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/776f12c26c377787ecca9c8bf854ac8b/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【C&#43;&#43;】—— 类与对象（五）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/fdd5175c1e7fc5318498ef410cf5615e/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【C语言初阶】C语言指针全攻略：解锁C语言深层奥秘的钥匙</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>