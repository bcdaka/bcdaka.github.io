<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【记录】LangChain｜Ollama结合LangChain使用的速通版（包含代码以及切换各种模型的方式） - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/e8c93409221424d29eb45a443985545a/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="【记录】LangChain｜Ollama结合LangChain使用的速通版（包含代码以及切换各种模型的方式）">
  <meta property="og:description" content="官方教程非常长，我看了很认可，但是看完了之后呢就需要一些整理得当的笔记让我自己能更快地找到需求。所以有了这篇文章。【写给自己看的，里面半句废话的解释都没有，如果看不懂的话直接看官方教程再看我的】
ollama是个平台，里面一大堆开源模型，llama是ollama平台上的某个开源模型的名字。个人把llama理解成ollama平台抛砖引玉的砖。
我是不打算一开始就用OpenAI的，打算先用一下开源模型。之后我还会写一篇OpenAI的速通版。
文章目录 前置准备用Prompt模板增加context：自定义文档内容增加context：从网页中获取文档内容增加context：从PDF中获取文档内容用文档检索器 （RAG方法） 增加chat_history：利用MessagesPlaceholder切换LLM model后话 前置准备 pip install langchain curl -fsSL https://ollama.com/install.sh | sh # linux装llama2的指令 # 如果用的是Windows或者MacOS，前往这里下载：https://ollama.com/ 用Prompt模板 from langchain_community.llms import Ollama from langchain_core.prompts import ChatPromptTemplate from langchain_core.output_parsers import StrOutputParser output_parser = StrOutputParser() llm = Ollama(model=&#34;llama2&#34;) prompt = ChatPromptTemplate.from_messages([ (&#34;system&#34;, &#34;You are world class technical documentation writer.&#34;), (&#34;user&#34;, &#34;{input}&#34;) ]) chain = prompt | llm | output_parser print(chain.invoke({&#34;input&#34;: &#34;how can langsmith help with testing?&#34;})) 增加context：自定义文档内容 from langchain_community.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-05-11T12:01:25+08:00">
    <meta property="article:modified_time" content="2024-05-11T12:01:25+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【记录】LangChain｜Ollama结合LangChain使用的速通版（包含代码以及切换各种模型的方式）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-tomorrow-night-eighties">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p><a href="https://python.langchain.com/docs/get_started/quickstart/" rel="nofollow">官方教程</a>非常长，我看了很认可，但是看完了之后呢就需要一些整理得当的笔记让我自己能更快地找到需求。所以有了这篇文章。【写给自己看的，里面半句废话的解释都没有，如果看不懂的话直接看官方教程再看我的】</p> 
<blockquote> 
 <p>ollama是个平台，里面一大堆开源模型，llama是ollama平台上的某个开源模型的名字。个人把llama理解成ollama平台抛砖引玉的砖。</p> 
</blockquote> 
<p>我是不打算一开始就用OpenAI的，打算先用一下开源模型。之后我还会写一篇OpenAI的速通版。</p> 
<p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><ul><li><a href="#_7" rel="nofollow">前置准备</a></li><li><a href="#Prompt_15" rel="nofollow">用Prompt模板</a></li><li><a href="#context_34" rel="nofollow">增加context：自定义文档内容</a></li><li><ul><li><a href="#context_61" rel="nofollow">增加context：从网页中获取文档内容</a></li><li><a href="#contextPDF_72" rel="nofollow">增加context：从PDF中获取文档内容</a></li><li><a href="#_RAG_83" rel="nofollow">用文档检索器 （RAG方法）</a></li></ul> 
   </li><li><a href="#chat_historyMessagesPlaceholder_133" rel="nofollow">增加chat_history：利用MessagesPlaceholder</a></li><li><a href="#LLM_model_200" rel="nofollow">切换LLM model</a></li><li><a href="#_221" rel="nofollow">后话</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h3><a id="_7"></a>前置准备</h3> 
<pre><code class="prism language-bash">pip <span class="token function">install</span> langchain
<span class="token function">curl</span> <span class="token parameter variable">-fsSL</span> https://ollama.com/install.sh <span class="token operator">|</span> <span class="token function">sh</span> <span class="token comment"># linux装llama2的指令</span>
<span class="token comment"># 如果用的是Windows或者MacOS，前往这里下载：https://ollama.com/</span>
</code></pre> 
<h3><a id="Prompt_15"></a>用Prompt模板</h3> 
<pre><code class="prism language-python"><span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>llms <span class="token keyword">import</span> Ollama
<span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> ChatPromptTemplate
<span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>output_parsers <span class="token keyword">import</span> StrOutputParser

output_parser <span class="token operator">=</span> StrOutputParser<span class="token punctuation">(</span><span class="token punctuation">)</span>

llm <span class="token operator">=</span> Ollama<span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"llama2"</span><span class="token punctuation">)</span>
prompt <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">.</span>from_messages<span class="token punctuation">(</span><span class="token punctuation">[</span>
    <span class="token punctuation">(</span><span class="token string">"system"</span><span class="token punctuation">,</span> <span class="token string">"You are world class technical documentation writer."</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"{input}"</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
chain <span class="token operator">=</span> prompt <span class="token operator">|</span> llm <span class="token operator">|</span> output_parser

<span class="token keyword">print</span><span class="token punctuation">(</span>chain<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span><span class="token string">"input"</span><span class="token punctuation">:</span> <span class="token string">"how can langsmith help with testing?"</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="context_34"></a>增加context：自定义文档内容</h3> 
<pre><code class="prism language-python"><span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>llms <span class="token keyword">import</span> Ollama
<span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> ChatPromptTemplate
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains<span class="token punctuation">.</span>combine_documents <span class="token keyword">import</span> create_stuff_documents_chain

llm <span class="token operator">=</span> Ollama<span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"llama2"</span><span class="token punctuation">)</span>

prompt <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">.</span>from_template<span class="token punctuation">(</span><span class="token triple-quoted-string string">"""Answer the following question based only on the provided context:

&lt;context&gt;
{context}
&lt;/context&gt;

Question: {input}"""</span><span class="token punctuation">)</span>

document_chain <span class="token operator">=</span> create_stuff_documents_chain<span class="token punctuation">(</span>llm<span class="token punctuation">,</span> prompt<span class="token punctuation">)</span>

<span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>documents <span class="token keyword">import</span> Document
docs <span class="token operator">=</span> <span class="token punctuation">[</span>Document<span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token string">"langsmith can let you visualize test results"</span><span class="token punctuation">)</span><span class="token punctuation">]</span>

document_chain<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span>
    <span class="token string">"input"</span><span class="token punctuation">:</span> <span class="token string">"how can langsmith help with testing?"</span><span class="token punctuation">,</span>
    <span class="token string">"context"</span><span class="token punctuation">:</span> docs
<span class="token punctuation">}</span><span class="token punctuation">)</span>
</code></pre> 
<h4><a id="context_61"></a>增加context：从网页中获取文档内容</h4> 
<p>下面这个代码会读网页的内容到docs里，可以替代上一节的<code>docs = Document(page_content="langsmith can let you visualize test results")</code>部分。</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>document_loaders <span class="token keyword">import</span> WebBaseLoader
loader <span class="token operator">=</span> WebBaseLoader<span class="token punctuation">(</span><span class="token string">"https://bbs.csdn.net/topics/618378840"</span><span class="token punctuation">)</span>

docs <span class="token operator">=</span> loader<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<h4><a id="contextPDF_72"></a>增加context：从PDF中获取文档内容</h4> 
<pre><code class="prism language-python"><span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>document_loaders <span class="token keyword">import</span> PyPDFLoader
loader <span class="token operator">=</span> PyPDFLoader<span class="token punctuation">(</span><span class="token string">"3399.pdf"</span><span class="token punctuation">)</span>

docs <span class="token operator">=</span> loader<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p>注意，根据我的观察，LangChain的PDF loader 是基于 pypdf 的，而实际上pypdf 不是很好用，对表格之类的信息更是一塌糊涂，我更喜欢自己解析一下PDF文件。详情可以看这篇文章：<a href="https://blog.csdn.net/qq_46106285/article/details/137059931">【记录】Python｜处理PDF的第三方库的对比大全（2024年）</a></p> 
<h4><a id="_RAG_83"></a>用文档检索器 （RAG方法）</h4> 
<p>文档检索器的作用是根据一些加权，来判断所有的文档列表中哪一个文档是最适合当前的提问的。</p> 
<p>下面的代码中增加了矢量检索器，详细的原理介绍见<a href="https://python.langchain.com/docs/modules/data_connection/vectorstores/" rel="nofollow">这里</a>（具体原理我也没看，直觉上就是给文本加权重然后算一算这样）。根据官方说，它还可以加SQL 表、互联网等，我也没看懂。</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>llms <span class="token keyword">import</span> Ollama
<span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> ChatPromptTemplate
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains<span class="token punctuation">.</span>combine_documents <span class="token keyword">import</span> create_stuff_documents_chain

llm <span class="token operator">=</span> Ollama<span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"llama2"</span><span class="token punctuation">)</span>

prompt <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">.</span>from_template<span class="token punctuation">(</span><span class="token triple-quoted-string string">"""Answer the following question based only on the provided context:

&lt;context&gt;
{context}
&lt;/context&gt;

Question: {input}"""</span><span class="token punctuation">)</span>

document_chain <span class="token operator">=</span> create_stuff_documents_chain<span class="token punctuation">(</span>llm<span class="token punctuation">,</span> prompt<span class="token punctuation">)</span>

<span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>documents <span class="token keyword">import</span> Document
docs <span class="token operator">=</span> <span class="token punctuation">[</span>Document<span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token string">"langsmith can let you visualize test results"</span><span class="token punctuation">)</span><span class="token punctuation">]</span>

<span class="token keyword">from</span> langchain_text_splitters <span class="token keyword">import</span> RecursiveCharacterTextSplitter
text_splitter <span class="token operator">=</span> RecursiveCharacterTextSplitter<span class="token punctuation">(</span><span class="token punctuation">)</span>
documents <span class="token operator">=</span> text_splitter<span class="token punctuation">.</span>split_documents<span class="token punctuation">(</span>docs<span class="token punctuation">)</span>

<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>embeddings <span class="token keyword">import</span> OllamaEmbeddings
embeddings <span class="token operator">=</span> OllamaEmbeddings<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>vectorstores <span class="token keyword">import</span> FAISS
vector <span class="token operator">=</span> FAISS<span class="token punctuation">.</span>from_documents<span class="token punctuation">(</span>documents<span class="token punctuation">,</span> embeddings<span class="token punctuation">)</span>

<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>embeddings <span class="token keyword">import</span> OllamaEmbeddings
embeddings <span class="token operator">=</span> OllamaEmbeddings<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>vectorstores <span class="token keyword">import</span> FAISS
vector <span class="token operator">=</span> FAISS<span class="token punctuation">.</span>from_documents<span class="token punctuation">(</span>documents<span class="token punctuation">,</span> embeddings<span class="token punctuation">)</span>

<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains <span class="token keyword">import</span> create_retrieval_chain

retriever <span class="token operator">=</span> vector<span class="token punctuation">.</span>as_retriever<span class="token punctuation">(</span><span class="token punctuation">)</span>
retrieval_chain <span class="token operator">=</span> create_retrieval_chain<span class="token punctuation">(</span>retriever<span class="token punctuation">,</span> document_chain<span class="token punctuation">)</span>

response <span class="token operator">=</span> retrieval_chain<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span><span class="token string">"input"</span><span class="token punctuation">:</span> <span class="token string">"how can langsmith help with testing?"</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">[</span><span class="token string">"answer"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="chat_historyMessagesPlaceholder_133"></a>增加chat_history：利用MessagesPlaceholder</h3> 
<p>总之就是改了Prompt结构，再多引入了一个create_history_aware_retriever函数。</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>llms <span class="token keyword">import</span> Ollama
<span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> ChatPromptTemplate
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains<span class="token punctuation">.</span>combine_documents <span class="token keyword">import</span> create_stuff_documents_chain

llm <span class="token operator">=</span> Ollama<span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"llama2"</span><span class="token punctuation">)</span>

<span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> MessagesPlaceholder
prompt <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">.</span>from_messages<span class="token punctuation">(</span><span class="token punctuation">[</span>
    <span class="token punctuation">(</span><span class="token string">"system"</span><span class="token punctuation">,</span> <span class="token triple-quoted-string string">"""Answer the user's questions based on the below context:

&lt;context&gt;
{context}
&lt;/context&gt;"""</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    MessagesPlaceholder<span class="token punctuation">(</span>variable_name<span class="token operator">=</span><span class="token string">"chat_history"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"{input}"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment">## Add MessagesPlaceholder</span>

document_chain <span class="token operator">=</span> create_stuff_documents_chain<span class="token punctuation">(</span>llm<span class="token punctuation">,</span> prompt<span class="token punctuation">)</span>

<span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>documents <span class="token keyword">import</span> Document
docs <span class="token operator">=</span> <span class="token punctuation">[</span>Document<span class="token punctuation">(</span>page_content<span class="token operator">=</span><span class="token string">"langsmith can let you visualize test results"</span><span class="token punctuation">)</span><span class="token punctuation">]</span>

<span class="token keyword">from</span> langchain_text_splitters <span class="token keyword">import</span> RecursiveCharacterTextSplitter
text_splitter <span class="token operator">=</span> RecursiveCharacterTextSplitter<span class="token punctuation">(</span><span class="token punctuation">)</span>
documents <span class="token operator">=</span> text_splitter<span class="token punctuation">.</span>split_documents<span class="token punctuation">(</span>docs<span class="token punctuation">)</span>

<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>embeddings <span class="token keyword">import</span> OllamaEmbeddings
embeddings <span class="token operator">=</span> OllamaEmbeddings<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>vectorstores <span class="token keyword">import</span> FAISS
vector <span class="token operator">=</span> FAISS<span class="token punctuation">.</span>from_documents<span class="token punctuation">(</span>documents<span class="token punctuation">,</span> embeddings<span class="token punctuation">)</span>

<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>embeddings <span class="token keyword">import</span> OllamaEmbeddings
embeddings <span class="token operator">=</span> OllamaEmbeddings<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>vectorstores <span class="token keyword">import</span> FAISS
vector <span class="token operator">=</span> FAISS<span class="token punctuation">.</span>from_documents<span class="token punctuation">(</span>documents<span class="token punctuation">,</span> embeddings<span class="token punctuation">)</span>

<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains <span class="token keyword">import</span> create_retrieval_chain

<span class="token comment">##-- Start changing --##</span>
retriever <span class="token operator">=</span> vector<span class="token punctuation">.</span>as_retriever<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains <span class="token keyword">import</span> create_history_aware_retriever
retriever_chain <span class="token operator">=</span> create_history_aware_retriever<span class="token punctuation">(</span>llm<span class="token punctuation">,</span> retriever<span class="token punctuation">,</span> prompt<span class="token punctuation">)</span>

<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains <span class="token keyword">import</span> create_retrieval_chain
retrieval_chain <span class="token operator">=</span> create_retrieval_chain<span class="token punctuation">(</span>retriever_chain<span class="token punctuation">,</span> document_chain<span class="token punctuation">)</span>

<span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>messages <span class="token keyword">import</span> HumanMessage<span class="token punctuation">,</span> AIMessage

chat_history <span class="token operator">=</span> <span class="token punctuation">[</span>HumanMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"Can LangSmith help test my LLM applications?"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> AIMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"Yes!"</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
response <span class="token operator">=</span> retrieval_chain<span class="token punctuation">.</span>invoke<span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span>
    <span class="token string">"chat_history"</span><span class="token punctuation">:</span> chat_history<span class="token punctuation">,</span>
    <span class="token string">"input"</span><span class="token punctuation">:</span> <span class="token string">"Tell me how"</span><span class="token punctuation">,</span>
    <span class="token string">"context"</span><span class="token punctuation">:</span> <span class="token string">""</span> <span class="token comment"># I don't know why the 'context' variable is needed here, but it is required by the 'prompt' variable.</span>
<span class="token punctuation">}</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">)</span>
</code></pre> 
<p>运行结果：<br> <img src="https://images2.imgbox.com/aa/0c/hrsSoVqQ_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="LLM_model_200"></a>切换LLM model</h3> 
<p>ollama中包含了许多开源大模型，llama2只是其中的只有3.8G的一个小模型llama2:7b罢了。<br> 为了实现更好的效果，建议用更大的模型比如13b或者70b。</p> 
<p>运行大模型只需要对应的内存满足要求就可以了，不需要像训练那样需要太多的GPU开销啥的，挺划算的也挺好部署的，你们也可以试试用比较大的开源模型而不是用初始的那个llama2:7b。</p> 
<p>切换模型很简单，步骤如下：</p> 
<ol><li>打开<a href="https://ollama.com/library" rel="nofollow">https://ollama.com/library</a>找到你想要的模型。</li><li>以llama2:13b为例。切换分支到13b，关注指令pull后接的名称（这里是<code>llama2:13b</code>）。<img src="https://images2.imgbox.com/c5/a8/qI0nvpe4_o.png" alt="在这里插入图片描述"></li><li>复制pull指令并粘贴到终端：<code>ollama run llama2:13b</code>。</li><li>修改代码，把model=后面的llama2改成对应的名称即可，如下所示：<pre><code class="prism language-python"><span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>llms <span class="token keyword">import</span> Ollama
llm <span class="token operator">=</span> Ollama<span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"llama2:13b"</span><span class="token punctuation">)</span>
</code></pre> </li></ol> 
<h3><a id="_221"></a>后话</h3> 
<p><a href="https://python.langchain.com/docs/get_started/quickstart/#agent" rel="nofollow">代理</a>那一节，官方说本地模型的代理不可靠，而且这个也只是调用一些其他工具API，有需求的话自己看一下，我对这个没需求。</p> 
<p>至于后面的 langserve 的介绍，对我挺有用的但是暂时不需要写这个部分的代码，所以我寻思着以后要用了再写下一篇博客吧，这篇博客差不多长度了。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/c1681b8f2918635ec797455ca7cba5f4/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Kafka学习-Java使用Kafka</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/43825f31efd7781eeebb3615d59eea38/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">大文件传输的好帮手Libarchive：功能强大的开源归档文件处理库</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>