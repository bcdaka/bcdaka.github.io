<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>大数据-104 Spark Streaming Kafka Offset Scala实现Redis管理Offset并更新 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/c3fb28b185c79b4d236ca8192c76fa98/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="大数据-104 Spark Streaming Kafka Offset Scala实现Redis管理Offset并更新">
  <meta property="og:description" content="点一下关注吧！！！非常感谢！！持续更新！！！ 目前已经更新到了： Hadoop（已更完）HDFS（已更完）MapReduce（已更完）Hive（已更完）Flume（已更完）Sqoop（已更完）Zookeeper（已更完）HBase（已更完）Redis （已更完）Kafka（已更完）Spark（正在更新！） 章节内容 上节完成了如下的内容：
Spark Streaming Kafka自定义管理Offset Scala代码实现
Offset 管理 Spark Streaming 集成Kafka，允许从Kafka中读取一个或者多个Topic的数据，一个Kafka Topic包含一个或者多个分区，每个分区中的消息顺序存储，并使用offset来标记消息位置，开发者可以在Spark Streaming应用中通过offset来控制数据的读取位置。
Offsets 管理对于保证流式应用在整个生命周期中数据的连贯性是非常重要的，如果在应用停止或者报错退出之前将Offset持久化保存，该消息就会丢失，那么Spark Streaming就没有办法从上次停止或保存的位置继续消费Kafka中的消息。
Spark Streaming 与 Kafka 的集成 Spark Streaming 可以通过 KafkaUtils.createDirectStream 直接与 Kafka 集成。这种方式不会依赖于 ZooKeeper，而是直接从 Kafka 分区中读取数据。
在这种直接方式下，Spark Streaming 依赖 Kafka 的 API 来管理和存储消费者偏移量（Offsets），默认情况下偏移量保存在 Kafka 自身的 __consumer_offsets 主题中。
使用 Redis 管理 Offsets Redis 作为一个高效的内存数据库，常用于存储 Spark Streaming 中的 Kafka 偏移量。
通过手动管理偏移量，你可以在每批次数据处理后，将当前批次的 Kafka 偏移量存储到 Redis 中。这样，在应用程序重新启动时，可以从 Redis 中读取最后处理的偏移量，从而从正确的位置继续消费 Kafka 数据。
实现步骤 从 Redis 获取偏移量 应用启动时，从 Redis 中读取上次处理的偏移量，并从这些偏移量开始消费 Kafka 数据。">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-08-27T09:33:12+08:00">
    <meta property="article:modified_time" content="2024-08-27T09:33:12+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">大数据-104 Spark Streaming Kafka Offset Scala实现Redis管理Offset并更新</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_0"></a>点一下关注吧！！！非常感谢！！持续更新！！！</h2> 
<h2><a id="_1"></a>目前已经更新到了：</h2> 
<ul><li>Hadoop（已更完）</li><li>HDFS（已更完）</li><li>MapReduce（已更完）</li><li>Hive（已更完）</li><li>Flume（已更完）</li><li>Sqoop（已更完）</li><li>Zookeeper（已更完）</li><li>HBase（已更完）</li><li>Redis （已更完）</li><li>Kafka（已更完）</li><li>Spark（正在更新！）</li></ul> 
<h2><a id="_14"></a>章节内容</h2> 
<p>上节完成了如下的内容：</p> 
<ul><li>Spark Streaming Kafka</li><li>自定义管理Offset Scala代码实现<br> <img src="https://images2.imgbox.com/a4/87/mPP9a0Y2_o.png" alt="在这里插入图片描述"></li></ul> 
<h2><a id="Offset__19"></a>Offset 管理</h2> 
<p>Spark Streaming 集成Kafka，允许从Kafka中读取一个或者多个Topic的数据，一个Kafka Topic包含一个或者多个分区，每个分区中的消息顺序存储，并使用offset来标记消息位置，开发者可以在Spark Streaming应用中通过offset来控制数据的读取位置。<br> Offsets 管理对于保证流式应用在整个生命周期中数据的连贯性是非常重要的，如果在应用停止或者报错退出之前将Offset持久化保存，该消息就会丢失，那么Spark Streaming就没有办法从上次停止或保存的位置继续消费Kafka中的消息。</p> 
<h3><a id="Spark_Streaming__Kafka__23"></a>Spark Streaming 与 Kafka 的集成</h3> 
<p>Spark Streaming 可以通过 KafkaUtils.createDirectStream 直接与 Kafka 集成。这种方式不会依赖于 ZooKeeper，而是直接从 Kafka 分区中读取数据。<br> 在这种直接方式下，Spark Streaming 依赖 Kafka 的 API 来管理和存储消费者偏移量（Offsets），默认情况下偏移量保存在 Kafka 自身的 __consumer_offsets 主题中。</p> 
<h3><a id="_Redis__Offsets_27"></a>使用 Redis 管理 Offsets</h3> 
<p>Redis 作为一个高效的内存数据库，常用于存储 Spark Streaming 中的 Kafka 偏移量。<br> 通过手动管理偏移量，你可以在每批次数据处理后，将当前批次的 Kafka 偏移量存储到 Redis 中。这样，在应用程序重新启动时，可以从 Redis 中读取最后处理的偏移量，从而从正确的位置继续消费 Kafka 数据。</p> 
<h3><a id="_31"></a>实现步骤</h3> 
<h4><a id="_Redis__32"></a>从 Redis 获取偏移量</h4> 
<p>应用启动时，从 Redis 中读取上次处理的偏移量，并从这些偏移量开始消费 Kafka 数据。</p> 
<h4><a id="_34"></a>处理数据</h4> 
<p>通过 Spark Streaming 处理从 Kafka 消费到的数据。</p> 
<h4><a id="_Redis_36"></a>保存偏移量到 Redis</h4> 
<p>每处理完一批数据后，将最新的偏移量存储到 Redis 中。这样，如果应用程序崩溃或重启，可以从这个位置继续消费。</p> 
<h3><a id="OffsetsKeyRedisOffsets_Redis_39"></a>自定义Offsets：根据Key从Redis获取Offsets 处理完更新Redis</h3> 
<h4><a id="_40"></a>添加依赖</h4> 
<pre><code class="prism language-xml"><span class="token comment">&lt;!-- jedis --&gt;</span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>redis.clients<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>jedis<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>2.9.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
</code></pre> 
<p>服务器上我们需要有：<br> Redis服务启动<br> <img src="https://images2.imgbox.com/00/4e/MS4KfnHj_o.png" alt="在这里插入图片描述"><br> Kafka服务启动<br> <img src="https://images2.imgbox.com/77/7e/01UPsGhK_o.png" alt="在这里插入图片描述"><br> 编写代码，实现的主要逻辑如下所示：</p> 
<pre><code class="prism language-scala"><span class="token keyword">package</span> <span class="token namespace">icu<span class="token punctuation">.</span>wzk</span>

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>ConsumerConfig<span class="token punctuation">,</span> ConsumerRecord<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>common<span class="token punctuation">.</span></span>TopicPartition
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>common<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span></span>StringDeserializer
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>log4j<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>Level<span class="token punctuation">,</span> Logger<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span>SparkConf
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>dstream<span class="token punctuation">.</span></span>InputDStream
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>kafka010<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>ConsumerStrategies<span class="token punctuation">,</span> HasOffsetRanges<span class="token punctuation">,</span> KafkaUtils<span class="token punctuation">,</span> LocationStrategies<span class="token punctuation">,</span> OffsetRange<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>Seconds<span class="token punctuation">,</span> StreamingContext<span class="token punctuation">}</span>

<span class="token keyword">object</span> KafkaDStream3 <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    Logger<span class="token punctuation">.</span>getLogger<span class="token punctuation">(</span><span class="token string">"args"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setLevel<span class="token punctuation">(</span>Level<span class="token punctuation">.</span>ERROR<span class="token punctuation">)</span>
    <span class="token keyword">val</span> conf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"KafkaDStream3"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> ssc <span class="token operator">=</span> <span class="token keyword">new</span> StreamingContext<span class="token punctuation">(</span>conf<span class="token punctuation">,</span> Seconds<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> groupId<span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span> <span class="token string">"wzkicu"</span>
    <span class="token keyword">val</span> topics<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> Array<span class="token punctuation">(</span><span class="token string">"spark_streaming_test01"</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> kafkaParams<span class="token operator">:</span> Map<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> Object<span class="token punctuation">]</span> <span class="token operator">=</span> getKafkaConsumerParameters<span class="token punctuation">(</span>groupId<span class="token punctuation">)</span>

    <span class="token comment">// 从 Kafka 获取 Offsets</span>
    <span class="token keyword">val</span> offsets<span class="token operator">:</span> Map<span class="token punctuation">[</span>TopicPartition<span class="token punctuation">,</span> <span class="token builtin">Long</span><span class="token punctuation">]</span> <span class="token operator">=</span> OffsetsRedisUtils<span class="token punctuation">.</span>getOffsetsFromRedis<span class="token punctuation">(</span>topics<span class="token punctuation">,</span> groupId<span class="token punctuation">)</span>

    <span class="token comment">// 创建 DStream</span>
    <span class="token keyword">val</span> dstream<span class="token operator">:</span> InputDStream<span class="token punctuation">[</span>ConsumerRecord<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> KafkaUtils<span class="token punctuation">.</span>createDirectStream<span class="token punctuation">(</span>
      ssc<span class="token punctuation">,</span>
      LocationStrategies<span class="token punctuation">.</span>PreferConsistent<span class="token punctuation">,</span>
      ConsumerStrategies<span class="token punctuation">.</span>Subscribe<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span>topics<span class="token punctuation">,</span> kafkaParams<span class="token punctuation">,</span> offsets<span class="token punctuation">)</span>
    <span class="token punctuation">)</span>

    <span class="token comment">// DStream 转换&amp;输出</span>
    dstream<span class="token punctuation">.</span>foreachRDD <span class="token punctuation">{<!-- --></span>
      <span class="token punctuation">(</span>rdd<span class="token punctuation">,</span> time<span class="token punctuation">)</span> <span class="token keyword">=&gt;</span>
        <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>rdd<span class="token punctuation">.</span>isEmpty<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
          <span class="token comment">// 处理消息</span>
          println<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token id function">s</span><span class="token string">"====== rdd.count = </span><span class="token interpolation"><span class="token punctuation">${<!-- --></span><span class="token expression">rdd<span class="token punctuation">.</span>count<span class="token punctuation">(</span><span class="token punctuation">)</span></span><span class="token punctuation">}</span></span><span class="token string">, time = </span><span class="token interpolation"><span class="token punctuation">$</span><span class="token expression">time</span></span><span class="token string"> ======="</span></span><span class="token punctuation">)</span>
          <span class="token comment">// 将 Offsets 保存到 Redis</span>
          <span class="token keyword">val</span> offsetRanges<span class="token operator">:</span> Array<span class="token punctuation">[</span>OffsetRange<span class="token punctuation">]</span> <span class="token operator">=</span> rdd<span class="token punctuation">.</span>asInstanceOf<span class="token punctuation">[</span>HasOffsetRanges<span class="token punctuation">]</span><span class="token punctuation">.</span>offsetRanges
          OffsetsRedisUtils<span class="token punctuation">.</span>saveOffsetsToRedis<span class="token punctuation">(</span>offsetRanges<span class="token punctuation">,</span> groupId<span class="token punctuation">)</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>

    ssc<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>
    ssc<span class="token punctuation">.</span>awaitTermination<span class="token punctuation">(</span><span class="token punctuation">)</span>

  <span class="token punctuation">}</span>

  <span class="token keyword">private</span> <span class="token keyword">def</span> getKafkaConsumerParameters<span class="token punctuation">(</span>groupId<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token operator">:</span> Map<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> Object<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    Map<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> Object<span class="token punctuation">]</span><span class="token punctuation">(</span>
      ConsumerConfig<span class="token punctuation">.</span>BOOTSTRAP_SERVERS_CONFIG <span class="token operator">-&gt;</span> <span class="token string">"h121.wzk.icu:9092"</span><span class="token punctuation">,</span>
      ConsumerConfig<span class="token punctuation">.</span>KEY_DESERIALIZER_CLASS_CONFIG <span class="token operator">-&gt;</span> classOf<span class="token punctuation">[</span>StringDeserializer<span class="token punctuation">]</span><span class="token punctuation">,</span>
      ConsumerConfig<span class="token punctuation">.</span>VALUE_DESERIALIZER_CLASS_CONFIG <span class="token operator">-&gt;</span> classOf<span class="token punctuation">[</span>StringDeserializer<span class="token punctuation">]</span><span class="token punctuation">,</span>
      ConsumerConfig<span class="token punctuation">.</span>GROUP_ID_CONFIG <span class="token operator">-&gt;</span> groupId<span class="token punctuation">,</span>
      ConsumerConfig<span class="token punctuation">.</span>AUTO_OFFSET_RESET_CONFIG <span class="token operator">-&gt;</span> <span class="token string">"earliest"</span><span class="token punctuation">,</span>
      ConsumerConfig<span class="token punctuation">.</span>ENABLE_AUTO_COMMIT_CONFIG <span class="token operator">-&gt;</span> <span class="token punctuation">(</span><span class="token boolean">false</span><span class="token operator">:</span> java<span class="token punctuation">.</span>lang<span class="token punctuation">.</span><span class="token builtin">Boolean</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

</code></pre> 
<p>代码中我们封装了一个工具类：</p> 
<pre><code class="prism language-scala"><span class="token keyword">package</span> <span class="token namespace">icu<span class="token punctuation">.</span>wzk</span>

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>common<span class="token punctuation">.</span></span>TopicPartition
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>kafka010<span class="token punctuation">.</span></span>OffsetRange
<span class="token keyword">import</span> <span class="token namespace">redis<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>jedis<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>Jedis<span class="token punctuation">,</span> JedisPool<span class="token punctuation">,</span> JedisPoolConfig<span class="token punctuation">}</span>

<span class="token keyword">import</span> <span class="token namespace">scala<span class="token punctuation">.</span>collection<span class="token punctuation">.</span>mutable</span>

<span class="token keyword">object</span> OffsetsRedisUtils <span class="token punctuation">{<!-- --></span>

  <span class="token keyword">private</span> <span class="token keyword">val</span> config <span class="token operator">=</span> <span class="token keyword">new</span> JedisPoolConfig
  <span class="token keyword">private</span> <span class="token keyword">val</span> redisHost <span class="token operator">=</span> <span class="token string">"h121.wzk.icu"</span>
  <span class="token keyword">private</span> <span class="token keyword">val</span> redisPort <span class="token operator">=</span> <span class="token number">6379</span>

  config<span class="token punctuation">.</span>setMaxTotal<span class="token punctuation">(</span><span class="token number">30</span><span class="token punctuation">)</span>
  config<span class="token punctuation">.</span>setMaxIdle<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span>

  <span class="token keyword">private</span> <span class="token keyword">val</span> pool<span class="token operator">=</span> <span class="token keyword">new</span> JedisPool<span class="token punctuation">(</span>config<span class="token punctuation">,</span> redisHost<span class="token punctuation">,</span> redisPort<span class="token punctuation">,</span> <span class="token number">10000</span><span class="token punctuation">)</span>
  <span class="token keyword">private</span> <span class="token keyword">val</span> topicPrefix <span class="token operator">=</span> <span class="token string">"kafka:topic"</span>

  <span class="token keyword">private</span> <span class="token keyword">def</span> getKey<span class="token punctuation">(</span>topic<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> groupId<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> prefix<span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span> topicPrefix<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span> <span class="token string-interpolation"><span class="token id function">s</span><span class="token string">"</span><span class="token interpolation"><span class="token punctuation">$</span><span class="token expression">prefix</span></span><span class="token string">:</span><span class="token interpolation"><span class="token punctuation">$</span><span class="token expression">topic</span></span><span class="token string">:</span><span class="token interpolation"><span class="token punctuation">$</span><span class="token expression">groupId</span></span><span class="token string">"</span></span>
  <span class="token keyword">private</span> <span class="token keyword">def</span> getRedisConnection<span class="token operator">:</span> Jedis <span class="token operator">=</span> pool<span class="token punctuation">.</span>getResource

  <span class="token comment">// 从Redis中获取Offsets</span>
  <span class="token keyword">def</span> getOffsetsFromRedis<span class="token punctuation">(</span>topics<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">,</span> groupId<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token operator">:</span> Map<span class="token punctuation">[</span>TopicPartition<span class="token punctuation">,</span> <span class="token builtin">Long</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">val</span> jedis<span class="token operator">:</span> Jedis <span class="token operator">=</span> getRedisConnection
    <span class="token keyword">val</span> offsets<span class="token operator">:</span> Array<span class="token punctuation">[</span>mutable<span class="token punctuation">.</span>Map<span class="token punctuation">[</span>TopicPartition<span class="token punctuation">,</span> <span class="token builtin">Long</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> topics<span class="token punctuation">.</span>map <span class="token punctuation">{<!-- --></span>
      topic <span class="token keyword">=&gt;</span>
        <span class="token keyword">import</span> <span class="token namespace">scala<span class="token punctuation">.</span>collection<span class="token punctuation">.</span></span>JavaConverters<span class="token punctuation">.</span>_
        jedis<span class="token punctuation">.</span>hgetAll<span class="token punctuation">(</span>getKey<span class="token punctuation">(</span>topic<span class="token punctuation">,</span> groupId<span class="token punctuation">)</span><span class="token punctuation">)</span>
          <span class="token punctuation">.</span>asScala
          <span class="token punctuation">.</span>map <span class="token punctuation">{<!-- --></span>
            <span class="token keyword">case</span> <span class="token punctuation">(</span>partition<span class="token punctuation">,</span> offset<span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> <span class="token keyword">new</span> TopicPartition<span class="token punctuation">(</span>topic<span class="token punctuation">,</span> partition<span class="token punctuation">.</span>toInt<span class="token punctuation">)</span> <span class="token operator">-&gt;</span> offset<span class="token punctuation">.</span>toLong
          <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
    jedis<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
    offsets<span class="token punctuation">.</span>flatten<span class="token punctuation">.</span>toMap
  <span class="token punctuation">}</span>

  <span class="token comment">// 将 Offsets 保存到 Redis</span>
  <span class="token keyword">def</span> saveOffsetsToRedis<span class="token punctuation">(</span>ranges<span class="token operator">:</span> Array<span class="token punctuation">[</span>OffsetRange<span class="token punctuation">]</span><span class="token punctuation">,</span> groupId<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">val</span> jedis<span class="token operator">:</span> Jedis <span class="token operator">=</span> getRedisConnection
    ranges
      <span class="token punctuation">.</span>map<span class="token punctuation">(</span>range <span class="token keyword">=&gt;</span> <span class="token punctuation">(</span>range<span class="token punctuation">.</span>topic<span class="token punctuation">,</span> range<span class="token punctuation">.</span>partition <span class="token operator">-&gt;</span> range<span class="token punctuation">.</span>untilOffset<span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>groupBy<span class="token punctuation">(</span>_<span class="token punctuation">.</span>_1<span class="token punctuation">)</span>
      <span class="token punctuation">.</span>map <span class="token punctuation">{<!-- --></span>
        <span class="token keyword">case</span> <span class="token punctuation">(</span>topic<span class="token punctuation">,</span> buffer<span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> <span class="token punctuation">(</span>topic<span class="token punctuation">,</span> buffer<span class="token punctuation">.</span>map<span class="token punctuation">(</span>_<span class="token punctuation">.</span>_2<span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">}</span>
      <span class="token punctuation">.</span>foreach <span class="token punctuation">{<!-- --></span>
        <span class="token keyword">case</span> <span class="token punctuation">(</span>topic<span class="token punctuation">,</span> partitionAndOffset<span class="token punctuation">)</span> <span class="token keyword">=&gt;</span>
          <span class="token keyword">val</span> offsets<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> partitionAndOffset<span class="token punctuation">.</span>map<span class="token punctuation">(</span>elem <span class="token keyword">=&gt;</span> <span class="token punctuation">(</span>elem<span class="token punctuation">.</span>_1<span class="token punctuation">.</span>toString<span class="token punctuation">,</span> elem<span class="token punctuation">.</span>_2<span class="token punctuation">.</span>toString<span class="token punctuation">)</span><span class="token punctuation">)</span>
          <span class="token keyword">import</span> <span class="token namespace">scala<span class="token punctuation">.</span>collection<span class="token punctuation">.</span></span>JavaConverters<span class="token punctuation">.</span>_
          jedis<span class="token punctuation">.</span>hmset<span class="token punctuation">(</span>getKey<span class="token punctuation">(</span>topic<span class="token punctuation">,</span> groupId<span class="token punctuation">)</span><span class="token punctuation">,</span> offsets<span class="token punctuation">.</span>toMap<span class="token punctuation">.</span>asJava<span class="token punctuation">)</span>
      <span class="token punctuation">}</span>

    jedis<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>

<span class="token punctuation">}</span>

</code></pre> 
<p>我们启动后，如图所示：<br> <img src="https://images2.imgbox.com/16/67/iNTfzWbl_o.png" alt="在这里插入图片描述"><br> 这里我使用Redis查看当前的存储情况：<br> <img src="https://images2.imgbox.com/d1/6e/p43GeFrD_o.png" alt="在这里插入图片描述"><br> 可以看到当前已经写入了，我们继续启动 KafkaProducer工具，继续写入数据。<br> 可以看到，已经统计到数据了。<br> <img src="https://images2.imgbox.com/c9/04/mg5ZITNR_o.png" alt="在这里插入图片描述"><br> 我们继续查看当前的Redis中的数据：<br> <img src="https://images2.imgbox.com/60/d6/uomTYBfl_o.png" alt="在这里插入图片描述"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/e5d970dc58d56072334570dc1d1b6d0a/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">智能新时代：探索【人工智能】、【机器学习】与【深度学习】的前沿技术与应用</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/433f957509f06acb133fb4b9a046760e/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">10、Flink 动态表之更新和追加查询详解</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>