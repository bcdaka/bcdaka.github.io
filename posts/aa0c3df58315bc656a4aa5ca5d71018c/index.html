<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>秋叶V4.9整合包发布！什么是Stable Diffusion？如何安装Stable Diffusion？ - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/aa0c3df58315bc656a4aa5ca5d71018c/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="秋叶V4.9整合包发布！什么是Stable Diffusion？如何安装Stable Diffusion？">
  <meta property="og:description" content="Stable Diffusion秋叶整合包，一键安装Stable Diffusion，门槛极低，完全免费，支持Nvidia全系列显卡。
来自B站up主秋葉aaaki近期推出的Stable Diffusion整合包v4.9版本，能够让零基础用户轻松在本地部署Stable Diffusion，适合希望使用AI绘画的朋友。
Stable Diffusion（SD）是什么?
Stable Diffusion是一款2022年发布的文本到图像生成模型，由Stability AI公司与多个学术研究者和非营利组织合作开发。其源代码和模型已经开源，由AUTOMATIC1111在Github上维护一个完整项目，得到全球开发者的共同维护。开源社区对Stable Diffusion的普及做出了重大贡献。
该模型最大特点是开源，可在电脑本地离线运行，适用于大部分配备至少8GB显存的中等性能GPU。推荐的显存为12G。
AI训练与输出结合了深度学习的软硬件原理，常用到Nvidia显卡及相关的CUDA、CUDNN技术，以及xformer、pytorch等深度学习组件。对于希望深入学习AI的用户来说，这些技术需要大量额外的编程学习，可能会感到困难。而秋叶整合包则大大简化了部署过程，使其更易于理解和实施。
Stable Diffusion的基本概念：
大模型：结合素材与SD低模（如SD1.5/SD1.4/SD2.1）经深度学习炼制而成的高级模型，直接用于生成图片。大模型是决定出图大方向的基础底料，主要扩展名为CKPT/SAFETENSORS。
VAE：类似于滤镜，对大模型进行补充，稳定画面色彩范围，常见扩展名同样为CKPT/SAFETENSORS。
LoRA：基于特定大模型深度学习炼制的模型插件，需配合大模型使用，能在中小范围内调整出图风格或补充大模型缺失的元素。根据SD底模炼制的LoRA在不同大模型间切换时具有较好的通用性，而基于特定大模型炼制的LoRA可能在配合时展现出更佳的效果。ControlNet：高级模型插件，赋予SD“视觉”，能基于现有图片获取线条或景深信息，进而用于图片处理。
Stable Diffusion Web-UI（SD-WEBUI）：由开源大师AUTOMATIC1111基于Stability AI算法开发的软件，支持通过图形界面在浏览器中操作SD。
秋叶包：中国开发者秋叶制作的整合包，考虑到WEBUI基于GitHub的部署通常需高网络和Python环境支持，秋叶包内置隔离的Python环境和Git，无需深入了解这两软件即可运行，极大降低了使用门槛，使更多人能享受AI绘图乐趣。
如何安装Stable Diffusion秋叶整合包？
确认配置要求： 系统：需运行Windows 10或更高版本的操作系统。显卡：推荐使用Nvidia品牌的独立显卡，并确保显存容量达到6GB以上。若仅用于生成图像，6GB显存足够；若计划进行模型训练，则建议显存容量为12GB以上。 查看显卡型号的步骤：
在电脑左下角的Windows图标上右键点击；选择“设备管理器”；在设备管理器中找到“显示适配器”，即可查看显卡型号信息。 文件下载与解压： 可从指定来源免费下载文件至本地电脑，并将文件解压至D盘。注意，解压路径最好不包含中文目录，以避免可能的兼容性问题。
SD秋叶V4.9整合包给大家准备好了,扫描下方,即可免费获取
一、打开下载好的安装包（文末获取） 1、安装 *2、安装中* 二、解压启动AI绘画 1、解压 2、启动 三、开始使用 四、 下载模型和安装模型路径 1.安装路径 \2. 模型下载地址根据需求下载
3.放进对应的目录后刷新后，就可以在左边选择对应的模型。
五、 Controlnet插件安装（后台回复的文件已经自带该插件） 1.打开webui复制下方链接到图片中的指示位置点击安装
https://jihulab.com/hanamizuki/sd-webui-controlnet 2. Controlnet模型安装（文章末下载） 根据图片路径移动模型文件过去
**
**
*3. 回到webui重启*
六、 配置跟不上，推荐云电脑 最近，我发现有一个全新的解决方案来解决Stable-Diffusion的部署问题，这就是使用青椒云远程服务。通过这种方式，你无需自行部署Stable-Diffusion，不需要担心硬件要求，也不用担心兼容性问题。
青椒云远程服务的使用体验类似于远程控制一台Windows电脑，远程服务器上预装了各种常用大模型，甚至可以提供高达300G的系统盘空间。你只需打开远程服务，即可开始使用Stable-Diffusion，无需繁琐的安装过程。
这对于那些由于部署难度而无法使用Stable-Diffusion的小伙伴来说是一个很好的解决方案。通过使用青椒云远程服务，你可以更方便地体验Stable-Diffusion的魅力。
这里直接将该软件分享出来给大家吧~
1.stable diffusion安装包 随着技术的迭代，目前 Stable Diffusion 已经能够生成非常艺术化的图片了，完全有赶超人类的架势，已经有不少工作被这类服务替代，比如制作一个 logo 图片，画一张虚拟老婆照片，画质堪比相机。">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-08-16T11:31:39+08:00">
    <meta property="article:modified_time" content="2024-08-16T11:31:39+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">秋叶V4.9整合包发布！什么是Stable Diffusion？如何安装Stable Diffusion？</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p><img src="https://images2.imgbox.com/be/4a/zCTJOwxt_o.jpg" alt="图片"></p> 
<p>Stable Diffusion秋叶整合包，一键安装Stable Diffusion，门槛极低，完全免费，支持Nvidia全系列显卡。</p> 
<p>来自<strong>B站up主秋葉aaaki</strong>近期推出的Stable Diffusion整合包<strong>v4.9版本</strong>，能够让零基础用户轻松在本地部署Stable Diffusion，适合希望使用AI绘画的朋友。</p> 
<p><strong>Stable Diffusion（SD）是什么?</strong></p> 
<p>Stable Diffusion是一款2022年发布的文本到图像生成模型，由Stability AI公司与多个学术研究者和非营利组织合作开发。其源代码和模型已经开源，由AUTOMATIC1111在Github上维护一个完整项目，得到全球开发者的共同维护。开源社区对Stable Diffusion的普及做出了重大贡献。</p> 
<p>该模型最大特点是开源，可在电脑本地离线运行，适用于大部分配备至少8GB显存的中等性能GPU。推荐的显存为12G。</p> 
<p>AI训练与输出结合了深度学习的软硬件原理，常用到Nvidia显卡及相关的CUDA、CUDNN技术，以及xformer、pytorch等深度学习组件。对于希望深入学习AI的用户来说，这些技术需要大量额外的编程学习，可能会感到困难。而秋叶整合包则大大简化了部署过程，使其更易于理解和实施。</p> 
<p><strong>Stable Diffusion的基本概念：</strong></p> 
<p>大模型：结合素材与SD低模（如SD1.5/SD1.4/SD2.1）经深度学习炼制而成的高级模型，直接用于生成图片。大模型是决定出图大方向的基础底料，主要扩展名为CKPT/SAFETENSORS。</p> 
<p>VAE：类似于滤镜，对大模型进行补充，稳定画面色彩范围，常见扩展名同样为CKPT/SAFETENSORS。</p> 
<p>LoRA：基于特定大模型深度学习炼制的模型插件，需配合大模型使用，能在中小范围内调整出图风格或补充大模型缺失的元素。根据SD底模炼制的LoRA在不同大模型间切换时具有较好的通用性，而基于特定大模型炼制的LoRA可能在配合时展现出更佳的效果。ControlNet：高级模型插件，赋予SD“视觉”，能基于现有图片获取线条或景深信息，进而用于图片处理。</p> 
<p>Stable Diffusion Web-UI（SD-WEBUI）：由开源大师AUTOMATIC1111基于Stability AI算法开发的软件，支持通过图形界面在浏览器中操作SD。</p> 
<p>秋叶包：中国开发者秋叶制作的整合包，考虑到WEBUI基于GitHub的部署通常需高网络和Python环境支持，秋叶包内置隔离的Python环境和Git，无需深入了解这两软件即可运行，极大降低了使用门槛，使更多人能享受AI绘图乐趣。</p> 
<p><strong>如何安装Stable Diffusion秋叶整合包？</strong></p> 
<ol><li>确认配置要求：</li></ol> 
<ul><li>系统：需运行Windows 10或更高版本的操作系统。</li><li>显卡：推荐使用Nvidia品牌的独立显卡，并确保显存容量达到6GB以上。若仅用于生成图像，6GB显存足够；若计划进行模型训练，则建议显存容量为12GB以上。</li></ul> 
<p>查看显卡型号的步骤：</p> 
<ul><li>在电脑左下角的Windows图标上右键点击；</li><li>选择“设备管理器”；</li><li>在设备管理器中找到“显示适配器”，即可查看显卡型号信息。</li></ul> 
<ol><li>文件下载与解压：</li></ol> 
<ul><li> <p>可从指定来源免费下载文件至本地电脑，并将文件解压至D盘。注意，解压路径最好不包含中文目录，以避免可能的兼容性问题。</p> <p><strong>SD秋叶V4.9整合包给大家准备好了,扫描下方,即可免费获取</strong></p> </li></ul> 
<p><img src="https://images2.imgbox.com/2c/f2/Kxloetsd_o.jpg" alt="在这里插入图片描述"></p> 
<h2><a id="_48"></a><strong>一、打开下载好的安装包（文末获取）</strong></h2> 
<h2><a id="1_50"></a><strong>1、安装</strong></h2> 
<p><img src="https://images2.imgbox.com/d9/35/W43XEoai_o.png" alt="图片"></p> 
<h2><a id="2_54"></a><em><strong>*2、安装中*</strong></em></h2> 
<p><img src="https://images2.imgbox.com/54/93/EG9xmaQU_o.png" alt="图片"></p> 
<p><img src="https://images2.imgbox.com/cf/73/jgjLk94x_o.png" alt="图片"></p> 
<h2><a id="AI_62"></a><strong>二、解压启动AI绘画</strong></h2> 
<h2><a id="1_64"></a><strong>1、解压</strong></h2> 
<p><img src="https://images2.imgbox.com/a0/72/WHSn2PQo_o.png" alt="图片"></p> 
<h2><a id="2_68"></a><strong>2、启动</strong></h2> 
<p><img src="https://images2.imgbox.com/76/5b/QkjB9ASh_o.png" alt="图片"></p> 
<p><img src="https://images2.imgbox.com/99/7b/Av2o2Ggi_o.png" alt="图片"></p> 
<h2><a id="_74"></a><strong>三、开始使用</strong></h2> 
<h2><a id="_76"></a></h2> 
<p><img src="https://images2.imgbox.com/31/ea/HTsahxF8_o.png" alt="图片"></p> 
<h2><a id="__82"></a><strong>四、 下载模型和安装模型路径</strong></h2> 
<h2><a id="1_84"></a><strong>1.安装路径</strong></h2> 
<p><img src="https://images2.imgbox.com/19/a4/whNmSblY_o.png" alt="图片"></p> 
<p>\2. 模型下载地址根据需求下载</p> 
<p><img src="https://images2.imgbox.com/26/91/YB7YV8nH_o.png" alt="图片"></p> 
<p>3.放进对应的目录后刷新后，就可以在左边选择对应的模型。</p> 
<p><img src="https://images2.imgbox.com/ce/26/K04yUrPa_o.png" alt="图片"></p> 
<h2><a id="__Controlnet_103"></a><strong>五、 Controlnet插件安装（后台回复的文件已经自带该插件）</strong></h2> 
<p><strong>1.打开webui复制下方链接到图片中的指示位置点击安装</strong></p> 
<ul><li></ul> 
<pre><code>https://jihulab.com/hanamizuki/sd-webui-controlnet
</code></pre> 
<p><img src="https://images2.imgbox.com/00/52/DQLINv9F_o.png" alt="图片"></p> 
<p><strong>2. Controlnet模型安装（文章末下载）</strong> <strong>根据图片路径移动模型文件过去</strong></p> 
<p>**<br> **</p> 
<p><img src="https://images2.imgbox.com/42/64/NIyuubHJ_o.png" alt="图片"></p> 
<p><em><strong>*3. 回到webui重启*</strong></em></p> 
<p><img src="https://images2.imgbox.com/2f/ed/DG7u6q7B_o.png" alt="图片"></p> 
<h2><a id="__130"></a><strong>六、 配置跟不上，推荐云电脑</strong></h2> 
<p>最近，我发现有一个全新的解决方案来解决Stable-Diffusion的部署问题，这就是使用青椒云远程服务。通过这种方式，你无需自行部署Stable-Diffusion，不需要担心硬件要求，也不用担心兼容性问题。</p> 
<p>青椒云远程服务的使用体验类似于远程控制一台Windows电脑，远程服务器上预装了各种常用大模型，甚至可以提供高达300G的系统盘空间。你只需打开远程服务，即可开始使用Stable-Diffusion，无需繁琐的安装过程。</p> 
<p>这对于那些由于部署难度而无法使用Stable-Diffusion的小伙伴来说是一个很好的解决方案。通过使用青椒云远程服务，你可以更方便地体验Stable-Diffusion的魅力。</p> 
<p>这里直接将该软件分享出来给大家吧~</p> 
<h4><a id="1stable_diffusion_143"></a>1.stable diffusion安装包</h4> 
<p>随着技术的迭代，目前 Stable Diffusion 已经能够生成非常艺术化的图片了，完全有赶超人类的架势，已经有不少工作被这类服务替代，比如制作一个 logo 图片，画一张虚拟老婆照片，画质堪比相机。</p> 
<p>最新 Stable Diffusion 除了有win多个版本，就算说底端的显卡也能玩了哦！此外还带来了Mac版本，<strong>仅支持macOS 12.3或更高版本</strong>。</p> 
<p><img src="https://images2.imgbox.com/7f/85/q1ZP3nuc_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="2stable_diffusion_151"></a>2.stable diffusion视频合集</h4> 
<p>我们在学习的时候，往往书籍源码难以理解，阅读困难，这时候视频教程教程是就很适合了，生动形象加上案例实战，一步步带你入坑stable diffusion，科学有趣才能更方便的学习下去。</p> 
<p><img src="https://images2.imgbox.com/e5/a4/rRYEcRfc_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="3stable_diffusion_157"></a>3.stable diffusion模型下载</h4> 
<p>stable diffusion往往一开始使用时图片等无法达到理想的生成效果，这时则需要通过使用大量训练数据，调整模型的超参数（如学习率、训练轮数、模型大小等），可以使得模型更好地适应数据集，并生成更加真实、准确、高质量的图像。</p> 
<p><img src="https://images2.imgbox.com/63/68/h5yyWdc2_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="4stable_diffusion_163"></a>4.stable diffusion提示词</h4> 
<p>提示词是构建由文本到图像模型解释和理解的单词的过程。可以把它理解为你告诉 AI 模型要画什么而需要说的语言，整个SD学习过程中都离不开这本提示词手册。</p> 
<p><img src="https://images2.imgbox.com/b0/68/qiWKJDVx_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="5SD0_169"></a>5.SD从0到落地实战演练</h4> 
<p><img src="https://images2.imgbox.com/0f/9a/aexbOruv_o.png" alt="在这里插入图片描述"></p> 
<p>如果你能在15天内完成所有的任务，那你堪称天才。然而，如果你能完成 60-70% 的内容，你就已经开始具备成为一名SD大神的正确特征了。</p> 
<p>这份完整版的stable diffusion资料我已经打包好，需要的点击下方插件，即可前往免费领取！</p> 
<p><img src="https://images2.imgbox.com/52/7e/rOCZ2hew_o.jpg" alt="在这里插入图片描述"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/bed4a90407d9e21712a317e948862f92/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">手机设备IP地址切换：方法、应用与注意事项</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/ff60ce8348fde320b6097b49f9132cd0/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">在亚马逊云科技上部署Llama大模型并开发负责任的AI生活智能助手</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>