<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Stable Diffusion文生图模型训练入门实战（完整代码） - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/fc98a8fbc472ebade966b0d9983fc0f0/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="Stable Diffusion文生图模型训练入门实战（完整代码）">
  <meta property="og:description" content="Stable Diffusion 1.5（SD1.5）是由Stability AI在2022年8月22日开源的文生图模型，是SD最经典也是社区最活跃的模型之一。
以SD1.5作为预训练模型，在火影忍者数据集上微调一个火影风格的文生图模型（非Lora方式），是学习SD训练的入门任务。
显存要求 22GB左右
在本文中，我们会使用SD-1.5模型在火影忍者数据集上做训练，同时使用SwanLab监控训练过程、评估模型效果。
代码：Github实验日志过程：SD-naruto - SwanLab模型：runwayml/stable-diffusion-v1-5数据集：lambdalabs/naruto-blip-captionsSwanLab：https://swanlab.cn 1.环境安装 本案例基于Python&gt;=3.8，请在您的计算机上安装好Python；
另外，您的计算机上至少要有一张英伟达显卡（显存大约要求22GB左右）。
我们需要安装以下这几个Python库，在这之前，请确保你的环境内已安装了pytorch以及CUDA：
swanlab diffusers datasets accelerate torchvision transformers 一键安装命令：
pip install swanlab diffusers datasets accelerate torchvision transformers 本文的代码测试于diffusers0.29.0、accelerate0.30.1、datasets2.18.0、transformers4.41.2、swanlab==0.3.11，更多库版本可查看SwanLab记录的Python环境。
2.准备数据集 本案例是用的是火影忍者数据集，该数据集主要被用于训练文生图模型。
该数据集由1200条（图像、描述）对组成，左边是火影人物的图像，右边是对它的描述：
我们的训练任务，便是希望训练后的SD模型能够输入提示词，生成火影风格的图像：
数据集的大小大约700MB左右；数据集的下载方式有两种：
如果你的网络与HuggingFace连接是通畅的，那么直接运行我下面提供的代码即可，它会直接通过HF的datasets库进行下载。如果网络存在问题，我也把它放到百度网盘（提取码: gtk8），下载naruto-blip-captions.zip到本地解压后，运行到与训练脚本同一目录下。 3.准备模型 这里我们使用HuggingFace上Runway发布的stable-diffusion-v1-5模型。
模型的下载方式同样有两种：
如果你的网络与HuggingFace连接是通畅的，那么直接运行我下面提供的代码即可，它会直接通过HF的transformers库进行下载。如果网络存在问题，我也把它放到百度网盘（提取码: gtk8），下载stable-diffusion-v1-5.zip到本地解压后，运行到与训练脚本同一目录下。 4. 配置训练可视化工具 我们使用SwanLab来监控整个训练过程，并评估最终的模型效果。
如果你是第一次使用SwanLab，那么还需要去https://swanlab.cn上注册一个账号，在用户设置页面复制你的API Key，然后在训练开始时粘贴进去即可：
5.开始训练 由于训练的代码比较长，所以我把它放到了Github里，请Clone里面的代码：
git clone https://github.com/Zeyi-Lin/Stable-Diffusion-Example.git 如果你与HuggingFace的网络连接通畅，那么直接运行训练：
python train_sd1-5_naruto.py \ --use_ema \ --resolution=512 --center_crop --random_flip \ --train_batch_size=1 \ --gradient_accumulation_steps=4 \ --gradient_checkpointing \ --max_train_steps=15000 \ --learning_rate=1e-05 \ --max_grad_norm=1 \ --seed=42 \ --lr_scheduler=&#34;">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-06-19T19:10:51+08:00">
    <meta property="article:modified_time" content="2024-06-19T19:10:51+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Stable Diffusion文生图模型训练入门实战（完整代码）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p><a href="https://huggingface.co/runwayml/stable-diffusion-v1-5/tree/main" rel="nofollow">Stable Diffusion 1.5</a>（SD1.5）是由Stability AI在2022年8月22日开源的文生图模型，是SD最经典也是社区最活跃的模型之一。</p> 
<p>以SD1.5作为预训练模型，在火影忍者数据集上微调一个火影风格的文生图模型（非Lora方式），是学习<strong>SD训练</strong>的入门任务。</p> 
<p><img src="https://images2.imgbox.com/08/5f/ohGnCPh0_o.png" alt="在这里插入图片描述"></p> 
<blockquote> 
 <p>显存要求 22GB左右</p> 
</blockquote> 
<p>在本文中，我们会使用<a href="https://huggingface.co/runwayml/stable-diffusion-v1-5" rel="nofollow">SD-1.5</a>模型在<a href="https://huggingface.co/datasets/lambdalabs/naruto-blip-captions" rel="nofollow">火影忍者</a>数据集上做训练，同时使用<a href="https://swanlab.cn" rel="nofollow">SwanLab</a>监控训练过程、评估模型效果。</p> 
<ul><li>代码：<a href="https://github.com/Zeyi-Lin/Stable-Diffusion-Example">Github</a></li><li>实验日志过程：<a href="https://swanlab.cn/@ZeyiLin/SD-Naruto/runs/21flglg1lbnqo67a6f1kr/environment/requirements" rel="nofollow">SD-naruto - SwanLab</a></li><li>模型：<a href="https://huggingface.co/runwayml/stable-diffusion-v1-5" rel="nofollow">runwayml/stable-diffusion-v1-5</a></li><li>数据集：<a href="https://huggingface.co/datasets/lambdalabs/naruto-blip-captions" rel="nofollow">lambdalabs/naruto-blip-captions</a></li><li>SwanLab：<a href="https://swanlab.cn" rel="nofollow">https://swanlab.cn</a></li></ul> 
<h3><a id="1_18"></a>1.环境安装</h3> 
<p>本案例基于<strong>Python&gt;=3.8</strong>，请在您的计算机上安装好Python；</p> 
<p>另外，您的计算机上至少要有一张英伟达显卡（显存大约要求22GB左右）。</p> 
<p>我们需要安装以下这几个Python库，在这之前，请确保你的环境内已安装了pytorch以及CUDA：</p> 
<pre><code class="prism language-txt">swanlab
diffusers
datasets
accelerate
torchvision
transformers
</code></pre> 
<p>一键安装命令：</p> 
<pre><code class="prism language-bash">pip <span class="token function">install</span> swanlab diffusers datasets accelerate torchvision transformers
</code></pre> 
<blockquote> 
 <p>本文的代码测试于diffusers<mark>0.29.0、accelerate</mark>0.30.1、datasets<mark>2.18.0、transformers</mark>4.41.2、swanlab==0.3.11，更多库版本可查看<a href="https://swanlab.cn/@ZeyiLin/Text2Image/runs/21flglg1lbnqo67a6f1kr/environment/requirements" rel="nofollow">SwanLab记录的Python环境</a>。</p> 
</blockquote> 
<h3><a id="2_44"></a>2.准备数据集</h3> 
<p>本案例是用的是<a href="https://huggingface.co/datasets/lambdalabs/naruto-blip-captions" rel="nofollow">火影忍者</a>数据集，该数据集主要被用于训练文生图模型。</p> 
<p>该数据集由1200条（图像、描述）对组成，左边是火影人物的图像，右边是对它的描述：</p> 
<p><img src="https://images2.imgbox.com/94/1e/pvMfdavE_o.png" alt="在这里插入图片描述"></p> 
<p>我们的训练任务，便是希望训练后的SD模型能够输入提示词，生成火影风格的图像：</p> 
<p><img src="https://images2.imgbox.com/7f/bb/WDck83FE_o.png" alt="在这里插入图片描述"></p> 
<hr> 
<p>数据集的大小大约700MB左右；数据集的下载方式有两种：</p> 
<ol><li>如果你的网络与HuggingFace连接是通畅的，那么直接运行我下面提供的代码即可，它会直接通过HF的<code>datasets</code>库进行下载。</li><li>如果网络存在问题，我也把它放到<a href="https://pan.baidu.com/s/1Yu5HjXnHxK0Wgymc8G-g5g?pwd=gtk8" rel="nofollow">百度网盘</a>（提取码: gtk8），下载<code>naruto-blip-captions.zip</code>到本地解压后，运行到与训练脚本同一目录下。</li></ol> 
<h3><a id="3_65"></a>3.准备模型</h3> 
<p>这里我们使用HuggingFace上Runway发布的<a href="https://huggingface.co/runwayml/stable-diffusion-v1-5" rel="nofollow">stable-diffusion-v1-5</a>模型。</p> 
<p><img src="https://images2.imgbox.com/1c/ad/Me91ZWSx_o.png" alt="在这里插入图片描述"></p> 
<p>模型的下载方式同样有两种：</p> 
<ol><li>如果你的网络与HuggingFace连接是通畅的，那么直接运行我下面提供的代码即可，它会直接通过HF的<code>transformers</code>库进行下载。</li><li>如果网络存在问题，我也把它放到<a href="https://pan.baidu.com/s/1Yu5HjXnHxK0Wgymc8G-g5g?pwd=gtk8" rel="nofollow">百度网盘</a>（提取码: gtk8），下载<code>stable-diffusion-v1-5.zip</code>到本地解压后，运行到与训练脚本同一目录下。</li></ol> 
<h3><a id="4__77"></a>4. 配置训练可视化工具</h3> 
<p>我们使用<a href="https://swanlab.cn" rel="nofollow">SwanLab</a>来监控整个训练过程，并评估最终的模型效果。</p> 
<p>如果你是第一次使用SwanLab，那么还需要去https://swanlab.cn上注册一个账号，在<strong>用户设置</strong>页面复制你的API Key，然后在训练开始时粘贴进去即可：</p> 
<p><img src="https://images2.imgbox.com/e6/c0/Lg4psftp_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="5_86"></a>5.开始训练</h3> 
<p>由于训练的代码比较长，所以我把它放到了<a href="https://github.com/Zeyi-Lin/Stable-Diffusion-Example/tree/main">Github</a>里，请Clone里面的代码：</p> 
<pre><code class="prism language-bash"><span class="token function">git</span> clone https://github.com/Zeyi-Lin/Stable-Diffusion-Example.git
</code></pre> 
<p>如果你与HuggingFace的网络连接通畅，那么直接运行训练：</p> 
<pre><code class="prism language-bash">python train_sd1-5_naruto.py <span class="token punctuation">\</span>
  <span class="token parameter variable">--use_ema</span> <span class="token punctuation">\</span>
  <span class="token parameter variable">--resolution</span><span class="token operator">=</span><span class="token number">512</span> <span class="token parameter variable">--center_crop</span> <span class="token parameter variable">--random_flip</span> <span class="token punctuation">\</span>
  <span class="token parameter variable">--train_batch_size</span><span class="token operator">=</span><span class="token number">1</span> <span class="token punctuation">\</span>
  <span class="token parameter variable">--gradient_accumulation_steps</span><span class="token operator">=</span><span class="token number">4</span> <span class="token punctuation">\</span>
  <span class="token parameter variable">--gradient_checkpointing</span> <span class="token punctuation">\</span>
  <span class="token parameter variable">--max_train_steps</span><span class="token operator">=</span><span class="token number">15000</span> <span class="token punctuation">\</span>
  <span class="token parameter variable">--learning_rate</span><span class="token operator">=</span>1e-05 <span class="token punctuation">\</span>
  <span class="token parameter variable">--max_grad_norm</span><span class="token operator">=</span><span class="token number">1</span> <span class="token punctuation">\</span>
  <span class="token parameter variable">--seed</span><span class="token operator">=</span><span class="token number">42</span> <span class="token punctuation">\</span>
  <span class="token parameter variable">--lr_scheduler</span><span class="token operator">=</span><span class="token string">"constant"</span> <span class="token punctuation">\</span>
  <span class="token parameter variable">--lr_warmup_steps</span><span class="token operator">=</span><span class="token number">0</span> <span class="token punctuation">\</span>
  <span class="token parameter variable">--output_dir</span><span class="token operator">=</span><span class="token string">"sd-naruto-model"</span>
</code></pre> 
<p>上面这些参数的含义如下：</p> 
<ul><li><code>--use_ema</code>: 使用指数移动平均 (EMA) 技术，该技术可以提高模型的泛化能力，在训练过程中使用模型参数的移动平均值进行预测，而不是直接使用当前模型参数。</li><li><code>--resolution=512</code>: 设置训练图像的分辨率为 512 像素。</li><li><code>--center_crop</code>: 对图像进行中心裁剪，将图像的中心部分作为训练样本，忽略图像边缘的部分。</li><li><code>--random_flip</code>: 在训练过程中对图像进行随机翻转，增加训练数据的多样性。</li><li><code>--train_batch_size=1</code>: 设置训练批次大小为 1，即每次训练只使用一张图像。</li><li><code>--gradient_accumulation_steps=4</code>: 梯度累积步数为 4，即每进行 4 次训练才进行一次参数更新。</li><li><code>--gradient_checkpointing</code>: 使用梯度检查点技术，可以减少内存使用量，加快训练速度。</li><li><code>--max_train_steps=15000</code>: 设置最大训练步数为 15000 步。</li><li><code>--learning_rate=1e-05</code>: 设置学习率为 1e-05。</li><li><code>--max_grad_norm=1</code>: 设置梯度范数的最大值为 1，防止梯度爆炸。</li><li><code>--seed=42</code>: 设置随机种子为 42，确保每次训练的随机性一致。</li><li><code>--lr_scheduler="constant"</code>: 使用常数学习率调度器，即在整个训练过程中保持学习率不变。</li><li><code>--lr_warmup_steps=0</code>: 设置学习率预热步数为 0，即不进行预热。</li><li><code>--output_dir="sd-naruto-model"</code>: 设置模型输出目录为 “sd-naruto-model”。</li></ul> 
<hr> 
<p>如果你的模型或数据集用的是<strong>上面的网盘下载的</strong>，那么你需要做下面的两件事：</p> 
<p><strong>第一步</strong>：将数据集和模型文件夹放到训练脚本同一目录下，文件结构如下：</p> 
<pre><code class="prism language-txt">|--- sd_config.py
|--- train_sd1-5_naruto.py
|--- stable-diffusion-v1-5
|--- naruto-blip-captions
</code></pre> 
<p><code>stable-diffusion-v1-5</code>是下载好的模型文件夹，<code>naruto-blip-captions</code>是下载好的数据集文件夹。</p> 
<p><strong>第二步</strong>：修改<code>sd_config.py</code>的代码，将<code>pretrained_model_name_or_path</code>和<code>dataset_name</code>的default值分别改为下面这样：</p> 
<pre><code class="prism language-python">    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span>
        <span class="token string">"--pretrained_model_name_or_path"</span><span class="token punctuation">,</span>
        <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">str</span><span class="token punctuation">,</span>
        default<span class="token operator">=</span><span class="token string">"./stable-diffusion-v1-5"</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span>
        <span class="token string">"--dataset_name"</span><span class="token punctuation">,</span>
        <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">str</span><span class="token punctuation">,</span>
        default<span class="token operator">=</span><span class="token string">"./naruto-blip-captions"</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span>
</code></pre> 
<p>然后运行启动命令即可。</p> 
<hr> 
<p>看到下面的进度条即代表训练开始：</p> 
<p><img src="https://images2.imgbox.com/35/cf/Nc4hK2lS_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="6__169"></a>6. 训练结果演示</h3> 
<p>我们在<a href="https://swanlab.cn/@ZeyiLin/SD-Naruto/runs/21flglg1lbnqo67a6f1kr/chart" rel="nofollow">SwanLab</a>上查看最终的训练结果：</p> 
<p><img src="https://images2.imgbox.com/59/80/BJdVGz3r_o.png" alt="在这里插入图片描述"></p> 
<p>可以看到SD训练的特点是loss一直在震荡，随着epoch的增加，loss在最初下降后，后续的变化其实并不大：</p> 
<p><img src="https://images2.imgbox.com/14/ec/gP2sZ12n_o.png" alt="在这里插入图片描述"></p> 
<p>我们来看看主观生成的图像，第一个epoch的图像长这样：</p> 
<p><img src="https://images2.imgbox.com/e3/a8/JReHsuX3_o.png" alt="在这里插入图片描述"></p> 
<p>可以看到詹姆斯还是非常的“原生态”，迈克尔杰克逊生成的也怪怪的。。。</p> 
<p>再看一下中间的状态：</p> 
<p><img src="https://images2.imgbox.com/c2/77/KnWLvYVl_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/ca/45/fROYUqic_o.png" alt="在这里插入图片描述"></p> 
<p>经过比较长时间的训练后，效果就好了不少。</p> 
<blockquote> 
 <p>比较有意思的是，比尔盖茨生成出来的形象总是感觉非常邪恶。。。</p> 
</blockquote> 
<p>详细训练过程看这里：<a href="https://swanlab.cn/@ZeyiLin/SD-Naruto/runs/21flglg1lbnqo67a6f1kr/chart" rel="nofollow">SD-Naruto - SwanLab</a></p> 
<p>至此，你已经完成了SD模型在火影忍者数据集上的训练。</p> 
<h3><a id="7__205"></a>7. 模型推理</h3> 
<p>训练好的模型会放到<code>sd-naruto-model</code>文件夹下，推理代码如下：</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> diffusers <span class="token keyword">import</span> StableDiffusionPipeline
<span class="token keyword">import</span> torch

model_id <span class="token operator">=</span> <span class="token string">"./sd-naruto-model"</span>
pipe <span class="token operator">=</span> StableDiffusionPipeline<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_id<span class="token punctuation">,</span> torch_dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float16<span class="token punctuation">)</span>
pipe <span class="token operator">=</span> pipe<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">"cuda"</span><span class="token punctuation">)</span>

prompt <span class="token operator">=</span> <span class="token string">"Lebron James with a hat"</span>
image <span class="token operator">=</span> pipe<span class="token punctuation">(</span>prompt<span class="token punctuation">)</span><span class="token punctuation">.</span>images<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>  
    
image<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string">"result.png"</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="_223"></a>相关链接</h3> 
<ul><li>代码：<a href="https://github.com/Zeyi-Lin/Stable-Diffusion-Example">Github</a></li><li>实验日志过程：<a href="https://swanlab.cn/@ZeyiLin/SD-Naruto/runs/21flglg1lbnqo67a6f1kr/environment/requirements" rel="nofollow">SD-naruto - SwanLab</a></li><li>模型：<a href="https://huggingface.co/runwayml/stable-diffusion-v1-5" rel="nofollow">runwayml/stable-diffusion-v1-5</a></li><li>数据集：<a href="https://huggingface.co/datasets/lambdalabs/naruto-blip-captions" rel="nofollow">lambdalabs/naruto-blip-captions</a></li><li>SwanLab：<a href="https://swanlab.cn" rel="nofollow">https://swanlab.cn</a></li></ul>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/19a1084b2594677cffa766c2c829c3e2/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Flink 反压</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/cb168d4b97fbd681d26d91521197b97d/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【AI 大模型】提示工程 ① ( 通用人工智能 和 专用人工智能 | 掌握 提示工程 的优势 | 提示工程目的 | 提示词组成、迭代、调优及示例 | 思维链 | 启用思维链的指令 | 思维链原理 )</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>