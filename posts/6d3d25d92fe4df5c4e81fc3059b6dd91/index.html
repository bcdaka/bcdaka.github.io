<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>在IDEA运行spark程序（搭建Spark开发环境） - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/6d3d25d92fe4df5c4e81fc3059b6dd91/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="在IDEA运行spark程序（搭建Spark开发环境）">
  <meta property="og:description" content="建议大家写在Linux上搭建好Hadoop的完全分布式集群环境和Spark集群环境，以下在IDEA中搭建的环境仅仅是在window系统上进行spark程序的开发学习，在window系统上可以不用安装hadoop和spark，spark程序可以通过pom.xml的文件配置，添加spark-core依赖，可以直接在IDEA中编写spark程序并运行结果。
一、相关软件的下载及环境配置 1.jdk的下载安装及环境变量配置（我选择的版本是jdk8.0（即jdk1.8），建议不要使用太高版本的，不然配置pom.xml容易报错） 链接：https://pan.baidu.com/s/1deXf6pgMiRca1O724fUOxg 提取码：sxuy
双击安装包，一直“Next”即可，最好不要安装到C盘，中间修改一下安装路径即可，最后点击“Finish”。我将jdk1.8安装在了D盘目录下的soft文件夹，bin路径如下：
配置环境变量：
win&#43;R打开命令窗口输入：javac -verison ，进行检测是否成功配置环境变量：
2.IDEA的下载安装（我选择的版本是2019.2.3，建议选择低版本的IDEA） 官网下载地址：IntelliJ IDEA – 领先的 Java 和 Kotlin IDE (jetbrains.com.cn)
3.scala的下载（我选择的版本是2.12.15）安装及环境变量的配置 官网下载地址：The Scala Programming Language (scala-lang.org)
双击打开下载好的安装程序，一直“Next”即可，最好不要安装到C盘，中间修改一下安装路径即可，最后点击“Finish”。我将scala软件安装在了D盘目录下的Develop文件夹，bin路径如下：
配置scala的系统环境变量，将scala安装的bin目录路径加入到系统环境变量path中：
win&#43;R打开命令窗口输入：scala -verison ，进行检测是否成功配置环境变量：
4.scala插件（版本要与IDEA版本保持一致，下载2019.2.3版本）的下载安装 官网地址：Scala - IntelliJ IDEs Plugin | Marketplacehttps://plugins.jetbrains.com/plugin/1347-scala/versions/stable
下载完成后，将下载的压缩包解压到IDEA安装目录下的plugins目录下：
5.maven的下载（我选择的版本是3.5.4）与安装，系统环境变量的配置 官网地址:Maven – Download Apache Maven
将对应版本的压缩包下载到本地,并新建一个文件夹Localwarehouse，用来保存下载的依赖文件
配置maven的系统环境配置，跟以上配置的方法一样，将bin目录地址写入path环境变量：
打开maven安装包下的conf文件夹下面的settings.xml,添加如下代码：
&lt;localRepository&gt;D:\\Develop\\maven\\Localwarehouse&lt;/localRepository&gt; 在settings.xml配置文件中找到mirrors节点，添加阿里云仓库代码，具体代码如下配置（注意要添加在&lt;mirrors&gt;和&lt;/mirrors&gt;两个标签之间）：
&lt;!-- 阿里云仓库 --&gt; &lt;mirror&gt; &lt;id&gt;alimaven&lt;/id&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;name&gt;aliyun maven&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/repositories/central/&lt;/url&gt; &lt;/mirror&gt; 添加如下代码用来配置jdk版本：
&lt;profile&gt; &lt;id&gt;jdk-1.8.0&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;jdk&gt;1.8.0&lt;/jdk&gt; &lt;/activation&gt; &lt;properties&gt; &lt;maven.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-04-18T15:43:01+08:00">
    <meta property="article:modified_time" content="2024-04-18T15:43:01+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">在IDEA运行spark程序（搭建Spark开发环境）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>       建议大家写在Linux上搭建好Hadoop的完全分布式集群环境和Spark集群环境，以下在IDEA中搭建的环境仅仅是在window系统上进行spark程序的开发学习，在window系统上可以不用安装hadoop和spark，spark程序可以通过pom.xml的文件配置，添加spark-core依赖，可以直接在IDEA中编写spark程序并运行结果。</p> 
<h2><strong>一、相关软件的下载及环境配置</strong></h2> 
<h4><strong>1.jdk的下载安装及环境变量配置（我选择的版本是jdk8.0（即jdk1.8），建议不要使用太高版本的，不然配置pom.xml容易报错）</strong></h4> 
<p>链接：https://pan.baidu.com/s/1deXf6pgMiRca1O724fUOxg <br> 提取码：sxuy</p> 
<p>双击安装包，一直“Next”即可，最好不要安装到C盘，中间修改一下安装路径即可，最后点击“Finish”。我将jdk1.8安装在了D盘目录下的soft文件夹，bin路径如下：</p> 
<p><img alt="" height="403" src="https://images2.imgbox.com/64/ef/MIgVs9sr_o.png" width="536"></p> 
<p></p> 
<p><strong>配置环境变量：</strong></p> 
<p><img alt="" height="307" src="https://images2.imgbox.com/89/40/4LIZe6TU_o.png" width="323"><img alt="" height="297" src="https://images2.imgbox.com/8d/f0/IJiOfX1x_o.png" width="208"></p> 
<p><img alt="" height="324" src="https://images2.imgbox.com/43/1e/yEA8PFm3_o.png" width="288"><img alt="" height="314" src="https://images2.imgbox.com/c5/77/ATYrb4Kz_o.png" width="327"></p> 
<p><img alt="" height="548" src="https://images2.imgbox.com/48/50/ONORbObq_o.png" width="570"></p> 
<p>win+R打开命令窗口输入：javac -verison ，进行检测是否成功配置环境变量：</p> 
<p></p> 
<p><img alt="" height="122" src="https://images2.imgbox.com/31/08/QIaw9e5F_o.png" width="401"></p> 
<p></p> 
<h4><strong>2.IDEA的</strong><strong>下载安装（我选择的版本是2019.2.3，建议选择低版本的IDEA）</strong></h4> 
<p>官网下载地址：<a href="https://www.jetbrains.com.cn/idea/" rel="nofollow" title="IntelliJ IDEA – 领先的 Java 和 Kotlin IDE (jetbrains.com.cn)">IntelliJ IDEA – 领先的 Java 和 Kotlin IDE (jetbrains.com.cn)</a></p> 
<p><img alt="" height="852" src="https://images2.imgbox.com/3c/70/psL2BTC5_o.png" width="1200"></p> 
<h4><strong>3.scala的下载（我选择的版本是2.12.15）安装及环境变量的配置</strong></h4> 
<p>官网下载地址：<a href="https://www.scala-lang.org/" rel="nofollow" title="The Scala Programming Language (scala-lang.org)">The Scala Programming Language (scala-lang.org)</a></p> 
<p><img alt="" height="750" src="https://images2.imgbox.com/ce/cb/W51ieh0a_o.png" width="1200"></p> 
<p>双击打开下载好的安装程序，一直“Next”即可，最好不要安装到C盘，中间修改一下安装路径即可，最后点击“Finish”。我将scala软件安装在了D盘目录下的Develop文件夹，bin路径如下：</p> 
<p><img alt="" height="318" src="https://images2.imgbox.com/0c/7a/KqnSmo4H_o.png" width="422"></p> 
<p><strong>配置scala的系统环境变量，将scala安装的bin目录路径加入到系统环境变量path中：</strong></p> 
<p><img alt="" height="254" src="https://images2.imgbox.com/09/5a/eWop9iG2_o.png" width="264"></p> 
<p>win+R打开命令窗口输入：scala -verison ，进行检测是否成功配置环境变量：</p> 
<p><img alt="" height="199" src="https://images2.imgbox.com/9e/53/bDpvG5Qu_o.png" width="1068"></p> 
<p></p> 
<h4><strong>4.scala插件（版本要与IDEA版本保持一致，下载2019.2.3版本）的下载安装</strong></h4> 
<p>官网地址：<a class="has-card" href="https://plugins.jetbrains.com/plugin/1347-scala/versions/stable" rel="nofollow" title="Scala - IntelliJ IDEs Plugin | Marketplace"><span class="link-card-box"><span class="link-title">Scala - IntelliJ IDEs Plugin | Marketplace</span><span class="link-link"><img class="link-link-icon" src="https://images2.imgbox.com/63/e8/zcgt9IpJ_o.png" alt="icon-default.png?t=N7T8">https://plugins.jetbrains.com/plugin/1347-scala/versions/stable</span></span></a></p> 
<p>下载完成后，将下载的压缩包解压到IDEA安装目录下的plugins目录下：</p> 
<p><img alt="" height="428" src="https://images2.imgbox.com/aa/3d/14BjaJTq_o.png" width="920"></p> 
<h4><strong>5.maven的下载（我选择的版本是3.5.4）与安装，系统环境变量的配置</strong></h4> 
<p>官网地址:<a href="https://maven.apache.org/download.cgi" rel="nofollow" title="Maven – Download Apache Maven">Maven – Download Apache Maven</a></p> 
<p style="margin-left:.0001pt;text-align:justify;">将对应版本的压缩包下载到本地,并新建一个文件夹Localwarehouse，用来保存下载的依赖文件</p> 
<p style="margin-left:.0001pt;text-align:justify;"><img alt="" height="219" src="https://images2.imgbox.com/cd/d4/7XbYrXVs_o.png" width="830"></p> 
<p style="margin-left:.0001pt;text-align:justify;">配置maven的系统环境配置，跟以上配置的方法一样，将bin目录地址写入path环境变量：</p> 
<p style="margin-left:.0001pt;text-align:justify;"><img alt="" height="796" src="https://images2.imgbox.com/b1/89/DajaLJyM_o.png" width="827"></p> 
<p style="margin-left:.0001pt;text-align:justify;"><img alt="" height="211" src="https://images2.imgbox.com/72/24/pWpDC4jR_o.png" width="1089"></p> 
<p style="margin-left:.0001pt;text-align:justify;"><span style="color:#0d0016;">打开maven安装包下的conf文件夹下面的settings.xml,添加如下代码：</span></p> 
<pre><code class="language-html">&lt;localRepository&gt;D:\\Develop\\maven\\Localwarehouse&lt;/localRepository&gt;</code></pre> 
<p style="margin-left:.0001pt;text-align:justify;"><img alt="" height="214" src="https://images2.imgbox.com/fe/06/GD0ebHuk_o.png" width="830"></p> 
<p style="margin-left:.0001pt;text-align:justify;">在settings.xml配置文件中找到mirrors节点，添加阿里云仓库代码，具体代码如下配置（注意要添加在&lt;mirrors&gt;和&lt;/mirrors&gt;两个标签之间）：</p> 
<pre><code>&lt;!-- 阿里云仓库 --&gt;
&lt;mirror&gt;
	&lt;id&gt;alimaven&lt;/id&gt;
	&lt;mirrorOf&gt;central&lt;/mirrorOf&gt;
	&lt;name&gt;aliyun maven&lt;/name&gt;
	&lt;url&gt;http://maven.aliyun.com/nexus/content/repositories/central/&lt;/url&gt;
&lt;/mirror&gt;</code></pre> 
<p style="margin-left:.0001pt;text-align:justify;"><img alt="" height="322" src="https://images2.imgbox.com/25/06/FaE1dh4a_o.png" width="748"></p> 
<p style="margin-left:.0001pt;text-align:justify;"><span style="color:#0d0016;">添加如下代码用来配置jdk版本：</span></p> 
<pre><code class="language-html">   &lt;profile&gt;
    &lt;id&gt;jdk-1.8.0&lt;/id&gt;
    &lt;activation&gt;
    &lt;activeByDefault&gt;true&lt;/activeByDefault&gt;
    &lt;jdk&gt;1.8.0&lt;/jdk&gt;
    &lt;/activation&gt;
    &lt;properties&gt;
    &lt;maven.compiler.source&gt;1.8.0&lt;/maven.compiler.source&gt;
    &lt;maven.compiler.target&gt;1.8.0&lt;/maven.compiler.target&gt;
    &lt;maven.compiler.compilerVersion&gt;1.8.0&lt;/maven.compiler.compilerVersion&gt;
    &lt;/properties&gt;
    &lt;/profile&gt;</code></pre> 
<p></p> 
<p><img alt="" height="691" src="https://images2.imgbox.com/73/64/LmJ2gMZV_o.png" width="1147"></p> 
<h2><strong>二、将maven加载到IDEA中</strong></h2> 
<p><img alt="" height="339" src="https://images2.imgbox.com/a2/aa/EeCzxooF_o.png" width="223"><img alt="" height="289" src="https://images2.imgbox.com/c2/7c/h9Trqs0m_o.png" width="428"></p> 
<h2>三、检测scala插件是否在IDEA中已经安装成功</h2> 
<p><img alt="" height="342" src="https://images2.imgbox.com/30/6c/K4WDExs2_o.png" width="507"></p> 
<h2>四、用maven新建一个工程项目</h2> 
<p><img alt="" height="256" src="https://images2.imgbox.com/63/4e/mZ8hEJtS_o.png" width="249"><img alt="" height="203" src="https://images2.imgbox.com/30/86/4YJMetFo_o.png" width="427"></p> 
<p><img alt="" height="163" src="https://images2.imgbox.com/ad/23/UbOBb3Pt_o.png" width="342"><img alt="" height="161" src="https://images2.imgbox.com/08/46/9VzUcnZy_o.png" width="338"></p> 
<p><img alt="" height="558" src="https://images2.imgbox.com/03/c8/md4fY6Iy_o.png" width="1200"></p> 
<h2><strong>五、配置pom.xml文件</strong></h2> 
<p><strong>1.如果只需要在本地运行spark程序，则只需要添加scala-library、spark-core、spark-sql、spark-streaming等依赖，添加代码如下：</strong></p> 
<pre><code class="language-html">&lt;properties&gt;
        &lt;!-- 声明scala的版本 --&gt;
        &lt;scala.version&gt;2.12.15&lt;/scala.version&gt;
        &lt;!-- 声明linux集群搭建的spark版本，如果没有搭建则不用写 --&gt;
        &lt;spark.version&gt;3.2.1&lt;/spark.version&gt;
        &lt;!-- 声明linux集群搭建的Hadoop版本 ，如果没有搭建则不用写--&gt;
        &lt;hadoop.version&gt;3.1.4&lt;/hadoop.version&gt;
    &lt;/properties&gt;
    &lt;dependencies&gt;
        &lt;!--scala--&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.scala-lang&lt;/groupId&gt;
            &lt;artifactId&gt;scala-library&lt;/artifactId&gt;
            &lt;version&gt;${scala.version}&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-core --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;
            &lt;artifactId&gt;spark-core_2.12&lt;/artifactId&gt;
            &lt;version&gt;3.2.1&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-sql --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;
            &lt;artifactId&gt;spark-sql_2.12&lt;/artifactId&gt;
            &lt;version&gt;3.2.1&lt;/version&gt;
        &lt;/dependency&gt;
        &lt;!-- https://mvnrepository.com/artifact/org.apache.spark/spark-streaming --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.apache.spark&lt;/groupId&gt;
            &lt;artifactId&gt;spark-streaming_2.12&lt;/artifactId&gt;
            &lt;version&gt;3.2.1&lt;/version&gt;
            &lt;scope&gt;provided&lt;/scope&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;</code></pre> 
<h2><strong>六、新建scala类文件编写代码</strong></h2> 
<p>当你右键发现无法新建scala类，需要将<span style="color:#fe2c24;"><strong>scala SDK</strong></span>添加到当前项目中。</p> 
<p><img alt="" height="658" src="https://images2.imgbox.com/ce/9f/tcfEZVyw_o.png" width="1098"></p> 
<p><img alt="" height="565" src="https://images2.imgbox.com/bd/c1/L7mLKQP6_o.png" width="335"><img alt="" height="399" src="https://images2.imgbox.com/6d/ed/LMroGtAX_o.png" width="475"></p> 
<p></p> 
<p><strong>鼠标点击java文件夹，右键new---&gt;Scala Class</strong></p> 
<p><img alt="" height="360" src="https://images2.imgbox.com/30/b5/cfAKQ6PY_o.png" width="595"></p> 
<p><img alt="" height="270" src="https://images2.imgbox.com/7f/24/P3g15rTu_o.png" width="547"></p> 
<p>在WordCount文件中编写如下代码：</p> 
<pre><code class="language-java">import org.apache.spark.sql.SparkSession
object WordCount {
  def main(args: Array[String]): Unit = {
    val spark = SparkSession
      .builder()
      .master("local[*]")
      .appName("word count")
      .getOrCreate()
    val sc = spark.sparkContext
    val rdd = sc.textFile("data/input/words.txt")
    val counts = rdd.flatMap(_.split(" ")).map((_,1)).reduceByKey(_+_)
    counts.collect().foreach(println)
    println("全部的单词数："+counts.count())
    counts.saveAsTextFile("data/output/word-count")
  }
}</code></pre> 
<p>准备好测试文件words.txt,将文件存放在scalaproject--&gt;data--&gt;input--&gt;words.txt</p> 
<pre><code class="language-html">hello me you her
hello me you
hello me
hello</code></pre> 
<p style="margin-left:.0001pt;text-align:left;"><img alt="" height="377" src="https://images2.imgbox.com/49/c6/HZgZ9Q7I_o.png" width="544"></p> 
<p style="margin-left:.0001pt;text-align:left;"><strong>运行WordCount程序</strong></p> 
<p style="margin-left:.0001pt;text-align:left;"><img alt="" height="392" src="https://images2.imgbox.com/88/17/fI4YlB7S_o.png" width="498"></p> 
<p style="margin-left:.0001pt;text-align:left;"><span style="color:#fe2c24;"><strong>运行结果：</strong></span></p> 
<p><img alt="" height="319" src="https://images2.imgbox.com/cc/d1/hRL1N2Ye_o.png" width="395"></p> 
<p><img alt="" height="373" src="https://images2.imgbox.com/f4/89/RX6nNiwA_o.png" width="1200"></p> 
<h2>七、其他注意事项</h2> 
<p>如果运行spark程序，控制台有输出 “Could not locate executable null\bin\winutils.exe in the Hadoop binaries”错误提示，解决方案请参考以下文章：</p> 
<p><a class="link-info has-card" href="https://blog.csdn.net/hyj_king/article/details/104299371" title="https://blog.csdn.net/hyj_king/article/details/104299371"><span class="link-card-box"><span class="link-title">https://blog.csdn.net/hyj_king/article/details/104299371</span><span class="link-link"><img class="link-link-icon" src="https://images2.imgbox.com/bb/6a/diQeKXIg_o.png" alt="icon-default.png?t=N7T8">https://blog.csdn.net/hyj_king/article/details/104299371</span></span></a></p> 
<p><strong>winuntils.exe下载地址：</strong></p> 
<p><a class="has-card" href="https://github.com/cdarlint/winutils" title="GitHub - cdarlint/winutils: winutils.exe hadoop.dll and hdfs.dll binaries for hadoop windows"><span class="link-card-box"><span class="link-title">GitHub - cdarlint/winutils: winutils.exe hadoop.dll and hdfs.dll binaries for hadoop windows</span><span class="link-desc">winutils.exe hadoop.dll and hdfs.dll binaries for hadoop windows - cdarlint/winutils</span><span class="link-link"><img class="link-link-icon" src="https://images2.imgbox.com/be/16/QNrqWiUE_o.png" alt="icon-default.png?t=N7T8">https://github.com/cdarlint/winutils</span></span></a></p> 
<p>如果运行你的spark程序，在控制台上打印出很多info信息，解决方案请参考以下文章：</p> 
<p><a class="has-card" href="https://blog.csdn.net/weixin_44328257/article/details/125846290" title="Spark控制台不打印INFO，只输出结果_no custom resources configured for spark.driver.-CSDN博客"><span class="link-card-box"><span class="link-title">Spark控制台不打印INFO，只输出结果_no custom resources configured for spark.driver.-CSDN博客</span><span class="link-link"><img class="link-link-icon" src="https://images2.imgbox.com/73/40/yjPHBXlW_o.png" alt="icon-default.png?t=N7T8">https://blog.csdn.net/weixin_44328257/article/details/125846290</span></span></a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/0a4c5c57a0981bf250252da24f460dd8/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">uni-app开发小程序（项目搭建）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/dd977c6e8aff833560b5e28a5f7f78d4/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">前端-vue项目debugger调试</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>