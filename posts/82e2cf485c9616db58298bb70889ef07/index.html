<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【peft】huggingface大模型加载多个LoRA并随时切换 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/82e2cf485c9616db58298bb70889ef07/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="【peft】huggingface大模型加载多个LoRA并随时切换">
  <meta property="og:description" content="加载多个LoRA并随时切换 参考Multi Adapter support
要求 peft&gt;=0.3.0
用法说明 在加载第一个适配器时，可以通过 PeftModel.from_pretrained 方法并指定 adapter_name 参数来给它命名。否则，将使用默认的适配器名称 default。要加载另一个适配器，请使用 PeftModel 的 load_adapter() 方法，例如：model.load_adapter(peft_model_path, adapter_name)要切换适配器，请使用 PeftModel 的 set_adapter() 方法，例如：model.set_adapter(adapter_name)要禁用适配器，请使用上下文管理器 disable_adapter()，例如：with model.disable_adapter()特别适用于LoRA方法：要合并和卸载当前活动的适配器，以便将LoRA权重添加到基础模型权重中，并将注入的LoRA模型删除以恢复具有添加了LoRA权重的Transformers基础模型的模型，请使用 merge_and_unload()方法，例如：model = model.merge_and_unload() 例子 from peft import PeftModel from transformers import LlamaTokenizer, LlamaForCausalLM, GenerationConfig model_name = &#34;decapoda-research/llama-7b-hf&#34; tokenizer = LlamaTokenizer.from_pretrained(model_name) model = LlamaForCausalLM.from_pretrained( model_name, load_in_8bit=True, device_map=&#34;auto&#34;, use_auth_token=True ) model = PeftModel.from_pretrained(model, &#34;tloen/alpaca-lora-7b&#34;, adapter_name=&#34;eng_alpaca&#34;) model.load_adapter(&#34;22h/cabrita-lora-v0-1&#34;, adapter_name=&#34;portuguese_alpaca&#34;) model.set_adapter(&#34;eng_alpaca&#34;) instruction = &#34;Tell me about alpacas.&#34; print(evaluate(instruction)) &#34;&#34;&#34;output The alpaca (Vicugna pacos) is a domesticated species of South American camelid.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2023-05-14T00:06:52+08:00">
    <meta property="article:modified_time" content="2023-05-14T00:06:52+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【peft】huggingface大模型加载多个LoRA并随时切换</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-github-gist">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="LoRA_0"></a>加载多个LoRA并随时切换</h2> 
<blockquote> 
 <p>参考<a href="https://github.com/huggingface/peft/pull/263">Multi Adapter support</a><br> 要求 <code>peft&gt;=0.3.0</code></p> 
</blockquote> 
<h3><a id="_5"></a>用法说明</h3> 
<ol><li>在加载第一个适配器时，可以通过 <code>PeftModel.from_pretrained</code> 方法并指定 <strong><code>adapter_name</code></strong> 参数来给它命名。否则，将使用默认的适配器名称 <code>default</code>。</li><li>要加载另一个适配器，请使用 <code>PeftModel</code> 的 <strong><code>load_adapter()</code></strong> 方法，例如：<code>model.load_adapter(peft_model_path, adapter_name)</code></li><li>要切换适配器，请使用 <code>PeftModel</code> 的 <strong><code>set_adapter()</code></strong> 方法，例如：<code>model.set_adapter(adapter_name)</code></li><li>要禁用适配器，请使用上下文管理器 <code>disable_adapter()</code>，例如：<code>with model.disable_adapter()</code></li><li><strong>特别适用于LoRA方法</strong>：要合并和卸载当前活动的适配器，以便将LoRA权重添加到基础模型权重中，并将注入的LoRA模型删除以恢复具有添加了LoRA权重的Transformers基础模型的模型，请使用 <code>merge_and_unload()</code>方法，例如：<code>model = model.merge_and_unload()</code></li></ol> 
<h3><a id="_12"></a>例子</h3> 
<pre><code class="prism language-python"><span class="token keyword">from</span> peft <span class="token keyword">import</span> PeftModel
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> LlamaTokenizer<span class="token punctuation">,</span> LlamaForCausalLM<span class="token punctuation">,</span> GenerationConfig

model_name <span class="token operator">=</span> <span class="token string">"decapoda-research/llama-7b-hf"</span>
tokenizer <span class="token operator">=</span> LlamaTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_name<span class="token punctuation">)</span>
model <span class="token operator">=</span> LlamaForCausalLM<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>
    model_name<span class="token punctuation">,</span>
    load_in_8bit<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    device_map<span class="token operator">=</span><span class="token string">"auto"</span><span class="token punctuation">,</span>
    use_auth_token<span class="token operator">=</span><span class="token boolean">True</span>
<span class="token punctuation">)</span>
model <span class="token operator">=</span> PeftModel<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model<span class="token punctuation">,</span> <span class="token string">"tloen/alpaca-lora-7b"</span><span class="token punctuation">,</span> adapter_name<span class="token operator">=</span><span class="token string">"eng_alpaca"</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>load_adapter<span class="token punctuation">(</span><span class="token string">"22h/cabrita-lora-v0-1"</span><span class="token punctuation">,</span> adapter_name<span class="token operator">=</span><span class="token string">"portuguese_alpaca"</span><span class="token punctuation">)</span>

model<span class="token punctuation">.</span>set_adapter<span class="token punctuation">(</span><span class="token string">"eng_alpaca"</span><span class="token punctuation">)</span>
instruction <span class="token operator">=</span> <span class="token string">"Tell me about alpacas."</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>evaluate<span class="token punctuation">(</span>instruction<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token triple-quoted-string string">"""output
The alpaca (Vicugna pacos) is a domesticated species of South American camelid. It resembles a small llama in appearance, but unlike the llama, it is not used as a beast of burden. It is kept primarily for its fiber, which can be spun into yarn. Alpaca fiber is warmer, lighter, and softer than sheep's wool, and is highly valued in the textile industry. The fiber comes in a variety of natural colors, including white, beige, cream, and fawn. It can also be dyed in a wide range of colors.
Alpaca herds can be found in the highlands of Peru, Bolivia, Chile, Ecuador, and Colombia. They are also raised in the United States, Canada, Australia, New Zealand, and Europe. The animals graze on grasses, herbs, and shrubs, and can survive in temperatures as low as -30°F (-34°C). They are social animals, living in herds of up to 20 individuals.
The fiber of the alpaka is used to make clothing
"""</span>


model<span class="token punctuation">.</span>set_adapter<span class="token punctuation">(</span><span class="token string">"portuguese_alpaca"</span><span class="token punctuation">)</span>
instruction <span class="token operator">=</span> <span class="token string">"Invente uma desculpa criativa pra dizer que não preciso ir à festa."</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>evaluate<span class="token punctuation">(</span>instruction<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token triple-quoted-string string">"""output
"Eu preciso ficar em casa para cuidar de meu gato."
"""</span>


<span class="token keyword">with</span> model<span class="token punctuation">.</span>disable_adapter<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    instruction <span class="token operator">=</span> <span class="token string">"Invente uma desculpa criativa pra dizer que não preciso ir à festa."</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>evaluate<span class="token punctuation">(</span>instruction<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token triple-quoted-string string">"""output
I'm sorry, but I can't go to the party. I'm sick. I have a cold. I don't feel well. I need to stay at home and rest.
I have a lot of homework to do. My dog ate my homework. My homework is too hard. I didn't have time to do it. It's too late. I forgot about it.
My parents won't let me go. My parents are out of town. They're on vacation. They have to work. They are sick. They need to take care of my brother.
They're not home. They went to the grocery store. They took the car to the mechanic. They had to go to a meeting. They were in a hurry. They forgot about me.
Their car broke down. Their car ran out of gas. They got a flat tire. They couldn't find a parking space. They didn' t have enough money. They lost their wallet.
It's raining. The roads are icy. There's a blizzard. There are too many cars on the road. There was an accident.
"""</span>
</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/daae0c0e30223f712faea224146c32ba/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">滤波笔记一：卡尔曼滤波（Kalman Filtering）详解</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/23cfa69cf8e04865803a9c07260b3bdb/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">stable-diffusion-webui 启动服务，卡在浏览器loading中, 重定向解决</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>