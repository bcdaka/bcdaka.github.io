<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>教程：利用LLaMA_Factory微调llama3:8b大模型 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/23d0d99a00fea64528ed6b134a8f324c/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="教程：利用LLaMA_Factory微调llama3:8b大模型">
  <meta property="og:description" content="一、安装llama模型文件 下载地址（魔塔）：https://modelscope.cn/models/LLM-Research/Meta-Llama-3-8B-Instruct/files
点击下载模型，复制git命令：
git clone https://www.modelscope.cn/LLM-Research/Meta-Llama-3-8B-Instruct.git 在存放模型空白处右键，点击git bash here，下载llama3模型至本地
由于文件较大，因此该过程比较久，保持下载窗口打开，知道出现下一命令行表示下载完成。
二、安装LLaMA-Factory github:hiyouga/LLaMA-Factory: Unify Efficient Fine-Tuning of 100&#43; LLMs (github.com)
将其下载到本地
三、为LLaMA-Factory配置环境 进入LLaMA-Factory目录，在路径处输入cmd并回车进入该目录位置的终端
新建虚拟环境
conda create -n llama_factory python=3.10 -y 激活虚拟环境
conda activate llama_factory 安装依赖
pip install -e .[metrics,modelscope,qwen] pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 pip install https://github.com/jllllll/bitsandbytes-windows-webui/releases/download/wheels/bitsandbytes-0.41.2.post2-py3-none-win_amd64.whl 安装tensorboard
pip install tensorboard 设置环境变量
Set USE MODELSCOPE HUB=1 四、运行LLaMA-Factory的webui.py 执行代码
python src/webui.py 若顺利，会打开如下网页(初始界面)
五、微调模型 在“Model name”中选择“LLaMA3-8B”,将“Model path”中的路径填写Meta-Llama-3-8B-Instruct文件夹的路径
在dataset中即可选择预先准备好的数据集进行微调
以微调为中文模型举例，则在下拉选项中选择后缀为zh的数据集
点击“Start”开始微调。">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-05-26T00:25:55+08:00">
    <meta property="article:modified_time" content="2024-05-26T00:25:55+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">教程：利用LLaMA_Factory微调llama3:8b大模型</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2>一、安装llama模型文件</h2> 
<p>下载地址（魔塔）：<a href="https://caovan.com/go?_=48ce46a27aaHR0cHM6Ly9tb2RlbHNjb3BlLmNuL21vZGVscy9MTE0tUmVzZWFyY2gvTWV0YS1MbGFtYS0zLThCLUluc3RydWN0L2ZpbGVz" rel="nofollow" title="https://modelscope.cn/models/LLM-Research/Meta-Llama-3-8B-Instruct/files">https://modelscope.cn/models/LLM-Research/Meta-Llama-3-8B-Instruct/files</a></p> 
<p>点击下载模型，复制git命令：</p> 
<pre><code class="language-bash">git clone https://www.modelscope.cn/LLM-Research/Meta-Llama-3-8B-Instruct.git</code></pre> 
<p><img alt="" height="834" src="https://images2.imgbox.com/48/b6/93MEq7rM_o.png" width="1200"></p> 
<p>在存放模型空白处右键，点击git bash here，下载llama3模型至本地</p> 
<p>由于文件较大，因此该过程比较久，保持下载窗口打开，知道出现下一命令行表示下载完成。</p> 
<p><img alt="" height="620" src="https://images2.imgbox.com/41/a9/4C09WfGR_o.png" width="1139"></p> 
<h2>二、安装LLaMA-Factory</h2> 
<p>github:<a href="https://github.com/hiyouga/LLaMA-Factory" title="hiyouga/LLaMA-Factory: Unify Efficient Fine-Tuning of 100+ LLMs (github.com)">hiyouga/LLaMA-Factory: Unify Efficient Fine-Tuning of 100+ LLMs (github.com)</a></p> 
<p>将其下载到本地</p> 
<p><img alt="" height="983" src="https://images2.imgbox.com/03/ce/Uriy5XPW_o.png" width="1200"></p> 
<h2>三、为LLaMA-Factory配置环境</h2> 
<p>进入LLaMA-Factory目录，在路径处输入cmd并回车进入该目录位置的终端</p> 
<p><img alt="" height="269" src="https://images2.imgbox.com/16/c0/R7ww9967_o.png" width="1114"></p> 
<p>新建虚拟环境</p> 
<pre><code class="language-bash">conda create -n llama_factory python=3.10 -y</code></pre> 
<p>激活虚拟环境</p> 
<pre><code class="language-bash">conda activate llama_factory</code></pre> 
<p>安装依赖</p> 
<pre><code class="language-bash">pip install -e .[metrics,modelscope,qwen]</code></pre> 
<pre><code class="language-bash">pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121</code></pre> 
<pre><code class="language-bash">pip install https://github.com/jllllll/bitsandbytes-windows-webui/releases/download/wheels/bitsandbytes-0.41.2.post2-py3-none-win_amd64.whl</code></pre> 
<p>安装tensorboard</p> 
<pre><code class="language-bash">pip install tensorboard</code></pre> 
<p>设置环境变量</p> 
<pre><code class="language-bash">Set USE MODELSCOPE HUB=1</code></pre> 
<h2>四、运行LLaMA-Factory的webui.py</h2> 
<p>执行代码</p> 
<pre><code class="language-bash">python src/webui.py</code></pre> 
<p>若顺利，会打开如下网页(初始界面)</p> 
<p><img alt="" height="924" src="https://images2.imgbox.com/39/07/KTo45h3c_o.png" width="1200"></p> 
<h2>五、微调模型</h2> 
<p>在“Model name”中选择“LLaMA3-8B”,将“Model path”中的路径填写Meta-Llama-3-8B-Instruct文件夹的路径</p> 
<p><img alt="" height="136" src="https://images2.imgbox.com/56/dd/vbgcn1TI_o.png" width="1200"></p> 
<p>在dataset中即可选择预先准备好的数据集进行微调</p> 
<p><img alt="" height="644" src="https://images2.imgbox.com/fe/ff/daIOneeg_o.png" width="1200"></p> 
<p>以微调为中文模型举例，则在下拉选项中选择后缀为zh的数据集</p> 
<p>点击“Start”开始微调。</p> 
<h2>六、导出模型</h2> 
<p>1.微调训练结束之后，点击“Export”选项卡，切换到导出功能区！</p> 
<p>2.点击“Refresh adapters”按钮，刷新lora模型，在左侧的下拉列表中选择刚刚训练好的模型！</p> 
<p>3.在“Max shard size(GB)”中设置好每个拆分模型的最大size；</p> 
<p>4.在“Export dir”中设置模型保存的路径；</p> 
<p>5.点击“Export”按钮，开始导出模型（需要点时间等待）；</p> 
<p><img alt="" height="365" src="https://images2.imgbox.com/ac/35/HExX62iA_o.png" width="1200"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/b75110b67a3f02bf7ae292b3f48fd4ef/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">深度学习之父 Hinton 万字访谈录：中美 AI 竞赛没有退路可言（GPT-4o总结版）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/0b4d63fe301f42e3c91761d4a357bd3f/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">golang适配GBase8s(南大通用)数据库</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>