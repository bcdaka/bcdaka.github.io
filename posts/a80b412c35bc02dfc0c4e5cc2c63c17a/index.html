<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>2024年大数据最全Hadoop大数据集群搭建（超详细）_hadoop集群搭建，快速从入门到精通 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/a80b412c35bc02dfc0c4e5cc2c63c17a/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="2024年大数据最全Hadoop大数据集群搭建（超详细）_hadoop集群搭建，快速从入门到精通">
  <meta property="og:description" content="网上学习资料一大堆，但如果学到的知识不成体系，遇到问题时只是浅尝辄止，不再深入研究，那么很难做到真正的技术提升。
需要这份系统化资料的朋友，可以戳这里获取
一个人可以走的很快，但一群人才能走的更远！不论你是正从事IT行业的老鸟或是对IT行业感兴趣的新人，都欢迎加入我们的的圈子（技术交流、学习资源、职场吐槽、大厂内推、面试辅导），让我们一起学习成长！
修改完成之后记得使用命令source /etc/profile，使修改生效
4. JDK环境验证 java -version
第六步：安装Hadoop 1. 下载Hadoop 3.1.3 Index of /dist/hadoop/common
2. 安装Hadoop 同样通过mobaxterm的上的SFTP功能（或其他工具）上传到/export/software目录下，然后解压到/export/servers目录下
cd /export/software
mobaxterm的上的SFTP功能
tar -zxvf hadoop-3.1.3.tar.gz -C /export/servers/
3. 配置Hadoop系统环境变量 vim /etc/profile
配置环境变量
export HADOOP_HOME=/export/servers/hadoop-3.1.3
export PATH=: H A D O O P _ H O M E / b i n : HADOOP\_HOME/bin: HADOOP_HOME/bin:HADOOP_HOME/sbin:$PATH
同时添加hadoop为root用户，否则启动的HDFS的时候可能会报错
export HDFS_NAMENODE_USER=root
export HDFS_DATANODE_USER=root
export HDFS_SECONDARYNAMENODE_USER=root
export YARN_RESOURCEMANAGER_USER=root
export YARN_NODEMANAGER_USER=root
执行source /etc/profile命令,让配置生效
4. 验证Hadoop环境 hadoop version">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-05-09T15:58:17+08:00">
    <meta property="article:modified_time" content="2024-05-09T15:58:17+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">2024年大数据最全Hadoop大数据集群搭建（超详细）_hadoop集群搭建，快速从入门到精通</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p><img src="https://images2.imgbox.com/a7/a9/Z0oRH4Vl_o.png" alt="img"><br> <img src="https://images2.imgbox.com/9e/8d/A4K07sgs_o.png" alt="img"></p> 
<p><strong>网上学习资料一大堆，但如果学到的知识不成体系，遇到问题时只是浅尝辄止，不再深入研究，那么很难做到真正的技术提升。</strong></p> 
<p><strong><a href="https://bbs.csdn.net/forums/4f45ff00ff254613a03fab5e56a57acb">需要这份系统化资料的朋友，可以戳这里获取</a></strong></p> 
<p><strong>一个人可以走的很快，但一群人才能走的更远！不论你是正从事IT行业的老鸟或是对IT行业感兴趣的新人，都欢迎加入我们的的圈子（技术交流、学习资源、职场吐槽、大厂内推、面试辅导），让我们一起学习成长！</strong></p> 
<p><img src="https://images2.imgbox.com/8d/22/398F0Km4_o.png" alt="">修改完成之后记得使用命令source /etc/profile，使修改生效</p> 
<h4><a id="4_JDK_17"></a>4. JDK环境验证</h4> 
<p>java -version</p> 
<p><img src="https://images2.imgbox.com/3a/fb/9owKSErD_o.png" alt=""></p> 
<h3><a id="Hadoop_27"></a>第六步：安装Hadoop</h3> 
<h4><a id="1_Hadoop_313_30"></a>1. 下载Hadoop 3.1.3</h4> 
<p><a href="" rel="nofollow">Index of /dist/hadoop/common</a></p> 
<p><img src="https://images2.imgbox.com/cc/b0/9Q1oieON_o.png" alt=""></p> 
<p><img src="https://images2.imgbox.com/99/d3/wcicbwZp_o.png" alt=""></p> 
<h4><a id="2_Hadoop_42"></a>2. 安装Hadoop</h4> 
<p>同样通过mobaxterm的上的SFTP功能（或其他工具）上传到/export/software目录下，然后解压到/export/servers目录下</p> 
<p>cd /export/software</p> 
<p>mobaxterm的上的SFTP功能</p> 
<p><img src="https://images2.imgbox.com/86/73/2Ij7hRNI_o.png" alt=""></p> 
<p>tar -zxvf hadoop-3.1.3.tar.gz -C /export/servers/</p> 
<p><img src="https://images2.imgbox.com/17/dd/FXD4698M_o.png" alt=""></p> 
<h4><a id="3_Hadoop_63"></a>3. 配置Hadoop系统环境变量</h4> 
<p>vim /etc/profile</p> 
<p>配置环境变量</p> 
<p>export HADOOP_HOME=/export/servers/hadoop-3.1.3</p> 
<p>export PATH=:<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         H 
        
       
         A 
        
       
         D 
        
       
         O 
        
       
         O 
        
       
         P 
        
       
         _ 
        
       
         H 
        
       
         O 
        
       
         M 
        
       
         E 
        
       
         / 
        
       
         b 
        
       
         i 
        
       
         n 
        
       
         : 
        
       
      
        HADOOP\_HOME/bin: 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.06em; vertical-align: -0.31em;"></span><span class="mord mathnormal" style="margin-right: 0.0813em;">H</span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right: 0.0278em;">D</span><span class="mord mathnormal" style="margin-right: 0.1389em;">OOP</span><span class="mord" style="margin-right: 0.0278em;">_</span><span class="mord mathnormal" style="margin-right: 0.0813em;">H</span><span class="mord mathnormal" style="margin-right: 0.0576em;">OME</span><span class="mord">/</span><span class="mord mathnormal">bin</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">:</span></span></span></span></span>HADOOP_HOME/sbin:$PATH</p> 
<p><img src="https://images2.imgbox.com/c3/8b/71WBDGqv_o.png" alt=""></p> 
<p>同时添加hadoop为root用户，否则启动的HDFS的时候可能会报错</p> 
<p>export HDFS_NAMENODE_USER=root</p> 
<p>export HDFS_DATANODE_USER=root</p> 
<p>export HDFS_SECONDARYNAMENODE_USER=root</p> 
<p>export YARN_RESOURCEMANAGER_USER=root</p> 
<p>export YARN_NODEMANAGER_USER=root</p> 
<p><img src="https://images2.imgbox.com/55/e4/JYpNyKWD_o.png" alt=""></p> 
<p>执行source /etc/profile命令,让配置生效</p> 
<h4><a id="4_Hadoop_106"></a>4. 验证Hadoop环境</h4> 
<p>hadoop version</p> 
<p><img src="https://images2.imgbox.com/88/ea/upPaWKzG_o.png" alt=""></p> 
<p>==========================   快照    ==================================</p> 
<h3><a id="Hadoop_121"></a>第七步：Hadoop集群配置</h3> 
<p>集群配置如下：</p> 
<p><img src="https://images2.imgbox.com/bb/b6/dEVNDuIG_o.png" alt=""></p> 
<h4><a id="1Hadoop_132"></a>1、配置Hadoop集群主节点</h4> 
<h5><a id="1hadoopenvsh_135"></a>（1）修改hadoop-env.sh文件</h5> 
<p>cd /export/servers/hadoop-3.1.3/etc/hadoop</p> 
<p>vim hadoop-env.sh</p> 
<p>找到export JAVA_HOME的位置修改</p> 
<p>export JAVA_HOME=/export/servers/jdk</p> 
<p><img src="https://images2.imgbox.com/bf/b3/JSpjpcI5_o.png" alt=""></p> 
<h5><a id="2coresitexml_154"></a>（2）修改core-site.xml文件</h5> 
<p>主要是配置主进程NameNode的运行主机和运行生成数据的临时目录</p> 
<p>vim core-site.xml</p> 
<p>写入以下内容</p> 
<p></p> 
<p>fs.defaultFS</p> 
<p>hdfs://hadoop01:9000</p> 
<p></p> 
<p></p> 
<p>hadoop.tmp.dir</p> 
<p>/export/servers/hadoop-3.1.3/tmp</p> 
<p></p> 
<p><img src="https://images2.imgbox.com/81/40/Ds03hPev_o.png" alt=""></p> 
<h5><a id="3hdfssitexml_200"></a>（3）修改hdfs-site.xml文件</h5> 
<p>设置HDFS数据块的副本数量以及second namenode的地址</p> 
<p>vim hdfs-site.xml</p> 
<p>写入以下内容</p> 
<p></p> 
<p>dfs.replication</p> 
<p>3</p> 
<p></p> 
<p></p> 
<p>dfs.namenode.secondary.http-address</p> 
<p>hadoop02:50090</p> 
<p></p> 
<p><img src="https://images2.imgbox.com/c1/1b/PQqi1QpF_o.png" alt=""></p> 
<h5><a id="4mapredsitexml_246"></a>（4）修改mapred-site.xml文件</h5> 
<p>设置MapReduce的运行时框架</p> 
<p>vim mapred-site.xml</p> 
<p>写入以下内容</p> 
 
<p></p> 
<p>mapreduce.framework.name</p> 
<p>yarn</p> 
<p></p> 
<p><img src="https://images2.imgbox.com/16/f8/UysrRL9Q_o.png" alt=""></p> 
<h5><a id="5yarnsitexml_283"></a>（5）修改yarn-site.xml文件</h5> 
<p>设置yarn集群的管理者</p> 
<p>vim yarn-site.xml</p> 
<p>写入以下内容</p> 
<p></p> 
<p>yarn.resourcemanager.hostname</p> 
<p>hadoop01</p> 
<p></p> 
<p></p> 
<p>yarn.nodemanager.aux-services</p> 
<p>mapreduce_shuffle</p> 
<p></p> 
<p><img src="https://images2.imgbox.com/3a/82/QoPbb8YV_o.png" alt=""></p> 
<h5><a id="6workers_329"></a>（6）修改workers文件</h5> 
<p>该文件用来记录从节点的主机名（hadoop 2.x中为slaves文件）</p> 
<p>打开该配置文件，先删除里面的内容（默认localhost），然后配置如下内容。</p> 
<p>vim workers</p> 
<p>删除默认内容，添加以下内容</p> 
<p>hadoop01</p> 
<p>hadoop02</p> 
<p>hadoop03</p> 
<p><img src="https://images2.imgbox.com/20/5d/PsGQdWoq_o.png" alt=""></p> 
<h4><a id="2_357"></a>2、将集群主节点的配置文件分发到其他子节点</h4> 
<p>完成Hadoop集群主节点hadoop01的配置后，还需要将系统环境配置文件、JDK安装目录和Hadoop安装目录分发到其他子节点hadoop02和hadoop03上，具体指令：</p> 
<p>scp /etc/profile hadoop02:/etc/profile</p> 
<p>scp /etc/profile hadoop03:/etc/profile</p> 
<p>scp -r /export/ hadoop02:/</p> 
<p>scp -r /export/ hadoop03:/</p> 
<p>传完之后要在hadoop02和hadoop03上分别执行 source /etc/profile 命令，来刷新配置文件</p> 
<p>如果使用scp时需要输入密码，请重新检查ssh配置！</p> 
<h4><a id="_381"></a></h4> 
<h3><a id="_384"></a>第八步：格式化文件系统</h3> 
<p>初次启动HDFS集群时，必须对主节点进行格式化处理。在hadoop01上执行</p> 
<p>格式化文件系统指令如下：</p> 
<p>hdfs namenode -format</p> 
<p><img src="https://images2.imgbox.com/72/5c/tQwg3YP0_o.png" alt=""></p> 
<p>不要多次格式化主节点！</p> 
<h3><a id="hadoop_402"></a>第九步：启动和关闭hadoop集群</h3> 
<p>脚本一键启动：</p> 
<p>hadoop01主节点上执行：</p> 
<p>start-dfs.sh</p> 
<p><img src="https://images2.imgbox.com/db/91/JEduB86I_o.png" alt=""></p> 
<p>可以通过jps看到</p> 
<p><img src="https://images2.imgbox.com/51/be/9JoQ5pQ0_o.png" alt=""><img src="https://images2.imgbox.com/37/00/WMOVxfIp_o.png" alt=""></p> 
<p><img src="https://images2.imgbox.com/a2/18/Ua7li2rd_o.png" alt=""></p> 
<p>在主节点上执行</p> 
<p>start-yarn.sh</p> 
<p><img src="https://images2.imgbox.com/40/48/I16CxmTM_o.png" alt=""></p> 
<p><img src="https://images2.imgbox.com/26/85/243DjovT_o.png" alt=""></p> 
<p><img src="https://images2.imgbox.com/fb/6d/5jNs0s0M_o.png" alt=""><img src="https://images2.imgbox.com/14/82/MWbyh3z4_o.png" alt=""></p> 
<p>如果想要关闭，输入stop-dfs.sh即可（不要执行）</p> 
<h4><a id="_451"></a></h4> 
<h3><a id="UIhadoop_454"></a>第十步：通过UI界面查看hadoop运行状态</h3> 
<h4><a id="1__457"></a>1. 关闭防火墙功能</h4> 
<p>在3台虚拟机上均执行以下命令</p> 
<p>本次临时关闭防火墙、永久关闭防火墙</p> 
<p>systemctl stop firewalld.service</p> 
<p>systemctl disable firewalld.service</p> 
<h4><a id="2_windowsip_472"></a>2. 修改windows下ip映射</h4> 
<p>打开C:\Windows\System32\drivers\etc下的hosts文件,添加以下内容（注：如果没有notepad++这类软件，可以通过记事本保存在其他位置，然后拖动到该文件夹下）</p> 
<p>192.168.121.134 hadoop01</p> 
<p>192.168.121.135 hadoop02</p> 
<p>192.168.121.136 hadoop03</p> 
<p><img src="https://images2.imgbox.com/68/db/tz8PDx9u_o.png" alt=""></p> 
<p>在浏览器输入</p> 
<p>http://hadoop01:9870</p> 
<p>http://hadoop01:8088</p> 
<p>即可访问HDFS和Yarn</p> 
<p><img src="https://images2.imgbox.com/71/a9/ezfMrRjm_o.png" alt=""></p> 
<p><img src="https://images2.imgbox.com/b3/f7/3wddHQT5_o.png" alt=""></p> 
<p></p> 
<p>==========================   快照    ==================================</p> 
<h3><a id="hadoop_517"></a>第十一步：hadoop集群初体验</h3> 
<p>统计word.txt中各单词出现的次数</p> 
<p>在Hadoop01创建如下目录，并添加测试文件</p> 
<p>mkdir -p /export/data</p> 
<p>cd /export/data</p> 
<p>vi word.txt</p> 
<p>写入下列内容</p> 
<p>hello world</p> 
<p>hello hadoop</p> 
<p>hello students</p> 
<p><img src="https://images2.imgbox.com/74/e5/NRtpvsDq_o.png" alt=""></p> 
<p>在HDFS上创建 /wordcount/input目录</p> 
<p>hadoop fs -mkdir -p /wordcount/input</p> 
<p>创建完成后可以在HDFS的网站上看到</p> 
<p><img src="https://images2.imgbox.com/59/70/EeZk3OJ2_o.png" alt=""></p> 
<p><img src="https://images2.imgbox.com/6c/5b/f08D8K7O_o.png" alt=""></p> 
<p>将word.txt上传到该目录下</p> 
<p>hadoop fs -put /export/data/word.txt /wordcount/input</p> 
<p><img src="https://images2.imgbox.com/45/69/pXMwJGJ1_o.png" alt=""></p> 
<p></p> 
<p>执行该程序（参考下文中可能遇到的问题，问题1、2为必现问题，建议直接修改）</p> 
<p>cd /export/servers/hadoop-3.1.3/share/hadoop/mapreduce</p> 
<p>hadoop jar hadoop-mapreduce-examples-3.1.3.jar wordcount /wordcount/input /wordcount/output</p> 
<p><img src="https://images2.imgbox.com/76/d2/eZTnvSCg_o.png" alt=""></p> 
<p>查看结果如下：</p> 
<p><img src="https://images2.imgbox.com/a6/8a/uDA4Kead_o.png" alt=""></p> 
<p><img src="https://images2.imgbox.com/98/f5/gAptILnB_o.png" alt=""></p> 
<p></p> 
<h4><a id="_602"></a></h4> 
<h4><a id="_605"></a>注意：</h4> 
<h5><a id="1_608"></a>可能遇到的问题1:</h5> 
<p>找不到或无法加载主类 org.apache.hadoop.mapreduce.v2.app.MRAppMaster</p> 
<p><strong>解决方法：</strong></p> 
<p>输入 hadoop classpath</p> 
<p>复制返回的信息</p> 
<p>修改yarn-site.xml</p> 
<p>cd /export/servers/hadoop-3.1.3/etc/hadoop</p> 
<p>vim yarn-site.xml</p> 
<p>新增以下内容</p> 
<p>yarn.application.classpath</p> 
<p>输入刚才返回的Hadoop classpath路径</p> 
<p></p> 
<p><img src="https://images2.imgbox.com/a6/9e/KpFckDaW_o.png" alt=""></p> 
<p></p> 
<h5><a id="2_653"></a>可能遇到的问题2：</h5> 
<p>Container killed on request. Exit code is 143</p> 
<p><strong>解决方法：</strong></p> 
<p>cd /export/servers/hadoop-3.1.3/etc/hadoop</p> 
<p>vim mapred-site.xml</p> 
<p>mapreduce.map.memory.mb</p> 
<p>2048</p> 
<p>maps的资源限制</p> 
<p>mapreduce.reduce.memory.mb</p> 
<p>2048</p> 
<p>reduces的资源限制</p> 
<p><img src="https://images2.imgbox.com/fa/a5/ls0HKztM_o.png" alt=""></p> 
<h5><a id="3_710"></a><strong>可能遇到的问题3：</strong></h5> 
<p><img src="https://images2.imgbox.com/aa/c5/pYjgZDo8_o.png" alt="img"><br> <img src="https://images2.imgbox.com/39/af/8Bbtx3E5_o.png" alt="img"></p> 
<p><strong>网上学习资料一大堆，但如果学到的知识不成体系，遇到问题时只是浅尝辄止，不再深入研究，那么很难做到真正的技术提升。</strong></p> 
<p><strong><a href="https://bbs.csdn.net/forums/4f45ff00ff254613a03fab5e56a57acb">需要这份系统化资料的朋友，可以戳这里获取</a></strong></p> 
<p><strong>一个人可以走的很快，但一群人才能走的更远！不论你是正从事IT行业的老鸟或是对IT行业感兴趣的新人，都欢迎加入我们的的圈子（技术交流、学习资源、职场吐槽、大厂内推、面试辅导），让我们一起学习成长！</strong></p> 
<p>2048</p> 
<p>maps的资源限制</p> 
<p>mapreduce.reduce.memory.mb</p> 
<p>2048</p> 
<p>reduces的资源限制</p> 
<p><img src="https://images2.imgbox.com/13/21/IKJGX7DA_o.png" alt=""></p> 
<h5><a id="3_762"></a><strong>可能遇到的问题3：</strong></h5> 
<p>[外链图片转存中…(img-s7jxFCc3-1715241465601)]<br> [外链图片转存中…(img-AjnmgvmT-1715241465601)]</p> 
<p><strong>网上学习资料一大堆，但如果学到的知识不成体系，遇到问题时只是浅尝辄止，不再深入研究，那么很难做到真正的技术提升。</strong></p> 
<p><strong><a href="https://bbs.csdn.net/forums/4f45ff00ff254613a03fab5e56a57acb">需要这份系统化资料的朋友，可以戳这里获取</a></strong></p> 
<p><strong>一个人可以走的很快，但一群人才能走的更远！不论你是正从事IT行业的老鸟或是对IT行业感兴趣的新人，都欢迎加入我们的的圈子（技术交流、学习资源、职场吐槽、大厂内推、面试辅导），让我们一起学习成长！</strong></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/689b38fa24080e700b241014090e3d8c/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Java将Unicode转换为中文字符</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/79aabd2a8bd481393e647e27dc2ea1c6/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">AI语言战争再起：阿里巴巴发布通义千问Qwen2.5追平GPT-4 Turbo，中文能力傲视群雄</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>