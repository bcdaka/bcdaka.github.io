<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【目标检测】2024最新-用YOLOv8训练自己的数据集（保姆级教学） - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/4cc5494d528c95b497f550fa3227e930/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="【目标检测】2024最新-用YOLOv8训练自己的数据集（保姆级教学）">
  <meta property="og:description" content="【2024.4】Windows11系统 1.为打开网页流畅，建议准备梯子，打开Github等网站时会明显加快
2.准备Anaconda，可参考其他博主文章下载
一、代码下载 官网下载YOLOv8（建议开梯子） ​ 二、环境配置 1.在Anaconda中利用conda命令创建环境yolov8，并激活环境 -- 创建环境 conda create -n yolov8 python=3.9 -- 激活环境 conda activate yolov8 2.pip的源换到国内aliyun镜像，会提高下载速度 pip config set install.trusted-host mirrors.aliyun.com 3.安装一下yolov8在python&gt;=3.8版本必要安装包，配置文件已经内置其中： pip install ultralytics 4.下载预训练权重模型： （1）推荐yolov8s.pt或者yolov8n.pt，模型小，下载快（用梯子）
（2）下载完成后，将模型放在ultralytics-main文件夹下
5.检验环境： （1）在环境中打开项目ultralytics-main：
① 在Anaconda Prompt中cd到ultralytics-main目录下
② 在Pycharm终端直接打开
（2）运行以下指令：
yolo predict model=yolov8n.pt source=&#39;ultralytics/assets/bus.jpg&#39; (3)若运行成功会在D:\ultralytics-main下生成\runs\detect\predict，且文件中会包含一张照片
​
三、训练模型 【CPU】 1.准备工作： （1）在ultralytics-main目录下新建data文件夹；
（2）再在data目录下新建四个文件夹:Annotations文件夹，images文件夹，ImageSets文件夹，labels文件夹
​
2.准备数据集： （1）将准备好的图片以.jpg的格式放入images文件夹中
（2）利用labelimg进行标注后将生成的.xml文件保存至Annotations文件夹中
3.数据集的划分： （1）在ultralytics-main目录下创建一个split_train_val.py文件；
（2）运行文件之后会在imageSets文件夹下将数据集划分为训练集train.txt、验证集val.txt、测试集test.txt，里面存放的就是用于训练、验证、测试的图片名称，代码内容如下：
import os import random trainval_percent = 0.9 train_percent = 0.9 xmlfilepath = &#39;data/Annotations&#39; txtsavepath = &#39;data/ImageSets&#39; total_xml = os.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-07-12T15:14:30+08:00">
    <meta property="article:modified_time" content="2024-07-12T15:14:30+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【目标检测】2024最新-用YOLOv8训练自己的数据集（保姆级教学）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h4 id="%E3%80%902024.4%E3%80%91Windows11%E7%B3%BB%E7%BB%9F"><strong>【2024.4】Windows11系统</strong></h4> 
<p><strong>        1.为打开网页流畅，建议准备梯子，打开Github等网站时会明显加快</strong></p> 
<p><strong>        2.准备<a class="link-info" href="https://www.anaconda.com/" rel="nofollow" title="Anaconda">Anaconda</a>，可参考其他博主文章下载</strong></p> 
<p></p> 
<h3 id="%E4%B8%80%E3%80%81%E4%BB%A3%E7%A0%81%E4%B8%8B%E8%BD%BD">一、代码下载</h3> 
<h4 id="%E5%AE%98%E7%BD%91%E4%B8%8B%E8%BD%BDYolov8%EF%BC%88%E5%BB%BA%E8%AE%AE%E5%BC%80%E6%A2%AF%E5%AD%90%EF%BC%89"><a class="link-info" href="https://github.com/ultralytics/ultralytics" title="官网">官网</a>下载YOLOv8（建议开梯子）</h4> 
<h4 id="%E2%80%8B%E7%BC%96%E8%BE%91%E2%80%8B"><img alt="" height="328" src="https://images2.imgbox.com/c0/78/Q3gn7PYn_o.png" width="695">​</h4> 
<h3 id="%E4%BA%8C%E3%80%81%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE">二、环境配置</h3> 
<h4 id="1.%E5%9C%A8Anaconda%E4%B8%AD%E5%88%A9%E7%94%A8conda%E5%91%BD%E4%BB%A4%E5%88%9B%E5%BB%BA%E7%8E%AF%E5%A2%83yolov8%EF%BC%8C%E5%B9%B6%E6%BF%80%E6%B4%BB%E7%8E%AF%E5%A2%83">1.在Anaconda中利用conda命令创建环境yolov8，并激活环境</h4> 
<div> 
 <pre><code class="language-python">-- 创建环境
conda create -n yolov8 python=3.9

-- 激活环境
conda activate yolov8
</code></pre> 
</div> 
<h4 id="2.pip%E7%9A%84%E6%BA%90%E6%8D%A2%E5%88%B0%E5%9B%BD%E5%86%85aliyun%E9%95%9C%E5%83%8F%EF%BC%8C%E4%BC%9A%E6%8F%90%E9%AB%98%E4%B8%8B%E8%BD%BD%E9%80%9F%E5%BA%A6">2.pip的源换到国内aliyun镜像，会提高下载速度</h4> 
<div> 
 <pre><code class="language-python">pip config set install.trusted-host mirrors.aliyun.com
</code></pre> 
</div> 
<h4 id="3.%E5%AE%89%E8%A3%85%E4%B8%80%E4%B8%8Byolov8%E5%9C%A8python%3E%3D3.8%E7%89%88%E6%9C%AC%E5%BF%85%E8%A6%81%E5%AE%89%E8%A3%85%E5%8C%85%EF%BC%8C%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E5%B7%B2%E7%BB%8F%E5%86%85%E7%BD%AE%E5%85%B6%E4%B8%AD%EF%BC%9A">3.安装一下yolov8在python&gt;=3.8版本必要安装包，配置文件已经内置其中：</h4> 
<div> 
 <pre><code class="language-python">pip install ultralytics
</code></pre> 
</div> 
<h4 id="4.%E4%B8%8B%E8%BD%BD%E9%A2%84%E8%AE%AD%E7%BB%83%E6%9D%83%E9%87%8D%E6%A8%A1%E5%9E%8B%EF%BC%9A">4.下载预训练权重模型：</h4> 
<p><strong>（1）推荐<a class="link-info" href="https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8s.pt" title="yolov8s.pt">yolov8s.pt</a>或者<a class="link-info" href="https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt" title="yolov8n.pt">yolov8n.pt</a>，模型小，下载快（用梯子）</strong></p> 
<p><strong>（2）下载完成后，将模型放在ultralytics-main文件夹下</strong></p> 
<h4 id="5.%E6%A3%80%E9%AA%8C%E7%8E%AF%E5%A2%83%EF%BC%9A">5.检验环境：</h4> 
<p><strong>（1）在环境中打开项目ultralytics-main：</strong></p> 
<p><strong>       ① 在Anaconda Prompt中cd到ultralytics-main目录下</strong></p> 
<p><img alt="" height="245" src="https://images2.imgbox.com/8f/3b/j1UU5M7M_o.png" width="559"></p> 
<p><strong>       ② 在Pycharm终端直接打开</strong></p> 
<p><img alt="" height="364" src="https://images2.imgbox.com/1f/f1/DSCJdScI_o.png" width="877"></p> 
<p><strong>（2）运行以下指令：</strong></p> 
<div> 
 <pre><code class="language-python">yolo predict model=yolov8n.pt source='ultralytics/assets/bus.jpg'
</code></pre> 
</div> 
<p><strong>(3)若运行成功会在D:\ultralytics-main下生成\runs\detect\predict，且文件中会包含一张照片</strong></p> 
<p><img alt="" height="723" src="https://images2.imgbox.com/ff/4a/Q9qXCp0F_o.jpg" width="542">​</p> 
<h3 id="%E4%B8%89%E3%80%81%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B">三、训练模型</h3> 
<h4 id="%E3%80%90CPU%E3%80%91">【CPU】</h4> 
<h5 id="1.%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C%EF%BC%9A">1.准备工作：</h5> 
<p><strong>（1）在ultralytics-main目录下新建data文件夹；</strong></p> 
<p><strong>（2）再在data目录下新建四个文件夹:Annotations文件夹，images文件夹，ImageSets文件夹，labels文件夹</strong></p> 
<p><img alt="" height="257" src="https://images2.imgbox.com/1d/f1/rZDuUADq_o.png" width="416">​</p> 
<h5 id="2.%E5%87%86%E5%A4%87%E6%95%B0%E6%8D%AE%E9%9B%86%EF%BC%9A">2.准备数据集：</h5> 
<p><strong>（1）将准备好的图片以.jpg的格式放入images文件夹中</strong></p> 
<p><strong>（2）利用labelimg进行标注后将生成的.xml文件保存至Annotations文件夹中</strong></p> 
<h5 id="3.%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E5%88%92%E5%88%86%EF%BC%9A">3.数据集的划分：</h5> 
<p><strong>（1）在ultralytics-main目录下创建一个split_train_val.py文件；</strong></p> 
<p><strong>（2）运行文件之后会在imageSets文件夹下将数据集划分为训练集train.txt、验证集val.txt、测试集test.txt，里面存放的就是用于训练、验证、测试的图片名称，代码内容如下：</strong></p> 
<div> 
 <pre><code class="language-python">import os
import random
 
 
trainval_percent = 0.9
train_percent = 0.9
xmlfilepath = 'data/Annotations'
txtsavepath = 'data/ImageSets'
total_xml = os.listdir(xmlfilepath)
 
num = len(total_xml)
list = range(num)
tv = int(num * trainval_percent)
tr = int(tv * train_percent)
trainval = random.sample(list, tv)
train = random.sample(trainval, tr)
 
ftrainval = open('data/ImageSets/trainval.txt', 'w')
ftest = open('data/ImageSets/test.txt', 'w')
ftrain = open('data/ImageSets/train.txt', 'w')
fval = open('data/ImageSets/val.txt', 'w')
 
for i in list:
    name = total_xml[i][:-4] + '\n'
    if i in trainval:
        ftrainval.write(name)
        if i in train:
            ftrain.write(name)
        else:
            fval.write(name)
    else:
        ftest.write(name)
 
ftrainval.close()
ftrain.close()
fval.close()
ftest.close()
</code></pre> 
</div> 
<h5 id="4.%E8%BD%AC%E5%8C%96%E6%95%B0%E6%8D%AE%E9%9B%86%E6%A0%BC%E5%BC%8F%EF%BC%9A">4.转化数据集格式：</h5> 
<p><strong>（1）在ultralytics-main目录下创建一个voc_label.py文件</strong></p> 
<p><strong>（2）运行后会生成转换后labels文件夹下图片的txt文件，还会在data文件夹下得到三个包含数据集路径的txt文件，train.txt，test.txt，val.txt这3个txt文件为划分后图像所在位置的绝对路径</strong></p> 
<p><strong>（3）代码内容如下：</strong></p> 
<div> 
 <pre><code class="language-python">import xml.etree.ElementTree as ET
import os
from os import getcwd

sets = ['train', 'val', 'test']
classes = ['填写自己的类别']
abs_path = os.getcwd()
print(abs_path)


def convert(size, box):
    dw = 1. / (size[0])
    dh = 1. / (size[1])
    x = (box[0] + box[1]) / 2.0 - 1
    y = (box[2] + box[3]) / 2.0 - 1
    w = box[1] - box[0]
    h = box[3] - box[2]
    x = x * dw
    w = w * dw
    y = y * dh
    h = h * dh
    return x, y, w, h


def convert_annotation(image_id):
    in_file = open('data/Annotations/%s.xml' % (image_id), encoding='UTF-8')
    out_file = open('data/labels/%s.txt' % (image_id), 'w')
    tree = ET.parse(in_file)
    root = tree.getroot()
    size = root.find('size')
    w = int(size.find('width').text)
    h = int(size.find('height').text)
    for obj in root.iter('object'):
        # difficult = obj.find('difficult').text
        difficult = obj.find('difficult').text
        cls = obj.find('name').text
        if cls not in classes or int(difficult) == 1:
            continue
        cls_id = classes.index(cls)
        xmlbox = obj.find('bndbox')
        b = (float(xmlbox.find('xmin').text), float(xmlbox.find('xmax').text), float(xmlbox.find('ymin').text),
             float(xmlbox.find('ymax').text))
        b1, b2, b3, b4 = b
        # 标注越界修正
        if b2 &gt; w:
            b2 = w
        if b4 &gt; h:
            b4 = h
        b = (b1, b2, b3, b4)
        bb = convert((w, h), b)
        out_file.write(str(cls_id) + " " + " ".join([str(a) for a in bb]) + '\n')


wd = getcwd()
for image_set in sets:
    if not os.path.exists('data/labels/'):
        os.makedirs('data/labels/')
    image_ids = open('data/ImageSets/%s.txt' % (image_set)).read().strip().split()
    list_file = open('data/%s.txt' % (image_set), 'w')
    for image_id in image_ids:
        list_file.write(abs_path + '/data/images/%s.jpg\n' % (image_id))
        convert_annotation(image_id)
    list_file.close()
</code></pre> 
</div> 
<h5 id="5.%E7%BC%96%E5%86%99%E6%95%B0%E6%8D%AE%E9%9B%86%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%EF%BC%9A">5.编写数据集配置文件：</h5> 
<p><strong>在ultralytics-main目录下创建 wheat.yaml，代码内容如下：</strong></p> 
<div> 
 <pre><code class="language-python">train: D:/ultralytics-main/data/train.txt
val: D:/ultralytics-main/data/val.txt
test: D:/ultralytics-main/data/test.txt

nc: 5 # 填写类别数

names: ["填写自己的类别"]  # 要和voc_label.py中的类别数目顺序一模一样

# train,val,test的路径根据自己情况而定</code></pre> 
</div> 
<h5 id="6.%E4%B8%8B%E8%BD%BDCPU%E7%89%88pytorch%EF%BC%9A">6.下载CPU版pytorch：</h5> 
<p><strong>（1）具体网站（用梯子）：</strong><a href="https://pytorch.org/get-started/previous-versions/" rel="nofollow" title="Previous PyTorch Versions | PyTorch">Previous PyTorch Versions | PyTorch</a> <strong>选择找到与cpu相关的pip指令，例如：</strong><br><img alt="" height="350" src="https://images2.imgbox.com/52/24/Nvfg7QYm_o.png" width="1200"></p> 
<p><strong>（2）在conda创建的yolov8环境中输入找到的pip指令，等待下载完成即可</strong></p> 
<h5 id="7.%E5%91%BD%E4%BB%A4%E8%A1%8C%E8%BF%90%E8%A1%8C%EF%BC%9A">7.命令行运行：</h5> 
<p><strong>（1）同样先在环境中打开项目ultralytics-main（参考二、5.(1)）</strong></p> 
<p><strong>（2）运行训练指令：</strong></p> 
<pre><code class="language-python">yolo train data=wheat.yaml model=yolov8s.pt epochs=300 imgsz=640 batch=8 workers=0 device=cpu</code></pre> 
<div></div> 
<blockquote> 
 <p><strong>data为yaml配置文件，后边填写你的配置文件的相对/绝对路径<br> model为下载的预训练模型，在主文件下<br> epochs为训练轮数<br> imagez为训练时ai看到的图片大小，检查大图片建议使用640，小图片可以320 越大越吃性能<br> batch为一轮训练中每一次放入图片数量，越大越快效果越好，但是对性能要求越高<br> device为使用的设备，使用cpu练就写cpu，使用显卡大多数都是0，多显卡就0,1,2...多少显卡往后写多少 </strong></p> 
</blockquote> 
<h4 id="%E3%80%90GPU%E3%80%91">【GPU】</h4> 
<h5 id="1.%E6%A3%80%E6%9F%A5%E8%87%AA%E5%B7%B1%E7%94%B5%E8%84%91%E7%9A%84CUDA%E7%89%88%E6%9C%AC%EF%BC%9A">1.检查自己电脑的CUDA版本：</h5> 
<p><strong>（1）点击键盘 win + i ，输入cmd，敲击回车</strong></p> 
<p><strong>（2）输入以下指令：</strong> </p> 
<blockquote> 
 <p>nvidia-smi</p> 
</blockquote> 
<p><strong>（3）显示出以下内容说明系统已安装CUDA：</strong></p> 
<p><img alt="" height="509" src="https://images2.imgbox.com/aa/8c/yxYmJjjl_o.png" width="1111">​   <strong>      eg：若未显示此界面，则去<a class="link-info" href="https://developer.nvidia.com/cuda-toolkit-archive" rel="nofollow" title="CUDA官网">CUDA官网</a>下载与系统兼容版本</strong> </p> 
<h5 id="2.%E4%B8%8B%E8%BD%BDpytorch%EF%BC%9A"><strong>2.下载pytorch：</strong></h5> 
<p><strong>（1）只能<span style="color:#fe2c24;">下载 &lt;= CUDA Version</span>的pytorch版本，这里我们选择找到pip相关指令</strong></p> 
<p><strong>（2）具体网站：（用梯子）</strong><a href="https://pytorch.org/get-started/previous-versions/" rel="nofollow" title="Previous PyTorch Versions | PyTorch">Previous PyTorch Versions | PyTorch</a></p> 
<p><strong>（3） 在conda创建的yolov8环境中输入找到的pip指令，等待下载完成即可</strong></p> 
<h5><strong>3.下载torch的gpu版本：</strong></h5> 
<p><strong>（1）在环境中打开项目ultralytics-main（参考二、5.(1)）</strong></p> 
<p><strong>（2）输入指令查看torch是否为gpu版本：</strong></p> 
<pre><code class="language-python">pip list</code></pre> 
<p>如下图， torch那行对应的torch版本，例如这样就是cpu版本，需要去下载相关torch的gpu版本</p> 
<p><img alt="" height="291" src="https://images2.imgbox.com/0c/e0/GaEsYHYe_o.png" width="472"></p> 
<p><strong>（3）打开网址：</strong><a class="has-card" href="http://download.pytorch.org/whl/torch_stable.html" rel="nofollow" title="http://download.pytorch.org/whl/torch_stable.html"><span class="link-card-box"><span class="link-title">http://download.pytorch.org/whl/torch_stable.html</span><span class="link-link"><img class="link-link-icon" src="https://images2.imgbox.com/78/ba/IVohQb4j_o.png" alt="icon-default.png?t=N7T8">http://download.pytorch.org/whl/torch_stable.html</span></span></a></p> 
<p>        <img alt="" height="166" src="https://images2.imgbox.com/9d/77/OZgdC6sU_o.png" width="416"></p> 
<blockquote> 
 <p><strong>       </strong> <strong>cu121/</strong>表示你在教程【GPU】1.当中官网上下载的cuda版本</p> 
 <p>        <strong>torch-2.2.2%2Bcu121/</strong>表示刚才在pip list中查看的torch的版本</p> 
 <p>        <strong>cp312-cp312</strong>表示你yolov8的环境python版本，如果按我的教程来的话为3.9</p> 
 <p>       <strong> win-amd64.whl</strong>简而言之就是windows系统</p> 
</blockquote> 
<p>① 按照上述要求找到你需要的下载链接点进去</p> 
<p>② 在D盘新建一个文件夹D:\torch_gpu，保存在其中</p> 
<p>③ 在项目环境中输入指令：（后面的路径为你whl所保存的位置）</p> 
<pre><code class="language-python">pip install D:\torch_gpu\torch-2.2.2+cu121-cp39-cp39-win_amd64.whl</code></pre> 
<p><strong>（4）检验是否安装成功：</strong></p> 
<p> ① 在环境中打开项目ultralytics-main（参考二、5.(1)）</p> 
<p>② 输入指令：</p> 
<pre><code class="language-python">pip list</code></pre> 
<p> <img alt="" height="278" src="https://images2.imgbox.com/8f/04/kPKSVsLZ_o.png" width="439"></p> 
<p>--------------------------------出现+cu+你的cuda版本型号即为<strong><span style="color:#38d8f0;">安装成功</span></strong>---------------------------------------- </p> 
<h5 id="3.%20%E8%BF%90%E8%A1%8C%E5%91%BD%E4%BB%A4%E8%A1%8C%EF%BC%9A"><strong>4. 运行训练命令：</strong></h5> 
<p><strong>（1）参考【CPU】1--5 </strong></p> 
<p><strong>（2） 同样先在环境中打开项目ultralytics-main（参考二、5.(1)）</strong></p> 
<p><strong>（3）</strong><strong>运行以下指令：</strong></p> 
<pre><code class="language-python">yolo train data=wheat.yaml model=yolov8s.pt epochs=300 imgsz=640 batch=8 workers=0 device=0</code></pre> 
<blockquote> 
 <p><strong>data</strong>为yaml配置文件，后边填写你的配置文件的相对/绝对路径<br><strong>model</strong>为下载的预训练模型，在主文件下<br><strong>epochs</strong>为训练轮数<br><strong>imagez</strong>为训练时ai看到的图片大小，检查大图片建议使用640，小图片可以320 越大越吃性能<br><strong>batch</strong>为一轮训练中每一次放入图片数量，越大越快效果越好，但是对性能要求越高<br><strong>device</strong>为使用的设备，使用cpu练就写cpu，gpu使用显卡大多数都是0，多显卡就0,1,2,3,...多少显卡往后写多少</p> 
</blockquote> 
<h3 id="%C2%A0%E5%9B%9B%E3%80%81%E8%BF%87%E7%A8%8B%E7%BB%86%E8%8A%82"> 四、过程细节</h3> 
<h4 id="1.%E6%9C%80%E7%BB%88%C2%A0ultralytics-main%20%E7%9B%AE%E5%BD%95%E4%B8%8B%E6%95%B4%E4%BD%93%E6%83%85%E5%86%B5%E5%A6%82%E4%B8%8B%EF%BC%9A">1.最终 ultralytics-main 目录下整体情况如下：</h4> 
<p><img alt="" class="left" height="441" src="https://images2.imgbox.com/a5/84/X4DxIGcL_o.png" width="272"><img alt="" class="left" height="367" src="https://images2.imgbox.com/cd/b4/0N5vneP4_o.png" width="326"></p> 
<p><strong>eg ：红色框内部分为自己添加的部分，runs文件夹的生成参考二、6.(3)</strong></p> 
<h4 id="2.%20%E4%BD%BF%E7%94%A8labelimg%E6%A0%87%E6%B3%A8%E6%95%B0%E6%8D%AE%E9%9B%86%E8%BD%AC.xml%E6%A0%BC%E5%BC%8F">2. 使用labelimg标注数据集转.xml格式</h4> 
<h5 id="%EF%BC%881%EF%BC%89%E5%AE%89%E8%A3%85%E5%B9%B6%E6%89%93%E5%BC%80labelimg">（1）安装并打开labelimg</h5> 
<p><strong>① 在conda创建新环境labelimg，指令如下：</strong></p> 
<pre><code class="language-python">conda create -n labelimg  python=3.9
</code></pre> 
<p><strong> ② 激活lalelimg环境，指令如下：</strong></p> 
<pre><code class="language-python">conda activate labelimg
</code></pre> 
<p><strong>③ 在此环境下安装labelimg，指令可如下：</strong></p> 
<pre><code class="language-python">pip install labelimg -i https://pypi.tuna.tsinghua.edu.cn/simple  #不推荐，会出现依赖缺失或者版本不匹配问题 
 
pip install labelimg  #推荐用此方法安装
</code></pre> 
<p>  <strong>      eg：以一种方式安装即可</strong></p> 
<p><strong>④ 打开labelimg，指令如下：</strong></p> 
<pre><code class="language-python">labelimg
</code></pre> 
<h5 id="%EF%BC%882%EF%BC%89%E4%BD%BF%E7%94%A8labelimg">（2）使用labelimg</h5> 
<p><strong>① 打开labelimg：</strong></p> 
<p><img alt="" height="168" src="https://images2.imgbox.com/d4/f6/0q2XbJbJ_o.png" width="507"></p> 
<p><strong>② 使用介绍：</strong></p> 
<p><img alt="" height="435" src="https://images2.imgbox.com/e3/de/MRTUMX6P_o.png" width="663"></p> 
<p><img alt="" height="485" src="https://images2.imgbox.com/3c/e6/HGd7yyBg_o.png" width="647"></p> 
<p><strong>③ 与三、3.数据集划分相关步骤：</strong></p> 
<p>Ⅰ选择PascalVOC(即.xml格式)</p> 
<p>Ⅱ 点击Open Dir打开文件夹D:\ultralytics-main\data\images中的.jpg格式的图片</p> 
<p>Ⅲ Change Save Dir选择文件夹D:\ultralytics-main\data\Annotations</p> 
<p>Ⅳ 打好标签以后若先前勾选View-Auto Save mode选项即可自动保存</p> 
<p><img alt="" height="402" src="https://images2.imgbox.com/48/f1/Z6UpBKTA_o.png" width="601"></p> 
<h4 id="3.Pycharm%E9%A1%B9%E7%9B%AE%E8%A7%A3%E9%87%8A%E5%99%A8%E7%9A%84%E9%80%89%E6%8B%A9%C2%A0">3.Pycharm项目解释器的选择 </h4> 
<p>我使用的是Pycham2024.1版本，截止2024.4最新版本，解释器选择的conda环境，如下</p> 
<h4 id="%E2%80%8B%E7%BC%96%E8%BE%91%E5%A6%82%E4%BD%95%E5%8A%A0%E8%BD%BDconda%E7%8E%AF%E5%A2%83%20%EF%BC%9F"><img alt="" height="919" src="https://images2.imgbox.com/cc/66/pVk5JCNi_o.png" width="1200">如何加载conda环境 ？</h4> 
<blockquote> 
 <p><strong>找到Anaconda目录下的\Library\bin\conda.bat，然后加载环境选择yolov8即可，如下</strong></p> 
</blockquote> 
<p><img alt="" height="280" src="https://images2.imgbox.com/67/20/DFH3lqHD_o.png" width="1066"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/3b746a8d122b521b343024b350badefc/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">设计模式大白话之适配器模式</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/6d9e4b4b99d60e39890c15ee8a67816f/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">前端Axios搭配Vue（认清Axios，Axios结合Vue发出Ajax请求，返回JSON数据案例！简洁易懂。）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>