<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>bert-base-chinese模型的完整训练、推理和一些思考 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/f7489a613860331ba1f1f552b1e4ea2e/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="bert-base-chinese模型的完整训练、推理和一些思考">
  <meta property="og:description" content="前言 使用google-bert/bert-base-chinese模型进行中文文本分类任务，使用THUCNews中文数据集进行训练，训练完成后，可以导出模型，进行预测。
项目详细介绍和数据下载 数据集下载地址
Github完整代码
现记录训练过程中的一些感悟 1、训练时遇到的两个核心参数warmup_steps和weight_decay 代码片段如下
需要弄明白一些基础概念
epoch：指模型在训练过程中遍历完整个训练数据集一次。
step：指模型在训练过程中处理完一个batch的数据并完成一次梯度更新。
batch_size： 指在一次step中模型用于训练的数据量。
假设 训练数据集有 n 个样本，每个epoch的step计算方式
s t e p = n b a t c h _ s i z e step = \frac{n}{batch\_size} step=batch_sizen​
训练过程的总步数为
s t e p s = s t e p × n u m _ t r a i n _ e p o c h s steps = step \times num\_train\_epochs steps=step×num_train_epochs">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-08-13T15:22:09+08:00">
    <meta property="article:modified_time" content="2024-08-13T15:22:09+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">bert-base-chinese模型的完整训练、推理和一些思考</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h4><a id="_0"></a>前言</h4> 
<p>使用<code>google-bert/bert-base-chinese</code>模型进行中文文本分类任务，使用THUCNews中文数据集进行训练，训练完成后，可以导出模型，进行预测。</p> 
<h4><a id="_3"></a>项目详细介绍和数据下载</h4> 
<p><a href="http://thuctc.thunlp.org/" rel="nofollow">数据集下载地址</a></p> 
<p><a href="https://github.com/hgsw/classification-base-bert.git">Github完整代码</a></p> 
<h4><a id="_8"></a>现记录训练过程中的一些感悟</h4> 
<h4><a id="1warmup_stepsweight_decay_10"></a>1、训练时遇到的两个核心参数<code>warmup_steps</code>和<code>weight_decay</code></h4> 
<p>代码片段如下<br> <img src="https://images2.imgbox.com/8e/09/Ci5kxiH0_o.png" alt="在这里插入图片描述" width="80%"></p> 
<p>需要弄明白一些基础概念</p> 
<p>epoch：指模型在训练过程中遍历完整个训练数据集一次。</p> 
<p>step：指模型在训练过程中处理完一个batch的数据并完成一次梯度更新。</p> 
<p>batch_size： 指在一次step中模型用于训练的数据量。</p> 
<p>假设 训练数据集有 n 个样本，每个epoch的step计算方式<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          s 
         
        
          t 
         
        
          e 
         
        
          p 
         
        
          = 
         
         
         
           n 
          
          
          
            b 
           
          
            a 
           
          
            t 
           
          
            c 
           
          
            h 
           
          
            _ 
           
          
            s 
           
          
            i 
           
          
            z 
           
          
            e 
           
          
         
        
       
         step = \frac{n}{batch\_size} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8095em; vertical-align: -0.1944em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 2.1036em; vertical-align: -0.996em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.1076em;"><span class="" style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathnormal">ba</span><span class="mord mathnormal">t</span><span class="mord mathnormal">c</span><span class="mord mathnormal">h</span><span style="margin-right: 0.0278em;" class="mord">_</span><span class="mord mathnormal">s</span><span class="mord mathnormal">i</span><span class="mord mathnormal">ze</span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathnormal">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.996em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></span><br> 训练过程的总步数为<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          s 
         
        
          t 
         
        
          e 
         
        
          p 
         
        
          s 
         
        
          = 
         
        
          s 
         
        
          t 
         
        
          e 
         
        
          p 
         
        
          × 
         
        
          n 
         
        
          u 
         
        
          m 
         
        
          _ 
         
        
          t 
         
        
          r 
         
        
          a 
         
        
          i 
         
        
          n 
         
        
          _ 
         
        
          e 
         
        
          p 
         
        
          o 
         
        
          c 
         
        
          h 
         
        
          s 
         
        
       
         steps = step \times num\_train\_epochs 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8095em; vertical-align: -0.1944em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">p</span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.8095em; vertical-align: -0.1944em;"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1.0044em; vertical-align: -0.31em;"></span><span class="mord mathnormal">n</span><span class="mord mathnormal">u</span><span class="mord mathnormal">m</span><span style="margin-right: 0.0278em;" class="mord">_</span><span class="mord mathnormal">t</span><span style="margin-right: 0.0278em;" class="mord mathnormal">r</span><span class="mord mathnormal">ain</span><span style="margin-right: 0.0278em;" class="mord">_</span><span class="mord mathnormal">e</span><span class="mord mathnormal">p</span><span class="mord mathnormal">oc</span><span class="mord mathnormal">h</span><span class="mord mathnormal">s</span></span></span></span></span></span></p> 
<p><code>warmup_steps</code>：主要目的是为了平稳地提升学习率，让模型在训练初期不会因为太高的学习率而跳过或远离全局最优解。</p> 
<p><em>常见做法是将其设置为总训练步数的5%到10%的值。</em></p> 
<p>此训练过程中warmup steps下限的计算方式如下，训练数据18w<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          w 
         
        
          a 
         
        
          r 
         
        
          m 
         
        
          u 
         
        
          p 
         
        
          _ 
         
        
          s 
         
        
          t 
         
        
          e 
         
        
          p 
         
        
          s 
         
        
          = 
         
         
         
           180000 
          
         
           32 
          
         
        
          × 
         
        
          5 
         
        
          × 
         
        
          5 
         
        
          % 
         
        
          = 
         
        
          1406 
         
        
       
         warmup\_steps = \frac{180000}{32} \times 5 \times 5\% = 1406 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.9251em; vertical-align: -0.31em;"></span><span style="margin-right: 0.0269em;" class="mord mathnormal">w</span><span class="mord mathnormal">a</span><span style="margin-right: 0.0278em;" class="mord mathnormal">r</span><span class="mord mathnormal">m</span><span class="mord mathnormal">u</span><span class="mord mathnormal">p</span><span style="margin-right: 0.0278em;" class="mord">_</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal">e</span><span class="mord mathnormal">p</span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 2.0074em; vertical-align: -0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.3214em;"><span class="" style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">32</span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">180000</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.686em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.7278em; vertical-align: -0.0833em;"></span><span class="mord">5</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.8056em; vertical-align: -0.0556em;"></span><span class="mord">5%</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">1406</span></span></span></span></span></span></p> 
<p>减少 warmup_steps 可能会导致模型更快地达到较高的学习率，从而错过或远离全局最优解。</p> 
<p><code>weight_decay</code>：是用于正则化模型权重的，实际上是 L2 正则化的一种形式</p> 
<p>weight_decay的作用是在损失函数中添加一个惩罚项，该惩罚项与权重的平方成正比，这有助于抑制权重的大小，从而防止模型过拟合</p> 
<p>weight_decay设置得过低，可能不足以防止过拟合；设置得过高，则可能导致模型欠拟合，即模型过于简单，无法很好地捕捉数据中的模式</p> 
<h4><a id="2tensorboard_logdirlogs_50"></a>2、通过<code>tensorboard --logdir=./logs</code>可视化训练过程</h4> 
<p>训练过程截图如下：</p> 
<p>2.1、训练阶段</p> 
<p>可以明显的看到训练时的学习率先逐渐上升之后在下降，这是我们想要的趋势。训练的损失值逐步下降，这也是我们希望的。但是当我们在分析评估数据数据集的损失时，我们会发现此时模型应该是过拟合了。</p> 
<p><img src="https://images2.imgbox.com/44/1e/59KDDLAZ_o.png" alt="在这里插入图片描述"></p> 
<p>2.2、推理阶段</p> 
<p>随着训练过程的增加，模型在评估数据集上的损失也是逐步减少，当在step=11250时，评估数据集上的损失开始逐渐增加，而训练数据的损失还在减少，那么可以肯定模型已经过拟合了。</p> 
<p><strong>模型已经充分的挖掘训练数据集中的语义特征，过分的学习到数据中的一些细枝末节</strong>。从而在新数据集上的表现越来越差。这种在训练数据集上表现优秀，在评估或测试数据集上表现较差现象，即模型出现了过拟合。</p> 
<p><img src="https://images2.imgbox.com/52/ce/UgqJBu7C_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="3_69"></a>3、模型混淆矩阵的分析</h4> 
<p>混淆矩阵结果如下<br> <img src="https://images2.imgbox.com/39/cc/J4iCpm35_o.png" alt="在这里插入图片描述" width="87%"><br> 指标如下</p> 
<table><thead><tr><th>Accuracy</th><th>0.9434</th></tr></thead><tbody><tr><td>Precision</td><td>0.9438</td></tr><tr><td>Recall</td><td>0.9434</td></tr></tbody></table> 
<p>具体多分类任务指标和混淆矩阵分析<a href="https://blog.csdn.net/weixin_42924890/article/details/135561264">参考这里</a>非常详细。</p> 
<h4><a id="4_83"></a>4、如何解决模型过拟合的现象</h4> 
<p>【待更新】疯狂参数调节优化中…</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/947d9cfb279bb601524244badb531b6f/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">EasyExcel-高性能的 Java Excel 处理库</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/0ef5d02551491545d553bd5c1520bb84/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【区块链&#43;食品安全】湖南省食品行业联合会：溯链中国—基于区块链的食品安全可信追溯平台 | FISCO BCOS应用案例</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>