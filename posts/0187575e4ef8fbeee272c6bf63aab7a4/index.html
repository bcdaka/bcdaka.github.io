<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【多视图聚类】Reconsidering Representation Alignment for Multi-view Clustering - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/0187575e4ef8fbeee272c6bf63aab7a4/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="【多视图聚类】Reconsidering Representation Alignment for Multi-view Clustering">
  <meta property="og:description" content="Reconsidering Representation Alignment for Multi-view Clustering
CVPR 2021
0.论文摘要和信息 摘要 对齐视图表示的分布是当今用于深度多视图聚类的最先进模型的核心组件。然而，我们发现了nävely对齐表示分布的几个缺点。我们证明了这些缺点既导致表示空间中可分离的聚类更少，又抑制了模型对视图进行优先排序的能力。基于这些观察，我们开发了一个简单的深度多视图聚类基线模型。我们的基线模型完全避免了表示对齐，同时表现类似于或优于当前技术水平。我们还通过添加对比学习组件来扩展我们的基线模型。这引入了选择性对齐过程，保留了模型对视图进行优先排序的能力。我们的实验表明，对比学习组件增强了基线模型，在几个数据集上比当前的技术水平有了很大的提高。
作者信息 Daniel J. Trosten Sigurd Løkse Robert Jenssen Michael Kampffmeyer
代码地址 SiMVC&amp;CoMVC
1.引言 从不同的角度或通过使用不同传感器的集合来收集几种真实世界的数据。例如，视频包含视觉和听觉成分，而带字幕的图像包括原始图像数据和描述性文本。在这两个示例中，视图的低级内容差异很大，但它们仍然可以携带相同的高级聚类结构。多视图聚类的目标是通过同时从所有可用视图中学习来发现这种公共聚类结构。
同时从多个来源学习不是一件小事[6]。然而，深度学习的引入[33]导致了几种有前途的深度多视图聚类模型的发展[1, 36, 48, 61, 64]。这些模型通过用特定于视图的编码器网络变换每个视图来有效地从多个视图中学习。所得到的表示被融合以获得公共表示对于所有视图，然后可以由后续聚类模块对其进行聚类。
深度多视图聚类的当前技术状态使用对抗性训练来对齐来自不同视图的表示分布[36, 64]。
对齐分布导致视图不变表示，这有利于随后的视图融合和聚类模块[64]。视图不变表示保留所有视图中存在的信息，同时丢弃仅存在于视图子集中的信息。如果视图特定信息与聚类目标无关，则编码器学会去除它对于聚类模块将是有利的。此外，对齐表示分布引入了一个辅助任务，该任务正则化编码器，并有助于保持输入空间的局部几何结构。这已被证明可以改进单视图深度聚类模型[21]。
然而，尽管有这些优点，我们发现多视图聚类的分布对齐的三个重要缺点：
对齐表示可防止表示空间中的视图优先化。视图对于聚类目标不一定同样重要。因此，模型应该能够基于视图表示中包含的信息自适应地确定视图的优先级。然而，通过使这些分布尽可能相似，对齐表示分布使得模型更难确定表示空间中的视图的优先级。
只有当编码器可以在所有视图中分离所有聚类时，才能实现聚类的一对一对齐。当聚类结构仅部分地存在于各个视图中时，对齐导致聚类在表示空间中合并在一起。这使得后续聚类模块的聚类任务更加困难。
对齐表示分布会使区分聚类变得更加困难。由于对抗性对齐仅考虑表示分布，因此来自一个视图的给定聚类可能与来自另一个视图的不同聚类对齐。标签分布的这种错位已被证明对表示空间中的判别模型有负面影响[62]。
用于多模态聚类的端到端对抗性注意力网络（EAMC）[64]代表了深度多视图聚类的当前技术水平。EAMC通过优化编码器网络上的对抗目标来对齐视图表示。所得表示与加权平均值融合，权重通过将表示传递通过注意力网络而产生。根据我们上面的推理，我们假设对抗性模块完成的对齐可能会挫败注意力机制的目的。从而抑制视图优先化，并导致融合后较少的可分离聚类。我们的假设得到了EAMC[64]的经验结果的支持，其中所有数据集的融合权重接近均匀。相等的融合权重使得所有视图对融合表示的贡献相等，而不管它们的内容如何。此外，注意力网络产生的融合权重取决于当前批次内的所有样本。因此，如果不对注意力机制进行额外的修改，EAMC就不可能进行样本外推理。
在这项工作中，我们试图缓解在深度多视图聚类中对齐表示分布时可能出现的问题。为此，我们做出以下关键贡献：
•我们强调了在深度多视图聚类中对齐表示分布的陷阱，并表明这些陷阱限制了现有技术的模型。
•我们提出了简单多视图聚类（SiMVC），这是一种用于深度多视图聚类的新的简单基线模型，没有任何形式的对齐。尽管与现有方法相比它很简单，但我们的实验表明，这种基线模型的性能类似于——在某些情况下，甚至优于——当前最先进的方法。SiMVC使用学习的线性组合来组合视图的表示，这是一种简单但有效的视图优先级排序机制。我们从经验上证明了这种机制允许模型抑制无信息视图并强调对聚类目标重要的视图。
•为了利用对齐的优势——即保留局部几何结构和视图不变性——同时避免陷阱，我们将选择性对比对齐模块附加到SiMVC。对比模块在样本水平对齐表示之间的角度，避免了标签分布未对齐的问题。此外，在一对一对齐不可能的情况下，我们使模型能够忽略对比目标，保留模型对视图进行优先排序的能力。我们将这种模型称为对比多视图聚类（CoMVC）。
2.多视图聚类中分布对齐的陷阱 这里，我们考虑多视图聚类问题的理想化版本。这允许我们研究和形式化我们对多视图聚类中表示分布对齐的观察。通过假设对于每个视图，聚类中的所有样本都位于输入空间中的同一点，我们开发了以下命题：
Proposition 1 命题1。假设我们的数据集由 V V V个视图和 k k k个地面实况聚类组成，我们希望根据这个地面实况聚类来聚类数据。此外，我们作出以下假设：
1.对于每个视图，属于相同地面真实簇的所有观察位于输入空间中的同一点。
2.对于给定的视图 v v v， v ∈ { 1 , . . . , V } v ∈ \{1, .">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-08-29T11:05:39+08:00">
    <meta property="article:modified_time" content="2024-08-29T11:05:39+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【多视图聚类】Reconsidering Representation Alignment for Multi-view Clustering</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>Reconsidering Representation Alignment for Multi-view Clustering<br> CVPR 2021<br> <img src="https://images2.imgbox.com/85/ed/22X2TkGT_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="0_4"></a>0.论文摘要和信息</h2> 
<h3><a id="_5"></a>摘要</h3> 
<p>对齐视图表示的分布是当今用于深度多视图聚类的最先进模型的核心组件。然而，我们发现了nävely对齐表示分布的几个缺点。我们证明了这些缺点既导致表示空间中可分离的聚类更少，又抑制了模型对视图进行优先排序的能力。基于这些观察，我们开发了一个简单的深度多视图聚类基线模型。我们的基线模型完全避免了表示对齐，同时表现类似于或优于当前技术水平。我们还通过添加对比学习组件来扩展我们的基线模型。这引入了选择性对齐过程，保留了模型对视图进行优先排序的能力。我们的实验表明，对比学习组件增强了基线模型，在几个数据集上比当前的技术水平有了很大的提高。</p> 
<h3><a id="_8"></a>作者信息</h3> 
<p>Daniel J. Trosten Sigurd Løkse Robert Jenssen Michael Kampffmeyer</p> 
<h3><a id="_11"></a>代码地址</h3> 
<p><a href="https://github.com/DanielTrosten/mvc">SiMVC&amp;CoMVC</a></p> 
<h2><a id="1_14"></a>1.引言</h2> 
<p>从不同的角度或通过使用不同传感器的集合来收集几种真实世界的数据。例如，视频包含视觉和听觉成分，而带字幕的图像包括原始图像数据和描述性文本。在这两个示例中，视图的低级内容差异很大，但它们仍然可以携带相同的高级聚类结构。多视图聚类的目标是通过同时从所有可用视图中学习来发现这种公共聚类结构。</p> 
<p>同时从多个来源学习不是一件小事[6]。然而，深度学习的引入[33]导致了几种有前途的深度多视图聚类模型的发展[1, 36, 48, 61, 64]。这些模型通过用特定于视图的编码器网络变换每个视图来有效地从多个视图中学习。所得到的表示被融合以获得公共表示对于所有视图，然后可以由后续聚类模块对其进行聚类。</p> 
<p>深度多视图聚类的当前技术状态使用对抗性训练来对齐来自不同视图的表示分布[36, 64]。</p> 
<p>对齐分布导致视图不变表示，这有利于随后的视图融合和聚类模块[64]。视图不变表示保留所有视图中存在的信息，同时丢弃仅存在于视图子集中的信息。如果视图特定信息与聚类目标无关，则编码器学会去除它对于聚类模块将是有利的。此外，对齐表示分布引入了一个辅助任务，该任务正则化编码器，并有助于保持输入空间的局部几何结构。这已被证明可以改进单视图深度聚类模型[21]。</p> 
<p>然而，尽管有这些优点，我们发现多视图聚类的分布对齐的三个重要缺点：<br> 对齐表示可防止表示空间中的视图优先化。视图对于聚类目标不一定同样重要。因此，模型应该能够基于视图表示中包含的信息自适应地确定视图的优先级。然而，通过使这些分布尽可能相似，对齐表示分布使得模型更难确定表示空间中的视图的优先级。</p> 
<p>只有当编码器可以在所有视图中分离所有聚类时，才能实现聚类的一对一对齐。当聚类结构仅部分地存在于各个视图中时，对齐导致聚类在表示空间中合并在一起。这使得后续聚类模块的聚类任务更加困难。</p> 
<p>对齐表示分布会使区分聚类变得更加困难。由于对抗性对齐仅考虑表示分布，因此来自一个视图的给定聚类可能与来自另一个视图的不同聚类对齐。标签分布的这种错位已被证明对表示空间中的判别模型有负面影响[62]。</p> 
<p>用于多模态聚类的端到端对抗性注意力网络（EAMC）[64]代表了深度多视图聚类的当前技术水平。EAMC通过优化编码器网络上的对抗目标来对齐视图表示。所得表示与加权平均值融合，权重通过将表示传递通过注意力网络而产生。根据我们上面的推理，我们假设对抗性模块完成的对齐可能会挫败注意力机制的目的。从而抑制视图优先化，并导致融合后较少的可分离聚类。我们的假设得到了EAMC[64]的经验结果的支持，其中所有数据集的融合权重接近均匀。相等的融合权重使得所有视图对融合表示的贡献相等，而不管它们的内容如何。此外，注意力网络产生的融合权重取决于当前批次内的所有样本。因此，如果不对注意力机制进行额外的修改，EAMC就不可能进行样本外推理。</p> 
<p>在这项工作中，我们试图缓解在深度多视图聚类中对齐表示分布时可能出现的问题。为此，我们做出以下关键贡献：<br> •我们强调了在深度多视图聚类中对齐表示分布的陷阱，并表明这些陷阱限制了现有技术的模型。<br> •我们提出了简单多视图聚类（SiMVC），这是一种用于深度多视图聚类的新的简单基线模型，没有任何形式的对齐。尽管与现有方法相比它很简单，但我们的实验表明，这种基线模型的性能类似于——在某些情况下，甚至优于——当前最先进的方法。SiMVC使用学习的线性组合来组合视图的表示，这是一种简单但有效的视图优先级排序机制。我们从经验上证明了这种机制允许模型抑制无信息视图并强调对聚类目标重要的视图。<br> •为了利用对齐的优势——即保留局部几何结构和视图不变性——同时避免陷阱，我们将选择性对比对齐模块附加到SiMVC。对比模块在样本水平对齐表示之间的角度，避免了标签分布未对齐的问题。此外，在一对一对齐不可能的情况下，我们使模型能够忽略对比目标，保留模型对视图进行优先排序的能力。我们将这种模型称为对比多视图聚类（CoMVC）。</p> 
<h2><a id="2_37"></a>2.多视图聚类中分布对齐的陷阱</h2> 
<p>这里，我们考虑多视图聚类问题的理想化版本。这允许我们研究和形式化我们对多视图聚类中表示分布对齐的观察。通过假设对于每个视图，聚类中的所有样本都位于输入空间中的同一点，我们开发了以下命题：</p> 
<h4><a id="Proposition_1_40"></a>Proposition 1</h4> 
<p>命题1。假设我们的数据集由<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         V 
        
       
      
        V 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord mathnormal" style="margin-right: 0.2222em;">V</span></span></span></span></span>个视图和<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         k 
        
       
      
        k 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord mathnormal" style="margin-right: 0.0315em;">k</span></span></span></span></span>个地面实况聚类组成，我们希望根据这个地面实况聚类来聚类数据。此外，我们作出以下假设：<br> 1.对于每个视图，属于相同地面真实簇的所有观察位于输入空间中的同一点。<br> 2.对于给定的视图<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         v 
        
       
      
        v 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal" style="margin-right: 0.0359em;">v</span></span></span></span></span>，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         v 
        
       
         ∈ 
        
       
         { 
        
       
         1 
        
       
         , 
        
       
         . 
        
       
         . 
        
       
         . 
        
       
         , 
        
       
         V 
        
       
         } 
        
       
      
        v ∈ \{1, . . . , V \} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5782em; vertical-align: -0.0391em;"></span><span class="mord mathnormal" style="margin-right: 0.0359em;">v</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">{<!-- --></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal" style="margin-right: 0.2222em;">V</span><span class="mclose">}</span></span></span></span></span>，输入空间中唯一点（即不同/可分离簇）的数量为<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          k 
         
        
          v 
         
        
       
      
        k_v 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0315em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.0315em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>。<br> 3.使用特定于视图的编码器将视图映射到表示，并且随后根据具有唯一权重的线性组合进行融合。</p> 
<p>则融合后唯一簇的最大个数为<br> <img src="https://images2.imgbox.com/42/63/WgmAwbeu_o.png" alt="在这里插入图片描述"></p> 
<p>如果来自不同视图的表示的分布完全对齐，并且<br> <img src="https://images2.imgbox.com/4a/70/DKUhtKuQ_o.png" alt="在这里插入图片描述"><br> 如果没有执行对齐。</p> 
<h3><a id="1_53"></a>命题1的含义</h3> 
<p>命题1中的<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          κ 
         
        
          . 
         
         
         
           f 
          
         
           u 
          
         
           s 
          
         
           e 
          
         
           d 
          
         
        
       
      
        κ^{fused}_. 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.0961em; vertical-align: -0.247em;"></span><span class="mord"><span class="mord mathnormal">κ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.8491em;"><span class="" style="top: -2.453em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">.</span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.1076em;">f</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">se</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.247em;"><span class=""></span></span></span></span></span></span></span></span></span></span>控制聚类模块能够聚类融合表示的程度。如果<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          κ 
         
        
          . 
         
         
         
           f 
          
         
           u 
          
         
           s 
          
         
           e 
          
         
           d 
          
         
        
       
         &lt; 
        
       
         k 
        
       
      
        κ^{fused}_. &lt; k 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.0961em; vertical-align: -0.247em;"></span><span class="mord"><span class="mord mathnormal">κ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.8491em;"><span class="" style="top: -2.453em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">.</span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.1076em;">f</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">se</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.247em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord mathnormal" style="margin-right: 0.0315em;">k</span></span></span></span></span>，则意味着融合后部分聚类位于同一点，使得聚类模块无法区分这些聚类。在其中一个视图将所有簇分组在一起的极端情况下（即<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          k 
         
        
          v 
         
        
       
         = 
        
       
         1 
        
       
      
        k_v = 1 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0315em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.0315em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">1</span></span></span></span></span>），则遵循<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          κ 
         
         
         
           a 
          
         
           l 
          
         
           i 
          
         
           g 
          
         
           n 
          
         
           e 
          
         
           d 
          
         
         
         
           f 
          
         
           u 
          
         
           s 
          
         
           e 
          
         
           d 
          
         
        
       
         = 
        
       
         1 
        
       
      
        κ^{fused}_{aligned} = 1 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.4044em; vertical-align: -0.4374em;"></span><span class="mord"><span class="mord mathnormal">κ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.967em;"><span class="" style="top: -2.3987em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right: 0.0197em;">l</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">g</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">d</span></span></span></span><span class="" style="top: -3.1809em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.1076em;">f</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">se</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.4374em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">1</span></span></span></span></span>。发生这种情况是因为所有其他视图都与无信息视图（<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          k 
         
        
          v 
         
        
       
         = 
        
       
         1 
        
       
      
        k_v = 1 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0315em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.0315em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">1</span></span></span></span></span>）对齐，从而使表示空间中的聚类结构折叠。因此，对齐防止了该视图的抑制，并且使得更难区分表示空间中的簇。</p> 
<p>然而，如果我们能够区分所有视图中的所有聚类，则对于所有视图，我们有<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          k 
         
        
          v 
         
        
       
         = 
        
       
         k 
        
       
      
        k_v = k 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0315em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.0315em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord mathnormal" style="margin-right: 0.0315em;">k</span></span></span></span></span>，导致<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          κ 
         
         
         
           a 
          
         
           l 
          
         
           i 
          
         
           g 
          
         
           n 
          
         
           e 
          
         
           d 
          
         
         
         
           f 
          
         
           u 
          
         
           s 
          
         
           e 
          
         
           d 
          
         
        
       
         = 
        
        
        
          κ 
         
         
         
           n 
          
         
           o 
          
         
           t 
           
         
           a 
          
         
           l 
          
         
           i 
          
         
           g 
          
         
           n 
          
         
           e 
          
         
           d 
          
         
         
         
           f 
          
         
           u 
          
         
           s 
          
         
           e 
          
         
           d 
          
         
        
       
         = 
        
       
         k 
        
       
      
        κ^{fused}_{aligned} = κ^{fused}_{not \,aligned} = k 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.4044em; vertical-align: -0.4374em;"></span><span class="mord"><span class="mord mathnormal">κ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.967em;"><span class="" style="top: -2.3987em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right: 0.0197em;">l</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">g</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">d</span></span></span></span><span class="" style="top: -3.1809em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.1076em;">f</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">se</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.4374em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1.4044em; vertical-align: -0.4374em;"></span><span class="mord"><span class="mord mathnormal">κ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.967em;"><span class="" style="top: -2.3987em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">t</span><span class="mspace mtight" style="margin-right: 0.1952em;"></span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right: 0.0197em;">l</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">g</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">d</span></span></span></span><span class="" style="top: -3.1809em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.1076em;">f</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">se</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.4374em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord mathnormal" style="margin-right: 0.0315em;">k</span></span></span></span></span>。在这种情况下，基于对齐的模型和基于非对齐的模型都有可能完美地对数据进行聚类，前提是聚类模块具有足够的能力。因此，基于对齐的模型可以受益于对齐的优点，同时仍然能够在融合后分离聚类。</p> 
<h4><a id="_58"></a>玩具数据实验</h4> 
<p>命题1进行了简化，即对于每个视图，聚类中的所有样本都位于同一点。为了证明在不太理想化的环境中对齐表示分布的潜在负面影响，并进一步激发问题，我们创建了一个简单的双视图数据集。数据集如图2所示，在两个二维视图中包含五个椭圆簇。</p> 
<p><img src="https://images2.imgbox.com/4a/f5/9PvjPjRu_o.png" alt="在这里插入图片描述"><br> 图2：玩具数据集。视图1：类(1-3)和(4,5)重叠。视图2：类1是孤立的，类(2,4)和(3,5)重叠。</p> 
<p>我们将SiMVC和SiMVC与对抗性对齐（SiMVC+Adv.）拟合到该数据集，以证明在受控环境中对齐分布的影响。此外，我们将CoMVC和当前最先进的EAMC相结合，以评估更先进的对齐程序。注意，对于所有这些模型，融合被实现为视图表示的加权平均，如在命题1中。关于SiMVC和CoMVC的其余细节将在下一节中提供。</p> 
<p>图1a和1b示出了尝试用对抗性对齐来对齐分布防止SiMVC在簇1和簇4之间分离。通过将对抗性对齐添加到SiMVC，融合后可见簇的数量从5减少到4。这与命题1一致，因为对于该数据集，我们有<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          κ 
         
         
         
           a 
          
         
           l 
          
         
           i 
          
         
           g 
          
         
           n 
          
         
           e 
          
         
           d 
          
         
         
         
           f 
          
         
           u 
          
         
           s 
          
         
           e 
          
         
           d 
          
         
        
       
         = 
        
       
         4 
        
       
      
        κ^{fused}_{aligned} = 4 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.4044em; vertical-align: -0.4374em;"></span><span class="mord"><span class="mord mathnormal">κ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.967em;"><span class="" style="top: -2.3987em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right: 0.0197em;">l</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">g</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">d</span></span></span></span><span class="" style="top: -3.1809em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.1076em;">f</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">se</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.4374em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">4</span></span></span></span></span>和<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          κ 
         
         
         
           n 
          
         
           o 
          
         
           t 
           
         
           a 
          
         
           l 
          
         
           i 
          
         
           g 
          
         
           n 
          
         
           e 
          
         
           d 
          
         
         
         
           f 
          
         
           u 
          
         
           s 
          
         
           e 
          
         
           d 
          
         
        
       
         = 
        
       
         5 
        
       
      
        κ^{fused}_{not \,aligned} = 5 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.4044em; vertical-align: -0.4374em;"></span><span class="mord"><span class="mord mathnormal">κ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.967em;"><span class="" style="top: -2.3987em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">t</span><span class="mspace mtight" style="margin-right: 0.1952em;"></span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right: 0.0197em;">l</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">g</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">d</span></span></span></span><span class="" style="top: -3.1809em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.1076em;">f</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">se</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.4374em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">5</span></span></span></span></span>。图1c显示了依赖于余弦相似性的CoMVC对齐了大多数观测值之间的角度。这种对齐不会导致融合表示中的类重叠。EAMC试图对齐视图表示的分布（图1d），导致类难以分离的融合表示。有趣的是，得到的融合表示表现出单个点组，这明显比类似理想主义设置中的上限<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          κ 
         
         
         
           a 
          
         
           l 
          
         
           i 
          
         
           g 
          
         
           n 
          
         
           e 
          
         
           d 
          
         
         
         
           f 
          
         
           u 
          
         
           s 
          
         
           e 
          
         
           d 
          
         
        
       
         = 
        
       
         4 
        
       
      
        κ^{fused}_{aligned} = 4 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.4044em; vertical-align: -0.4374em;"></span><span class="mord"><span class="mord mathnormal">κ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.967em;"><span class="" style="top: -2.3987em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight" style="margin-right: 0.0197em;">l</span><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">g</span><span class="mord mathnormal mtight">n</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">d</span></span></span></span><span class="" style="top: -3.1809em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.1076em;">f</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">se</span><span class="mord mathnormal mtight">d</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.4374em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">4</span></span></span></span></span>差。我们假设这是由于EAMC的融合权重，我们观察到在这个实验中几乎相等，因此打破了命题1中的假设3。</p> 
<p><img src="https://images2.imgbox.com/f1/1e/cLBx6UsA_o.png" alt="在这里插入图片描述"><br> 图1：在我们的玩具数据集中，有和没有对抗性对齐的SiMVC、CoMVC和EAMC的表示。</p> 
<h2><a id="3_74"></a>3.方法</h2> 
<h3><a id="31_SiMVC_76"></a>3.1 简单多视图聚类(SiMVC)</h3> 
<p>假设我们的数据集由从<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         V 
        
       
      
        V 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord mathnormal" style="margin-right: 0.2222em;">V</span></span></span></span></span>个视图观察到的<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         n 
        
       
      
        n 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span></span>个对象组成。设<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          x 
         
        
          i 
         
         
         
           ( 
          
         
           v 
          
         
           ) 
          
         
        
       
      
        x^{(v)}_i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.3217em; vertical-align: -0.2769em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.0448em;"><span class="" style="top: -2.4231em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span class="" style="top: -3.2198em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">v</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2769em;"><span class=""></span></span></span></span></span></span></span></span></span></span>是从视图<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         v 
        
       
      
        v 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal" style="margin-right: 0.0359em;">v</span></span></span></span></span>观察到的物体<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         i 
        
       
      
        i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span></span>。然后，我们模型的目标是将每个对象的视图集<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         { 
        
        
        
          x 
         
        
          i 
         
         
         
           ( 
          
         
           1 
          
         
           ) 
          
         
        
       
         , 
        
       
         . 
        
       
         . 
        
       
         . 
        
       
         , 
        
        
        
          x 
         
        
          i 
         
         
         
           ( 
          
         
           V 
          
         
           ) 
          
         
        
       
         } 
        
       
      
        \{x^{(1)}_i , . . . , x^{(V)}_i \} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.3217em; vertical-align: -0.2769em;"></span><span class="mopen">{<!-- --></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.0448em;"><span class="" style="top: -2.4231em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span class="" style="top: -3.2198em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2769em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.0448em;"><span class="" style="top: -2.4231em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span class="" style="top: -3.2198em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right: 0.2222em;">V</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2769em;"><span class=""></span></span></span></span></span></span><span class="mclose">}</span></span></span></span></span>分配给<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         k 
        
       
      
        k 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord mathnormal" style="margin-right: 0.0315em;">k</span></span></span></span></span>个聚类中的一个。</p> 
<p>为了实现这一点，我们首先根据 转换<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          x 
         
        
          i 
         
         
         
           ( 
          
         
           v 
          
         
           ) 
          
         
        
       
      
        x^{(v)}_i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.3217em; vertical-align: -0.2769em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.0448em;"><span class="" style="top: -2.4231em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span class="" style="top: -3.2198em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">v</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2769em;"><span class=""></span></span></span></span></span></span></span></span></span></span>到他的表示<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          z 
         
        
          i 
         
         
         
           ( 
          
         
           v 
          
         
           ) 
          
         
        
       
      
        z^{(v)}_i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.3217em; vertical-align: -0.2769em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.044em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.0448em;"><span class="" style="top: -2.4231em; margin-left: -0.044em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span class="" style="top: -3.2198em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">v</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2769em;"><span class=""></span></span></span></span></span></span></span></span></span></span></p> 
<p><img src="https://images2.imgbox.com/da/48/miREaA5E_o.png" alt="在这里插入图片描述"></p> 
<p>其中<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          f 
         
         
         
           ( 
          
         
           v 
          
         
           ) 
          
         
        
       
      
        f^{(v)} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.0824em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1076em;">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.888em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">v</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span></span>表示视图<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         v 
        
       
      
        v 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal" style="margin-right: 0.0359em;">v</span></span></span></span></span>的编码器网络。然后，我们将融合表示计算为加权平均值</p> 
<p><img src="https://images2.imgbox.com/83/1c/Oew2jaAD_o.png" alt="在这里插入图片描述"></p> 
<p>其中<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          w 
         
        
          1 
         
        
       
         , 
        
       
         . 
        
       
         . 
        
       
         . 
        
       
         , 
        
        
        
          w 
         
        
          v 
         
        
       
      
        w_1, . . . , w_v 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>是融合权重，对于<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         v 
        
       
         = 
        
       
         1 
        
       
         , 
        
       
         . 
        
       
         . 
        
       
         . 
        
       
         , 
        
       
         V 
        
       
      
        v = 1, . . . , V 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal" style="margin-right: 0.0359em;">v</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.8778em; vertical-align: -0.1944em;"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal" style="margin-right: 0.2222em;">V</span></span></span></span></span>和<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          ∑ 
         
         
         
           v 
          
         
           = 
          
         
           1 
          
         
        
          V 
         
        
        
        
          w 
         
        
          v 
         
        
       
         = 
        
       
         1 
        
       
      
        ∑^V_{v=1} w_v = 1 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.2809em; vertical-align: -0.2997em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position: relative; top: 0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.9812em;"><span class="" style="top: -2.4003em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">v</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span class="" style="top: -3.2029em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.2222em;">V</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2997em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">1</span></span></span></span></span>，满足<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          w 
         
        
          v 
         
        
       
         &gt; 
        
       
         0 
        
       
      
        w_v &gt; 0 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6891em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">0</span></span></span></span></span>。我们通过保留一组非归一化权重来实施这些约束，从中我们获得<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          w 
         
        
          1 
         
        
       
         , 
        
       
         . 
        
       
         . 
        
       
         . 
        
       
         , 
        
        
        
          w 
         
        
          V 
         
        
       
      
        w_1, . . . , w_V 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.2222em;">V</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>使用softmax函数。我们让未归一化的权重成为可训练的参数——这种设计选择具有以下优点：（i）在训练期间，模型有一种简单且可解释的方法来根据其聚类目标对视图进行优先级排序。通过不依赖辅助注意力网络，我们还使模型在内存消耗和训练时间方面更加高效。（ii）在推理中，权重充当任何其他模型参数，这意味着可以用任意批量大小进行样本外推理，而无需对训练的模型进行任何修改。固定融合权重也导致确定性预测，其独立于批次内的任何其他样本。</p> 
<p>为了获得最终的聚类分配，我们将融合表示通过全连接层，产生隐藏表示<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          h 
         
        
          i 
         
        
       
      
        h_i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>。这由另一个具有softmax激活的全连接层处理，以获得软聚类分配的<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         k 
        
       
      
        k 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord mathnormal" style="margin-right: 0.0315em;">k</span></span></span></span></span>维向量<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          α 
         
        
          i 
         
        
       
      
        α_i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5806em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.0037em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>。</p> 
<p>损失函数。我们采用基于深度发散的聚类（DDC）[30]损失，它在单视图图像聚类中显示了最先进的性能[30]。这也是EAMC[64]使用的聚类损失——多视图聚类当前的SOTA。</p> 
<p>聚类损失由三项组成，分别强制聚类可分离性和紧凑性、正交聚类分配以及聚类分配对单纯形角的接近度。第一个损失项来自柯西-施瓦茨散度的多密度推广[28]，并要求簇是可分离的和隐藏表示空间中的紧凑：</p> 
<p><img src="https://images2.imgbox.com/56/30/As4xN6Hv_o.png" alt="在这里插入图片描述"></p> 
<p>其中<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         k 
        
       
      
        k 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord mathnormal" style="margin-right: 0.0315em;">k</span></span></span></span></span>表示簇的数量，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          κ 
         
         
         
           i 
          
         
           j 
          
         
        
       
         = 
        
       
         e 
        
       
         x 
        
       
         p 
        
       
         ( 
        
       
         − 
        
       
         ∣ 
        
       
         ∣ 
        
        
        
          h 
         
        
          i 
         
        
       
         − 
        
        
        
          h 
         
        
          j 
         
        
       
         ∣ 
        
        
        
          ∣ 
         
        
          2 
         
        
       
         / 
        
       
         ( 
        
       
         2 
        
        
        
          σ 
         
        
          2 
         
        
       
         ) 
        
       
         ) 
        
       
      
        κ_{ij} = exp(−||h_i − h_j||^2/(2σ^2)) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7167em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal">κ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord">−</span><span class="mord">∣∣</span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1.1002em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord">∣</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8141em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord">/</span><span class="mopen">(</span><span class="mord">2</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">σ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8141em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">))</span></span></span></span></span>，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         σ 
        
       
      
        σ 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal" style="margin-right: 0.0359em;">σ</span></span></span></span></span>是超参数。<br> 第二项鼓励不同对象的聚类分配向量是正交的：<br> <img src="https://images2.imgbox.com/23/14/6IuZbvCS_o.png" alt="在这里插入图片描述"><br> 最后，第三项将聚类分配向量推向<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          R 
         
        
          k 
         
        
       
      
        \mathbb{R}^k 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8491em;"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8491em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0315em;">k</span></span></span></span></span></span></span></span></span></span></span></span>中的标准单纯形：</p> 
<p><img src="https://images2.imgbox.com/f3/62/c3WLdovU_o.png" alt="在这里插入图片描述"></p> 
<p>中<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          m 
         
         
         
           i 
          
         
           j 
          
         
        
       
         = 
        
       
         e 
        
       
         x 
        
       
         p 
        
       
         ( 
        
       
         − 
        
       
         ∣ 
        
       
         ∣ 
        
        
        
          α 
         
        
          i 
         
        
       
         − 
        
        
        
          e 
         
        
          j 
         
        
       
         ∣ 
        
        
        
          ∣ 
         
        
          2 
         
        
       
         ) 
        
       
      
        m_{ij} = exp(−||α_i − e_j||^2) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7167em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord">−</span><span class="mord">∣∣</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.0037em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1.1002em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord">∣</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8141em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          e 
         
        
          j 
         
        
       
      
        e_j 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7167em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span></span></span></span></span>是<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          R 
         
        
          k 
         
        
       
      
        \mathbb{R}^k 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8491em;"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8491em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0315em;">k</span></span></span></span></span></span></span></span></span></span></span></span>中标准单纯形的角<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         j 
        
       
      
        j 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.854em; vertical-align: -0.1944em;"></span><span class="mord mathnormal" style="margin-right: 0.0572em;">j</span></span></span></span></span>。</p> 
<p>我们在SiMVC训练期间最小化的最终聚类损失是这三项的总和：</p> 
<p><img src="https://images2.imgbox.com/16/1e/975SGyzE_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="32__114"></a>3.2 对比多视图聚类</h3> 
<p>对比学习提供了一种在样本级别对齐来自不同视图的表示的方法，迫使标签分布也对齐。因此，我们的假设是，选择性对比对齐将允许模型学习非常适合聚类的公共表示，同时避免前面讨论的分布比对的陷阱。自监督对比模型在各种下游计算机视觉任务中显示出巨大的潜力[5, 12, 13, 20, 22, 40, 49]。这些模型通过要求来自正对的表示被映射得很近，而来自负对的表示被映射得足够远来学习图像表示。在多视图学习中，每个对象都有一组来自与其相关联的不同视图的观察结果。这允许了对的自然定义：让同一对象的视图是正对，不同对象的视图是负对。</p> 
<p>根据[12]，我们计算两个表示<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          z 
         
        
          i 
         
         
         
           ( 
          
         
           v 
          
         
           ) 
          
         
        
       
      
        z^{(v)}_i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.3217em; vertical-align: -0.2769em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.044em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.0448em;"><span class="" style="top: -2.4231em; margin-left: -0.044em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span class="" style="top: -3.2198em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">v</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2769em;"><span class=""></span></span></span></span></span></span></span></span></span></span>和<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          z 
         
        
          j 
         
         
         
           ( 
          
         
           u 
          
         
           ) 
          
         
        
       
      
        z^{(u)}_j 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.4578em; vertical-align: -0.413em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.044em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.0448em;"><span class="" style="top: -2.4231em; margin-left: -0.044em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span><span class="" style="top: -3.2198em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">u</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.413em;"><span class=""></span></span></span></span></span></span></span></span></span></span>的相似性作为余弦相似性：</p> 
<p><img src="https://images2.imgbox.com/63/86/T5vQS4hG_o.png" alt="在这里插入图片描述"></p> 
<p>请注意，在[12]中，他们表明，在表示和相似性之间添加投影头会产生更好的表示——就学习到的表示的线性分类精度而言。我们发现我们的模型并非如此，所以我们选择直接计算表示的相似性。比较我们的模型有和没有投影头的版本的实验可以在补充中找到。</p> 
<p>为了定义任意数量的视图的对比损失，我们引入了NT-Xent损失的以下广义版本[12]：</p> 
<p><img src="https://images2.imgbox.com/8a/29/oE4sqfAU_o.png" alt="在这里插入图片描述"><br> 其中，当<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         u 
        
       
         ≠ 
        
       
         v 
        
       
      
        u\neq v 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8889em; vertical-align: -0.1944em;"></span><span class="mord mathnormal">u</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel"><span class="mrel"><span class="mord vbox"><span class="thinbox"><span class="rlap"><span class="strut" style="height: 0.8889em; vertical-align: -0.1944em;"></span><span class="inner"><span class="mord"><span class="mrel"></span></span></span><span class="fix"></span></span></span></span></span><span class="mrel">=</span></span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal" style="margin-right: 0.0359em;">v</span></span></span></span></span>时，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          1 
         
         
         
           { 
          
         
           u 
          
         
           ≠ 
          
         
           v 
          
         
           } 
          
         
        
       
      
        \mathbb{1}_{\{u\neq v\}} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.9996em; vertical-align: -0.3552em;"></span><span class="mord"><span class="mord">1</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.5198em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">{<!-- --></span><span class="mord mathnormal mtight">u</span><span class="mrel mtight"><span class="mrel mtight"><span class="mord vbox mtight"><span class="thinbox mtight"><span class="rlap mtight"><span class="strut" style="height: 0.8889em; vertical-align: -0.1944em;"></span><span class="inner"><span class="mord mtight"><span class="mrel mtight"></span></span></span><span class="fix"></span></span></span></span></span><span class="mrel mtight">=</span></span><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">v</span><span class="mclose mtight">}</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.3552em;"><span class=""></span></span></span></span></span></span></span></span></span></span>的求值为1，否则为0，并且</p> 
<p><img src="https://images2.imgbox.com/68/55/KkdJOnyW_o.png" alt="在这里插入图片描述"><br> 这里，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         τ 
        
       
      
        τ 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal" style="margin-right: 0.1132em;">τ</span></span></span></span></span>是超参数，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         N 
        
       
         e 
        
       
         g 
        
       
         ( 
        
        
        
          z 
         
        
          i 
         
         
         
           ( 
          
         
           v 
          
         
           ) 
          
         
        
       
         , 
        
        
        
          z 
         
        
          i 
         
         
         
           ( 
          
         
           u 
          
         
           ) 
          
         
        
       
         ) 
        
       
      
        Neg(z^{(v)}_i , z^{(u)}_i ) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.3217em; vertical-align: -0.2769em;"></span><span class="mord mathnormal" style="margin-right: 0.109em;">N</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.044em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.0448em;"><span class="" style="top: -2.4231em; margin-left: -0.044em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span class="" style="top: -3.2198em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">v</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2769em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.044em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.0448em;"><span class="" style="top: -2.4231em; margin-left: -0.044em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span class="" style="top: -3.2198em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">u</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2769em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>表示对应于正对<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         ( 
        
        
        
          z 
         
        
          i 
         
         
         
           ( 
          
         
           v 
          
         
           ) 
          
         
        
       
         , 
        
        
        
          z 
         
        
          i 
         
         
         
           ( 
          
         
           u 
          
         
           ) 
          
         
        
       
         ) 
        
       
      
        (z^{(v)}_i , z^{(u)}_i) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.3217em; vertical-align: -0.2769em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.044em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.0448em;"><span class="" style="top: -2.4231em; margin-left: -0.044em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span class="" style="top: -3.2198em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">v</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2769em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.044em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.0448em;"><span class="" style="top: -2.4231em; margin-left: -0.044em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span class="" style="top: -3.2198em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">u</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2769em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>的负对的相似性集合。我们为所有实验设置<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         τ 
        
       
         = 
        
       
         0.1 
        
       
      
        τ=0.1 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal" style="margin-right: 0.1132em;">τ</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">0.1</span></span></span></span></span>，遵循[12]。</p> 
<p>构造<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         N 
        
       
         e 
        
       
         g 
        
       
         ( 
        
        
        
          z 
         
        
          i 
         
         
         
           ( 
          
         
           v 
          
         
           ) 
          
         
        
       
         , 
        
        
        
          z 
         
        
          i 
         
         
         
           ( 
          
         
           u 
          
         
           ) 
          
         
        
       
         ) 
        
       
      
        Neg(z^{(v)}_i , z^{(u)}_i ) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.3217em; vertical-align: -0.2769em;"></span><span class="mord mathnormal" style="margin-right: 0.109em;">N</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.044em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.0448em;"><span class="" style="top: -2.4231em; margin-left: -0.044em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span class="" style="top: -3.2198em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">v</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2769em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.044em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.0448em;"><span class="" style="top: -2.4231em; margin-left: -0.044em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span class="" style="top: -3.2198em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">u</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2769em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>的直接方法是包括对象<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         i 
        
       
      
        i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span></span>的所有视图与当前批内所有其他对象的所有视图之间的相似性。然而，最小化等式(11)将导致具有低相似性分数的负样本。这确实是普通对比学习的目标，但它可能与聚类目标相反，在聚类目标中，我们希望来自同一聚类的对象在表示空间中分组在一起，因此彼此相似。为了防止对比损失破坏这个群结构，我们以以下方式构造<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         N 
        
       
         e 
        
       
         g 
        
       
         ( 
        
        
        
          z 
         
        
          i 
         
         
         
           ( 
          
         
           v 
          
         
           ) 
          
         
        
       
         , 
        
        
        
          z 
         
        
          i 
         
         
         
           ( 
          
         
           u 
          
         
           ) 
          
         
        
       
         ) 
        
       
      
        Neg(z^{(v)}_i , z^{(u)}_i ) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.3217em; vertical-align: -0.2769em;"></span><span class="mord mathnormal" style="margin-right: 0.109em;">N</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.044em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.0448em;"><span class="" style="top: -2.4231em; margin-left: -0.044em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span class="" style="top: -3.2198em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">v</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2769em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.044em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.0448em;"><span class="" style="top: -2.4231em; margin-left: -0.044em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span class="" style="top: -3.2198em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">u</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2769em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>：首先，我们定义集合</p> 
<p><img src="https://images2.imgbox.com/62/eb/d6VTZLOv_o.png" alt="在这里插入图片描述"></p> 
<p>它由对象<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         i 
        
       
      
        i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span></span>的所有视图和被分配给不同于对象<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         i 
        
       
      
        i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span></span>的簇的所有其他对象的所有视图之间的所有相似性组成。然后，我们通过从<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          N 
         
        
          i 
         
        
       
      
        \mathcal{N}_i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathcal" style="margin-right: 0.1474em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.1474em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>中采样固定数量的相似性来构造<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         N 
        
       
         e 
        
       
         g 
        
       
         ( 
        
        
        
          z 
         
        
          i 
         
         
         
           ( 
          
         
           v 
          
         
           ) 
          
         
        
       
         , 
        
        
        
          z 
         
        
          i 
         
         
         
           ( 
          
         
           u 
          
         
           ) 
          
         
        
       
         ) 
        
       
      
        Neg(z^{(v)}_i , z^{(u)}_i ) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.3217em; vertical-align: -0.2769em;"></span><span class="mord mathnormal" style="margin-right: 0.109em;">N</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.044em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.0448em;"><span class="" style="top: -2.4231em; margin-left: -0.044em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span class="" style="top: -3.2198em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">v</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2769em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.044em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.0448em;"><span class="" style="top: -2.4231em; margin-left: -0.044em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span class="" style="top: -3.2198em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">u</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2769em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>。这个过程确保我们只排斥由聚类模块分配给不同聚类的对象的表示。<br> CoMVC是将这种对比学习框架添加到SiMVC中的结果。图3显示了包含两个视图的数据集模型的示意图。我们用来训练CoMVC的损失是</p> 
<p><img src="https://images2.imgbox.com/b9/6d/7uaRS60F_o.png" alt="在这里插入图片描述"><br> 图3：我们提出的双视图数据集模型概述。在SiMVC和CoMVC中，视图首先由视图特定编码器网络<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          f 
         
         
         
           ( 
          
         
           1 
          
         
           ) 
          
         
        
       
      
        f^{(1)} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.0824em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1076em;">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.888em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span></span>和<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          f 
         
         
         
           ( 
          
         
           2 
          
         
           ) 
          
         
        
       
      
        f^{(2)} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.0824em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1076em;">f</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.888em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">2</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span></span></span></span></span>编码。所得表示与加权平均值融合，然后由聚类模块聚类。CoMVC包括一个额外的对比模块。</p> 
<p><img src="https://images2.imgbox.com/ff/2a/qoCWxeqV_o.png" alt="在这里插入图片描述"><br> 其中<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          L 
         
         
         
           c 
          
         
           l 
          
         
           u 
          
         
           s 
          
         
           t 
          
         
           e 
          
         
           r 
          
         
        
       
      
        \mathcal{L}_{cluster} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathcal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span><span class="mord mathnormal mtight" style="margin-right: 0.0197em;">l</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">s</span><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight" style="margin-right: 0.0278em;">er</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>是等式(8)中定义的聚类损失，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         δ 
        
       
      
        δ 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord mathnormal" style="margin-right: 0.0379em;">δ</span></span></span></span></span>是影响对比损失强度的超参数。<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          w 
         
        
          1 
         
        
       
         , 
        
       
         . 
        
       
         . 
        
       
         . 
        
        
        
          w 
         
        
          V 
         
        
       
      
        w_1, . . . w_V 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">...</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.2222em;">V</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>是来自SiMVC的融合权重。</p> 
<p>注意，我们不通过最小操作传播梯度，以避免将最小融合权重设置为0的琐碎解决方案。</p> 
<p>最小化对比损失导致具有高余弦相似性的表示。因此，对比对齐是（i）近似的，因为仅考虑表示之间的角度，而不考虑表示本身；和（ii）在样本级别上，防止未对准的标签分布。此外，将对比损失乘以最小融合权重自动地根据最少信息视图的权重调整对比损失的强度。因此，对齐是选择性的：如果模型通过将其融合权重设置为0来学习丢弃视图，则它将同时禁用对齐过程。通过调整对齐权重和不依赖对抗性训练，CoMVC可以受益于对齐表示的优势，同时规避对抗性对齐的缺点和最小-最大优化的可能困难[4, 19]。\</p> 
<h2><a id="4_152"></a>4.相关工作</h2> 
<p>在本节中，我们将简要总结关于多视图聚类的现有工作，以及讨论多模态学习中模态对齐的相关工作。现有的多视图聚类方法可以分为两类：传统的（基于非深度学习的）方法和基于深度学习的方法。</p> 
<h3><a id="_156"></a>传统方法</h3> 
<p>两阶段方法首先从所有视图中学习一个公共表示，然后使用单视图聚类算法对它们进行聚类[7, 11]。然而，最近的工作表明，让学习到的表示适应聚类算法会导致更好的聚类[56]。为了避免两阶段方法的这一缺点，非负矩阵分解[8, 15, 24, 57, 63]已被用于直接从数据矩阵计算聚类分配矩阵。类似地，子空间方法假设观测值可以由一个或多个自表示矩阵[5, 10, 37, 41, 55, 58, 59, 61]表示，并使用自表示矩阵来识别由所有观测值跨越的向量空间的线性子空间，其表示不同的聚类。替代的流行方法包括基于图[44, 48, 50, 51, 60, 65]和核[16, 18, 35, 39]的方法，这两种方法都假设数据可以用一个或多个核（或亲和）矩阵来表示，使得可以基于这些矩阵找到相应的聚类。</p> 
<h3><a id="_161"></a>基于深度学习的方法</h3> 
<p>基于深度学习的两阶段方法[2, 43, 52]的工作方式类似于上述两阶段方法，但使用深度神经网络来学习公共表示。然而，两阶段方法通常优于深度端到端方法，这些方法使它们的表示学习网络适应后续的聚类模块。例如，基于深度图的方法 [14, 25, 26, 34]使用亲和矩阵和图神经网络来直接聚类数据。类似地，深亚子空间方法[1, 3]做出与上述相同的子空间假设，但是从其深度神经网络中的中间表示计算自表示矩阵。最后，对抗方法[36, 64]使用生成器和鉴别器来对齐来自不同视图的隐藏表示的分布。这些对抗性方法优于先前的多视图聚类方法，在几个多视图数据集上产生了最先进的聚类性能。</p> 
<h3><a id="_165"></a>分布对齐</h3> 
<p>在多视图聚类领域之外，na ı̈vely对齐分布的问题最近引起了越来越多的关注[62, 53]，并导致了更有效的融合技术[23, 9, 46]。然而，这种努力在很大程度上仅限于有监督的多模态学习框架和领域适应方法。</p> 
<h2><a id="5_168"></a>5.实验</h2> 
<h3><a id="51__170"></a>5.1 设置</h3> 
<h4><a id="_172"></a>实施</h4> 
<p>我们的模型是在PyTorch[45]框架中实现的。我们使用Adam优化技术[31]和默认参数，在大小为100的小批量上训练100个时期的模型。我们观察到100个时期足以使训练收敛。训练重复20次，我们报告导致聚类损失中<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          L 
         
        
          1 
         
        
       
      
        \mathcal{L}_1 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathcal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>最低值的运行结果。<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         σ 
        
       
      
        σ 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal" style="margin-right: 0.0359em;">σ</span></span></span></span></span>超参数被设置为小批量内隐藏表示之间中值成对距离的15%，遵循[30]。对于对比模型，我们将所有实验中每个正对的负对的数量设置为25。我们将双视图数据集设置为<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         δ 
        
       
         = 
        
       
         0.1 
        
       
      
        δ = 0.1 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord mathnormal" style="margin-right: 0.0379em;">δ</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">0.1</span></span></span></span></span>，将三视图数据集设置为<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         δ 
        
       
         = 
        
       
         20 
        
       
      
        δ = 20 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord mathnormal" style="margin-right: 0.0379em;">δ</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">20</span></span></span></span></span>。我们观察到三视图数据集受益于更强的对比。我们的实现和架构细节的完整概述可以在补充中找到。</p> 
<h4><a id="_174"></a>数据集</h4> 
<p>我们使用六个众所周知的多视图数据集[36, 64]来评估我们的模型，这些数据集包含原始图像数据和矢量数据。这些是：（一）PASCAL VOC 2007（VOC）[17]。我们使用[27]提供的版本，其中包含手动标记的自然图像的要点特征和词频计数。（ii）哥伦比亚消费者视频（CCV）[29]，由来自互联网视频的SIFT、STIP和MFCC特征组成。（iii）Edge-MNIST（E-MNIST）[38]，其是普通MNIST数据集的一个版本，其中视图分别包含原始数字和边缘检测版本。（iv）Edge-FashionMNIST（E-FMNIST）[54]，它由服装项目的灰度图像组成。我们通过运行与用于创建E-MNIST的边缘检测器相同的边缘检测器来合成第二个视图。(v)COIL-20[42]，其中包含从不同角度描绘的20个项目的灰度图像。我们通过将一个项目的图像随机分组为三个一组来创建一个三视图数据集。（vi）SentencesNYU v2（RGB-D）[32]，它由室内场景的图像以及每个图像的描述组成。在[64]之后，我们使用来自ResNet-50的图像特征，没有分类头，在ImageNet数据集上预训练，作为第一个视图。使用预先训练的doc2vec模型在维基百科数据集上嵌入图像描述构成了第二个视图。</p> 
<p>请注意，对于具有多个标签的数据集，我们选择只有一个标签的对象。有关评估数据集的更多信息，请参见表1。</p> 
<p><img src="https://images2.imgbox.com/26/ab/HY6ULmeU_o.png" alt="在这里插入图片描述"><br> 表1：用于评价的数据集总结。对象。还有分类。分别表示数据集中存在的对象和类别的数量。视图和维度。分别表示视图的数量和每个视图的维度。请注意，对于E-MNIST、E-FMNIST和COIL-20，所有视图的输入维度都是相同的。</p> 
<h4><a id="_183"></a>基线模型</h4> 
<p>我们将我们的模型与一组广泛的基线方法进行比较，这些方法代表了多视图聚类的当前技术水平：(i)每个视图上的谱聚类(SC)[47]，以及所有视图SC(con)的级联；（ii）鲁棒多视图K均值聚类（RMKMC）[8]；（三）基于张量的表示学习多视图聚类tRLMvc[15]；（iv）一致和特定的多视图子空间聚类（CSMSC）[41]；(v)加权多视图谱聚类(WMSC)[65]；(vi)多视图共识图聚类(MCGC)[60]；(vii)深度典型相关分析(DCCA)[2]；（viii）深度多模态子空间聚类（DMSC）[1]；（ix）深度对抗性多视图聚类（DAMC）[36]；以及（x）用于多模态聚类的端到端对抗性注意力网络（EAMC）[64]。</p> 
<h4><a id="_187"></a>评价指标</h4> 
<p>为了确保公平的比较，我们报告了多次运行的基线结果，遵循[64]。为了评估模型的聚类性能，我们使用无监督聚类精度（ACC）和归一化互信息（NMI）。对于这两个指标，较高的值对应于更好的聚类。</p> 
<h3><a id="52__190"></a>5.2 结论</h3> 
<h4><a id="_192"></a>定量结果</h4> 
<p>VOC、CCV和E-MNIST如表2所示。结果表明，与对抗性对齐相比，不对齐表示可以具有显著改善(在E-MNIST上ACC的相对增益大于29%)，而选择性对齐总是改善性能。请注意，表2中E-MNIST的条目缺失，因为样本的数量使得传统方法在计算上不可行。</p> 
<p><img src="https://images2.imgbox.com/6c/4f/UDTh4kSx_o.png" alt="在这里插入图片描述"><br> 表2：VOC、CCV和EMNIST的聚类指标[%]。最佳和次佳以粗体突出显示。我们的模型和最佳基线模型之间的差异显示在括号中。绿色差异表示改进。基线结果取自[64]。</p> 
<h4><a id="_197"></a>消融实验</h4> 
<p>我们进行了一项消融研究，以评估对比损失中不同成分的影响9。具体地，我们在E-MNIST和VOC上训练有和没有提出的负对采样和自适应权重因子<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         ( 
        
       
         m 
        
       
         i 
        
       
         n 
        
       
         { 
        
        
        
          w 
         
        
          1 
         
        
       
         , 
        
       
         . 
        
       
         . 
        
       
         . 
        
       
         , 
        
        
        
          w 
         
        
          V 
         
        
       
         } 
        
       
         ) 
        
       
      
        (min\{w_1, . . . , w_V \}) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal">min</span><span class="mopen">{<!-- --></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.2222em;">V</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">})</span></span></span></span></span>.当我们移除负采样时，我们通过包括对象<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         i 
        
       
      
        i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span></span>的所有视图和当前批中所有其他对象的所有视图之间的相似性来构造<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         N 
        
       
         e 
        
       
         g 
        
       
         ( 
        
        
        
          z 
         
        
          i 
         
         
         
           ( 
          
         
           v 
          
         
           ) 
          
         
        
       
         , 
        
        
        
          z 
         
        
          i 
         
         
         
           ( 
          
         
           u 
          
         
           ) 
          
         
        
       
         ) 
        
       
      
        Neg(z^{(v)}_i , z^{(u)}_i ) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.3217em; vertical-align: -0.2769em;"></span><span class="mord mathnormal" style="margin-right: 0.109em;">N</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.044em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.0448em;"><span class="" style="top: -2.4231em; margin-left: -0.044em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span class="" style="top: -3.2198em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">v</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2769em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.044em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.0448em;"><span class="" style="top: -2.4231em; margin-left: -0.044em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span class="" style="top: -3.2198em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">u</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2769em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>。</p> 
<p>消融研究的结果（表4）显示，放弃自适应加权和负采样策略都对CoMVC的性能产生负面影响。这证明了将它们纳入最终对比损失的合理性。</p> 
<p><img src="https://images2.imgbox.com/c5/90/6UTRKb2D_o.png" alt="在这里插入图片描述"><br> 表4：CoMVC在E-MNIST和VOC上的消融研究结果。</p> 
<h4><a id="_208"></a>视图优先级</h4> 
<p>表5示出了针对所有数据集的EAMC、SiMVC和CoMVC获得的权重参数。EAMC总是产生接近均匀的权重分布，而SiMVC和CoMVC能够抑制无信息视图。请注意，对于数据集，如COIL-20，其中视图被认为同样重要，我们也观察到SiMVC和CoMVC接近均匀的权重分布。</p> 
<p>因为COIL-20中的视图指的是从随机角度描绘的物体。</p> 
<p><img src="https://images2.imgbox.com/65/1a/eBFwS5hm_o.png" alt="在这里插入图片描述"></p> 
<p>表5：EAMC、SiMVC和CoMVC的融合权重[%]。对于EAMC，我们将整个数据集分成大小为100的批次，并报告这些批次的平均权重。</p> 
<p>为了进一步评估我们的模型对视图进行优先排序的能力，我们用加性高斯噪声破坏了E-MNIST中的边缘视图（视图2），并随着噪声标准偏差的增加记录模型的性能。我们还重复了EAMC模型的实验，因为它代表了当前的技术水平。图4示出了针对不同噪声水平的噪声视图和聚类精度的所得融合权重。对于SiMVC和CoMVC，我们观察到噪声视图的权重随着噪声的增加而降低。因此，用于确定视图优先级的机制如预期的那样工作。因此，无论噪声水平如何，SiMVC和CoMVC都可以产生准确的聚类。反过来，我们观察到EAMC中的注意力机制不能产生抑制噪声视图的融合权重。随着噪声的增加，这导致聚类精度显著下降。</p> 
<p><img src="https://images2.imgbox.com/c0/7b/pJiCmD1C_o.png" alt="在这里插入图片描述"><br> 图4：E-MNIST上的融合权重和聚类精度（ACC），第二个视图中添加了越来越多的高斯噪声。</p> 
<h4><a id="CoMVC_223"></a>CoMVC中的选择性对齐</h4> 
<p>图5展示了E-MNIST数据集的无噪声和有噪声变体在CoMVC中的选择性对齐。在无噪声的情况下，CoMVC对齐表示，从而产生分离良好的聚类。然而，当第二视图被噪声破坏时，视图优先化机制通过将其融合权重设置为0而丢弃。这同时禁用对齐过程，防止融合表示被噪声视图破坏，从而保留聚类结构。</p> 
<p><img src="https://images2.imgbox.com/28/49/tOi0zZyS_o.png" alt="在这里插入图片描述"><br> 图5：常规（顶部）和噪声（<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         σ 
        
       
         = 
        
       
         1 
        
       
      
        σ=1 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal" style="margin-right: 0.0359em;">σ</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">1</span></span></span></span></span>）E-MNIST（底部）融合前后的学习表示。使用T-SNE投影到二维。</p> 
<h2><a id="6_230"></a>6.结论</h2> 
<p>我们的工作强调了在执行多视图聚类时考虑表示对齐的重要性。将我们的SiMVC的结果与以前的结果进行比较表明，使用对抗性学习对齐分布可以阻止模型学习良好的聚类，而CoMVC则说明了选择性对齐的好处，利用了两个世界的优点。</p> 
<h2><a id="8_234"></a>8.引用文献</h2> 
<ul><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [1] Mahdi Abavisani and Vishal M. Patel. Deep Multimodal Subspace Clustering Networks. IEEE Journal of Selected Topics in Signal Processing, 12(6), 2018.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [2] Galen Andrew, Raman Arora, Jeff Bilmes, and Karen Livescu. Deep Canonical Correlation Analysis. In International Conference on Machine Learning, 2013.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [3] Aluizio F. R. Ara ́ ujo, Victor O. Antonino, and Karina L. Ponce-Guevara. Self-organizing subspace clustering for highdimensional and multi-view data. Neural Networks, 2020.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [4] Martin Arjovsky, Soumith Chintala, and L ́ eon Bottou. Wasserstein Generative Adversarial Networks. In International Conference on Machine Learning, 2017.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [5] Philip Bachman, R Devon Hjelm, and William Buchwalter. Learning Representations by Maximizing Mutual Information Across Views. In Neural Information Processing Systems, 2019.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [6] Tadas Baltrusaitis, Chaitanya Ahuja, and Louis-Philippe Morency. Multimodal Machine Learning: A Survey and Taxonomy. IEEE Transactions on Pattern Analysis and Machine Intelligence, 41(2), 2019.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [7] M. B. Blaschko and C. H. Lampert. Correlational spectral clustering. In Computer Vision and Pattern Recognition, 2008.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [8] Xiao Cai, Feiping Nie, and Heng Huang. Multi-View KMeans Clustering on Big Data. In International Joint Conference on Artificial Intelligence, 2013.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [9] C ̆ at ̆ alina Cangea, Petar Veliˇ ckovi ́ c, and Pietro Li` o. Xflow: Cross-modal deep neural networks for audiovisual classification. IEEE Transactions on Neural Networks and Learning Systems, 2019.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [10] Xiaochun Cao, Changqing Zhang, Huazhu Fu, Si Liu, and Hua Zhang. Diversity-induced Multi-view Subspace Clustering. In Computer Vision and Pattern Recognition, 2015.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [11] Kamalika Chaudhuri, Sham Kakade, K. Livescu, and Karthik Sridharan. Multi-View Clustering via Canonical Correlation Analysis. In International Conference on Machine Learning, 2009.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [12] Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. A Simple Framework for Contrastive Learning of Visual Representations. In International Conference on Machine Learning, 2020.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [13] Ting Chen, Simon Kornblith, Kevin Swersky, Mohammad Norouzi, and Geoffrey Hinton. Big Self-Supervised Models are Strong Semi-Supervised Learners. arXiv:2006.10029 [cs, stat], 2020.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [14] Jiafeng Cheng, Qianqian Wang, Quanxue Gao, Deyan Xie, and Zhiqiang Tao. Multi-View Attribute Graph Convolution Networks for Clustering. In International Joint Conference on Artificial Intelligence, 2020.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [15] Miaomiao Cheng, Liping Jing, and Michael K. Ng. TensorBased Low-Dimensional Representation Learning for MultiView Clustering. IEEE Transactions on Image Processing, 28(5), 2019.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [16] Liang Du, Peng Zhou, Lei Shi, Hanmo Wang, Mingyu Fan, Wenjian Wang, and Yi-Dong Shen. Robust multiple kernel k-means using l21-norm. In AAAI Conference on Artificial Intelligence, 2015.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [17] Mark Everingham, Luc Van Gool, Christopher K. I. Williams, John Winn, and Andrew Zisserman. The Pascal Visual Object Classes (VOC) Challenge. In International Journal of Computer Vision, 2010.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [18] Mehmet G ̈ onen and Adam A. Margolin. Localized Data Fusion for Kernel k-Means Clustering with Application to Cancer Biology. In Neural Information Processing Systems, 2014.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [19] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative Adversarial Nets. In Neural Information Processing Systems, 2014.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [20] Jean-Bastien Grill, Florian Strub, Florent Altch ́ e, Corentin Tallec, Pierre H. Richemond, Elena Buchatskaya, Carl Doersch, Bernardo Avila Pires, Zhaohan Daniel Guo, Mohammad Gheshlaghi Azar, Bilal Piot, Koray Kavukcuoglu, R ́ emi Munos, and Michal Valko. Bootstrap your own latent: A new approach to self-supervised Learning. arXiv:2006.07733 [cs, stat], 2020.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [21] Xifeng Guo, Long Gao, Xinwang Liu, and Jianping Yin. Improved Deep Embedded Clustering with Local Structure Preservation. In Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence, Melbourne, Australia, 2017.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [22] Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, and Ross Girshick. Momentum Contrast for Unsupervised Visual Representation Learning. In Computer Vision and Pattern Recognition, 2020.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [23] Ming Hou, Jiajia Tang, Jianhai Zhang, Wanzeng Kong, and Qibin Zhao. Deep multimodal multilinear fusion with highorder polynomial pooling. In Advances in Neural Information Processing Systems, pages 12136–12145, 2019.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [24] Aiping Huang, Tiesong Zhao, and Chia-Wen Lin. MultiView Data Fusion Oriented Clustering via Nuclear Norm Minimization. IEEE Transactions on Image Processing, 29, 2020.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [25] Shudong Huang. Auto-weighted multi-view clustering via deep matrix decomposition. Pattern Recognition, 2020.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [26] Shuning Huang, Kaoru Ota, Mianxiong Dong, and Fanzhang Li. MultiSpectralNet: Spectral Clustering Using Deep Neural Network for Multi-View Data. IEEE Transactions on Computational Social Systems, 6(4), 2019.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [27] Sung Ju Hwang and Kristen Grauman. Accounting for the relative importance of objects in image retrieval. In British Machine Vision Conference, 2010.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [28] Robert Jenssen, Jose C. Principe, Deniz Erdogmus, and Torbjørn Eltoft. The Cauchy–Schwarz divergence and Parzen windowing: Connections to graph theory and Mercer kernels. Journal of the Franklin Institute, 343(6), 2006.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [29] Yu-Gang Jiang, Guangnan Ye, Shih-Fu Chang, Daniel Ellis, and Alexander C. Loui. Consumer video understanding: A benchmark database and an evaluation of human and machine performance. In International Conference on Multimedia Retrieval, 2011.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [30] Michael Kampffmeyer, Sigurd Løkse, Filippo M. Bianchi, Lorenzo Livi, Arnt-Børre Salberg, and Robert Jenssen. Deep divergence-based approach to clustering. Neural Networks, 113, 2019.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [31] Diederik P. Kingma and Jimmy Ba. Adam: A Method for Stochastic Optimization. In International Conference on Learning Representations, 2015.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [32] Chen Kong, Dahua Lin, Mohit Bansal, Raquel Urtasun, and Sanja Fidler. What Are You Talking About? Text-to-Image Coreference. In Computer Vision and Pattern Recognition, Columbus, OH, USA, 2014.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [33] Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep Learning. Nature, 521(7553), 2015.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [34] Jianqiang Li, Guoxu Zhou, Yuning Qiu, Yanjiao Wang, Yu Zhang, and Shengli Xie. Deep graph regularized non-negative matrix factorization for multi-view clustering. Neurocomputing, 390, 2020.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [35] Miaomiao Li, Xinwang Liu, Lei Wang, Yong Dou, Jianping Yin, and En Zhu. Multiple kernel clustering with local kernel alignment maximization. In International Joint Conference on Artificial Intelligence, 2016.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [36] Zhaoyang Li, Qianqian Wang, Zhiqiang Tao, Quanxue Gao, and Zhaohua Yang. Deep Adversarial Multi-view Clustering Network. In International Joint Conference on Artificial Intelligence, 2019.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [37] Guangcan Liu, Zhouchen Lin, Shuicheng Yan, Ju Sun, Yong Yu, and Yi Ma. Robust Recovery of Subspace Structures by Low-Rank Representation. IEEE Transactions on Pattern Analysis and Machine Intelligence, 35(1), 2013.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [38] Ming-Yu Liu and Oncel Tuzel. Coupled Generative Adversarial Networks. In Neural Information Processing Systems, 2016.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [39] Xinwang Liu. Multiple Kernel k-Means Clustering with Matrix-Induced Regularization. In AAAI Conference on Artificial Intelligence, 2016.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [40] Sindy L ̈ owe, Peter O’Connor, and Bastiaan Veeling. Putting An End to End-to-End: Gradient-Isolated Learning of Representations. In Neural Information Processing Systems, 2019.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [41] Shirui Luo, Changqing Zhang, Wei Zhang, and Xiaochun Cao. Consistent and Specific Multi-View Subspace Clustering. In AAAI Conference on Artificial Intelligence, 2018.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [42] Sameer A. Nene, Shree K. Nayar, and Hiroshi Murase. Columbia Object Image Library (COIL-20). Techincal Report CUCS-006-96, 1996.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [43] Jiquan Ngiam, Aditya Khosla, Mingyu Kim, Juhan Nam, Honglak Lee, and Andrew Ng. Multimodal Deep Learning. In International Conference on Machine Learning, 2011.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [44] Feiping Nie, Jing Li, and Xuelong Li. Self-weighted Multiview Clustering with Multiple Graphs. In International Joint Conference on Artificial Intelligence, 2017.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [45] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. PyTorch: An imperative style, high-performance deep learning library. In Neural Information Processing Systems, 2019.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [46] Juan-Manuel P ́ erez-R ́ ua, Valentin Vielzeuf, St ́ ephane Pateux, Moez Baccouche, and Fr ́ ed ́ eric Jurie. Mfas: Multimodal fusion architecture search. In Proceedings of the IEEE Conference on computer vision and pattern recognition, pages 6966–6975, 2019.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [47] Jianbo Shi and J. Malik. Normalized Cuts and Image Segmentation. IEEE Transactions on Pattern Analysis and Machine Intelligence, 22(8), 2000.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [48] Zhiqiang Tao, Hongfu Liu, Sheng Li, Zhengming Ding, and Yun Fu. Marginalized Multiview Ensemble Clustering. IEEE Transactions on Neural Networks and Learning Systems, 31(2), 2020.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [49] Aaron van den Oord, Yazhe Li, and Oriol Vinyals. Representation Learning with Contrastive Predictive Coding. arXiv:1807.03748 [cs, stat], 2019.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [50] Beilei Wang, Yun Xiao, Zhihui Li, Xuanhong Wang, Xiaojiang Chen, and Dingyi Fang. Robust Self-Weighted MultiView Projection Clustering. In AAAI Conference on Artificial Intelligence, 2020.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [51] R. Wang, F. Nie, Z. Wang, H. Hu, and X. Li. Parameter-Free Weighted Multi-View Projected Clustering with Structured Graph Learning. IEEE Transactions on Knowledge and Data Engineering, 32(10), 2020.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [52] Weiran Wang, Raman Arora, Karen Livescu, and Jeff Bilmes. On Deep Multi-View Representation Learning. In International Conference on Machine Learning, 2015.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [53] Yifan Wu, Ezra Winston, Divyansh Kaushik, and Zachary Lipton. Domain adaptation with asymmetrically-relaxed distribution alignment. In International Conference on Machine Learning, pages 6872–6881, 2019.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [54] Han Xiao, Kashif Rasul, and Roland Vollgraf. FashionMNIST: A Novel Image Dataset for Benchmarking Machine Learning Algorithms. arXiv:1708.07747 [cs, stat], 2017.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [55] Deyan Xie, Xiangdong Zhang, Quanxue Gao, Jiale Han, Song Xiao, and Xinbo Gao. Multiview Clustering by Joint Latent Representation and Similarity Learning. IEEE Transactions on Cybernetics, 2019.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [56] Junyuan Xie, Ross Girshick, and Ali Farhadi. Unsupervised Deep Embedding for Clustering Analysis. In International Conference on Machine Learning, 2016.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [57] Chang Xu, D. Tao, and Chao Xu. Multi-view Self-Paced Learning for Clustering. In International Joint Conference on Artificial Intelligence, 2015.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [58] Zhiyong Yang, Qianqian Xu, Weigang Zhang, Xiaochun Cao, and Qingming Huang. Split Multiplicative Multi-View Subspace Clustering. IEEE Transactions on Image Processing, 28(10), 2019.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [59] Ming Yin, Junbin Gao, Shengli Xie, and Yi Guo. Multiview Subspace Clustering via Tensorial t-Product Representation. IEEE Transactions on Neural Networks and Learning Systems, 30(3), 2019.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [60] Kun Zhan, Feiping Nie, Jing Wang, and Yi Yang. Multiview Consensus Graph Clustering. IEEE Transactions on Image Processing, 28(3), 2019.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [61] Changqing Zhang, Huazhu Fu, Qinghua Hu, Xiaochun Cao, Yuan Xie, Dacheng Tao, and Dong Xu. Generalized Latent Multi-View Subspace Clustering. IEEE Transactions on Pattern Analysis and Machine Intelligence, 42(1), 2020.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [62] Han Zhao, Remi Tachet des Combes, Kun Zhang, and Geoffrey J. Gordon. On Learning Invariant Representation for Domain Adaptation. arXiv:1901.09453 [cs, stat], 2019.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [63] Handong Zhao, Zhengming Ding, and Yun Fu. Multi-View Clustering via Deep Matrix Factorization. In AAAI Conference on Artificial Intelligence, 2017.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [64] Runwu Zhou and Yi-Dong Shen. End-to-End AdversarialAttention Network for Multi-Modal Clustering. In Computer Vision and Pattern Recognition, 2020.</li><li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled> [65] Linlin Zong, Xianchao Zhang, Xinyue Liu, and Hong Yu. Weighted Multi-View Spectral Clustering Based on Spectral Perturbation. In AAAI Conference on Artificial Intelligence, 2018.</li></ul>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/b972b0b2cd106fe71323e51359e1a4de/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【动态规划】子数组系列一（数组中连续的一段）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/3fc00c64f1601bb8ae04882f68004d2d/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">React中实现antd自定义图标，鼠标悬浮变色</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>