<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>DataWhaleX魔搭夏令营第四期AIGC方向task01笔记 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/7022e767b17419e2f6b5783ea05795db/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="DataWhaleX魔搭夏令营第四期AIGC方向task01笔记">
  <meta property="og:description" content="从零入门AI生图原理&amp;实践是Datawhale AI 夏令营（第四期）“AIGC”方向的学习活动，基于魔搭社区“可图Kolors-LoRA风格故事挑战赛”开展的实践学习。
在task01中，我们主要在魔搭社区搭建PAI实例并体验一下baseline~
学习链接：https://linklearner.com/activity/14/10/24
赛题任务 参赛者需在可图Kolors 模型的基础上训练LoRA 模型，生成无限风格，如水墨画风格、水彩风格、赛博朋克风格、日漫风格......
基于LoRA模型生成 8 张图片组成连贯故事，故事内容可自定义；基于8图故事，评估LoRA风格的美感度及连贯性 样例：偶像少女养成日记
速通指南 开通阿里云PAI-DSW试用 链接：https://free.aliyun.com/?productCode=learn
在魔搭社区进行授权 链接：https://www.modelscope.cn/my/mynotebook/authorization
（以上图例来自Datawhale AI 夏令营（第四期）“AIGC”方向的“从零入门AI生图原理&amp;实践”）
报名赛事 赛事链接：https://tianchi.aliyun.com/competition/entrance/532254
在魔搭社区创建PAI实例 链接：https://www.modelscope.cn/my/mynotebook/authorization
（以上图例来自Datawhale AI 夏令营（第四期）“AIGC”方向的“从零入门AI生图原理&amp;实践”）
体验Baseline！ 打开实例
下载文件
在终端中运行以下代码
git lfs install git clone https://www.modelscope.cn/datasets/maochase/kolors.git 进入得到的kolors文件夹，打开baseline文件
安装环境，然后重启kernel
如果想要不同的图片风格，可以依次调整8段prompt来修改图片的描述
依次运行剩余代码
生成的图像在这里
微调结果上传魔搭 移动结果文件 打开terminal（终端）并运行以下代码
mkdir /mnt/workspace/kolors/output &amp; cd cp /mnt/workspace/kolors/models/lightning_logs/version_0/checkpoints/epoch\=0-step\=500.ckpt /mnt/workspace/kolors/output/ cp /mnt/workspace/kolors/1.jpg /mnt/workspace/kolors/output/ 下载结果文件 进入output文件夹，分别下载两个文件到本地
创建并上传模型所需内容 链接：https://www.modelscope.cn/models/create
流程如下：
（以上图例来自Datawhale AI 夏令营（第四期）“AIGC”方向的“从零入门AI生图原理&amp;实践”）
最后记得关闭PAI实例，不然会一直消耗试用额度的
链接：https://www.modelscope.cn/my/mynotebook/authorization
代码详情 以下是Baseline中的代码解释
环境安装 !">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-08-11T20:36:27+08:00">
    <meta property="article:modified_time" content="2024-08-11T20:36:27+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">DataWhaleX魔搭夏令营第四期AIGC方向task01笔记</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p><strong>从零入门AI生图原理&amp;实践</strong>是Datawhale AI 夏令营（第四期）“AIGC”方向的学习活动，基于魔搭社区<strong>“</strong><strong>可图Kolors-LoRA风格故事挑战赛</strong><strong>”</strong>开展的实践学习。</p> 
<p>在task01中，我们主要在魔搭社区搭建PAI实例并体验一下baseline~</p> 
<p>学习链接：<a href="https://linklearner.com/activity/14/10/24" rel="nofollow" title="https://linklearner.com/activity/14/10/24">https://linklearner.com/activity/14/10/24</a></p> 
<h2>赛题任务</h2> 
<ol><li> <p>参赛者需在可图Kolors 模型的基础上训练LoRA 模型，生成无限风格，如水墨画风格、水彩风格、赛博朋克风格、日漫风格......</p> </li><li> <p>基于LoRA模型生成 8 张图片组成连贯故事，故事内容可<strong>自定义</strong>；基于8图故事，评估LoRA风格的美感度及连贯性 样例：偶像少女养成日记</p> </li></ol> 
<h2>速通指南</h2> 
<h3>开通阿里云PAI-DSW试用</h3> 
<p>链接：<u><a href="https://free.aliyun.com/?productCode=learn" rel="nofollow" title="https://free.aliyun.com/?productCode=learn">https://free.aliyun.com/?productCode=learn</a></u></p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/b3/b2/3vRHlbvX_o.png"></p> 
<h3>在魔搭社区进行授权</h3> 
<p>链接：<u><a class="link-info" href="https://www.modelscope.cn/my/mynotebook/authorization" rel="nofollow" title="https://www.modelscope.cn/my/mynotebook/authorization">https://www.modelscope.cn/my/mynotebook/authorization</a></u></p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/ec/67/tiYlHd78_o.png"></p> 
<p style="text-align:center;">（以上图例来自Datawhale AI 夏令营（第四期）“AIGC”方向的“从零入门AI生图原理&amp;实践”）</p> 
<h3>报名赛事</h3> 
<p>赛事链接：<u><a class="link-info" href="https://tianchi.aliyun.com/competition/entrance/532254" rel="nofollow" title="https://tianchi.aliyun.com/competition/entrance/532254">https://tianchi.aliyun.com/competition/entrance/532254</a></u></p> 
<h3>在魔搭社区创建PAI实例</h3> 
<p>链接：<u><a class="link-info" href="https://www.modelscope.cn/my/mynotebook/authorization" rel="nofollow" title="https://www.modelscope.cn/my/mynotebook/authorization">https://www.modelscope.cn/my/mynotebook/authorization</a></u></p> 
<p style="text-align:center;"><u><img alt="" src="https://images2.imgbox.com/79/46/GMVdU1uV_o.png"></u></p> 
<p style="text-align:center;">（以上图例来自Datawhale AI 夏令营（第四期）“AIGC”方向的“从零入门AI生图原理&amp;实践”）</p> 
<h3>体验Baseline！</h3> 
<p>打开实例</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/3f/86/mfN25Z8k_o.png"></p> 
<p>下载文件</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/6d/14/c0wBaH94_o.png"></p> 
<p>在终端中运行以下代码</p> 
<pre><code class="language-python">git lfs install
git clone https://www.modelscope.cn/datasets/maochase/kolors.git</code></pre> 
<p>进入得到的kolors文件夹，打开baseline文件</p> 
<p>安装环境，然后重启kernel</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/7f/42/lwSBN8oC_o.png"></p> 
<p>如果想要不同的图片风格，可以依次调整8段prompt来修改图片的描述</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/55/60/UyjDjcmN_o.png"></p> 
<p>依次运行剩余代码</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/03/39/kpFj7s2J_o.png"></p> 
<p>生成的图像在这里</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/13/89/UMtP3L8l_o.png"></p> 
<h3>微调结果上传魔搭</h3> 
<h4>移动结果文件</h4> 
<p>打开terminal（终端）并运行以下代码</p> 
<pre><code class="language-python">mkdir /mnt/workspace/kolors/output &amp; cd 
cp /mnt/workspace/kolors/models/lightning_logs/version_0/checkpoints/epoch\=0-step\=500.ckpt /mnt/workspace/kolors/output/
cp /mnt/workspace/kolors/1.jpg /mnt/workspace/kolors/output/</code></pre> 
<h4>下载结果文件</h4> 
<p>进入output文件夹，分别下载两个文件到本地</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/d3/84/pFJ7h5N6_o.png"></p> 
<h4>创建并上传模型所需内容</h4> 
<p>链接：<a class="link-info" href="https://www.modelscope.cn/models/create" rel="nofollow" title="https://www.modelscope.cn/models/create">https://www.modelscope.cn/models/create</a></p> 
<p>流程如下：</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/67/ed/0VPteZBO_o.png"></p> 
<p style="text-align:center;">（以上图例来自Datawhale AI 夏令营（第四期）“AIGC”方向的“从零入门AI生图原理&amp;实践”）</p> 
<p>最后记得关闭PAI实例，不然会一直消耗试用额度的</p> 
<p>链接：<u><a class="link-info" href="https://www.modelscope.cn/my/mynotebook/authorization" rel="nofollow" title="https://www.modelscope.cn/my/mynotebook/authorization">https://www.modelscope.cn/my/mynotebook/authorization</a></u></p> 
<h2>代码详情</h2> 
<p>以下是Baseline中的代码解释</p> 
<h3>环境安装</h3> 
<pre><code class="language-python">!pip install simple-aesthetics-predictor

!pip install -v -e data-juicer

!pip uninstall pytorch-lightning -y
!pip install peft lightning pandas torchvision

!pip install -e DiffSynth-Studio</code></pre> 
<p>代码导入了需要用到的库，包括 data-juicer 和微调的工具 DiffSynth-Studio</p> 
<h3>下载数据集</h3> 
<pre><code class="language-python">#下载数据集
from modelscope.msdatasets import MsDataset

ds = MsDataset.load(
    'AI-ModelScope/lowres_anime',
    subset_name='default',
    split='train',
    cache_dir="/mnt/workspace/kolors/data"
)

import json, os
from data_juicer.utils.mm_utils import SpecialTokens
from tqdm import tqdm

os.makedirs("./data/lora_dataset/train", exist_ok=True)
os.makedirs("./data/data-juicer/input", exist_ok=True)
with open("./data/data-juicer/input/metadata.jsonl", "w") as f:
    for data_id, data in enumerate(tqdm(ds)):
        image = data["image"].convert("RGB")
        image.save(f"/mnt/workspace/kolors/data/lora_dataset/train/{data_id}.jpg")
        metadata = {"text": "二次元", "image": [f"/mnt/workspace/kolors/data/lora_dataset/train/{data_id}.jpg"]}
        f.write(json.dumps(metadata))
        f.write("\n")</code></pre> 
<p>下载数据集kolors</p> 
<h3>处理数据集，保存数据处理结果</h3> 
<pre><code class="language-python">data_juicer_config = """
# global parameters
project_name: 'data-process'
dataset_path: './data/data-juicer/input/metadata.jsonl'  # path to your dataset directory or file
np: 4  # number of subprocess to process your dataset

text_keys: 'text'
image_key: 'image'
image_special_token: '&lt;__dj__image&gt;'

export_path: './data/data-juicer/output/result.jsonl'

# process schedule
# a list of several process operators with their arguments
process:
    - image_shape_filter:
        min_width: 1024
        min_height: 1024
        any_or_all: any
    - image_aspect_ratio_filter:
        min_ratio: 0.5
        max_ratio: 2.0
        any_or_all: any
"""
with open("data/data-juicer/data_juicer_config.yaml", "w") as file:
    file.write(data_juicer_config.strip())

!dj-process --config data/data-juicer/data_juicer_config.yaml


import pandas as pd
import os, json
from PIL import Image
from tqdm import tqdm


texts, file_names = [], []
os.makedirs("./data/lora_dataset_processed/train", exist_ok=True)
with open("./data/data-juicer/output/result.jsonl", "r") as file:
    for data_id, data in enumerate(tqdm(file.readlines())):
        data = json.loads(data)
        text = data["text"]
        texts.append(text)
        image = Image.open(data["image"][0])
        image_path = f"./data/lora_dataset_processed/train/{data_id}.jpg"
        image.save(image_path)
        file_names.append(f"{data_id}.jpg")
data_frame = pd.DataFrame()
data_frame["file_name"] = file_names
data_frame["text"] = texts
data_frame.to_csv("./data/lora_dataset_processed/train/metadata.csv", index=False, encoding="utf-8-sig")
data_frame</code></pre> 
<h3>lora微调</h3> 
<pre><code class="language-python"># 下载模型
from diffsynth import download_models
download_models(["Kolors", "SDXL-vae-fp16-fix"])

#模型训练
import os

cmd = """
python DiffSynth-Studio/examples/train/kolors/train_kolors_lora.py \
  --pretrained_unet_path models/kolors/Kolors/unet/diffusion_pytorch_model.safetensors \
  --pretrained_text_encoder_path models/kolors/Kolors/text_encoder \
  --pretrained_fp16_vae_path models/sdxl-vae-fp16-fix/diffusion_pytorch_model.safetensors \
  --lora_rank 16 \
  --lora_alpha 4.0 \
  --dataset_path data/lora_dataset_processed \
  --output_path ./models \
  --max_epochs 1 \
  --center_crop \
  --use_gradient_checkpointing \
  --precision "16-mixed"
""".strip()

os.system(cmd)</code></pre> 
<h3>加载微调好的模型</h3> 
<pre><code class="language-python">from diffsynth import ModelManager, SDXLImagePipeline
from peft import LoraConfig, inject_adapter_in_model
import torch


def load_lora(model, lora_rank, lora_alpha, lora_path):
    lora_config = LoraConfig(
        r=lora_rank,
        lora_alpha=lora_alpha,
        init_lora_weights="gaussian",
        target_modules=["to_q", "to_k", "to_v", "to_out"],
    )
    model = inject_adapter_in_model(lora_config, model)
    state_dict = torch.load(lora_path, map_location="cpu")
    model.load_state_dict(state_dict, strict=False)
    return model


# Load models
model_manager = ModelManager(torch_dtype=torch.float16, device="cuda",
                             file_path_list=[
                                 "models/kolors/Kolors/text_encoder",
                                 "models/kolors/Kolors/unet/diffusion_pytorch_model.safetensors",
                                 "models/kolors/Kolors/vae/diffusion_pytorch_model.safetensors"
                             ])
pipe = SDXLImagePipeline.from_model_manager(model_manager)

# Load LoRA
pipe.unet = load_lora(
    pipe.unet,
    lora_rank=16, # This parameter should be consistent with that in your training script.
    lora_alpha=2.0, # lora_alpha can control the weight of LoRA.
    lora_path="models/lightning_logs/version_0/checkpoints/epoch=0-step=500.ckpt"
)</code></pre> 
<h3>图片生成</h3> 
<pre><code class="language-python">torch.manual_seed(0)
image = pipe(
    prompt="二次元，一个紫色短发小女孩，在家中沙发上坐着，双手托着腮，很无聊，全身，粉色连衣裙",
    negative_prompt="丑陋、变形、嘈杂、模糊、低对比度",
    cfg_scale=4,
    num_inference_steps=50, height=1024, width=1024,
)
image.save("1.jpg")</code></pre> 
<p>调用训练好的模型生成图片</p> 
<h2>文生图基础知识介绍</h2> 
<p>文生图主要以SD系列基础模型为主，以及在其基础上微调的lora模型和人物基础模型等。</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/2e/45/FoZdlTQq_o.png"></p> 
<h3>提示词（Prompt）</h3> 
<p>提示词可以分为正向提示词（Positive Prompt）和反向提示词（Negative Prompt），它们分别用于确定生成内容和排除不希望出现的元素。其中，正向提示词用于表明用户希望生成的内容类型、风格、质量等要求，而反向提示词则用于排除用户不希望出现的元素或特征，从而确保生成的内容符合用户的期望。</p> 
<h3>Lora</h3> 
<p>Lora（Low-Rank Adaptation，即低秩自适应）模型是一种轻量级的微调方法，它不是指单一的具体模型，而是指一类通过特定微调技术应用于基础模型的扩展应用。在处理图像和文本等复杂数据时，Lora模型通过学习和调整神经网络中特定层的权重，以较小的参数代价实现模型对特定任务的适应，从而在不显著影响原始模型性能的前提下，提高模型在特定任务上的表现。在Stable Diffusion这一文本到图像合成模型的框架下，Lora被用来对预训练好的大模型进行针对性优化，以实现对特定主题、风格或任务的精细化控制。</p> 
<h4>Lora的特点</h4> 
<p><strong>低秩自适应</strong>：Lora模型通过引入低秩矩阵来近似原始模型中的权重变化，从而减少了需要学习的参数数量。这种方法可以在微调过程中更加高效。</p> 
<p><strong>灵活性</strong>：Lora模型可以应用在多种预训练模型上，例如GPT、BERT等。此外，Lora模型还可以与其他微调技术结合使用，从而进一步提高效率。</p> 
<p><strong>高效性</strong>：因为Lora模型只调整部分层的权重，所以它的训练速度通常比完全微调整个模型要快得多。因此Lora模型在需要快速适应新任务或数据集的场景中非常有效。</p> 
<h3>ComfyUI</h3> 
<p>ComfyUI 是一个工作流工具，主要用于简化和优化 AI 模型的配置和训练过程。通过直观的界面和集成的功能，用户可以轻松地进行模型微调、数据预处理、图像生成等任务，从而提高工作效率和生成效果。</p> 
<h4>ComfyUI的特点</h4> 
<p><strong>节点式工作流程</strong>：ComfyUI通过拖拽和连接不同的节点来构建图像生成流程，每个节点代表一个特定的功能或模型，比如加载模型、文本编码、采样器、VAE解码等。</p> 
<p><strong>高度定制性</strong>：用户可以根据自己的需求自定义工作流程，通过连接不同的节点，可以实现更精准、更复杂的图像生成效果。</p> 
<p><strong>优化生成流程</strong>：ComfyUI的内部生成流程经过优化，生成图片的速度相较于传统的Web UI有明显提升，而且对显存的要求更低。</p> 
<p><strong>可复现性</strong>：由于工作流程是基于节点构建的，因此可以轻松地导出或分享工作流程，并确保生成效果的可复现性。</p> 
<h3>参考图控制</h3> 
<p>ControlNet是一种用于精确控制图像生成过程的技术组件。它是一个附加到预训练的扩散模型（如Stable Diffusion模型）上的可训练神经网络模块。扩散模型通常用于从随机噪声逐渐生成图像的过程，而ControlNet的作用在于引入额外的控制信号，使得用户能够更具体地指导图像生成的各个方面（如姿势关键点、分割图、深度图、颜色等）。</p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/8df5902433952d899a1d4ccaf0f45041/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">MySQL：表的设计原则和聚合函数</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/7524500c6b248ee6c835ad7278787fb9/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">C:每日一题：字符串左旋</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>