<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>基于人体姿势估计的舞蹈检测（AI Dance based on Human Pose Estimation） - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/9ea6f7d44734e7c2d6535e02b9cc91ef/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="基于人体姿势估计的舞蹈检测（AI Dance based on Human Pose Estimation）">
  <meta property="og:description" content="人体姿势骨架以图形格式表示人的方向。本质上，它是一组坐标，可以连接起来描述人的姿势。骨架中的每个坐标都被称为一个部分(或一个关节，或一个关键点)。两个部分之间的有效连接称为一对(或分支)。下面是一个人体姿势骨架样本。
因此，在本文中，我们将研究如何使用深度神经网络模型在OpenCV中执行人体姿态估计。
AI Dance based on Human Pose Estimation 1、数据集2、模型架构3、实验和结果加载网络结构读取图像和准备输入到网络做出预测并分析关键点画出骨架 1、数据集 由于缺乏高质量的数据集，人体姿态估计一直是一个具有挑战性的问题。如今，每一个AI挑战都是需要一个好的数据集来完成的。在过去的几年里，有挑战性的数据集已经发布，这使得研究人员更容易有效地解决这个问题。
以下是常用的数据集：
COCO Key-points 数据集MPII 人体姿态估计数据集VGG姿态数据集SURREAL（实际任务下的人体姿态数据集）UP-3D数据集
本文中我们采用的是COCO数据集进行人体姿态估计任务。 2、模型架构 OpenPose首先检测属于图像中每个人的部分(关键点)，然后将部分分配给不同的个体。下图是OpenPose模型的架构。
该模型将尺寸为w × h的彩色图像作为输入，并生成图像中每个人关键点的二维位置作为输出。检测分三个阶段进行:
阶段一：VGGNet的前10层用于为输入图像创建特征映射。阶段二：使用2分支多级CNN，其中第一个分支预测身体部位位置(例如肘部，膝盖等)的一组2D置信度图(S)。下面给出了关键点的置信度图和亲和度图。第二个分支预测部分亲和度的一组二维向量场(L)，它编码了部分之间的关联程度。阶段三：通过贪婪推理对置信度图和亲和度图进行解析，生成图像中所有人的二维关键点。
3、实验和结果 在本节中，为了简单起见，我们将加载用于理解单个人的人体姿态估计的训练模型。步骤如下:
下载模型的权重： 权重下载
加载网络结构 我们正在使用在Caffe深度学习框架上训练的模型。Caffe模型有2个文件：
Prototxt文件，它指定了神经网络的体系结构Caffemodel文件，存储训练模型的权重 读取图像和准备输入到网络 我们使用OpenCV读取的输入帧应该转换为输入blob(如Caffe)，以便它可以馈送到网络。这是使用blobFromImage函数完成的，该函数将图像从OpenCV格式转换为Caffe blob格式。首先，我们将像素值归一化为(0,1)。然后我们指定图像的尺寸。接下来，要减去的平均值，即(0,0,0)。
做出预测并分析关键点 一旦将图像传递给模型，就可以进行预测。输出为4D矩阵:
第一个维度是图像ID(如果向网络传递多个图像)。第二个维度表示关键点的索引。该模型生成的置信度图和部件关联图都是连接在一起的。对于COCO模型，它由57部分组成- 18关键点置信度图&#43; 1背景&#43; 19*2部分亲和图。第三个维度是输出映射的高度。第四个维度是输出映射的宽度。 画出骨架 当我们有关键点的时候我们就可以画骨架了只要把它们对连接起来。
# 2.Load the network # Specify the paths for the 2 files protoFile = &#34;pose/mpi/pose_deploy_linevec_faster_4_stages.prototxt&#34; weightsFile = &#34;pose/mpi/pose_iter_160000.caffemodel&#34; # Read the network into Memory net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile) #3.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2023-06-30T09:54:38+08:00">
    <meta property="article:modified_time" content="2023-06-30T09:54:38+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">基于人体姿势估计的舞蹈检测（AI Dance based on Human Pose Estimation）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p><strong>人体姿势骨架以图形格式表示人的方向。本质上，它是一组坐标，可以连接起来描述人的姿势。骨架中的每个坐标都被称为一个部分(或一个关节，或一个关键点)。两个部分之间的有效连接称为一对(或分支)。下面是一个人体姿势骨架样本。</strong><br> <strong>因此，在本文中，我们将研究如何使用深度神经网络模型在OpenCV中执行人体姿态估计。</strong><br> </p> 
<div class="toc"> 
 <h4>AI Dance based on Human Pose Estimation</h4> 
 <ul><li><a href="#1_3" rel="nofollow">1、数据集</a></li><li><a href="#2_12" rel="nofollow">2、模型架构</a></li><li><a href="#3_20" rel="nofollow">3、实验和结果</a></li><li><ul><li><ul><li><a href="#_25" rel="nofollow">加载网络结构</a></li><li><a href="#_29" rel="nofollow">读取图像和准备输入到网络</a></li><li><a href="#_31" rel="nofollow">做出预测并分析关键点</a></li><li><a href="#_37" rel="nofollow">画出骨架</a></li></ul> 
  </li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h2><a id="1_3"></a>1、数据集</h2> 
<p>由于缺乏高质量的数据集，人体姿态估计一直是一个具有挑战性的问题。如今，每一个AI挑战都是需要一个好的数据集来完成的。在过去的几年里，有挑战性的数据集已经发布，这使得研究人员更容易有效地解决这个问题。<br> 以下是常用的数据集：</p> 
<ul><li>COCO Key-points 数据集</li><li>MPII 人体姿态估计数据集</li><li>VGG姿态数据集</li><li>SURREAL（实际任务下的人体姿态数据集）</li><li>UP-3D数据集<br> 本文中我们采用的是COCO数据集进行人体姿态估计任务。</li></ul> 
<h2><a id="2_12"></a>2、模型架构</h2> 
<p>OpenPose首先检测属于图像中每个人的部分(关键点)，然后将部分分配给不同的个体。下图是OpenPose模型的架构。<br> <img src="https://images2.imgbox.com/e8/0e/DVCbhxmF_o.png" alt="在这里插入图片描述"><br> 该模型将尺寸为w × h的彩色图像作为输入，并生成图像中每个人关键点的二维位置作为输出。检测分三个阶段进行:</p> 
<ol><li><strong>阶段一</strong>：VGGNet的前10层用于为输入图像创建特征映射。</li><li><strong>阶段二</strong>：使用2分支多级CNN，其中第一个分支预测身体部位位置(例如肘部，膝盖等)的一组2D置信度图(S)。下面给出了关键点的置信度图和亲和度图。第二个分支预测部分亲和度的一组二维向量场(L)，它编码了部分之间的关联程度。</li><li><strong>阶段三</strong>：通过贪婪推理对置信度图和亲和度图进行解析，生成图像中所有人的二维关键点。<br> <img src="https://images2.imgbox.com/a6/0b/jRRS6bGj_o.png" alt="在这里插入图片描述"></li></ol> 
<h2><a id="3_20"></a>3、实验和结果</h2> 
<p>在本节中，为了简单起见，我们将加载用于理解单个人的人体姿态估计的训练模型。步骤如下:</p> 
<p><mark>下载模型的权重</mark>： <a href="https://drive.google.com/file/d/1WYWwZR_mtUSfRCR-Rwi0mDGNlL_Uvbei/view?usp=sharing" rel="nofollow">权重下载</a></p> 
<h4><a id="_25"></a>加载网络结构</h4> 
<p>我们正在使用在Caffe深度学习框架上训练的模型。Caffe模型有2个文件：</p> 
<ul><li>Prototxt文件，它指定了神经网络的体系结构</li><li>Caffemodel文件，存储训练模型的权重</li></ul> 
<h4><a id="_29"></a>读取图像和准备输入到网络</h4> 
<p>我们使用OpenCV读取的输入帧应该转换为输入blob(如Caffe)，以便它可以馈送到网络。这是使用blobFromImage函数完成的，该函数将图像从OpenCV格式转换为Caffe blob格式。首先，我们将像素值归一化为(0,1)。然后我们指定图像的尺寸。接下来，要减去的平均值，即(0,0,0)。</p> 
<h4><a id="_31"></a>做出预测并分析关键点</h4> 
<p>一旦将图像传递给模型，就可以进行预测。输出为4D矩阵:</p> 
<ol><li>第一个维度是图像ID(如果向网络传递多个图像)。</li><li>第二个维度表示关键点的索引。该模型生成的置信度图和部件关联图都是连接在一起的。对于COCO模型，它由57部分组成- 18关键点置信度图+ 1背景+ 19*2部分亲和图。</li><li>第三个维度是输出映射的高度。</li><li>第四个维度是输出映射的宽度。</li></ol> 
<h4><a id="_37"></a>画出骨架</h4> 
<p>当我们有关键点的时候我们就可以画骨架了只要把它们对连接起来。</p> 
<pre><code class="prism language-python"><span class="token comment"># 2.Load the network</span>
<span class="token comment"># Specify the paths for the 2 files</span>
protoFile <span class="token operator">=</span> <span class="token string">"pose/mpi/pose_deploy_linevec_faster_4_stages.prototxt"</span>
weightsFile <span class="token operator">=</span> <span class="token string">"pose/mpi/pose_iter_160000.caffemodel"</span>
<span class="token comment"># Read the network into Memory</span>
net <span class="token operator">=</span> cv2<span class="token punctuation">.</span>dnn<span class="token punctuation">.</span>readNetFromCaffe<span class="token punctuation">(</span>protoFile<span class="token punctuation">,</span> weightsFile<span class="token punctuation">)</span>

<span class="token comment">#3.Read Image and Prepare Input to the Network</span>

<span class="token comment"># Read image</span>
frame <span class="token operator">=</span> cv2<span class="token punctuation">.</span>imread<span class="token punctuation">(</span><span class="token string">"single.jpg"</span><span class="token punctuation">)</span>

<span class="token comment"># Specify the input image dimensions</span>
inWidth <span class="token operator">=</span> <span class="token number">368</span>
inHeight <span class="token operator">=</span> <span class="token number">368</span>

<span class="token comment"># Prepare the frame to be fed to the network</span>
inpBlob <span class="token operator">=</span> cv2<span class="token punctuation">.</span>dnn<span class="token punctuation">.</span>blobFromImage<span class="token punctuation">(</span>frame<span class="token punctuation">,</span> <span class="token number">1.0</span> <span class="token operator">/</span> <span class="token number">255</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>inWidth<span class="token punctuation">,</span> inHeight<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> swapRB<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> crop<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

<span class="token comment"># Set the prepared object as the input blob of the network</span>
net<span class="token punctuation">.</span>setInput<span class="token punctuation">(</span>inpBlob<span class="token punctuation">)</span>


<span class="token comment"># 4. Make Predictions and Parse Keypoints</span>
output <span class="token operator">=</span> net<span class="token punctuation">.</span>forward<span class="token punctuation">(</span><span class="token punctuation">)</span>
H <span class="token operator">=</span> out<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span>
W <span class="token operator">=</span> out<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span>
<span class="token comment"># Empty list to store the detected keypoints</span>
points <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># confidence map of corresponding body's part.</span>
    probMap <span class="token operator">=</span> output<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> i<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>

    <span class="token comment"># Find global maxima of the probMap.</span>
    minVal<span class="token punctuation">,</span> prob<span class="token punctuation">,</span> minLoc<span class="token punctuation">,</span> point <span class="token operator">=</span> cv2<span class="token punctuation">.</span>minMaxLoc<span class="token punctuation">(</span>probMap<span class="token punctuation">)</span>

    <span class="token comment"># Scale the point to fit on the original image</span>
    x <span class="token operator">=</span> <span class="token punctuation">(</span>frameWidth <span class="token operator">*</span> point<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">/</span> W
    y <span class="token operator">=</span> <span class="token punctuation">(</span>frameHeight <span class="token operator">*</span> point<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">/</span> H

    <span class="token keyword">if</span> prob <span class="token operator">&amp;</span>amp<span class="token punctuation">;</span>amp<span class="token punctuation">;</span>gt<span class="token punctuation">;</span> threshold <span class="token punctuation">:</span>
        cv2<span class="token punctuation">.</span>circle<span class="token punctuation">(</span>frame<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">255</span><span class="token punctuation">,</span> <span class="token number">255</span><span class="token punctuation">)</span><span class="token punctuation">,</span> thickness<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> lineType<span class="token operator">=</span>cv<span class="token punctuation">.</span>FILLED<span class="token punctuation">)</span>
        cv2<span class="token punctuation">.</span>putText<span class="token punctuation">(</span>frame<span class="token punctuation">,</span> <span class="token string">"{}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> cv2<span class="token punctuation">.</span>FONT_HERSHEY_SIMPLEX<span class="token punctuation">,</span> <span class="token number">1.4</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">255</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> lineType<span class="token operator">=</span>cv2<span class="token punctuation">.</span>LINE_AA<span class="token punctuation">)</span>

        <span class="token comment"># Add the point to the list if the probability is greater than the threshold</span>
        points<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">else</span> <span class="token punctuation">:</span>
        points<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">)</span>

cv2<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span><span class="token string">"Output-Keypoints"</span><span class="token punctuation">,</span>frame<span class="token punctuation">)</span>
cv2<span class="token punctuation">.</span>waitKey<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
cv2<span class="token punctuation">.</span>destroyAllWindows<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 5. Draw Skeleton</span>
<span class="token keyword">for</span> pair <span class="token keyword">in</span> POSE_PAIRS<span class="token punctuation">:</span>
    partA <span class="token operator">=</span> pair<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    partB <span class="token operator">=</span> pair<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>

    <span class="token keyword">if</span> points<span class="token punctuation">[</span>partA<span class="token punctuation">]</span> <span class="token keyword">and</span> points<span class="token punctuation">[</span>partB<span class="token punctuation">]</span><span class="token punctuation">:</span>
        cv2<span class="token punctuation">.</span>line<span class="token punctuation">(</span>frameCopy<span class="token punctuation">,</span> points<span class="token punctuation">[</span>partA<span class="token punctuation">]</span><span class="token punctuation">,</span> points<span class="token punctuation">[</span>partB<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">255</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
Human Pose Estimation<span class="token punctuation">.</span>py hosted <span class="token keyword">with</span>  by GitHub
</code></pre> 
<p>输出结果如下：<br> <img src="https://images2.imgbox.com/e2/68/Y3xYxOW8_o.png" alt="在这里插入图片描述"><br> 视频结果如下：<a href="https://youtu.be/JrekUhYvGt4" rel="nofollow">Youtobe:Human-Pose-Estimation</a></p> 
<p>上述源码开源，已经上传☞此链接： <a href="https://download.csdn.net/download/weixin_51141489/87970957">代码传送门</a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/e20b50ea299c9a003e30ff18603057e5/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">python--连接oracle数据库</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/bb230e6d7d0a1e2a9a0c555e9c6b7cd4/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">开发Android原生插件，引入自己打的jar报，编译报 Unsupported class file major version 61</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>