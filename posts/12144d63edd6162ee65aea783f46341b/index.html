<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>如何用Langchain封装自定义语言模型 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/12144d63edd6162ee65aea783f46341b/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="如何用Langchain封装自定义语言模型">
  <meta property="og:description" content="为了将一个自定义的语言模型集成到 LangChain 中，你需要创建一个类来继承 langchain_core.language_models.llms.LLM 类，并实现特定的方法。下面是一些关键点，可以帮助你构思如何集成你的语言模型：
继承 LLM 类 你需要从 langchain_core.language_models.llms.LLM 类继承，并且至少实现 _call 方法。这个基类提供了一些通用的功能，比如回调管理等。
实现 _call 方法 这是最重要的方法，它定义了如何调用你的语言模型来生成文本。方法签名如下：
def _call( self, prompt: str, stop: Optional[List[str]] = None, run_manager: Optional[CallbackManagerForLLMRun] = None, **kwargs: Any, ) -&gt; str: prompt: 用户提供的文本提示。stop: 一个可选的字符串列表，这些字符串如果出现在生成的文本中，将会停止生成过程。run_manager: 一个可选的回调管理器，用于跟踪和报告生成过程中的状态。**kwargs: 其他可变的关键字参数，这些参数可能会被模型使用。 其他常用方法和属性 _llm_type 属性: 返回一个字符串标识你的语言模型的类型。_identifying_params 属性: 返回一个字典，其中包含识别该模型实例的重要参数。_check_validity_of_input 方法: 用于检查输入的有效性，这是一个可选的方法。 示例 这里是一个简化的示例，展示如何创建一个自定义的 LLM 类：
from langchain_core.language_models.llms import LLM from typing import Any, Optional, List, Mapping import requests class CustomLLM(LLM): &#34;&#34;&#34;Custom LLM implementation.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-08-13T07:29:47+08:00">
    <meta property="article:modified_time" content="2024-08-13T07:29:47+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">如何用Langchain封装自定义语言模型</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>为了将一个自定义的语言模型集成到 LangChain 中，你需要创建一个类来继承 <code>langchain_core.language_models.llms.LLM</code> 类，并实现特定的方法。下面是一些关键点，可以帮助你构思如何集成你的语言模型：</p> 
<h4><a id="_LLM__2"></a>继承 <code>LLM</code> 类</h4> 
<p>你需要从 <code>langchain_core.language_models.llms.LLM</code> 类继承，并且至少实现 <code>_call</code> 方法。这个基类提供了一些通用的功能，比如回调管理等。</p> 
<h4><a id="__call__5"></a>实现 <code>_call</code> 方法</h4> 
<p>这是最重要的方法，它定义了如何调用你的语言模型来生成文本。方法签名如下：</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">_call</span><span class="token punctuation">(</span>
    self<span class="token punctuation">,</span>
    prompt<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span>
    stop<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>List<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    run_manager<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>CallbackManagerForLLMRun<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    <span class="token operator">**</span>kwargs<span class="token punctuation">:</span> Any<span class="token punctuation">,</span>
<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">str</span><span class="token punctuation">:</span>
</code></pre> 
<ul><li><strong><code>prompt</code></strong>: 用户提供的文本提示。</li><li><strong><code>stop</code></strong>: 一个可选的字符串列表，这些字符串如果出现在生成的文本中，将会停止生成过程。</li><li><strong><code>run_manager</code></strong>: 一个可选的回调管理器，用于跟踪和报告生成过程中的状态。</li><li><strong><code>**kwargs</code></strong>: 其他可变的关键字参数，这些参数可能会被模型使用。</li></ul> 
<h4><a id="_21"></a>其他常用方法和属性</h4> 
<ul><li><strong><code>_llm_type</code> 属性</strong>: 返回一个字符串标识你的语言模型的类型。</li><li><strong><code>_identifying_params</code> 属性</strong>: 返回一个字典，其中包含识别该模型实例的重要参数。</li><li><strong><code>_check_validity_of_input</code> 方法</strong>: 用于检查输入的有效性，这是一个可选的方法。</li></ul> 
<h4><a id="_26"></a>示例</h4> 
<p>这里是一个简化的示例，展示如何创建一个自定义的 LLM 类：</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> langchain_core<span class="token punctuation">.</span>language_models<span class="token punctuation">.</span>llms <span class="token keyword">import</span> LLM
<span class="token keyword">from</span> typing <span class="token keyword">import</span> Any<span class="token punctuation">,</span> Optional<span class="token punctuation">,</span> List<span class="token punctuation">,</span> Mapping
<span class="token keyword">import</span> requests

<span class="token keyword">class</span> <span class="token class-name">CustomLLM</span><span class="token punctuation">(</span>LLM<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Custom LLM implementation."""</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> endpoint_url<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> api_key<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""Initialize with endpoint and API key."""</span>
        self<span class="token punctuation">.</span>endpoint_url <span class="token operator">=</span> endpoint_url
        self<span class="token punctuation">.</span>api_key <span class="token operator">=</span> api_key

    <span class="token decorator annotation punctuation">@property</span>
    <span class="token keyword">def</span> <span class="token function">_llm_type</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">str</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""Return type of llm."""</span>
        <span class="token keyword">return</span> <span class="token string">"custom_llm"</span>

    <span class="token decorator annotation punctuation">@property</span>
    <span class="token keyword">def</span> <span class="token function">_identifying_params</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Mapping<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">,</span> Any<span class="token punctuation">]</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""Get the identifying parameters."""</span>
        <span class="token keyword">return</span> <span class="token punctuation">{<!-- --></span><span class="token string">"endpoint_url"</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>endpoint_url<span class="token punctuation">,</span> <span class="token string">"api_key"</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>api_key<span class="token punctuation">}</span>

    <span class="token keyword">def</span> <span class="token function">_call</span><span class="token punctuation">(</span>
        self<span class="token punctuation">,</span>
        prompt<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span>
        stop<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>List<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
        run_manager<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span>CallbackManagerForLLMRun<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
        <span class="token operator">**</span>kwargs<span class="token punctuation">:</span> Any<span class="token punctuation">,</span>
    <span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">str</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""Call out to the custom LLM inference endpoint."""</span>
        headers <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">"Content-Type"</span><span class="token punctuation">:</span> <span class="token string">"application/json"</span><span class="token punctuation">,</span> <span class="token string">"Authorization"</span><span class="token punctuation">:</span> <span class="token string-interpolation"><span class="token string">f"Bearer </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>self<span class="token punctuation">.</span>api_key<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">}</span>
        data <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">"prompt"</span><span class="token punctuation">:</span> prompt<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">}</span>

        <span class="token keyword">try</span><span class="token punctuation">:</span>
            response <span class="token operator">=</span> requests<span class="token punctuation">.</span>post<span class="token punctuation">(</span>self<span class="token punctuation">.</span>endpoint_url<span class="token punctuation">,</span> headers<span class="token operator">=</span>headers<span class="token punctuation">,</span> json<span class="token operator">=</span>data<span class="token punctuation">)</span>
            response<span class="token punctuation">.</span>raise_for_status<span class="token punctuation">(</span><span class="token punctuation">)</span>
            result <span class="token operator">=</span> response<span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">"result"</span><span class="token punctuation">]</span>
        <span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>
            <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Error calling the LLM: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>e<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

        <span class="token keyword">if</span> stop <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            result <span class="token operator">=</span> enforce_stop_tokens<span class="token punctuation">(</span>result<span class="token punctuation">,</span> stop<span class="token punctuation">)</span>

        <span class="token keyword">return</span> result
</code></pre> 
<h4><a id="_76"></a>注意事项</h4> 
<ul><li><strong>错误处理</strong>: 在 <code>_call</code> 方法中处理可能出现的网络错误或无效响应。</li><li><strong>参数处理</strong>: 根据你的模型需求，可能需要处理额外的参数。</li><li><strong>回调管理</strong>: 如果需要跟踪生成过程，可以利用 <code>run_manager</code> 来触发回调。</li></ul> 
<h4><a id="_LangChain_81"></a>集成到 LangChain</h4> 
<p>一旦你定义了自定义的 LLM 类，就可以像使用其他 LangChain 支持的模型一样使用它。例如，你可以创建一个 <code>CustomLLM</code> 实例，并将其用作 LangChain 中的聊天机器人、文档检索系统或其他组件的一部分。</p> 
<h4><a id="_84"></a>示例使用</h4> 
<pre><code class="prism language-python"><span class="token keyword">from</span> langchain_community<span class="token punctuation">.</span>llms <span class="token keyword">import</span> CustomLLM

llm <span class="token operator">=</span> CustomLLM<span class="token punctuation">(</span>endpoint_url<span class="token operator">=</span><span class="token string">"https://your-endpoint-url.com"</span><span class="token punctuation">,</span> api_key<span class="token operator">=</span><span class="token string">"your-api-key"</span><span class="token punctuation">)</span>
response <span class="token operator">=</span> llm<span class="token punctuation">(</span><span class="token string">"What is the meaning of life?"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">)</span>
</code></pre> 
<p>通过以上步骤，你可以成功地将一个自定义的语言模型集成到 LangChain 中，并利用其丰富的功能。如果你有具体的模型或者更复杂的需求，可以进一步定制你的类。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/bf5f28271f4f3f308b168e543c010bb9/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">打造高效存储与访问体验：NFS共享携手Nginx负载均衡，赋能企业级数据流通与性能优化</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/7df9095e3cf53fa1b9ffe1bf8d793909/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【大数据】重塑时代的核心技术及其发展历程</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>