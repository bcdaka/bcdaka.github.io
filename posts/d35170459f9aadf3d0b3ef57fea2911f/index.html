<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>FastGPT 调用本地Whisper模型进行语音转文字 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/d35170459f9aadf3d0b3ef57fea2911f/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="FastGPT 调用本地Whisper模型进行语音转文字">
  <meta property="og:description" content="目录
一、部署Whisper模型。
二、oneapi配置
三、修改镜像中的webservice.py文件，开放跨域请求。
四、修改FastGPT代码修改
FastGPT地址:https://github.com/labring/FastGPT fastgpt默认的语音转文字模型使用的openai里面的whisper，由于我没有openai 的token故需要自己部署本地的语音转文字模型，经研究发现可以部署本地的whisper，但是该接口无法接入到oneapi（我目前没研究出来）。故直接修改fastgpt代码直接调用接口获取语音转文字内容。
注：fastgpt的麦克风权限是本地部署的才能用，或者有HTTPS证书的才可以用（麦克风权限比较重要可能涉及隐私，故浏览器对这个要求比较严格）。我目前是本地部署的fastgpt。
一、部署Whisper模型。 我部署的是whisper-asr-webservicehttps://github.com/ahmetoner/whisper-asr-webservice，地址https://github.com/ahmetoner/whisper-asr-webservice。直接docker部署的，运行如下指令
docker run -d -p 9000:9000 -e ASR_MODEL=base onerahmet/openai-whisper-asr-webservice:latest
二、oneapi配置 fastgpt中project\app\data\config.local.json中关于语音模型的配置的模型名称是whisper-1，如下图：
所以在oneapi中配置时模型名称也要写whisper-1。模型名称是一一对应的（早期版的oneapi不支持多个模型，新版本应该是修复这个问题了。我这里还是延续之前我的配置方法习惯，只写一个）
三、修改镜像中的webservice.py文件，开放跨域请求。 也可以直接修改文件再生成镜像继续后面的步骤。我是先部署了容器后，才发现跨域问题。
1、开启容器
2、进入容器 docker exec -ti 容器id /bin/bahs
3、找到要修改的文件并修改，一般容器都没有安装vim\nano等编辑器。故需要将文件复制出来修改后在传上去。
docker cp &lt;container_name_or_id&gt;:/app/app/webservice.py /usr/local/yxq/webservice.py
docker cp &lt;container_name_or_id&gt;:/app/Dockerfile /usr/local/yxq/Dockerfile
修改完后再传上去
docker cp /usr/local/yxq/webservice.py &lt;container_name_or_id&gt;:/app/app/webservice.py docker cp /usr/local/yxq/Dockerfile &lt;container_name_or_id&gt;:/app/Dockerfile
webservice.py修改如下：
增加如下代码：
from fastapi.middleware.cors import CORSMiddleware app.add_middleware( CORSMiddleware, allow_origins=[&#34;*&#34;], allow_credentials=True, allow_methods=[&#34;*&#34;], allow_headers=[&#34;*&#34;] ) 代码位置如图：
Dockerfile修改如下：RUN $POETRY_VENV/bin/pip install starlette==0.15.0
修改dockerfile镜像后，镜像启动会先将需要的包下载下来。
4、**将修改后的容器保存为新的镜像：** 使用以下命令将修改后的容器保存为新的镜像： `docker commit 容器id &lt;new_image_name&gt;:&lt;tag&gt;`">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-05-09T17:08:33+08:00">
    <meta property="article:modified_time" content="2024-05-09T17:08:33+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">FastGPT 调用本地Whisper模型进行语音转文字</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p id="main-toc"><strong>目录</strong></p> 
<p id="%E4%B8%80%E3%80%81%E9%83%A8%E7%BD%B2Whisper%E6%A8%A1%E5%9E%8B%E3%80%82-toc" style="margin-left:120px;"><a href="#%E4%B8%80%E3%80%81%E9%83%A8%E7%BD%B2Whisper%E6%A8%A1%E5%9E%8B%E3%80%82" rel="nofollow">一、部署Whisper模型。</a></p> 
<p id="%E4%BA%8C%E3%80%81oneapi%E9%85%8D%E7%BD%AE-toc" style="margin-left:120px;"><a href="#%E4%BA%8C%E3%80%81oneapi%E9%85%8D%E7%BD%AE" rel="nofollow">二、oneapi配置</a></p> 
<p id="%E4%B8%89%E3%80%81%E4%BF%AE%E6%94%B9%E9%95%9C%E5%83%8F%E4%B8%AD%E7%9A%84webservice.py%E6%96%87%E4%BB%B6%EF%BC%8C%E5%BC%80%E6%94%BE%E8%B7%A8%E5%9F%9F%E8%AF%B7%E6%B1%82%E3%80%82-toc" style="margin-left:120px;"><a href="#%E4%B8%89%E3%80%81%E4%BF%AE%E6%94%B9%E9%95%9C%E5%83%8F%E4%B8%AD%E7%9A%84webservice.py%E6%96%87%E4%BB%B6%EF%BC%8C%E5%BC%80%E6%94%BE%E8%B7%A8%E5%9F%9F%E8%AF%B7%E6%B1%82%E3%80%82" rel="nofollow">三、修改镜像中的webservice.py文件，开放跨域请求。</a></p> 
<p id="%E5%9B%9B%E3%80%81%E4%BF%AE%E6%94%B9FastGPT%E4%BB%A3%E7%A0%81%E4%BF%AE%E6%94%B9-toc" style="margin-left:120px;"><a href="#%E5%9B%9B%E3%80%81%E4%BF%AE%E6%94%B9FastGPT%E4%BB%A3%E7%A0%81%E4%BF%AE%E6%94%B9" rel="nofollow">四、修改FastGPT代码修改</a></p> 
<hr id="hr-toc"> 
<p></p> 
<h5 id="FastGPT%E5%9C%B0%E5%9D%80%3Ahttps%3A%2F%2Fgithub.com%2Flabring%2FFastGPT">FastGPT地址:<a href="https://github.com/labring/FastGPT" title="https://github.com/labring/FastGPT">https://github.com/labring/FastGPT</a></h5> 
<p>fastgpt默认的语音转文字模型使用的openai里面的whisper，由于我没有openai 的token故需要自己部署本地的语音转文字模型，经研究发现可以部署本地的whisper，但是该接口无法接入到oneapi（我目前没研究出来）。故直接修改fastgpt代码直接调用接口获取语音转文字内容。</p> 
<p>注：fastgpt的麦克风权限是本地部署的才能用，或者有HTTPS证书的才可以用（麦克风权限比较重要可能涉及隐私，故浏览器对这个要求比较严格）。我目前是本地部署的fastgpt。</p> 
<h5 id="%E4%B8%80%E3%80%81%E9%83%A8%E7%BD%B2Whisper%E6%A8%A1%E5%9E%8B%E3%80%82">一、部署Whisper模型。</h5> 
<p>我部署的是whisper-asr-webservice<a href="https://github.com/ahmetoner/whisper-asr-webservice" title="https://github.com/ahmetoner/whisper-asr-webservice">https://github.com/ahmetoner/whisper-asr-webservice</a>，地址<a href="https://github.com/ahmetoner/whisper-asr-webservice" title="https://github.com/ahmetoner/whisper-asr-webservice">https://github.com/ahmetoner/whisper-asr-webservice</a>。直接docker部署的，运行如下指令</p> 
<p>docker run -d -p 9000:9000 -e ASR_MODEL=base onerahmet/openai-whisper-asr-webservice:latest</p> 
<h5 id="%E4%BA%8C%E3%80%81oneapi%E9%85%8D%E7%BD%AE">二、oneapi配置</h5> 
<p>fastgpt中project\app\data\config.local.json中关于语音模型的配置的模型名称是whisper-1，如下图：</p> 
<p><img alt="" height="222" src="https://images2.imgbox.com/25/f8/Jyl8MBqr_o.png" width="400"></p> 
<p>所以在oneapi中配置时模型名称也要写whisper-1。模型名称是一一对应的（早期版的oneapi不支持多个模型，新版本应该是修复这个问题了。我这里还是延续之前我的配置方法习惯，只写一个）</p> 
<p><img alt="" height="1197" src="https://images2.imgbox.com/f0/b9/dHBqUn2S_o.png" width="1200"></p> 
<h5 id="%E4%B8%89%E3%80%81%E4%BF%AE%E6%94%B9%E9%95%9C%E5%83%8F%E4%B8%AD%E7%9A%84webservice.py%E6%96%87%E4%BB%B6%EF%BC%8C%E5%BC%80%E6%94%BE%E8%B7%A8%E5%9F%9F%E8%AF%B7%E6%B1%82%E3%80%82">三、修改镜像中的webservice.py文件，开放跨域请求。</h5> 
<p>也可以直接修改文件再生成镜像继续后面的步骤。我是先部署了容器后，才发现跨域问题。</p> 
<p>1、开启容器<br> 2、进入容器 docker exec -ti 容器id /bin/bahs<br> 3、找到要修改的文件并修改，一般容器都没有安装vim\nano等编辑器。故需要将文件复制出来修改后在传上去。<br>     docker cp &lt;container_name_or_id&gt;:/app/app/webservice.py /usr/local/yxq/webservice.py<br>     docker cp &lt;container_name_or_id&gt;:/app/Dockerfile /usr/local/yxq/Dockerfile<br>     修改完后再传上去<br>     docker cp /usr/local/yxq/webservice.py &lt;container_name_or_id&gt;:/app/app/webservice.py <br>     docker cp /usr/local/yxq/Dockerfile &lt;container_name_or_id&gt;:/app/Dockerfile</p> 
<p> webservice.py修改如下：</p> 
<p>        增加如下代码：</p> 
<pre><code class="language-python">from fastapi.middleware.cors import CORSMiddleware

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"]
)</code></pre> 
<p>代码位置如图：</p> 
<p><img alt="" height="1200" src="https://images2.imgbox.com/e8/8f/zepmc8qL_o.png" width="1200"></p> 
<p>Dockerfile修改如下：RUN $POETRY_VENV/bin/pip install starlette==0.15.0</p> 
<p><img alt="" height="1200" src="https://images2.imgbox.com/40/13/BEiElQje_o.png" width="1200"></p> 
<p>修改dockerfile镜像后，镜像启动会先将需要的包下载下来。<br> 4、**将修改后的容器保存为新的镜像：** 使用以下命令将修改后的容器保存为新的镜像： <br>     `docker commit 容器id &lt;new_image_name&gt;:&lt;tag&gt;`<br>     将 `&lt;new_image_name&gt;:&lt;tag&gt;` 替换为你要保存的新镜像的名称和标签。<br> 5、**删除临时容器：** 容器已经保存为新的镜像后，你可以删除临时容器：<br>     `docker rm temp_container`<br>     这将删除临时容器，释放资源。</p> 
<p>保存完新镜像后，重建容器。我使用的1panel直接更换的镜像就可以用了。先把容器停止，然后更换镜像后保存即可。</p> 
<p><img alt="" height="1200" src="https://images2.imgbox.com/ae/a5/F45UzGyf_o.png" width="1200"></p> 
<p>可使用postman验证下接口。如下：</p> 
<p><img alt="" height="850" src="https://images2.imgbox.com/29/17/4P480h3S_o.png" width="1068"></p> 
<h5 id="%E5%9B%9B%E3%80%81%E4%BF%AE%E6%94%B9FastGPT%E4%BB%A3%E7%A0%81%E4%BF%AE%E6%94%B9">四、修改FastGPT代码修改</h5> 
<p>1、先开启应用的语音输入配置，如图<img alt="" height="1200" src="https://images2.imgbox.com/5d/ad/j3bXXlaD_o.png" width="1200"></p> 
<p>2、修改文件useSpeech.ts。由于代码中使用的封装的post请求方法，而封装的requets.ts中将返回结果取值为data.data,但是上面的whisper-asr-webservice接口返回的数据只有一层data（可通过上面的postman接口截图可以看出只有一层结构），故需要单独修改下，方法如下：</p> 
<pre><code class="language-TypeScript">// const result = await POST&lt;string&gt;('http://192.168.1.39:9000/asr', formData2, {
//   timeout: 6000000,
//   headers: {
//     'Content-Type': 'multipart/form-data; charset=utf-8'
//   }
// });
// console.log("语音转文字完毕:", result);
// 发送 POST 请求
const response = await axios.post('http://192.168.1.39:9000/asr', formData2, {
  timeout: 60000, // 6000秒
  headers: {
    // 当发送 'Content-Type': 'multipart/form-data'时，不需要指定具体的boundary
    // Browser/Axios会为你处理
    // 'Content-Type': 'multipart/form-data; charset=utf-8' // 不推荐手动设置
  },
  // 告诉axios，即使返回的内容是文本，也不需要进行任何转换处理
  responseType: 'text' // 明确指定响应类型为"text"，以获得文本响应
});
// 使用 Axios，成功的响应数据在 response 中
console.log("语音转文字完毕:", response);
onFinish(response.data);</code></pre> 
<p>注释掉的是原先的代码，由于返回结果取值是data.data导致取值是undefined。故使用后面的代码代替 。超时时间尽量长点，如果部署模型的服务器配置低则接口会响应较慢。</p> 
<p>效果如下：</p> 
<p><img alt="" height="1188" src="https://images2.imgbox.com/d5/2d/X3zFjHMz_o.gif" width="1200"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/79aabd2a8bd481393e647e27dc2ea1c6/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">AI语言战争再起：阿里巴巴发布通义千问Qwen2.5追平GPT-4 Turbo，中文能力傲视群雄</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/8d7d3233cf484d0d60014adc6e26855e/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">MongoDB Atlas Vector Search与Amazon Bedrock集成已全面可用</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>