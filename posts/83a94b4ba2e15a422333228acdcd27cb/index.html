<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>T-Eval：大模型智能体能力评测基准解读 | ACL 2024 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/83a94b4ba2e15a422333228acdcd27cb/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="T-Eval：大模型智能体能力评测基准解读 | ACL 2024">
  <meta property="og:description" content="AI Agent（智能体）作为大模型的重要应用模式，能够通过使用外部工具来执行复杂任务，完成多步骤的工作流程。为了更全面地评估模型的工具使用能力，司南及合作伙伴团队推出了T-Eval评测基准，相关成果论文已被ACL 2024主会录用，点击链接可查看原文：https://arxiv.org/abs/2312.14033。
T-Eval评测基准 使用了工具的大语言模型有着惊艳的问题解决能力，但是如何评估模型的工具使用能力还有很大的探索空间。现有评估方法通常只关注模型处理单步骤任务时的工具调用表现，缺少在多步骤复杂任务场景下模型使用工具能力的评估。
因此，为了更全面地评估大语言模型的工具使用能力，司南及合作伙伴团队推出了 T-Eval (a step-by-step Tool Evaluation benchmark for LLMs) 评测基准，相较于之前整体评估模型的方式，论文中将大模型的工具使用分解为多个子过程，包括规划、推理、检索、理解、指令跟随和审查。
规划（PLAN）：制定工具调用策略。
推理（REASON）：理解工具使用环境和自身功能，生成逻辑思考内容。
检索（RETRIEVE）：从给定的工具列表中选择合适的工具。
理解（UNDERSTAND）：正确理解工具使用的参考文档和所需参数。
指令跟随（INSTRUCT）：生成指定格式的工具调用请求。
审查（REVIEW）：评估每个工具调用执行的结果，确保回答满足预期目标。
这种分解方法不仅能够帮助我们更全面地理解大模型在工具使用方面的能力，还能够识别出模型在工具使用过程中的主要瓶颈。我们在T-Eval上进行了广泛的实验，并进行了深入分析。实验结果表明，T-Eval对模型的单过程能力和综合能力具有一致评价，即单个能力得分越高，在复杂任务中的表现就越好。
T-Eval构建过程 T-Eval 的构建主要包括 3 个阶段：工具收集、指令生成和黄金方案标注。首先，我们根据可用性和使用率，挑选了15种基本工具，涵盖了研究、旅行、娱乐、网络、生活和金融等多个领域。此外，还为每个工具生成了详细的API文档，以减少因工具描述不充分而导致的工具调用失败案例。
然后，我们利用 GPT-3.5 生成了初始问题，并通过 GPT-4 进一步完善问题。之后，我们开发了一个多智能体框架，利用所提供的工具解决问题，同时收集解决方案路径和工具响应。最后，我们使用人类专家来挑选高质量样本。
T-Eval主要贡献 （1）细粒度评测：T-Eval将评测过程分解为多个子任务，分别评估模型在工具使用上的细粒度能力。
（2）多智能体数据生成：使用了由人类专家验证的多智能体数据生成流程，显著减少了外部因素的影响，使评测结果更加稳定、公平。
（3）广泛实验：通过在各种大模型上的广泛实验，验证了T-Eval的有效性和普适性，为当前大语言模型的工具使用能力瓶颈提供了宝贵的见解，并为改进工具使用能力提供了新的视角。
评测结果 我们在 T-Eval 上对 20 种大语言模型进行了评测，包括基于API的商业模型和开源模型。结果显示，GPT-4在整体评分上取得了最高分，显示出其卓越的工具使用能力。对于开源模型，我们对三种不同规模的模型进行了实验，它们的尺寸大约是7B、13B和70B，可以发现，随着模型参数的增加，其表现也更加优秀。特别是Qwen-72B模型，其总得分已接近API模型水平。
T-Eval 现已加入 OpenCompass 评测平台，更多详细内容可参考以下链接！
GitHub：https://github.com/open-compass/T-EvalOpenCompass官网：https://hub.opencompass.org.cn/dataset-detail/T-Eval联系我们：opencompass@pjlab.org.cn 欢迎大家关注“司南评测体系”微信公众号，获取更多大模型评测相关知识~">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-07-29T11:46:41+08:00">
    <meta property="article:modified_time" content="2024-07-29T11:46:41+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">T-Eval：大模型智能体能力评测基准解读 | ACL 2024</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p><strong>AI</strong><strong> Agent（智能体）</strong>作为大模型的重要应用模式，能够通过使用外部工具来执行复杂任务，完成多步骤的工作流程。为了更全面地评估模型的工具使用能力，司南及合作伙伴团队推出了<strong>T-Eval评测基准，相关成果论文已被</strong><strong>ACL</strong><strong> 2024主会录用，点击链接可查看原文</strong>：https://arxiv.org/abs/2312.14033。</p> 
<h3>T-Eval评测基准</h3> 
<p>使用了工具的大语言模型有着惊艳的问题解决能力，但是如何评估模型的工具使用能力还有很大的探索空间。现有评估方法通常只关注模型处理单步骤任务时的工具调用表现，缺少在多步骤复杂任务场景下模型使用工具能力的评估。</p> 
<p>因此，为了更全面地评估大语言模型的工具使用能力，司南及合作伙伴团队推出了<strong> T-Eval (a step-by-step </strong><strong>Tool Evaluation</strong><strong> benchmark for LLMs)</strong> 评测基准，相较于之前整体评估模型的方式，论文中将大模型的工具使用分解为多个子过程，包括<strong>规划、推理、检索、理解</strong><strong>、指令跟随</strong><strong>和审查</strong><strong>。</strong></p> 
<ul><li> <p><strong>规划（PLAN）</strong>：制定工具调用策略。</p> </li><li> <p><strong>推理（REASON）</strong>：理解工具使用环境和自身功能，生成逻辑思考内容。</p> </li><li> <p><strong>检索（RETRIEVE）</strong>：从给定的工具列表中选择合适的工具。</p> </li><li> <p><strong>理解（UNDERSTAND）</strong>：正确理解工具使用的参考文档和所需参数。</p> </li><li> <p><strong>指令跟随（INSTRUCT）</strong>：生成指定格式的工具调用请求。</p> </li><li> <p><strong>审查（REVIEW）</strong>：评估每个工具调用执行的结果，确保回答满足预期目标。</p> </li></ul> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/a8/64/drXPohMh_o.png"></p> 
<p>这种分解方法不仅能够帮助我们更全面地理解大模型在工具使用方面的能力，还能够识别出模型在工具使用过程中的主要瓶颈。我们在T-Eval上进行了广泛的实验，并进行了深入分析。实验结果表明，T-Eval对模型的单过程能力和综合能力具有一致评价，即单个能力得分越高，在复杂任务中的表现就越好。</p> 
<h3>T-Eval构建过程</h3> 
<p>T-Eval 的构建主要包括 3 个阶段：<strong>工具收集、指令生成和</strong><strong>黄金方案</strong><strong>标注</strong>。首先，我们根据可用性和使用率，挑选了15种基本工具，涵盖了研究、旅行、娱乐、网络、生活和金融等多个领域。此外，还为每个工具生成了详细的API文档，以减少因工具描述不充分而导致的工具调用失败案例。</p> 
<p>然后，我们利用 GPT-3.5 生成了初始问题，并通过 GPT-4 进一步完善问题。之后，我们开发了一个多智能体框架，利用所提供的工具解决问题，同时收集解决方案路径和工具响应。最后，我们使用人类专家来挑选高质量样本。</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/d8/a3/n0jyHeox_o.png"></p> 
<h3>T-Eval主要贡献</h3> 
<p>（1）<strong>细粒度评测：</strong>T-Eval将评测过程分解为多个子任务，分别评估模型在工具使用上的细粒度能力。</p> 
<p>（2）<strong>多智能体数据生成：</strong>使用了由人类专家验证的多智能体数据生成流程，显著减少了外部因素的影响，使评测结果更加稳定、公平。</p> 
<p>（3）<strong>广泛实验：</strong>通过在各种大模型上的广泛实验，验证了T-Eval的有效性和普适性，为当前大语言模型的工具使用能力瓶颈提供了宝贵的见解，并为改进工具使用能力提供了新的视角。</p> 
<h3>评测结果</h3> 
<p>我们在 T-Eval 上对 20 种大语言模型进行了评测，包括基于API的商业模型和开源模型。结果显示，GPT-4在整体评分上取得了最高分，显示出其卓越的工具使用能力。对于开源模型，我们对三种不同规模的模型进行了实验，它们的尺寸大约是7B、13B和70B，可以发现，随着模型参数的增加，其表现也更加优秀。特别是Qwen-72B模型，其总得分已接近API模型水平。</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/eb/05/hMO9QKgO_o.png"></p> 
<p>T-Eval 现已加入 OpenCompass 评测平台，更多详细内容可参考以下链接！</p> 
<ul><li>GitHub：<a class="link-info" href="https://github.com/open-compass/T-Eval" title="https://github.com/open-compass/T-Eval">https://github.com/open-compass/T-Eval</a></li><li>OpenCompass官网：<a class="link-info" href="https://hub.opencompass.org.cn/dataset-detail/T-Eval" rel="nofollow" title="https://hub.opencompass.org.cn/dataset-detail/T-Eval">https://hub.opencompass.org.cn/dataset-detail/T-Eval</a></li><li>联系我们：opencompass@pjlab.org.cn</li></ul> 
<hr> 
<p>欢迎大家关注<strong>“司南评测体系”微信公众号</strong>，获取更多大模型评测相关知识~</p> 
<p><img alt="" height="258" src="https://images2.imgbox.com/90/ce/uSqPAcux_o.jpg" width="258">       </p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/9722ae1499a86a6373045738698b9a27/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Linux初学基本命令</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/5f54c923a935e842efdda4127d0a5872/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">51单片机嵌入式开发：21、STC89C52R控制抢答器&#43;数码管&#43;后台显示&#43;LCD1602x显示</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>