<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Vision Transformer(ViT)模型原理及PyTorch逐行实现 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/315c15138656ef80f7cdbd04db4b8f74/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="Vision Transformer(ViT)模型原理及PyTorch逐行实现">
  <meta property="og:description" content="Vision Transformer(ViT)模型原理及PyTorch逐行实现 一、TRM模型结构 1.Encoder Position Embedding 注入位置信息Multi-head Self-attention 对各个位置的embedding融合（空间融合）LayerNorm &amp; ResidualFeedforward Neural Network 对每个位置上单独仿射变换（通道融合） Linear1(large)Linear2(d_model) LayerNorm &amp; Residual 2.Decoder Position EmbeddingCasual Multi-head Self-attentionLayerNorm &amp; ResidualMemory-base Multi-head Cross-attentionLayerNorm &amp; ResidualFeedforward Neural Network Linear1(large)Linear2(d_model) LayerNorm &amp; Residual 二、TRM使用类型 Encoder only 【 ViT 所使用的】 BERT、分类任务、非流式任务 Decoder only GPT系列、语言建模、自回归生成任务、流式任务 Encoder-Decoder 机器翻译、语音识别 三、TRM特点 无先验假设（例如：局部关联性、有序建模性）核心计算在于自注意力机制，平方复杂度数据量的要求与归纳偏置【人类通过归纳法得到的经验，把这些经验带入到模型中，很多事物的共性】的引入成反比 四、Vision Transformer(ViT) DNN perspective 图像的信息量主要还是聚集在一块区域上 image2patch 将图片切分成很多个块patch2embedding 将每个块转换为向量 CNN perspective 从卷积的角度得到向量 2D convolution over image 二维卷积flatten the output feature map 把输出的卷积图拉直 class token embedding 占位符position embedding interpolation when inference Transformer Encoder 只使用的Encoderclassification head 最后分类 五、ViT论文讲解 ​ 首先将一副图片分为很多个块，每个块的大小都是不会变化的，图片即使大一点，只是序列更长一点。先左到右，再上到下，把图片拉直成一个序列的形状。把每个块中的像素点进行归一化，范围变为0到1之间，再把块里面的所有值通过一个线性变换映射到模型的维度，得到patchembedding，得到以后，我们为了做分类任务，还需要在序列的开头加上一个可训练的embedding，这个是随机初始化的。这样就构造出了一个n&#43;1长度的序列，然后我们再加入position embedding，加上后的这个序列的表征就可以送入到TRM的encoder当中，最后取出结果中的我们加入的可训练的embedding位置上的值（输出状态），经过一个MLP，得到各个类别的概率分布，再通过一个交叉熵函数算出分类的loss，这样就完成了一个ViT模型的搭建。">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-09-08T11:22:40+08:00">
    <meta property="article:modified_time" content="2024-09-08T11:22:40+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Vision Transformer(ViT)模型原理及PyTorch逐行实现</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="Vision_TransformerViTPyTorch_0"></a>Vision Transformer(ViT)模型原理及PyTorch逐行实现</h2> 
<h3><a id="TRM_2"></a>一、TRM模型结构</h3> 
<h4><a id="1Encoder_4"></a>1.Encoder</h4> 
<ol><li>Position Embedding 注入位置信息</li><li><strong>Multi-head Self-attention</strong> 对各个位置的embedding融合（空间融合）</li><li>LayerNorm &amp; Residual</li><li>Feedforward Neural Network 对每个位置上单独仿射变换（通道融合） 
  <ul><li>Linear1(large)</li><li>Linear2(d_model)</li></ul> </li><li>LayerNorm &amp; Residual</li></ol> 
<h4><a id="2Decoder_14"></a>2.Decoder</h4> 
<ol><li>Position Embedding</li><li><strong>Casual Multi-head Self-attention</strong></li><li>LayerNorm &amp; Residual</li><li><strong>Memory-base Multi-head Cross-attention</strong></li><li>LayerNorm &amp; Residual</li><li>Feedforward Neural Network 
  <ul><li>Linear1(large)</li><li>Linear2(d_model)</li></ul> </li><li>LayerNorm &amp; Residual</li></ol> 
<h3><a id="TRM_26"></a>二、TRM使用类型</h3> 
<ol><li>Encoder only 【 ViT 所使用的】 
  <ul><li>BERT、分类任务、非流式任务</li></ul> </li><li>Decoder only 
  <ul><li>GPT系列、语言建模、自回归生成任务、流式任务</li></ul> </li><li>Encoder-Decoder 
  <ul><li>机器翻译、语音识别</li></ul> </li></ol> 
<h3><a id="TRM_35"></a>三、TRM特点</h3> 
<ol><li>无先验假设（例如：局部关联性、有序建模性）</li><li>核心计算在于自注意力机制，平方复杂度</li><li>数据量的要求与<strong>归纳偏置</strong>【人类通过归纳法得到的经验，把这些经验带入到模型中，很多事物的共性】的引入成反比</li></ol> 
<h3><a id="Vision_TransformerViT_41"></a>四、Vision Transformer(ViT)</h3> 
<ol><li>DNN perspective 图像的信息量主要还是聚集在一块区域上 
  <ul><li>image2patch 将图片切分成很多个块</li><li>patch2embedding 将每个块转换为向量</li></ul> </li><li>CNN perspective 从卷积的角度得到向量 
  <ul><li>2D convolution over image 二维卷积</li><li>flatten the output feature map 把输出的卷积图拉直</li></ul> </li><li>class token embedding 占位符</li><li>position embedding 
  <ul><li>interpolation when inference</li></ul> </li><li>Transformer Encoder 只使用的Encoder</li><li>classification head 最后分类</li></ol> 
<h3><a id="ViT_55"></a>五、ViT论文讲解</h3> 
<p><img src="https://images2.imgbox.com/4f/a3/i1Cw3CZn_o.png" alt="image-20240908092056541"></p> 
<p>​ 首先将一副图片分为很多个块，每个块的大小都是不会变化的，图片即使大一点，只是序列更长一点。先左到右，再上到下，把图片拉直成一个序列的形状。把每个块中的像素点进行归一化，范围变为0到1之间，再把块里面的所有值通过一个线性变换映射到模型的维度，得到patchembedding，得到以后，我们为了做分类任务，还需要在序列的开头加上一个可训练的embedding，这个是随机初始化的。这样就构造出了一个n+1长度的序列，然后我们再加入position embedding，加上后的这个序列的表征就可以送入到TRM的encoder当中，最后取出结果中的我们加入的可训练的embedding位置上的值（输出状态），经过一个MLP，得到各个类别的概率分布，再通过一个交叉熵函数算出分类的loss，这样就完成了一个ViT模型的搭建。</p> 
<h3><a id="_61"></a>六、代码实现</h3> 
<h4><a id="1convert_image_to_embedding_vector_sequence_63"></a>1.convert image to embedding vector sequence</h4> 
<p>1.通过DNN实现</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F

<span class="token keyword">def</span> <span class="token function">image2emb_naive</span><span class="token punctuation">(</span>image<span class="token punctuation">,</span>patch_size<span class="token punctuation">,</span>weight<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># image shape: bs*channel*h*w</span>
    patch <span class="token operator">=</span> F<span class="token punctuation">.</span>unfold<span class="token punctuation">(</span>image<span class="token punctuation">,</span>kernel_size<span class="token operator">=</span>patch_size<span class="token punctuation">,</span>stride<span class="token operator">=</span>patch_size<span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">)</span>
    patch_embedding <span class="token operator">=</span> patch @ weight
    <span class="token keyword">return</span> patch_embedding

<span class="token comment"># test code for image2emb</span>
bs<span class="token punctuation">,</span>ic<span class="token punctuation">,</span>image_h<span class="token punctuation">,</span>image_w<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">8</span>
patch_size<span class="token operator">=</span><span class="token number">4</span> <span class="token comment"># 每个块的大小为4*4（自定义）</span>
model_dim<span class="token operator">=</span><span class="token number">8</span> <span class="token comment">#将每个块映射成长度为8的向量（自定义）</span>
patch_depth<span class="token operator">=</span>patch_size<span class="token operator">*</span>patch_size<span class="token operator">*</span>ic
image<span class="token operator">=</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>bs<span class="token punctuation">,</span>ic<span class="token punctuation">,</span>image_h<span class="token punctuation">,</span>image_w<span class="token punctuation">)</span> <span class="token comment">#初始化</span>
weight<span class="token operator">=</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>patch_depth<span class="token punctuation">,</span>model_dim<span class="token punctuation">)</span><span class="token comment">#初始化</span>

patch_embedding_navie<span class="token operator">=</span>image2emb_navie<span class="token punctuation">(</span>image<span class="token punctuation">,</span>patch_size<span class="token punctuation">,</span>weight<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>patch_embedding_naive<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment"># [1,4,8],分成四块了，每块对应一个长度为8的向量 </span>
</code></pre> 
<p>2.通过CNN实现</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F

<span class="token keyword">def</span> <span class="token function">image2emb_conv</span><span class="token punctuation">(</span>image<span class="token punctuation">,</span>kernel<span class="token punctuation">,</span>stride<span class="token punctuation">)</span><span class="token punctuation">:</span>
    conv_output<span class="token operator">=</span>F<span class="token punctuation">.</span>conv2d<span class="token punctuation">(</span>image<span class="token punctuation">,</span>kernel<span class="token punctuation">,</span>stride<span class="token operator">=</span>stride<span class="token punctuation">)</span> <span class="token comment"># bs*oc*oh*ow</span>
    bs<span class="token punctuation">,</span>oc<span class="token punctuation">,</span>oh<span class="token punctuation">,</span>ow<span class="token operator">=</span>conv_output<span class="token punctuation">.</span>shape
    patch_embedding<span class="token operator">=</span>conv_output<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span>bs<span class="token punctuation">,</span>oc<span class="token punctuation">,</span>oh<span class="token operator">*</span>ow<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> patch_embedding

<span class="token comment"># test code for image2emb</span>
bs<span class="token punctuation">,</span>ic<span class="token punctuation">,</span>image_h<span class="token punctuation">,</span>image_w<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">8</span>
patch_size<span class="token operator">=</span><span class="token number">4</span>
model_dim<span class="token operator">=</span><span class="token number">8</span>
patch_depth<span class="token operator">=</span>patch_size<span class="token operator">*</span>patch_size<span class="token operator">*</span>ic
image<span class="token operator">=</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>bs<span class="token punctuation">,</span>ic<span class="token punctuation">,</span>image_h<span class="token punctuation">,</span>image_w<span class="token punctuation">)</span>
weight<span class="token operator">=</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>patch_depth<span class="token punctuation">,</span>model_dim<span class="token punctuation">)</span> <span class="token comment">#model_dim是输出通道数目，patch_depth是卷积核的面积乘以输入通道数</span>

kernel<span class="token operator">=</span>weight<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>ic<span class="token punctuation">,</span>patch_size<span class="token punctuation">,</span>patch_size<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># oc*ic*kh*kw</span>
patch_embedding_conv<span class="token operator">=</span>image2emb_conv<span class="token punctuation">(</span>image<span class="token punctuation">,</span>kernel<span class="token punctuation">,</span>patch_size<span class="token punctuation">)</span> <span class="token comment"># 二维卷积的方法得到embedding</span>
</code></pre> 
<h4><a id="2prepend_CLS_token_embedding_115"></a>2.prepend CLS token embedding</h4> 
<pre><code class="prism language-python">cls_token_embedding <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>model_dim<span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
token_embedding <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span>bs<span class="token punctuation">,</span>cls_token_embedding<span class="token punctuation">]</span><span class="token punctuation">,</span>patch_embedding_conv<span class="token punctuation">]</span><span class="token punctuation">,</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
</code></pre> 
<p>​ 提问：本身cls_token_embedding没有和任何样本矩阵有乘法联系，最后训练出来的也是一张确定的表，在做inference的时候，完全是一个常数的作用。送入transformer后，又与其他矩阵做了MHA，没搞懂用意何在啊？</p> 
<p>​ 答：有联系啊，就是与其他时刻的sample做MHSA。这个token其实是取代了avg pool的作用，也就是说，你可以用avg pool得到分类的logits，也可以用采用cls token来得到分类的logits</p> 
<p>​ <strong>注意</strong>：cls_token_embedding作为batch_size中每一个序列的开始，应该对于每一个序列的开始都torch.cat同样的一个cls_token_embedding，然后都是对这同一个cls_token_embedding进行训练，所以这里的cls token embedding应该是二维的，1*model_dim，与batchsize无关。</p> 
<h4><a id="3add_position_embedding_128"></a>3.add position embedding</h4> 
<pre><code class="prism language-python">max_num_token<span class="token operator">=</span><span class="token number">16</span> <span class="token comment">#自定义</span>
position_embedding_table <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>max_num_token<span class="token punctuation">,</span>model_dim<span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
seq_len<span class="token operator">=</span>token_embedding<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token comment"># 刚刚的1+4</span>
position_embedding<span class="token operator">=</span>torch<span class="token punctuation">.</span>tile<span class="token punctuation">(</span>position_embedding_table<span class="token punctuation">[</span><span class="token punctuation">:</span>seq_len<span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span>token_embedding<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># 5,bs,1,1</span>
token_embedding <span class="token operator">+=</span> position_embedding
</code></pre> 
<h4><a id="4pass_embedding_to_Transformer_Encoder_138"></a>4.pass embedding to Transformer Encoder</h4> 
<pre><code class="prism language-python">encoder_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>TransformerEncoderLayer<span class="token punctuation">(</span>d_model<span class="token operator">=</span>model_dim<span class="token punctuation">,</span>nhead<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">)</span>
transformer_encoder<span class="token operator">=</span>nn<span class="token punctuation">.</span>TransformerEncoder<span class="token punctuation">(</span>encoder_layer<span class="token punctuation">,</span>num_layers<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">)</span>
encoder_output<span class="token operator">=</span>transformer_encoder<span class="token punctuation">(</span>token_embedding<span class="token punctuation">)</span>
</code></pre> 
<h4><a id="5do_classification_146"></a>5.do classification</h4> 
<pre><code class="prism language-python">cls_token_output<span class="token operator">=</span>encoder_output<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token comment">#拿到TRM的输出值</span>
num_classes<span class="token operator">=</span><span class="token number">10</span> <span class="token comment"># 自定义的类别数目</span>
label<span class="token operator">=</span>torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token punctuation">(</span>bs<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 自定义的生成的label</span>
linear_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>model_dim<span class="token punctuation">,</span>num_classes<span class="token punctuation">)</span> 
logits <span class="token operator">=</span> linear_layer<span class="token punctuation">(</span>cls_token_output<span class="token punctuation">)</span>
loss_fn<span class="token operator">=</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
loss<span class="token operator">=</span>loss_fn<span class="token punctuation">(</span>logits<span class="token punctuation">,</span>label<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>loss<span class="token punctuation">)</span>
</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/fb213328e7b66a1830193a2a462818de/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">ue5 AI追角色后失去目标解决办法</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/9cca99ef11575f804c0f08ee87b0aeaf/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Java 21的Preferences API的笔记</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>