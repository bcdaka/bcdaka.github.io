<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【计算机视觉】目标跟踪任务概述和算法介绍 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/f2d9e59f8cecb079663acc0a271437ea/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="【计算机视觉】目标跟踪任务概述和算法介绍">
  <meta property="og:description" content="一、前言 1.1：目标跟踪VS目标检测：区别和联系 区别：
任务目标
目标跟踪任务的目标是在视频序列中跟踪一个特定目标的位置，即给定第一帧中的目标位置后，在后续帧中确定目标的位置。而目标检测任务的目标是在静态图像中检测和定位出现的目标，即在给定图像中找到所有目标的边界框。 数据输入
目标跟踪任务通常涉及处理视频序列，需要在连续的帧之间跟踪特定的目标。而目标检测任务则处理静态图像，每个图像都是独立的输入。 上下文信息利用
在目标跟踪任务中，由于连续帧之间存在时间和空间上的相关性，可以利用先前帧中的信息来帮助确定目标的位置。(前面所讲的限制区域搜索策略,就是利用这种连续帧之间的相关性,来确定下一帧的搜索区间)而目标检测任务通常只使用单个图像，缺乏时间上的上下文信息。(联系之前做的安全帽视频检测,虽然也是对视频进行处理,但是本质还是每一帧都是一个单独的处理对象,无任何联系) 联系
目标表示
目标跟踪任务和目标检测任务都需要对目标进行有效的表示，通常使用边界框来表示目标的位置和大小。 特征提取
两个任务都需要从输入数据中提取特征以表示目标。常见的特征提取方法包括使用卷积神经网络（CNN）提取图像特征或使用光流等方法提取视频序列中的运动特征。 目标类别识别
虽然目标跟踪任务的主要目标是确定目标的位置，但有时也需要对目标进行类别识别，即确定目标属于哪个类别。在目标检测任务中，类别识别是一个重要的子任务，需要确定每个检测到的目标的类别标签。 1.2：目标跟踪任务分类 单目标跟踪：给定一个目标，追踪这个目标的位置
单目标，单摄像头
无模型的，只有第一帧指定的 框
短期跟踪，不支持重新检测，丢失后，就跟踪失败
跟踪器不使用任何未来帧。主要逻辑 启动跟踪器 Setup tracker 设置目标区域 Read initial object region and first image 初始化跟踪器 Initialize tracker with provided region and image 循环 loop 读取下一张图像 Read next image 图像为空 if image is empty then 跳出循环 Break the tracking loop end if 更新跟踪器 Update tracker with provided image 记录目标区域 Write region to file 结束循环 end loop 清理跟踪器 Cleanup tracker 多目标跟踪：追踪多个目标的位置">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-03-11T21:47:05+08:00">
    <meta property="article:modified_time" content="2024-03-11T21:47:05+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【计算机视觉】目标跟踪任务概述和算法介绍</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-dracula">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_0"></a>一、前言</h2> 
<h3><a id="11VS_1"></a>1.1：目标跟踪VS目标检测：区别和联系</h3> 
<p><b><font color="#cb2582"><i>区别：</i></font></b></p> 
<ol><li> <p><b><font color="#e17055">任务目标</font></b></p> 
  <ul><li>目标跟踪任务的目标是在<strong>视频序列</strong>中跟踪一个<strong>特定目标</strong>的位置，即<strong>给定第一帧中的目标位置后，在后续帧中确定目标的位置。</strong></li><li>而目标检测任务的目标是在<strong>静态图像</strong>中检测和定位出现的目标，即在<strong>给定图像中找到所有目标的边界框</strong>。</li></ul> </li><li> <p><b><font color="#e17055">数据输入</font></b></p> 
  <ul><li>目标跟踪任务通常涉及处理<strong>视频序列</strong>，需要在<strong>连续的帧之间跟踪特定的目标</strong>。</li><li>而目标检测任务则处理<strong>静态图像</strong>，每个图像都是<strong>独立的输入</strong>。</li></ul> </li><li> <p><b><font color="#e17055">上下文信息利用</font></b></p> 
  <ul><li>在目标跟踪任务中，由于<strong>连续帧之间存在时间和空间上的相关性</strong>，可以利用<strong>先前帧中的信息</strong>来帮助确定目标的位置。(前面所讲的限制区域搜索策略,就是利用这种连续帧之间的相关性,来确定下一帧的搜索区间)</li><li>而目标检测任务通常只使用<strong>单个图像</strong>，缺乏时间上的上下文信息。(联系之前做的安全帽视频检测,虽然也是对视频进行处理,但是本质还是每一帧都是一个单独的处理对象,无任何联系)</li></ul> </li></ol> 
<p><b><font color="#266ecd"><i>联系</i></font></b></p> 
<ol><li> <p><b><font color="#70a1ff">目标表示</font></b></p> 
  <ul><li>目标跟踪任务和目标检测任务都需要对目标进行有效的表示，通常使用<strong>边界框</strong>来<strong>表示目标的位置和大小</strong>。</li></ul> </li><li> <p><b><font color="#70a1ff">特征提取</font></b></p> 
  <ul><li>两个任务都需要<strong>从输入数据中提取特征以表示目标</strong>。常见的特征提取方法包括使用卷积神经网络（CNN）提取图像特征或使用<strong>光流</strong>等方法提取视频序列中的运动特征。</li></ul> </li><li> <p><b><font color="#70a1ff">目标类别识别</font></b></p> 
  <ul><li>虽然目标跟踪任务的主要目标是<strong>确定目标的位置</strong>，但有时也需要对目标进行<strong>类别识别</strong>，即确定目标属于哪个类别。在目标检测任务中，<strong>类别识别是一个重要的子任务</strong>，需要确定每个检测到的目标的类别标签。</li></ul> </li></ol> 
<h3><a id="12_27"></a>1.2：目标跟踪任务分类</h3> 
<ul><li> <p><b><i><font color="#00972e">单目标跟踪：</font>给定一个目标，追踪这个目标的位置</i></b></p> 
  <ul><li>单目标，单摄像头<br> 无模型的，只有第一帧指定的 框<br> 短期跟踪，不支持重新检测，丢失后，就跟踪失败<br> 跟踪器不使用任何未来帧。</li><li>主要逻辑</li></ul> <pre><code class="prism language-cpp">启动跟踪器 Setup tracker
    设置目标区域 Read initial object region <span class="token operator">and</span> first image
    初始化跟踪器 Initialize tracker with provided region <span class="token operator">and</span> image
    循环 loop
        读取下一张图像 Read next image
        图像为空 <span class="token keyword">if</span> image is empty then
            跳出循环 Break the tracking loop
        end <span class="token keyword">if</span>
        更新跟踪器 Update tracker with provided image
        记录目标区域 Write region to file
    结束循环 end loop
    清理跟踪器 Cleanup tracker
</code></pre> </li><li> <p><b><i><font color="#00972e">多目标跟踪：</font>追踪多个目标的位置</i></b></p> </li><li> <p><b><i><font color="#00972e">Person Re-ID - 行人重识别</font><br> </i></b>利用计算机视觉技术判断图像或者<strong>视频序列</strong>中是否存在<strong>特定行人</strong>的技术。广泛被认为是一个图像检索的子问题。给定一个监控行人图像，检索<strong>跨设备</strong>下的该行人图像。旨在弥补固定的摄像头的视觉局限，并可与<strong>行人检测/行人跟踪技术</strong>相结合。</p> </li><li> <p><b><i><font color="#00972e">MTMCT - 多目标多摄像头跟踪（Multi-target Multi-camera Tracking）：</font>跟踪多个摄像头拍摄的多个人</i></b></p> </li><li> <p><b><i><font color="#00972e">姿态跟踪</font></i></b></p> 
  <ul><li><strong>Step1：姿态估计（Pose Estimation）</strong>：在每一帧中检测人体的关键点。这可能是基于深度学习的方法，如使用卷积神经网络（CNN）来预测关键点的位置。</li><li><strong>Step2：姿态关联（Pose Association）：</strong> 在视频序列的连续帧中将检测到的人体姿态与<strong>之前跟踪的姿态</strong>相匹配，以确保同一个人的姿态在整个视频中能够被正确地关联起来</li></ul> </li></ul> 
<p>按照<b><font color="#e84393">任务计算类型</font></b>又可以分为以下2类</p> 
<ul><li><b><i><font color="#3498db"> 在线跟踪：</font></i></b>在线跟踪需要实时处理任务，通过过去和现在帧来跟踪未来帧中物体的位置。</li><li><b><i><font color="#3498db">离线跟踪 ：</font></i></b>离线跟踪是离线处理任务，可以通过过去、现在和未来的帧来推断物体的位置，因此准确率会在线跟踪高。</li></ul> 
<h3><a id="13_61"></a>1.3：目标跟踪的困难点</h3> 
<ul><li> <p><strong>形态变化</strong> - 姿态变化是目标跟踪中常见的干扰问题。运动目标发生姿态变化时, 会导致它的特征以及外观模型发生改变, 容易导致跟踪失败。例如:体育比赛中的运动员、马路上的行人。</p> </li><li> <p><strong>尺度变化</strong> - 尺度的自适应也是目标跟踪中的关键问题。当目标尺度缩小时, 由于跟踪框不能自适应跟踪, 会将很多背景信息包含在内, 导致目标模型的更新错误:当目标尺度增大时, 由于跟踪框不能将目标完全包括在内, 跟踪框内目标信息不全, 也会导致目标模型的更新错误。因此, 实现尺度自适应跟踪是十分必要的。</p> </li><li> <p><strong>遮挡与消失</strong> - 目标在运动过程中可能出现被遮挡或者短暂的消失情况。当这种情况发生时, 跟踪框容易将遮挡物以及背景信息包含在跟踪框内, 会导致后续帧中的跟踪目标漂移到遮挡物上面。若目标被完全遮挡时, 由于找不到目标的对应模型, 会导致跟踪失败。</p> </li><li> <p><strong>图像模糊</strong> - 光照强度变化, 目标快速运动, 低分辨率等情况会导致图像模型, 尤其是在运动目标与背景相似的情况下更为明显。因此, 选择有效的特征对目标和背景进行区分非常必要。</p> </li></ul> 
<h2><a id="_70"></a>二、目标跟踪算法介绍</h2> 
<p><img src="https://images2.imgbox.com/d6/14/5xUm5Us3_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="21_74"></a>2.1：生成式模型</h3> 
<blockquote> 
 <p>参考：<a href="http://www.cse.psu.edu/~rtc12/CSE598C/meanshiftIntro.pdf" rel="nofollow">http://www.cse.psu.edu/~rtc12/CSE598C/meanshiftIntro.pdf</a></p> 
</blockquote> 
<p>Appearance-Based Tracking 代表算法：<strong>均值漂移算法(Mean Shift)、LK光流</strong>等。</p> 
<p><img src="https://images2.imgbox.com/dc/d9/KTbFBbpB_o.png" alt="在这里插入图片描述"><br> 在当前帧对目标区域建模，下一帧寻找与模型最相似的区域就是预测位置，与传统的盲搜不同，它利用<strong>相邻帧之间目标位置变化不大</strong>的特点，采用<strong>迭代逼近</strong>的方式提高算法的搜索速度<br> <img src="https://images2.imgbox.com/04/bd/Djp4pkuR_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="22_82"></a>2.2：判别式模型</h3> 
<p>目前比较流行的是<em><strong>判别类方法(Discriminative Tracking)</strong></em></p> 
<blockquote> 
 <p>参考：<a href="https://www.cse.psu.edu/~rtc12/CSE598C/classificationTracking.pdf" rel="nofollow">https://www.cse.psu.edu/~rtc12/CSE598C/classificationTracking.pdf</a><br> <a href="https://www.cse.psu.edu/~rtc12/CSE598C/LKintro.pdf" rel="nofollow">https://www.cse.psu.edu/~rtc12/CSE598C/LKintro.pdf</a></p> 
</blockquote> 
<p><img src="https://images2.imgbox.com/4a/9b/0xeHGOo5_o.png" alt="在这里插入图片描述"></p> 
<ul><li><b><i><font color="#e84393"> 核心思想：</font></i></b>在视频序列中区分目标对象和背景环境，即<strong>学习一个分类器或者一个滤波器来判别目标和非目标</strong>。</li></ul> 
<p>步骤如下：</p> 
<ol><li><b><font color="#27ae60"> <i>特征提取:</i></font></b><br> 从目标对象和周围的背景区域提取特征。这些特征可以是手工设计的，如HOG（方向梯度直方图）、SIFT（尺度不变特征变换）等，或者是深度学习方法自动学习得到的特征。</li><li><b><font color="#27ae60"> <i>模型训练:</i></font></b><br> 使用提取的特征训练一个判别模型。这个模型的任务是区分目标和背景。训练过程可以使用正样本（目标）和负样本（背景）来完成。</li><li><b><font color="#27ae60"> <i>目标定位:</i></font></b><br> 在后续的视频帧中，判别模型被用来搜索和定位目标。定位通常是通过在新帧中评估多个候选区域，并选择判别模型输出最高分数的区域作为目标的新位置。</li><li><b><font color="#27ae60"> <i>在线更新:⭐</i></font></b><br> 跟踪过程中，目标的外观可能会变化，因此<strong>判别模型需要在线更新</strong>以适应这些变化。更新策略可以是增量学习或者使用一种滑动窗口机制来<strong>逐渐忘记旧的样本</strong> 
  <blockquote> 
   <p>这里其实就体现了目标跟踪和目标检测的不同，目标跟踪需要不断利用连续帧之间的信息，进行跟踪。而目标检测or分类是处理静态的图片帧，一旦模型训练的足够好，就可以达到理想效果。</p> 
  </blockquote> </li><li><b><font color="#27ae60"> <i>尺度和旋转处理:</i></font></b><br> 目标在移动过程中可能会发生尺度变化或旋转。判别式跟踪方法需要有一定的机制来适应这些变化。</li></ol> 
<p>判别式跟踪方法的代表包括：</p> 
<ul><li><strong>TLD (Tracking-Learning-Detection):</strong> TLD跟踪器将跟踪、学习和检测结合起来，以应对长时跟踪中的目标外观变化。</li><li><strong>Struck (Structured Output Tracking with Kernels):</strong> Struck跟踪器使用结构化输出SVM并结合核技巧来进行目标跟踪。</li><li><strong>MOSSE (Minimum Output Sum of Squared Error):</strong> MOSSE使用相关滤波器进行快速跟踪，并具有很好的实时性和准确性。</li><li><strong>KCF (Kernelized Correlation Filters):</strong> KCF通过核技巧增强相关滤波器的性能，能够处理非线性特征空间。</li><li><strong>DCF (Discriminative Correlation Filters):</strong> DCF基于相关滤波器，通过学习区分目标和背景的滤波器系数进行跟踪。</li></ul> 
<p>深度学习方法，如基于卷积神经网络（CNN）和孪生网络的跟踪器，其实也可以归类为判别式方法，因为它们通常涉及到<strong>训练一个能够区分目标和背景的网络</strong>。</p> 
<p>判别式跟踪方法的优点在于它们通常能提供较高的跟踪精度，并且能较好地处理遮挡、光照变化和背景干扰等问题。然而，这些方法的挑战在于需要<strong>有效的在线更新机制</strong>以及对<strong>目标外观变化的适应性</strong>。</p> 
<p>判别式方法的目标跟踪与目标检测的主要关联和区别在于后者通常作为<strong>跟踪任务的一个组成部分</strong>。在跟踪的开始阶段，可以使用<strong>目标检测来初始化跟踪器</strong>，之后<strong>目标跟踪算法会接管，持续追踪目标对象随时间的移动和变化</strong>。</p> 
<h3><a id="24_120"></a>2.4：总结</h3> 
<p>生成式目标跟踪方法与相关滤波的判别式目标跟踪方法有几个关键的区别：</p> 
<ul><li><strong>模型概念：</strong> 
  <ul><li>生成式方法：生成式跟踪方法的核心思想是<strong>建模目标的外观</strong>，并尝试在后续帧中重新找到这个外观。它通常通过建立一个目标的外观模型，然后在新的帧中寻找与该模型最相似的区域。</li><li>判别式方法（如相关滤波）：判别式方法是基于<strong>区分目标和背景的思想</strong>。它<strong>学习一个分类器或者滤波器来区分目标和周围的背景</strong>。相关滤波跟踪算法通过<strong>训练相关滤波器</strong>来<strong>最大化目标和非目标之间的响应差异</strong>。</li></ul> </li><li><strong>目标定位：</strong> 
  <ul><li>生成式方法：在新的帧中，生成式方法通常通过寻找与模型最相似的区域来定位目标，通常使用<strong>搜索窗口</strong>在整个图像中搜索。</li><li>判别式方法：相关滤波算法使用滤波器在目标周围的区域进行<strong>卷积</strong>，产生一个响应图，并在这个<strong>响应图</strong>中找到最大响应值对应的位置作为目标的新位置。</li></ul> </li><li><strong>处理遮挡和变化</strong>： 
  <ul><li>生成式方法：生成式方法依赖于目标的外观模型，如果目标发生显著变化或遭受遮挡，这种方法可能会丢失目标。</li><li>判别式方法：相关滤波算法能够在<strong>线更新滤波器</strong>来适应目标的外观变化，这使得它们在处理遮挡和外观变化时通常更为鲁棒。</li></ul> </li><li><strong>实时性：</strong> 
  <ul><li>生成式方法：尽管一些生成式方法可以实现快速跟踪，但是它们在搜索过程中可能会受到计算效率的限制。</li><li>判别式方法：相关滤波算法特别适合于<strong>实时跟踪</strong>，因为它们在频域中进行计算，可以利用快速傅里叶变换来加速响应图的生成。</li></ul> </li><li><strong>背景信息：</strong> 
  <ul><li>生成式方法：这种方法主要关注于<strong>目标的表示</strong>，没有显式地利用背景信息。</li><li>判别式方法：相关滤波以及其他判别式方法通过考虑背景，学习一个可以区分目标和背景的滤波器。</li></ul> </li></ul> 
<p>在实际应用中，选择哪种跟踪方法取决于特定的任务需求、环境条件以及性能要求。有时，为了提高跟踪的稳定性和准确性，也会将生成式和判别式方法结合起来使用。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/04691902d582942256565d1c2fcc6c35/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">初级爬虫实战——巴黎圣母院新闻</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/2ee1f84f68453c27a030a564c6cac9bf/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Ubuntu介绍、与centos的区别、基于VMware安装Ubuntu Server 22.04、配置远程连接、安装jdk&#43;Tomcat</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>