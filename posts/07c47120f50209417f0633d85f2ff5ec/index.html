<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Spark学习 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/07c47120f50209417f0633d85f2ff5ec/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="Spark学习">
  <meta property="og:description" content="Spark学习 什么是spark？
Apache Spark是一个开源的集群计算系统，旨在使数据分析变得快速
既运行得快，又写得快
spark5大模块：
回顾：MR的执行流程
hadoop为什么慢？？？额外的复制，序列化，磁盘IO开销
spark为什么快？？？因为内存计算，当然还有DAG(有向无环图)
支持3种语言的API ：Scala（很好）Python（不错）Java（…）
有4种模式可以运行
Local 多用于测试
Standalone 节点运行
Mesos
YARN 最具前景
本地部署spark： 添加依赖
&lt;dependency&gt; &lt;groupId&gt;org.scala-lang&lt;/groupId&gt; &lt;artifactId&gt;scala-library&lt;/artifactId&gt; &lt;version&gt;2.12.10&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.scala-lang&lt;/groupId&gt; &lt;artifactId&gt;scala-compiler&lt;/artifactId&gt; &lt;version&gt;2.12.10&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.scala-lang&lt;/groupId&gt; &lt;artifactId&gt;scala-reflect&lt;/artifactId&gt; &lt;version&gt;2.12.10&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.spark&lt;/groupId&gt; &lt;artifactId&gt;spark-core_2.12&lt;/artifactId&gt; &lt;version&gt;3.1.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.spark&lt;/groupId&gt; &lt;artifactId&gt;spark-sql_2.12&lt;/artifactId&gt; &lt;version&gt;3.1.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.spark&lt;/groupId&gt; &lt;artifactId&gt;spark-streaming_2.12&lt;/artifactId&gt; &lt;version&gt;3.1.3&lt;/version&gt; &lt;/dependency&gt; WordCount:
数据展示：
import org.apache.spark.rdd.RDD import org.apache.spark.{SparkConf, SparkContext} object WordCount { def main(args: Array[String]): Unit = { // 创建spark配置文件对象 val conf = new SparkConf() // 设置运行模式 // local模式运行，需要设置setMaster // 若要是集群运行，注释这句话即可 conf.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-07-24T21:35:32+08:00">
    <meta property="article:modified_time" content="2024-07-24T21:35:32+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Spark学习</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h3><a id="Spark_0"></a>Spark学习</h3> 
<p>什么是spark？</p> 
<blockquote> 
 <p>Apache Spark是一个开源的集群计算系统，旨在使数据分析变得快速</p> 
 <p>既运行得快，又写得快</p> 
</blockquote> 
<p>spark5大模块：</p> 
<img src="https://images2.imgbox.com/d7/f1/YYaCt614_o.png" alt="image.png"> 
<p>回顾：MR的执行流程</p> 
<p><img src="https://images2.imgbox.com/c5/ac/6IgglSc5_o.png" alt="mr.png"></p> 
<p>hadoop为什么慢？？？额外的复制，序列化，磁盘IO开销</p> 
<p>spark为什么快？？？因为内存计算，当然还有DAG(有向无环图)</p> 
<p>支持3种语言的API ：Scala（很好）Python（不错）Java（…）</p> 
<p>有4种模式可以运行</p> 
<p>Local 多用于测试</p> 
<p>Standalone 节点运行</p> 
<p>Mesos</p> 
<p>YARN 最具前景</p> 
<h3><a id="spark_36"></a>本地部署spark：</h3> 
<p>添加依赖</p> 
<pre><code class="prism language-xml">		<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.scala-lang<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>scala-library<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
     		<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>2.12.10<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>

        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.scala-lang<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>scala-compiler<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>2.12.10<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>

        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.scala-lang<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>scala-reflect<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>2.12.10<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>

        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.spark<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>spark-core_2.12<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>3.1.3<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>

        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.spark<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>spark-sql_2.12<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
             <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>3.1.3<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>

        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.spark<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>spark-streaming_2.12<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
             <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>3.1.3<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
</code></pre> 
<p>WordCount:</p> 
<p>数据展示：</p> 
<img src="https://images2.imgbox.com/a1/c2/obRdAJ2b_o.png" alt="image.png"> 
<pre><code class="prism language-scala"><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span></span>RDD
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>

<span class="token keyword">object</span> WordCount <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token comment">// 创建spark配置文件对象</span>
    <span class="token keyword">val</span> conf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment">// 设置运行模式</span>
    <span class="token comment">// local模式运行，需要设置setMaster</span>
    <span class="token comment">// 若要是集群运行，注释这句话即可</span>
    conf<span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local"</span><span class="token punctuation">)</span>

    <span class="token comment">// 设置spark作业的名字</span>
    conf<span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"wordcount"</span><span class="token punctuation">)</span>

    <span class="token comment">// 创建spark上下文环境对象</span>
    <span class="token keyword">val</span> sc <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>

    <span class="token comment">// 1. 读取文件   每次读一行</span>
    <span class="token comment">//RDD是spark core中的核心数据结构，将来运行的时候，数据会在RDD之间流动，默认基于内存计算</span>
    <span class="token keyword">val</span> lineRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"spark/data/test.text"</span><span class="token punctuation">)</span>

<span class="token comment">//    lineRDD.foreach(println)</span>
    <span class="token comment">// 2.处理数据  根据分隔符切分  扁平化处理</span>
    <span class="token keyword">val</span> wordRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> lineRDD<span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment">//    wordRDD.foreach(println)</span>

    <span class="token comment">// 3.将每一个单词组成(word,1)</span>
    <span class="token keyword">val</span> kvRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> wordRDD<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token comment">// 分组</span>
      <span class="token keyword">val</span> kv<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> Iterable<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> kvRDD<span class="token punctuation">.</span>groupBy<span class="token punctuation">(</span>_<span class="token punctuation">.</span>_1<span class="token punctuation">)</span>
      <span class="token keyword">val</span> result<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> kv<span class="token punctuation">.</span>map<span class="token punctuation">(</span>s <span class="token keyword">=&gt;</span> <span class="token punctuation">(</span>s<span class="token punctuation">.</span>_1<span class="token punctuation">,</span> s<span class="token punctuation">.</span>_2<span class="token punctuation">.</span>size<span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token comment">// 打印</span>
    result<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>

    <span class="token comment">/*
 * 链式调用
 * */</span>
    sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"spark/data/test.text"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>groupBy<span class="token punctuation">(</span>_<span class="token punctuation">.</span>_1<span class="token punctuation">)</span>
      <span class="token punctuation">.</span>map<span class="token punctuation">(</span>s <span class="token keyword">=&gt;</span> <span class="token punctuation">(</span>s<span class="token punctuation">.</span>_1<span class="token punctuation">,</span> s<span class="token punctuation">.</span>_2<span class="token punctuation">.</span>size<span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<img src="https://images2.imgbox.com/f3/05/tAqYwrWg_o.png" alt="image.png"> 
<p>wordcount 图解：</p> 
<img src="https://images2.imgbox.com/ca/54/rXGTqn5U_o.png" alt="spark.png"> 
<h3><a id="Spark_Core_142"></a>Spark Core</h3> 
<h4><a id="spark_RDD_144"></a>spark RDD</h4> 
<blockquote> 
 <p>RDD: 弹性分布式数据集</p> 
 <ul><li> <p>弹性：数据量可大可小</p> <p>RDD类似于容器，但是本身存储的不是数据，是计算逻辑</p> <p>当遇到行动算子的时候，整个spark作业才会被触发执行，是从第一个RDD开始执行，数据才开始产生流动</p> <p>数据在RDD之间只是流动关系，不会存储</p> <p>流动的数据量可以很大，也可以很小，所以称为弹性</p> </li><li> <p>分布式：</p> <p>spark本质上它是需要从HDFS中读取数据的，HDFS是分布式，数据block块将来可能会在不同的datanode上</p> <p>RDD中流动的数据，可能会来自不同的datanode中的block块数据</p> </li><li> <p>数据集：</p> <p>计算流动过程中，可以短暂地将RDD看成一个容器，容器中有数据，默认情况下在内存中不会进行存储</p> <p>后面会有办法将一个RDD的数据存储到磁盘中</p> </li></ul> 
</blockquote> 
<h5><a id="RDD_171"></a>RDD的五大特性（重要！！！）</h5> 
<blockquote> 
 <p>1、RDD是由一系列分区构成</p> 
 <p>注意：</p> 
 <p>​ 1）读文件时的minPartitions参数只能决定最小分区数，实际读取文件后的RDD分区数，由数据内容本身以及集群的分布来共同决定的</p> 
 <p>​ 2）若设置minPartitions的大小比block块数量还少的话，实际上以block块数量来决定分区数</p> 
 <p>​ 3）产生shuffle的算子调用时，可以传入numPartitions，实际真正改变RDD的分区数，设置多少，最终RDD就有多少分区</p> 
 <p>2、算子是作用在每一个分区上的</p> 
 <p>3、RDD与RDD之间存在一些依赖关系</p> 
 <ul><li>1）窄依赖 前一个RDD中的某一个分区数据只会到后一个RDD中的某一个分区 一对一的关系</li><li>2）宽依赖 前一个RDD中的某一个分区数据会进入到后一个RDD中的不同分区中 一对多的关系 也可以通过查看是否产生shuffle来判断</li><li>3）整个spark作业会被宽依赖的个数划分若干个stage, Num(stage) = Num(宽依赖) + 1</li><li>4）当遇到产生shuffle的算子的时候，涉及到从前一个RDD写数据到磁盘中，从磁盘中读取数据到后一个RDD的现象，</li><li>注意：第一次触发执行的时候，磁盘是没有数据的，所以会从第一个RDD产生开始执行</li><li>当重复触发相同的执行的时候，对于同一个DAG有向无环图而言，会直接从shuffle之后的RDD开始执行，可以直接从磁盘读取数据。</li><li>5）一个阶段中，RDD有几个分区，就会有几个并行task任务</li></ul> 
 <p>4、kv算子只能作用在kv的RDD上</p> 
 <p>5、spark会提供最优的任务计算方式，只移动计算，不移动数据。</p> 
</blockquote> 
<p>spark作业执行的特点：</p> 
<ul><li>1、只有遇到行动算子的时候，整个spark作业才会被触发执行</li><li>2、遇到几次，执行几次</li></ul> 
<pre><code class="prism language-scala">  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token comment">// 创建spark配置文件对象</span>
    <span class="token keyword">val</span> conf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment">// 设置运行模式</span>
    <span class="token comment">// local模式运行，需要设置setMaster</span>
    <span class="token comment">// 若要是集群运行，注释这句话即可</span>
    conf<span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local"</span><span class="token punctuation">)</span>

    <span class="token comment">// 设置spark作业的名字</span>
    conf<span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"WordCount"</span><span class="token punctuation">)</span>

    <span class="token comment">// 创建spark上下文环境对象</span>
    <span class="token keyword">val</span> sc <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>

    <span class="token comment">// 1. 读取文件   每次读一行</span>
    <span class="token comment">//RDD是spark core中的核心数据结构，将来运行的时候，数据会在RDD之间流动，默认基于内存计算</span>
<span class="token comment">//    val lineRDD: RDD[String] = sc.textFile("spark/data/test.text")</span>
<span class="token comment">//    println(lineRDD.getNumPartitions)  // 查看分区数  默认一个分区</span>
    <span class="token keyword">val</span> linesRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"spark/data/wcs/*"</span><span class="token punctuation">,</span>minPartitions <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span>  <span class="token comment">// 设置最小分区数 为3 不是实际分区数</span>
    println<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token id function">s</span><span class="token string">"lineRDD的分区数：</span><span class="token interpolation"><span class="token punctuation">${<!-- --></span><span class="token expression">linesRDD<span class="token punctuation">.</span>getNumPartitions</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>  <span class="token comment">// 2个分区 说明 有几个block块 就有几个分区  下面的几个RDD都是两个分区</span>


    <span class="token comment">// 2.处理数据  根据分隔符切分  扁平化处理</span>
    <span class="token keyword">val</span> wordRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> linesRDD<span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment">//    wordRDD.foreach(println)</span>


    <span class="token comment">// 3.将每一个单词组成(word,1)</span>
    <span class="token keyword">val</span> kvRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> wordRDD<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment">// 分组</span>
    <span class="token comment">// 需要取消读文件时设置的最小分区数，从这之后的分区数为5，说明产生shuffle的算子调用时 numPartitions可以改变RDD的分区数</span>
    <span class="token keyword">val</span> kv<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> Iterable<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> kvRDD<span class="token punctuation">.</span>groupBy<span class="token punctuation">(</span>_<span class="token punctuation">.</span>_1<span class="token punctuation">,</span>numPartitions <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> result<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> kv<span class="token punctuation">.</span>map<span class="token punctuation">(</span>s <span class="token keyword">=&gt;</span> <span class="token punctuation">(</span>s<span class="token punctuation">.</span>_1<span class="token punctuation">,</span> s<span class="token punctuation">.</span>_2<span class="token punctuation">.</span>size<span class="token punctuation">)</span><span class="token punctuation">)</span>


    <span class="token keyword">val</span> resRDD2<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> result<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>kv<span class="token operator">:</span> <span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> <span class="token punctuation">{<!-- --></span>
      println<span class="token punctuation">(</span><span class="token string">"==================防伪码====================="</span><span class="token punctuation">)</span>
      <span class="token punctuation">(</span>kv<span class="token punctuation">.</span>_1<span class="token punctuation">,</span> kv<span class="token punctuation">.</span>_2<span class="token punctuation">)</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span>
    <span class="token comment">//打印</span>
    resRDD2<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>  <span class="token comment">// 调用了算子 所以执行了 直接使用println是不行的</span>
    <span class="token comment">//    println("=" * 100)</span>
    <span class="token comment">//    resRDD2.foreach(println)  调用一次 执行一次</span>

<span class="token comment">// 查看spark jobs 界面  查看job数 stage数 task任务数（取决于分区数）  DAG 有向无环图</span>

    <span class="token comment">// 打印</span>
<span class="token comment">//    result.foreach(println)</span>

    <span class="token comment">//指定的是文件夹的路径</span>
    <span class="token comment">//spark如果是local本地运行的话，会将本地文件系统看作一个hdfs文件系统  出现crc校验文件等</span>
<span class="token comment">//    result.saveAsTextFile("spark/data/outdata1")</span>

  <span class="token punctuation">}</span>
</code></pre> 
<h5><a id="RDD__272"></a>RDD 算子</h5> 
<blockquote> 
 <p>transformation 算子 转换算子（RDD-&gt;RDD）</p> 
 <p>Action算子 行动算子</p> 
</blockquote> 
<img src="https://images2.imgbox.com/18/3b/9U58dqVb_o.png" alt="image.png"> 
<p>宽依赖和窄依赖的例子：</p> 
<img src="https://images2.imgbox.com/76/51/hA6wc6JP_o.png" alt="image.png"> 
<p>窄依赖中的pipeline操作：使得task’的执行任务非常快<br> <img src="https://images2.imgbox.com/50/ff/Zik20957_o.png" alt="image.png"></p> 
<h6><a id="_287"></a>转换算子</h6> 
<h6><a id="Map_289"></a>Map</h6> 
<pre><code class="prism language-scala"><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span></span>RDD
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>

<span class="token keyword">object</span> Demo1Map <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">val</span> conf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span>
    conf<span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local"</span><span class="token punctuation">)</span>
    conf<span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"Map算子演示"</span><span class="token punctuation">)</span>
    <span class="token comment">// 上下文对象</span>
    <span class="token keyword">val</span> sc <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>
    <span class="token keyword">val</span> lineRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"spark/data/students.txt"</span><span class="token punctuation">)</span>
    <span class="token comment">//map操作算子：将rdd中的数据依次取出，传递给后面函数逻辑，将计算后的数据返回到新的rdd中</span>
    <span class="token comment">//将rdd中的数据依次取出，处理完的数据返回下一个rdd直接继续执行后续的逻辑</span>
    <span class="token keyword">val</span> rdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> lineRDD<span class="token punctuation">.</span>map<span class="token punctuation">(</span>s <span class="token keyword">=&gt;</span> <span class="token punctuation">{<!-- --></span>
      println<span class="token punctuation">(</span><span class="token string">"============桀桀桀============="</span><span class="token punctuation">)</span>
      <span class="token keyword">val</span> arr1<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> s<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span>
      <span class="token punctuation">(</span>arr1<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> arr1<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> arr1<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> arr1<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> arr1<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span>
<span class="token comment">// 此时运行  没有结果  因为没有行动算子</span>
    <span class="token comment">// foreach就是一个行动算子</span>
    rdd<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>

<span class="token comment">// 结果： 不是先打印1000次  ============桀桀桀============= 交替进行</span>
    <span class="token comment">//...</span>
    <span class="token comment">//============桀桀桀=============</span>
    <span class="token comment">//(1500100934,隆高旻,21,男,理科五班)</span>
    <span class="token comment">//============桀桀桀=============</span>
    <span class="token comment">//(1500100935,蓬昆琦,21,男,文科六班)</span>
    <span class="token comment">//============桀桀桀=============</span>
    <span class="token comment">//(1500100936,习振锐,23,男,理科二班)</span>
  <span class="token comment">// ....</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<h6><a id="Filter_327"></a>Filter</h6> 
<pre><code class="prism language-scala"><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span></span>RDD

<span class="token keyword">object</span> Demo2Filter <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">val</span> conf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span>
    conf<span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local"</span><span class="token punctuation">)</span>
    conf<span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"Filter算子演示"</span><span class="token punctuation">)</span>
    <span class="token comment">// 上下文对象</span>
    <span class="token keyword">val</span> sc <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>
    <span class="token keyword">val</span> lineRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"spark/data/students.txt"</span><span class="token punctuation">)</span>
    <span class="token comment">// 过滤除所有的男生</span>
    <span class="token comment">//filter转换算子：将rdd中的数据依次取出，传递给后面的函数，跟map一样，也是依次传递一条</span>
    <span class="token keyword">val</span> genderRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> lineRDD<span class="token punctuation">.</span>filter<span class="token punctuation">(</span>s <span class="token keyword">=&gt;</span> <span class="token punctuation">{<!-- --></span>
<span class="token comment">//      println("============桀桀桀=============")  打印的可能是女生</span>
      <span class="token comment">//      s.split(",")(3).equals("男")</span>
      <span class="token comment">// 将确定的字符串值放前面 假如为空？</span>
<span class="token comment">//      "男".equals(s.split(",")(3))</span>
      <span class="token keyword">var</span> b<span class="token operator">:</span> <span class="token builtin">Boolean</span> <span class="token operator">=</span> <span class="token boolean">false</span>
      <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token string">"女"</span><span class="token punctuation">.</span>equals<span class="token punctuation">(</span>s<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
        println<span class="token punctuation">(</span><span class="token string">"============这是女生=================="</span><span class="token punctuation">)</span>
      <span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{<!-- --></span>
        println<span class="token punctuation">(</span><span class="token string">"============这是男生=================="</span><span class="token punctuation">)</span>
        b <span class="token operator">=</span> <span class="token string">"男"</span><span class="token punctuation">.</span>equals<span class="token punctuation">(</span>s<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">}</span>
      b
    <span class="token punctuation">}</span><span class="token punctuation">)</span>
genderRDD<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>

<span class="token comment">// 结果</span>
    <span class="token comment">// ...</span>
<span class="token comment">//    1500100968,谭晗日,24,男,文科五班</span>
<span class="token comment">//    ============桀桀桀=============</span>
<span class="token comment">//    1500100969,毛昆鹏,24,男,文科三班</span>
<span class="token comment">//    ============桀桀桀=============</span>
<span class="token comment">//    ============桀桀桀=============</span>
<span class="token comment">//    ============桀桀桀=============</span>
<span class="token comment">//    1500100972,王昂杰,23,男,理科二班</span>
<span class="token comment">//    ============桀桀桀=============</span>
<span class="token comment">//    ============桀桀桀=============</span>
<span class="token comment">//    1500100974,容鸿晖,21,男,文科五班</span>
<span class="token comment">//    ============桀桀桀=============</span>
<span class="token comment">//    1500100975,蓬曜瑞,22,男,理科三班</span>
<span class="token comment">//    ============桀桀桀=============</span>
<span class="token comment">//    ============桀桀桀=============</span>
<span class="token comment">//    ============桀桀桀=============</span>
<span class="token comment">//    1500100978,郜昆卉,21,男,文科五班</span>
<span class="token comment">// ...</span>


    <span class="token comment">// 结果2:  验证打印============桀桀桀=============是因为 过滤了女生</span>
<span class="token comment">//    1500100898,祁高旻,22,男,理科五班</span>
<span class="token comment">//    ============这是男生==================</span>
<span class="token comment">//    1500100899,计浩言,22,男,文科四班</span>
<span class="token comment">//    ============这是女生==================</span>
<span class="token comment">//    ============这是男生==================</span>
<span class="token comment">//    1500100901,崔海昌,21,男,理科六班</span>
<span class="token comment">//    ============这是男生==================</span>
<span class="token comment">//    1500100902,丰昊明,23,男,文科六班</span>
<span class="token comment">//    ============这是女生==================</span>
<span class="token comment">//    ============这是女生==================</span>
<span class="token comment">//    ============这是女生==================</span>
<span class="token comment">//    ============这是女生==================</span>
<span class="token comment">//    ============这是女生==================</span>
<span class="token comment">//    ============这是男生==================</span>
<span class="token comment">//    1500100908,那光济,22,男,文科二班</span>
<span class="token comment">//    ============这是男生==================</span>
<span class="token comment">//    1500100909,符景天,23,男,文科二班</span>

  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<h6><a id="FlatMap_403"></a>FlatMap</h6> 
<pre><code class="prism language-scala"><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span></span>RDD

<span class="token keyword">object</span> Demo3FlatMap <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">val</span> conf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span>
    conf<span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local"</span><span class="token punctuation">)</span>
    conf<span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"FlatMap算子演示"</span><span class="token punctuation">)</span>
    <span class="token comment">// 上下文对象</span>
    <span class="token keyword">val</span> sc <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>
    <span class="token keyword">val</span> lineRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"spark/data/wcs/words.txt"</span><span class="token punctuation">)</span>
    <span class="token comment">/**
    * flatMap: 将rdd中的数据每一条数据传递给后面的函数，最终将返回的数组或者是序列进行扁平化，返回给新的集合
    */</span>
    <span class="token keyword">val</span> rdd1<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> lineRDD<span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>s<span class="token keyword">=&gt;</span><span class="token punctuation">{<!-- --></span>
      println<span class="token punctuation">(</span><span class="token string">"============一条数据============="</span><span class="token punctuation">)</span>
      s<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"\\|"</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span>

rdd1<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>

<span class="token comment">// 结果</span>
<span class="token comment">//    ============一条数据=============</span>
    <span class="token comment">//hello</span>
    <span class="token comment">//world</span>
    <span class="token comment">//============一条数据=============</span>
    <span class="token comment">//java</span>
    <span class="token comment">//hadoop</span>
    <span class="token comment">//linux</span>
    <span class="token comment">//============一条数据=============</span>
    <span class="token comment">//java</span>
    <span class="token comment">//scala</span>
    <span class="token comment">//hadoop</span>
   <span class="token comment">// ......</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<h6><a id="Sample_444"></a>Sample</h6> 
<pre><code class="prism language-scala"><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span></span>RDD

<span class="token keyword">object</span> Demo4Sample <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">val</span> conf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span>
    conf<span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local"</span><span class="token punctuation">)</span>
    conf<span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"Sample算子演示"</span><span class="token punctuation">)</span>
    <span class="token comment">// 上下文对象</span>
    <span class="token keyword">val</span> sc <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>
    <span class="token keyword">val</span> lineRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"spark/data/students.txt"</span><span class="token punctuation">)</span>
    <span class="token comment">/*
     def sample(
      withReplacement: Boolean,  去重
      fraction: Double,       抽样的比例
      seed: Long = Utils.random.nextLong): RDD[T] = {
      */</span>
    <span class="token comment">/**
     * sample抽样，1000条数据，抽0.1比例，结果的数量在100左右  不去重
     * 这个函数主要在机器学习的时候会用到
     */</span>
    <span class="token keyword">val</span> rdd1<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> lineRDD<span class="token punctuation">.</span>sample<span class="token punctuation">(</span>withReplacement <span class="token operator">=</span> <span class="token boolean">false</span><span class="token punctuation">,</span> fraction <span class="token operator">=</span> <span class="token number">0.1</span><span class="token punctuation">)</span>
    rdd1<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>
    <span class="token comment">// 结果: 在100条数据左右 每次运行不一样</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<h6><a id="GroupBy_475"></a>GroupBy</h6> 
<pre><code class="prism language-scala"><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span></span>RDD
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>

<span class="token keyword">object</span> Demo5GroupBy <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"groupBy"</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>
    <span class="token comment">// 求每个班的平均年龄</span>
    <span class="token keyword">val</span> lineRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"spark/data/students.txt"</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> arr1<span class="token operator">:</span> RDD<span class="token punctuation">[</span>Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> lineRDD<span class="token punctuation">.</span>map<span class="token punctuation">(</span>s <span class="token keyword">=&gt;</span> <span class="token punctuation">{<!-- --></span>
      s<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span>
    <span class="token comment">//像这种RDD中的元素是(key,value)类型的，我们将这种RDD称之为键值对RDD(kv格式RDD)</span>
    <span class="token keyword">val</span> clazzWithAgeRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> arr1<span class="token punctuation">.</span>map <span class="token punctuation">{<!-- --></span>
      <span class="token keyword">case</span> Array<span class="token punctuation">(</span>_<span class="token punctuation">,</span> _<span class="token punctuation">,</span> age<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> _<span class="token punctuation">,</span> clazz<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span>
        <span class="token punctuation">(</span>clazz<span class="token punctuation">,</span> age<span class="token punctuation">.</span>toInt<span class="token punctuation">)</span>
    <span class="token punctuation">}</span>
    <span class="token comment">// groupBy算子 的使用  分组条件是我们自己指定的   spark中groupBy之后的，所有值会被封装到一个Iterable迭代器中存储</span>
    <span class="token keyword">val</span> groupRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> Iterable<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> clazzWithAgeRDD<span class="token punctuation">.</span>groupBy<span class="token punctuation">(</span>_<span class="token punctuation">.</span>_1<span class="token punctuation">)</span>
    <span class="token keyword">val</span> kvRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Double</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> groupRDD<span class="token punctuation">.</span>map<span class="token punctuation">(</span>kv <span class="token keyword">=&gt;</span> <span class="token punctuation">{<!-- --></span>
      <span class="token keyword">val</span> clazz<span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span> kv<span class="token punctuation">.</span>_1
      <span class="token keyword">val</span> avgAge<span class="token operator">:</span> <span class="token builtin">Double</span> <span class="token operator">=</span> kv<span class="token punctuation">.</span>_2<span class="token punctuation">.</span>map<span class="token punctuation">(</span>_<span class="token punctuation">.</span>_2<span class="token punctuation">)</span><span class="token punctuation">.</span>sum<span class="token punctuation">.</span>toDouble <span class="token operator">/</span> kv<span class="token punctuation">.</span>_2<span class="token punctuation">.</span>size
      <span class="token punctuation">(</span>clazz<span class="token punctuation">,</span> avgAge<span class="token punctuation">)</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span>
    kvRDD<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>
    <span class="token comment">// 结果:</span>
    <span class="token comment">//(理科二班,22.556962025316455)</span>
    <span class="token comment">//(文科三班,22.680851063829788)</span>
    <span class="token comment">//(理科四班,22.63736263736264)</span>
    <span class="token comment">//(理科一班,22.333333333333332)</span>
    <span class="token comment">//(文科五班,22.30952380952381)</span>
    <span class="token comment">//(文科一班,22.416666666666668)</span>
    <span class="token comment">//(文科四班,22.506172839506174)</span>
    <span class="token comment">//(理科六班,22.48913043478261)</span>
    <span class="token comment">//(理科三班,22.676470588235293)</span>
    <span class="token comment">//(文科六班,22.60576923076923)</span>
    <span class="token comment">//(理科五班,22.642857142857142)</span>
    <span class="token comment">//(文科二班,22.379310344827587)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<h6><a id="GroupByKey_523"></a>GroupByKey</h6> 
<pre><code class="prism language-scala"><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span></span>RDD
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>

<span class="token keyword">object</span> Demo6GroupByKey <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"groupByKey"</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>

    <span class="token keyword">val</span> linesRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"spark/data/students.txt"</span><span class="token punctuation">)</span>
    <span class="token comment">//求每个班级的平均年龄</span>
    <span class="token keyword">val</span> arrayRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span>Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> linesRDD<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>line<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> clazzWithAgeRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> arrayRDD<span class="token punctuation">.</span>map <span class="token punctuation">{<!-- --></span>
      <span class="token keyword">case</span> Array<span class="token punctuation">(</span>_<span class="token punctuation">,</span> _<span class="token punctuation">,</span> age<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> _<span class="token punctuation">,</span> clazz<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span>
        <span class="token punctuation">(</span>clazz<span class="token punctuation">,</span> age<span class="token punctuation">.</span>toInt<span class="token punctuation">)</span>
    <span class="token punctuation">}</span>

        <span class="token comment">/**
         * GroupByKey属于kv格式的算子，只能作用在kv格式的RDD上
         * 也就说，只有kv格式的RDD才能调用kv格式的算子
         */</span>
        <span class="token keyword">val</span> gbkRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> Iterable<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> clazzWithAgeRDD<span class="token punctuation">.</span>groupByKey<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">val</span> resRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Double</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> gbkRDD<span class="token punctuation">.</span>map<span class="token punctuation">(</span>kv <span class="token keyword">=&gt;</span> <span class="token punctuation">(</span>kv<span class="token punctuation">.</span>_1<span class="token punctuation">,</span> kv<span class="token punctuation">.</span>_2<span class="token punctuation">.</span>sum<span class="token punctuation">.</span>toDouble <span class="token operator">/</span> kv<span class="token punctuation">.</span>_2<span class="token punctuation">.</span>size<span class="token punctuation">)</span><span class="token punctuation">)</span>
        resRDD<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>
      <span class="token comment">// 结果:</span>
    <span class="token comment">//(理科二班,22.556962025316455)</span>
    <span class="token comment">//(文科三班,22.680851063829788)</span>
    <span class="token comment">//(理科四班,22.63736263736264)</span>
    <span class="token comment">//(理科一班,22.333333333333332)</span>
    <span class="token comment">//(文科五班,22.30952380952381)</span>
    <span class="token comment">//(文科一班,22.416666666666668)</span>
    <span class="token comment">//(文科四班,22.506172839506174)</span>
    <span class="token comment">//(理科六班,22.48913043478261)</span>
    <span class="token comment">//(理科三班,22.676470588235293)</span>
    <span class="token comment">//(文科六班,22.60576923076923)</span>
    <span class="token comment">//(理科五班,22.642857142857142)</span>
    <span class="token comment">//(文科二班,22.379310344827587)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>spark core中 groupBy算子与groupByKey算子的区别？</p> 
<blockquote> 
 <p>1、代码格式上：</p> 
 <ul><li> <p>groupBy的分组条件可以自己指定，并且绝大部分的RDD都可以调用该算子，返回的是键和元素本身组成的迭代器构成的kv格式RDD</p> </li><li> <p>groupByKey算子，只能由kv格式的RDD进行调用，分组的条件会自动根据键进行分组，不需要在自己指定，返回的是键和值组成的迭代器构成的kv格式RDD</p> </li></ul> 
 <p>2、执行shuffle数据量来看</p> 
 <ul><li> <p>groupBy产生的shuffle数据量在一定程度上要大于groupByKey产生的shuffle数据量</p> </li><li> <p>所以groupByKey算子的执行效率要比groupBy算子的执行效率要高</p> </li></ul> 
</blockquote> 
<h6><a id="ReduceByKey_586"></a>ReduceByKey</h6> 
<pre><code class="prism language-scala"><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span></span>RDD

<span class="token keyword">object</span> Demo7ReduceByKey <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"ReduceByKey"</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>

    <span class="token keyword">val</span> linesRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"spark/data/score.txt"</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> arrayRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span>Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> linesRDD<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>line<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment">//分别使用groupByKey和reduceByKey计算每个学生的总分</span>
    <span class="token comment">// 封装成只有kv</span>
    <span class="token keyword">val</span> idWithScoreRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> arrayRDD<span class="token punctuation">.</span>map <span class="token punctuation">{<!-- --></span>
      <span class="token keyword">case</span> Array<span class="token punctuation">(</span>id<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> _<span class="token punctuation">,</span> score<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span>
        <span class="token punctuation">(</span>id<span class="token punctuation">,</span> score<span class="token punctuation">.</span>toInt<span class="token punctuation">)</span>
    <span class="token punctuation">}</span>
    <span class="token comment">// 先使用groupByKey</span>
    <span class="token keyword">val</span> kvRDD1<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> Iterable<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> idWithScoreRDD<span class="token punctuation">.</span>groupByKey<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> resRDD1<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> kvRDD1<span class="token punctuation">.</span>map<span class="token punctuation">(</span>kv <span class="token keyword">=&gt;</span> <span class="token punctuation">(</span>kv<span class="token punctuation">.</span>_1<span class="token punctuation">,</span> kv<span class="token punctuation">.</span>_2<span class="token punctuation">.</span>sum<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment">//    resRDD1.foreach(println)</span>
    <span class="token comment">//结果</span>
    <span class="token comment">//(1500100724,440)</span>
    <span class="token comment">//(1500100369,376)</span>
    <span class="token comment">//(1500100378,402)</span>
    <span class="token comment">//(1500100306,505)</span>
    <span class="token comment">//(1500100578,397)</span>
    <span class="token comment">//(1500100968,320)</span>
    <span class="token comment">//(1500100690,435) ...</span>

    <span class="token comment">// 使用ReduceByKey</span>
    <span class="token keyword">val</span> resRDD2<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> idWithScoreRDD<span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_ <span class="token operator">+</span> _<span class="token punctuation">)</span>
    resRDD2<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>
    <span class="token comment">// 结果</span>
    <span class="token comment">//(1500100883,362)</span>
    <span class="token comment">//(1500100990,422)</span>
    <span class="token comment">//(1500100346,391)</span>
    <span class="token comment">//(1500100178,388)</span>
    <span class="token comment">//(1500100894,371)</span>
    <span class="token comment">//(1500100519,334)</span>
    <span class="token comment">//(1500100905,264)</span>
    <span class="token comment">//(1500100624,317)...</span>
    
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>groupByKey与reduceBykey的区别？</p> 
<blockquote> 
 <p>相同点：</p> 
 <ul><li>它们都是kv格式的算子，只有kv格式的RDD才能调用</li></ul> 
 <p>不同点：</p> 
 <ul><li>1）groupByKey只是单纯地根据键进行分组，分组后的逻辑可以在后续的处理中调用其他的算子实现</li><li>2）reduceByKey 相当于MR中的预聚合，所以shuffle产生的数据量要比groupByKey中shuffle产生的数据量少，效率高，速度要快一些</li><li>3）groupByKey的灵活度要比reduceByKey灵活度要高，reduceBykey无法做一些复杂的操作，比如方差。但是groupByKey可以在分组之后的RDD进行方差操作</li></ul> 
</blockquote> 
<p>图解：</p> 
<img src="https://images2.imgbox.com/0f/d1/f6QbIKqe_o.png" alt="groupByKeyreduceByKey.png"> 
<h6><a id="Union_653"></a>Union</h6> 
<pre><code class="prism language-scala"><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span></span>RDD
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>

<span class="token keyword">object</span> Demo8Union <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"reduceByKey"</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>
    <span class="token comment">//parallelize：将scala的集合变成spark中的RDD</span>
    <span class="token keyword">val</span> rdd1<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>List<span class="token punctuation">(</span>
      <span class="token punctuation">(</span><span class="token string">"1001"</span><span class="token punctuation">,</span> <span class="token string">"fy"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      <span class="token punctuation">(</span><span class="token string">"1002"</span><span class="token punctuation">,</span> <span class="token string">"fy2"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      <span class="token punctuation">(</span><span class="token string">"1003"</span><span class="token punctuation">,</span> <span class="token string">"fy3"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      <span class="token punctuation">(</span><span class="token string">"1004"</span><span class="token punctuation">,</span> <span class="token string">"fy4"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      <span class="token punctuation">(</span><span class="token string">"1005"</span><span class="token punctuation">,</span> <span class="token string">"fy5"</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span><span class="token punctuation">)</span>
    println<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token id function">s</span><span class="token string">"rdd1的分区数:</span><span class="token interpolation"><span class="token punctuation">${<!-- --></span><span class="token expression">rdd1<span class="token punctuation">.</span>getNumPartitions</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> rdd2<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>List<span class="token punctuation">(</span>
      <span class="token punctuation">(</span><span class="token string">"1006"</span><span class="token punctuation">,</span> <span class="token string">"fz6"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      <span class="token punctuation">(</span><span class="token string">"1007"</span><span class="token punctuation">,</span> <span class="token string">"fz7"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      <span class="token punctuation">(</span><span class="token string">"1008"</span><span class="token punctuation">,</span> <span class="token string">"fz8"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      <span class="token punctuation">(</span><span class="token string">"1003"</span><span class="token punctuation">,</span> <span class="token string">"fy3"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      <span class="token punctuation">(</span><span class="token string">"1009"</span><span class="token punctuation">,</span> <span class="token string">"fz9"</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span><span class="token punctuation">)</span>
    println<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token id function">s</span><span class="token string">"rdd2的分区数:</span><span class="token interpolation"><span class="token punctuation">${<!-- --></span><span class="token expression">rdd2<span class="token punctuation">.</span>getNumPartitions</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> rdd3<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>List<span class="token punctuation">(</span>
      <span class="token punctuation">(</span><span class="token string">"1006"</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      <span class="token punctuation">(</span><span class="token string">"1007"</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      <span class="token punctuation">(</span><span class="token string">"1008"</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      <span class="token punctuation">(</span><span class="token string">"1003"</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
      <span class="token punctuation">(</span><span class="token string">"1009"</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment">//两个RDD要想进行union合并，必须保证元素的格式和数据类型是一致的</span>
    <span class="token comment">//分区数也会进行合并，最终的分区数由两个RDD总共的分区数决定</span>
<span class="token comment">//    rdd1.union(rdd3) 不行</span>
    <span class="token keyword">val</span> resRDD1<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> rdd1<span class="token punctuation">.</span>union<span class="token punctuation">(</span>rdd2<span class="token punctuation">)</span>
    resRDD1<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span> <span class="token comment">// 结果看不出端倪 打印分区看看</span>
    println<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token id function">s</span><span class="token string">"resRDD1的分区数:</span><span class="token interpolation"><span class="token punctuation">${<!-- --></span><span class="token expression">resRDD1<span class="token punctuation">.</span>getNumPartitions</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
    <span class="token comment">// 结果</span>
    <span class="token comment">//rdd1的分区数:1</span>
    <span class="token comment">//rdd2的分区数:1</span>
    <span class="token comment">//resRDD1的分区数:2</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<h6><a id="Join_706"></a>Join</h6> 
<pre><code class="prism language-scala">  <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>
  <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span></span>RDD

  <span class="token comment">/**
   * join算子也要作用在kv格式的RDD上
   */</span>
  <span class="token keyword">object</span> Demo9Join <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
      <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local"</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"Join"</span><span class="token punctuation">)</span>

      <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>

      <span class="token keyword">val</span> rdd1<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>List<span class="token punctuation">(</span>
        <span class="token punctuation">(</span><span class="token string">"1001"</span><span class="token punctuation">,</span> <span class="token string">"1号"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">(</span><span class="token string">"1002"</span><span class="token punctuation">,</span> <span class="token string">"2号"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">(</span><span class="token string">"1003"</span><span class="token punctuation">,</span> <span class="token string">"3号"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">(</span><span class="token string">"1004"</span><span class="token punctuation">,</span> <span class="token string">"4号"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">(</span><span class="token string">"1005"</span><span class="token punctuation">,</span> <span class="token string">"5号"</span><span class="token punctuation">)</span>
      <span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token keyword">val</span> rdd2<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>List<span class="token punctuation">(</span>
        <span class="token punctuation">(</span><span class="token string">"1001"</span><span class="token punctuation">,</span> <span class="token string">"看美女"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">(</span><span class="token string">"1002"</span><span class="token punctuation">,</span> <span class="token string">"看综艺"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">(</span><span class="token string">"1003"</span><span class="token punctuation">,</span> <span class="token string">"看八卦"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">(</span><span class="token string">"1004"</span><span class="token punctuation">,</span> <span class="token string">"打游戏"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">(</span><span class="token string">"1009"</span><span class="token punctuation">,</span> <span class="token string">"学习"</span><span class="token punctuation">)</span>
      <span class="token punctuation">)</span><span class="token punctuation">)</span>

      <span class="token comment">/**
       * join 内连接
       * right join 右连接
       * left join 左连接
       * full join 全连接
       */</span>
      <span class="token comment">// join 内连接 两个rdd共同拥有的键才会进行关联</span>
      <span class="token comment">//    val resRDD1: RDD[(String, (String, String))] = rdd1.join(rdd2)</span>
      <span class="token comment">//    val resRDD2: RDD[(String, String, String)] = resRDD1.map {<!-- --></span>
      <span class="token comment">//      case (id: String, (name: String, like: String)) =&gt;</span>
      <span class="token comment">//        (id, name, like)</span>
      <span class="token comment">//    }</span>
      <span class="token comment">//    resRDD2.foreach(println)</span>

      <span class="token comment">//right join 右连接 保证右边rdd键的完整性</span>
      <span class="token comment">//    val resRDD2: RDD[(String, (Option[String], String))] = rdd1.rightOuterJoin(rdd2)</span>
      <span class="token comment">//    val resRDD3: RDD[(String, String, String)] = resRDD2.map {<!-- --></span>
      <span class="token comment">//      case (id: String, (Some(name), like: String)) =&gt;</span>
      <span class="token comment">//        (id, name, like)</span>
      <span class="token comment">//      case (id: String, (None, like: String)) =&gt;</span>
      <span class="token comment">//        (id, "查无此人", like)</span>
      <span class="token comment">//    }</span>
      <span class="token comment">//    resRDD3.foreach(println)</span>

      <span class="token comment">//TODO:自己完成左关联</span>
      <span class="token comment">// left join 左连接 保证左边rdd键的完整性</span>
      <span class="token keyword">val</span> resRDD2<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> Option<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> rdd1<span class="token punctuation">.</span>leftOuterJoin<span class="token punctuation">(</span>rdd2<span class="token punctuation">)</span>
      <span class="token keyword">val</span> resRDD3<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> resRDD2<span class="token punctuation">.</span>map <span class="token punctuation">{<!-- --></span>
        <span class="token keyword">case</span> <span class="token punctuation">(</span>id<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>name<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> Some<span class="token punctuation">(</span>like<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span>
          <span class="token punctuation">(</span>id<span class="token punctuation">,</span> name<span class="token punctuation">,</span> like<span class="token punctuation">)</span>
        <span class="token keyword">case</span> <span class="token punctuation">(</span>id<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>name<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> None<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span>
          <span class="token punctuation">(</span>id<span class="token punctuation">,</span> name<span class="token punctuation">,</span> <span class="token string">"此人无爱好"</span><span class="token punctuation">)</span>
      <span class="token punctuation">}</span>
      resRDD3<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>
      <span class="token comment">// 结果</span>

<span class="token comment">//      (1005,5号,此人无爱好)</span>
<span class="token comment">//      (1001,1号,看美女)</span>
<span class="token comment">//      (1002,2号,看综艺)</span>
<span class="token comment">//      (1004,4号,打游戏)</span>
<span class="token comment">//      (1003,3号,看八卦)</span>

<span class="token comment">//      //全关联</span>
<span class="token comment">//      val resRDD2: RDD[(String, (Option[String], Option[String]))] = rdd1.fullOuterJoin(rdd2)</span>
<span class="token comment">//      val resRDD3: RDD[(String, String, String)] = resRDD2.map {<!-- --></span>
<span class="token comment">//        case (id: String, (Some(name), Some(like))) =&gt;</span>
<span class="token comment">//          (id, name, like)</span>
<span class="token comment">//        case (id: String, (Some(name), None)) =&gt;</span>
<span class="token comment">//          (id, name, "此人无爱好")</span>
<span class="token comment">//        case (id: String, (None, Some(like))) =&gt;</span>
<span class="token comment">//          (id, "查无此人", like)</span>
<span class="token comment">//      }</span>
<span class="token comment">//      resRDD3.foreach(println)</span>
      
    <span class="token punctuation">}</span>
  <span class="token punctuation">}</span>
</code></pre> 
<h6><a id="MapValues_796"></a>MapValues</h6> 
<pre><code class="prism language-scala"><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span></span>RDD
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>

<span class="token keyword">object</span> Demo10MapValues <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"MapValues算子演示"</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>

    <span class="token keyword">val</span> linesRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"spark/data/students.txt"</span><span class="token punctuation">)</span>
    <span class="token comment">// 给每个人的年龄加上100</span>
    <span class="token keyword">val</span> kvRDD1<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> linesRDD<span class="token punctuation">.</span>map<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>map <span class="token punctuation">{<!-- --></span>
      <span class="token keyword">case</span> Array<span class="token punctuation">(</span>_<span class="token punctuation">,</span> name<span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">,</span> age<span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">,</span> _<span class="token punctuation">,</span>_<span class="token punctuation">)</span> <span class="token keyword">=&gt;</span>
        <span class="token punctuation">(</span>name<span class="token punctuation">,</span> age<span class="token punctuation">.</span>toInt<span class="token punctuation">)</span>
    <span class="token punctuation">}</span>


    <span class="token comment">/**
     * mapValues函数也是作用在kv格式的算子上
     * 将每个元素的值传递给后面的函数，进行处理得到新的值，键不变，这个处理后的组合重新返回到新的RDD中
     */</span>
    kvRDD1<span class="token punctuation">.</span>mapValues<span class="token punctuation">(</span>_ <span class="token operator">+</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>
    <span class="token comment">//(于从寒,123)</span>
    <span class="token comment">//(凌智阳,121)</span>
    <span class="token comment">//(卞乐萱,121)</span>
    <span class="token comment">//(于晗昱,122)</span>
    <span class="token comment">//(濮恨蕊,123)</span>
    <span class="token comment">//(戚昌盛,122)</span>
    <span class="token comment">//(满慕易,121)</span>
    
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<h6><a id="mapPartitions_835"></a>mapPartitions</h6> 
<pre><code class="prism language-scala"><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span></span>RDD
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>

<span class="token keyword">object</span> Demo11PartitionBy <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"mapPartitions算子演示"</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>

    <span class="token keyword">val</span> linesRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"spark/data/wcs/*"</span><span class="token punctuation">)</span>
    <span class="token comment">/**
     * mapPartitions：一次处理一个分区中的数据
     * 它与map的区别在于，map是每次处理一条数据就返回一条数据到下一个rdd
     * 而mapPartitions一次处理一个分区的数据，处理完再返回
     * 最后的处理效果和map的处理效果是一样的
     *
     * mapPartition可以优化与数据库连接的次数
     */</span>
    <span class="token comment">// s是Iterator[String]类型</span>
    <span class="token keyword">val</span> rdd1<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> linesRDD<span class="token punctuation">.</span>mapPartitions<span class="token punctuation">(</span>s <span class="token keyword">=&gt;</span> <span class="token punctuation">{<!-- --></span>
      println<span class="token punctuation">(</span><span class="token string">"========================="</span><span class="token punctuation">)</span>  <span class="token comment">// 打印了两次 对应两个分区</span>
      s<span class="token punctuation">.</span>map<span class="token punctuation">(</span>e <span class="token keyword">=&gt;</span> <span class="token punctuation">{<!-- --></span>
        e
      <span class="token punctuation">}</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span>
    rdd1<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<h6><a id="SortBy_870"></a>SortBy</h6> 
<pre><code class="prism language-scala"><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span></span>RDD
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>

<span class="token keyword">object</span> Demo12SortBy <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"SortBy算子演示"</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>

    <span class="token keyword">val</span> rdd1<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token number">34</span><span class="token punctuation">,</span> <span class="token number">123</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">231</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">34</span><span class="token punctuation">,</span> <span class="token number">56</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> rdd2<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> rdd1<span class="token punctuation">.</span>sortBy<span class="token punctuation">(</span><span class="token punctuation">(</span>e<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> e<span class="token punctuation">)</span>
    rdd2<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>
    <span class="token comment">//1</span>
    <span class="token comment">//1</span>
    <span class="token comment">//2</span>
    <span class="token comment">//6</span>
    <span class="token comment">//34</span>
    <span class="token comment">//34</span>
    <span class="token comment">//56</span>
    <span class="token comment">//123</span>
    <span class="token comment">//231</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<h6><a id="_901"></a>行动算子</h6> 
<h6><a id="Foreach_903"></a>Foreach</h6> 
<pre><code class="prism language-scala"><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span></span>RDD
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>

<span class="token keyword">object</span> Demo13Foreach <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"foreach算子演示"</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>

    <span class="token keyword">val</span> linesRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"spark/data/students.txt"</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> rdd1<span class="token operator">:</span> RDD<span class="token punctuation">[</span>Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> linesRDD<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>e<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> <span class="token punctuation">{<!-- --></span>
      e<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> rdd2<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> rdd1<span class="token punctuation">.</span>map <span class="token punctuation">{<!-- --></span>
      <span class="token keyword">case</span> Array<span class="token punctuation">(</span>id<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> name<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> age<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> gender<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> clazz<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span>
        <span class="token punctuation">(</span>id<span class="token punctuation">,</span> name<span class="token punctuation">,</span> age<span class="token punctuation">,</span> gender<span class="token punctuation">,</span> clazz<span class="token punctuation">)</span>
    <span class="token punctuation">}</span>
    <span class="token comment">/**
     * 行动算子，就可以触发一次作业执行，有几次行动算子调用，就会触发几次
     *
     * rdd是懒加载的性质
     */</span>
<span class="token comment">//    rdd2.foreach(println)</span>
    <span class="token comment">//    println("====================================")</span>
    <span class="token comment">//    rdd2.foreach(println)</span>
    println<span class="token punctuation">(</span><span class="token string">"哈哈哈"</span><span class="token punctuation">)</span> <span class="token comment">// 一定会打印，不属于spark作业中的语句</span>
    <span class="token keyword">val</span> rdd3<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> rdd2<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>t5<span class="token operator">:</span> <span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> <span class="token punctuation">{<!-- --></span>
      println<span class="token punctuation">(</span><span class="token string">"==============================="</span><span class="token punctuation">)</span> <span class="token comment">// 没有行动算子时 不会打印</span>
      t5
    <span class="token punctuation">}</span><span class="token punctuation">)</span>
    println<span class="token punctuation">(</span><span class="token string">"嘿嘿嘿"</span><span class="token punctuation">)</span><span class="token comment">// 不是Spark作业里的</span>

    rdd3<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span> <span class="token comment">// 数据和"===============================" 交替打印</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<h6><a id="Collect_946"></a>Collect</h6> 
<pre><code class="prism language-scala"><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span></span>RDD

<span class="token keyword">object</span> Demo14collect <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"Collect算子演示"</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>

    <span class="token keyword">val</span> linesRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"spark/data/students.txt"</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> rdd1<span class="token operator">:</span> RDD<span class="token punctuation">[</span>Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> linesRDD<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>e<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> <span class="token punctuation">{<!-- --></span>
      e<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> rdd2<span class="token operator">:</span> RDD<span class="token punctuation">[</span>Student<span class="token punctuation">]</span> <span class="token operator">=</span> rdd1<span class="token punctuation">.</span>map <span class="token punctuation">{<!-- --></span>
      <span class="token keyword">case</span> Array<span class="token punctuation">(</span>id<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> name<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> age<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> gender<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> clazz<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span>
        Student<span class="token punctuation">(</span>id<span class="token punctuation">.</span>toInt<span class="token punctuation">,</span> name<span class="token punctuation">,</span> age<span class="token punctuation">.</span>toInt<span class="token punctuation">,</span> gender<span class="token punctuation">,</span> clazz<span class="token punctuation">)</span>
    <span class="token punctuation">}</span>

    <span class="token comment">//collect将rdd转成合适的scala中的数据结构</span>
    <span class="token keyword">val</span> stuArr<span class="token operator">:</span> Array<span class="token punctuation">[</span>Student<span class="token punctuation">]</span> <span class="token operator">=</span> rdd2<span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment">//foreach是scala中的foreach，不会产生作业执行的</span>
    stuArr<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token keyword">case</span> <span class="token keyword">class</span> Student<span class="token punctuation">(</span>id<span class="token operator">:</span><span class="token builtin">Int</span><span class="token punctuation">,</span>name<span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">,</span>age<span class="token operator">:</span><span class="token builtin">Int</span><span class="token punctuation">,</span>gender<span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">,</span>clazz<span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">)</span>
</code></pre> 
<h6><a id="_980"></a>算子应用</h6> 
<pre><code class="prism language-scala"><span class="token comment">// 求总分前十的学生的各科成绩：</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>
  <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span></span>RDD

  <span class="token keyword">object</span> Demo15StudentTest1 <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
      <span class="token comment">//求年级总分前10的学生各科分数的详细信息</span>
      <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local"</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"MapValues算子演示"</span><span class="token punctuation">)</span>

      <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>

      <span class="token keyword">val</span> linesRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"spark/data/score.txt"</span><span class="token punctuation">)</span>

      <span class="token keyword">val</span> idWithScoreRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> linesRDD<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>line<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> <span class="token punctuation">{<!-- --></span>
        line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span> <span class="token keyword">match</span> <span class="token punctuation">{<!-- --></span>
          <span class="token keyword">case</span> Array<span class="token punctuation">(</span>id<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> subject_id<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> score<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span>
            <span class="token punctuation">(</span>id<span class="token punctuation">,</span> subject_id<span class="token punctuation">,</span> score<span class="token punctuation">.</span>toInt<span class="token punctuation">)</span>
        <span class="token punctuation">}</span>
      <span class="token punctuation">}</span><span class="token punctuation">)</span>
      
      <span class="token keyword">val</span> array1<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> idWithScoreRDD
        <span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>t3<span class="token operator">:</span> <span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> <span class="token punctuation">(</span>t3<span class="token punctuation">.</span>_1<span class="token punctuation">,</span> t3<span class="token punctuation">.</span>_3<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_ <span class="token operator">+</span> _<span class="token punctuation">)</span>
        <span class="token punctuation">.</span>sortBy<span class="token punctuation">(</span><span class="token punctuation">(</span>kv<span class="token operator">:</span> <span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> <span class="token operator">-</span>kv<span class="token punctuation">.</span>_2<span class="token punctuation">)</span>
        <span class="token punctuation">.</span>take<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span> <span class="token comment">// take 也是行动算子</span>
        <span class="token punctuation">.</span>map<span class="token punctuation">(</span>_<span class="token punctuation">.</span>_1<span class="token punctuation">)</span>

      idWithScoreRDD<span class="token punctuation">.</span>filter<span class="token punctuation">(</span><span class="token punctuation">(</span>t3<span class="token operator">:</span> <span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> <span class="token punctuation">{<!-- --></span>
        <span class="token keyword">val</span> bool<span class="token operator">:</span> <span class="token builtin">Boolean</span> <span class="token operator">=</span> array1<span class="token punctuation">.</span>contains<span class="token punctuation">(</span>t3<span class="token punctuation">.</span>_1<span class="token punctuation">)</span>
        <span class="token keyword">if</span><span class="token punctuation">(</span>bool<span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
          println<span class="token punctuation">(</span><span class="token string">"存在"</span><span class="token punctuation">)</span>
        <span class="token punctuation">}</span>
        bool
      <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span><span class="token punctuation">(</span>t3<span class="token operator">:</span> <span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> <span class="token punctuation">{<!-- --></span>
        println<span class="token punctuation">(</span><span class="token string">"=========================="</span><span class="token punctuation">)</span>
        println<span class="token punctuation">(</span>t3<span class="token punctuation">)</span>
      <span class="token punctuation">}</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">}</span>
</code></pre> 
<h5><a id="_1026"></a>缓存</h5> 
<p>缓存级别</p> 
<img src="https://images2.imgbox.com/a6/2e/QMAA3CwJ_o.png" alt=".png"> 
<h6><a id="cache_1032"></a>cache</h6> 
<pre><code class="prism language-scala"><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span></span>RDD
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>storage<span class="token punctuation">.</span></span>StorageLevel

<span class="token keyword">object</span> Demo16cache <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"缓存演示"</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>
    <span class="token comment">//===================================================================</span>

    <span class="token keyword">val</span> linesRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"spark/data/students.txt"</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> studentsRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span>Student2<span class="token punctuation">]</span> <span class="token operator">=</span> linesRDD<span class="token punctuation">.</span>map<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>map <span class="token punctuation">{<!-- --></span>
        <span class="token keyword">case</span> Array<span class="token punctuation">(</span>id<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> name<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> age<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> gender<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> clazz<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span>
          Student2<span class="token punctuation">(</span>id<span class="token punctuation">,</span> name<span class="token punctuation">,</span> age<span class="token punctuation">.</span>toInt<span class="token punctuation">,</span> gender<span class="token punctuation">,</span> clazz<span class="token punctuation">)</span>
      <span class="token punctuation">}</span>

    <span class="token comment">/**
     * 缓存：
     运行结束后 就消失了
     * 缓存的目的是为了spark core作业执行的时候，缩短rdd的执行链，能够更快的得到结果
     * 缓存的目的是避免每一次job作业执行的时候，都需要从第一个rdd算起
     * 对重复使用RDD进行缓存
     * cache 设置不了缓存级别
     * persist 可以设置缓存级别
     * 缓存的实现方式：
     *  1、需要缓存的rdd调用cache函数
     *  2、persist(StorageLevel.MEMORY_ONLY) 修改缓存级别
     *
     */</span>
    studentsRDD<span class="token punctuation">.</span>cache<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment">//默认将rdd缓存到内存中，缓存级别为memory_only</span>
<span class="token comment">//    studentsRDD.persist(StorageLevel.MEMORY_AND_DISK)  // 可以修改  这里改为加上磁盘（有时候内存不够的话）</span>



  <span class="token comment">// 需求1和2都重复使用了studentsRDD 可以放在一个地方 随用随拿 不用从第一个RDD开始运行</span>
    <span class="token comment">//需求1：求每个班级的人数</span>
    studentsRDD<span class="token punctuation">.</span>groupBy<span class="token punctuation">(</span>_<span class="token punctuation">.</span>clazz<span class="token punctuation">)</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span>kv<span class="token keyword">=&gt;</span><span class="token punctuation">{<!-- --></span>
      <span class="token punctuation">(</span>kv<span class="token punctuation">.</span>_1<span class="token punctuation">,</span>kv<span class="token punctuation">.</span>_2<span class="token punctuation">.</span>size<span class="token punctuation">)</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>
    <span class="token comment">//(理科二班,79)</span>
    <span class="token comment">//(文科三班,94)</span>
    <span class="token comment">//(理科四班,91)</span>
    <span class="token comment">//(理科一班,78)</span>
    <span class="token comment">//(文科五班,84)</span>
    <span class="token comment">//(文科一班,72)</span>
    <span class="token comment">//(文科四班,81)</span>
    <span class="token comment">//(理科六班,92)</span>
    <span class="token comment">//(理科三班,68)</span>
    <span class="token comment">//(文科六班,104)</span>
    <span class="token comment">//(理科五班,70)</span>
    <span class="token comment">//(文科二班,87)</span>

    <span class="token comment">//需求2：求每个年龄的人数</span>
    studentsRDD<span class="token punctuation">.</span>groupBy<span class="token punctuation">(</span>_<span class="token punctuation">.</span>age<span class="token punctuation">)</span>
      <span class="token punctuation">.</span>map<span class="token punctuation">(</span>kv<span class="token keyword">=&gt;</span><span class="token punctuation">(</span>kv<span class="token punctuation">.</span>_1<span class="token punctuation">,</span>kv<span class="token punctuation">.</span>_2<span class="token punctuation">.</span>size<span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>
    <span class="token comment">//(21,234)</span>
    <span class="token comment">//(22,271)</span>
    <span class="token comment">//(24,260)</span>
    <span class="token comment">//(23,235)</span>

<span class="token keyword">while</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>

<span class="token punctuation">}</span>

  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token keyword">case</span> <span class="token keyword">class</span> Student2<span class="token punctuation">(</span>id<span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">,</span>name<span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">,</span>age<span class="token operator">:</span><span class="token builtin">Int</span><span class="token punctuation">,</span>gender<span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">,</span>clazz<span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">)</span>
</code></pre> 
<p>进入spark jobs 查看 DAG 在map阶段就从cache里拿RDD了。</p> 
<img src="https://images2.imgbox.com/91/cc/SLY19pqx_o.png" alt="image.png"> 
<h6><a id="checkpoint_1112"></a>checkpoint</h6> 
<p>永久的保存数据</p> 
<pre><code class="prism language-scala"><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span></span>RDD
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>

<span class="token keyword">object</span> Demo17Checkpoint <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"缓存演示"</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>
    <span class="token comment">//设置检查点的存储路径</span>
    sc<span class="token punctuation">.</span>setCheckpointDir<span class="token punctuation">(</span><span class="token string">"spark/data/checkpoint1"</span><span class="token punctuation">)</span>
    <span class="token comment">//===================================================================</span>

    <span class="token keyword">val</span> linesRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"spark/data/students.txt"</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> studentsRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span>Student2<span class="token punctuation">]</span> <span class="token operator">=</span> linesRDD<span class="token punctuation">.</span>map<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>map <span class="token punctuation">{<!-- --></span>
        <span class="token keyword">case</span> Array<span class="token punctuation">(</span>id<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> name<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> age<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> gender<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> clazz<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span>
          Student2<span class="token punctuation">(</span>id<span class="token punctuation">,</span> name<span class="token punctuation">,</span> age<span class="token punctuation">.</span>toInt<span class="token punctuation">,</span> gender<span class="token punctuation">,</span> clazz<span class="token punctuation">)</span>
      <span class="token punctuation">}</span>

    <span class="token comment">/**
     * 永久将执行过程中RDD中流动的数据存储到磁盘（hdfs）中
     * checkpoint
     *
     * 需要设置checkpoint的路径，统一设置的
     *
     * checkpoint也相当于一个行动算子，触发作业执行
     * 第二次DAG有向无环图执行的时候，直接从最后一个有检查点的rdd开始向下执行
     */</span>
    studentsRDD<span class="token punctuation">.</span>checkpoint<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">// 必须得设置路径 在SparkContext 设置</span>



    <span class="token comment">//需求1：求每个班级的人数</span>
    <span class="token keyword">val</span> rdd1<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> Iterable<span class="token punctuation">[</span>Student2<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> studentsRDD<span class="token punctuation">.</span>groupBy<span class="token punctuation">(</span>_<span class="token punctuation">.</span>clazz<span class="token punctuation">)</span>
    <span class="token keyword">val</span> resRDD1<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> rdd1<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>kv<span class="token operator">:</span> <span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> Iterable<span class="token punctuation">[</span>Student2<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> <span class="token punctuation">(</span>kv<span class="token punctuation">.</span>_1<span class="token punctuation">,</span> kv<span class="token punctuation">.</span>_2<span class="token punctuation">.</span>size<span class="token punctuation">)</span><span class="token punctuation">)</span>
    resRDD1<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>

    <span class="token comment">//需求2：求每个年龄的人数</span>
    <span class="token keyword">val</span> rdd2<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> Iterable<span class="token punctuation">[</span>Student2<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> studentsRDD<span class="token punctuation">.</span>groupBy<span class="token punctuation">(</span>_<span class="token punctuation">.</span>age<span class="token punctuation">)</span>
    <span class="token keyword">val</span> resRDD2<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> rdd2<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>kv<span class="token operator">:</span> <span class="token punctuation">(</span><span class="token builtin">Int</span><span class="token punctuation">,</span> Iterable<span class="token punctuation">[</span>Student2<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> <span class="token punctuation">(</span>kv<span class="token punctuation">.</span>_1<span class="token punctuation">,</span> kv<span class="token punctuation">.</span>_2<span class="token punctuation">.</span>size<span class="token punctuation">)</span><span class="token punctuation">)</span>
    resRDD2<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>

    <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>

    <span class="token punctuation">}</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<blockquote> 
 <p>checkpoint和cache的区别？</p> 
 <ul><li>cache是将一个复杂的RDD做缓存，将来执行的时候，只是这个rdd会从缓存中取 数据量小</li><li>checkpoint是永久将rdd数据持久化，将来执行的时候，直接从检查点的rdd往后执行 数据量大 逻辑简单</li></ul> 
</blockquote> 
<h4><a id="Spark_1174"></a>本地搭建Spark</h4> 
<p>下载spark-3.1.3-bin-hadoop3.2.tgz</p> 
<p>(https://mirrors.huaweicloud.com/apache/spark/spark-3.1.3/)</p> 
<p>上传解压：</p> 
<pre><code class="prism language-sh"><span class="token function">tar</span> <span class="token parameter variable">-zxvf</span> spark-3.1.3-bin-hadoop3.2.tgz 
</code></pre> 
<p>改名</p> 
<pre><code class="prism language-sh"><span class="token function">mv</span> spark-3.1.3-bin-hadoop3.2/ spark-3.1.3
</code></pre> 
<p>更该所属用户所属组</p> 
<pre><code class="prism language-sh"><span class="token function">chown</span> <span class="token parameter variable">-R</span> root:root spark-3.1.3/
</code></pre> 
<p>添加环境变量</p> 
<pre><code class="prism language-sh"><span class="token assign-left variable">SPARK_HOME</span><span class="token operator">=</span>/usr/local/soft/spark-3.1.3
<span class="token builtin class-name">export</span> <span class="token assign-left variable"><span class="token environment constant">PATH</span></span><span class="token operator">=</span><span class="token variable">$SPARK_HOME</span>/bin:<span class="token environment constant">$PATH</span>
</code></pre> 
<p>修改配置文件 conf</p> 
<pre><code class="prism language-sh"><span class="token function">cp</span> spark-env.sh.template spark-env.sh
 增加配置
<span class="token builtin class-name">export</span> <span class="token assign-left variable">SPARK_MASTER_IP</span><span class="token operator">=</span>master
<span class="token builtin class-name">export</span> <span class="token assign-left variable">SPARK_MASTER_PORT</span><span class="token operator">=</span><span class="token number">7077</span>

<span class="token builtin class-name">export</span> <span class="token assign-left variable">SPARK_WORKER_CORES</span><span class="token operator">=</span><span class="token number">2</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable">SPARK_WORKER_INSTANCES</span><span class="token operator">=</span><span class="token number">1</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable">SPARK_WORKER_MEMORY</span><span class="token operator">=</span>2g
<span class="token builtin class-name">export</span> <span class="token assign-left variable">JAVA_HOME</span><span class="token operator">=</span>/usr/local/soft/jdk1.8.0_171
<span class="token comment">#master相当于RM  worker相当于NM</span>
</code></pre> 
<p>​ 增加从节点配置</p> 
<pre><code class="prism language-sh"> <span class="token function">cp</span> workers.template workers
    <span class="token comment"># 增加</span>
    node1
    node2
</code></pre> 
<p>复制到其它节点</p> 
<pre><code class="prism language-sh"><span class="token function">scp</span> <span class="token parameter variable">-r</span> spark-3.1.3 node1:<span class="token variable"><span class="token variable">`</span><span class="token builtin class-name">pwd</span><span class="token variable">`</span></span>
<span class="token function">scp</span> <span class="token parameter variable">-r</span> spark-3.1.3 node2:<span class="token variable"><span class="token variable">`</span><span class="token builtin class-name">pwd</span><span class="token variable">`</span></span>
</code></pre> 
<p>撰写运行spark脚本</p> 
<pre><code class="prism language-sh"><span class="token function">vim</span> startspark.sh
<span class="token comment">#! /bin/bash</span>
/usr/local/soft/spark-3.1.3/sbin/start-all.sh
</code></pre> 
<p>给脚本赋予执行权限</p> 
<pre><code class="prism language-sh"><span class="token function">chmod</span> +x startspark.sh 
</code></pre> 
<p>访问spark ui</p> 
<p>http://master:8080/</p> 
<img src="https://images2.imgbox.com/21/22/2vpBWtX9_o.png" alt="image.png"> 
<h4><a id="standalone_1256"></a>standalone</h4> 
<h5><a id="client_1258"></a>client模式</h5> 
<p>日志在本地输出，不需要开启hadoop一般用于上线前测试(bin/下执行)</p> 
<p>使用spark样例 运行计算圆周率</p> 
<pre><code class="prism language-sh">/usr/local/soft/spark-3.1.3/examples/jars/spark-examples_2.12-3.1.3.jar
<span class="token comment">#提交spark任务</span>
spark-submit <span class="token parameter variable">--class</span> org.apache.spark.examples.SparkPi <span class="token parameter variable">--master</span> spark://master:7077 --executor-memory 512m --total-executor-cores <span class="token number">1</span> spark-examples_2.12-3.1.3.jar <span class="token number">10</span>
<span class="token comment"># 10 是并行度 分区数 这里更大更精确</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/c2/8e/EAzXPBOL_o.png" alt="image.png"></p> 
<p>日志在本地显示</p> 
<h5><a id="cluster_1275"></a>cluster模式</h5> 
<p>上线使用，不会再本地打印日志 集群化运行</p> 
<pre><code class="prism language-sh">spark-submit <span class="token parameter variable">--class</span> org.apache.spark.examples.SparkPi <span class="token parameter variable">--master</span> spark://master:7077 --executor-memory 512M --total-executor-cores <span class="token number">1</span> --deploy-mode cluster spark-examples_2.12-3.1.3.jar <span class="token number">100</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/59/b8/8mQQeJbM_o.png" alt="image.png"></p> 
<p><img src="https://images2.imgbox.com/d5/85/Wi9bSsnd_o.png" alt="image.png"></p> 
<h5><a id="sparkshell_1287"></a>spark-shell</h5> 
<p>spark 提供的一个交互式的命令行，可以直接写代码</p> 
<p>编写代码打包上传在standalone下运行</p> 
<pre><code class="prism language-scala"><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span></span>RDD
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>

<span class="token keyword">object</span> Demo18Standalone <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"standalone集群运行"</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>

    <span class="token comment">//统计单词个数</span>
    <span class="token keyword">val</span> rdd1<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>parallelize<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token string">"hive|java|hello|world"</span><span class="token punctuation">,</span> <span class="token string">"hive|java|hadoop|world"</span><span class="token punctuation">,</span> <span class="token string">"hive|spark|hello|hadoop"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    rdd1<span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"\\|"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_<span class="token operator">+</span>_<span class="token punctuation">)</span>
      <span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>

    <span class="token comment">/**
     * standalone
     *  - client模式提交命令：
     *    spark-submit --class com.shujia.core.Demo18Standalone --master spark://master:7077 --executor-memory 512m --total-executor-cores 1 spark-1.0.jar 10
     *
     *  - cluster模式提交命令：
     *    spark-submit --class com.shujia.core.Demo18Standalone --master spark://master:7077 --executor-memory 512M --total-executor-cores 1 --deploy-mode cluster spark-1.0.jar 10
     *
     *
     */</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>client模式运行结果</p> 
<p><img src="https://images2.imgbox.com/11/78/Y95pfR3D_o.png" alt="image.png"></p> 
<p>cluster模式运行：</p> 
<p>将jar包发给node1 和node2中</p> 
<pre><code class="prism language-sh"><span class="token function">scp</span> spark-1.0.jar node1:/usr/local/soft/spark-3.1.3/jars/
<span class="token function">scp</span> spark-1.0.jar node2:/usr/local/soft/spark-3.1.3/jars/
 <span class="token function">mv</span> spark-1.0.jar /usr/local/soft/spark-3.1.3/jars/
</code></pre> 
<p><img src="https://images2.imgbox.com/07/7b/w48ZKjH8_o.png" alt="image.png"></p> 
<p><img src="https://images2.imgbox.com/43/ff/Pzc9TC6V_o.png" alt="image.png"></p> 
<h4><a id="yarn_1344"></a>yarn</h4> 
<p>停止spark集群<br> 在spark sbin目录下执行 ./stop-all.sh</p> 
<p>spark整合yarn只需要在一个节点整合, 可以删除node1 和node2中所有的spark 文件</p> 
<p>增加hadoop 配置文件地址</p> 
<pre><code class="prism language-sh"><span class="token function">vim</span> spark-env.sh
    <span class="token comment">#增加</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable">HADOOP_CONF_DIR</span><span class="token operator">=</span>/usr/local/soft/hadoop-3.1.3/etc/hadoop
</code></pre> 
<p>往yarn提交任务需要增加两个配置 yarn-site.xml(/usr/local/soft/hadoop-2.7.6/etc/hadoop/yarn-site.xml)</p> 
<pre><code class="prism language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>yarn.nodemanager.pmem-check-enabled<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>false<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>yarn.nodemanager.vmem-check-enabled<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>false<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>yarn.application.classpath<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>/usr/local/soft/hadoop-3.1.3/etc/hadoop:/usr/local/soft/hadoop-3.1.3/share/
hadoop/common/lib/*:/usr/local/soft/hadoop-3.1.3/share/hadoop/common/*:/usr/local/soft/hadoop-3.1.3/share/hadoop/hdfs:/usr/local/soft/hadoop-3.1.3/share/hadoop/hdfs/lib/*:/usr/local/soft/hadoop-3.1.3/share/hadoop/hdfs/*:/usr/local/soft/hadoop-3.1.3/share/hadoop/mapreduce/lib/*:/usr/local/soft/hadoop-3.1.3/share/hadoop/mapreduce/*:/usr/local/soft/hadoop-3.1.3/share/hadoop/yarn:/usr/local/soft/hadoop-3.1.3/share/hadoop/yarn/lib/*:/usr/local/soft/hadoop-3.1.3/share/hadoop/yarn/*<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span> 
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>yarn.log-aggregation-enable<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span> 
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>true<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span> 
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span> 
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span> 
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>yarn.log-aggregation.retain-seconds<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span> 
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>2592000<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span> 
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
</code></pre> 
<p>同步到其他节点，重启yarn</p> 
<pre><code class="prism language-sh"><span class="token function">scp</span> <span class="token parameter variable">-r</span> yarn-site.xml node1:<span class="token variable"><span class="token variable">`</span><span class="token builtin class-name">pwd</span><span class="token variable">`</span></span>
<span class="token function">scp</span> <span class="token parameter variable">-r</span> yarn-site.xml node2:<span class="token variable"><span class="token variable">`</span><span class="token builtin class-name">pwd</span><span class="token variable">`</span></span>
</code></pre> 
<p>spark on yarn client模式 日志在本地输出，一班用于上线前测试</p> 
<pre><code class="prism language-sh">spark-submit <span class="token parameter variable">--class</span> org.apache.spark.examples.SparkPi <span class="token parameter variable">--master</span> <span class="token function">yarn</span> --deploy-mode client spark-examples_2.12-3.1.3.jar <span class="token number">100</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/3e/83/BtRzoQIF_o.png" alt="image.png"></p> 
<img src="https://images2.imgbox.com/89/3a/6JGjwipG_o.png" alt="spark yarn-client.png"> 
<p>spark on yarn cluster模式 上线使用，不会再本地打印日志 减少io</p> 
<pre><code class="prism language-sh">spark-submit <span class="token parameter variable">--class</span> org.apache.spark.examples.SparkPi <span class="token parameter variable">--master</span> <span class="token function">yarn</span> --deploy-mode cluster spark-examples_2.12-3.1.3.jar <span class="token number">100</span>

<span class="token function">yarn</span> logs <span class="token parameter variable">-applicationId</span> application_1720850173901_0001 <span class="token comment"># 查看日志</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/72/38/9GPsf7q6_o.png" alt="image.png"></p> 
<p><img src="https://images2.imgbox.com/ff/cb/qyFlAjOo_o.png" alt="yarn-cluster.png"></p> 
<p>案例：</p> 
<pre><code class="prism language-scala"><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span></span>RDD
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>

<span class="token comment">//读取hdfs上的学生数据，统计每个班级的人数，写回到hdfs上</span>
<span class="token keyword">object</span> Demo19YarnCluster <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"spark yarn cluster"</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>

    <span class="token comment">//如果是打包到集群的话，这里的路径就是hdfs路径</span>
    <span class="token comment">//如果是local的话，这个路径就是我们windows的路径</span>
    <span class="token keyword">val</span> linesRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"/bigdata30/students.csv"</span><span class="token punctuation">)</span>

    <span class="token comment">//coalesce函数，repartition函数可以修改分区</span>
<span class="token comment">//    val linesRDD2: RDD[String] = linesRDD.coalesce(1)</span>
<span class="token comment">//    linesRDD.repartition(1)</span>

    println<span class="token punctuation">(</span><span class="token string">"============================================================================================================="</span><span class="token punctuation">)</span>
    println<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token id function">s</span><span class="token string">"========================== linesRDD的分区数是:</span><span class="token interpolation"><span class="token punctuation">${<!-- --></span><span class="token expression">linesRDD<span class="token punctuation">.</span>getNumPartitions</span><span class="token punctuation">}</span></span><span class="token string"> ==================================="</span></span><span class="token punctuation">)</span>
    println<span class="token punctuation">(</span><span class="token string">"============================================================================================================="</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> clazzKVRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> linesRDD<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>line<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> <span class="token punctuation">{<!-- --></span>
      line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span> <span class="token keyword">match</span> <span class="token punctuation">{<!-- --></span>
        <span class="token keyword">case</span> Array<span class="token punctuation">(</span>_<span class="token punctuation">,</span> _<span class="token punctuation">,</span> _<span class="token punctuation">,</span> _<span class="token punctuation">,</span> clazz<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span>
          <span class="token punctuation">(</span>clazz<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment">// 班级和1构成的键值对</span>
      <span class="token punctuation">}</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> resultRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> clazzKVRDD<span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_ <span class="token operator">+</span> _<span class="token punctuation">)</span>

    <span class="token keyword">val</span> resultRDD2<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> resultRDD<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>t2<span class="token operator">:</span> <span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> <span class="token string-interpolation"><span class="token id function">s</span><span class="token string">"</span><span class="token interpolation"><span class="token punctuation">${<!-- --></span><span class="token expression">t2<span class="token punctuation">.</span>_1</span><span class="token punctuation">}</span></span><span class="token string">,</span><span class="token interpolation"><span class="token punctuation">${<!-- --></span><span class="token expression">t2<span class="token punctuation">.</span>_2</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
    println<span class="token punctuation">(</span><span class="token string">"============================================================================================================="</span><span class="token punctuation">)</span>
    println<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token id function">s</span><span class="token string">"========================== resultRDD2的分区数是:</span><span class="token interpolation"><span class="token punctuation">${<!-- --></span><span class="token expression">resultRDD2<span class="token punctuation">.</span>getNumPartitions</span><span class="token punctuation">}</span></span><span class="token string"> ==================================="</span></span><span class="token punctuation">)</span>
    println<span class="token punctuation">(</span><span class="token string">"============================================================================================================="</span><span class="token punctuation">)</span>

    <span class="token comment">//行动算子，触发作业执行</span>
    resultRDD2<span class="token punctuation">.</span>saveAsTextFile<span class="token punctuation">(</span><span class="token string">"/bigdata30/sparkout1"</span><span class="token punctuation">)</span>

  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>打包上传 在jar包目录下运行</p> 
<pre><code class="prism language-sh">spark-submit <span class="token parameter variable">--class</span> com.shujia.core.Demo19YarnCluster <span class="token parameter variable">--master</span> <span class="token function">yarn</span> --deploy-mode cluster spark-1.0.jar
</code></pre> 
<p>在HDFS上可以看到结果</p> 
<h4><a id="_1471"></a>术语解释</h4> 
<blockquote> 
 <p>Application：基于Spark的应用程序，包含了driver程序和 集群上的executor</p> 
 <p>DriverProgram：运行main函数并且新建SparkContext的程序</p> 
 <p>ClusterManager：在集群上获取资源的外部服务(例如 standalone,Mesos,Yarn )</p> 
 <p>WorkerNode：集群中任何可以运行应用用代码的节点</p> 
 <p>Executor：是在一个workernode上为某应用用启动的一个进程，该进程负责运行任务，并且负责将数据存在内存或者磁盘上。每个应用用都有各自自独立的executors</p> 
 <p>Task：被送到某个executor上的执行单元 线程</p> 
 <p>Job：包含很多任务的并行计算的task，可以看做和Spark的action对应，每个action都会触发一个job任务</p> 
 <p>Stage：一个Job会被拆分很多组任务，每组任务被称为Stage(就像MapReduce分map任务和reduce任务一样)</p> 
</blockquote> 
<h4><a id="_1491"></a>任务调度</h4> 
<p>包含 重试机制 推测执行机制</p> 
<p><img src="https://images2.imgbox.com/3e/b1/6OXxji2s_o.png" alt="spark.png"></p> 
<p>DAG Scheduler：</p> 
<blockquote> 
 <p>基于Stage构建DAG，决定每个任务的最佳位置</p> 
 <p>记录哪个RDD或者Stage输出被物化</p> 
 <p>将taskset传给底层调度器TaskScheduler</p> 
 <p>重新提交shuffle输出丢失的stage</p> 
</blockquote> 
<p>Task Scheduler:</p> 
<blockquote> 
 <p>提交taskset(一组并行task)到集群运行并汇报结果</p> 
 <p>出现shuffle输出lost要报告fetchfailed错误</p> 
 <p>碰到straggle任务需要放到别的节点上重试</p> 
 <p>为每一一个TaskSet维护一一个TaskSetManager(追踪本地性及错误信息)</p> 
</blockquote> 
<h4><a id="_1519"></a>累加器</h4> 
<img src="https://images2.imgbox.com/90/92/sBJMT7OU_o.png" alt=".png"> 
<pre><code class="prism language-scala"><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span></span>RDD
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span>LongAccumulator
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>

<span class="token keyword">object</span> Demo21Accumulator <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"累加器案例"</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>

        <span class="token keyword">val</span> linesRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"spark/data/students.txt"</span><span class="token punctuation">)</span>

<span class="token comment">//        var num = 0</span>

    <span class="token comment">/**
     * 累加器
     * 必要有行动算子触发作业执行
     * 1.因为累加器的执行是在RDD中执行的，而RDD是在Executor中执行的，而要想在Executor中执行就得有一个action算子触发任务调度
     * 
     */</span>


<span class="token comment">//        linesRDD.foreach((e: String) =&gt; {<!-- --></span>
<span class="token comment">//          num += 1</span>
<span class="token comment">//          println("-----------------------")</span>
<span class="token comment">//          println(num) // 可以到1000</span>
<span class="token comment">//        })</span>
<span class="token comment">//        println(s"num的值为：$num") // 0</span>

    <span class="token comment">//使用累加器</span>
    <span class="token comment">// 创建累加器变量</span>
        <span class="token keyword">val</span> c1<span class="token operator">:</span> LongAccumulator <span class="token operator">=</span> sc<span class="token punctuation">.</span>longAccumulator<span class="token punctuation">(</span><span class="token string">"c1"</span><span class="token punctuation">)</span>
        linesRDD<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span><span class="token punctuation">(</span>e<span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">)</span><span class="token keyword">=&gt;</span><span class="token punctuation">{<!-- --></span>
          c1<span class="token punctuation">.</span>add<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token punctuation">}</span><span class="token punctuation">)</span>
        println<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token id function">s</span><span class="token string">"累加之后的值为：</span><span class="token interpolation"><span class="token punctuation">${<!-- --></span><span class="token expression">c1<span class="token punctuation">.</span>value</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

    <span class="token comment">//使用累加器</span>
    <span class="token comment">// 使用map时 必须加上行动算子触发作业执行</span>
<span class="token comment">//        val c1: LongAccumulator = sc.longAccumulator("c1")</span>
<span class="token comment">//        linesRDD.map((e: String) =&gt; {<!-- --></span>
<span class="token comment">//          c1.add(1)</span>
<span class="token comment">//        }).collect()</span>
<span class="token comment">//        println(s"累加之后的值为：${c1.value}")</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<h4><a id="Spark_RDD__1576"></a>Spark RDD 注意事项</h4> 
<pre><code class="prism language-scala">	<span class="token comment">/**
     * 写spark core程序的注意事项
     * 1、RDD中无法嵌套使用RDD
     * 2、RDD中无法使用SparkContext
     */</span>
        <span class="token keyword">val</span> studentLinesRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"spark/data/students.txt"</span><span class="token punctuation">)</span>
        <span class="token keyword">val</span> scoreLinesRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"spark/data/score.txt"</span><span class="token punctuation">)</span>

        <span class="token keyword">val</span> rdd1<span class="token operator">:</span> RDD<span class="token punctuation">[</span>RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> studentLinesRDD<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>line1<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> <span class="token punctuation">{<!-- --></span>
          scoreLinesRDD<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>line2<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> <span class="token punctuation">{<!-- --></span>
            <span class="token keyword">val</span> s1<span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span> line1<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mkString<span class="token punctuation">(</span><span class="token string">"|"</span><span class="token punctuation">)</span>
            <span class="token keyword">val</span> s2<span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span> line2<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mkString<span class="token punctuation">(</span><span class="token string">"|"</span><span class="token punctuation">)</span>
            <span class="token punctuation">(</span>s1<span class="token punctuation">,</span> s2<span class="token punctuation">)</span>
          <span class="token punctuation">}</span><span class="token punctuation">)</span>
        <span class="token punctuation">}</span><span class="token punctuation">)</span>

        rdd1<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span> <span class="token comment">// 报错</span>

<span class="token comment">//    val studentLinesRDD: RDD[String] = sc.textFile("spark/data/students.txt")</span>
<span class="token comment">//    val scoreLinesRDD: RDD[String] = sc.textFile("spark/data/score.txt")</span>
<span class="token comment">//</span>
<span class="token comment">//    val rdd1: RDD[RDD[(String, String)]] = studentLinesRDD.map((line1: String) =&gt; {<!-- --></span>
<span class="token comment">//      sc.textFile("spark/data/score.txt").map((line2: String) =&gt; {<!-- --></span>
<span class="token comment">//        val s1: String = line1.split(",").mkString("|")</span>
<span class="token comment">//        val s2: String = line2.split(",").mkString("|")</span>
<span class="token comment">//        (s1, s2)</span>
<span class="token comment">//      })</span>
<span class="token comment">//    })</span>
</code></pre> 
<h4><a id="_1611"></a>广播变量</h4> 
<pre><code class="prism language-scala"><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>broadcast<span class="token punctuation">.</span></span>Broadcast
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span></span>RDD
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">scala<span class="token punctuation">.</span>collection<span class="token punctuation">.</span>mutable</span>
<span class="token keyword">import</span> <span class="token namespace">scala<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>BufferedSource<span class="token punctuation">,</span> Source<span class="token punctuation">}</span>

<span class="token comment">/**
 * 广播大变量
 */</span>
<span class="token keyword">object</span> Demo22Broadcast <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"广播变量"</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> sc<span class="token operator">:</span> SparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>

    <span class="token keyword">val</span> bs<span class="token operator">:</span> List<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> Source<span class="token punctuation">.</span>fromFile<span class="token punctuation">(</span><span class="token string">"spark/data/students.txt"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>getLines<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toList
    <span class="token comment">//map1变量在Driver端</span>
    <span class="token comment">//会随着task任务一并发送到executor中执行，后期随着map1的数据量变大</span>
    <span class="token comment">//也就意味着，每次发送任务，附带的数据量就会很大，无形之中，降低的执行速度</span>
    <span class="token keyword">val</span> map1<span class="token operator">:</span> mutable<span class="token punctuation">.</span>Map<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token keyword">new</span> mutable<span class="token punctuation">.</span>HashMap<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> <span class="token punctuation">(</span>elem <span class="token keyword">&lt;-</span> bs<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
      <span class="token keyword">val</span> array1<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> elem<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span>
      <span class="token keyword">val</span> id<span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span> array1<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
      <span class="token keyword">val</span> name<span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span> array1<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
      <span class="token keyword">val</span> age<span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span> array1<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>
      <span class="token keyword">val</span> gender<span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span> array1<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>
      <span class="token keyword">val</span> clazz<span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span> array1<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span>
      map1<span class="token punctuation">.</span>put<span class="token punctuation">(</span>id<span class="token punctuation">,</span> name <span class="token operator">+</span> <span class="token string">","</span> <span class="token operator">+</span> age <span class="token operator">+</span> <span class="token string">","</span> <span class="token operator">+</span> gender <span class="token operator">+</span> <span class="token string">","</span> <span class="token operator">+</span> clazz<span class="token punctuation">)</span>
    <span class="token punctuation">}</span>

    <span class="token comment">/**
     * 广播变量
     * 使用SparkContext中的一个功能，将Driver端的变量广播到executor执行的节点上的blockManager中
     */</span>
    <span class="token keyword">val</span> bc<span class="token operator">:</span> Broadcast<span class="token punctuation">[</span>mutable<span class="token punctuation">.</span>Map<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>broadcast<span class="token punctuation">(</span>map1<span class="token punctuation">)</span>


    <span class="token keyword">val</span> scoreRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"spark/data/score.txt"</span><span class="token punctuation">)</span>

    <span class="token comment">//未使用广播变量</span>
    <span class="token comment">//    val resRDD: RDD[(String, String, String)] = scoreRDD.map((line: String) =&gt; {<!-- --></span>
    <span class="token comment">//      val array1: Array[String] = line.split(",")</span>
    <span class="token comment">//      val id: String = array1(0)</span>
    <span class="token comment">//      //      通过map1的变量，通过键获取值</span>
    <span class="token comment">//      val info: String = map1.getOrElse(id, "查无此人") // map1相当于一个副本与task任务一起发送到Executor中执行</span>
    <span class="token comment">//      val score: String = array1(2)</span>
    <span class="token comment">//      (id, info, score)</span>
    <span class="token comment">//    })</span>

    <span class="token comment">//使用广播变量</span>
      <span class="token comment">//以广播变量的形式，发送到Executor中的blockManager中</span>
      <span class="token comment">// 只发送计算逻辑</span>
    <span class="token keyword">val</span> resRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> scoreRDD<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>line<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> <span class="token punctuation">{<!-- --></span>
      <span class="token keyword">val</span> array1<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span>
      <span class="token keyword">val</span> id<span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span> array1<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>  
      <span class="token comment">//通过广播过来的大变量，进行关联数据 .value 方法取出变量</span>
      <span class="token keyword">val</span> map2<span class="token operator">:</span> mutable<span class="token punctuation">.</span>Map<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> bc<span class="token punctuation">.</span>value  
      <span class="token keyword">val</span> info<span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span> map2<span class="token punctuation">.</span>getOrElse<span class="token punctuation">(</span>id<span class="token punctuation">,</span> <span class="token string">"查无此人"</span><span class="token punctuation">)</span>
      <span class="token keyword">val</span> score<span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span> array1<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>
      <span class="token punctuation">(</span>id<span class="token punctuation">,</span> info<span class="token punctuation">,</span> score<span class="token punctuation">)</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span>

    resRDD<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>BlockManager：</p> 
<img src="https://images2.imgbox.com/95/c5/5iyduZOs_o.png" alt="blockmanger.png"> 
<h3><a id="Spark_Sql_1687"></a>Spark Sql</h3> 
<p>Spark SQL是Spark的核心组件之一</p> 
<p>与RDD类似，DataFrame也是一个分布式数据容器，是spark sql的重要的数据结构</p> 
<p>初识spark sql： WordCount</p> 
<p>数据准备</p> 
<img src="https://images2.imgbox.com/e0/f8/g0GFOHfO_o.png" alt="image.png"> 
<blockquote> 
 <p>spark sql处理数据的步骤</p> 
 <ul><li>1、读取数据源</li><li>2、将读取到的DF注册成一个临时视图</li><li>3、使用sparkSession的sql函数，编写sql语句操作临时视图，返回的依旧是一个DataFrame</li><li>4、将结果写出到hdfs上</li></ul> 
</blockquote> 
<pre><code class="prism language-scala"><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span>SparkContext
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>DataFrame<span class="token punctuation">,</span> Dataset<span class="token punctuation">,</span> Row<span class="token punctuation">,</span> SaveMode<span class="token punctuation">,</span> SparkSession<span class="token punctuation">}</span>

<span class="token keyword">object</span> Demo1WordCount <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token comment">// spark sql的环境</span>
    <span class="token keyword">val</span> ss<span class="token operator">:</span> SparkSession <span class="token operator">=</span> SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>master<span class="token punctuation">(</span><span class="token string">"local"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>appName<span class="token punctuation">(</span><span class="token string">"sql语法"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment">// spark sql是spark core的上层api，如果要想使用rdd的编程</span>
    <span class="token comment">// 可以直接通过sparkSession获取SparkContext对象</span>
<span class="token comment">//    val context: SparkContext = ss.sparkContext</span>

      <span class="token comment">// 读文件</span>
      <span class="token comment">//spark sql的核心数据类型是DataFrame</span>
      <span class="token keyword">val</span> df1<span class="token operator">:</span> DataFrame <span class="token operator">=</span> ss<span class="token punctuation">.</span>read
        <span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">"csv"</span><span class="token punctuation">)</span> <span class="token comment">// 读取csv格式的文件，但是实际上这种做法可以读取任意分隔符的文本文件</span>
        <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"sep"</span><span class="token punctuation">,</span> <span class="token string">"\n"</span><span class="token punctuation">)</span> <span class="token comment">//指定读取数据的列与列之间的分隔符</span>
        <span class="token punctuation">.</span>schema<span class="token punctuation">(</span><span class="token string">"line String"</span><span class="token punctuation">)</span> <span class="token comment">// 指定表的列字段 包括列名和列数据类型</span>
        <span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"spark/data/wcs/words.txt"</span><span class="token punctuation">)</span>

    <span class="token comment">// 查看dataframe的数据内容</span>
<span class="token comment">//      df1.show()</span>
    <span class="token comment">//查看表结构</span>
    <span class="token comment">//    df1.printSchema()</span>


    <span class="token comment">/**
     * sql语句是无法直接作用在DataFrame上面的
     * 需要提前将要使用sql分析的DataFrame注册成一张表（临时视图）
     */</span>
    <span class="token comment">//老版本的做法将df注册成一张表</span>
    <span class="token comment">//    df1.registerTempTable("wcs")</span>
    df1<span class="token punctuation">.</span>createOrReplaceTempView<span class="token punctuation">(</span><span class="token string">"wcs"</span><span class="token punctuation">)</span>

    <span class="token comment">/**
     * 编写sql语句作用在表上
     * sql语法是完全兼容hive语法
     */</span>
    <span class="token keyword">val</span> df2<span class="token operator">:</span> DataFrame <span class="token operator">=</span> ss<span class="token punctuation">.</span>sql<span class="token punctuation">(</span>
      <span class="token triple-quoted-string string">"""
        |select
        |t1.word,
        |count(1) as counts
        |from(
        |select
        |explode(split(line,'\\|')) as word
        |from wcs) t1 group by t1.word
        |"""</span><span class="token punctuation">.</span>stripMargin<span class="token punctuation">)</span>
      df2<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">// show默认结果只展示20条数据</span>

    <span class="token comment">//通过观察源码发现，DataFrame底层数据类型其实就是封装了DataSet的数据类型</span>
    <span class="token keyword">val</span> resDS<span class="token operator">:</span> Dataset<span class="token punctuation">[</span>Row<span class="token punctuation">]</span> <span class="token operator">=</span> df2<span class="token punctuation">.</span>repartition<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment">// 设置分区为1 合并分区</span>

    <span class="token comment">//将计算后的DataFrame保存到本地磁盘文件中</span>
    resDS<span class="token punctuation">.</span>write
      <span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">"csv"</span><span class="token punctuation">)</span> <span class="token comment">//csv文件默认的分隔符是英文逗号</span>
      <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"sep"</span><span class="token punctuation">,</span><span class="token string">"\t"</span><span class="token punctuation">)</span>  <span class="token comment">// 设置分隔符</span>
      <span class="token punctuation">.</span>mode<span class="token punctuation">(</span>SaveMode<span class="token punctuation">.</span>Overwrite<span class="token punctuation">)</span> <span class="token comment">// 如果想每次覆盖之前的执行结果的话，可以在写文件的同时指定写入模式，使用模式枚举类</span>
      <span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string">"spark/data/sqlOut1"</span><span class="token punctuation">)</span>  <span class="token comment">// 路径是一个文件夹</span>

  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<img src="https://images2.imgbox.com/fc/59/sGkyWcBY_o.png" alt="image.png"> 
<h4><a id="DSL_WordCount_1778"></a>DSL WordCount</h4> 
<pre><code class="prism language-scala">
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>DataFrame<span class="token punctuation">,</span> SaveMode<span class="token punctuation">,</span> SparkSession<span class="token punctuation">}</span>

<span class="token keyword">object</span> Demo2DSLWordCount <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token comment">//创建SparkSession对象</span>
    <span class="token keyword">val</span> sparkSession<span class="token operator">:</span> SparkSession <span class="token operator">=</span> SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>master<span class="token punctuation">(</span><span class="token string">"local"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>appName<span class="token punctuation">(</span><span class="token string">"DSL语法风格编写spark sql"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> df1<span class="token operator">:</span> DataFrame <span class="token operator">=</span> sparkSession<span class="token punctuation">.</span>read
      <span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">"csv"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>schema<span class="token punctuation">(</span><span class="token string">"line STRING"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"sep"</span><span class="token punctuation">,</span> <span class="token string">"\n"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"spark/data/wcs/words.txt"</span><span class="token punctuation">)</span>

    <span class="token comment">/**
     * 如果要想使用DSL语法编写spark sql的话，需要导入两个隐式转换
     */</span>
    <span class="token comment">//将sql中的函数，封装成spark程序中的一个个的函数直接调用，以传参的方式调用</span>
    <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>functions<span class="token punctuation">.</span></span>_
    <span class="token comment">//主要作用是，将来可以在调用的函数中，使用$函数，将列名字符串类型转成一个ColumnName类型</span>
    <span class="token comment">//而ColumnName是继承自Column类的</span>
    <span class="token keyword">import</span> <span class="token namespace">sparkSession<span class="token punctuation">.</span>implicits<span class="token punctuation">.</span></span>_

    <span class="token comment">//老版本聚合操作</span>
    <span class="token comment">//    df1.select(explode(split($"line","\\|")) as "word")</span>
    <span class="token comment">//      .groupBy($"word")</span>
    <span class="token comment">//      .count().show()</span>

    <span class="token comment">//新版本聚合操作</span>
    <span class="token keyword">val</span> resDF<span class="token operator">:</span> DataFrame <span class="token operator">=</span> df1<span class="token punctuation">.</span>select<span class="token punctuation">(</span>explode<span class="token punctuation">(</span>split<span class="token punctuation">(</span>$<span class="token string">"line"</span><span class="token punctuation">,</span> <span class="token string">"\\|"</span><span class="token punctuation">)</span><span class="token punctuation">)</span> as <span class="token string">"word"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>groupBy<span class="token punctuation">(</span>$<span class="token string">"word"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>agg<span class="token punctuation">(</span>count<span class="token punctuation">(</span>$<span class="token string">"word"</span><span class="token punctuation">)</span> as <span class="token string">"counts"</span><span class="token punctuation">)</span>

    resDF<span class="token punctuation">.</span>repartition<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>write
      <span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">"csv"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"sep"</span><span class="token punctuation">,</span><span class="token string">"\t"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>mode<span class="token punctuation">(</span>SaveMode<span class="token punctuation">.</span>Overwrite<span class="token punctuation">)</span>
      <span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string">"spark/data/sqlOut2"</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<h4><a id="DSl_1827"></a>DSl语法</h4> 
<pre><code class="prism language-scala"><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>expressions<span class="token punctuation">.</span></span>Window
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>DataFrame<span class="token punctuation">,</span> SaveMode<span class="token punctuation">,</span> SparkSession<span class="token punctuation">}</span>
<span class="token keyword">object</span> Demo3DSLApi <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>

    <span class="token comment">//创建SparkSession对象</span>
        <span class="token keyword">val</span> sparkSession<span class="token operator">:</span> SparkSession <span class="token operator">=</span> SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span>
          <span class="token punctuation">.</span>config<span class="token punctuation">(</span><span class="token string">"spark.sql.shuffle.partitions"</span><span class="token punctuation">,</span><span class="token string">"1"</span><span class="token punctuation">)</span> <span class="token comment">// 设置分区数 全局设置</span>
          <span class="token punctuation">.</span>master<span class="token punctuation">(</span><span class="token string">"local"</span><span class="token punctuation">)</span>
          <span class="token punctuation">.</span>appName<span class="token punctuation">(</span><span class="token string">"DSL语法风格编写spark sql"</span><span class="token punctuation">)</span>
          <span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>functions<span class="token punctuation">.</span></span>_
        <span class="token keyword">import</span> <span class="token namespace">sparkSession<span class="token punctuation">.</span>implicits<span class="token punctuation">.</span></span>_

    <span class="token comment">// 读取json文件 转成DF</span>
<span class="token comment">//    读取json数据的时候，是不需要指定表结构，可以自动根据json的键值来构建DataFrame</span>
<span class="token comment">//    sparkSession.read</span>
<span class="token comment">//      .format("json")</span>
<span class="token comment">//      .load("spark/data/students.json")</span>
    <span class="token comment">// 新版</span>
        <span class="token keyword">val</span> df1<span class="token operator">:</span> DataFrame <span class="token operator">=</span> sparkSession<span class="token punctuation">.</span>read<span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token string">"spark/data/students.json"</span><span class="token punctuation">)</span>
<span class="token comment">//        df1.show(100)    // 可以指定读取数据行数</span>
      <span class="token comment">// 一列值过长时，不能完全显示 传入第二个参数，使其更详细</span>
<span class="token comment">//      df1.show(100,truncate = false)</span>

    <span class="token comment">/*
    * DSL 语法的函数
    * */</span>

    <span class="token comment">/*
    *select
    *类似于纯sql语法中的select关键字，传入要查询的列
    */</span>
    <span class="token comment">//LIKE：select name,clazz from xxx;</span>
<span class="token comment">//      df1.select("name","clazz").show()</span>
    <span class="token comment">// another type</span>
    <span class="token comment">//    df1.select($"name", $"age").show()</span>
    <span class="token comment">//查询每个学生的姓名，原本的年龄，年龄+1</span>
    <span class="token comment">/**
     * 与select功能差不多的查询函数
     * 如果要以传字符串的形式给到select的话，并且还想对列进行表达式处理的话，可以使用selectExpr函数
     */</span>
<span class="token comment">//      df1.selectExpr("name","age","age+1 as new_age").show()</span>
    <span class="token comment">//如果想要使用select函数查询的时候对列做操作的话，可以使用$函数将列变成一个对象</span>
<span class="token comment">//        df1.select($"name", $"age", $"age" + 1 as "new_age").show()</span>


    <span class="token comment">/*
    * where
    * 过滤
    * */</span>
<span class="token comment">//    df1.where("gender='男'").show()</span>
<span class="token comment">//    df1.where("gender='男' and substring(clazz,0,2)='理科'").show()// 不如sql语句</span>
    <span class="token comment">//建议使用隐式转换中的功能进行处理过滤 === 三个等号 类似于sql中的=</span>
<span class="token comment">//      df1.where($"gender"==="男" and substring($"clazz",0,2)==="理科").show()</span>

        <span class="token comment">// 过滤出女生 理科  不等于男生</span>
<span class="token comment">//     =!= : 类似于sql中的!=或者&lt;&gt;  不等于某个值</span>
<span class="token comment">//        df1.where($"gender"=!="男" and substring($"clazz",0,2)==="理科").show()</span>


    <span class="token comment">/*
    * groupBy
    * 非分组字段是无法出现在select查询语句中的
    * */</span>
    <span class="token comment">//查询每个班级的人数</span>
    <span class="token comment">//    df1.groupBy("clazz")</span>
    <span class="token comment">//      .agg(count("clazz") as "counts")</span>
    <span class="token comment">//      .show()</span>


      <span class="token comment">/*
      * orderBy
      * */</span>
    <span class="token comment">//    df1.groupBy("clazz")</span>
    <span class="token comment">//      .agg(count("clazz") as "counts")</span>
    <span class="token comment">//      .orderBy($"counts".desc)  // 降序</span>
    <span class="token comment">//      .show(3)</span>


    <span class="token comment">/*
    * join
    * */</span>
<span class="token keyword">val</span> df2<span class="token operator">:</span> DataFrame <span class="token operator">=</span> sparkSession<span class="token punctuation">.</span>read
  <span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">"csv"</span><span class="token punctuation">)</span>
  <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"sep"</span><span class="token punctuation">,</span> <span class="token string">","</span><span class="token punctuation">)</span>
  <span class="token punctuation">.</span>schema<span class="token punctuation">(</span><span class="token string">"id STRING,subject_id STRING,score INT"</span><span class="token punctuation">)</span>
  <span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"spark/data/score.txt"</span><span class="token punctuation">)</span>

    <span class="token comment">// df1与df2关联</span>
    <span class="token comment">//关联字段名不一样的情况</span>
<span class="token comment">//    df2.join(df1,$"id"===$"sid","inner")</span>
<span class="token comment">//      .select("id","name","age","gender","clazz","subject_id","score")</span>
<span class="token comment">//      .show(10)</span>

    <span class="token comment">// 一样的情况</span>
<span class="token comment">//    df2.join(df1,"id")</span>
<span class="token comment">//          .select("id","name","age","gender","clazz","subject_id","score")</span>
<span class="token comment">//          .show(10)</span>

    <span class="token comment">//如果关联的字段名一样且想使用其他连接方式的话,可以将字段名字用Seq()传入,同时可以传连接方式</span>
    <span class="token comment">//    df2.join(df1, Seq("id"),"left")</span>
    <span class="token comment">//          .select("id","name","age","gender","clazz","subject_id","score")</span>
    <span class="token comment">//          .show(10)</span>


    <span class="token comment">/*
    * 开窗
    *无论是在纯sql中还是在DSL语法中,开窗是不会改变原表条数
    * */</span>
    <span class="token comment">//计算每个班级总分前3的学生</span>
    <span class="token comment">//纯spark sql的方式实现</span>
    <span class="token comment">//    df1.createOrReplaceTempView("students")</span>
    <span class="token comment">//    df2.createOrReplaceTempView("scores")</span>
    <span class="token comment">//    sparkSession.sql(</span>
    <span class="token comment">//      """</span>
    <span class="token comment">//        |select</span>
    <span class="token comment">//        |*</span>
    <span class="token comment">//        |from</span>
    <span class="token comment">//        |(</span>
    <span class="token comment">//        |select t1.id,</span>
    <span class="token comment">//        |t2.name,</span>
    <span class="token comment">//        |t2.clazz,</span>
    <span class="token comment">//        |t1.sumScore,</span>
    <span class="token comment">//        |row_number() over(partition by t2.clazz order by t1.sumScore desc) as rn</span>
    <span class="token comment">//        |from</span>
    <span class="token comment">//        |(</span>
    <span class="token comment">//        | select id,</span>
    <span class="token comment">//        |        sum(score) as sumScore</span>
    <span class="token comment">//        | from</span>
    <span class="token comment">//        |   scores</span>
    <span class="token comment">//        | group by id) t1</span>
    <span class="token comment">//        |join</span>
    <span class="token comment">//        | students t2</span>
    <span class="token comment">//        |on(t1.id=t2.id)) tt1 where tt1.rn&lt;=3</span>
    <span class="token comment">//        |""".stripMargin).show()</span>

<span class="token comment">// DSl实现</span>
  df2<span class="token punctuation">.</span>groupBy<span class="token punctuation">(</span><span class="token string">"id"</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span>agg<span class="token punctuation">(</span>sum<span class="token punctuation">(</span><span class="token string">"score"</span><span class="token punctuation">)</span> as <span class="token string">"sumScore"</span><span class="token punctuation">)</span> <span class="token comment">// 计算总分</span>
    <span class="token punctuation">.</span>join<span class="token punctuation">(</span>df1<span class="token punctuation">,</span><span class="token string">"id"</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span>select<span class="token punctuation">(</span>$<span class="token string">"id"</span><span class="token punctuation">,</span>$<span class="token string">"name"</span><span class="token punctuation">,</span>$<span class="token string">"clazz"</span><span class="token punctuation">,</span>$<span class="token string">"sumScore"</span><span class="token punctuation">,</span>row_number<span class="token punctuation">(</span><span class="token punctuation">)</span> over Window<span class="token punctuation">.</span>partitionBy<span class="token punctuation">(</span><span class="token string">"clazz"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>orderBy<span class="token punctuation">(</span>$<span class="token string">"sumScore"</span><span class="token punctuation">.</span>desc<span class="token punctuation">)</span>as <span class="token string">"rn"</span><span class="token punctuation">)</span> <span class="token comment">//开窗 排序</span>
    <span class="token punctuation">.</span>where<span class="token punctuation">(</span>$<span class="token string">"rn"</span><span class="token operator">&lt;=</span><span class="token number">3</span><span class="token punctuation">)</span>
    <span class="token comment">//.repartition(1) 单独设置分区数</span>
    <span class="token punctuation">.</span>write
    <span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">"csv"</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span>mode<span class="token punctuation">(</span>SaveMode<span class="token punctuation">.</span>Overwrite<span class="token punctuation">)</span>
    <span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string">"spark/data/sqlOut3"</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<h4><a id="Date_Source_Api_1985"></a>Date Source Api</h4> 
<pre><code class="prism language-scala"><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span>SparkSession

<span class="token keyword">object</span> Demo4SourceAPI <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">val</span> sparkSession<span class="token operator">:</span> SparkSession <span class="token operator">=</span> SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>master<span class="token punctuation">(</span><span class="token string">"local"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>appName<span class="token punctuation">(</span><span class="token string">"data source api"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>config<span class="token punctuation">(</span><span class="token string">"spark.sql.shuffle.partitions"</span><span class="token punctuation">,</span> <span class="token string">"1"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment">/**
     * 导入隐式转换
     */</span>

    <span class="token comment">/**
     * ================================读写csv格式的数据=========================
     */</span>
    <span class="token comment">//如果是直接调用csv函数读取数据的话，无法做表结构的设置</span>
    <span class="token comment">//    val df1: DataFrame = sparkSession.read</span>
    <span class="token comment">//      .csv("spark/data/test1.csv")</span>
    <span class="token comment">//    //使用format的形式读取数据的同时可以设置表结构</span>
    <span class="token comment">//    val df2: DataFrame = sparkSession.read</span>
    <span class="token comment">//      .format("csv")</span>
    <span class="token comment">//      .schema("id STRING,name STRING,age INT")</span>
    <span class="token comment">//      .load("spark/data/test1.csv")</span>
    <span class="token comment">//    df2.show()</span>
		<span class="token comment">// 读取学生数据</span>
    <span class="token comment">//    val df1: DataFrame = sparkSession.read</span>
    <span class="token comment">//      .format("csv")</span>
    <span class="token comment">//      .schema("id STRING,name STRING,age INT,gender STRING,clazz STRING")</span>
    <span class="token comment">//      .option("sep", ",")</span>
    <span class="token comment">//      .load("spark/data/students.txt")</span>
    <span class="token comment">//</span>
    <span class="token comment">//    df1.createOrReplaceTempView("students")</span>
    <span class="token comment">//</span>
    <span class="token comment">//    val resDF1: DataFrame = sparkSession.sql(</span>
    <span class="token comment">//      """</span>
    <span class="token comment">//        |select</span>
    <span class="token comment">//        |clazz,</span>
    <span class="token comment">//        |count(1) as counts</span>
    <span class="token comment">//        |from students</span>
    <span class="token comment">//        |group by clazz</span>
    <span class="token comment">//        |""".stripMargin)</span>
    <span class="token comment">//    //以csv格式写出到磁盘文件夹中</span>
    <span class="token comment">//    resDF1.write</span>
    <span class="token comment">//      .format("csv")</span>
    <span class="token comment">      .option("sep",",")</span>
    <span class="token comment">//      .mode(SaveMode.Overwrite)</span>
    <span class="token comment">//      .save("spark/data/sqlout4")</span>

    <span class="token comment">/**
     * ===================================读写json格式的数据========================
     */</span>
    <span class="token comment">//    val df1: DataFrame = sparkSession.read</span>
    <span class="token comment">//      .json("spark/data/students.json")</span>
    <span class="token comment">//   写数据</span>
    <span class="token comment">//    df1.groupBy("age")</span>
    <span class="token comment">//      .agg(count("age") as "counts")</span>
    <span class="token comment">//      .write</span>
    <span class="token comment">//      .json("spark/data/sqlout5")</span>

    <span class="token comment">/**
     * ================================读写parquet格式的数据=================
     *
     * parquet格式的文件存储，是由【信息熵】决定的
     */</span>
    <span class="token comment">//    val df1: DataFrame = sparkSession.read</span>
    <span class="token comment">//      .json("spark/data/students2.json")</span>
    <span class="token comment">//</span>
    <span class="token comment">//    //以parquet格式写出去</span>
    <span class="token comment">//    df1.write</span>
    <span class="token comment">//      .parquet("spark/data/sqlout7")</span>

    <span class="token comment">//读取parquet格式的数据</span>
    <span class="token comment">//    val df2: DataFrame = sparkSession.read</span>
    <span class="token comment">//      .parquet("spark/data/sqlout7/part-00000-23f5482d-74d5-4569-9bf4-ea0ec91e86dd-c000.snappy.parquet")</span>
    <span class="token comment">//    df2.show()</span>

    <span class="token comment">/**
     * ======================================读写orc格式的数据=====================
     *文件被压缩的更小 读写速度最快
     */</span>
<span class="token comment">//    val df1: DataFrame = sparkSession.read</span>
<span class="token comment">//      .json("spark/data/students2.json")</span>
<span class="token comment">//    df1.write</span>
<span class="token comment">//      .orc("spark/data/sqlout8")</span>
<span class="token comment">//</span>
<span class="token comment">//    sparkSession.read</span>
<span class="token comment">//      .orc("spark/data/sqlout8/part-00000-a33e356c-fd1f-4a5e-a87f-1d5b28f6008b-c000.snappy.orc")</span>
<span class="token comment">//      .show()</span>


    <span class="token comment">/**
     * ==================================读写jdbc格式的数据===================
     * 需要导入mysql驱动包
     */</span>
    sparkSession<span class="token punctuation">.</span>read
      <span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">"jdbc"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"url"</span><span class="token punctuation">,</span> <span class="token string">"jdbc:mysql://master:3306/studentdb?useUnicode=true&amp;characterEncoding=UTF-8&amp;useSSL=false"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"dbtable"</span><span class="token punctuation">,</span> <span class="token string">"studentdb.jd_goods"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"root"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"password"</span><span class="token punctuation">,</span> <span class="token string">"123456"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span>truncate <span class="token operator">=</span> <span class="token boolean">false</span><span class="token punctuation">)</span>

  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<h4><a id="RDDDataFrame_2097"></a>RDD与DataFrame互相转换</h4> 
<pre><code class="prism language-scala"><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span>SparkContext
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span></span>RDD
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>DataFrame<span class="token punctuation">,</span> Row<span class="token punctuation">,</span> SparkSession<span class="token punctuation">}</span>

<span class="token keyword">object</span> Demo5RDD2DataFrame <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">val</span> sparkSession<span class="token operator">:</span> SparkSession <span class="token operator">=</span> SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>master<span class="token punctuation">(</span><span class="token string">"local"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>appName<span class="token punctuation">(</span><span class="token string">"rdd与df之间的转换"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>config<span class="token punctuation">(</span><span class="token string">"spark.sql.shuffle.partitions"</span><span class="token punctuation">,</span> <span class="token string">"1"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment">//通过SparkSession获取sparkContext对象</span>
    <span class="token keyword">val</span> sparkContext<span class="token operator">:</span> SparkContext <span class="token operator">=</span> sparkSession<span class="token punctuation">.</span>sparkContext

    <span class="token comment">//作用1：使用$函数</span>
    <span class="token comment">//作用2：可以在不同的数据结构之间转换</span>
    <span class="token keyword">import</span> <span class="token namespace">sparkSession<span class="token punctuation">.</span>implicits<span class="token punctuation">.</span></span>_

    <span class="token comment">/**
     * spark core的核心数据结构是：RDD
     * spark sql的核心数据结构是DataFrame
     */</span>
    <span class="token comment">// RDD-&gt;DataFrame  .toDF</span>
    <span class="token keyword">val</span> linesRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sparkContext<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"spark/data/students.txt"</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> stuRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> linesRDD<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>line<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> <span class="token punctuation">{<!-- --></span>
      line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span> <span class="token keyword">match</span> <span class="token punctuation">{<!-- --></span>
        <span class="token keyword">case</span> Array<span class="token punctuation">(</span>id<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> name<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> age<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> gender<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> clazz<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span>
          <span class="token punctuation">(</span>id<span class="token punctuation">,</span> name<span class="token punctuation">,</span> age<span class="token punctuation">,</span> gender<span class="token punctuation">,</span> clazz<span class="token punctuation">)</span>
      <span class="token punctuation">}</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> resRDD1<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> stuRDD<span class="token punctuation">.</span>groupBy<span class="token punctuation">(</span>_<span class="token punctuation">.</span>_5<span class="token punctuation">)</span>
      <span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>kv<span class="token operator">:</span> <span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> Iterable<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> <span class="token punctuation">{<!-- --></span>
        <span class="token punctuation">(</span>kv<span class="token punctuation">.</span>_1<span class="token punctuation">,</span> kv<span class="token punctuation">.</span>_2<span class="token punctuation">.</span>size<span class="token punctuation">)</span>
      <span class="token punctuation">}</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> df1<span class="token operator">:</span> DataFrame <span class="token operator">=</span> resRDD1<span class="token punctuation">.</span>toDF  <span class="token comment">// 转成DF</span>
    <span class="token keyword">val</span> df2<span class="token operator">:</span> DataFrame <span class="token operator">=</span> df1<span class="token punctuation">.</span>select<span class="token punctuation">(</span>$<span class="token string">"_1"</span> as <span class="token string">"clazz"</span><span class="token punctuation">,</span> $<span class="token string">"_2"</span> as <span class="token string">"counts"</span><span class="token punctuation">)</span>
    df2<span class="token punctuation">.</span>printSchema<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment">// DataFrame-&gt;RDD  .rdd</span>
    <span class="token keyword">val</span> resRDD2<span class="token operator">:</span> RDD<span class="token punctuation">[</span>Row<span class="token punctuation">]</span> <span class="token operator">=</span> df2<span class="token punctuation">.</span>rdd
<span class="token comment">//    resRDD2.map((row:Row)=&gt;{<!-- --></span>
<span class="token comment">//      val clazz: String = row.getAs[String]("clazz")</span>
<span class="token comment">//      val counts: Integer = row.getAs[Integer]("counts")</span>
<span class="token comment">//      s"班级:$clazz, 人数:$counts"</span>
<span class="token comment">//    }).foreach(println)</span>
<span class="token comment">// 模式匹配</span>
    resRDD2<span class="token punctuation">.</span>map <span class="token punctuation">{<!-- --></span>
      <span class="token keyword">case</span> Row<span class="token punctuation">(</span>clazz<span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">,</span> counts<span class="token operator">:</span>Integer<span class="token punctuation">)</span><span class="token keyword">=&gt;</span>
        <span class="token string-interpolation"><span class="token id function">s</span><span class="token string">"班级:</span><span class="token interpolation"><span class="token punctuation">$</span><span class="token expression">clazz</span></span><span class="token string">, 人数:</span><span class="token interpolation"><span class="token punctuation">$</span><span class="token expression">counts</span></span><span class="token string">"</span></span>
    <span class="token punctuation">}</span><span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<h4><a id="_2155"></a>开窗函数</h4> 
<blockquote> 
 <p>开窗：over</p> 
 <ul><li>聚合开窗函数：sum count lag(取上一条) lead(取后一条)</li><li>排序开窗函数：row_number rank dense_rank</li></ul> 
</blockquote> 
<pre><code class="prism language-scala"><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>expressions<span class="token punctuation">.</span></span>Window
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>DataFrame<span class="token punctuation">,</span> Dataset<span class="token punctuation">,</span> Row<span class="token punctuation">,</span> SparkSession<span class="token punctuation">}</span>
<span class="token comment">/**
 *  练习开窗的题目： DSL语法去做
 *    统计总分年级排名前十学生各科的分数
 *    统计每科都及格的学生
 *    统计总分大于年级平均分的学生
 *    统计每个班级的每个名次之间的分数差
 */</span>
<span class="token keyword">object</span> Demo6WindowFun <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">val</span> sparkSession<span class="token operator">:</span> SparkSession <span class="token operator">=</span> SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>master<span class="token punctuation">(</span><span class="token string">"local"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>appName<span class="token punctuation">(</span><span class="token string">"rdd与df之间的转换"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>config<span class="token punctuation">(</span><span class="token string">"spark.sql.shuffle.partitions"</span><span class="token punctuation">,</span> <span class="token string">"1"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment">/**
     * 导入隐式转换你
     */</span>
    <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>functions<span class="token punctuation">.</span></span>_
    <span class="token keyword">import</span> <span class="token namespace">sparkSession<span class="token punctuation">.</span>implicits<span class="token punctuation">.</span></span>_

    <span class="token comment">/**
     * 读取三个数据文件
     */</span>
    <span class="token keyword">val</span> studentsDF<span class="token operator">:</span> DataFrame <span class="token operator">=</span> sparkSession<span class="token punctuation">.</span>read
      <span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">"csv"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>schema<span class="token punctuation">(</span><span class="token string">"id STRING,name STRING,age INT,gender STRING,clazz STRING"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"spark/data/students.txt"</span><span class="token punctuation">)</span>
<span class="token comment">//    studentsDF.show()</span>
    <span class="token keyword">val</span> scoresDF<span class="token operator">:</span> DataFrame <span class="token operator">=</span> sparkSession<span class="token punctuation">.</span>read
      <span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">"csv"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>schema<span class="token punctuation">(</span><span class="token string">"id STRING,subject_id STRING,score INT"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"spark/data/score.txt"</span><span class="token punctuation">)</span>
<span class="token comment">//    scoresDF.show()</span>
    <span class="token keyword">val</span> subjectsDF<span class="token operator">:</span> DataFrame <span class="token operator">=</span> sparkSession<span class="token punctuation">.</span>read
      <span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">"csv"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>schema<span class="token punctuation">(</span><span class="token string">"subject_id STRING,subject_name STRING,subject_score INT"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"spark/data/subject.txt"</span><span class="token punctuation">)</span>
<span class="token comment">//    subjectsDF.show()</span>

    <span class="token comment">//统计总分年级排名前十学生各科的分数</span>
    <span class="token keyword">val</span> resDS1<span class="token operator">:</span> Dataset<span class="token punctuation">[</span>Row<span class="token punctuation">]</span> <span class="token operator">=</span> scoresDF
      <span class="token punctuation">.</span>join<span class="token punctuation">(</span>studentsDF<span class="token punctuation">,</span> <span class="token string">"id"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"sumScore"</span><span class="token punctuation">,</span> sum<span class="token punctuation">(</span><span class="token string">"score"</span><span class="token punctuation">)</span> over Window<span class="token punctuation">.</span>partitionBy<span class="token punctuation">(</span><span class="token string">"id"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment">// dense_rank 不跳过排名 并列</span>
      <span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"rn"</span><span class="token punctuation">,</span> dense_rank<span class="token punctuation">(</span><span class="token punctuation">)</span> over Window<span class="token punctuation">.</span>partitionBy<span class="token punctuation">(</span>substring<span class="token punctuation">(</span>$<span class="token string">"clazz"</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>orderBy<span class="token punctuation">(</span>$<span class="token string">"sumScore"</span><span class="token punctuation">.</span>desc<span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>where<span class="token punctuation">(</span>$<span class="token string">"rn"</span> <span class="token operator">&lt;=</span> <span class="token number">10</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>limit<span class="token punctuation">(</span><span class="token number">120</span><span class="token punctuation">)</span>

    <span class="token comment">//统计每科都及格的学生</span>
    <span class="token keyword">val</span> resDS2<span class="token operator">:</span> Dataset<span class="token punctuation">[</span>Row<span class="token punctuation">]</span> <span class="token operator">=</span> scoresDF
      <span class="token punctuation">.</span>join<span class="token punctuation">(</span>subjectsDF<span class="token punctuation">,</span> <span class="token string">"subject_id"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>where<span class="token punctuation">(</span>$<span class="token string">"score"</span> <span class="token operator">&gt;=</span> $<span class="token string">"subject_score"</span> <span class="token operator">*</span> <span class="token number">0.6</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"jigeCount"</span><span class="token punctuation">,</span> count<span class="token punctuation">(</span>expr<span class="token punctuation">(</span><span class="token string">"1"</span><span class="token punctuation">)</span><span class="token punctuation">)</span> over Window<span class="token punctuation">.</span>partitionBy<span class="token punctuation">(</span>$<span class="token string">"id"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>where<span class="token punctuation">(</span>$<span class="token string">"jigeCount"</span> <span class="token operator">==</span><span class="token operator">=</span> <span class="token number">6</span><span class="token punctuation">)</span>

    <span class="token comment">//统计总分大于年级平均分的学生</span>
    <span class="token keyword">val</span> resDS3<span class="token operator">:</span> Dataset<span class="token punctuation">[</span>Row<span class="token punctuation">]</span> <span class="token operator">=</span> scoresDF
      <span class="token punctuation">.</span>join<span class="token punctuation">(</span>studentsDF<span class="token punctuation">,</span> <span class="token string">"id"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"sumScore"</span><span class="token punctuation">,</span> sum<span class="token punctuation">(</span>$<span class="token string">"score"</span><span class="token punctuation">)</span> over Window<span class="token punctuation">.</span>partitionBy<span class="token punctuation">(</span>$<span class="token string">"id"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"avgScore"</span><span class="token punctuation">,</span> avg<span class="token punctuation">(</span>$<span class="token string">"sumScore"</span><span class="token punctuation">)</span> over Window<span class="token punctuation">.</span>partitionBy<span class="token punctuation">(</span>substring<span class="token punctuation">(</span>$<span class="token string">"clazz"</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>where<span class="token punctuation">(</span>$<span class="token string">"sumScore"</span> <span class="token operator">&gt;</span> $<span class="token string">"avgScore"</span><span class="token punctuation">)</span>

    <span class="token comment">//统计每个班级的每个名次之间的分数差</span>
    <span class="token keyword">val</span> resDF4<span class="token operator">:</span> DataFrame <span class="token operator">=</span> scoresDF
      <span class="token punctuation">.</span>join<span class="token punctuation">(</span>studentsDF<span class="token punctuation">,</span> <span class="token string">"id"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>groupBy<span class="token punctuation">(</span><span class="token string">"id"</span><span class="token punctuation">,</span> <span class="token string">"clazz"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>agg<span class="token punctuation">(</span>sum<span class="token punctuation">(</span><span class="token string">"score"</span><span class="token punctuation">)</span> as <span class="token string">"sumScore"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"rn"</span><span class="token punctuation">,</span> row_number<span class="token punctuation">(</span><span class="token punctuation">)</span> over Window<span class="token punctuation">.</span>partitionBy<span class="token punctuation">(</span>$<span class="token string">"clazz"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>orderBy<span class="token punctuation">(</span>$<span class="token string">"sumScore"</span><span class="token punctuation">.</span>desc<span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"beforeSumScore"</span><span class="token punctuation">,</span> lag<span class="token punctuation">(</span>$<span class="token string">"sumScore"</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">750</span><span class="token punctuation">)</span> over Window<span class="token punctuation">.</span>partitionBy<span class="token punctuation">(</span>$<span class="token string">"clazz"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>orderBy<span class="token punctuation">(</span>$<span class="token string">"sumScore"</span><span class="token punctuation">.</span>desc<span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"cha"</span><span class="token punctuation">,</span> $<span class="token string">"beforeSumScore"</span> <span class="token operator">-</span> $<span class="token string">"sumScore"</span><span class="token punctuation">)</span>

  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<h4><a id="DSL_2240"></a>DSL练习</h4> 
<pre><code class="prism language-txt">公司代码,年度,1月-12月的收入金额
burk,year,tsl01,tsl02,tsl03,tsl04,tsl05,tsl06,tsl07,tsl08,tsl09,tsl10,tsl11,tsl12
853101,2010,100200,25002,19440,20550,14990,17227,40990,28778,19088,29889,10990,20990
853101,2011,19446,20556,14996,17233,40996,28784,19094,28779,19089,29890,10991,20991
853101,2012,19447,20557,14997,17234,20560,15000,17237,28780,19090,29891,10992,20992
853101,2013,20560,15000,17237,41000,17234,20560,15000,17237,41000,29892,10993,20993
853101,2014,19449,20559,14999,17236,41000,28788,28786,19096,29897,41000,28788,20994
853101,2015,100205,25007,19445,20555,17236,40999,28787,19097,29898,29894,10995,20995
853101,2016,100206,25008,19446,20556,17237,41000,28788,19098,29899,29895,10996,20996
853101,2017,100207,25009,17234,20560,15000,17237,41000,15000,17237,41000,28788,20997
853101,2018,100208,25010,41000,28788,28786,19096,29897,28786,19096,29897,10998,20998
853101,2019,100209,25011,17236,40999,28787,19097,29898,28787,19097,29898,10999,20999
846271,2010,100210,25012,17237,41000,28788,19098,29899,28788,19098,29899,11000,21000
846271,2011,100211,25013,19451,20561,15001,17238,41001,28789,19099,29900,11001,21001
846271,2012,100212,100213,20190,6484,46495,86506,126518,166529,206540,246551,286562,326573
846271,2013,100213,100214,21297,5008,44466,83924,123382,162839,202297,241755,281213,320671
846271,2014,100214,100215,22405,3531,42436,81341,120245,159150,198055,236959,275864,314769
846271,2015,100215,100216,23512,2055,19096,29897,28786,19096,29897,41000,29892,308866
846271,2016,100216,100217,24620,579,38377,76175,28788,28786,19096,29897,41000,302964
846271,2017,100217,100218,25727,898,36347,73592,40999,28787,19097,29898,29894,297062
846271,2018,100218,100219,26835,2374,34318,71009,41000,28788,19098,29899,29895,291159
846271,2019,100219,100220,27942,3850,32288,68427,17237,41000,15000,17237,41000,285257


1、统计每个公司每年按月累计收入  行转列 --&gt; sum窗口函数

输出结果
公司代码,年度,月份,当月收入,累计收入


2、统计每个公司当月比上年同期增长率  行转列 --&gt; lag窗口函数
公司代码,年度,月度,增长率（当月收入/上年当月收入 - 1）
</code></pre> 
<pre><code class="prism language-scala"><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>expressions<span class="token punctuation">.</span></span>Window
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>Column<span class="token punctuation">,</span> DataFrame<span class="token punctuation">,</span> SparkSession<span class="token punctuation">}</span>

<span class="token keyword">object</span> Demo7Burks <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">val</span> sparkSession<span class="token operator">:</span> SparkSession <span class="token operator">=</span> SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>master<span class="token punctuation">(</span><span class="token string">"local"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>appName<span class="token punctuation">(</span><span class="token string">"练习1需求"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>config<span class="token punctuation">(</span><span class="token string">"spark.sql.shuffle.partitions"</span><span class="token punctuation">,</span> <span class="token string">"1"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span>
	<span class="token comment">//导入隐式转换</span>
    <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>functions<span class="token punctuation">.</span></span>_
    <span class="token keyword">import</span> <span class="token namespace">sparkSession<span class="token punctuation">.</span>implicits<span class="token punctuation">.</span></span>_
	<span class="token comment">// 加载数据</span>
    <span class="token keyword">val</span> burksDF<span class="token operator">:</span> DataFrame <span class="token operator">=</span> sparkSession<span class="token punctuation">.</span>read
      <span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">"csv"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>schema<span class="token punctuation">(</span><span class="token string">"burk STRING,year STRING"</span> <span class="token operator">+</span>
        <span class="token string">",tsl01 DOUBLE,tsl02 DOUBLE,tsl03 DOUBLE"</span> <span class="token operator">+</span>
        <span class="token string">",tsl04 DOUBLE,tsl05 DOUBLE,tsl06 DOUBLE"</span> <span class="token operator">+</span>
        <span class="token string">",tsl07 DOUBLE,tsl08 DOUBLE,tsl09 DOUBLE"</span> <span class="token operator">+</span>
        <span class="token string">",tsl10 DOUBLE,tsl11 DOUBLE,tsl12 DOUBLE"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"spark/data/burks.txt"</span><span class="token punctuation">)</span>

    <span class="token comment">/**
     * 1、统计每个公司每年按月累计收入  行转列 --&gt; sum窗口函数
     *
     * 输出结果
     * 公司代码,年度,月份,当月收入,累计收入
     */</span>
    <span class="token comment">// 纯sql的方式实现</span>
    burksDF<span class="token punctuation">.</span>createOrReplaceTempView<span class="token punctuation">(</span><span class="token string">"burks"</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> resDF1<span class="token operator">:</span> DataFrame <span class="token operator">=</span> sparkSession<span class="token punctuation">.</span>sql<span class="token punctuation">(</span>
      <span class="token triple-quoted-string string">"""
        |select
        |t1.burk as burk,
        |t1.year as year,
        |t1.month as month,
        |t1.tsl as tsl,
        |sum(t1.tsl) over(partition by burk,year order by month) as leiji
        |from
        |(select
        | burk,
        | year,
        | month,
        | tsl
        |from
        | burks
        | lateral view explode(map(1,tsl01,2,tsl02,3,tsl03,4,tsl04,5,tsl05,6,tsl06,7,tsl07,8,tsl08,9,tsl09,10,tsl10,11,tsl11,12,tsl12)) T as month,tsl
        | ) t1
        |"""</span><span class="token punctuation">.</span>stripMargin<span class="token punctuation">)</span>
<span class="token comment">// DSL方法实现</span>
    <span class="token keyword">val</span> m<span class="token operator">:</span> Column <span class="token operator">=</span> map<span class="token punctuation">(</span>
      expr<span class="token punctuation">(</span><span class="token string">"1"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> $<span class="token string">"tsl01"</span><span class="token punctuation">,</span>
      expr<span class="token punctuation">(</span><span class="token string">"2"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> $<span class="token string">"tsl02"</span><span class="token punctuation">,</span>
      expr<span class="token punctuation">(</span><span class="token string">"3"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> $<span class="token string">"tsl03"</span><span class="token punctuation">,</span>
      expr<span class="token punctuation">(</span><span class="token string">"4"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> $<span class="token string">"tsl04"</span><span class="token punctuation">,</span>
      expr<span class="token punctuation">(</span><span class="token string">"5"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> $<span class="token string">"tsl05"</span><span class="token punctuation">,</span>
      expr<span class="token punctuation">(</span><span class="token string">"6"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> $<span class="token string">"tsl06"</span><span class="token punctuation">,</span>
      expr<span class="token punctuation">(</span><span class="token string">"7"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> $<span class="token string">"tsl07"</span><span class="token punctuation">,</span>
      expr<span class="token punctuation">(</span><span class="token string">"8"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> $<span class="token string">"tsl08"</span><span class="token punctuation">,</span>
      expr<span class="token punctuation">(</span><span class="token string">"9"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> $<span class="token string">"tsl09"</span><span class="token punctuation">,</span>
      expr<span class="token punctuation">(</span><span class="token string">"10"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> $<span class="token string">"tsl10"</span><span class="token punctuation">,</span>
      expr<span class="token punctuation">(</span><span class="token string">"11"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> $<span class="token string">"tsl11"</span><span class="token punctuation">,</span>
      expr<span class="token punctuation">(</span><span class="token string">"12"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> $<span class="token string">"tsl12"</span>
    <span class="token punctuation">)</span>

    <span class="token comment">// DSL语法方式实现</span>
<span class="token comment">//    burksDF.select($"burk",$"year",explode(m) as Array("month","tsl"))</span>
<span class="token comment">//      .withColumn("leiji",sum($"tsl") over Window.partitionBy($"burk",$"year").orderBy($"month"))</span>
<span class="token comment">//      .show()</span>

    <span class="token comment">/**
     * 2、统计每个公司当月比上年同期增长率  行转列 --&gt; lag窗口函数
     * 公司代码,年度,月度,增长率（当月收入/上年当月收入 - 1）
     *
     * 853101 2010 1 10000
     * 853101 2011 1 11000  10000
     */</span>
    <span class="token keyword">val</span> resDF2<span class="token operator">:</span> DataFrame <span class="token operator">=</span> burksDF<span class="token punctuation">.</span>select<span class="token punctuation">(</span>$<span class="token string">"burk"</span><span class="token punctuation">,</span> $<span class="token string">"year"</span><span class="token punctuation">,</span> explode<span class="token punctuation">(</span>m<span class="token punctuation">)</span> as Array<span class="token punctuation">(</span><span class="token string">"month"</span><span class="token punctuation">,</span> <span class="token string">"tsl"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"beforeTsl"</span><span class="token punctuation">,</span> lag<span class="token punctuation">(</span>$<span class="token string">"tsl"</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">)</span> over Window<span class="token punctuation">.</span>partitionBy<span class="token punctuation">(</span>$<span class="token string">"burk"</span><span class="token punctuation">,</span> $<span class="token string">"month"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>orderBy<span class="token punctuation">(</span>$<span class="token string">"year"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"p"</span><span class="token punctuation">,</span> round<span class="token punctuation">(</span><span class="token punctuation">(</span>$<span class="token string">"tsl"</span> <span class="token operator">/</span> $<span class="token string">"beforeTsl"</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cast<span class="token punctuation">(</span><span class="token string">"string"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"new_p"</span><span class="token punctuation">,</span> when<span class="token punctuation">(</span>$<span class="token string">"p"</span><span class="token punctuation">.</span>isNotNull<span class="token punctuation">,</span> $<span class="token string">"p"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>otherwise<span class="token punctuation">(</span><span class="token string">"该年的当月是第一次计数"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>select<span class="token punctuation">(</span>$<span class="token string">"burk"</span><span class="token punctuation">,</span> $<span class="token string">"year"</span><span class="token punctuation">,</span> $<span class="token string">"month"</span><span class="token punctuation">,</span> $<span class="token string">"tsl"</span><span class="token punctuation">,</span> $<span class="token string">"new_p"</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<h4><a id="_Spark_sql_2365"></a>集群运行 Spark sql</h4> 
<p>编写一个简单代码</p> 
<pre><code class="prism language-scala"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>shujia<span class="token punctuation">.</span>sql</span>

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>DataFrame<span class="token punctuation">,</span> SparkSession<span class="token punctuation">}</span>

<span class="token keyword">object</span> Demo8SubmitYarn <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">val</span> sparkSession<span class="token operator">:</span> SparkSession <span class="token operator">=</span> SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment">//      .master("local")</span>
      <span class="token punctuation">.</span>appName<span class="token punctuation">(</span><span class="token string">"提交到yarn 计算每个班级的人数"</span><span class="token punctuation">)</span>
      <span class="token comment">//参数设置的优先级：代码优先级 &gt; 命令优先级 &gt; 配置文件优先级</span>
      <span class="token punctuation">.</span>config<span class="token punctuation">(</span><span class="token string">"spark.sql.shuffle.partitions"</span><span class="token punctuation">,</span> <span class="token string">"1"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>functions<span class="token punctuation">.</span></span>_
    <span class="token keyword">import</span> <span class="token namespace">sparkSession<span class="token punctuation">.</span>implicits<span class="token punctuation">.</span></span>_

    <span class="token keyword">val</span> df1<span class="token operator">:</span> DataFrame <span class="token operator">=</span> sparkSession<span class="token punctuation">.</span>read
      <span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">"csv"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>schema<span class="token punctuation">(</span><span class="token string">"id STRING,name STRING,age INT,gender STRING,clazz STRING"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>load<span class="token punctuation">(</span>args<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">// hdfs上的路径  给参数</span>

    <span class="token keyword">val</span> df2<span class="token operator">:</span> DataFrame <span class="token operator">=</span> df1<span class="token punctuation">.</span>groupBy<span class="token punctuation">(</span>$<span class="token string">"clazz"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>agg<span class="token punctuation">(</span>count<span class="token punctuation">(</span>$<span class="token string">"id"</span><span class="token punctuation">)</span> as <span class="token string">"counts"</span><span class="token punctuation">)</span>

    df2<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

    df2<span class="token punctuation">.</span>write
      <span class="token punctuation">.</span>csv<span class="token punctuation">(</span>args<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">// 带传参数</span>

  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>打包上传 上传数据</p> 
<p>运行</p> 
<pre><code class="prism language-sh">spark-submit <span class="token parameter variable">--master</span> <span class="token function">yarn</span> --deploy-mode client <span class="token parameter variable">--class</span> com.shujia.sql.Demo8SubmitYarn <span class="token parameter variable">--conf</span> <span class="token assign-left variable">spark.sql.shuffle.partitions</span><span class="token operator">=</span><span class="token number">1</span> spark-1.0.jar <span class="token punctuation">(</span>数据输入路径<span class="token punctuation">)</span><span class="token punctuation">(</span>输出路径<span class="token punctuation">)</span>
</code></pre> 
<p>注意：</p> 
<p>在代码中，我们设置了分区数为1，我们在命令中设置分区数100 看看效果</p> 
<pre><code class="prism language-sh">spark-submit <span class="token parameter variable">--master</span> <span class="token function">yarn</span> --deploy-mode client <span class="token parameter variable">--class</span> com.shujia.sql.Demo8SubmitYarn <span class="token parameter variable">--conf</span> <span class="token assign-left variable">spark.sql.shuffle.partitions</span><span class="token operator">=</span><span class="token number">100</span> spark-1.0.jar<span class="token punctuation">(</span>数据输入路径<span class="token punctuation">)</span><span class="token punctuation">(</span>输出路径<span class="token punctuation">)</span>
</code></pre> 
<p>运行发现 还是一个分区。</p> 
<p>结论：参数设置的优先级：代码优先级 &gt; 命令优先级 &gt; 配置文件优先级</p> 
<h4><a id="spark_shell__repl_sqlContext______2427"></a>spark shell (repl) 里面使用sqlContext 测试使用，简单任务使用</h4> 
<pre><code class="prism language-sh">spark-shell <span class="token parameter variable">--master</span> <span class="token function">yarn</span> --deploy-mode client
</code></pre> 
<p>可以在这里面编写代码</p> 
<h4><a id="_2437"></a>字符串拼接</h4> 
<pre><code class="prism language-scala"><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>DataFrame<span class="token punctuation">,</span> SparkSession<span class="token punctuation">}</span>

<span class="token keyword">object</span> Demo9Test <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">val</span> sparkSession<span class="token operator">:</span> SparkSession <span class="token operator">=</span> SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>master<span class="token punctuation">(</span><span class="token string">"local"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>appName<span class="token punctuation">(</span><span class="token string">"提交到yarn 计算每个班级的人数"</span><span class="token punctuation">)</span>
      <span class="token comment">//参数设置的优先级：代码优先级 &gt; 命令优先级 &gt; 配置文件优先级</span>
      <span class="token punctuation">.</span>config<span class="token punctuation">(</span><span class="token string">"spark.sql.shuffle.partitions"</span><span class="token punctuation">,</span> <span class="token string">"1"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>functions<span class="token punctuation">.</span></span>_
    <span class="token keyword">import</span> <span class="token namespace">sparkSession<span class="token punctuation">.</span>implicits<span class="token punctuation">.</span></span>_

    <span class="token keyword">val</span> df1<span class="token operator">:</span> DataFrame <span class="token operator">=</span> sparkSession<span class="token punctuation">.</span>read
      <span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">"csv"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>schema<span class="token punctuation">(</span><span class="token string">"id STRING,name STRING,age INT,gender STRING,clazz STRING"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"sep"</span><span class="token punctuation">,</span> <span class="token string">","</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"spark/data/students.txt"</span><span class="token punctuation">)</span>
<span class="token comment">// 字符串拼接</span>
    df1<span class="token punctuation">.</span>select<span class="token punctuation">(</span>$<span class="token string">"name"</span><span class="token punctuation">,</span> concat<span class="token punctuation">(</span>expr<span class="token punctuation">(</span><span class="token string">"'姓名: '"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>$<span class="token string">"name"</span><span class="token punctuation">)</span> as <span class="token string">"new_str"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

    df1<span class="token punctuation">.</span>groupBy<span class="token punctuation">(</span>$<span class="token string">"clazz"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>agg<span class="token punctuation">(</span>
        count<span class="token punctuation">(</span>expr<span class="token punctuation">(</span><span class="token string">"1"</span><span class="token punctuation">)</span><span class="token punctuation">)</span> as <span class="token string">"counts"</span><span class="token punctuation">,</span>
        avg<span class="token punctuation">(</span>$<span class="token string">"age"</span><span class="token punctuation">)</span> as <span class="token string">"avgAge"</span>
      <span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<h4><a id="sparksql_2471"></a>spark-sql</h4> 
<p>进入命令行，和hive的命令行一样，直接写sql，默认去hive读数据</p> 
<pre><code class="prism language-sh"> spark-sql <span class="token parameter variable">--master</span> <span class="token function">yarn</span> --deploy-mode client 
</code></pre> 
<h4><a id="sparkhive_2479"></a>spark整合hive</h4> 
<blockquote> 
 <p>在spark sql中使用hive的元数据</p> 
 <p>spark sql是使用spark进行计算的，hive使用MR进行计算的</p> 
</blockquote> 
<h5><a id="1hivehivesitexmlhive_2485"></a>1、在hive的hive-site.xml修改一行配置，增加了这一行配置之后，以后在使用hive之前都需要先启动元数据服务</h5> 
<p>cd /usr/local/soft/hive-1.2.1/conf/</p> 
<pre><code class="prism language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>hive.metastore.uris<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>thrift://master:9083<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>       
</code></pre> 
<h5><a id="2hive_hvie_2496"></a>2、启动hive元数据服务, 将hvie的元数据暴露给第三方使用</h5> 
<pre><code class="prism language-shell"><span class="token function">nohup</span>  hive <span class="token parameter variable">--service</span> metastore <span class="token operator">&gt;&gt;</span> metastore.log <span class="token operator"><span class="token file-descriptor important">2</span>&gt;</span><span class="token file-descriptor important">&amp;1</span> <span class="token operator">&amp;</span>
</code></pre> 
<h5><a id="3hivesitexml__spark_conf_2502"></a>3、将hive-site.xml 复制到spark conf目录下</h5> 
<pre><code>cp hive-site.xml /usr/local/soft/spark-3.1.3/conf/
</code></pre> 
<h5><a id="4_mysql_spark_jars_2508"></a>4、 将mysql 驱动包复制到spark jars目录下</h5> 
<pre><code class="prism language-shell"><span class="token builtin class-name">cd</span> /usr/local/soft/hive-3.1.2/lib
<span class="token function">cp</span> mysql-connector-java-8.0.29.jar /usr/local/soft/spark-3.1.3/jars/ 
</code></pre> 
<h5><a id="5sparksql_hive_2515"></a>5、整合好之后在spark-sql 里面就可以使用hive的表了</h5> 
<pre><code class="prism language-shell"><span class="token comment"># 启动hive元数据</span>
<span class="token comment"># 模式是local模式</span>
spark-sql <span class="token parameter variable">-conf</span>  <span class="token assign-left variable">spark.sql.shuffle.partitions</span><span class="token operator">=</span><span class="token number">2</span>
<span class="token comment"># 使用yarn-client模式</span>
spark-sql <span class="token parameter variable">--master</span> yarn-client  <span class="token parameter variable">--conf</span>  <span class="token assign-left variable">spark.sql.shuffle.partitions</span><span class="token operator">=</span><span class="token number">1</span>

<span class="token comment">#在spark-sql中设置运行参数</span>
<span class="token builtin class-name">set</span> <span class="token assign-left variable">spark.sql.shuffle.partitions</span><span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">;</span>
<span class="token comment"># 执行一些sql...</span>
</code></pre> 
<p>spark-sql -e</p> 
<pre><code class="prism language-sql"><span class="token comment">-- 执行一条sql语句，执行完，自动退出</span>
spark<span class="token operator">-</span><span class="token keyword">sql</span> <span class="token operator">-</span>e <span class="token string">"select * from student"</span>
</code></pre> 
<p>spark-sql -f</p> 
<pre><code class="prism language-sql">vim a<span class="token punctuation">.</span><span class="token keyword">sql</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> student
<span class="token comment">-- 执行一个sql文件</span>
spark<span class="token operator">-</span><span class="token keyword">sql</span> <span class="token operator">-</span>f a<span class="token punctuation">.</span><span class="token keyword">sql</span>
</code></pre> 
<h5><a id="sparksql_hivehive_2545"></a>当spark-sql 和hive整合好之后再代码中也可以直接使用hive的表</h5> 
<p>导入依赖</p> 
<pre><code class="prism language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.spark<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>spark-hive_2.12<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>

        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.hadoop<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>hadoop-client<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>

        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.hive<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>hive-exec<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>


<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>com.fasterxml.jackson.core<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>jackson-databind<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>2.10.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
 
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>com.fasterxml.jackson.core<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>jackson-core<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>2.10.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
</code></pre> 
<p>准备工作：将hive的配置文件，hadoop的配置文件 复制到项目中resources文件夹中：</p> 
<blockquote> 
 <p>core-site.xml</p> 
 <p>hdfs-site.xml</p> 
 <p>yarn-site.xml</p> 
 <p>hive-site.xml</p> 
</blockquote> 
<pre><code class="prism language-scala"><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span>SparkSession

<span class="token keyword">object</span> Demo10HiveOnSpark <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">val</span> sparkSession<span class="token operator">:</span> SparkSession <span class="token operator">=</span> SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>master<span class="token punctuation">(</span><span class="token string">"local"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>appName<span class="token punctuation">(</span><span class="token string">"提交到yarn 计算每个班级的人数"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>config<span class="token punctuation">(</span><span class="token string">"spark.sql.shuffle.partitions"</span><span class="token punctuation">,</span> <span class="token string">"1"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>enableHiveSupport<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">// 开启hive的配置</span>
      <span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span>

    sparkSession<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">"use bigdata30"</span><span class="token punctuation">)</span>

    sparkSession<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">"select * from sqoop_students1 limit 10"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span>truncate <span class="token operator">=</span> <span class="token boolean">false</span><span class="token punctuation">)</span>

  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>


<span class="token comment">//写好的代码不能再本地运行， 需要打包上传到集群运行</span>
</code></pre> 
<p>spark sql和hvie的建表语句一样</p> 
<pre><code class="prism language-sql"><span class="token keyword">create</span> external <span class="token keyword">table</span> students
<span class="token punctuation">(</span>
id  string<span class="token punctuation">,</span>
name string<span class="token punctuation">,</span>
age <span class="token keyword">int</span><span class="token punctuation">,</span>
gender string<span class="token punctuation">,</span>
clazz string
<span class="token punctuation">)</span>
<span class="token keyword">ROW</span> FORMAT DELIMITED <span class="token keyword">FIELDS</span> <span class="token keyword">TERMINATED</span> <span class="token keyword">BY</span> <span class="token string">','</span>
location <span class="token string">'/bigdata30/spark_in/data/student'</span><span class="token punctuation">;</span>

<span class="token keyword">create</span> <span class="token keyword">table</span> score
<span class="token punctuation">(</span>
student_id  string<span class="token punctuation">,</span>
cource_id string<span class="token punctuation">,</span>
sco <span class="token keyword">int</span>
<span class="token punctuation">)</span>
<span class="token keyword">ROW</span> FORMAT DELIMITED <span class="token keyword">FIELDS</span> <span class="token keyword">TERMINATED</span> <span class="token keyword">BY</span> <span class="token string">','</span>
STORED <span class="token keyword">AS</span> textfile
location <span class="token string">'/data/score/'</span><span class="token punctuation">;</span>
</code></pre> 
<p>禁用集群spark日志</p> 
<pre><code>cd /usr/local/soft/spark-2.4.5/conf
mv log4j.properties.template log4j.properties
vim log4j.properties
修改配置
log4j.rootCategory=ERROR, console
</code></pre> 
<h4><a id="spark_sqlhive_2650"></a>spark sql和hive区别</h4> 
<p>1、spark sql缓存</p> 
<pre><code class="prism language-sql"><span class="token comment">-- 进入spark sql命令行</span>
spark<span class="token operator">-</span><span class="token keyword">sql</span>
<span class="token comment">-- 可以通过一个网址访问spark任务</span>
http:<span class="token comment">//master:4040</span>
<span class="token comment">-- 设置并行度</span>
<span class="token keyword">set</span> spark<span class="token punctuation">.</span><span class="token keyword">sql</span><span class="token punctuation">.</span>shuffle<span class="token punctuation">.</span>partitions<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">;</span>

<span class="token comment">-- 再spark-sql中对同一个表进行多次查询的时候可以将表缓存起来</span>
cache <span class="token keyword">table</span> student<span class="token punctuation">;</span>
<span class="token comment">-- 删除缓存</span>
uncache <span class="token keyword">table</span> student<span class="token punctuation">;</span>

<span class="token comment">-- 再代码中也可以缓存DF</span>
 studentDF<span class="token punctuation">.</span>persist<span class="token punctuation">(</span>StorageLevel<span class="token punctuation">.</span>MEMORY_ONLY<span class="token punctuation">)</span>
</code></pre> 
<p>2、spark sql mapjoin — 广播变量</p> 
<p>Reduce Join</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> 
student <span class="token keyword">as</span> a
<span class="token keyword">join</span> 
score <span class="token keyword">as</span> b
<span class="token keyword">on</span>
a<span class="token punctuation">.</span>id<span class="token operator">=</span>b<span class="token punctuation">.</span>student_id
</code></pre> 
<p>MapJoin</p> 
<blockquote> 
 <p>当一个大表关联小表的时候可以将小表加载到内存中进行关联---- 广播变量</p> 
 <p>在map端进行表关联，不会产生shuffle</p> 
</blockquote> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> <span class="token comment">/*+broadcast(a)  */</span> <span class="token operator">*</span> <span class="token keyword">from</span> 
student <span class="token keyword">as</span> a
<span class="token keyword">join</span> 
score <span class="token keyword">as</span> b
<span class="token keyword">on</span>
a<span class="token punctuation">.</span>id<span class="token operator">=</span>b<span class="token punctuation">.</span>student_id
</code></pre> 
<blockquote> 
 <p>/*+broadcast(a) */ HINT:给sql加提示的语法</p> 
</blockquote> 
<blockquote> 
 <p>表1<br> 姓名,科目,分数<br> name,item,score<br> 张三,数学,33<br> 张三,英语,77<br> 李四,数学,66<br> 李四,英语,78</p> 
 <p>表2<br> 姓名,数学,英语<br> name,math,english<br> 张三,33,77<br> 李四,66,78</p> 
 <p>1、将表1转化成表2<br> 2、将表2转化成表1</p> 
</blockquote> 
<h4><a id="_2720"></a>行列转换</h4> 
<pre><code class="prism language-scala"><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>Column<span class="token punctuation">,</span> DataFrame<span class="token punctuation">,</span> SparkSession<span class="token punctuation">}</span>

<span class="token comment">/**
 *
 * 1、行列转换
 *
 */</span>
<span class="token keyword">object</span> Demo11Student <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">val</span> sparkSession<span class="token operator">:</span> SparkSession <span class="token operator">=</span> SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>master<span class="token punctuation">(</span><span class="token string">"local"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>appName<span class="token punctuation">(</span><span class="token string">"行转列 列转行案例演示"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>functions<span class="token punctuation">.</span></span>_
    <span class="token keyword">import</span> <span class="token namespace">sparkSession<span class="token punctuation">.</span>implicits<span class="token punctuation">.</span></span>_

    <span class="token comment">//当你配置了hdfs等一些配置文件，那么默认读取路径是hadoop的，否则是本地</span>
    <span class="token keyword">val</span> df1<span class="token operator">:</span> DataFrame <span class="token operator">=</span> sparkSession<span class="token punctuation">.</span>read
      <span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">"csv"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>schema<span class="token punctuation">(</span><span class="token string">"name STRING,item STRING,score INT"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"/bigdata30/stu.txt"</span><span class="token punctuation">)</span>


    <span class="token comment">//列转行</span>
    <span class="token keyword">val</span> resDF<span class="token operator">:</span> DataFrame <span class="token operator">=</span> df1<span class="token punctuation">.</span>groupBy<span class="token punctuation">(</span>$<span class="token string">"name"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>agg<span class="token punctuation">(</span>
        sum<span class="token punctuation">(</span>when<span class="token punctuation">(</span>$<span class="token string">"item"</span> <span class="token operator">==</span><span class="token operator">=</span> <span class="token string">"数学"</span><span class="token punctuation">,</span> $<span class="token string">"score"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>otherwise<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span> as <span class="token string">"math"</span><span class="token punctuation">,</span>
        sum<span class="token punctuation">(</span>when<span class="token punctuation">(</span>$<span class="token string">"item"</span> <span class="token operator">==</span><span class="token operator">=</span> <span class="token string">"英语"</span><span class="token punctuation">,</span> $<span class="token string">"score"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>otherwise<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span> as <span class="token string">"english"</span>
      <span class="token punctuation">)</span>

<span class="token comment">//    val array1: Column = array($"math", $"english")</span>

    <span class="token keyword">val</span> m<span class="token operator">:</span> Column <span class="token operator">=</span> map<span class="token punctuation">(</span>
      expr<span class="token punctuation">(</span><span class="token string">"'数学'"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> $<span class="token string">"math"</span><span class="token punctuation">,</span>
      expr<span class="token punctuation">(</span><span class="token string">"'英语'"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> $<span class="token string">"english"</span>
    <span class="token punctuation">)</span>

    <span class="token comment">//行转列</span>
    resDF<span class="token punctuation">.</span>select<span class="token punctuation">(</span>$<span class="token string">"name"</span><span class="token punctuation">,</span>explode<span class="token punctuation">(</span>m<span class="token punctuation">)</span> as Array<span class="token punctuation">(</span><span class="token string">"item"</span><span class="token punctuation">,</span><span class="token string">"score"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>


  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<h4><a id="UDF_2771"></a>自定义UDF函数</h4> 
<blockquote> 
 <p>sparkSession.udf.register(“hhh”,fun1) // 注册成函数</p> 
</blockquote> 
<pre><code class="prism language-scala"><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>expressions<span class="token punctuation">.</span></span>UserDefinedFunction
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>DataFrame<span class="token punctuation">,</span> SparkSession<span class="token punctuation">}</span>

<span class="token keyword">object</span> Demo12UDF <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">val</span> sparkSession<span class="token operator">:</span> SparkSession <span class="token operator">=</span> SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>master<span class="token punctuation">(</span><span class="token string">"local"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>appName<span class="token punctuation">(</span><span class="token string">"行转列 列转行案例演示"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>functions<span class="token punctuation">.</span></span>_
    <span class="token keyword">import</span> <span class="token namespace">sparkSession<span class="token punctuation">.</span>implicits<span class="token punctuation">.</span></span>_

    <span class="token comment">//当你配置了hdfs等一些配置文件，那么默认读取路径是hadoop的，否则是本地</span>
    <span class="token keyword">val</span> df1<span class="token operator">:</span> DataFrame <span class="token operator">=</span> sparkSession<span class="token punctuation">.</span>read
      <span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">"csv"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>schema<span class="token punctuation">(</span><span class="token string">"id STRING,name STRING,age INT,gender STRING,clazz STRING"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"sep"</span><span class="token punctuation">,</span> <span class="token string">","</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"/bigdata30/students.csv"</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> fun1<span class="token operator">:</span> UserDefinedFunction <span class="token operator">=</span> udf<span class="token punctuation">(</span><span class="token string">"姓名: "</span> <span class="token operator">+</span> _<span class="token punctuation">)</span>
    <span class="token comment">// 注册成一张表</span>
    df1<span class="token punctuation">.</span>createOrReplaceTempView<span class="token punctuation">(</span><span class="token string">"students"</span><span class="token punctuation">)</span>
    <span class="token comment">//将自定义的函数变量注册成sql语句中的函数</span>
    sparkSession<span class="token punctuation">.</span>udf<span class="token punctuation">.</span>register<span class="token punctuation">(</span><span class="token string">"hhh"</span><span class="token punctuation">,</span>fun1<span class="token punctuation">)</span>  <span class="token comment">// 取任意名字</span>
    sparkSession<span class="token punctuation">.</span>sql<span class="token punctuation">(</span>
      <span class="token triple-quoted-string string">"""
        |select
        |id,
        |name,
        |hhh(name) as new_name
        |from
        |students
        |"""</span><span class="token punctuation">.</span>stripMargin<span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>在spark-sql命令行创建：</p> 
<pre><code class="prism language-scala"><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>ql<span class="token punctuation">.</span>exec<span class="token punctuation">.</span></span>UDF

<span class="token keyword">class</span> Demo13Str <span class="token keyword">extends</span> UDF <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> evaluate<span class="token punctuation">(</span>line<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span> <span class="token string">"胡哈哈哈："</span> <span class="token operator">+</span> line

<span class="token punctuation">}</span>

<span class="token comment">/**
 * 1、自定义类继承UDF类，重写evaluate方法
 * 2、打包，spark-1.0.jar 将jar包放到spark目录下的jars目录下
 * 3、在spark-sql命令行中注册函数
 * create function hhhh as 'com.shujia.sql.Demo13Str'
 *
 *
 * */</span>
</code></pre> 
<h4><a id="DSL_2835"></a>DSL练习（二）</h4> 
<h5><a id="_2837"></a>工作经历</h5> 
<p>数据：</p> 
<p>91330000733796106P,杭州海康威视数字技术股份有限公司,2020-02-01 00:00:00<br> 91330000733796106P,杭州海康威视数字技术股份有限公司,2020-03-01 00:00:00<br> 91330000733796106P,杭州海康威视数字技术股份有限公司,2020-04-01 00:00:00<br> 91330000733796106P,杭州海康威视数字技术股份有限公司,2020-05-01 00:00:00<br> 91330000733796106P,阿里云计算有限公司,2020-06-01 00:00:00<br> 91330000733796106P,阿里云计算有限公司,2020-07-01 00:00:00<br> 91330000733796106P,阿里云计算有限公司,2020-08-01 00:00:00<br> 91330000733796106P,阿里云计算有限公司,2020-09-01 00:00:00<br> 91330000733796106P,杭州海康威视数字技术股份有限公司,2020-10-01 00:00:00<br> 91330000733796106P,杭州海康威视数字技术股份有限公司,2020-11-01 00:00:00<br> 91330000733796106P,杭州海康威视数字技术股份有限公司,2020-12-01 00:00:00<br> 91330000733796106P,杭州海康威视数字技术股份有限公司,2021-01-01 00:00:00<br> 91330000733796106P,杭州海康威视数字技术股份有限公司,2021-02-01 00:00:00<br> 91330000733796106P,杭州海康威视数字技术股份有限公司,2021-03-01 00:00:00<br> aaaaaaaaaaaaaaaaaa,杭州海康威视数字技术股份有限公司,2020-02-01 00:00:00<br> aaaaaaaaaaaaaaaaaa,杭州海康威视数字技术股份有限公司,2020-03-01 00:00:00<br> aaaaaaaaaaaaaaaaaa,杭州海康威视数字技术股份有限公司,2020-04-01 00:00:00<br> aaaaaaaaaaaaaaaaaa,杭州海康威视数字技术股份有限公司,2020-05-01 00:00:00<br> aaaaaaaaaaaaaaaaaa,阿里云计算有限公司,2020-06-01 00:00:00<br> aaaaaaaaaaaaaaaaaa,阿里云计算有限公司,2020-07-01 00:00:00<br> aaaaaaaaaaaaaaaaaa,阿里云计算有限公司,2020-08-01 00:00:00<br> aaaaaaaaaaaaaaaaaa,阿里云计算有限公司,2020-09-01 00:00:00<br> aaaaaaaaaaaaaaaaaa,杭州海康威视数字技术股份有限公司,2020-10-01 00:00:00<br> aaaaaaaaaaaaaaaaaa,杭州海康威视数字技术股份有限公司,2020-11-01 00:00:00<br> aaaaaaaaaaaaaaaaaa,杭州海康威视数字技术股份有限公司,2020-12-01 00:00:00<br> aaaaaaaaaaaaaaaaaa,杭州海康威视数字技术股份有限公司,2021-01-01 00:00:00<br> aaaaaaaaaaaaaaaaaa,杭州海康威视数字技术股份有限公司,2021-02-01 00:00:00<br> aaaaaaaaaaaaaaaaaa,杭州海康威视数字技术股份有限公司,2021-03-01 00:00:00</p> 
<p>需求：统计每个员工的工作经历</p> 
<p>结果结构：</p> 
<p>员工编号，开始时间，结束时间，公司名称</p> 
<pre><code class="prism language-scala"><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>expressions<span class="token punctuation">.</span></span>Window
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>DataFrame<span class="token punctuation">,</span> SaveMode<span class="token punctuation">,</span> SparkSession<span class="token punctuation">}</span>

<span class="token keyword">object</span> Demo14SheBao <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">val</span> sparkSession<span class="token operator">:</span> SparkSession <span class="token operator">=</span> SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>master<span class="token punctuation">(</span><span class="token string">"local"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>appName<span class="token punctuation">(</span><span class="token string">"经历练习"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>functions<span class="token punctuation">.</span></span>_
    <span class="token keyword">import</span> <span class="token namespace">sparkSession<span class="token punctuation">.</span>implicits<span class="token punctuation">.</span></span>_

    <span class="token keyword">val</span> df1<span class="token operator">:</span> DataFrame <span class="token operator">=</span> sparkSession<span class="token punctuation">.</span>read
      <span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">"csv"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>schema<span class="token punctuation">(</span><span class="token string">"id STRING,burk STRING,sdate STRING"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"/bigdata30/shebao.txt"</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> resDF<span class="token operator">:</span> DataFrame <span class="token operator">=</span> df1<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"before_burk"</span><span class="token punctuation">,</span> lag<span class="token punctuation">(</span>$<span class="token string">"burk"</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span> over Window<span class="token punctuation">.</span>partitionBy<span class="token punctuation">(</span>$<span class="token string">"id"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>orderBy<span class="token punctuation">(</span>$<span class="token string">"sdate"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>select<span class="token punctuation">(</span>
        $<span class="token string">"id"</span><span class="token punctuation">,</span>
        $<span class="token string">"burk"</span><span class="token punctuation">,</span>
        $<span class="token string">"sdate"</span><span class="token punctuation">,</span>
        when<span class="token punctuation">(</span>$<span class="token string">"before_burk"</span><span class="token punctuation">.</span>isNull<span class="token punctuation">,</span> $<span class="token string">"burk"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>otherwise<span class="token punctuation">(</span>$<span class="token string">"before_burk"</span><span class="token punctuation">)</span> as <span class="token string">"before_burk"</span>
      <span class="token punctuation">)</span><span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"flag"</span><span class="token punctuation">,</span> when<span class="token punctuation">(</span>$<span class="token string">"burk"</span> <span class="token operator">==</span><span class="token operator">=</span> $<span class="token string">"before_burk"</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>otherwise<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"tmp"</span><span class="token punctuation">,</span> sum<span class="token punctuation">(</span>$<span class="token string">"flag"</span><span class="token punctuation">)</span> over Window<span class="token punctuation">.</span>partitionBy<span class="token punctuation">(</span>$<span class="token string">"id"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>orderBy<span class="token punctuation">(</span>$<span class="token string">"sdate"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>groupBy<span class="token punctuation">(</span>$<span class="token string">"id"</span><span class="token punctuation">,</span> $<span class="token string">"burk"</span><span class="token punctuation">,</span> $<span class="token string">"tmp"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>agg<span class="token punctuation">(</span>
        min<span class="token punctuation">(</span>$<span class="token string">"sdate"</span><span class="token punctuation">)</span> as <span class="token string">"start_date"</span><span class="token punctuation">,</span>
        max<span class="token punctuation">(</span>$<span class="token string">"sdate"</span><span class="token punctuation">)</span> as <span class="token string">"end_date"</span>
      <span class="token punctuation">)</span><span class="token punctuation">.</span>select<span class="token punctuation">(</span>$<span class="token string">"id"</span><span class="token punctuation">,</span> $<span class="token string">"burk"</span><span class="token punctuation">,</span> $<span class="token string">"start_date"</span><span class="token punctuation">,</span> $<span class="token string">"end_date"</span><span class="token punctuation">)</span>
<span class="token comment">// 保存结果</span>
    resDF<span class="token punctuation">.</span>write
      <span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">"csv"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>mode<span class="token punctuation">(</span>SaveMode<span class="token punctuation">.</span>Overwrite<span class="token punctuation">)</span>
      <span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string">"/bigdata30/spark_out4"</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<h5><a id="_2919"></a>蚂蚁森林植物申领统计</h5> 
<p>table_name：user_low_carbon</p> 
<table><thead><tr><th>字段名</th><th>字段描述</th></tr></thead><tbody><tr><td>user_id</td><td>用户</td></tr><tr><td>data_dt</td><td>日期</td></tr><tr><td>low_carbon</td><td>减少碳排放（g）</td></tr></tbody></table> 
<p>蚂蚁森林植物换购表，用于记录申领环保植物所需要减少的碳排放量</p> 
<p>table_name: plant_carbon</p> 
<table><thead><tr><th>字段名</th><th>字段描述</th></tr></thead><tbody><tr><td>plant_id</td><td>植物编号</td></tr><tr><td>plant_name</td><td>植物名</td></tr><tr><td>plant_carbon</td><td>换购植物所需要的碳</td></tr></tbody></table> 
<p>题目一</p> 
<p>蚂蚁森林植物申领统计<br> 问题：假设2017年1月1日开始记录低碳数据（user_low_carbon），假设2017年10月1日之前满足申领条件的用户都申领了一颗p004-胡杨，<br> 剩余的能量全部用来领取“p002-沙柳” 。<br> 统计在10月1日累计申领“p002-沙柳” 排名前10的用户信息；以及他比后一名多领了几颗沙柳。<br> 得到的统计结果如下表样式：</p> 
<pre><code>user_id  plant_count less_count(比后一名多领了几颗沙柳)
u_101    1000         100
u_088    900          400
u_103    500          …
</code></pre> 
<p><strong>题目二</strong></p> 
<p>蚂蚁森林低碳用户排名分析<br> 问题：查询user_low_carbon表中每日流水记录，条件为：<br> 用户在2017年，连续三天（或以上）的天数里，<br> 每天减少碳排放（low_carbon）都超过100g的用户低碳流水。<br> 需要查询返回满足以上条件的user_low_carbon表中的记录流水。<br> 例如用户u_002符合条件的记录如下，因为2017/1/2~2017/1/5连续四天的碳排放量之和都大于等于100g：</p> 
<pre><code class="prism language-TXT"> user_id data_dt  low_carbon
 u_002  2017/1/2  150
 u_002  2017/1/2  70
 u_002  2017/1/3  30
 u_002  2017/1/3  80
 u_002  2017/1/4  150
 u_002  2017/1/5  101
</code></pre> 
<pre><code class="prism language-scala"><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>expressions<span class="token punctuation">.</span></span>Window
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>DataFrame<span class="token punctuation">,</span> Row<span class="token punctuation">,</span> SparkSession<span class="token punctuation">}</span>

<span class="token keyword">object</span> Demo15MaYi <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token comment">/**
     * 创建SparkSession的环境对象
     */</span>
    <span class="token keyword">val</span> sparkSession<span class="token operator">:</span> SparkSession <span class="token operator">=</span> SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>master<span class="token punctuation">(</span><span class="token string">"local"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>appName<span class="token punctuation">(</span><span class="token string">"蚂蚁森林案例"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>config<span class="token punctuation">(</span><span class="token string">"spark.sql.shuffle.partitions"</span><span class="token punctuation">,</span> <span class="token string">"1"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>functions<span class="token punctuation">.</span></span>_
    <span class="token keyword">import</span> <span class="token namespace">sparkSession<span class="token punctuation">.</span>implicits<span class="token punctuation">.</span></span>_

    <span class="token comment">//读取用户每日碳排放量信息表</span>
    <span class="token keyword">val</span> userLowCarbonDF<span class="token operator">:</span> DataFrame <span class="token operator">=</span> sparkSession<span class="token punctuation">.</span>read
      <span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">"csv"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"sep"</span><span class="token punctuation">,</span> <span class="token string">"\t"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>schema<span class="token punctuation">(</span><span class="token string">"user_id STRING,date_dt STRING,low_carbon Double"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"spark/data/ant_user_low_carbon.txt"</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> plantCarbonDF<span class="token operator">:</span> DataFrame <span class="token operator">=</span> sparkSession<span class="token punctuation">.</span>read
      <span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">"csv"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"sep"</span><span class="token punctuation">,</span> <span class="token string">"\t"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>schema<span class="token punctuation">(</span><span class="token string">"plant_id STRING,plant_name STRING,plant_carbon Double"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"spark/data/ant_plant_carbon.txt"</span><span class="token punctuation">)</span>

    <span class="token comment">//因为用户信息表与植物信息表是没有直接关联条件的，需要单独的从植物信息表中将胡杨和沙柳的所需能量提取出来由变量保存</span>
    <span class="token keyword">val</span> huYangCarbon<span class="token operator">:</span> <span class="token builtin">Double</span> <span class="token operator">=</span> plantCarbonDF<span class="token punctuation">.</span>where<span class="token punctuation">(</span>$<span class="token string">"plant_name"</span> <span class="token operator">==</span><span class="token operator">=</span> <span class="token string">"胡杨"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>select<span class="token punctuation">(</span>$<span class="token string">"plant_carbon"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>rdd
      <span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>head
      <span class="token punctuation">.</span>getAs<span class="token punctuation">[</span><span class="token builtin">Double</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token string">"plant_carbon"</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> shaLiuCarbon<span class="token operator">:</span> <span class="token builtin">Double</span> <span class="token operator">=</span> plantCarbonDF<span class="token punctuation">.</span>where<span class="token punctuation">(</span>$<span class="token string">"plant_name"</span> <span class="token operator">==</span><span class="token operator">=</span> <span class="token string">"沙柳"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>select<span class="token punctuation">(</span>$<span class="token string">"plant_carbon"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>rdd
      <span class="token punctuation">.</span>collect<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>head
      <span class="token punctuation">.</span>getAs<span class="token punctuation">[</span><span class="token builtin">Double</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token string">"plant_carbon"</span><span class="token punctuation">)</span>

    println<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token id function">s</span><span class="token string">"胡杨所需碳排放量：</span><span class="token interpolation"><span class="token punctuation">$</span><span class="token expression">huYangCarbon</span></span><span class="token string">, 沙柳所需碳排放量：</span><span class="token interpolation"><span class="token punctuation">$</span><span class="token expression">shaLiuCarbon</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
    println<span class="token punctuation">(</span><span class="token string">"=========================================================================="</span><span class="token punctuation">)</span>

    <span class="token comment">/**
     * 题目一：蚂蚁森林植物申领统计
     *    假设2017年1月1日开始记录低碳数据（user_low_carbon），假设2017年10月1日之前满足申领条件的用户都申领了一颗p004-胡杨，
     * 剩余的能量全部用来领取“p002-沙柳” 。
     * 统计在10月1日累计申领“p002-沙柳” 排名前10的用户信息；以及他比后一名多领了几颗沙柳。
     * 得到的统计结果如下表样式：
     */</span>
    <span class="token comment">//过滤日期是2017年1月1日到2017年10月1日之间的</span>
    userLowCarbonDF<span class="token punctuation">.</span>where<span class="token punctuation">(</span>$<span class="token string">"date_dt"</span> <span class="token operator">&gt;=</span> <span class="token string">"2017/1/1"</span> and $<span class="token string">"date_dt"</span> <span class="token operator">&lt;=</span> <span class="token string">"2017/10/1"</span><span class="token punctuation">)</span><span class="token comment">//.show()</span>
    <span class="token comment">//根据用户，日期分组，聚合每一天总的排放量</span>
      <span class="token punctuation">.</span>groupBy<span class="token punctuation">(</span>$<span class="token string">"user_id"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>agg<span class="token punctuation">(</span>sum<span class="token punctuation">(</span>$<span class="token string">"low_carbon"</span><span class="token punctuation">)</span> as <span class="token string">"low_carbon"</span><span class="token punctuation">)</span><span class="token comment">//.show()</span>
    <span class="token comment">//新增一列，表示申领条件后的剩余能量</span>
      <span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"other_carbon"</span><span class="token punctuation">,</span>when<span class="token punctuation">(</span>$<span class="token string">"low_carbon"</span> <span class="token operator">&gt;=</span> huYangCarbon<span class="token punctuation">,</span>$<span class="token string">"low_carbon"</span> <span class="token operator">-</span> huYangCarbon<span class="token punctuation">)</span><span class="token punctuation">.</span>otherwise<span class="token punctuation">(</span>$<span class="token string">"low_carbon"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">//.show()</span>
    <span class="token comment">//新增一列，计算领取沙柳的棵树</span>
      <span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"plant_count"</span><span class="token punctuation">,</span>floor<span class="token punctuation">(</span>$<span class="token string">"other_carbon"</span> <span class="token operator">/</span> shaLiuCarbon<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">//.show()</span>
      <span class="token comment">//新增一列，取出后一个沙柳的棵树</span>
      <span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"after_plant_count"</span><span class="token punctuation">,</span>lead<span class="token punctuation">(</span>$<span class="token string">"plant_count"</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span> over Window<span class="token punctuation">.</span>orderBy<span class="token punctuation">(</span>$<span class="token string">"plant_count"</span><span class="token punctuation">.</span>desc<span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"less_count"</span><span class="token punctuation">,</span>$<span class="token string">"plant_count"</span> <span class="token operator">-</span> $<span class="token string">"after_plant_count"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>limit<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>select<span class="token punctuation">(</span>$<span class="token string">"user_id"</span><span class="token punctuation">,</span>$<span class="token string">"plant_count"</span><span class="token punctuation">,</span>$<span class="token string">"less_count"</span><span class="token punctuation">)</span>
<span class="token comment">//      .show()</span>

    <span class="token comment">/**
     * 题目二：蚂蚁森林低碳用户排名分析
     *    查询user_low_carbon表中每日流水记录，条件为：
     * 用户在2017年，连续三天（或以上）的天数里，
     * 每天减少碳排放（low_carbon）都超过100g的用户低碳流水。
     * 需要查询返回满足以上条件的user_low_carbon表中的记录流水。
     * 例如用户u_002符合条件的记录如下，因为2017/1/2~2017/1/5连续四天的碳排放量之和都大于等于100g：
     */</span>
    <span class="token comment">//根据用户和日期进行分组，得到每一天碳排放量</span>
    userLowCarbonDF<span class="token punctuation">.</span>groupBy<span class="token punctuation">(</span>$<span class="token string">"user_id"</span><span class="token punctuation">,</span>$<span class="token string">"date_dt"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>agg<span class="token punctuation">(</span>sum<span class="token punctuation">(</span>$<span class="token string">"low_carbon"</span><span class="token punctuation">)</span> as <span class="token string">"day_carbon"</span><span class="token punctuation">)</span>
      <span class="token comment">//过滤出大于100碳排放量的天</span>
      <span class="token punctuation">.</span>where<span class="token punctuation">(</span>$<span class="token string">"day_carbon"</span> <span class="token operator">&gt;</span> <span class="token number">100</span><span class="token punctuation">)</span>
      <span class="token comment">//根据用户开窗，以日期升序排序</span>
      <span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"rn"</span><span class="token punctuation">,</span>row_number<span class="token punctuation">(</span><span class="token punctuation">)</span> over Window<span class="token punctuation">.</span>partitionBy<span class="token punctuation">(</span>$<span class="token string">"user_id"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>orderBy<span class="token punctuation">(</span>$<span class="token string">"date_dt"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token comment">//将日期减去编号，根据结果判断天数是否连续</span>
      <span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"tmp_date"</span><span class="token punctuation">,</span>date_sub<span class="token punctuation">(</span>regexp_replace<span class="token punctuation">(</span>$<span class="token string">"date_dt"</span><span class="token punctuation">,</span><span class="token string">"/"</span><span class="token punctuation">,</span><span class="token string">"-"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>$<span class="token string">"rn"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment">//新增一列，计算用户连续的天数</span>
      <span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"days"</span><span class="token punctuation">,</span>count<span class="token punctuation">(</span>expr<span class="token punctuation">(</span><span class="token string">"1"</span><span class="token punctuation">)</span><span class="token punctuation">)</span> over Window<span class="token punctuation">.</span>partitionBy<span class="token punctuation">(</span>$<span class="token string">"user_id"</span><span class="token punctuation">,</span>$<span class="token string">"tmp_date"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token comment">//过滤出连续天数是大于3的</span>
      <span class="token punctuation">.</span>where<span class="token punctuation">(</span>$<span class="token string">"days"</span> <span class="token operator">&gt;=</span> <span class="token number">3</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>select<span class="token punctuation">(</span>$<span class="token string">"user_id"</span><span class="token punctuation">,</span>$<span class="token string">"date_dt"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>join<span class="token punctuation">(</span>userLowCarbonDF<span class="token punctuation">,</span>List<span class="token punctuation">(</span><span class="token string">"user_id"</span><span class="token punctuation">,</span><span class="token string">"date_dt"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>select<span class="token punctuation">(</span>$<span class="token string">"user_id"</span><span class="token punctuation">,</span>$<span class="token string">"date_dt"</span><span class="token punctuation">,</span>$<span class="token string">"low_carbon"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<h3><a id="Spark_streaming_3076"></a>Spark streaming</h3> 
<p><img src="https://images2.imgbox.com/ac/02/ylSZgTp2_o.png" alt="sparkStreamingFlink.png"></p> 
<p>通过wordcount 认识spark streaming</p> 
<pre><code class="prism language-scala"><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>dstream<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>DStream<span class="token punctuation">,</span> ReceiverInputDStream<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>Duration<span class="token punctuation">,</span> Durations<span class="token punctuation">,</span> StreamingContext<span class="token punctuation">}</span>

<span class="token keyword">object</span> Demo1WordCount <span class="token punctuation">{<!-- --></span>
  <span class="token comment">/**
   * Spark core: SparkContext 核心数据结构：RDD
   * Spark sql: SparkSession 核心数据结构：DataFrame
   * Spark streaming: StreamingContext  核心数据结构：DStream(底层封装了RDD)
   */</span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">val</span> conf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span>
    conf<span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"wordCount"</span><span class="token punctuation">)</span>
    conf<span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[2]"</span><span class="token punctuation">)</span> <span class="token comment">// 给定核数</span>
    <span class="token keyword">val</span> context <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>
    <span class="token comment">//创建Spark Streaming的运行环境，和前两个模块是不一样的</span>
    <span class="token comment">//Spark Streaming是依赖于Spark core的环境的</span>
    <span class="token comment">//this(sparkContext: SparkContext, batchDuration: Duration)</span>
    <span class="token comment">//Spark Streaming处理之前，是有一个接收数据的过程</span>
    <span class="token comment">//batchDuration，表示接收多少时间段内的数据</span>
    <span class="token keyword">val</span> streamingContext <span class="token operator">=</span> <span class="token keyword">new</span> StreamingContext<span class="token punctuation">(</span>context<span class="token punctuation">,</span> Durations<span class="token punctuation">.</span>seconds<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">// 传入接收时间</span>

     <span class="token comment">//Spark Streaming程序理论上是一旦启动，就不会停止，除非报错，人为停止，停电等其他突然场景导致程序终止</span>
    <span class="token comment">// 监控一个端口号中的数据，手动向端口号中打数据</span>
    <span class="token comment">// 模拟kafka</span>
    <span class="token keyword">val</span> rids<span class="token operator">:</span> ReceiverInputDStream<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> streamingContext<span class="token punctuation">.</span>socketTextStream<span class="token punctuation">(</span><span class="token string">"master"</span><span class="token punctuation">,</span>  <span class="token number">12345</span><span class="token punctuation">)</span>
    <span class="token comment">// 对接收的数据进行处理</span>
    <span class="token keyword">val</span> resDS<span class="token operator">:</span> DStream<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> rids
      <span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_ <span class="token operator">+</span> _<span class="token punctuation">)</span>

resDS<span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment">/**
     * sparkStreaming启动的方式和前两个模块启动方式不一样
     */</span>
    streamingContext<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>
    streamingContext<span class="token punctuation">.</span>awaitTermination<span class="token punctuation">(</span><span class="token punctuation">)</span>
    streamingContext<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

</code></pre> 
<p><img src="https://images2.imgbox.com/c8/0c/6qCeOi9l_o.png" alt="image.png"></p> 
<p><img src="https://images2.imgbox.com/aa/67/6EXRMFTV_o.png" alt=".png"></p> 
<p>如何将上一次处理的结果保留下来？</p> 
<blockquote> 
 <ul><li>需要使用有状态的算子来处理当前批次数据与历史数据的关系<br> * updateStateByKey(S:ClassTag)(updateFunc: (Seq[V], Option[S]) =&gt; Option[S]): DStream[(K, S)] 
   <ul><li>Seq: 序列，表示历史键对应的值组成的序列 (hello, seq:[1,1,1])</li><li>Option: 当前批次输入键对应的value值，如果历史中没有该键，这个值就是None, 如果历史中出现了这个键，这个值就是Some(值)</li><li>有状态算子使用注意事项：</li><li>1、有状态算子ByKey算子只适用于k-v类型的DStream</li><li>2、有状态算子使用的时候，需要提前设置checkpoint的路径，因为需要将历史批次的结果存储下来</li></ul> </li></ul> 
</blockquote> 
<pre><code class="prism language-scala"><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>dstream<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>DStream<span class="token punctuation">,</span> ReceiverInputDStream<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>Duration<span class="token punctuation">,</span> Durations<span class="token punctuation">,</span> StreamingContext<span class="token punctuation">}</span>

<span class="token keyword">object</span> Demo2WordCount2 <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>

    <span class="token keyword">val</span> conf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span>
    conf<span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[2]"</span><span class="token punctuation">)</span> <span class="token comment">// 给定核数</span>
    conf<span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"spark Streaming 单词统计"</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> sparkContext <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>


    <span class="token keyword">val</span> streamingContext <span class="token operator">=</span> <span class="token keyword">new</span> StreamingContext<span class="token punctuation">(</span>sparkContext<span class="token punctuation">,</span> Durations<span class="token punctuation">.</span>seconds<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment">//设置的是一个文件夹 存储历史数据</span>
    streamingContext<span class="token punctuation">.</span>checkpoint<span class="token punctuation">(</span><span class="token string">"spark/data/checkpoint2"</span><span class="token punctuation">)</span>


    <span class="token keyword">val</span> rids<span class="token operator">:</span> ReceiverInputDStream<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> streamingContext<span class="token punctuation">.</span>socketTextStream<span class="token punctuation">(</span><span class="token string">"master"</span><span class="token punctuation">,</span> <span class="token number">12345</span><span class="token punctuation">)</span>
    <span class="token comment">//hello world</span>

    <span class="token keyword">val</span> wordsDS<span class="token operator">:</span> DStream<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> rids<span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> kvDS<span class="token operator">:</span> DStream<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> wordsDS<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">// (hello,1) (hello,1)  (hello,1)</span>

    <span class="token comment">/**
     * 每5秒中resDS中的数据，是当前5s内的数据
     * reduceByKey，只会对当前5s批次中的数据求和
     */</span>
    <span class="token comment">//    val resDS: DStream[(String, Int)] = kvDS.reduceByKey(_ + _)</span>


  
    <span class="token keyword">val</span> resDS<span class="token operator">:</span> DStream<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> kvDS<span class="token punctuation">.</span>updateStateByKey<span class="token punctuation">(</span><span class="token punctuation">(</span>seq1<span class="token operator">:</span> Seq<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">,</span> opt1<span class="token operator">:</span> Option<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> <span class="token punctuation">{<!-- --></span>
    <span class="token comment">// 上一次的总和</span>
      <span class="token keyword">val</span> sumValue<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> seq1<span class="token punctuation">.</span>sum
      <span class="token comment">// 这一次的</span>
      <span class="token keyword">val</span> num<span class="token operator">:</span> <span class="token builtin">Int</span> <span class="token operator">=</span> opt1<span class="token punctuation">.</span>getOrElse<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
      Option<span class="token punctuation">(</span>sumValue <span class="token operator">+</span> num<span class="token punctuation">)</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span>


    println<span class="token punctuation">(</span><span class="token string">"--------------------------------------"</span><span class="token punctuation">)</span>
    resDS<span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token punctuation">)</span>
    println<span class="token punctuation">(</span><span class="token string">"--------------------------------------"</span><span class="token punctuation">)</span>

    streamingContext<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>
    streamingContext<span class="token punctuation">.</span>awaitTermination<span class="token punctuation">(</span><span class="token punctuation">)</span>
    streamingContext<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>

  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/c6/d8/rKEgDtUX_o.png" alt="image.png"></p> 
<h4><a id="_3201"></a>窗口</h4> 
<blockquote> 
 <p>滑动窗口和滚动窗口</p> 
</blockquote> 
<img src="https://images2.imgbox.com/4c/63/jSweKW4N_o.png" alt=".png"> 
<pre><code class="prism language-scala"><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span>SparkSession
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>dstream<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>DStream<span class="token punctuation">,</span> ReceiverInputDStream<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>Durations<span class="token punctuation">,</span> StreamingContext<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>

<span class="token keyword">object</span> Demo3Window <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token comment">/**
     * 创建spark streaming的环境
     * 旧版本创建的方式
     */</span>
    <span class="token comment">//    val conf: SparkConf = new SparkConf().setMaster("local[2]").setAppName("窗口案例")</span>
    <span class="token comment">//    val context = new SparkContext(conf)</span>
    <span class="token comment">//    val sc = new StreamingContext(context, Durations.seconds(5))</span>

    <span class="token comment">/**
     * 新版本的创建方式
     */</span>
    <span class="token keyword">val</span> context<span class="token operator">:</span> SparkContext <span class="token operator">=</span> SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>master<span class="token punctuation">(</span><span class="token string">"local[2]"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>appName<span class="token punctuation">(</span><span class="token string">"窗口案例"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>config<span class="token punctuation">(</span><span class="token string">"spark.sql.shuffle.partitions"</span><span class="token punctuation">,</span> <span class="token string">"1"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>sparkContext
    <span class="token keyword">val</span> sc <span class="token operator">=</span> <span class="token keyword">new</span> StreamingContext<span class="token punctuation">(</span>context<span class="token punctuation">,</span> Durations<span class="token punctuation">.</span>seconds<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">// 正常每次接收5s内的数据</span>

    <span class="token comment">//1000 ~ 65535 端口号</span>
    <span class="token keyword">val</span> infoDS<span class="token operator">:</span> ReceiverInputDStream<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>socketTextStream<span class="token punctuation">(</span><span class="token string">"master"</span><span class="token punctuation">,</span> <span class="token number">10086</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> wordsDS<span class="token operator">:</span> DStream<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> infoDS<span class="token punctuation">.</span>flatMap<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> kvDS<span class="token operator">:</span> DStream<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> wordsDS<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment">/**
     * 1、如果只是为了计算当前批次接收的数据，直接调用reduceByKey
     * 2、如果要将最新批次的数据与历史数据结合处理的话，需要调用有状态算子 updateStateByKey
     * 3、如果要实现滑动窗口或者滚动窗口的话，需要使用窗口类算子reduceByKeyAndWindow
     */</span>
    <span class="token comment">//def reduceByKeyAndWindow(reduceFunc: (V, V) =&gt; V,windowDuration: Duration,slideDuration: Duration): DStream[(K, V)]</span>
    <span class="token comment">//reduceFunc 编写处理相同的键对应的value值做处理</span>
    <span class="token comment">//windowDuration  设置窗口的大小</span>
    <span class="token comment">//slideDuration  设置滑动的大小</span>
    <span class="token comment">//每间隔slideDuration大小的时间计算一次数据，计算数据的范围是最近windowDuration大小时间的数据</span>
    <span class="token keyword">val</span> resDS<span class="token operator">:</span> DStream<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> kvDS<span class="token punctuation">.</span>reduceByKeyAndWindow<span class="token punctuation">(</span><span class="token punctuation">(</span>v1<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">,</span> v2<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> v1 <span class="token operator">+</span> v2<span class="token punctuation">,</span> Durations<span class="token punctuation">.</span>seconds<span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Durations<span class="token punctuation">.</span>seconds<span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment">/**
     * 当窗口大小与滑动大小一致的时候，那么就会从滑动窗口转变成滚动窗口的效果
     */</span>
<span class="token comment">//    val resDS: DStream[(String, Int)] = kvDS.reduceByKeyAndWindow((v1: Int, v2: Int) =&gt; v1 + v2, Durations.seconds(10), Durations.seconds(10))</span>


    resDS<span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token punctuation">)</span>

    sc<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>
    sc<span class="token punctuation">.</span>awaitTermination<span class="token punctuation">(</span><span class="token punctuation">)</span>
    sc<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>

  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<h4><a id="_3269"></a>各数据类型之间的关系</h4> 
<p><img src="https://images2.imgbox.com/ad/b6/ru3uEI4S_o.png" alt="spark.png"></p> 
<h5><a id="foreachRDD_3273"></a>foreachRDD</h5> 
<pre><code class="prism language-scala"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>shujia<span class="token punctuation">.</span>streaming</span>

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span>SparkContext
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span></span>RDD
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>DataFrame<span class="token punctuation">,</span> SparkSession<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>dstream<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>DStream<span class="token punctuation">,</span> ReceiverInputDStream<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>Durations<span class="token punctuation">,</span> StreamingContext<span class="token punctuation">}</span>

<span class="token keyword">object</span> Demo4DStream2RDD <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token comment">//使用DataFrame的语法</span>
    <span class="token keyword">val</span> sparkSession<span class="token operator">:</span> SparkSession <span class="token operator">=</span> SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>master<span class="token punctuation">(</span><span class="token string">"local[2]"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>appName<span class="token punctuation">(</span><span class="token string">"rdd与DStream的关系"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>config<span class="token punctuation">(</span><span class="token string">"spark.sql.shuffle.partitions"</span><span class="token punctuation">,</span> <span class="token string">"1"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>functions<span class="token punctuation">.</span></span>_
    <span class="token keyword">import</span> <span class="token namespace">sparkSession<span class="token punctuation">.</span>implicits<span class="token punctuation">.</span></span>_

    <span class="token comment">//使用RDD的语法</span>
    <span class="token keyword">val</span> sparkContext<span class="token operator">:</span> SparkContext <span class="token operator">=</span> sparkSession<span class="token punctuation">.</span>sparkContext

    <span class="token comment">//使用DStream的语法</span>
    <span class="token keyword">val</span> streamingContext <span class="token operator">=</span> <span class="token keyword">new</span> StreamingContext<span class="token punctuation">(</span>sparkContext<span class="token punctuation">,</span> Durations<span class="token punctuation">.</span>seconds<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> infoDS<span class="token operator">:</span> ReceiverInputDStream<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> streamingContext<span class="token punctuation">.</span>socketTextStream<span class="token punctuation">(</span><span class="token string">"master"</span><span class="token punctuation">,</span> <span class="token number">10086</span><span class="token punctuation">)</span>
    <span class="token comment">//如果DS不是键值形式的话，可以单独调用window函数进行设置窗口的形式</span>
    <span class="token keyword">val</span> new_infoDS<span class="token operator">:</span> DStream<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> infoDS<span class="token punctuation">.</span>window<span class="token punctuation">(</span>Durations<span class="token punctuation">.</span>seconds<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Durations<span class="token punctuation">.</span>seconds<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment">// hello world java hello java</span>
    <span class="token comment">/**
     * foreachRDD：在DS中使用rdd的语法操作数据
     * 缺点：该函数是没有返回值的
     * 需求：我们在想使用DS中的RDD的同时，想要使用结束后，会得到一个新的DS
     */</span>
    new_infoDS<span class="token punctuation">.</span>foreachRDD<span class="token punctuation">(</span><span class="token punctuation">(</span>rdd<span class="token operator">:</span>RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">=&gt;</span><span class="token punctuation">{<!-- --></span>
      println<span class="token punctuation">(</span><span class="token string">"------------------------------"</span><span class="token punctuation">)</span>
<span class="token comment">//      val resRDD: RDD[(String, Int)] = rdd.flatMap(_.split(" "))</span>
<span class="token comment">//        .map((_, 1))</span>
<span class="token comment">//        .reduceByKey(_ + _)</span>
<span class="token comment">//      resRDD.foreach(println)</span>

      <span class="token comment">//rdd和df之间可以转换 使用RDD的方式处理</span>
      <span class="token keyword">val</span> df1<span class="token operator">:</span> DataFrame <span class="token operator">=</span> rdd<span class="token punctuation">.</span>toDF<span class="token punctuation">.</span>select<span class="token punctuation">(</span>$<span class="token string">"value"</span> as <span class="token string">"info"</span><span class="token punctuation">)</span>
      df1<span class="token punctuation">.</span>createOrReplaceTempView<span class="token punctuation">(</span><span class="token string">"words"</span><span class="token punctuation">)</span>
      <span class="token keyword">val</span> resDF<span class="token operator">:</span> DataFrame <span class="token operator">=</span> sparkSession<span class="token punctuation">.</span>sql<span class="token punctuation">(</span>
        <span class="token triple-quoted-string string">"""
          |select
          |t1.wds as word,
          |count(1) as counts
          |from
          |(
          |select
          |explode(split(info,' ')) as  wds
          |from words) t1
          |group by t1.wds
          |"""</span><span class="token punctuation">.</span>stripMargin<span class="token punctuation">)</span>
      resDF<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span>

    streamingContext<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>
    streamingContext<span class="token punctuation">.</span>awaitTermination<span class="token punctuation">(</span><span class="token punctuation">)</span>
    streamingContext<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>

  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>transform</p> 
<pre><code class="prism language-scala"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>shujia<span class="token punctuation">.</span>streaming</span>

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span>SparkContext
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span></span>RDD
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>DataFrame<span class="token punctuation">,</span> Row<span class="token punctuation">,</span> SparkSession<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>dstream<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>DStream<span class="token punctuation">,</span> ReceiverInputDStream<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>Durations<span class="token punctuation">,</span> StreamingContext<span class="token punctuation">}</span>


<span class="token comment">/**
 * 面试题：foreachRDD与transform的区别
 */</span>
<span class="token keyword">object</span> Demo5TransFormat <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token comment">//使用DataFrame的语法</span>
    <span class="token keyword">val</span> sparkSession<span class="token operator">:</span> SparkSession <span class="token operator">=</span> SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>master<span class="token punctuation">(</span><span class="token string">"local[2]"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>appName<span class="token punctuation">(</span><span class="token string">"rdd与DStream的关系"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>config<span class="token punctuation">(</span><span class="token string">"spark.sql.shuffle.partitions"</span><span class="token punctuation">,</span> <span class="token string">"1"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>functions<span class="token punctuation">.</span></span>_
    <span class="token keyword">import</span> <span class="token namespace">sparkSession<span class="token punctuation">.</span>implicits<span class="token punctuation">.</span></span>_

    <span class="token comment">//使用RDD的语法</span>
    <span class="token keyword">val</span> sparkContext<span class="token operator">:</span> SparkContext <span class="token operator">=</span> sparkSession<span class="token punctuation">.</span>sparkContext

    <span class="token comment">//使用DStream的语法</span>
    <span class="token keyword">val</span> streamingContext <span class="token operator">=</span> <span class="token keyword">new</span> StreamingContext<span class="token punctuation">(</span>sparkContext<span class="token punctuation">,</span> Durations<span class="token punctuation">.</span>seconds<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> infoDS<span class="token operator">:</span> ReceiverInputDStream<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> streamingContext<span class="token punctuation">.</span>socketTextStream<span class="token punctuation">(</span><span class="token string">"master"</span><span class="token punctuation">,</span> <span class="token number">10086</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> resDS<span class="token operator">:</span> DStream<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> infoDS<span class="token punctuation">.</span>transform<span class="token punctuation">(</span><span class="token punctuation">(</span>rdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> <span class="token punctuation">{<!-- --></span>
      <span class="token comment">//直接对rdd进行处理，返回新的rdd</span>
      <span class="token comment">//      val resRDD: RDD[(String, Int)] = rdd.flatMap(_.split(" "))</span>
      <span class="token comment">//        .map((_, 1))</span>
      <span class="token comment">//        .reduceByKey(_ + _)</span>
      <span class="token comment">//      resRDD</span>

      <span class="token comment">//将rdd转df，使用sql做分析</span>
      <span class="token comment">//rdd和df之间可以转换</span>
      <span class="token keyword">val</span> df1<span class="token operator">:</span> DataFrame <span class="token operator">=</span> rdd<span class="token punctuation">.</span>toDF<span class="token punctuation">.</span>select<span class="token punctuation">(</span>$<span class="token string">"value"</span> as <span class="token string">"info"</span><span class="token punctuation">)</span>
      df1<span class="token punctuation">.</span>createOrReplaceTempView<span class="token punctuation">(</span><span class="token string">"words"</span><span class="token punctuation">)</span>
      <span class="token keyword">val</span> resDF<span class="token operator">:</span> DataFrame <span class="token operator">=</span> sparkSession<span class="token punctuation">.</span>sql<span class="token punctuation">(</span>
        <span class="token triple-quoted-string string">"""
          |select
          |t1.wds as word,
          |count(1) as counts
          |from
          |(
          |select
          |explode(split(info,' ')) as  wds
          |from words) t1
          |group by t1.wds
          |"""</span><span class="token punctuation">.</span>stripMargin<span class="token punctuation">)</span>

      <span class="token keyword">val</span> resRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> resDF<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>row<span class="token operator">:</span> Row<span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> <span class="token punctuation">(</span>row<span class="token punctuation">.</span>getAs<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> row<span class="token punctuation">.</span>getAs<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      resRDD
    <span class="token punctuation">}</span><span class="token punctuation">)</span>

    resDS<span class="token punctuation">.</span>print<span class="token punctuation">(</span><span class="token punctuation">)</span>

    streamingContext<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>
    streamingContext<span class="token punctuation">.</span>awaitTermination<span class="token punctuation">(</span><span class="token punctuation">)</span>
    streamingContext<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>


  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>区别：</p> 
<blockquote> 
 <p>transform: 将Dstream的操作转化为RDD的操作，返回的是一个新的RDD</p> 
 <p>foreach: 将Dstream的操作转化为RDD的操作，没有返回值 ，直接在函数中操作</p> 
</blockquote> 
<h4><a id="yarn_3426"></a>yarn提交作业</h4> 
<p>打包代码 上传</p> 
<pre><code class="prism language-sh">spark-submit <span class="token parameter variable">--master</span> <span class="token function">yarn</span> --deploy-mode client <span class="token parameter variable">--class</span> com.shujia.streaming.Demo6YarnSubmiti  spark-1.0.jar --num-executors <span class="token number">2</span> --executor-cores <span class="token number">1</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/49/2b/POLL6bow_o.png" alt="image.png"></p> 
<h4><a id="spark_streaming_3438"></a>spark streaming保存文件到本地</h4> 
<pre><code class="prism language-scala">    <span class="token comment">//将结果存储到磁盘中</span>
    <span class="token comment">//只能设置文件夹的名字和文件的后缀</span>
    <span class="token comment">//每一批次运行，都会产生新的小文件夹，文件夹中有结果数据文件</span>
    resDS<span class="token punctuation">.</span>saveAsTextFiles<span class="token punctuation">(</span><span class="token string">"spark/data/streamout/stream"</span><span class="token punctuation">,</span><span class="token string">"txt"</span><span class="token punctuation">)</span>
</code></pre> 
<p>拓展：将数据保存到数据库中</p> 
<pre><code class="prism language-scala"><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span>SparkContext
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span></span>RDD
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span>SparkSession
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>Durations<span class="token punctuation">,</span> StreamingContext<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>dstream<span class="token punctuation">.</span></span>ReceiverInputDStream

<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>Connection<span class="token punctuation">,</span> DriverManager<span class="token punctuation">,</span> PreparedStatement<span class="token punctuation">}</span>

<span class="token keyword">object</span> Demo8DS2Mysql <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token comment">//使用DataFrame的语法</span>
    <span class="token keyword">val</span> sparkSession<span class="token operator">:</span> SparkSession <span class="token operator">=</span> SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>master<span class="token punctuation">(</span><span class="token string">"local[2]"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>appName<span class="token punctuation">(</span><span class="token string">"rdd与DStream的关系"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>config<span class="token punctuation">(</span><span class="token string">"spark.sql.shuffle.partitions"</span><span class="token punctuation">,</span> <span class="token string">"1"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>functions<span class="token punctuation">.</span></span>_
    <span class="token keyword">import</span> <span class="token namespace">sparkSession<span class="token punctuation">.</span>implicits<span class="token punctuation">.</span></span>_

    <span class="token comment">//使用RDD的语法</span>
    <span class="token keyword">val</span> sparkContext<span class="token operator">:</span> SparkContext <span class="token operator">=</span> sparkSession<span class="token punctuation">.</span>sparkContext

    <span class="token comment">//使用DStream的语法</span>
    <span class="token keyword">val</span> streamingContext <span class="token operator">=</span> <span class="token keyword">new</span> StreamingContext<span class="token punctuation">(</span>sparkContext<span class="token punctuation">,</span> Durations<span class="token punctuation">.</span>seconds<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> infoDS<span class="token operator">:</span> ReceiverInputDStream<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> streamingContext<span class="token punctuation">.</span>socketTextStream<span class="token punctuation">(</span><span class="token string">"master"</span><span class="token punctuation">,</span> <span class="token number">10086</span><span class="token punctuation">)</span>


        infoDS<span class="token punctuation">.</span>foreachRDD<span class="token punctuation">(</span><span class="token punctuation">(</span>rdd<span class="token operator">:</span>RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">=&gt;</span><span class="token punctuation">{<!-- --></span>
          println<span class="token punctuation">(</span><span class="token string">"======================= 正在处理一批数据 =========================="</span><span class="token punctuation">)</span>
          <span class="token comment">//处理rdd中每一条数据</span>
          rdd<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span><span class="token punctuation">(</span>line<span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">)</span><span class="token keyword">=&gt;</span><span class="token punctuation">{<!-- --></span>
            <span class="token comment">//如果将创建连接的代码写在这里，这样的话，每条数据都会创建一次连接</span>
            <span class="token comment">/**
             * 创建与数据库连接对象
             */</span>
            <span class="token comment">//注册驱动</span>
            Class<span class="token punctuation">.</span>forName<span class="token punctuation">(</span><span class="token string">"com.mysql.jdbc.Driver"</span><span class="token punctuation">)</span>
            <span class="token comment">//创建数据库连接对象</span>
            <span class="token keyword">val</span> conn<span class="token operator">:</span> Connection <span class="token operator">=</span> DriverManager<span class="token punctuation">.</span>getConnection<span class="token punctuation">(</span>
              <span class="token string">"jdbc:mysql://master:3306/bigdata30?useUnicode=true&amp;characterEncoding=UTF-8&amp;useSSL=false"</span><span class="token punctuation">,</span>
              <span class="token string">"root"</span><span class="token punctuation">,</span>
              <span class="token string">"123456"</span>
            <span class="token punctuation">)</span>
            <span class="token comment">//创建预编译对象</span>
            <span class="token keyword">val</span> statement<span class="token operator">:</span> PreparedStatement <span class="token operator">=</span> conn<span class="token punctuation">.</span>prepareStatement<span class="token punctuation">(</span><span class="token string">"insert into students values(?,?,?,?,?)"</span><span class="token punctuation">)</span>

            <span class="token keyword">val</span> info<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span>
            statement<span class="token punctuation">.</span>setInt<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>info<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toInt<span class="token punctuation">)</span>
            statement<span class="token punctuation">.</span>setString<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span>info<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            statement<span class="token punctuation">.</span>setInt<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span>info<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toInt<span class="token punctuation">)</span>
            statement<span class="token punctuation">.</span>setString<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span>info<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            statement<span class="token punctuation">.</span>setString<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span>info<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

            <span class="token comment">//执行sql语句</span>
            statement<span class="token punctuation">.</span>executeUpdate<span class="token punctuation">(</span><span class="token punctuation">)</span>

            <span class="token comment">//释放资源</span>
            statement<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
            conn<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
          <span class="token punctuation">}</span><span class="token punctuation">)</span>
        <span class="token punctuation">}</span><span class="token punctuation">)</span>
        streamingContext<span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span>
    	streamingContext<span class="token punctuation">.</span>awaitTermination<span class="token punctuation">(</span><span class="token punctuation">)</span>
    	streamingContext<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>但是这样做每一条数据处理都会创建一次连接，浪费资源： 尝试改造</p> 
<pre><code class="prism language-scala"><span class="token comment">/**
     * 设想中的改造，不一定能运行
     * 我们将原本在rdd中创建连接的代码放到了ds中，发现PreparedStatement不能与task任务一起序列化到executor中的
     * 这样的写法是不可以的！！！！！！！
     */</span>
    <span class="token comment">//    infoDS.foreachRDD((rdd: RDD[String]) =&gt; {<!-- --></span>
    <span class="token comment">//      println("======================= 正在处理一批数据 ==========================")</span>
    <span class="token comment">//      //如果将创建连接的代码写在这里，这样的话，每条数据都会创建一次连接</span>
    <span class="token comment">//      /**</span>
    <span class="token comment">//       * 创建与数据库连接对象</span>
    <span class="token comment">//       */</span>
    <span class="token comment">//      //注册驱动</span>
    <span class="token comment">//      Class.forName("com.mysql.jdbc.Driver")</span>
    <span class="token comment">//      //创建数据库连接对象</span>
    <span class="token comment">//      val conn: Connection = DriverManager.getConnection(</span>
    <span class="token comment">//        "jdbc:mysql://master:3306/bigdata30?useUnicode=true&amp;characterEncoding=UTF-8&amp;useSSL=false",</span>
    <span class="token comment">//        "root",</span>
    <span class="token comment">//        "123456"</span>
    <span class="token comment">//      )</span>
    <span class="token comment">//      //创建预编译对象</span>
    <span class="token comment">//      val statement: PreparedStatement = conn.prepareStatement("insert into students values(?,?,?,?,?)")</span>
    <span class="token comment">//      //处理rdd中每一条数据</span>
    <span class="token comment">//      rdd.foreach((line: String) =&gt; {<!-- --></span>
    <span class="token comment">//        val info: Array[String] = line.split(",")</span>
    <span class="token comment">//        statement.setInt(1, info(0).toInt)</span>
    <span class="token comment">//        statement.setString(2, info(1))</span>
    <span class="token comment">//        statement.setInt(3, info(2).toInt)</span>
    <span class="token comment">//        statement.setString(4, info(3))</span>
    <span class="token comment">//        statement.setString(5, info(4))</span>
    <span class="token comment">//        //执行sql语句</span>
    <span class="token comment">//        statement.executeUpdate()</span>
    <span class="token comment">//      })</span>
    <span class="token comment">//</span>
    <span class="token comment">//      //释放资源</span>
    <span class="token comment">//      statement.close()</span>
    <span class="token comment">//      conn.close()</span>
    <span class="token comment">//</span>
    <span class="token comment">//    })</span>
</code></pre> 
<p>最终版本：foreachPartition算子</p> 
<pre><code class="prism language-scala"><span class="token comment">/**
     * rdd中有一个算子foreachPartition
     * rdd本质是由一系列分区构成的，如果我们可以将分区数设置为1，且每个分区创建一个连接不就好了么
     */</span>
    infoDS<span class="token punctuation">.</span>foreachRDD<span class="token punctuation">(</span><span class="token punctuation">(</span>rdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> <span class="token punctuation">{<!-- --></span>
      println<span class="token punctuation">(</span><span class="token string">"======================= 接收到 5s 一批次数据 =========================="</span><span class="token punctuation">)</span>
      rdd<span class="token punctuation">.</span>repartition<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>
      println<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token id function">s</span><span class="token string">" DS封装的RDD中的分区数为:</span><span class="token interpolation"><span class="token punctuation">${<!-- --></span><span class="token expression">rdd<span class="token punctuation">.</span>getNumPartitions</span><span class="token punctuation">}</span></span><span class="token string"> "</span></span><span class="token punctuation">)</span>

      <span class="token comment">/**
       * foreachPartition，处理一个分区的数据
       * 将一个分区的数据，封装成了一个迭代器
       */</span>
      rdd<span class="token punctuation">.</span>foreachPartition<span class="token punctuation">(</span><span class="token punctuation">(</span>itr<span class="token operator">:</span> Iterator<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> <span class="token punctuation">{<!-- --></span>
        println<span class="token punctuation">(</span><span class="token string">"======================= 正在处理一个分区的数据 =========================="</span><span class="token punctuation">)</span>
        <span class="token comment">/**
         * 创建与数据库连接对象
         */</span>
        <span class="token comment">//注册驱动</span>
        Class<span class="token punctuation">.</span>forName<span class="token punctuation">(</span><span class="token string">"com.mysql.jdbc.Driver"</span><span class="token punctuation">)</span>
        <span class="token comment">//创建数据库连接对象</span>
        <span class="token keyword">val</span> conn<span class="token operator">:</span> Connection <span class="token operator">=</span> DriverManager<span class="token punctuation">.</span>getConnection<span class="token punctuation">(</span>
          <span class="token string">"jdbc:mysql://master:3306/bigdata30?useUnicode=true&amp;characterEncoding=UTF-8&amp;useSSL=false"</span><span class="token punctuation">,</span>
          <span class="token string">"root"</span><span class="token punctuation">,</span>
          <span class="token string">"123456"</span>
        <span class="token punctuation">)</span>
        <span class="token comment">//创建预编译对象</span>
        <span class="token keyword">val</span> statement<span class="token operator">:</span> PreparedStatement <span class="token operator">=</span> conn<span class="token punctuation">.</span>prepareStatement<span class="token punctuation">(</span><span class="token string">"insert into students values(?,?,?,?,?)"</span><span class="token punctuation">)</span>
        println<span class="token punctuation">(</span><span class="token string">"========================= 创建了一次连接 ========================="</span><span class="token punctuation">)</span>
        itr<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span><span class="token punctuation">(</span>line<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> <span class="token punctuation">{<!-- --></span>
          <span class="token keyword">val</span> info<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span>
          statement<span class="token punctuation">.</span>setInt<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> info<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toInt<span class="token punctuation">)</span>
          statement<span class="token punctuation">.</span>setString<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> info<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
          statement<span class="token punctuation">.</span>setInt<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> info<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toInt<span class="token punctuation">)</span>
          statement<span class="token punctuation">.</span>setString<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> info<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
          statement<span class="token punctuation">.</span>setString<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> info<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
          <span class="token comment">//执行sql语句</span>
          statement<span class="token punctuation">.</span>executeUpdate<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token punctuation">}</span><span class="token punctuation">)</span>
        statement<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
        conn<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">}</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="Spark__3613"></a>Spark 优化</h3> 
<p>spark 调优</p> 
<blockquote> 
 <p>避免创建重复的RDD</p> 
 <p>尽可能复用同一个RDD</p> 
 <p>对多次使用的RDD进行持久化 ♥</p> 
 <p>尽量避免使用shuffle类算子</p> 
 <p>使用map-side预聚合的shuffle操作</p> 
 <p>使用高性能的算子 ♥</p> 
 <p>广播大变量♥</p> 
 <p>使用Kryo优化序列化性能</p> 
 <p>优化数据结构使用高性能的库fastutil</p> 
</blockquote> 
<h4><a id="RDD_3635"></a>对多次使用的RDD进行持久化</h4> 
<blockquote> 
 <p>默认情况下，性能最高的当然是MEMORY_ONLY，但前提是你的内存必须足够足够大， 可以绰绰有余地存放下整个RDD的所有数据。因为不进行序列化与反序列化操作，就避 免了这部分的性能开销;对这个RDD的后续算子操作，都是基于纯内存中的数据的操作 ，不需要从磁盘文件中读取数据，性能也很高;而且不需要复制一份数据副本，并远程传 送到其他节点上。但是这里必须要注意的是，在实际的生产环境中，恐怕能够直接用这种 策略的场景还是有限的，如果RDD中数据比较多时(比如几十亿)，直接用这种持久化 级别，会导致JVM的OOM内存溢出异常。</p> 
</blockquote> 
<blockquote> 
 <p>如果使用MEMORY_ONLY级别时发生了内存溢出（OOM），那么建议尝试使用 MEMORY_ONLY_SER级别。该级别会将RDD数据序列化后再保存在内存中，此时每个 partition仅仅是一个字节数组而已，大大减少了对象数量，并降低了内存占用。这种级别 比MEMORY_ONLY多出来的性能开销，主要就是序列化与反序列化的开销。但是后续算 子可以基于纯内存进行操作，因此性能总体还是比较高的。此外，可能发生的问题同上， 如果RDD中的数据量过多的话，还是可能会导致OOM内存溢出的异常。</p> 
</blockquote> 
<blockquote> 
 <p>如果纯内存的级别都无法使用，那么建议使用MEMORY_AND_DISK_SER策略，而不是 MEMORY_AND_DISK策略。因为既然到了这一步，就说明RDD的数据量很大，内存无 法完全放下。序列化后的数据比较少，可以节省内存和磁盘的空间开销。同时该策略会优 先尽量尝试将数据缓存在内存中，内存缓存不下才会写入磁盘。</p> 
</blockquote> 
<blockquote> 
 <p>通常不建议使用DISK_ONLY和后缀为_2的级别:因为完全基于磁盘文件进行数据的读写 ，会导致性能急剧降低，有时还不如重新计算一次所有RDD。后缀为_2的级别，必须将 所有数据都复制一份副本，并发送到其他节点上，数据复制以及网络传输会导致较大的性 能开销，除非是要求作业的高可用性，否则不建议使用。</p> 
</blockquote> 
<h4><a id="_3645"></a>使用高性能的算子</h4> 
<blockquote> 
 <p>使用reduceByKey/aggregateByKey替代groupByKey</p> 
 <p>使用mapPartitions替代普通map Transformation算子</p> 
 <p>使用foreachPartitions替代foreach Action算子</p> 
 <p>使用filter之后进行coalesce操作</p> 
 <p>使用repartitionAndSortWithinPartitions替代repartition与sort类操作代码</p> 
 <p>repartition:coalesce(numPartitions，true) 增多分区使用这个</p> 
 <p>coalesce(numPartitions，false) 减少分区 没有shuffle只是合并 partition</p> 
</blockquote> 
<p>aggregateByKey</p> 
<pre><code class="prism language-scala"><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span>SparkContext
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span></span>RDD
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span>SparkSession

<span class="token keyword">object</span> Demo2AggregateByKey <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token comment">//使用reduceByKey/aggregateByKey替代groupByKey</span>
    <span class="token keyword">val</span> sparkSession<span class="token operator">:</span> SparkSession <span class="token operator">=</span> SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>config<span class="token punctuation">(</span><span class="token string">"spark.sql.shuffle.partitions"</span><span class="token punctuation">,</span> <span class="token string">"1"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>master<span class="token punctuation">(</span><span class="token string">"local[2]"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>appName<span class="token punctuation">(</span><span class="token string">"缓存优化"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> sparkContext<span class="token operator">:</span> SparkContext <span class="token operator">=</span> sparkSession<span class="token punctuation">.</span>sparkContext


    <span class="token keyword">val</span> stuRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sparkContext<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"spark/data/students.txt"</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> clazzKVRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> stuRDD<span class="token punctuation">.</span>map<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span> <span class="token keyword">match</span> <span class="token punctuation">{<!-- --></span>
      <span class="token keyword">case</span> Array<span class="token punctuation">(</span>_<span class="token punctuation">,</span> _<span class="token punctuation">,</span> _<span class="token punctuation">,</span> _<span class="token punctuation">,</span> clazz<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span>
        <span class="token punctuation">(</span>clazz<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span>

    <span class="token comment">//reduceByKey的使用，分组之后，直接使用聚合</span>
    <span class="token comment">//理解为普通的MapReduce中的根据相同的键进入到同一个reduce, 然后在reduce端聚合</span>
    <span class="token comment">//实际上这里对应的是前一个RDD中的分区中数据相同的键到后一个RDD中同一个分区，在后一个RDD分区中的聚合</span>
    <span class="token comment">//    val resRDD: RDD[(String, Int)] = clazzKVRDD.reduceByKey(_ + _)</span>
    <span class="token comment">//    resRDD.foreach(println)</span>

    <span class="token comment">//groupByKey 不做聚合，只做前一个RDD中的分区中数据相同的键到后一个RDD中同一个分区 (尽量使用reduceByKey去替代)</span>
    <span class="token comment">//    val resRDD2: RDD[(String, Int)] = clazzKVRDD.groupByKey()</span>
    <span class="token comment">//      .map((kv: (String, Iterable[Int])) =&gt; {<!-- --></span>
    <span class="token comment">//        (kv._1, kv._2.sum)</span>
    <span class="token comment">//      })</span>
    <span class="token comment">//    resRDD2.foreach(println)</span>

    <span class="token comment">//aggregateByKey</span>
    <span class="token comment">//aggregateByKey(zeroValue: U)(seqOp: (U, V) =&gt; U,  combOp: (U, U) =&gt; U)</span>
    <span class="token comment">//zeroValue: 初始值，这个参数只会被后面第一个参数函数所使用</span>
    <span class="token comment">//seqOp: 相当于map端预聚合的逻辑</span>
    <span class="token comment">//combOp: 相当于reduce端的聚合逻辑</span>
    <span class="token keyword">val</span> resRDD3<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> clazzKVRDD<span class="token punctuation">.</span>aggregateByKey<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">(</span>
      <span class="token comment">//相当于map端预聚合的逻辑</span>
      <span class="token punctuation">(</span>a1<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">,</span> a2<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> a1 <span class="token operator">+</span> a2<span class="token punctuation">,</span>
      <span class="token comment">//相当于reduce端的聚合逻辑</span>
      <span class="token punctuation">(</span>b1<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">,</span> b2<span class="token operator">:</span> <span class="token builtin">Int</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> b1 <span class="token operator">+</span> b2
    <span class="token punctuation">)</span>

    resRDD3<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>


  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>mapPartitions</p> 
<pre><code class="prism language-scala"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>shujia<span class="token punctuation">.</span>opt</span>

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span>SparkContext
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span></span>RDD
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span>SparkSession

<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>text<span class="token punctuation">.</span></span>SimpleDateFormat
<span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span>Date

<span class="token keyword">object</span> Demo3MapPartitions <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token comment">//使用mapPartitions替代普通map Transformation算子</span>
    <span class="token comment">//使用reduceByKey/aggregateByKey替代groupByKey</span>
    <span class="token keyword">val</span> sparkSession<span class="token operator">:</span> SparkSession <span class="token operator">=</span> SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>config<span class="token punctuation">(</span><span class="token string">"spark.sql.shuffle.partitions"</span><span class="token punctuation">,</span> <span class="token string">"1"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>master<span class="token punctuation">(</span><span class="token string">"local[2]"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>appName<span class="token punctuation">(</span><span class="token string">"缓存优化"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> sparkContext<span class="token operator">:</span> SparkContext <span class="token operator">=</span> sparkSession<span class="token punctuation">.</span>sparkContext

    <span class="token keyword">val</span> lineRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sparkContext<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"spark/data/ant_user_low_carbon.txt"</span><span class="token punctuation">)</span>
    println<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token id function">s</span><span class="token string">"lineRDD的分区数：</span><span class="token interpolation"><span class="token punctuation">${<!-- --></span><span class="token expression">lineRDD<span class="token punctuation">.</span>getNumPartitions</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

    <span class="token comment">/**
     * map算子主要作用是，遍历RDD中的每一条数据，进行处理返回新的一条数据
     * 如果在处理过程中，需要创建工具对象的话，那么使用map不太好，原因是因为每一条数据都需要new一下
     * 可能会造成内存溢出
     */</span>
<span class="token comment">//    val resRDD: RDD[(String, String, String)] = lineRDD.map((line: String) =&gt; {<!-- --></span>
<span class="token comment">//      println("===================创建一次对象=============================")// 每次都会创建</span>
<span class="token comment">//      val info: Array[String] = line.split("\t")</span>
<span class="token comment">//      val t1: String = info(1)</span>
<span class="token comment">//      val sdf = new SimpleDateFormat("yyyy/MM/dd")</span>
<span class="token comment">//      val date: Date = sdf.parse(t1)</span>
<span class="token comment">//      val sdf2 = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss")</span>
<span class="token comment">//      val t2: String = sdf2.format(date)</span>
<span class="token comment">//      (info(0), t2, info(2))</span>
<span class="token comment">//    })</span>
<span class="token comment">//    resRDD.foreach(println)</span>

    <span class="token comment">/**
     * 实际上针对上面的案例，我们可以针对rdd中的每一个分区创建一个工具对象，在每条数据上使用
     * mapPartitions,将每一个分区中的数据封装成了一个迭代器
     */</span>
    <span class="token keyword">val</span> resRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> lineRDD<span class="token punctuation">.</span>mapPartitions<span class="token punctuation">(</span><span class="token punctuation">(</span>itr<span class="token operator">:</span> Iterator<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> <span class="token punctuation">{<!-- --></span>
      println<span class="token punctuation">(</span><span class="token string">"===================创建一次对象============================="</span><span class="token punctuation">)</span> <span class="token comment">// 只会创建两次</span>
      <span class="token keyword">val</span> sdf <span class="token operator">=</span> <span class="token keyword">new</span> SimpleDateFormat<span class="token punctuation">(</span><span class="token string">"yyyy/MM/dd"</span><span class="token punctuation">)</span>
      <span class="token keyword">val</span> sdf2 <span class="token operator">=</span> <span class="token keyword">new</span> SimpleDateFormat<span class="token punctuation">(</span><span class="token string">"yyyy-MM-dd HH:mm:ss"</span><span class="token punctuation">)</span>
      itr<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>line<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span> <span class="token punctuation">{<!-- --></span>
        <span class="token keyword">val</span> info<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"\t"</span><span class="token punctuation">)</span>
        <span class="token keyword">val</span> t1<span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span> info<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token keyword">val</span> date<span class="token operator">:</span> Date <span class="token operator">=</span> sdf<span class="token punctuation">.</span>parse<span class="token punctuation">(</span>t1<span class="token punctuation">)</span>
        <span class="token keyword">val</span> t2<span class="token operator">:</span> <span class="token builtin">String</span> <span class="token operator">=</span> sdf2<span class="token punctuation">.</span>format<span class="token punctuation">(</span>date<span class="token punctuation">)</span>
        <span class="token punctuation">(</span>info<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> t2<span class="token punctuation">,</span> info<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">}</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span>

    resRDD<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

</code></pre> 
<h5><a id="RepartitionCoalesce_3786"></a>Repartition和Coalesce区别</h5> 
<ul><li> <p>关系：两者都是用来改变RDD的partition数量的，repartition底层调用的就是coalesce方法：coalesce(numPartitions, shuffle = true)</p> </li><li> <p>区别：repartition一定会发生shuffle，coalesce根据传入的参数来判断是否发生shuffle，一般情况下增大rdd的partition数量使用repartition，减少partition数量时使用coalesce</p> </li></ul> 
<pre><code class="prism language-scala">
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span></span>RDD
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>

<span class="token keyword">object</span> Demo4Coalesce1 <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token comment">//repartition:coalesce(numPartitions，true) 增多分区使用这个</span>
    <span class="token comment">//coalesce(numPartitions，false) 减少分区 没有shuffle只是合并 partition</span>
    <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"重分区"</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> sc <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>

    <span class="token keyword">val</span> lineRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"spark/data/students.txt"</span><span class="token punctuation">)</span>
    println<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token id function">s</span><span class="token string">"lineRDD的分区数：</span><span class="token interpolation"><span class="token punctuation">${<!-- --></span><span class="token expression">lineRDD<span class="token punctuation">.</span>getNumPartitions</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

    <span class="token comment">/**
     * 使用repartition
     */</span>
    <span class="token comment">//增大分区数，使用repartition，返回一个新的rdd,会产生shuffle</span>
    <span class="token comment">//    val resRDD1: RDD[String] = lineRDD.repartition(10)</span>
    <span class="token comment">//    println(s"resRDD1的分区数：${resRDD1.getNumPartitions}")</span>
    <span class="token comment">//    resRDD1.foreach(println)</span>
    <span class="token comment">//减少分区数，使用repartition，返回一个新的rdd,会产生shuffle</span>
    <span class="token comment">//    val resRDD2: RDD[String] = resRDD1.repartition(1)</span>
    <span class="token comment">//    println(s"resRDD2的分区数：${resRDD2.getNumPartitions}")</span>
    <span class="token comment">//    resRDD2.foreach(println)</span>


    <span class="token comment">/**
     * coalesce
     *
     * 1、默认增大分区是不会产生shuffle的  如果想要，加上参数shuffle = true
     * 2、合并分区直接给分区数，不会产生shuffle
     */</span>

    <span class="token keyword">val</span> resRDD1<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> lineRDD<span class="token punctuation">.</span>coalesce<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> shuffle <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">)</span>
    println<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token id function">s</span><span class="token string">"resRDD1的分区数：</span><span class="token interpolation"><span class="token punctuation">${<!-- --></span><span class="token expression">resRDD1<span class="token punctuation">.</span>getNumPartitions</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
<span class="token comment">//    resRDD1.foreach(println)</span>

    <span class="token keyword">val</span> resRDD2<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> resRDD1<span class="token punctuation">.</span>coalesce<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>shuffle <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">)</span>
    println<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token id function">s</span><span class="token string">"resRDD2的分区数：</span><span class="token interpolation"><span class="token punctuation">${<!-- --></span><span class="token expression">resRDD2<span class="token punctuation">.</span>getNumPartitions</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
    resRDD2<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>


    <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
  <span class="token comment">// 查看DAG</span>
    <span class="token punctuation">}</span>


  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>合并小文件时：</p> 
<pre><code class="prism language-scala"><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>SparkConf<span class="token punctuation">,</span> SparkContext<span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span></span>RDD

<span class="token comment">/**
 * 当资源充足的情况下，可以适当的使用重分区算子，扩大分区数
 * 当资源不足的情况下，可以适当的减少分区数
 *
 * 分区数会影响rdd的并行任务数
 */</span>
<span class="token keyword">object</span> Demo5Coalesce2 <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token comment">//repartition:coalesce(numPartitions，true) 增多分区使用这个</span>
    <span class="token comment">//coalesce(numPartitions，false) 减少分区 没有shuffle只是合并 partition</span>
    <span class="token keyword">val</span> conf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"重分区"</span><span class="token punctuation">)</span>
    <span class="token keyword">val</span> sc <span class="token operator">=</span> <span class="token keyword">new</span> SparkContext<span class="token punctuation">(</span>conf<span class="token punctuation">)</span>

    <span class="token keyword">val</span> lineRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> sc<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"spark/data/test1/*"</span><span class="token punctuation">)</span>
    println<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token id function">s</span><span class="token string">"lineRDD的分区数：</span><span class="token interpolation"><span class="token punctuation">${<!-- --></span><span class="token expression">lineRDD<span class="token punctuation">.</span>getNumPartitions</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

    <span class="token comment">/**
     * Coalesce算子通常是用在合并小文件时候使用
     * 对应的spark core中的话，通常使用该算子进行合并分区
     */</span>
    <span class="token keyword">val</span> lineRDD2<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> lineRDD<span class="token punctuation">.</span>coalesce<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
    lineRDD2<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<h4><a id="_3883"></a>广播大变量</h4> 
<blockquote> 
 <p>如果使用的外部变量比较大，建议使用Spark的广播功能，对该变量进行广播。广播 后的变量，会保证每个Executor的内存中，只驻留一份变量副本，而Executor中的 task执行时共享该Executor中的那份变量副本。这样的话，可以大大减少变量副本 的数量，从而减少网络传输的性能开销，并减少对Executor内存的占用开销，降低 GC的频率</p> 
</blockquote> 
<blockquote> 
 <p>广播大变量发送方式:Executor一开始并没有广播变量，而是task运行需要用到广 播变量，会找executor的blockManager要，bloackManager找Driver里面的 blockManagerMaster要。</p> 
</blockquote> 
<pre><code class="prism language-scala"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>shujia<span class="token punctuation">.</span>opt</span>

<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span>DataFrame<span class="token punctuation">,</span> SparkSession<span class="token punctuation">}</span>

<span class="token keyword">object</span> Demo6Join <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">val</span> sparkSession<span class="token operator">:</span> SparkSession <span class="token operator">=</span> SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>master<span class="token punctuation">(</span><span class="token string">"local"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>appName<span class="token punctuation">(</span><span class="token string">"spark sql使用广播变量"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>config<span class="token punctuation">(</span><span class="token string">"spark.sql.shuffle.partitions"</span><span class="token punctuation">,</span> <span class="token string">"1"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>functions<span class="token punctuation">.</span></span>_
    <span class="token keyword">import</span> <span class="token namespace">sparkSession<span class="token punctuation">.</span>implicits<span class="token punctuation">.</span></span>_

    <span class="token keyword">val</span> studentsDF<span class="token operator">:</span> DataFrame <span class="token operator">=</span> sparkSession<span class="token punctuation">.</span>read
      <span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">"csv"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"seq"</span><span class="token punctuation">,</span> <span class="token string">","</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>schema<span class="token punctuation">(</span><span class="token string">"id STRING,name STRING,age INT,gender STRING,clazz STRING"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"spark/data/students.txt"</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> scoresDF<span class="token operator">:</span> DataFrame <span class="token operator">=</span> sparkSession<span class="token punctuation">.</span>read
      <span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">"csv"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"seq"</span><span class="token punctuation">,</span> <span class="token string">","</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>schema<span class="token punctuation">(</span><span class="token string">"id STRING,subject_id STRING,score INT"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"spark/data/score.txt"</span><span class="token punctuation">)</span>


    <span class="token comment">/**
     * 如果在spark sql中是两个DF进行join关联的话，并且运行模式是local模式的话，会自动地将关联的DF进行广播
     * 如果不是local模式，不会自动进行，需要手动将要广播的DF给广播出去
     *
     * 广播大变量，1G的变量
     *
     * hint
     * 会进行两次job作业
     * 第一次是将关联的DF广播
     * 第二次是使用广播的DF进行关联
     */</span>
    <span class="token keyword">val</span> resDF<span class="token operator">:</span> DataFrame <span class="token operator">=</span> scoresDF<span class="token punctuation">.</span>join<span class="token punctuation">(</span>studentsDF<span class="token punctuation">.</span>hint<span class="token punctuation">(</span><span class="token string">"broadcast"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"id"</span><span class="token punctuation">)</span>

    resDF<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>

    <span class="token punctuation">}</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<h4><a id="Kryo_3941"></a>使用Kryo优化序列化性能</h4> 
<p>序列化：</p> 
<blockquote> 
 <p>在Spark中，主要有三个地方涉及到了序列化</p> 
 <ul><li>在算子函数中使用到外部变量时，该变量会被序列化后进行网络传输</li><li>将自定义的类型作为RDD的泛型类型时(比如JavaRDD，SXT是自定义类型)，所有自 定义类型对象，都会进行序列化。因此这种情况下，也要求自定义的类必须实现 Serializable接口。</li><li>使用可序列化的持久化策略时(比如MEMORY_ONLY_SER)，Spark会将RDD中的每个 partition都序列化成一个大的字节数组。</li></ul> 
</blockquote> 
<p>Kryo序列化器介绍:</p> 
<blockquote> 
 <p>park支持使用Kryo序列化机制。Kryo序列化机制，比默认的Java序列化机制，速度要快 ，序列化后的数据要更小，大概是Java序列化机制的1/10。所以Kryo序列化优化以后，可 以让网络传输的数据变少;在集群中耗费的内存资源大大减少。</p> 
</blockquote> 
<blockquote> 
 <p>对于这三种出现序列化的地方，我们都可以通过使用Kryo序列化类库，来优化序列化和 反序列化的性能。Spark默认使用的是Java的序列化机制，也就是 ObjectOutputStream/ObjectInputStream API来进行序列化和反序列化。但是Spark同 时支持使用Kryo序列化库，Kryo序列化类库的性能比Java序列化类库的性能要高很多。 官方介绍，Kryo序列化机制比Java序列化机制，性能高10倍左右。Spark之所以默认没有 使用Kryo作为序列化类库，是因为Kryo要求最好要注册所有需要进行序列化的自定义类 型，因此对于开发者来说，这种方式比较麻烦</p> 
</blockquote> 
<p>自定义一个序列化类：</p> 
<pre><code class="prism language-scala"><span class="token keyword">import</span> <span class="token namespace">com<span class="token punctuation">.</span>esotericsoftware<span class="token punctuation">.</span>kryo<span class="token punctuation">.</span></span>Kryo
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>serializer<span class="token punctuation">.</span></span>KryoRegistrator

<span class="token keyword">class</span> Demo8Kryo <span class="token keyword">extends</span> KryoRegistrator <span class="token punctuation">{<!-- --></span>
    <span class="token comment">// 实现它的方法</span>
  <span class="token keyword">override</span> <span class="token keyword">def</span> registerClasses<span class="token punctuation">(</span>kryo<span class="token operator">:</span> Kryo<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token comment">//告诉spark程序，使用kryo序列化，具体是什么要进行kryo序列化</span>
    kryo<span class="token punctuation">.</span>register<span class="token punctuation">(</span>classOf<span class="token punctuation">[</span>Student<span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment">//    kryo.register(classOf[Teacher])</span>

  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>使用kryo序列化：</p> 
<blockquote> 
 <p>.config(“spark.serializer”, “org.apache.spark.serializer.KryoSerializer”)</p> 
 <p>.config(“spark.kryo.registrator”, “自定义类”)</p> 
</blockquote> 
<pre><code class="prism language-scala"><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span>SparkContext
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>rdd<span class="token punctuation">.</span></span>RDD
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span>SparkSession
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>storage<span class="token punctuation">.</span></span>StorageLevel

<span class="token keyword">object</span> Demo7Kryo <span class="token punctuation">{<!-- --></span>
  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">val</span> sparkSession<span class="token operator">:</span> SparkSession <span class="token operator">=</span> SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>config<span class="token punctuation">(</span><span class="token string">"spark.sql.shuffle.partitions"</span><span class="token punctuation">,</span> <span class="token string">"1"</span><span class="token punctuation">)</span>
      <span class="token comment">//将序列化方式设置为Kryo的序列化方式</span>
      <span class="token punctuation">.</span>config<span class="token punctuation">(</span><span class="token string">"spark.serializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.spark.serializer.KryoSerializer"</span><span class="token punctuation">)</span>
      <span class="token comment">//自定义一个序列化类，指定要序列化的东西</span>
      <span class="token punctuation">.</span>config<span class="token punctuation">(</span><span class="token string">"spark.kryo.registrator"</span><span class="token punctuation">,</span> <span class="token string">"com.shujia.opt.Demo8Kryo"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>master<span class="token punctuation">(</span><span class="token string">"local[2]"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>appName<span class="token punctuation">(</span><span class="token string">"缓存优化"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">val</span> sparkContext<span class="token operator">:</span> SparkContext <span class="token operator">=</span> sparkSession<span class="token punctuation">.</span>sparkContext


    <span class="token keyword">val</span> studentsRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span>Student<span class="token punctuation">]</span> <span class="token operator">=</span> sparkContext<span class="token punctuation">.</span>textFile<span class="token punctuation">(</span><span class="token string">"spark/data/students.txt"</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span>map<span class="token punctuation">(</span>_<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span> <span class="token keyword">match</span> <span class="token punctuation">{<!-- --></span>
        <span class="token keyword">case</span> Array<span class="token punctuation">(</span>id<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> name<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> age<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> gender<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> clazz<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">)</span> <span class="token keyword">=&gt;</span>
          Student<span class="token punctuation">(</span>id<span class="token punctuation">,</span> name<span class="token punctuation">,</span> age<span class="token punctuation">.</span>toInt<span class="token punctuation">,</span> gender<span class="token punctuation">,</span> clazz<span class="token punctuation">)</span>
      <span class="token punctuation">}</span><span class="token punctuation">)</span>

    <span class="token comment">/**
     * 第二次job作业使用的数据大小
     * 未使用序列化进行缓存：238.3 KiB
     * 使用是默认的序列化方式：65.4 KiB
     * 使用kryo序列化：43.0 KiB
     */</span>
<span class="token comment">//    studentsRDD.cache() // 默认的缓存级别是MEMORY_ONLY</span>
    studentsRDD<span class="token punctuation">.</span>persist<span class="token punctuation">(</span>StorageLevel<span class="token punctuation">.</span>MEMORY_ONLY_SER<span class="token punctuation">)</span>

    <span class="token comment">/**
     * 计算每个班级的人数
     */</span>
    <span class="token keyword">val</span> resRDD<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> studentsRDD<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>stu<span class="token operator">:</span>Student<span class="token punctuation">)</span><span class="token keyword">=&gt;</span><span class="token punctuation">(</span>stu<span class="token punctuation">.</span>clazz<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_ <span class="token operator">+</span> _<span class="token punctuation">)</span>
    resRDD<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>

    <span class="token comment">/**
     * 计算每个性别的人数
     */</span>
    <span class="token keyword">val</span> resRDD2<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">Int</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> studentsRDD<span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token punctuation">(</span>stu<span class="token operator">:</span>Student<span class="token punctuation">)</span><span class="token keyword">=&gt;</span><span class="token punctuation">(</span>stu<span class="token punctuation">.</span>gender<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reduceByKey<span class="token punctuation">(</span>_ <span class="token operator">+</span> _<span class="token punctuation">)</span>
    resRDD2<span class="token punctuation">.</span>foreach<span class="token punctuation">(</span>println<span class="token punctuation">)</span>
    <span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
<span class="token comment">// 查看DAG 等信息</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

<span class="token keyword">case</span> <span class="token keyword">class</span> Student<span class="token punctuation">(</span>id<span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">,</span>name<span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">,</span>age<span class="token operator">:</span><span class="token builtin">Int</span><span class="token punctuation">,</span>gender<span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">,</span>clazz<span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">)</span><span class="token comment">// 样例类</span>
</code></pre> 
<h4><a id="_4036"></a>优化数据结构</h4> 
<blockquote> 
 <p>Java中，有三种类型比较耗费内存:</p> 
 <ul><li>对象，每个Java对象都有对象头、引用等额外的信息，因此比较占用内存空间。</li><li>字符串，每个字符串内部都有一个字符数组以及长度等额外信息。</li><li>集合类型，比如HashMap、LinkedList等，因为集合类型内部通常会使用一些内部类来 封装集合元素，比如Map.Entry。</li></ul> 
 <p>因此Spark官方建议，在Spark编码实现中，特别是对于算子函数中的代码，尽 量不要使用上述三种数据结构，尽量使用字符串替代对象，使用原始类型(比如 Int、Long)替代字符串，使用数组替代集合类型，这样尽可能地减少内存占用 ，从而降低GC频率，提升性能。</p> 
</blockquote> 
<h4><a id="_4046"></a>数据本地性</h4> 
<blockquote> 
 <p>数据本地化级别:</p> 
 <p>PROCESS_LOCAL <strong>进程本地化</strong>，数据和task任务在同一个Executor中执行，默认</p> 
 <p>NODE_LOCA <strong>节点本地化</strong> 数据和task任务在同一个节点中不同的Executor中执行 跨Executor拉取数据</p> 
 <p>NO_PREF 第三方存储中间件得到数据，mysql clickhouse redis</p> 
 <p>RACK_LOCAL <strong>机架本地化</strong> task任务和数据在同一个机架不同的节点中执行 跨节点拉取数据</p> 
 <p>ANY <strong>跨机架本地化</strong> task任务和数据不在一个机架上</p> 
</blockquote> 
<p>配置参数</p> 
<blockquote> 
 <p>spark.locality.wait</p> 
 <p>spark.locality.wait.process</p> 
 <p>spark.locality.wait.node</p> 
 <p>spark.locality.wait.rack</p> 
</blockquote> 
<p><img src="https://images2.imgbox.com/07/9b/4IEs40NI_o.png" alt=".png"></p> 
<h4><a id="JVM_4072"></a>JVM调优</h4> 
<blockquote> 
 <p>Spark task执行算子函数，可能会创建很多对象，这些对象，都是要放入JVM年轻代中</p> 
 <p>RDD的缓存数据也会放入到堆内存中</p> 
</blockquote> 
<p>配置</p> 
<blockquote> 
 <p>spark.storage.memoryFraction 默认是0.6</p> 
</blockquote> 
<h4><a id="Executor_4084"></a>调节Executor堆外内存</h4> 
<blockquote> 
 <p>问题原因: Executor由于内存不足或者对外内存不足了，挂掉了，对应的Executor上面的block manager也挂掉了，找不到对应的shuffle map output文件，Reducer端不能够拉取数 据 Executor并没有挂掉，而是在拉取数据的过程出现了问题</p> 
</blockquote> 
<blockquote> 
 <p>调节一下executor的堆外内存。也许就可以避免报错;:</p> 
 <p>yarn下:–conf spark.yarn.executor.memoryOverhead=2048 单位M</p> 
 <p>standlone下:–conf spark.executor.memoryOverhead=2048单位M</p> 
 <p>也可以在代码中设置</p> 
</blockquote> 
<blockquote> 
 <p>堆外内存上限默认是每一个executor的内存大小的10%;真正处理大数据的时候， 这里都会出现问题，导致spark作业反复崩溃，无法运行;此时就会去调节这个参数，到至少1G (1024M)，甚至说2G、4G</p> 
</blockquote> 
<blockquote> 
 <p>调节等待时长</p> 
 <p>executor在进行shuffle write，优先从自己本地关联的BlockManager中获取某份数据如果本地 block manager没有的话，那么会通过TransferService，去远程连接其他节点上executor的block manager去获取，<strong>尝试建立远程的网络连接</strong>，并且去拉取数据 频繁的让JVM堆内存满溢，进行垃圾回收。正好碰到那个exeuctor的JVM在垃圾回收。处于垃圾回 收过程中，所有的工作线程全部停止;相当于只要一旦进行垃圾回收，spark / executor停止工作， 无法提供响应，spark默认的网络连接的超时时长，是60s;如果卡住60s都无法建立连接的话，那 么这个task就失败了。</p> 
 <p>解决?–conf spark.core.connection.ack.wait.timeout=300</p> 
</blockquote> 
<h4><a id="_4106"></a>参数模板</h4> 
<pre><code class="prism language-txt">--num-executors executor的数量
--executor-memory 每一个executor的内存
--executor-cores 每一个executor的核心数
--driver-memory Driver的内存1G-2G(保存广播变量)
--spark.storage.memoryFraction 设置RDD持久化数据在Executor内存中能占的比例，默认是0.6。
--spark.shuffle.memoryFraction 用户shuffle的内存占比默认0.2

-- spark提交yarn-client模式的命令模板
spark-submit --master yarn --deploy-mode client --num-executors 2 --executor-memory 1G --executor-cores 1 --class xxx.xxx.Xxx xxx.jar
-- spark提交yarn-cluster模式的命令模板
spark-submit --master yarn --deploy-mode cluster --num-executors 2 --executor-memory 1G --executor-cores 1 --class xxx.xxx.Xxx xxx.jar

总的内存=num-executors * executor-memory
总的核数=num-executors * executor-cores

不能乱给，且不能给满，因为作业执行还有其他的进行需要额外启动 --num-executors 200 --executor-memory 100G --executor-cores 100 （错误给资源的例子）

spark on yarn 资源设置标准

1、单个任务的总内存和总核数一般在yarn总的资源的1/3到1/2之间给资源
一般来说一个稍微大点的公司，集群的服务器个数大概在10台左右
单台服务器的内存大概是128G,核数大概是40个左右（国网，电信 100台以上）
小公司：如果公司规模总人数在80人左右，大数据部门在11人左右，5台大数据平台服务器 每一台的配置是8核16G内存

yarn总的内存 = 10*128G*0.8=960G
yarn总的核数 = 40*10=400

提交spark作业资源
参数计算后总的内存=960*（1/3 | 1/2）= 300G - 480G
参数计算后总的核数=400*（1/3 | 1/2）= 120 - 200

2、在实际生产上线的时候，资源要按照实际的情况合理定资源
2.1、数据量比较小  - 10G
10G = 80个block = rdd80分区 = 80个task
- 最理想资源指定   -- 剩余资源充足
--num-executors=40
--executor-memory=4G
--executor-cores=2
- 资源里面最优的方式 -- 剩余资源不是很充足时
--num-executors=20
--executor-memory=4G
--executor-cores=2

2.2、数据量比较大时 - 80G
80G = 640block = 640分区 = 640task
- 最理想资源指定   -- 剩余资源充足, 如果剩余资源不够，还需要减少指定的资源
--num-executors=100
--executor-memory=4G
--executor-cores=2


-- spark.locality.wait: spark task 再executor中执行前的等待时间 默认3秒
spark.yarn.executor.memoryOverhead : 堆外内存 默认等于堆内存的10%
spark.network.timeout spark网络链接的超时时间 默认120s

模板
spark-submit 
--master yarn 
--deploy-mode cluster
--num-executors = 50
--executor-memory = 4G
--executor-cores = 2
--driver-memory = 2G
--conf spark.storage.memoryFraction=0.4
--conf spark.shuffle.memoryFraction=0.4
--conf spark.locality.wait=10s
--conf spark.shuffle.file.buffer=64kb
--conf spark.yarn.executor.memoryOverhead=1024
--conf spark.network.timeout=200s


以下参数也可以在spark代码中指定
--conf spark.storage.memoryFraction=0.4
--conf spark.shuffle.memoryFraction=0.4
--conf spark.locality.wait=10s
--conf spark.shuffle.file.buffer=64kb
--conf spark.yarn.executor.memoryOverhead=1024
--conf spark.network.timeout=200s
</code></pre> 
<h4><a id="shuffle_4189"></a>shuffle调优</h4> 
<blockquote> 
 <p>概述:</p> 
 <p>reduceByKey:要把分布在集群各个节点上的数据中的同一个key，对应的values，都给 集中到一个节点的一个executor的一个task中，对集合起来的value执行传入的函数进行 reduce操作，最后变成一个value</p> 
 <p>配置</p> 
 <p>spark.shuffle.manager， 默认是sort</p> 
 <p>spark.shuffle.consolidateFiles，默认是false</p> 
 <p>spark.shuffle.file.buffer，默认是32k</p> 
 <p>spark.shuffle.memoryFraction，默认是0.2</p> 
</blockquote> 
<h3><a id="Spark__4207"></a>Spark 数据倾斜解决</h3> 
<ul><li> <p>Spark中的数据倾斜，表现主要有下面几种：</p> 
  <blockquote> 
   <p>数据倾斜产生的原因：1、数据分布不均，2，同时产生了shuffle</p> 
  </blockquote> 
  <ol><li>Executor lost，OOM，Shuffle过程出错；</li></ol> </li></ul> 
<ol start="2"><li>lDriver OOM；</li><li>单个Executor执行时间特别久，整体任务卡在某个阶段不能结束；</li><li>正常运行的任务突然失败</li></ol> 
<p>数据倾斜优化：</p> 
<h4><a id="Hive_ETL_4221"></a>使用Hive ETL预处理数据</h4> 
<ul><li>适用场景：导致数据倾斜的是Hive表。如果该Hive表中的数据本身很不均匀（比如某个key对应了100万数据，其他key才对应了10条数据），而且业务场景需要频繁使用Spark对Hive表执行某个分析操作，那么比较适合使用这种技术方案。</li><li>实现思路：此时可以评估一下，是否可以通过Hive来进行数据预处理（即通过Hive ETL预先对数据按照key进行聚合，或者是预先和其他表进行join），然后在Spark作业中针对的数据源就不是原来的Hive表了，而是预处理后的Hive表。此时由于数据已经预先进行过聚合或join操作了，那么在Spark作业中也就不需要使用原先的shuffle类算子执行这类操作了。</li><li>方案实现原理：这种方案从根源上解决了数据倾斜，因为彻底避免了在Spark中执行shuffle类算子，那么肯定就不会有数据倾斜的问题了。但是这里也要提醒一下大家，这种方式属于治标不治本。因为毕竟数据本身就存在分布不均匀的问题，所以Hive ETL中进行group by或者join等shuffle操作时，还是会出现数据倾斜，导致Hive ETL的速度很慢。我们只是把数据倾斜的发生提前到了Hive ETL中，避免Spark程序发生数据倾斜而已。</li><li>方案优缺点： 
  <ol><li>优点：实现起来简单便捷，效果还非常好，完全规避掉了数据倾斜，Spark作业的性能会大幅度提升。</li><li>缺点：治标不治本，Hive ETL中还是会发生数据倾斜。</li></ol> </li><li>方案实践经验：在一些Java系统与Spark结合使用的项目中，会出现Java代码频繁调用Spark作业的场景，而且对Spark作业的执行性能要求很高，就比较适合使用这种方案。将数据倾斜提前到上游的Hive ETL，每天仅执行一次，只有那一次是比较慢的，而之后每次Java调用Spark作业时，执行速度都会很快，能够提供更好的用户体验。</li></ul> 
<h4><a id="key_4231"></a>过滤少数导致倾斜的key</h4> 
<ul><li>方案适用场景：如果发现导致倾斜的key就少数几个，而且对计算本身的影响并不大的话，那么很适合使用这种方案。比如99%的key就对应10条数据，但是只有一个key对应了100万数据，从而导致了数据倾斜。</li><li>方案实现思路：如果我们判断那少数几个数据量特别多的key，对作业的执行和计算结果不是特别重要的话，那么干脆就直接过滤掉那少数几个key。比如，在Spark SQL中可以使用where子句过滤掉这些key或者在Spark Core中对RDD执行filter算子过滤掉这些key。如果需要每次作业执行时，动态判定哪些key的数据量最多然后再进行过滤，那么可以使用sample算子对RDD进行采样，然后计算出每个key的数量，取数据量最多的key过滤掉即可。</li><li>方案实现原理：将导致数据倾斜的key给过滤掉之后，这些key就不会参与计算了，自然不可能产生数据倾斜。</li><li>方案优缺点： 
  <ol><li>优点：实现简单，而且效果也很好，可以完全规避掉数据倾斜。</li><li>缺点：适用场景不多，大多数情况下，导致倾斜的key还是很多的，并不是只有少数几个。</li></ol> </li></ul> 
<h4><a id="shuffle_4240"></a>提高shuffle操作的并行度</h4> 
<ul><li>方案适用场景：如果我们必须要对数据倾斜迎难而上，那么建议优先使用这种方案，因为这是处理数据倾斜最简单的一种方案。</li><li>方案实现思路：在对RDD执行shuffle算子时，给shuffle算子传入一个参数，比如reduceByKey(1000)，该参数就设置了这个shuffle算子执行时shuffle read task的数量，即spark.sql.shuffle.partitions，该参数代表了shuffle read task的并行度，默认是200，对于很多场景来说都有点过小。</li><li>方案实现原理：增加shuffle read task的数量，可以让原本分配给一个task的多个key分配给多个task，从而让每个task处理比原来更少的数据。举例来说，如果原本有5个key，每个key对应10条数据，这5个key都是分配给一个task的，那么这个task就要处理50条数据。而增加了shuffle read task以后，每个task就分配到一个key，即每个task就处理10条数据，那么自然每个task的执行时间都会变短了。</li><li>方案优缺点： 
  <ol><li>优点：实现起来比较简单，可以有效缓解和减轻数据倾斜的影响。</li><li>缺点：只是缓解了数据倾斜而已，没有彻底根除问题，根据实践经验来看，其效果有限。</li></ol> </li></ul> 
<h4><a id="__4249"></a>双重聚合 （局部聚合+全局聚合）</h4> 
<ul><li>方案适用场景：对RDD执行reduceByKey等聚合类shuffle算子或者在Spark SQL中使用group by语句进行分组聚合时，比较适用这种方案。</li><li>方案实现思路：这个方案的核心实现思路就是进行两阶段聚合：第一次是局部聚合，先给每个key都打上一个随机数，比如10以内的随机数，此时原先一样的key就变成不一样的了，比如(hello, 1) (hello, 1) (hello, 1) (hello, 1)，就会变成(1_hello, 1) (1_hello, 1) (2_hello, 1) (2_hello, 1)。接着对打上随机数后的数据，执行reduceByKey等聚合操作，进行局部聚合，那么局部聚合结果，就会变成了(1_hello, 2) (2_hello, 2)。然后将各个key的前缀给去掉，就会变成(hello,2)(hello,2)，再次进行全局聚合操作，就可以得到最终结果了，比如(hello, 4)。</li><li>方案实现原理：将原本相同的key通过附加随机前缀的方式，变成多个不同的key，就可以让原本被一个task处理的数据分散到多个task上去做局部聚合，进而解决单个task处理数据量过多的问题。接着去除掉随机前缀，再次进行全局聚合，就可以得到最终的结果。具体原理见下图。</li><li>方案优缺点： 
  <ol><li>优点：对于聚合类的shuffle操作导致的数据倾斜，效果是非常不错的。通常都可以解决掉数据倾斜，或者至少是大幅度缓解数据倾斜，将Spark作业的性能提升数倍以上。</li><li>缺点：仅仅适用于聚合类的shuffle操作，适用范围相对较窄。如果是join类的shuffle操作，还得用其他的解决方案。</li></ol> </li></ul> 
<h4><a id="reduce_joinmap_join_4258"></a>将reduce join转为map join</h4> 
<ul><li>方案适用场景：在对RDD使用join类操作，或者是在Spark SQL中使用join语句时，而且join操作中的一个RDD或表的数据量比较小（比如几百M或者一两G），比较适用此方案。</li><li>方案实现思路：不使用join算子进行连接操作，而使用Broadcast变量与map类算子实现join操作，进而完全规避掉shuffle类的操作，彻底避免数据倾斜的发生和出现。将较小RDD中的数据直接通过collect算子拉取到Driver端的内存中来，然后对其创建一个Broadcast变量，广播给其他Executor节点；接着对另外一个RDD执行map类算子，在算子函数内，从Broadcast变量中获取较小RDD的全量数据，与当前RDD的每一条数据按照连接key进行比对，如果连接key相同的话，那么就将两个RDD的数据用你需要的方式连接起来。</li><li>方案实现原理：普通的join是会走shuffle过程的，而一旦shuffle，就相当于会将相同key的数据拉取到一个shuffle read task中再进行join，此时就是reduce join。但是如果一个RDD是比较小的，则可以采用广播小RDD全量数据+map算子来实现与join同样的效果，也就是map join，此时就不会发生shuffle操作，也就不会发生数据倾斜。具体原理如下图所示。</li><li>方案优缺点： 
  <ol><li>优点：对join操作导致的数据倾斜，效果非常好，因为根本就不会发生shuffle，也就根本不会发生数据倾斜。</li><li>缺点：适用场景较少，因为这个方案只适用于一个大表和一个小表的情况。毕竟我们需要将小表进行广播，此时会比较消耗内存资源，driver和每个Executor内存中都会驻留一份小RDD的全量数据。如果我们广播出去的RDD数据比较大，比如10G以上，那么就可能发生内存溢出了。因此并不适合两个都是大表的情况。</li></ol> </li></ul> 
<h4><a id="keyjoin_4267"></a>采样倾斜key并分拆join操作</h4> 
<ul><li>方案适用场景：两个RDD/Hive表进行join的时候，如果数据量都比较大，无法采用“解决方案五”，那么此时可以看一下两个RDD/Hive表中的key分布情况。如果出现数据倾斜，是因为其中某一个RDD/Hive表中的少数几个key的数据量过大，而另一个RDD/Hive表中的所有key都分布比较均匀，那么采用这个解决方案是比较合适的。</li><li>方案实现思路：对包含少数几个数据量过大的key的那个RDD，通过sample算子采样出一份样本来，然后统计一下每个key的数量，计算出来数据量最大的是哪几个key。然后将这几个key对应的数据从原来的RDD中拆分出来，形成一个单独的RDD，并给每个key都打上n以内的随机数作为前缀；而不会导致倾斜的大部分key形成另外一个RDD。接着将需要join的另一个RDD，也过滤出来那几个倾斜key对应的数据并形成一个单独的RDD，将每条数据膨胀成n条数据，这n条数据都按顺序附加一个0~n的前缀；不会导致倾斜的大部分key也形成另外一个RDD。再将附加了随机前缀的独立RDD与另一个膨胀n倍的独立RDD进行join，此时就可以将原先相同的key打散成n份，分散到多个task中去进行join了。而另外两个普通的RDD就照常join即可。最后将两次join的结果使用union算子合并起来即可，就是最终的join结果。</li><li>方案实现原理：对于join导致的数据倾斜，如果只是某几个key导致了倾斜，可以将少数几个key分拆成独立RDD，并附加随机前缀打散成n份去进行join，此时这几个key对应的数据就不会集中在少数几个task上，而是分散到多个task进行join了。具体原理见下图。</li><li>方案优缺点： 
  <ol><li>优点：对于join导致的数据倾斜，如果只是某几个key导致了倾斜，采用该方式可以用最有效的方式打散key进行join。而且只需要针对少数倾斜key对应的数据进行扩容n倍，不需要对全量数据进行扩容。避免了占用过多内存。</li><li>缺点：如果导致倾斜的key特别多的话，比如成千上万个key都导致数据倾斜，那么这种方式也不适合。</li></ol> </li></ul> 
<h4><a id="RDDjoin_4276"></a>使用随机前缀和扩容RDD进行join</h4> 
<ul><li>方案实现思路：该方案的实现思路基本和“解决方案六”类似，首先查看RDD/Hive表中的数据分布情况，找到那个造成数据倾斜的RDD/Hive表，比如有多个key都对应了超过1万条数据。然后将该RDD的每条数据都打上一个n以内的随机前缀。同时对另外一个正常的RDD进行扩容，将每条数据都扩容成n条数据，扩容出来的每条数据都依次打上一个0~n的前缀。最后将两个处理后的RDD进行join即可。</li></ul>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/05245404aa6064a25e1cc4b0e7c808df/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">JavaScript轮播图</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/f2977a0832f36ac4e4c933ff148a5341/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">feign.codec.DecodeException: Could not extract response: no suitable HttpMessageConverter found for</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>