<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【AIGC】Diffusers:加载管道、模型和调度程序 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/2d465c9753d7c1d1ff0943e31e539364/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="【AIGC】Diffusers:加载管道、模型和调度程序">
  <meta property="og:description" content="前言 拥有一种使用扩散系统进行推理的简单方法对于🧨扩散器至关重要。扩散系统通常由多个组件组成，例如参数化模型、分词器和调度器，它们以复杂的方式进行交互。这就是为什么我们设计了 DiffusionPipeline，将整个扩散系统的复杂性包装成一个易于使用的 API，同时保持足够的灵活性以适应其他用例，例如将每个组件单独加载为构建块以组装您自己的扩散系统。
推理或训练所需的一切都可以通过该 from_pretrained() 方法访问。
本指南将向您展示如何加载：
来自中心和本地的管道将不同的组件放入管道中模型变体，例如不同的浮点类型或非指数平均平均 （EMA） 权重模型和调度程序 扩散管线 💡 如果您有兴趣更详细地了解 DiffusionPipeline 类的工作原理，请跳到DiffusionPipeline 说明部分。
DiffusionPipeline 类是从 Hub 加载最新趋势扩散模型的最简单、最通用的方法。DiffusionPipeline.from_pretrained（） 方法自动从检查点检测正确的管道类，下载并缓存所有必需的配置和权重文件，并返回准备进行推理的管道实例。
from diffusers import DiffusionPipeline repo_id = &#34;runwayml/stable-diffusion-v1-5&#34; pipe = DiffusionPipeline.from_pretrained(repo_id, use_safetensors=True) 还可以加载具有特定管道类的检查点。上面的示例加载了一个稳定扩散模型;若要获得相同的结果，请使用 StableDiffusionPipeline 类：
from diffusers import StableDiffusionPipeline repo_id = &#34;runwayml/stable-diffusion-v1-5&#34; pipe = StableDiffusionPipeline.from_pretrained(repo_id, use_safetensors=True) 模型（如 CompVis/stable-diffusion-v1-4 或runwayml/stable-diffusion-v1-5 ）也可以用于多个任务，例如文本到图像或图像到图像。若要区分要将模型用于的任务，必须直接使用其相应的特定于任务的管道类加载它：
from diffusers import StableDiffusionImg2ImgPipeline repo_id = &#34;runwayml/stable-diffusion-v1-5&#34; pipe = StableDiffusionImg2ImgPipeline.from_pretrained(repo_id) 本地管道 若要在本地加载扩散管道，请使用 git-lfs 手动将模型（在本例中为 runwayml/stable-diffusion-v1-5 ）下载到本地磁盘。这会在磁盘上创建一个本地文件夹 ./stable-diffusion-v1-5 ， ：">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-06-01T13:23:55+08:00">
    <meta property="article:modified_time" content="2024-06-01T13:23:55+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【AIGC】Diffusers:加载管道、模型和调度程序</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h3>前言</h3> 
<p>拥有一种使用扩散系统进行推理的简单方法对于🧨扩散器至关重要。扩散系统通常由多个组件组成，例如参数化模型、分词器和调度器，它们以复杂的方式进行交互。这就是为什么我们设计了 DiffusionPipeline，将整个扩散系统的复杂性包装成一个易于使用的 API，同时保持足够的灵活性以适应其他用例，例如将每个组件单独加载为构建块以组装您自己的扩散系统。</p> 
<p>推理或训练所需的一切都可以通过该 <code>from_pretrained()</code> 方法访问。</p> 
<p> 本指南将向您展示如何加载：</p> 
<ul style="margin-left:0;"><li>来自中心和本地的管道</li><li>将不同的组件放入管道中</li><li>模型变体，例如不同的浮点类型或非指数平均平均 （EMA） 权重</li><li>模型和调度程序</li></ul> 
<h3><span style="background-color:#ffffff;">扩散管线</span> </h3> 
<p> 💡 如果您有兴趣更详细地了解 <a class="link-info" href="https://huggingface.co/docs/diffusers/using-diffusers/loading#diffusionpipeline-explained" rel="nofollow" title="DiffusionPipeline">DiffusionPipeline</a> 类的工作原理，请跳到<a class="link-info" href="https://huggingface.co/docs/diffusers/v0.25.1/en/api/pipelines/overview#diffusers.DiffusionPipeline" rel="nofollow" title="DiffusionPipeline">DiffusionPipeline</a> 说明部分。</p> 
<p>DiffusionPipeline 类是从 Hub 加载最新趋势扩散模型的最简单、最通用的方法。DiffusionPipeline.from_pretrained（） 方法自动从检查点检测正确的管道类，下载并缓存所有必需的配置和权重文件，并返回准备进行推理的管道实例。</p> 
<pre><code class="language-python">from diffusers import DiffusionPipeline

repo_id = "runwayml/stable-diffusion-v1-5"
pipe = DiffusionPipeline.from_pretrained(repo_id, use_safetensors=True)</code></pre> 
<p> 还可以加载具有特定管道类的检查点。上面的示例加载了一个稳定扩散模型;若要获得相同的结果，请使用 StableDiffusionPipeline 类：</p> 
<pre><code class="language-python">from diffusers import StableDiffusionPipeline

repo_id = "runwayml/stable-diffusion-v1-5"
pipe = StableDiffusionPipeline.from_pretrained(repo_id, use_safetensors=True)</code></pre> 
<p> 模型（如 <code>CompVis/stable-diffusion-v1-4</code> 或<code>runwayml/stable-diffusion-v1-5</code> ）也可以用于多个任务，例如文本到图像或图像到图像。若要区分要将模型用于的任务，必须直接使用其相应的特定于任务的管道类加载它：</p> 
<pre><code class="language-python">from diffusers import StableDiffusionImg2ImgPipeline

repo_id = "runwayml/stable-diffusion-v1-5"
pipe = StableDiffusionImg2ImgPipeline.from_pretrained(repo_id)</code></pre> 
<h3> <span style="background-color:#ffffff;">本地管道</span></h3> 
<p> 若要在本地加载扩散管道，请使用 <code>git-lfs</code> 手动将模型（在本例中为 <code>runwayml/stable-diffusion-v1-5</code> ）下载到本地磁盘。这会在磁盘上创建一个本地文件夹 <code>./stable-diffusion-v1-5</code> ， ：</p> 
<pre><code class="language-python">git-lfs install
git clone https://huggingface.co/runwayml/stable-diffusion-v1-5</code></pre> 
<p> 然后将本地路径传递给 from_pretrained（）：</p> 
<pre><code class="language-python">from diffusers import DiffusionPipeline

repo_id = "./stable-diffusion-v1-5"
stable_diffusion = DiffusionPipeline.from_pretrained(repo_id, use_safetensors=True)</code></pre> 
<p> 当 from_pretrained（） 方法检测到本地路径时，它不会从 Hub 下载任何文件，但这也意味着它不会下载和缓存检查点的最新更改。</p> 
<h3> <span style="background-color:#ffffff;">在管道中交换组件</span></h3> 
<p> 您可以使用另一个兼容组件自定义任何管道的默认组件。定制很重要，因为：</p> 
<ul style="margin-left:0;"><li>更改调度程序对于探索生成速度和质量之间的权衡非常重要。</li><li>模型的不同组件通常是独立训练的，您可以将组件换成性能更好的组件。</li><li>在微调过程中，通常只训练某些组件（如 UNet 或文本编码器）。</li></ul> 
<p> 若要找出哪些计划程序与自定义兼容，可以使用以下 <code>compatibles</code> 方法：</p> 
<pre><code class="language-python">from diffusers import DiffusionPipeline

repo_id = "runwayml/stable-diffusion-v1-5"
stable_diffusion = DiffusionPipeline.from_pretrained(repo_id, use_safetensors=True)
stable_diffusion.scheduler.compatibles</code></pre> 
<p>让我们使用 SchedulerMixin.from_pretrained（） 方法将默认的 PNDMScheduler 替换为性能更高的调度器 EulerDiscreteScheduler。从管道存储库的正确子文件夹加载调度程序配置需要该 <code>subfolder="scheduler"</code> 参数。</p> 
<p>然后，您可以将新的 EulerDiscreteScheduler 实例传递给 DiffusionPipeline 中的 <code>scheduler</code> 参数：</p> 
<pre><code class="language-python">from diffusers import DiffusionPipeline, EulerDiscreteScheduler

repo_id = "runwayml/stable-diffusion-v1-5"
scheduler = EulerDiscreteScheduler.from_pretrained(repo_id, subfolder="scheduler")
stable_diffusion = DiffusionPipeline.from_pretrained(repo_id, scheduler=scheduler, use_safetensors=True)</code></pre> 
<h3 style="margin-left:0px;"><span style="background-color:#ffffff;">安全检查器</span></h3> 
<p> 像 Stable Diffusion 这样的扩散模型可能会产生有害内容，这就是为什么 🧨 Diffusers 有一个安全检查器来检查生成的输出是否符合已知的硬编码 NSFW 内容。如果您出于任何原因想要禁用安全检查器，请传递 <code>None</code> <code>safety_checker</code> 参数：</p> 
<pre><code class="language-python">from diffusers import DiffusionPipeline

repo_id = "runwayml/stable-diffusion-v1-5"
stable_diffusion = DiffusionPipeline.from_pretrained(repo_id, safety_checker=None, use_safetensors=True)
"""
You have disabled the safety checker for &lt;class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'&gt; by passing `safety_checker=None`. Ensure that you abide by the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend keeping the safety filter enabled in all public-facing circumstances, disabling it only for use cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .
"""</code></pre> 
<h3> <span style="background-color:#ffffff;">跨管道重用组件</span></h3> 
<p>您还可以在多个管道中重复使用相同的组件，以避免两次将权重加载到 RAM 中。使用 components 方法保存组件： </p> 
<pre><code class="language-python">from diffusers import StableDiffusionPipeline, StableDiffusionImg2ImgPipeline

model_id = "runwayml/stable-diffusion-v1-5"
stable_diffusion_txt2img = StableDiffusionPipeline.from_pretrained(model_id, use_safetensors=True)

components = stable_diffusion_txt2img.components</code></pre> 
<p> 然后，您可以将其 <code>components</code> 传递到另一个管道，而无需将权重重新加载到 RAM 中：</p> 
<pre><code class="language-python">stable_diffusion_img2img = StableDiffusionImg2ImgPipeline(**components)</code></pre> 
<p>如果希望更灵活地重用或禁用哪些组件，还可以将组件单独传递到管道。例如，若要在图像到图像管道中重用文本到图像管道中的相同组件，但安全检查器和特征提取器除外：</p> 
<pre><code class="language-python">from diffusers import StableDiffusionPipeline, StableDiffusionImg2ImgPipeline

model_id = "runwayml/stable-diffusion-v1-5"
stable_diffusion_txt2img = StableDiffusionPipeline.from_pretrained(model_id, use_safetensors=True)
stable_diffusion_img2img = StableDiffusionImg2ImgPipeline(
    vae=stable_diffusion_txt2img.vae,
    text_encoder=stable_diffusion_txt2img.text_encoder,
    tokenizer=stable_diffusion_txt2img.tokenizer,
    unet=stable_diffusion_txt2img.unet,
    scheduler=stable_diffusion_txt2img.scheduler,
    safety_checker=None,
    feature_extractor=None,
    requires_safety_checker=False,
)</code></pre> 
<h3 style="margin-left:0;"><span style="background-color:#ffffff;">模型权重变体</span></h3> 
<p> 以不同的浮点类型存储，以实现较低的精度和较低的存储，例如 <code>torch.float16</code> ，因为它只需要一半的带宽和存储即可下载。如果您正在继续训练或使用 CPU，则无法使用此变体。</p> 
<p><span style="color:#956fe7;"><strong>非指数平均 （EMA） 权重，不应用于推理</strong></span>。您应该<span style="color:#fe2c24;"><strong>使用它们来继续微调模型</strong></span>。 </p> 
<blockquote> 
 <p> 💡 当检查点具有相同的模型结构，但它们是在不同的数据集上训练的，并且使用不同的训练设置时，它们应该存储在单独的存储库中，而不是变体（例如， <code>stable-diffusion-v1-4</code> 和 <code>stable-diffusion-v1-5</code> ）。</p> 
</blockquote> 
<p> 否则，变体与原模型相同。它们具有完全相同的序列化格式（如 Safetensors）、模型结构和具有相同张量形状的权重。</p> 
<table cellspacing="0" style="width:627.333px;"><thead><tr><th style="border-color:#e5e7eb;vertical-align:bottom;"><strong>checkpoint type 检查点类型</strong></th><th style="border-color:#e5e7eb;vertical-align:bottom;"><strong>weight name 重量名称</strong></th><th style="border-color:#e5e7eb;vertical-align:bottom;"><strong>argument for loading weights<br> 加载砝码的参数</strong></th></tr></thead><tbody><tr><td style="background-color:#ffffff;border-color:#e5e7eb;vertical-align:baseline;">original 源语言</td><td style="background-color:#ffffff;border-color:#e5e7eb;vertical-align:baseline;">diffusion_pytorch_model.bin</td><td style="background-color:#ffffff;border-color:#e5e7eb;vertical-align:baseline;"></td></tr><tr><td style="background-color:#ffffff;border-color:#e5e7eb;vertical-align:baseline;">floating point 浮点</td><td style="background-color:#ffffff;border-color:#e5e7eb;vertical-align:baseline;">diffusion_pytorch_model.fp16.bin</td><td style="background-color:#ffffff;border-color:#e5e7eb;vertical-align:baseline;"><code>variant</code>, <code>torch_dtype</code></td></tr><tr><td style="background-color:#ffffff;border-color:#e5e7eb;vertical-align:baseline;">non-EMA 非 EMA</td><td style="background-color:#ffffff;border-color:#e5e7eb;vertical-align:baseline;">diffusion_pytorch_model.non_ema.bin</td><td style="background-color:#ffffff;border-color:#e5e7eb;vertical-align:baseline;"><code>variant</code></td></tr></tbody></table> 
<p> 对于加载变体，有两个重要的参数需要了解：</p> 
<p></p> 
<ul style="margin-left:0;"><li> <p style="margin-left:0;"><span style="color:#fe2c24;"><strong><code>torch_dtype</code></strong></span> 定义加载的检查点的浮点精度。例如，如果要通过加载 <code>fp16</code> 变体来节省带宽，则应指定 <code>torch_dtype=torch.float16</code> 将权重转换为 <code>fp16</code> 。否则， <code>fp16</code> 权重将转换为默认 <code>fp32</code> 精度。您也可以在不定义 <code>variant</code> 参数的情况下加载原始检查点，并将其转换为 <code>fp16</code> with <code>torch_dtype=torch.float16</code> .在这种情况下，将首先下载默认 <code>fp32</code> 权重，然后在加载后将其 <code>fp16</code> 转换为默认权重。</p> </li><li> <p style="margin-left:0;"><span style="color:#fe2c24;"><strong><code>variant</code></strong></span> 定义应从存储库加载哪些文件。例如，如果要从存储库加载 <code>non_ema</code> 变体，则应指定 <code>variant="non_ema"</code> 下载 <code>non_ema</code> <code>diffusers/stable-diffusion-variants</code> 文件。</p> </li></ul> 
<pre><code class="language-python">from diffusers import DiffusionPipeline
import torch

# load fp16 variant
stable_diffusion = DiffusionPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5", variant="fp16", torch_dtype=torch.float16, use_safetensors=True
)
# load non_ema variant
stable_diffusion = DiffusionPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5", variant="non_ema", use_safetensors=True
)</code></pre> 
<p>若要将存储在不同浮点类型中的检查点保存为非 EMA 变体，请使用 DiffusionPipeline.save_pretrained（） 方法并指定 <code>variant</code> 参数。您应该尝试将变体保存到与原始检查点相同的文件夹中，以便您可以从同一文件夹加载两者：</p> 
<pre><code class="language-python">from diffusers import DiffusionPipeline

# save as fp16 variant
stable_diffusion.save_pretrained("runwayml/stable-diffusion-v1-5", variant="fp16")
# save as non-ema variant
stable_diffusion.save_pretrained("runwayml/stable-diffusion-v1-5", variant="non_ema")</code></pre> 
<p>如果不将变体保存到现有文件夹，则必须指定参数， <code>variant</code> 否则它将抛出一个 <code>Exception</code> ，因为它找不到原始检查点：</p> 
<pre><code class="language-python"># 👎 this won't work
stable_diffusion = DiffusionPipeline.from_pretrained(
    "./stable-diffusion-v1-5", torch_dtype=torch.float16, use_safetensors=True
)
# 👍 this works
stable_diffusion = DiffusionPipeline.from_pretrained(
    "./stable-diffusion-v1-5", variant="fp16", torch_dtype=torch.float16, use_safetensors=True
)</code></pre> 
<h3 style="margin-left:0;"><span style="background-color:#ffffff;">模型</span></h3> 
<p> 模型从<span style="color:#956fe7;"><strong> ModelMixin.from_pretrained（） </strong></span>方法加载，该方法下载并缓存最新版本的模型权重和配置。如果本地缓存中有最新的文件，<span style="color:#fe2c24;"><strong>则 from_pretrained（） 会重用缓存中的文件，而不是重新下载它们。</strong></span></p> 
<p> 可以从带有参数的 <code>subfolder</code> 子文件夹加载模型。例如，模型权重 <code>runwayml/stable-diffusion-v1-5</code> 存储在 <code>unet</code> 子文件夹中：</p> 
<pre><code class="language-python">from diffusers import UNet2DConditionModel

repo_id = "runwayml/stable-diffusion-v1-5"
model = UNet2DConditionModel.from_pretrained(repo_id, subfolder="unet", use_safetensors=True)</code></pre> 
<p>或者<span style="color:#fe2c24;"><strong>直接从存储库的目录</strong></span>：</p> 
<pre><code class="language-python">from diffusers import UNet2DModel

repo_id = "google/ddpm-cifar10-32"
model = UNet2DModel.from_pretrained(repo_id, use_safetensors=True)</code></pre> 
<p>您还可以通过在 ModelMixin.from_pretrained（） 和 ModelMixin.save_pretrained（） 中指定 <code>variant</code> 参数来加载和保存模型变体：</p> 
<pre><code class="language-python">from diffusers import UNet2DConditionModel

model = UNet2DConditionModel.from_pretrained(
    "runwayml/stable-diffusion-v1-5", subfolder="unet", variant="non_ema", use_safetensors=True
)
model.save_pretrained("./local-unet", variant="non_ema")</code></pre> 
<h3 style="margin-left:0;"><span style="background-color:#ffffff;"> 调度程序</span></h3> 
<p>调度器是从 <span style="color:#fe2c24;"><strong>SchedulerMixin.from_pretrained（）</strong></span> 方法加载的，与模型不同，调度器没有参数化或训练;它们由配置文件定义。 </p> 
<p>加载调度程序不会消耗任何大量内存，并且相同的配置文件可用于各种不同的调度程序。例如，以下调度程序与 StableDiffusionPipeline 兼容，这意味着您可以在以下任何类中加载相同的调度程序配置文件： </p> 
<pre><code class="language-python">from diffusers import StableDiffusionPipeline
from diffusers import (
    DDPMScheduler,
    DDIMScheduler,
    PNDMScheduler,
    LMSDiscreteScheduler,
    EulerAncestralDiscreteScheduler,
    EulerDiscreteScheduler,
    DPMSolverMultistepScheduler,
)

repo_id = "runwayml/stable-diffusion-v1-5"

ddpm = DDPMScheduler.from_pretrained(repo_id, subfolder="scheduler")
ddim = DDIMScheduler.from_pretrained(repo_id, subfolder="scheduler")
pndm = PNDMScheduler.from_pretrained(repo_id, subfolder="scheduler")
lms = LMSDiscreteScheduler.from_pretrained(repo_id, subfolder="scheduler")
euler_anc = EulerAncestralDiscreteScheduler.from_pretrained(repo_id, subfolder="scheduler")
euler = EulerDiscreteScheduler.from_pretrained(repo_id, subfolder="scheduler")
dpm = DPMSolverMultistepScheduler.from_pretrained(repo_id, subfolder="scheduler")

# replace `dpm` with any of `ddpm`, `ddim`, `pndm`, `lms`, `euler_anc`, `euler`
pipeline = StableDiffusionPipeline.from_pretrained(repo_id, scheduler=dpm, use_safetensors=True)</code></pre> 
<h3 style="margin-left:0;"><span style="background-color:#ffffff;">DiffusionPipeline 解释</span></h3> 
<p> 作为类方法，DiffusionPipeline.from_pretrained（） 负责两件事：</p> 
<ul style="margin-left:0;"><li>下载推理所需的最新版本的文件夹结构并对其进行缓存。如果本地缓存中提供了最新的文件夹结构，则 DiffusionPipeline.from_pretrained（） 会重用缓存，并且不会重新下载文件。</li><li>将缓存的权重加载到正确的管道类（从文件中 <code>model_index.json</code> 检索），并返回该类的实例。</li></ul> 
<p> 管道的基础文件夹结构与其类实例直接对应。例如，StableDiffusionPipeline 对应于 <code>runwayml/stable-diffusion-v1-5</code> 中的文件夹结构。</p> 
<pre><code class="language-python">from diffusers import DiffusionPipeline

repo_id = "runwayml/stable-diffusion-v1-5"
pipeline = DiffusionPipeline.from_pretrained(repo_id, use_safetensors=True)
print(pipeline)</code></pre> 
<p> 你将看到 pipeline 是 StableDiffusionPipeline 的一个实例，它由七个组件组成：</p> 
<p></p> 
<ul style="margin-left:0;"><li><code>"feature_extractor"</code> ：来自 Transformer 的 🤗 CLIPImageProcessor。</li><li><code>"safety_checker"</code> ：用于筛选有害内容的组件。</li><li><code>"scheduler"</code> ：PNDMScheduler 的实例。</li><li><code>"text_encoder"</code> ：来自 Transformer 的 🤗 CLIPTextModel。</li><li><code>"tokenizer"</code> ：来自Transformer的 🤗 CLIPTokenizer。</li><li><code>"unet"</code> ：UNet2DConditionModel 的实例。</li><li><code>"vae"</code> ：AutoencoderKL 的实例。</li></ul> 
<pre><code class="language-python">StableDiffusionPipeline {
  "feature_extractor": [
    "transformers",
    "CLIPImageProcessor"
  ],
  "safety_checker": [
    "stable_diffusion",
    "StableDiffusionSafetyChecker"
  ],
  "scheduler": [
    "diffusers",
    "PNDMScheduler"
  ],
  "text_encoder": [
    "transformers",
    "CLIPTextModel"
  ],
  "tokenizer": [
    "transformers",
    "CLIPTokenizer"
  ],
  "unet": [
    "diffusers",
    "UNet2DConditionModel"
  ],
  "vae": [
    "diffusers",
    "AutoencoderKL"
  ]
}</code></pre> 
<p>将管道实例的组件与文件夹结构进行比较，你将看到存储库中的每个组件都有一个单独的 <code>runwayml/stable-diffusion-v1-5</code> 文件夹：</p> 
<pre><code class="language-python">.
├── feature_extractor
│   └── preprocessor_config.json
├── model_index.json
├── safety_checker
│   ├── config.json
|   ├── model.fp16.safetensors
│   ├── model.safetensors
│   ├── pytorch_model.bin
|   └── pytorch_model.fp16.bin
├── scheduler
│   └── scheduler_config.json
├── text_encoder
│   ├── config.json
|   ├── model.fp16.safetensors
│   ├── model.safetensors
│   |── pytorch_model.bin
|   └── pytorch_model.fp16.bin
├── tokenizer
│   ├── merges.txt
│   ├── special_tokens_map.json
│   ├── tokenizer_config.json
│   └── vocab.json
├── unet
│   ├── config.json
│   ├── diffusion_pytorch_model.bin
|   |── diffusion_pytorch_model.fp16.bin
│   |── diffusion_pytorch_model.f16.safetensors
│   |── diffusion_pytorch_model.non_ema.bin
│   |── diffusion_pytorch_model.non_ema.safetensors
│   └── diffusion_pytorch_model.safetensors
|── vae
.   ├── config.json
.   ├── diffusion_pytorch_model.bin
    ├── diffusion_pytorch_model.fp16.bin
    ├── diffusion_pytorch_model.fp16.safetensors
    └── diffusion_pytorch_model.safetensors</code></pre> 
<p>您可以将管道的每个组件作为属性进行访问，以查看其配置：</p> 
<pre><code class="language-python">pipeline.tokenizer
CLIPTokenizer(
    name_or_path="/root/.cache/huggingface/hub/models--runwayml--stable-diffusion-v1-5/snapshots/39593d5650112b4cc580433f6b0435385882d819/tokenizer",
    vocab_size=49408,
    model_max_length=77,
    is_fast=False,
    padding_side="right",
    truncation_side="right",
    special_tokens={
        "bos_token": AddedToken("&lt;|startoftext|&gt;", rstrip=False, lstrip=False, single_word=False, normalized=True),
        "eos_token": AddedToken("&lt;|endoftext|&gt;", rstrip=False, lstrip=False, single_word=False, normalized=True),
        "unk_token": AddedToken("&lt;|endoftext|&gt;", rstrip=False, lstrip=False, single_word=False, normalized=True),
        "pad_token": "&lt;|endoftext|&gt;",
    },
    clean_up_tokenization_spaces=True
)</code></pre> 
<p>每个管道都需要一个 <code>model_index.json</code> 文件，该文件告诉 DiffusionPipeline：</p> 
<ul style="margin-left:0;"><li>要从 <code>_class_name</code> 哪个管道类加载</li><li>哪个版本的🧨扩散器用于创建模型 <code>_diffusers_version</code></li></ul> 
<pre><code class="language-python">{
  "_class_name": "StableDiffusionPipeline",
  "_diffusers_version": "0.6.0",
  "feature_extractor": [
    "transformers",
    "CLIPImageProcessor"
  ],
  "safety_checker": [
    "stable_diffusion",
    "StableDiffusionSafetyChecker"
  ],
  "scheduler": [
    "diffusers",
    "PNDMScheduler"
  ],
  "text_encoder": [
    "transformers",
    "CLIPTextModel"
  ],
  "tokenizer": [
    "transformers",
    "CLIPTokenizer"
  ],
  "unet": [
    "diffusers",
    "UNet2DConditionModel"
  ],
  "vae": [
    "diffusers",
    "AutoencoderKL"
  ]
}</code></pre> 
<p>参考链接：</p> 
<p> <a href="https://huggingface.co/docs/diffusers/using-diffusers/loading" rel="nofollow" title="https://huggingface.co/docs/diffusers/using-diffusers/loading">https://huggingface.co/docs/diffusers/using-diffusers/loading</a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/0cdae027aa1dae7d5fffb4faf40c5839/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">通俗易懂-＞哈希表详解</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/5895c58f1633e40793ede394c3811367/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">LeetCode/NowCoder-栈和队列OJ练习</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>