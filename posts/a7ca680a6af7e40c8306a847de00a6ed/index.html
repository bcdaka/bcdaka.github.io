<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【大模型从入门到精通15】openAI API 构建和评估大型语言模型（LLM）应用3 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/a7ca680a6af7e40c8306a847de00a6ed/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="【大模型从入门到精通15】openAI API 构建和评估大型语言模型（LLM）应用3">
  <meta property="og:description" content="这里写目录标题 设置评估前的准备工作先决条件获取LLM响应 根据评估标准评估响应构建详细的评估标准评估过程示例评估 设置评估前的准备工作 先决条件 在开始评估过程之前，请确保必要的工具和配置已经到位：
import os import openai from dotenv import load_dotenv # 从 .env 文件加载 OpenAI API 密钥 load_dotenv() openai.api_key = os.environ.get(&#39;OPENAI_API_KEY&#39;) 获取LLM响应 为了评估LLM的表现，首先需要根据用户的查询获取一个响应：
def fetch_llm_response(prompts, model=&#34;gpt-3.5-turbo&#34;, temperature=0, max_tokens=500): &#34;&#34;&#34; 根据一系列提示从LLM获取响应。 参数: prompts (list): 消息字典列表，其中每条消息都有一个&#39;role&#39;（系统或用户）和&#39;content&#39;。 model (str): 要使用的LLM模型标识符。 temperature (float): 控制输出的随机性，0是最确定性的。 max_tokens (int): 响应中的最大令牌数。 返回: str: LLM响应的内容。 &#34;&#34;&#34; response = openai.ChatCompletion.create( model=model, messages=prompts, temperature=temperature, max_tokens=max_tokens ) return response.choices[0].message[&#34;content&#34;] 根据评估标准评估响应 构建详细的评估标准 评估标准作为评估LLM答案的指南，关注以下几个关键方面：
上下文相关性和事实准确性回答的完整性文本的连贯性和语法正确性 评估过程 在获取到LLM对查询的响应后，继续根据评估标准对其进行评估：
def evaluate_response_against_detailed_rubric(test_data, llm_response): &#34;">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-08-09T19:49:38+08:00">
    <meta property="article:modified_time" content="2024-08-09T19:49:38+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【大模型从入门到精通15】openAI API 构建和评估大型语言模型（LLM）应用3</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>这里写目录标题</h4> 
 <ul><li><ul><li><ul><li><a href="#_3" rel="nofollow">设置评估前的准备工作</a></li><li><ul><li><a href="#_4" rel="nofollow">先决条件</a></li><li><a href="#LLM_17" rel="nofollow">获取LLM响应</a></li></ul> 
    </li><li><a href="#_43" rel="nofollow">根据评估标准评估响应</a></li><li><ul><li><a href="#_44" rel="nofollow">构建详细的评估标准</a></li><li><a href="#_51" rel="nofollow">评估过程</a></li><li><a href="#_129" rel="nofollow">示例评估</a></li></ul> 
   </li></ul> 
  </li></ul> 
 </li></ul> 
</div> 
<br> 
<img src="https://images2.imgbox.com/b1/f1/kDF5z4m1_o.jpg" alt="在这里插入图片描述"> 
<p></p> 
<h4><a id="_3"></a>设置评估前的准备工作</h4> 
<h5><a id="_4"></a>先决条件</h5> 
<p>在开始评估过程之前，请确保必要的工具和配置已经到位：</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> os
<span class="token keyword">import</span> openai
<span class="token keyword">from</span> dotenv <span class="token keyword">import</span> load_dotenv

<span class="token comment"># 从 .env 文件加载 OpenAI API 密钥</span>
load_dotenv<span class="token punctuation">(</span><span class="token punctuation">)</span>
openai<span class="token punctuation">.</span>api_key <span class="token operator">=</span> os<span class="token punctuation">.</span>environ<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'OPENAI_API_KEY'</span><span class="token punctuation">)</span>
</code></pre> 
<h5><a id="LLM_17"></a>获取LLM响应</h5> 
<p>为了评估LLM的表现，首先需要根据用户的查询获取一个响应：</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">fetch_llm_response</span><span class="token punctuation">(</span>prompts<span class="token punctuation">,</span> model<span class="token operator">=</span><span class="token string">"gpt-3.5-turbo"</span><span class="token punctuation">,</span> temperature<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> max_tokens<span class="token operator">=</span><span class="token number">500</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    根据一系列提示从LLM获取响应。

    参数:
        prompts (list): 消息字典列表，其中每条消息都有一个'role'（系统或用户）和'content'。
        model (str): 要使用的LLM模型标识符。
        temperature (float): 控制输出的随机性，0是最确定性的。
        max_tokens (int): 响应中的最大令牌数。

    返回:
        str: LLM响应的内容。
    """</span>
    response <span class="token operator">=</span> openai<span class="token punctuation">.</span>ChatCompletion<span class="token punctuation">.</span>create<span class="token punctuation">(</span>
        model<span class="token operator">=</span>model<span class="token punctuation">,</span>
        messages<span class="token operator">=</span>prompts<span class="token punctuation">,</span>
        temperature<span class="token operator">=</span>temperature<span class="token punctuation">,</span> 
        max_tokens<span class="token operator">=</span>max_tokens
    <span class="token punctuation">)</span>
    <span class="token keyword">return</span> response<span class="token punctuation">.</span>choices<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>message<span class="token punctuation">[</span><span class="token string">"content"</span><span class="token punctuation">]</span>
</code></pre> 
<h4><a id="_43"></a>根据评估标准评估响应</h4> 
<h5><a id="_44"></a>构建详细的评估标准</h5> 
<p>评估标准作为评估LLM答案的指南，关注以下几个关键方面：</p> 
<ul><li>上下文相关性和事实准确性</li><li>回答的完整性</li><li>文本的连贯性和语法正确性</li></ul> 
<h5><a id="_51"></a>评估过程</h5> 
<p>在获取到LLM对查询的响应后，继续根据评估标准对其进行评估：</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">evaluate_response_against_detailed_rubric</span><span class="token punctuation">(</span>test_data<span class="token punctuation">,</span> llm_response<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    根据详细的评估标准评估LLM的响应，考虑响应的各种方面，包括准确性、相关性和完整性，
    基于提供的测试数据。该函数旨在通过在多个标准上给响应打分并提供行动建议的反馈来提供细致的评估。

    参数:
        test_data (dict): 包含'customer_query'（客户查询）、'context'（背景信息）以及可选的
                          'expected_answers'（预期答案），以便进行更细致的评估。
        llm_response (str): LLM对客户查询生成的响应。

    返回:
        dict: 包含总评分、按标准评分及详细反馈的字典。
    """</span>
    <span class="token comment"># 定义评估标准及其初始化分数</span>
    rubric_criteria <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
        <span class="token string">'accuracy'</span><span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">'weight'</span><span class="token punctuation">:</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token string">'score'</span><span class="token punctuation">:</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token string">'feedback'</span><span class="token punctuation">:</span> <span class="token string">''</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
        <span class="token string">'relevance'</span><span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">'weight'</span><span class="token punctuation">:</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token string">'score'</span><span class="token punctuation">:</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token string">'feedback'</span><span class="token punctuation">:</span> <span class="token string">''</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
        <span class="token string">'completeness'</span><span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">'weight'</span><span class="token punctuation">:</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token string">'score'</span><span class="token punctuation">:</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token string">'feedback'</span><span class="token punctuation">:</span> <span class="token string">''</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
        <span class="token string">'coherence'</span><span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">'weight'</span><span class="token punctuation">:</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token string">'score'</span><span class="token punctuation">:</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token string">'feedback'</span><span class="token punctuation">:</span> <span class="token string">''</span><span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
    total_weight <span class="token operator">=</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>criterion<span class="token punctuation">[</span><span class="token string">'weight'</span><span class="token punctuation">]</span> <span class="token keyword">for</span> criterion <span class="token keyword">in</span> rubric_criteria<span class="token punctuation">.</span>values<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment"># 构建评估提示</span>
    system_prompt <span class="token operator">=</span> <span class="token string">"根据提供的背景信息评价客服代表的回答。"</span>
    evaluation_prompt <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f"""\
    [问题]: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>test_data<span class="token punctuation">[</span><span class="token string">'customer_query'</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">
    [背景]: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>test_data<span class="token punctuation">[</span><span class="token string">'context'</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">
    [预期答案]: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>test_data<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'expected_answers'</span><span class="token punctuation">,</span> <span class="token string">'N/A'</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">
    [LLM回答]: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>llm_response<span class="token punctuation">}</span></span><span class="token string">

    根据准确性、与问题的相关性、所提供信息的完整性以及文本的连贯性评估回答。
    对每个标准给出评分（0-10）及任何具体的反馈。
    """</span></span>

    <span class="token comment"># 假设有一个函数 fetch_llm_evaluation 来处理评估过程</span>
    evaluation_results <span class="token operator">=</span> fetch_llm_evaluation<span class="token punctuation">(</span>system_prompt<span class="token punctuation">,</span> evaluation_prompt<span class="token punctuation">)</span>

    <span class="token comment"># 解析评估结果以填充评估标准的分数和反馈</span>
    <span class="token comment"># 这一步骤假设评估结果是以某种方式结构化，可以被程序化解析</span>
    <span class="token comment"># 例如，在文本中使用预定义的格式或标记</span>
    parse_evaluation_results<span class="token punctuation">(</span>evaluation_results<span class="token punctuation">,</span> rubric_criteria<span class="token punctuation">)</span>

    <span class="token comment"># 根据各标准分数的加权平均值计算总评分</span>
    overall_score <span class="token operator">=</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>criterion<span class="token punctuation">[</span><span class="token string">'score'</span><span class="token punctuation">]</span> <span class="token operator">*</span> criterion<span class="token punctuation">[</span><span class="token string">'weight'</span><span class="token punctuation">]</span> <span class="token keyword">for</span> criterion <span class="token keyword">in</span> rubric_criteria<span class="token punctuation">.</span>values<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> total_weight

    <span class="token comment"># 编译详细的反馈和分数</span>
    detailed_feedback <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>criteria<span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">'score'</span><span class="token punctuation">:</span> rubric_criteria<span class="token punctuation">[</span>criteria<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'score'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'feedback'</span><span class="token punctuation">:</span> rubric_criteria<span class="token punctuation">[</span>criteria<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'feedback'</span><span class="token punctuation">]</span><span class="token punctuation">}</span> <span class="token keyword">for</span> criteria <span class="token keyword">in</span> rubric_criteria<span class="token punctuation">}</span>

    <span class="token keyword">return</span> <span class="token punctuation">{<!-- --></span>
        <span class="token string">'overall_score'</span><span class="token punctuation">:</span> overall_score<span class="token punctuation">,</span>
        <span class="token string">'detailed_scores'</span><span class="token punctuation">:</span> detailed_feedback
    <span class="token punctuation">}</span>

<span class="token keyword">def</span> <span class="token function">fetch_llm_evaluation</span><span class="token punctuation">(</span>system_prompt<span class="token punctuation">,</span> evaluation_prompt<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    模拟获取基于LLM的评估。该函数通常会向LLM服务发送带有评估提示的请求并返回LLM的响应以供处理。
    """</span>
    <span class="token comment"># 占位符，代表调用LLM</span>
    <span class="token keyword">return</span> <span class="token string">"模拟LLM响应"</span>

<span class="token keyword">def</span> <span class="token function">parse_evaluation_results</span><span class="token punctuation">(</span>evaluation_text<span class="token punctuation">,</span> rubric_criteria<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    解析LLM返回的评估文本，并提取每个标准的分数和反馈，更新rubric_criteria字典。

    参数:
        evaluation_text (str): LLM响应中包含的评估分数和反馈的文本。
        rubric_criteria (dict): 要用分数和反馈更新的评估标准字典。
    """</span>
    <span class="token comment"># 示例解析逻辑，需要替换为实际解析LLM响应的代码</span>
    <span class="token keyword">for</span> criteria <span class="token keyword">in</span> rubric_criteria<span class="token punctuation">:</span>
        rubric_criteria<span class="token punctuation">[</span>criteria<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'score'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">8</span>  <span class="token comment"># 示例分数</span>
        rubric_criteria<span class="token punctuation">[</span>criteria<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'feedback'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">"在这方面做得不错。"</span>  <span class="token comment"># 示例反馈</span>
</code></pre> 
<h5><a id="_129"></a>示例评估</h5> 
<p>使用<code>evaluate_response_against_detailed_rubric</code>函数对一个响应进行评估，以了解它与提供的上下文的匹配程度以及信息的准确性。</p> 
<p>这里我们没有实际的测试数据和LLM响应，因此我们将创建一些示例数据来展示如何使用上述函数：</p> 
<pre><code class="prism language-python"><span class="token comment"># 示例测试数据</span>
test_data <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token string">'customer_query'</span><span class="token punctuation">:</span> <span class="token string">'我想知道如何重置我的账户密码。'</span><span class="token punctuation">,</span>
    <span class="token string">'context'</span><span class="token punctuation">:</span> <span class="token string">'这是一个在线购物平台，客户需要帮助重置密码。'</span><span class="token punctuation">,</span>
    <span class="token string">'expected_answers'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'请访问我们的帮助中心并遵循重置密码的步骤。'</span><span class="token punctuation">]</span>
<span class="token punctuation">}</span>

<span class="token comment"># 获取LLM响应</span>
prompts <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token punctuation">{<!-- --></span><span class="token string">'role'</span><span class="token punctuation">:</span> <span class="token string">'system'</span><span class="token punctuation">,</span> <span class="token string">'content'</span><span class="token punctuation">:</span> <span class="token string">'你是一位客服代表。'</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{<!-- --></span><span class="token string">'role'</span><span class="token punctuation">:</span> <span class="token string">'user'</span><span class="token punctuation">,</span> <span class="token string">'content'</span><span class="token punctuation">:</span> test_data<span class="token punctuation">[</span><span class="token string">'customer_query'</span><span class="token punctuation">]</span><span class="token punctuation">}</span>
<span class="token punctuation">]</span>
llm_response <span class="token operator">=</span> fetch_llm_response<span class="token punctuation">(</span>prompts<span class="token punctuation">)</span>

<span class="token comment"># 评估LLM响应</span>
evaluation_result <span class="token operator">=</span> evaluate_response_against_detailed_rubric<span class="token punctuation">(</span>test_data<span class="token punctuation">,</span> llm_response<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>evaluation_result<span class="token punctuation">)</span>
</code></pre> 
<p>请注意，<code>fetch_llm_evaluation</code> 和 <code>parse_evaluation_results</code> 函数中的逻辑需要根据实际情况进行调整，以便能够正确解析LLM的响应并提取分数和反馈。以上代码示例仅供参考，实际应用中需要根据具体情况调整和完善。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/dc939bd9ca959317d730a3f71fb628e0/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">UniTouch：开创性的多模态触觉模型引领零样本学习新时代</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/67609f7dcd23f04c98b3106e2fd86332/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">二进制与其他进制整数部分的相互转换、原码、反码、补码</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>