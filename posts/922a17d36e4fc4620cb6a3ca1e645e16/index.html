<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>AI 挑战周杰伦？Suno 全新功能面世，即兴哼几句就能创作成歌，还能模仿声音！... - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/922a17d36e4fc4620cb6a3ca1e645e16/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="AI 挑战周杰伦？Suno 全新功能面世，即兴哼几句就能创作成歌，还能模仿声音！...">
  <meta property="og:description" content="作者 | 王启隆
出品丨AI 科技大本营（ID：rgznai100）
2016 年，周杰伦根据女儿 Hathaway 在玩具钢琴上随意弹出的几个音符，激发出创作的灵感，谱写了一首温馨而深情的歌曲——《前世情人》。8 年过去，音乐创作逐步进入了 AI 时代，先前爆火出圈的音乐创作 AI 平台「Suno」在近日预热，未来将发布一项新功能：Sound-to-Song。意思是：用任何声音创作新歌曲（make a new song from any sound）。
即使你不像周杰伦一样拥有“绝对音感”，也不懂什么乐理与和弦，只需要哼唱一小段，Suno AI 就可以在你哼唱的基础上创作出完整的歌曲。下面便是 Suno 日前发布的第一波预热演示视频：《用喷壶演奏“迷幻摇滚”》。
某种意义上，这和 ChatGPT 推出的“语音输入”交互方式有异曲同工之妙，声音识别和语音识别如今已是各大 AI 产品的必备技术，比如说，我们基本可以在国产 AI App 使用聊天框旁边的说话功能：
但在音乐的世界，我们不需要像制作人一样苦口婆心地用对话的交互方式来教导 AI 怎么作曲，而是采用更简单的交互：直接唱出来。
这种创新的作曲方式将使用户能够把“声音采样”与“文字提示”结合起来，创作出独一无二的音乐作品。以前使用 Suno 作曲，可能还需要构思一下怎么写 Prompt 才能让 AI 明白你脑内的灵感；但现在，任何日常的声音，如 Suno 官方演示中喷壶敲击金属管的声音，都能转换成迷人的迷幻摇滚乐曲。
除了“喷壶摇滚”以外，Suno 还派出自家的工程师 Anessa 亲自演奏钢琴，并让 Suno AI 转化为完整的一首歌：
Suno 不仅将 Anessa 弹的这段钢琴准确无误地变成了手风琴演奏，还进行了“续写”。这意味着 Suno 在捕捉旋律的同时，它或许还能解析出潜在的和声结构，识别出和弦进行，并基于这些和声关系生成新的和声进展。
在下面这段由 Suno 产品经理 Rebecca 进行的官方演示中，我们可以看到类似的情况：
发现问题了吗？没错，Suno 现在不止能识别和弦，还能识别演唱者的音色！
如今，AI 克隆声音已经不再是什么新鲜事，我们经常可以在各大视频网站看到有人利用各种游戏动漫中的人物声音训练 AI 翻唱歌曲，但 Suno 所做的不仅是分析演唱者的独特音色特征以及演唱习惯，它还能使用合成的个性化音色，将新创作的旋律以接近原演唱者的声音表现出来，从而实现不仅旋律上的延续，还有音色上的连贯性和一致性。">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-06-05T09:10:34+08:00">
    <meta property="article:modified_time" content="2024-06-05T09:10:34+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">AI 挑战周杰伦？Suno 全新功能面世，即兴哼几句就能创作成歌，还能模仿声音！...</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div id="js_content"> 
 <p><img alt="" src="https://images2.imgbox.com/a9/0d/HwJ471Rw_o.jpg"></p> 
 <p style="text-align:left;">作者 | 王启隆</p> 
 <p style="text-align:left;">出品丨AI 科技大本营（ID：rgznai100）</p> 
 <p>2016 年，周杰伦根据女儿 Hathaway 在玩具钢琴上随意弹出的几个音符，激发出创作的灵感，谱写了一首温馨而深情的歌曲——《前世情人》。8 年过去，音乐创作逐步进入了 AI 时代，先前爆火出圈的音乐创作 AI 平台「<strong>Suno</strong>」在近日预热，未来将发布一项新功能：<strong>Sound-to-Song。</strong>意思是：<strong>用任何声音创作新歌曲</strong>（make a new song from any sound）。</p> 
 <p>即使你不像周杰伦一样拥有“绝对音感”，也不懂什么乐理与和弦，只需要哼唱一小段，Suno AI 就可以在你哼唱的基础上创作出完整的歌曲。下面便是 Suno 日前发布的第一波预热演示视频：《<strong>用喷壶演奏“迷幻摇滚”</strong>》。</p> 
 <p>某种意义上，这和 ChatGPT 推出的“语音输入”交互方式有异曲同工之妙，声音识别和语音识别如今已是各大 AI 产品的必备技术，比如说，我们基本可以在国产 AI App 使用聊天框旁边的说话功能：</p> 
 <p style="text-align:center;"><img alt="e78cf415c5fcd5f773920d23823c12ff.png" src="https://images2.imgbox.com/2f/2f/HPqQKo2Z_o.png"></p> 
 <p>但在音乐的世界，我们不需要像制作人一样苦口婆心地用对话的交互方式来教导 AI 怎么作曲，而是采用更简单的交互：直接唱出来。</p> 
 <p>这种创新的作曲方式将使用户能够把“<strong>声音采样</strong>”与“<strong>文字提示</strong>”结合起来，创作出独一无二的音乐作品。以前使用 Suno 作曲，可能还需要构思一下怎么写 Prompt 才能让 AI 明白你脑内的灵感；但现在，任何日常的声音，如 Suno 官方演示中喷壶敲击金属管的声音，都能转换成迷人的迷幻摇滚乐曲。</p> 
 <p>除了“喷壶摇滚”以外，Suno 还派出自家的工程师 Anessa 亲自演奏钢琴，并让 Suno AI 转化为完整的一首歌：</p> 
 <p>Suno 不仅将 Anessa 弹的这段钢琴准确无误地变成了手风琴演奏，还进行了“续写”。这意味着 Suno 在捕捉旋律的同时，<strong>它或许还能解析出潜在的和声结构，识别出和弦进行，并基于这些和声关系生成新的和声进展</strong>。</p> 
 <p>在下面这段由 Suno 产品经理 Rebecca 进行的官方演示中，我们可以看到类似的情况：</p> 
 <p>发现问题了吗？没错，<strong>Suno 现在不止能识别和弦，还能识别演唱者的音色</strong>！</p> 
 <p>如今，AI 克隆声音已经不再是什么新鲜事，我们经常可以在各大视频网站看到有人利用各种游戏动漫中的人物声音训练 AI 翻唱歌曲，但 Suno 所做的不仅是分析演唱者的独特音色特征以及演唱习惯，<strong>它还能使用合成的个性化音色，将新创作的旋律以接近原演唱者的声音表现出来，从而实现不仅旋律上的延续，还有音色上的连贯性和一致性</strong>。</p> 
 <p>这一技术的推出，预示着音乐创作的门槛将进一步降低，每个人都可以成为自己生活的“周杰伦”。接下来，让我们进一步解析 Suno 的这次重磅更新，看看还有哪些遗漏的发布内容。</p> 
 <p style="text-align:center;"><img alt="b70531bf31c69c5b7986bd18b53539a9.png" src="https://images2.imgbox.com/84/12/jCLtyFjS_o.png"></p> 
 <p style="text-align:center;"><strong>歌曲长度延长至 4 分钟！</strong></p> 
 <p style="text-align:center;"><strong><img alt="d3b3cb4cc0e0747fff1e953b44995344.png" src="https://images2.imgbox.com/e7/98/cKZcvQgM_o.png"></strong></p> 
 <p>此前，Suno 团队官宣表示 v4 版本还在“酝酿”当中，与此同时推出 v3.5 的抢先体验版本，供专业版和高级版会员使用。如今，免费用户也可以正式使用该功能，以下便是我作为免费账户点开模型列表时可选的选项：</p> 
 <p style="text-align:center;"><img alt="84cab1da8ac4a66e55a1ac44042eff46.png" src="https://images2.imgbox.com/88/c0/HggOpFyK_o.png"></p> 
 <p>Suno v3.5 最显著的改进之一是<strong>歌曲长度和结构的扩展</strong>。用户现在可以生成长达 4 分钟的音频片段，比以前的版本有了很大的提升。许多流行歌曲的时长设计在 3 到 5 分钟之间，而 4 分钟则是这个区间内的一个典型时长，这意味着我们现在可以用 Suno 创作更复杂、更多样化的作品，无需将多个剪辑拼接在一起。此外，现有的已创作歌曲还可以最多延长 2 分钟。</p> 
 <p>此外，Suno 现在拥有<strong>更连贯的旋律、和声和节奏</strong>，也就是说除了长度，在质量方面也提升了不少。Suno v3.5 改进了算法，可产生更连贯的旋律、和声和节奏。</p> 
 <p>作为测试，我让 Suno 尝试创作了一些电子游戏里经典的“Boss 战音乐”，但是要配上古典管弦乐作为点缀：</p> 
 <p>虽然我听不出作曲质量的提升究竟有多大，但可以直观感受到 4 分钟的长度大幅提升了一首歌的完整度，无论是 1 分钟和 2 分钟左右的变奏或是 3 分半的收尾都很精彩 —— 问题出在 3 分半之后，<strong>为了凑够 4 分钟的长度，Suno 强行再弹了半分钟钢琴，“画蛇添足”，显得十分突兀</strong>。</p> 
 <p>这种情况经常出现在大语言模型创作文章的时候：如果我们让 ChatGPT 写一段刚好 50 字的短讯，一字不多一字不少，那它就会为了凑字数或删字数创作出一些非常拗口的句子。这可能是因为大模型的训练目标在于最大化<strong>训练目标在于最大化预测下一个词（predict next-word ）的概率，确保生成文本的统计学合理性，而非始终保证文本的自然流畅或最优创意表达。</strong></p> 
 <p>纯音乐效果还算不错，那既然文章开头提到了周杰伦的《前世情人》，我们就让 Suno v3.5 也来挑战一下周董。</p> 
 <p style="text-align:center;"><img alt="a378dcf9158f5dd8dac7fe634fcdf194.png" src="https://images2.imgbox.com/3d/0f/uslAejJJ_o.png"></p> 
 <p>打开定制模式，输入《前世情人》的歌词，曲风选择这首歌“巴洛克式的华丽古典风格，加上电子迷幻嘻哈”的元素，使用最新的 v3.5 版本，成果如下：</p> 
 <p>效果不尽人意。v3.5 抢先体验时期，Reddit 网友便曾指出该版本存在的一大缺陷：<strong>无论输入什么提示词，都会生成一首毫无特色的流行歌曲。</strong>目前看来，这个问题仍旧存在，老版本的 Suno v3 在模仿各种小众歌曲风格方面反倒表现得更加出色。</p> 
 <p style="text-align:center;"><img alt="7fea9691dba7c7b60fb751d0eb2b209f.png" src="https://images2.imgbox.com/68/a9/PLZUUtzY_o.png"></p> 
 <p style="text-align:center;"><img alt="c575c7f013a0c94123d50108a59065da.png" src="https://images2.imgbox.com/2a/3d/T57vTk9W_o.png"></p> 
 <p style="text-align:center;"><strong>完美的“音色拷贝者”？</strong></p> 
 <p>v3.5 的基本更新显然是一次 0.5 级别的升级，并没有达到广大用户心目中的 v4 水平。相比之下，前文所述的 <strong>Sound-to-Song </strong>确实更让人耳目一新。事实上，有许多拿到了 Suno 内测资格的 AI 音乐家已经在 X 上晒出了自己用 Sound-to-Song 进行的创作成果：</p> 
 <p>AI 艺术家 Michael Carychao 拿到了 Sound-to-Song 的内测资格，这是他用创作的 AI 歌曲：《困惑》（Perplexed）。Michael 的吉他弹唱被 Suno 转化成了一首流行歌曲，所以他接下来上升了难度：</p> 
 <p>乐器换成口风琴之后，Suno 的表现事实上还比吉他流行乐好了不少。所以 Michael “变本加厉”，拿出了十根铅笔：</p> 
 <p>十根铅笔相互摩擦，模拟出了沙球（一种打击乐器）的效果，进而创作出了一首古巴音乐。</p> 
 <p>下一个例子由 Google 艺术文化实验室的常驻艺术家 Mario Klingemann 分享，Klingemann 从互联网档案馆 (Internet Archive) 获取了一段视频剪辑，这段视频特别含有对话或旁白，所以他打算通过这段视频来评估和展示 Suno 在处理自然语言语音方面的表现和创意潜力：</p> 
 <p>Suno 完美还原了视频中这位“Grumpy Old Man”（暴躁老头）的低沉音色，底下的评论区则称其为“经典老电影与现代节奏的绝妙融合”。Klingemann 还表示，将口语内容转化为“带有人声演唱的电子乐”的指令似乎主要来自于他向 Suno 提供的 Prompt，比如“口语”和“电子乐”。</p> 
 <p>正如 ChatGPT 让自然语言处理技术变得触手可及，Suno 的 AI 音乐扩展功能同样降低了音乐创作的技术门槛，可谓是“音乐的 ChatGPT 时刻”。但从某种意义上来说，AI 让音乐创作又回归到了最原始的冲动：质朴的鼓点、孤独的吟唱、悠扬的哼鸣 —— 表达自我，触动人心。</p> 
 <p style="text-align:center;"><img alt="b5b73c5aa87fc47ba22f3004d6e08be5.gif" src="https://images2.imgbox.com/84/53/ohdZBFKs_o.gif"></p> 
 <p>开发者正在迎接新一轮的技术浪潮变革。由 CSDN 和高端 IT 咨询和教育平台 Boolan 联合主办的 2024 年度「全球软件研发技术大会」秉承干货实料（案例）的内容原则，将于 7 月 4 日-5 日在北京正式举办。大会共设置了 12 个大会主题：大模型智能应用开发、软件开发智能化、AI 与 ML 智能运维、云原生架构……详情👉：http://sdcon.com.cn/</p> 
 <p style="text-align:center;"><img alt="961727511c905cd31355ba149b65ff3e.jpeg" src="https://images2.imgbox.com/a7/ac/nJ1mXSsb_o.jpg"></p> 
</div>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/a898af77b720202daaeb85bb6c489da5/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">03--nginx架构实战</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/c47507ce89de96f0f4de9810b0f0d6ec/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">github copilot vs 通义灵码 vs 腾讯云 AI 代码助手</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>