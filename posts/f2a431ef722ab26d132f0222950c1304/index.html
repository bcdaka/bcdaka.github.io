<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Docker&#43;Ollama&#43;WebUI&#43;AnythingLLM，构建企业本地AI大模型 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/f2a431ef722ab26d132f0222950c1304/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="Docker&#43;Ollama&#43;WebUI&#43;AnythingLLM，构建企业本地AI大模型">
  <meta property="og:description" content="文章目录 概要Ollama部署WebUI部署AnythingLLM部署Docker-Compose部署管理所有容器小结参考文章 概要 Ollama 是一个强大的大模型提供者，它通过开源的方式，为开发者和企业提供了先进的大型语言模型（LLM）。这些模型拥有处理和生成复杂语言任务的能力，为各种应用场景提供了强大的基础。
Open WebUI 则进一步增强了用户体验，它提供了一个高度可视化和用户友好的对话界面。这个界面不仅美观，而且功能丰富，使用户能够轻松地与背后的大模型进行交互，无论是通过文本聊天还是其他交互方式。
AnythingLLM 则是在这个基础上的一个创新工具，它允许用户利用 Ollama 提供的大模型能力，并结合本地数据，构建和定制符合个人或企业特定需求的 AI 大模型。AnythingLLM 的灵活性和定制性意味着用户可以根据自己的特定业务场景和需求，创建和优化 AI 解决方案，从而在保证数据安全和隐私的同时，实现更加个性化和高效的服务。
通过 AnythingLLM，用户可以轻松地将本地文档、资料和数据集成到 AI 模型中，实现智能检索、内容生成、问答系统等多样化功能。这不仅提高了工作效率，还增强了决策支持的能力。AnythingLLM 的多用户支持和精细的权限管理，使得团队协作变得更加简单和安全。
总的来说，Ollama、Open WebUI 和 AnythingLLM 的结合，为用户提供了一个从模型提供到界面交互，再到个性化定制的完整解决方案，使得构建和部署 AI 大模型变得更加容易、高效和安全。
Ollama部署 获取Ollama镜像:
使用Docker从镜像仓库拉取Ollama镜像：docker pull ollama/ollama 创建Ollama宿主机挂载目录:
在宿主机上创建一个目录用于Ollama数据的持久化存储：mkdir -p /data/docker/ollama/data 修改目录权限chmod -R 777 /data/docker/ollama 启动Ollama容器
使用以下命令启动Ollama容器，并将数据目录挂载到容器中：docker run \ -d \ --restart always \ --name ollama \ --privileged=true \ -p 11434:11434 \ -v /data/docker/ollama/data:/root/.ollama \ ollama/ollama 其中： -d 表示后台运行容器。--restart always 设置容器的重启策略。--name ollama 为容器指定一个名称。--privileged=true 使容器以特权模式运行，这将给予容器几乎相同于宿主机的权限。 -p 11434:11434 \ 将容器的11434端口映射到宿主机的11434端口。 -v /data/docker/ollama/data:/root/.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-05-31T12:39:21+08:00">
    <meta property="article:modified_time" content="2024-05-31T12:39:21+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Docker&#43;Ollama&#43;WebUI&#43;AnythingLLM，构建企业本地AI大模型</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><ul><li><a href="#_1" rel="nofollow">概要</a></li><li><a href="#Ollama_13" rel="nofollow">Ollama部署</a></li><li><a href="#WebUI_68" rel="nofollow">WebUI部署</a></li><li><a href="#AnythingLLM_112" rel="nofollow">AnythingLLM部署</a></li><li><a href="#DockerCompose_177" rel="nofollow">Docker-Compose部署管理所有容器</a></li><li><a href="#_264" rel="nofollow">小结</a></li><li><a href="#_266" rel="nofollow">参考文章</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h3><a id="_1"></a>概要</h3> 
<p><code>Ollama</code> 是一个强大的大模型提供者，它通过开源的方式，为开发者和企业提供了先进的大型语言模型（LLM）。这些模型拥有处理和生成复杂语言任务的能力，为各种应用场景提供了强大的基础。</p> 
<p><code>Open WebUI</code> 则进一步增强了用户体验，它提供了一个高度可视化和用户友好的对话界面。这个界面不仅美观，而且功能丰富，使用户能够轻松地与背后的大模型进行交互，无论是通过文本聊天还是其他交互方式。</p> 
<p><code>AnythingLLM</code> 则是在这个基础上的一个创新工具，它允许用户利用 Ollama 提供的大模型能力，并结合本地数据，构建和定制符合个人或企业特定需求的 AI 大模型。AnythingLLM 的灵活性和定制性意味着用户可以根据自己的特定业务场景和需求，创建和优化 AI 解决方案，从而在保证数据安全和隐私的同时，实现更加个性化和高效的服务。</p> 
<p>通过 AnythingLLM，用户可以轻松地将本地文档、资料和数据集成到 AI 模型中，实现智能检索、内容生成、问答系统等多样化功能。这不仅提高了工作效率，还增强了决策支持的能力。AnythingLLM 的多用户支持和精细的权限管理，使得团队协作变得更加简单和安全。</p> 
<p>总的来说，Ollama、Open WebUI 和 AnythingLLM 的结合，为用户提供了一个从模型提供到界面交互，再到个性化定制的完整解决方案，使得构建和部署 AI 大模型变得更加容易、高效和安全。</p> 
<h3><a id="Ollama_13"></a>Ollama部署</h3> 
<ol><li> <p><strong>获取Ollama镜像</strong>:</p> 
  <ul><li>使用Docker从镜像仓库拉取Ollama镜像：<pre><code class="prism language-shell"><span class="token function">docker</span> pull ollama/ollama
</code></pre> </li></ul> </li><li> <p><strong>创建Ollama宿主机挂载目录</strong>:</p> 
  <ul><li>在宿主机上创建一个目录用于Ollama数据的持久化存储：<pre><code class="prism language-shell"><span class="token function">mkdir</span> <span class="token parameter variable">-p</span> /data/docker/ollama/data
</code></pre> </li><li>修改目录权限<pre><code class="prism language-shell"><span class="token function">chmod</span>  <span class="token parameter variable">-R</span> <span class="token number">777</span> /data/docker/ollama
</code></pre> </li></ul> </li><li> <p><strong>启动Ollama容器</strong></p> 
  <ul><li>使用以下命令启动Ollama容器，并将数据目录挂载到容器中：<pre><code class="prism language-shell"><span class="token function">docker</span> run <span class="token punctuation">\</span>
  <span class="token parameter variable">-d</span> <span class="token punctuation">\</span>
  <span class="token parameter variable">--restart</span> always <span class="token punctuation">\</span>
  <span class="token parameter variable">--name</span> ollama <span class="token punctuation">\</span>
  <span class="token parameter variable">--privileged</span><span class="token operator">=</span>true <span class="token punctuation">\</span>
  <span class="token parameter variable">-p</span> <span class="token number">11434</span>:11434 <span class="token punctuation">\</span>
  <span class="token parameter variable">-v</span> /data/docker/ollama/data:/root/.ollama <span class="token punctuation">\</span>
  ollama/ollama
</code></pre> 其中： 
    <ul><li><code>-d</code> 表示后台运行容器。</li><li><code>--restart always</code> 设置容器的重启策略。</li><li><code>--name ollama </code> 为容器指定一个名称。</li><li><code>--privileged=true </code> 使容器以特权模式运行，这将给予容器几乎相同于宿主机的权限。</li><li><code> -p 11434:11434 \</code> 将容器的11434端口映射到宿主机的11434端口。</li><li><code> -v /data/docker/ollama/data:/root/.ollama</code> 将宿主机的数据目录挂载到容器中。</li><li><code>ollama/ollama</code> 指定要使用的ollama镜像和版本（latest）。</li></ul> </li></ul> </li><li> <p><strong>测试Ollama服务</strong>:</p> 
  <ul><li>进入Ollama容器：<pre><code class="prism language-shell"><span class="token function">docker</span> <span class="token builtin class-name">exec</span> <span class="token parameter variable">-it</span> ollama /bin/bash
</code></pre> </li><li>从Ollama仓库拉取<code>gemma</code>模型, 可从<a href="https://ollama.com/library" rel="nofollow">官网</a>查看有哪些模型<pre><code class="prism language-shell">ollama pull gemma:2b
</code></pre> </li><li>查看本地有哪些模型<pre><code class="prism language-shell">ollma list
</code></pre> </li><li>使用<code>gemma:2b</code>大模型， 然后与开启对话<pre><code class="prism language-shell">ollama run gemma:2b
</code></pre> </li></ul> </li></ol> 
<h3><a id="WebUI_68"></a>WebUI部署</h3> 
<ol><li> <p><strong>获取open-webui镜像</strong>:</p> 
  <ul><li>使用Docker从镜像仓库拉取open-webui镜像：<pre><code class="prism language-shell"><span class="token function">docker</span> pull m.daocloud.io/ghcr.io/open-webui/open-webui:main
</code></pre> </li></ul> </li><li> <p><strong>创建open-webui宿主机挂载目录</strong>:</p> 
  <ul><li>在宿主机上创建一个目录用于open-webui数据的持久化存储：<pre><code class="prism language-shell"><span class="token function">mkdir</span> <span class="token parameter variable">-p</span> /data/docker/open-webui/data
</code></pre> </li><li>修改目录权限<pre><code class="prism language-shell"><span class="token function">chmod</span>  <span class="token parameter variable">-R</span> <span class="token number">777</span> /data/docker/open-webui	 
</code></pre> </li></ul> </li><li> <p><strong>启动AnythingLLM容器</strong></p> 
  <ul><li>使用以下命令启动<code>open-webui</code>容器，并将数据目录挂载到容器中：<pre><code class="prism language-shell"><span class="token function">docker</span> run <span class="token punctuation">\</span>
  <span class="token parameter variable">-d</span> <span class="token punctuation">\</span>
  <span class="token parameter variable">--restart</span> always <span class="token punctuation">\</span>
  <span class="token parameter variable">--name</span> open-webui <span class="token punctuation">\</span>
  <span class="token parameter variable">--privileged</span><span class="token operator">=</span>true <span class="token punctuation">\</span>
  <span class="token parameter variable">-p</span> <span class="token number">3000</span>:8080 <span class="token punctuation">\</span>
  <span class="token parameter variable">-e</span> <span class="token assign-left variable">OLLAMA_BASE_URL</span><span class="token operator">=</span><span class="token string">"http://{ollma服务IP}:11434"</span>
  <span class="token parameter variable">-v</span> /data/docker/open-webui/data:/app/backend/data <span class="token punctuation">\</span>
   m.daocloud.io/ghcr.io/open-webui/open-webui:main
</code></pre> 其中： 
    <ul><li><code>-d</code> 表示后台运行容器。</li><li><code>--restart always</code> 设置容器的重启策略。</li><li><code>--name open-webui</code> 为容器指定一个名称。</li><li><code>--privileged=true </code> 使容器以特权模式运行，这将给予容器几乎相同于宿主机的权限。</li><li><code>-p 3000:8080 \</code> 将容器的3000端口映射到宿主机的8080端口。</li><li><code> -v /data/docker/open-webui/data:/app/backend/data</code> 将宿主机的数据目录挂载到容器中。</li><li><code> m.daocloud.io/ghcr.io/open-webui/open-webui:main</code> 指定要使用的open-webui镜像</li></ul> </li></ul> </li><li> <p><strong>测试open-webui服务</strong>:</p> 
  <ul><li>通过浏览器输入<code>http://{宿主机IP}:3000/auth</code>即可开始访问</li></ul> </li></ol> 
<h3><a id="AnythingLLM_112"></a>AnythingLLM部署</h3> 
<ol><li> <p><strong>获取AnythingLLM镜像</strong>:</p> 
  <ul><li>使用Docker从镜像仓库拉取AnythingLLM镜像：<pre><code class="prism language-shell"><span class="token function">docker</span> pull mintplexlabs/anythingllm
</code></pre> </li></ul> </li><li> <p><strong>创建AnythingLLM宿主机挂载目录</strong>:</p> 
  <ul><li>在宿主机上创建一个目录用于AnythingLLM数据的持久化存储：<pre><code class="prism language-shell"><span class="token function">mkdir</span> <span class="token parameter variable">-p</span> /data/docker/anythingllm/data
</code></pre> </li><li>在宿主机上创建一个目录用于存放AnythingLLM的环境变量信息<pre><code class="prism language-shell"><span class="token function">mkdir</span> <span class="token parameter variable">-p</span> /data/docker/anythingllm/env
</code></pre> </li><li>修改目录权限<pre><code class="prism language-shell"><span class="token function">chmod</span>  <span class="token parameter variable">-R</span> <span class="token number">777</span> /data/docker/anythingllm
</code></pre> </li></ul> </li><li> <p><strong>创建环境变量文件</strong></p> 
  <ul><li>创建配置文件<code>env.txt</code><pre><code class="prism language-shell"><span class="token builtin class-name">cd</span> /data/docker/anythingllm/env
<span class="token function">touch</span> env.txt
</code></pre> </li><li>增加环境变量信息<pre><code class="prism language-shell"><span class="token assign-left variable">SERVER_PORT</span><span class="token operator">=</span><span class="token number">3001</span>
<span class="token assign-left variable">STORAGE_DIR</span><span class="token operator">=</span><span class="token string">"/app/server/storage"</span>
<span class="token assign-left variable"><span class="token environment constant">UID</span></span><span class="token operator">=</span><span class="token string">'1000'</span>
<span class="token assign-left variable">GID</span><span class="token operator">=</span><span class="token string">'1000'</span>
</code></pre> </li></ul> </li><li> <p><strong>启动AnythingLLM容器</strong></p> 
  <ul><li>使用以下命令启动AnythingLLM容器，并将数据目录挂载到容器中：<pre><code class="prism language-shell"><span class="token function">docker</span> run <span class="token punctuation">\</span>
  <span class="token parameter variable">-d</span> <span class="token punctuation">\</span>
  <span class="token parameter variable">--restart</span> always <span class="token punctuation">\</span>
  <span class="token parameter variable">--name</span> anythingllm <span class="token punctuation">\</span>
  --cap-add SYS_ADMIN <span class="token punctuation">\</span>
  <span class="token parameter variable">--privileged</span><span class="token operator">=</span>true <span class="token punctuation">\</span>
  <span class="token parameter variable">-p</span> <span class="token number">3014</span>:3001 <span class="token punctuation">\</span>
  <span class="token parameter variable">-v</span> /data/docker/anythingllm/data:/app/server/storage <span class="token punctuation">\</span>
  <span class="token parameter variable">-v</span> /data/docker/anythingllm/env/env.txt:/app/server/.env <span class="token punctuation">\</span>
  mintplexlabs/anythingllm
</code></pre> 其中： 
    <ul><li><code>-d</code> 表示后台运行容器。</li><li><code>--restart always</code> 设置容器的重启策略。</li><li><code>--name anythingllm </code> 为容器指定一个名称。</li><li><code>--cap-add SYS_ADMIN</code> 添加SYS_ADMIN能力给容器，这意味着容器将获得更多的系统管理权限，比如进行磁盘管理、网络配置等</li><li><code>--privileged=true </code> 使容器以特权模式运行，这将给予容器几乎相同于宿主机的权限。</li><li><code> -p 3014:3001 \</code> 将容器的3014端口映射到宿主机的3001端口。</li><li><code> -v /data/docker/anythingllm/data:/app/server/storage</code> 将宿主机的数据目录挂载到容器中。</li><li><code>/data/docker/anythingllm/env/env.txt:/app/server/.env</code> 将宿主机的配置文件挂载到容器中。</li><li><code> mintplexlabs/anythingllm</code> 指定要使用的AnythingLLM镜像和版本（latest）。</li></ul> </li></ul> </li><li> <p><strong>测试AnythingLLM服务</strong>:</p> 
  <ul><li>通过浏览器输入<code>http://{宿主机IP}:3041</code>即可开始访问</li></ul> </li></ol> 
<h3><a id="DockerCompose_177"></a>Docker-Compose部署管理所有容器</h3> 
<p>将上面的docker run命令转换为docker-compose.yml文件，并设置open-webui和anythingllm服务依赖于ollama服务，方便管理</p> 
<pre><code class="prism language-yaml"><span class="token key atrule">version</span><span class="token punctuation">:</span> <span class="token string">'3.8'</span>

<span class="token key atrule">services</span><span class="token punctuation">:</span>
  <span class="token key atrule">ollama</span><span class="token punctuation">:</span>
    <span class="token key atrule">image</span><span class="token punctuation">:</span> ollama/ollama
    <span class="token key atrule">container_name</span><span class="token punctuation">:</span> ollama
    <span class="token key atrule">restart</span><span class="token punctuation">:</span> always
    <span class="token key atrule">privileged</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>
    <span class="token key atrule">ports</span><span class="token punctuation">:</span>
      <span class="token punctuation">-</span> <span class="token string">"11434:11434"</span>
    <span class="token key atrule">volumes</span><span class="token punctuation">:</span>
      <span class="token punctuation">-</span> /data/docker/ollama/data<span class="token punctuation">:</span>/root/.ollama
    <span class="token key atrule">networks</span><span class="token punctuation">:</span>
      <span class="token punctuation">-</span> llm_network

  <span class="token key atrule">open-webui</span><span class="token punctuation">:</span>
    <span class="token key atrule">image</span><span class="token punctuation">:</span> m.daocloud.io/ghcr.io/open<span class="token punctuation">-</span>webui/open<span class="token punctuation">-</span>webui<span class="token punctuation">:</span>main
    <span class="token key atrule">container_name</span><span class="token punctuation">:</span> open<span class="token punctuation">-</span>webui
    <span class="token key atrule">restart</span><span class="token punctuation">:</span> always
    <span class="token key atrule">privileged</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>
    <span class="token key atrule">ports</span><span class="token punctuation">:</span>
      <span class="token punctuation">-</span> <span class="token string">"3000:8080"</span>
    <span class="token key atrule">environment</span><span class="token punctuation">:</span>
      <span class="token key atrule">OLLAMA_BASE_URL</span><span class="token punctuation">:</span> <span class="token string">"http://ollama:11434"</span>
    <span class="token key atrule">volumes</span><span class="token punctuation">:</span>
      <span class="token punctuation">-</span> /data/docker/open<span class="token punctuation">-</span>webui/data<span class="token punctuation">:</span>/app/backend/data
    <span class="token key atrule">depends_on</span><span class="token punctuation">:</span>
      <span class="token punctuation">-</span> ollama
    <span class="token key atrule">networks</span><span class="token punctuation">:</span>
      <span class="token punctuation">-</span> llm_network

  <span class="token key atrule">anythingllm</span><span class="token punctuation">:</span>
    <span class="token key atrule">image</span><span class="token punctuation">:</span> mintplexlabs/anythingllm
    <span class="token key atrule">container_name</span><span class="token punctuation">:</span> anythingllm
    <span class="token key atrule">restart</span><span class="token punctuation">:</span> always
    <span class="token key atrule">cap_add</span><span class="token punctuation">:</span>
      <span class="token punctuation">-</span> SYS_ADMIN
    <span class="token key atrule">privileged</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>
    <span class="token key atrule">ports</span><span class="token punctuation">:</span>
      <span class="token punctuation">-</span> <span class="token string">"3014:3001"</span>
    <span class="token key atrule">volumes</span><span class="token punctuation">:</span>
      <span class="token punctuation">-</span> /data/docker/anythingllm/data<span class="token punctuation">:</span>/app/server/storage
      <span class="token punctuation">-</span> /data/docker/anythingllm/env/env.txt<span class="token punctuation">:</span>/app/server/.env
    <span class="token key atrule">depends_on</span><span class="token punctuation">:</span>
      <span class="token punctuation">-</span> ollama
    <span class="token key atrule">networks</span><span class="token punctuation">:</span>
      <span class="token punctuation">-</span> llm_network

<span class="token key atrule">networks</span><span class="token punctuation">:</span>
  <span class="token key atrule">llm_network</span><span class="token punctuation">:</span>
    <span class="token key atrule">driver</span><span class="token punctuation">:</span> bridge
</code></pre> 
<p>这个<code>docker-compose.yml</code>文件中定义了三个服务：<code>ollama</code>、<code>open-webui</code>和<code>anythingllm</code>。每个服务都有自己的配置，包括镜像、容器名称、重启策略、特权模式、端口映射和卷挂载。</p> 
<ul><li><code>environment</code>: 用于设置环境变量，这里<code>open-webui</code>服务设置了<code>OLLAMA_BASE_URL</code>环境变量，指向<code>ollama</code>服务。</li><li><code>depends_on</code>: 此选项用于指定服务依赖，确保<code>open-webui</code>和<code>anythingllm</code>服务在<code>ollama</code>服务启动后再启动。</li></ul> 
<p>请确保将<code>/data/docker/...</code>路径替换为实际的宿主机路径，或者根据需要创建这些目录。</p> 
<p>要使用此<code>docker-compose.yml</code>文件启动服务，你需要在包含该文件的目录中打开终端，然后运行：</p> 
<pre><code class="prism language-sh"><span class="token function">docker-compose</span> up <span class="token parameter variable">-d</span>
</code></pre> 
<p>这将按照文件中定义的配置启动所有服务。如果你想停止服务，可以使用：</p> 
<pre><code class="prism language-sh"><span class="token function">docker-compose</span> down
</code></pre> 
<p>这将停止并移除容器，但不会删除卷。如果你需要重新构建服务或者对配置进行了更改，可以使用：</p> 
<pre><code class="prism language-sh"><span class="token function">docker-compose</span> up <span class="token parameter variable">--build</span>
</code></pre> 
<p>这将重建任何已更改的服务的镜像。</p> 
<h3><a id="_264"></a>小结</h3> 
<h3><a id="_266"></a>参考文章</h3> 
<p><a href="https://ollama.com/" rel="nofollow">ollam官网</a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/4802bf844f76ae21faf38d22d2701204/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">安装MySQL报错 suffix ‘.‘ used for variable ‘mysqlx-port‘ (value ‘0.0‘)</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/1bc9513d45636e89ff3bbd1a61d0efde/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">校园交友|基于SprinBoot&#43;vue的校园交友网站(源码&#43;数据库&#43;文档)</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>