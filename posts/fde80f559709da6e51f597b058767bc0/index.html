<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【向量检索】之向量数据库Milvus,Faiss详解及应用案例 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/fde80f559709da6e51f597b058767bc0/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="【向量检索】之向量数据库Milvus,Faiss详解及应用案例">
  <meta property="og:description" content="Reference https://www.modb.pro/db/509268
笔记︱几款多模态向量检索引擎：Faiss 、milvus、Proxima、vearch、Jina等 - 知乎 (zhihu.com)
向量数据库入坑指南：聊聊来自元宇宙大厂 Meta 的相似度检索技术 Faiss - 苏洋的文章 - 知乎
常用的三种索引方式及原理-CSDN
向量搜索应用 向量检索技术，其主要的应用领域如人脸识别、推荐系统、图片搜索、视频指纹、语音处理、自然语言处理、文件搜索
背景 向量检索需要用到向量数据库，而普通的关系型数据库（如 MySQL、PostgreSQL）通常不适合处理向量检索任务。这是因为**【向量检索有其特殊的需求和性能要求】**。
原因如下：
1、向量检索的特性
高维度数据：向量通常是高维数据，可能有数百到数千个维度。处理高维数据需要特殊的数据结构和算法，以确保检索的效率。相似性度量：向量检索基于相似性度量（如欧氏距离、余弦相似度等）来查找相似向量。计算高维向量之间的相似性需要高效的算法，而普通数据库没有优化这些操作。近似最近邻搜索（ANN）：在大规模数据集上，精确最近邻搜索的计算开销非常大，因此通常使用近似最近邻搜索算法（如 LSH、HNSW、IVF 等）来提高检索效率。向量数据库通常内置了这些算法。 2、普通数据库的限制
索引结构：普通数据库的索引（如 B 树、哈希索引等）设计用于处理标量数据（如整数、字符串等），而不是高维向量。它们无法有效地支持高维相似性检索。查询优化：普通数据库的查询优化器针对 SQL 查询进行了优化，但对高维向量相似性检索的优化有限，可能导致查询性能低下。扩展性：处理大规模向量数据需要分布式存储和计算能力，普通数据库在这方面的支持不如专门设计的向量数据库。 3、向量数据库的优势
向量数据库（如 FAISS、Milvus、Annoy、Weaviate 等）专门为向量检索设计，具备以下优势：
高效的索引结构：支持多种高效的索引结构（如 HNSW、IVF、PQ 等），能够快速处理高维向量的相似性检索。优化的相似性计算：针对高维向量的相似性计算进行了优化，能够在大规模数据集上高效执行最近邻搜索。扩展性和分布式支持：许多向量数据库支持分布式存储和计算，能够处理海量向量数据，并在多个节点之间均衡负载。 4、结论
向量数据库通过专门的索引结构、优化的相似性计算以及分布式支持，显著提高了高维向量相似性检索的效率和扩展性。因此，对于需要处理大规模向量数据的应用场景（如推荐系统、图像搜索、自然语言处理等），使用向量数据库是更好的选择。
索引类型 索引类型原理特点适用场景优点缺点FLAT线性扫描: 直接对所有向量进行线性扫描，计算每个向量与查询向量之间的距离。精确度高，速度较慢。小规模数据集或对精度要求非常高的场景。精度高，因为计算了每个可能的距离。对于大数据集，速度非常慢。IVF簇划分: 将向量数据集分为多个簇（clusters），然后在这些簇内搜索。
【Inverted File Index】通过缩小搜索范围加速查询。搜索分两步：先找到最相关的簇，再在簇内搜索。中大规模数据集，平衡速度和精度。加速搜索速度，平衡速度和精度。精度稍低于 FLAT。PQ子空间划分: 将向量分成多个子空间
量化: 每个子空间独立量化，减少存储和计算复杂度。
【Product Quantization】存储效率高，查询速度快。精度有损，但通常可接受。大规模数据集，对存储和查询速度要求高的场景。存储效率高，查询速度快。量化带来精度损失。HNSW多层图结构: 构建一个包含多个层次的小世界图
导航搜索: 从高层次开始，逐层向下搜索，直到找到最近邻。
【Hierarchical Navigable Small World】高查询效率和精度，支持动态更新。高效查询，动态更新的大规模数据集。高效的查询速度和高精度。构建和维护图结构复杂，内存消耗较大。LSH哈希映射: 将相似的向量映射到相同的哈希桶。
【Locality-Sensitive Hashing】适用于高维数据，但精度相对较低。高维数据的近似最近邻搜索。适用于高维数据，查询速度快。精度相对较低。ANNOY随机投影树: 构建多棵树，每棵树基于不同的随机投影。
【Approximate Nearest Neighbors Oh Yeah】平衡了搜索速度和精度。大规模数据集。平衡速度和精度。构建时间较长。IVF-PQ簇划分和量化: 结合 IVF 和 PQ，将向量数据集分为多个簇，并在每个簇内进行量化。">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-06-18T20:46:03+08:00">
    <meta property="article:modified_time" content="2024-06-18T20:46:03+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【向量检索】之向量数据库Milvus,Faiss详解及应用案例</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="Reference_0"></a>Reference</h2> 
<p>https://www.modb.pro/db/509268</p> 
<p><a href="https://zhuanlan.zhihu.com/p/364923722" rel="nofollow">笔记︱几款多模态向量检索引擎：Faiss 、milvus、Proxima、vearch、Jina等 - 知乎 (zhihu.com)</a></p> 
<p><a href="https://zhuanlan.zhihu.com/p/560981386" rel="nofollow">向量数据库入坑指南：聊聊来自元宇宙大厂 Meta 的相似度检索技术 Faiss - 苏洋的文章 - 知乎</a></p> 
<p><a href="https://blog.csdn.net/ResumeProject/article/details/135350945">常用的三种索引方式及原理-CSDN</a></p> 
<h2><a id="_10"></a>向量搜索应用</h2> 
<p>向量检索技术，其主要的应用领域如人脸识别、推荐系统、图片搜索、视频指纹、语音处理、自然语言处理、文件搜索</p> 
<p><img src="https://images2.imgbox.com/b2/42/nGMOZNbi_o.png" alt="image"></p> 
<h2><a id="_16"></a>背景</h2> 
<p>向量检索需要用到向量数据库，而普通的关系型数据库（如 MySQL、PostgreSQL）通常不适合处理向量检索任务。这是因为**【向量检索有其特殊的需求和性能要求】**。</p> 
<p>原因如下：</p> 
<p><strong>1、向量检索的特性</strong></p> 
<ul><li><strong>高维度数据</strong>：向量通常是高维数据，可能有数百到数千个维度。处理高维数据需要特殊的数据结构和算法，以确保检索的效率。</li><li><strong>相似性度量</strong>：向量检索基于相似性度量（如欧氏距离、余弦相似度等）来查找相似向量。计算高维向量之间的相似性需要高效的算法，而普通数据库没有优化这些操作。</li><li><strong>近似最近邻搜索（ANN）</strong>：在大规模数据集上，精确最近邻搜索的计算开销非常大，因此通常使用近似最近邻搜索算法（如 LSH、HNSW、IVF 等）来提高检索效率。向量数据库通常内置了这些算法。</li></ul> 
<p><strong>2、普通数据库的限制</strong></p> 
<ul><li><strong>索引结构</strong>：普通数据库的索引（如 B 树、哈希索引等）设计用于处理标量数据（如整数、字符串等），而不是高维向量。它们无法有效地支持高维相似性检索。</li><li><strong>查询优化</strong>：普通数据库的查询优化器针对 SQL 查询进行了优化，但对高维向量相似性检索的优化有限，可能导致查询性能低下。</li><li><strong>扩展性</strong>：处理大规模向量数据需要分布式存储和计算能力，普通数据库在这方面的支持不如专门设计的向量数据库。</li></ul> 
<p><strong>3、向量数据库的优势</strong></p> 
<p>向量数据库（如 FAISS、Milvus、Annoy、Weaviate 等）专门为向量检索设计，具备以下优势：</p> 
<ul><li><strong>高效的索引结构</strong>：支持多种高效的索引结构（如 HNSW、IVF、PQ 等），能够快速处理高维向量的相似性检索。</li><li><strong>优化的相似性计算</strong>：针对高维向量的相似性计算进行了优化，能够在大规模数据集上高效执行最近邻搜索。</li><li><strong>扩展性和分布式支持</strong>：许多向量数据库支持分布式存储和计算，能够处理海量向量数据，并在多个节点之间均衡负载。</li></ul> 
<p><strong>4、结论</strong></p> 
<p>向量数据库通过专门的索引结构、优化的相似性计算以及分布式支持，显著提高了高维向量相似性检索的效率和扩展性。因此，对于需要处理大规模向量数据的应用场景（如推荐系统、图像搜索、自然语言处理等），使用向量数据库是更好的选择。</p> 
<h2><a id="_46"></a>索引类型</h2> 
<table><thead><tr><th>索引类型</th><th>原理</th><th>特点</th><th>适用场景</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td><strong>FLAT</strong></td><td><strong>线性扫描:</strong> 直接对所有向量进行线性扫描，计算每个向量与查询向量之间的距离。</td><td>精确度高，速度较慢。</td><td>小规模数据集或对精度要求非常高的场景。</td><td>精度高，因为计算了每个可能的距离。</td><td>对于大数据集，速度非常慢。</td></tr><tr><td><strong>IVF</strong></td><td><strong>簇划分:</strong> 将向量数据集分为多个簇（clusters），然后在这些簇内搜索。<br>【Inverted File Index】</td><td>通过缩小搜索范围加速查询。搜索分两步：先找到最相关的簇，再在簇内搜索。</td><td>中大规模数据集，平衡速度和精度。</td><td>加速搜索速度，平衡速度和精度。</td><td>精度稍低于 FLAT。</td></tr><tr><td><strong>PQ</strong></td><td><strong>子空间划分</strong>: 将向量分成多个子空间<br><strong>量化</strong>: 每个子空间独立量化，减少存储和计算复杂度。<br>【Product Quantization】</td><td>存储效率高，查询速度快。精度有损，但通常可接受。</td><td>大规模数据集，对存储和查询速度要求高的场景。</td><td>存储效率高，查询速度快。</td><td>量化带来精度损失。</td></tr><tr><td><strong>HNSW</strong></td><td><strong>多层图结构</strong>: 构建一个包含多个层次的小世界图<br><strong>导航搜索</strong>: 从高层次开始，逐层向下搜索，直到找到最近邻。<br>【Hierarchical Navigable Small World】</td><td>高查询效率和精度，支持动态更新。</td><td>高效查询，动态更新的大规模数据集。</td><td>高效的查询速度和高精度。</td><td>构建和维护图结构复杂，内存消耗较大。</td></tr><tr><td><strong>LSH</strong></td><td><strong>哈希映射</strong>: 将相似的向量映射到相同的哈希桶。<br>【Locality-Sensitive Hashing】</td><td>适用于高维数据，但精度相对较低。</td><td>高维数据的近似最近邻搜索。</td><td>适用于高维数据，查询速度快。</td><td>精度相对较低。</td></tr><tr><td><strong>ANNOY</strong></td><td><strong>随机投影树</strong>: 构建多棵树，每棵树基于不同的随机投影。<br>【Approximate Nearest Neighbors Oh Yeah】</td><td>平衡了搜索速度和精度。</td><td>大规模数据集。</td><td>平衡速度和精度。</td><td>构建时间较长。</td></tr><tr><td><strong>IVF-PQ</strong></td><td><strong>簇划分和量化</strong>: 结合 IVF 和 PQ，将向量数据集分为多个簇，并在每个簇内进行量化。<br>【Inverted File with Product Quantization】</td><td>进一步优化存储和查询效率。</td><td>大规模数据集，需要存储和查询效率优化的场景。</td><td>存储和查询效率进一步优化。</td><td>构建和维护较复杂。</td></tr><tr><td><strong>ScaNN</strong></td><td><strong>结合量化和排序</strong>: 结合矢量量化和距离排序等技术。 <br>【Scalable Nearest Neighbors】</td><td>在处理大规模数据集时表现出色。</td><td>大规模数据集。</td><td>在大规模数据集上表现出色。</td><td>算法复杂度较高。</td></tr></tbody></table> 
<p>——from ChatGPT</p> 
<h2><a id="_61"></a>相似度指标</h2> 
<ul><li><strong>Euclidean distance (L2)</strong>: This metric is generally used in the field of computer vision (CV).</li><li><strong>Inner product (IP)</strong>: This metric is generally used in the field of natural language processing (NLP). The metrics that are widely used for binary embeddings include:</li><li><strong>Hamming</strong>: This metric is generally used in the field of natural language processing (NLP).</li><li><strong>Jaccard</strong>: This metric is generally used in the field of molecular similarity search.</li><li><strong>Tanimoto</strong>: This metric is generally used in the field of molecular similarity search.</li><li><strong>Superstructure</strong>: This metric is generally used to search for similar superstructure of a molecule.</li><li><strong>Substructure</strong>: This metric is generally used to search for similar substructure of a molecule.</li></ul> 
<h2><a id="_71"></a>向量数据库</h2> 
<p>以下是主流向量数据库的对比：</p> 
<table><thead><tr><th>数据库</th><th>发布者</th><th>时间</th><th>功能</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td>Milvus</td><td>Zilliz (阿里巴巴孵化)</td><td>2019</td><td>多模态检索，分布式架构，数据持久化，查询优化</td><td>高性能，多模态支持，易用性强</td><td>部分功能依赖商业支持</td></tr><tr><td>FAISS</td><td>Facebook AI Research</td><td>2017</td><td>多种索引类型，内存高效利用，GPU 加速</td><td>高性能（尤其在 GPU 环境），灵活性强，社区支持丰富</td><td>持久化和分布式支持较弱，使用门槛较高</td></tr><tr><td>Annoy</td><td>Spotify</td><td>2014</td><td>随机投影树，读多写少，支持磁盘持久化</td><td>简单易用，支持磁盘持久化</td><td>写操作不高效，扩展性有限</td></tr><tr><td>NMSLIB</td><td>非官方开源项目</td><td>2013</td><td>多种近似最近邻算法，高性能，多语言绑定</td><td>性能优秀，灵活性强</td><td>文档和社区支持较少，缺乏商业支持</td></tr><tr><td>Weaviate</td><td>SeMI Technologies</td><td>2019</td><td>分布式搜索，知识图谱，RESTful API 和 GraphQL 支持</td><td>上下文感知，结合知识图谱提供智能搜索，支持分布式和大规模数据</td><td>部分功能依赖外部服务和插件，社区生态较新</td></tr><tr><td>Pinecone</td><td>Pinecone.io</td><td>2020</td><td>商业化托管服务，多种索引，自动扩展，实时更新</td><td>全托管服务，高可靠性，良好文档和客户支持</td><td>使用成本高，部分功能需要付费订阅</td></tr><tr><td>Qdrant</td><td>Qdrant</td><td>2021</td><td>高性能搜索，实时更新，分布式架构，数据持久化</td><td>高性能，实时更新，易用性强，支持分布式和持久化</td><td>分布式功能较新，社区生态正在发展</td></tr></tbody></table> 
<p>—— ChatGPT</p> 
<p><strong>Milvus</strong> 是一个功能强大、支持多模态和分布式架构的向量数据库，适用于需要处理大规模、多样化数据的场景。</p> 
<p><strong>FAISS</strong> 则以其高性能和灵活性著称，特别适合需要高效向量检索和 GPU 加速的场景。选择合适的向量数据库需要根据具体的应用需求、数据规模和性能要求来决定。</p> 
<table><thead><tr><th>向量数据库</th><th>GitHub Star 数量</th><th>GitHub Fork 数量</th><th>社区活跃度</th><th>使用情况及活跃度</th></tr></thead><tbody><tr><td>Milvus</td><td>14k+</td><td>2k+</td><td>高</td><td><strong>使用情况</strong>：广泛应用于多模态检索、推荐系统等领域。<br><strong>社区活跃度</strong>：活跃，有定期更新和活跃的社区支持。</td></tr><tr><td>FAISS</td><td>22k+</td><td>4k+</td><td>高</td><td><strong>使用情况</strong>：被广泛用于研究和工业界的高性能向量检索任务，尤其在 GPU 环境下。<br><strong>社区活跃度</strong>：非常活跃，有广泛的文档和社区支持。</td></tr><tr><td>Annoy</td><td>11k+</td><td>1k+</td><td>中</td><td><strong>使用情况</strong>：常用于推荐系统和音乐检索，尤其适合读多写少的场景。<br><strong>社区活跃度</strong>：活跃，维护较好，但更新频率相对较低。</td></tr><tr><td>NMSLIB</td><td>3k+</td><td>800+</td><td>中</td><td><strong>使用情况</strong>：用于各种高性能向量检索任务，支持多种算法。<br><strong>社区活跃度</strong>：活跃，有一定的用户基础和贡献者，但相对较小。</td></tr><tr><td>Weaviate</td><td>2k+</td><td>300+</td><td>中</td><td><strong>使用情况</strong>：适用于知识图谱和上下文感知的检索场景。<br><strong>社区活跃度</strong>：活跃，但由于是相对较新的项目，用户基础和生态正在发展中。</td></tr><tr><td>Pinecone</td><td>无公开仓库</td><td>无公开仓库</td><td>高（商业服务）</td><td><strong>使用情况</strong>：被多家企业用于生产环境中的向量检索任务。<br><strong>社区活跃度</strong>：高，通过商业支持和客户服务提供持续的更新和支持。</td></tr></tbody></table> 
<h2><a id="Milvus_106"></a>Milvus</h2> 
<p>【<strong>向量数据库</strong>】</p> 
<p>【<strong>支持高效的向量检索</strong>】Milvus 采用了高效的算法和数据结构，如倒排索引、HNSW、量化等，优化搜索性能和存储效率，适合于<strong>机器学习、人工智能和相似性搜索</strong>的应用场景。</p> 
<p>【<strong>高度可扩展</strong>】Milvus 支持容器化部署（如 Kubernetes）</p> 
<p>【<strong>易用性和灵活性</strong>】【<strong>强大的社区支持</strong>】</p> 
<h3><a id="Doc_116"></a>官方Doc</h3> 
<p>https://milvus.io/docs/v2.2.x</p> 
<h3><a id="_120"></a>背景</h3> 
<p>Milvus 是由 Zilliz 开发并开源的高性能分布式向量数据库，最初是由阿里巴巴孵化，旨在处理大规模、多模态的向量检索任务。Milvus 是 LF AI &amp; Data 基金会的托管项目之一。</p> 
<h3><a id="_124"></a>功能</h3> 
<ul><li><strong>多模态向量检索</strong>：支持文本、图像、视频、音频等多种数据类型的向量检索。</li><li><strong>多种索引类型</strong>：支持 IVF（Inverted File）、HNSW（Hierarchical Navigable Small World）、ANNOY、PQ（Product Quantization）等。</li><li><strong>分布式架构</strong>：支持横向扩展，能够处理海量数据并提供高并发性能。</li><li><strong>数据持久化</strong>：支持数据持久化和动态加载，确保数据的持久性和可恢复性。（Milvus 使用 RocksDB 作为持久化存储）</li><li><strong>高级查询</strong>：支持复杂查询，如布尔查询、批量查询等。</li><li><strong>图形化界面</strong>：提供 Milvus Insight 图形化管理界面，方便用户管理和监控集群。</li><li><strong>API 支持</strong>：提供丰富的 API，包括 RESTful API、Python SDK、Java SDK 等。</li></ul> 
<p><strong>【多模态向量检索支持】</strong></p> 
<ul><li><strong>特征提取</strong>：结合预训练模型进行特征提取，将多模态数据（文本、图像、视频等）转化为向量表示。</li><li><strong>统一接口</strong>：所有模态的数据在 Milvus 中统一表示为向量，用户可以通过统一接口进行检索操作。</li></ul> 
<p><strong>【分布式架构】</strong></p> 
<ul><li><strong>集群架构</strong>：包括 Coordinator、Proxy、Data Node、Query Node、Index Node 等组件，支持横向扩展和高并发。</li><li><strong>数据分片和分区</strong>：支持数据水平切分（Sharding）和逻辑分区（Partitioning），便于管理和检索。</li><li><strong>索引管理</strong>：支持多种索引类型的分布式构建和维护，提高大规模数据的检索性能。</li><li><strong>负载均衡和故障恢复</strong>：使用负载均衡机制和故障恢复机制，保证系统的高可用性。</li><li><strong>数据持久化</strong>：支持数据持久化和恢复，确保数据在节点故障或重启时不会丢失。</li></ul> 
<h3><a id="_153"></a>架构</h3> 
<p>Milvus 的架构主要由以下几个组件组成：</p> 
<ul><li><strong>Coordinator</strong>：负责集群管理、元数据管理和任务调度。</li><li><strong>Proxy</strong>：处理客户端请求，负责数据路由和负载均衡。</li><li><strong>Data Node</strong>：负责数据存储和管理，包括数据持久化和索引构建。</li><li><strong>Query Node</strong>：处理查询请求，执行向量检索和结果返回。</li><li><strong>Index Node</strong>：负责索引构建和维护，提高查询效率。</li><li><strong>Meta Store</strong>：存储元数据，如数据表结构、索引信息等。</li></ul> 
<img src="https://images2.imgbox.com/64/30/VZwRMoUo_o.png" alt="image"> 
<p><strong>【节点】</strong></p> 
<p>query node 负责查询，data node 负责数据写入和持久化、index node负责索引建立和加速查询</p> 
<p>the query node is in charge of data query; the data node is responsible for data insertion and data persistence; and the index node mainly deals with index building and query acceleration.</p> 
<h3><a id="_176"></a>设计原则</h3> 
<p><a href="https://milvus.io/blog/deep-dive-1-milvus-architecture-overview.md" rel="nofollow">The design principles of Milvus 2.0</a></p> 
<p><strong>数据流程</strong></p> 
<blockquote> 
 <p><strong>【logs --&gt; log snapshot --&gt; segment】</strong></p> 
 <p>Both the table and the log are data, In the case of Milvus, it aggregates logs using a processing window from TimeTick. Based on log sequence, multiple logs are aggregated into one small file called log snapshot. Then these log snapshots are combined to form a segment, which can be used individually for load balance.</p> 
</blockquote> 
<p><strong>第三方依赖</strong>：MinIO, etcd, and Pulsar.</p> 
<p>Milvus cluster includes eight microservice components and three third-party dependencies: MinIO, etcd, and Pulsar.</p> 
<p><strong>Storage层有三个部分组成：</strong></p> 
<p>Meta store、Log broker、Object storage</p> 
<h3><a id="_198"></a>数据处理过程</h3> 
<p><strong>Reference</strong></p> 
<p>**数据写入和数据持久化：**https://milvus.io/blog/deep-dive-4-data-insertion-and-data-persistence.md</p> 
<p><strong>加载数据到内存（实时查询）</strong>：https://milvus.io/blog/deep-dive-5-real-time-query.md#Load-data-to-query-node</p> 
<p><strong>1、数据写入：可以为每个 collection 设置分片数量（每个分片对应一个虚拟通道 vchannel），数据将根据主键的哈希值写入相应的分片。</strong></p> 
<p>You can specify a number of shards for each collection in Milvus, each shard corresponding to a virtual channel (<em>vchannel</em>). Any incoming insert/delete request is routed to shards based on the hash value of primary key.</p> 
<p><strong>当segment满了，会自动出发data flush (512 MB by default)</strong></p> 
<ul><li>**【segment】**Milvus中用于数据存储的最小单元。</li><li>indexes are built on segments.</li><li><strong>Automatically flush segment data</strong> If the segment is full, the data coord automatically triggers data flush.</li></ul> 
<p><strong>三种类型的segment</strong></p> 
<ul><li>There are three types of segments with different status in Milvus: growing, sealed, and flushed segment.</li><li>growing：可以插入数据</li><li>sealed：不再插入数据 A sealed segment is a closed segment</li><li>flushed ：已经被写入磁盘 A flushed segment is a segment that has already been written into disk. A segment can only be flushed when the allocated space in a sealed segment expires.</li></ul> 
<img src="https://images2.imgbox.com/33/20/61RXvMTR_o.jpg" alt="image"> 
<p><strong>2、索引建立：index node 从segmeng中将数据加载到内存，建立索引后再写回 object storage</strong></p> 
<p>The index node <strong>loads</strong> the log snapshots to index from a segment (which is in object storage) <strong>to memory</strong> , deserializes the corresponding data and metadata to build index, serializes the index when index building completes, and writes it back to object storage.</p> 
<p><strong>向量检索维度太高，传统基于树的索引不再适应，取而代之的有基于聚类和基于图的索引。</strong></p> 
<p>Vectors cannot be efficiently indexed with traditional tree-based indexes due to their high-dimensional nature, but can be indexed with techniques that are more mature in this subject, such as cluster- or graph-based indexes.</p> 
<p><strong>3、查询：query node在加载到内存的segment中执行查询</strong></p> 
<p>A collection in Milvus is split into multiple segments, and <strong>the query nodes loads indexes by segment.</strong></p> 
<p><strong>每个query 节点只负责两个任务：按照 query coord 的指令加载或释放段；在本地段中进行搜索。</strong></p> 
<p>Each node is responsible only for two tasks: Load or release segments following the instructions from query coord; conduct a search within the local segments.</p> 
<p><strong>有两种类型的segment： growing segments 和sealed segments</strong></p> 
<p>There are two types of segments, growing segments (for incremental data), and sealed segments (for historical data). Query nodes subscribe to vchannel to receive recent updates (incremental data) as growing segments.</p> 
<img src="https://images2.imgbox.com/0e/80/owe1D9SD_o.png" alt="image"> 
<p><strong>两只类型的数据被加载到query node : growing segments 和sealed segments</strong></p> 
<p>There are two types of data that are loaded to query node: streaming data from <a href="https://milvus.io/docs/v2.0.x/four_layers.md#Log-broker" rel="nofollow">log broker</a>, and historical data from <a href="https://milvus.io/docs/v2.0.x/four_layers.md#Object-storage" rel="nofollow">object storage</a> (also called persistent storage below).</p> 
<p><strong>query node 1从持久化存储中加载历史数据S1，从订阅日志代理中的channel 1加载G1</strong></p> 
<p>In query node 1 in the image, historical data (batch data), are loaded via the allocated S1 and S3 from persistent storage. In the meanwhile, query node 1 loads incremental data (streaming data) by subscribing to channel 1 in log broker.</p> 
<h3><a id="_257"></a>存储结构（逻辑）</h3> 
<h4><a id="Collection_259"></a>Collection</h4> 
<p>In Milvus, a collection is equivalent to a table in a relational database management system (RDBMS)</p> 
<p>数据存储在集合（Collection）中，每个集合包含多个实体（Entity），每个实体包含多个字段（Field），但最重要的是向量字段（Vector Field）。</p> 
<p><strong>【分组存储】</strong>: 将不同类型的数据分别存储在不同的 collections 中。例如，一个用于存储图像特征向量的 collection，另一个用于存储文本特征向量的 collection。</p> 
<h4><a id="index_269"></a>index</h4> 
<p>索引构建由索引节点完成。为了避免数据更新时频繁构建索引，Milvus 中的集合被进一步划分为多个段，每个段都有自己的索引。</p> 
<ul><li><strong>检索加速</strong>: 索引通过优化数据存储和访问路径，提高查询速度，特别是在处理大规模向量数据时。</li><li><strong>数据结构优化</strong>: 不同的索引类型（如 IVF、HNSW 等）使用不同的技术来组织数据，从而提升检索效率和存储空间利用率。</li><li><strong>主要索引类型</strong>: 
  <ul><li><strong>FLAT</strong>: 精确搜索，适用于小数据集。</li><li><strong>IVF_FLAT</strong>: 倒排文件 + FLAT，平衡精度和速度。</li><li><strong>IVF_SQ8</strong>: 倒排文件 + 量化技术，提高速度和降低存储空间。</li><li><strong>IVF_PQ</strong>: 倒排文件 + 产品量化，适用于大规模数据集。</li><li><strong>HNSW</strong>: 小世界图结构，实现高效的近似最近邻搜索。</li></ul> </li></ul> 
<h4><a id="schema_282"></a>schema</h4> 
<p>Schema 用于定义集合的属性以及集合中字段。</p> 
<p>Milvus 一个集合中仅支持一个主键字段。</p> 
<p><strong>Reference:</strong> <a href="https://milvus.io/docs/schema.md" rel="nofollow">字段架构属性</a></p> 
<h4><a id="Field__290"></a>Field 数据类型</h4> 
<p>https://milvus.io/docs/schema.md</p> 
<h3><a id="_296"></a>组成部分</h3> 
<h4><a id="__298"></a>查询 节点</h4> 
<p><strong>【Query Node】</strong></p> 
<p>Milvus 将一个集合拆分成多个 Segment，查询节点按 Segment 加载索引。当搜索请求到达时，会广播到所有查询节点并发搜索。然后每个节点剪枝本地 Segment，搜索符合条件的向量，并缩减后返回搜索结果。</p> 
<h4><a id="Knowhere_304"></a>Knowhere</h4> 
<p>Knowhere 是 Milvus 的核心向量执行引擎，它整合了多个向量相似性搜索库，包括<a href="https://github.com/facebookresearch/faiss">Faiss</a>、<a href="https://github.com/nmslib/hnswlib">Hnswlib</a>和<a href="https://github.com/spotify/annoy">Annoy</a>。 Knowhere 还旨在支持异构计算。它控制在哪个硬件（CPU 或 GPU）上执行索引构建和搜索请求。</p> 
<h4><a id="ANNS__308"></a>ANNS 向量索引</h4> 
<p>Milvus 支持的向量索引类型大多采用近似最近邻搜索（ANNS）算法。相较于通常非常耗时的精确检索，ANNS 的核心思想不再局限于返回最精确的结果，而是只搜索目标的邻居。ANNS 通过在可接受的范围内牺牲准确率来提高检索效率。</p> 
<h3><a id="_316"></a>优缺点</h3> 
<p><strong>优点</strong>：</p> 
<ul><li>高性能：优化大规模数据和高并发场景。</li><li>多模态支持：处理多种数据类型的向量检索。</li><li>易用性和灵活性：通过提供多语言SDK和RESTful API，Milvus 确保了易用性和灵活性，满足开发者和企业在图像检索、推荐系统、自然语言处理等多种场景下的需求。</li><li>分布式架构：支持横向扩展，适合大规模数据。</li></ul> 
<p><strong>缺点</strong>：</p> 
<ul><li>部分高级功能依赖商业支持。</li><li>学习曲线较陡峭，需要一定的配置和管理经验。</li></ul> 
<h3><a id="Milvus__330"></a>Milvus 应用场景</h3> 
<p>使用场景：推荐系统、图像搜索、文本检索、视频检索等。</p> 
<p>Milvus 应用场景示例：电商平台的多模态商品搜索</p> 
<p><strong>场景描述</strong>： 某大型电商平台需要提供多模态商品搜索功能，包括基于图像、文本和视频的搜索。用户可以通过上传图片、输入文本描述或提供视频片段来查找相似的商品。平台需要处理海量商品数据，支持高并发的搜索请求，并提供实时更新和持久化存储。</p> 
<p><strong>具体应用</strong>：</p> 
<ol><li><strong>图像搜索</strong>：用户上传一张商品图片，系统通过预训练的图像识别模型（如 ResNet）提取图像特征向量。Milvus 存储和管理这些特征向量，通过向量相似性搜索返回最相似的商品。</li><li><strong>文本搜索</strong>：用户输入商品描述（如“红色连衣裙”），系统通过 NLP 模型（如 BERT）提取文本特征向量。Milvus 存储文本向量，并基于向量相似性搜索返回相关商品。</li><li><strong>视频搜索</strong>：用户上传一个视频片段，系统通过视频理解模型提取视频帧的特征向量。Milvus 存储和管理视频特征向量，通过向量相似性搜索返回与视频内容相关的商品。</li></ol> 
<p><strong>Milvus 的优势</strong>：</p> 
<ul><li><strong>多模态支持</strong>：能够同时处理图像、文本和视频的向量检索，提供统一的检索接口。</li><li><strong>分布式架构</strong>：支持横向扩展，适应电商平台海量商品数据和高并发的搜索请求。</li><li><strong>数据持久化</strong>：支持数据持久化存储，确保数据的安全性和可恢复性。</li></ul> 
<h3><a id="_352"></a>问答</h3> 
<p><strong>插入操作和查询操作是分离的吗？</strong></p> 
<p>插入操作和查询操作由两个相互独立的模块处理。从客户端的角度来看，当插入的数据进入消息队列时，插入操作就完成了。但是，插入的数据在加载到查询节点之前是不可搜索的。如果段大小未达到索引构建阈值（默认为 512 MB），Milvus 将诉诸暴力搜索，查询性能可能会降低。</p> 
<p><strong>Milvus 会将重复主键视为更新操作吗？</strong></p> 
<p>不会。Milvus 目前不支持更新操作，也不检查实体主键是否重复。您有责任确保实体主键是唯一的，如果不是，Milvus 可能包含多个具有重复主键的实体。</p> 
<h2><a id="FAISS_364"></a>FAISS</h2> 
<blockquote> 
 <p>Faiss is a library for efficient <strong>similarity search</strong> and <strong>clustering of dense vectors</strong>.</p> 
</blockquote> 
<p>C++ 开发的，一些有用的算法要在GPU上实现</p> 
<h3><a id="_370"></a>背景</h3> 
<p>FAISS（Facebook AI Similarity Search）是由 Facebook AI Research 开发的高效向量相似性搜索库，旨在处理大规模、高维向量数据的相似性搜索任务。</p> 
<h3><a id="_374"></a>功能</h3> 
<ul><li><strong>多种索引类型</strong>：支持 Flat、IVF（Inverted File）、HNSW（Hierarchical Navigable Small World）、PQ（Product Quantization）等索引。</li><li><strong>高效计算</strong>：优化了内存和计算资源的使用，支持大规模向量数据的高效检索。</li><li><strong>GPU 加速</strong>：支持 GPU 加速，显著提升大规模数据的检索性能。</li><li><strong>聚类和分类</strong>：支持 K-means 聚类、层次聚类等算法，以及最近邻分类等任务。</li><li><strong>多语言支持</strong>：提供 C++ 和 Python 接口，方便集成和使用。</li></ul> 
<h3><a id="_382"></a>架构</h3> 
<p>FAISS 的架构相对简单，由以下几个核心组件组成：</p> 
<ul><li><strong>Index</strong>：存储和管理向量数据，并提供高效的检索功能。根据不同的索引类型，Index 有不同的实现。</li><li><strong>Vector Storage</strong>：存储原始向量数据。</li><li><strong>Distance Computation</strong>：计算向量之间的相似性，支持多种相似性度量，如 L2 距离、内积等。</li></ul> 
<h3><a id="_390"></a>优缺点</h3> 
<p><strong>优点</strong>：</p> 
<ul><li>高性能：特别是在 GPU 环境下，FAISS 能够显著提升检索速度。</li><li>灵活性：支持多种索引类型和配置，适应不同应用场景。</li><li>社区支持：拥有大量用户和丰富的文档资源。</li></ul> 
<p><strong>缺点</strong>：</p> 
<ul><li>数据持久化和分布式支持较弱：主要适用于内存内检索，不适合超大规模数据的持久存储和分布式处理。</li><li>学习曲线较陡峭：需要一定的配置和使用经验，特别是在选择和配置索引类型时。</li></ul> 
<p>数据持久化和分布式支持较弱的原因</p> 
<ul><li><strong>设计目标</strong>：FAISS 的设计更关注于内存内计算的效率和性能，而不是数据存储和持久化。</li><li><strong>内存内操作</strong>：主要在内存中操作向量数据和索引，以保证高效的相似性搜索。</li><li><strong>缺乏内置的持久化机制</strong>：虽然支持手动保存和加载索引，但缺乏自动持久化和数据恢复机制。</li><li><strong>单节点设计</strong>：初衷是为单节点设计，缺乏内置的集群管理、负载均衡和分布式一致性支持。</li></ul> 
<p><strong>核心：它能够实现“高性能向量检索”的原因</strong></p> 
<p>数据类型：Faiss只使用32位浮点矩阵（32-bit floating）。</p> 
<p>Faiss 也能够指定数据类型，比如 IndexFlatL2、IndexHNSW、IndexIVF等二十来种类型</p> 
<h3><a id="FAISS__420"></a>FAISS 应用场景</h3> 
<p>使用场景：推荐系统、图像搜索、文本检索、生物信息学等。</p> 
<p>FAISS 应用场景示例：研究机构的大规模基因相似性分析</p> 
<p><strong>场景描述</strong>： 某研究机构需要进行大规模基因数据的相似性分析，比较数百万条基因序列之间的相似性，以发现潜在的基因关联和突变模式。系统需要高效的计算能力，以在合理时间内完成大规模的相似性计算。</p> 
<p><strong>具体应用</strong>：</p> 
<ol><li><strong>数据准备</strong>：研究人员将基因序列数据转化为高维特征向量（如通过 k-mer 频率、序列嵌入等方法）。</li><li><strong>索引构建</strong>：使用 FAISS 构建大规模基因特征向量的索引。研究机构可以利用 FAISS 的 IVF-PQ（Inverted File with Product Quantization）索引，以在保证高精度的同时显著减少内存占用。</li><li><strong>相似性搜索</strong>：通过 FAISS 的内存内计算和 GPU 加速，快速进行基因向量的相似性搜索，发现与目标基因序列最相似的其他基因。</li></ol> 
<p><strong>FAISS 的优势</strong>：</p> 
<ul><li><strong>高性能计算</strong>：通过 GPU 加速和高效的索引结构，能够在大规模数据集上实现极高的相似性搜索性能。</li><li><strong>内存内操作</strong>：适用于需要在内存中进行高效计算的场景，特别是在基因相似性分析中，能够在较短时间内处理大量数据。</li><li><strong>灵活性</strong>：支持多种索引类型和相似性度量，适应不同的数据特征和分析需求。</li></ul> 
<h2><a id="_440"></a>对比</h2> 
<p>Elasticsearch 是一个开源的分布式搜索和分析引擎，主要用于全文搜索、结构化搜索、日志和数据分析。尽管 Elasticsearch 强大且多功能，但在替代 Milvus 或 FAISS 用于向量检索方面有其局限性。</p> 
<h3><a id="Elasticsearch__444"></a>Elasticsearch 的优点</h3> 
<ol><li><strong>全文搜索和结构化搜索</strong>：Elasticsearch 在处理全文搜索、布尔查询和结构化数据搜索方面非常强大，提供了丰富的查询DSL。</li><li><strong>分布式架构</strong>：Elasticsearch 的分布式架构和水平扩展能力使其能够处理大规模数据集和高并发查询。</li><li><strong>数据持久化</strong>：内置数据持久化和索引恢复机制，保证数据的持久性和可恢复性。</li><li><strong>实时索引和查询</strong>：支持实时的数据索引和查询，非常适合日志分析和时间序列数据。</li><li><strong>生态系统和工具</strong>：拥有丰富的生态系统和工具，如 Kibana 用于数据可视化，Logstash 用于数据处理和管道。</li></ol> 
<h3><a id="Elasticsearch__452"></a>Elasticsearch 的向量检索功能</h3> 
<p>Elasticsearch 引入了向量检索功能，通过插件（如 Elasticsearch k-NN 插件）或直接支持向量字段（如 dense_vector 类型）来实现向量相似性搜索。以下是它在向量检索方面的特点：</p> 
<ol><li><strong>k-NN 插件</strong>：Elasticsearch 提供 k-NN 插件，支持基于 L2 距离和余弦相似度的向量检索。</li><li><strong>dense_vector 类型</strong>：允许将向量作为字段存储在索引中，并使用向量相似度进行搜索。</li><li><strong>集成性</strong>：可以与 Elasticsearch 的其他功能（如全文搜索、聚合分析）无缝集成。</li></ol> 
<h3><a id="Elasticsearch__Milvus__FAISS__462"></a>Elasticsearch 与 Milvus 和 FAISS 的对比</h3> 
<h5><a id="1__464"></a>1. 性能</h5> 
<ul><li><strong>FAISS</strong>：专为高效内存内向量检索设计，特别是在 GPU 环境下，能够提供极高的检索速度。</li><li><strong>Milvus</strong>：专注于高性能向量检索，支持多种索引类型和分布式架构，适合大规模、高并发的向量检索任务。</li><li><strong>Elasticsearch</strong>：在全文搜索和结构化搜索方面表现出色，但在高维向量检索性能上可能不如 FAISS 和 Milvus。尽管 k-NN 插件提供了向量检索功能，但在处理大规模高维向量数据时，性能可能不如专门设计的向量数据库。</li></ul> 
<h5><a id="2__470"></a>2. 数据持久化和分布式支持</h5> 
<ul><li><strong>Milvus</strong>：内置数据持久化和分布式支持，适合大规模数据管理和高并发访问。</li><li><strong>Elasticsearch</strong>：具备强大的数据持久化和分布式架构，能够处理大规模数据，并提供高可用性和数据恢复机制。</li><li><strong>FAISS</strong>：主要设计用于内存内检索，缺乏内置的数据持久化和分布式支持，需要额外的解决方案来实现这些功能。</li></ul> 
<h5><a id="3__476"></a>3. 多模态支持</h5> 
<ul><li><strong>Milvus</strong>：专为多模态向量检索设计，能够处理文本、图像、视频等多种数据类型。</li><li><strong>Elasticsearch</strong>：主要用于文本和结构化数据搜索，通过扩展支持向量检索，但在多模态数据处理上不如 Milvus 专业。</li></ul> 
<h5><a id="4__481"></a>4. 易用性和生态系统</h5> 
<ul><li><strong>Elasticsearch</strong>：拥有丰富的生态系统和工具，提供直观的界面和广泛的社区支持，易于集成和使用。</li><li><strong>Milvus 和 FAISS</strong>：需要一定的配置和使用经验，Milvus 提供了图形化管理界面和丰富的 API，而 FAISS 更适合有特定高性能需求的用户。</li></ul> 
<h5><a id="5_486"></a>5.适用场景</h5> 
<ul><li><strong>Milvus</strong> 特别适合于需要高效向量搜索的应用，如图像和视频检索、推荐系统、自然语言处理和生物信息学等。它在处理这些需要计算内容相似度的复杂查询时表现出色。</li><li><strong>Elasticsearch</strong> 广泛用于日志分析、全文搜索、数据可视化（通过Kibana）和近实时的数据分析等场景。它在处理文本数据和提供灵活、复杂的查询能力方面非常强大。</li><li><strong>Milvus</strong>适合高维向量检索（如图像、音频、文本嵌入等相似度搜索），因为它能提供高效的向量检索。Milvus在大规模数据集和复杂索引类型下，会**<u>倾向于将大量数据加载到内存</u>**中。这使得Milvus在处理高维向量检索时能提供低延迟和高吞吐量。</li><li><strong>Elasticsearch</strong>适合全文搜索或结构化数据检索，因为它**<u>通过倒排索引和缓存机制</u>**能在较低内存占用下提供高效的查询。</li></ul> 
<h3><a id="_497"></a>数据规模</h3> 
<p>具体来说，处理大规模高维向量数据时，Elasticsearch 的性能瓶颈会因数据规模和具体的检索需求而有所不同。然而，可以提供一些指导性的数据规模和考虑因素，帮助判断何时应该使用专门设计的向量数据库（如 Milvus 或 FAISS）而不是 Elasticsearch。</p> 
<h4><a id="_501"></a>判断数据规模的标准</h4> 
<h5><a id="1__503"></a>1. 向量维度</h5> 
<p>高维向量数据（如 128 维、256 维甚至更高）需要更多的计算资源来进行相似性计算。一般来说，当向量维度超过 100 时，就需要考虑优化计算性能的方案。</p> 
<h5><a id="2__507"></a>2. 向量数量</h5> 
<p>数据集的规模在向量数量上也是一个关键因素。如果数据集中有数百万到数亿的向量，Elasticsearch 在进行高效检索时可能会遇到性能瓶颈。在这种情况下，专门的向量数据库可能更适合。</p> 
<h5><a id="3__511"></a>3. 检索延迟和并发请求量</h5> 
<p>对于实时性要求高、并发请求量大的应用场景，Elasticsearch 的性能可能无法满足要求。专门的向量数据库（如 Milvus 和 FAISS）在设计上更适合这种高并发、低延迟的需求。</p> 
<h4><a id="_515"></a>具体规模建议</h4> 
<ol><li><strong>小规模数据集</strong>： 
  <ul><li><strong>向量数量</strong>：少于 100,000 个向量</li><li><strong>向量维度</strong>：少于 128 维</li><li><strong>适用性</strong>：Elasticsearch 可以很好地处理，并提供丰富的搜索功能。</li></ul> </li><li><strong>中等规模数据集</strong>： 
  <ul><li><strong>向量数量</strong>：100,000 到 1,000,000 个向量</li><li><strong>向量维度</strong>：128 到 256 维</li><li><strong>适用性</strong>：Elasticsearch 可以处理，但可能需要优化和调优索引配置。在高并发场景下可能出现性能问题。</li></ul> </li><li><strong>大规模数据集</strong>： 
  <ul><li><strong>向量数量</strong>：超过 1,000,000 个向量</li><li><strong>向量维度</strong>：超过 256 维</li><li><strong>适用性</strong>：需要考虑使用专门的向量数据库（如 Milvus 或 FAISS），以确保检索性能和系统可扩展性。</li></ul> </li></ol> 
<h2><a id="_530"></a>问答</h2> 
<p><strong>！！！传统数据库和向量数据库的显著区别在哪里？</strong></p> 
<p><u>传统数据库重IO，向量数据库则需要大量计算资源</u></p> 
<p><strong>传统数据库</strong>：</p> 
<ul><li><strong>重IO操作</strong>：传统数据库（如MySQL、PostgreSQL等）在进行数据读写时，主要依赖磁盘的输入输出操作（IO）。这些操作包括将数据从磁盘读取到内存或将数据从内存写入磁盘。</li><li><strong>关注磁盘IO和CPU使用率等指标</strong>：在管理和优化传统数据库时，管理员通常会关注磁盘IO（读写速度和延迟）和CPU使用率。这是因为这两个指标直接影响数据库的性能，尤其是在处理大量读写请求时。</li></ul> 
<p><strong>向量数据库</strong>：</p> 
<ul><li><strong>设计计算节点和存储时需要考虑CPU和GPU</strong>：向量数据库（如Milvus、FAISS等）在存储和检索向量（高维数据，如图像或文本的嵌入表示）时，不仅依赖CPU，还可能需要使用GPU。这是因为向量检索（如计算向量之间的相似度）通常需要大量的计算资源，尤其是在处理高维向量和大规模数据时，GPU能够显著提高计算效率</li></ul> 
<h2><a id="_545"></a>实践</h2> 
<h3><a id="Faiss_547"></a>Faiss</h3> 
<p>安装：<a href="https://github.com/facebookresearch/faiss/blob/main/INSTALL.md">INSTALL-FAISS</a></p> 
<p>使用</p> 
<pre><code class="prism language-python"><span class="token comment"># 构建索引</span>
<span class="token keyword">import</span> faiss                   <span class="token comment"># make faiss available</span>
index <span class="token operator">=</span> faiss<span class="token punctuation">.</span>IndexFlatL2<span class="token punctuation">(</span>d<span class="token punctuation">)</span>   <span class="token comment"># build the index</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>index<span class="token punctuation">.</span>is_trained<span class="token punctuation">)</span>
index<span class="token punctuation">.</span>add<span class="token punctuation">(</span>xb<span class="token punctuation">)</span>                  <span class="token comment"># add vectors to the index</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>index<span class="token punctuation">.</span>ntotal<span class="token punctuation">)</span>

<span class="token comment"># 搜索</span>
k <span class="token operator">=</span> <span class="token number">4</span>                          <span class="token comment"># we want to see 4 nearest neighbors</span>
D<span class="token punctuation">,</span> I <span class="token operator">=</span> index<span class="token punctuation">.</span>search<span class="token punctuation">(</span>xb<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> k<span class="token punctuation">)</span> <span class="token comment"># sanity check 输入为query embeddig和neighbors数</span>
</code></pre> 
<h4><a id="API_Reference_566"></a>API Reference</h4> 
<p>https://faiss.ai/</p> 
<p>https://ai.meta.com/tools/faiss/</p> 
<p>https://github.com/facebookresearch/faiss/wiki</p> 
<p>https://github.com/facebookresearch/faiss/wiki/Faiss-indexes</p> 
<p>example Reference</p> 
<p><a href="https://medium.com/loopio-tech/how-to-use-faiss-to-build-your-first-similarity-search-bf0f708aa772#id_token=eyJhbGciOiJSUzI1NiIsImtpZCI6IjY3NGRiYmE4ZmFlZTY5YWNhZTFiYzFiZTE5MDQ1MzY3OGY0NzI4MDMiLCJ0eXAiOiJKV1QifQ.eyJpc3MiOiJodHRwczovL2FjY291bnRzLmdvb2dsZS5jb20iLCJhenAiOiIyMTYyOTYwMzU4MzQtazFrNnFlMDYwczJ0cDJhMmphbTRsamRjbXMwMHN0dGcuYXBwcy5nb29nbGV1c2VyY29udGVudC5jb20iLCJhdWQiOiIyMTYyOTYwMzU4MzQtazFrNnFlMDYwczJ0cDJhMmphbTRsamRjbXMwMHN0dGcuYXBwcy5nb29nbGV1c2VyY29udGVudC5jb20iLCJzdWIiOiIxMTMwMDg3MjE5OTgzODY2MzIzOTMiLCJlbWFpbCI6ImNoZW5jYXJlMTJAZ21haWwuY29tIiwiZW1haWxfdmVyaWZpZWQiOnRydWUsIm5iZiI6MTcxNzY1MzgwOSwibmFtZSI6IkNvbmcgQ2hlbiIsInBpY3R1cmUiOiJodHRwczovL2xoMy5nb29nbGV1c2VyY29udGVudC5jb20vYS9BQ2c4b2NJTVBTRTJ4UEVFZGNHRmVjcGdhMVpTbmx1eFZFdjFpaS00aUhUbl9nenBqY3U0N1E9czk2LWMiLCJnaXZlbl9uYW1lIjoiQ29uZyIsImZhbWlseV9uYW1lIjoiQ2hlbiIsImlhdCI6MTcxNzY1NDEwOSwiZXhwIjoxNzE3NjU3NzA5LCJqdGkiOiJkOGQzMGE5MmVmOGMyY2ZlNjkxYmZhMjRjMjE1NThlZWQxYWM0OTgwIn0.uqb1cUrZvFx7NaOwBoZbxX3b-9Tp5bF6e0lnMB27NXroySiXGVdeX9DOa8yrItvI5Bk-DnJ99MgeQYXI0Kf5xQBnrDoMr9dNmIyVMr832DCpK7FykqVJlN3NrVH7H8DINE2vW7mrSZX_XODK852VEDiOIhfNsDNXlvJ0veWvPU1fq-pNC_OFHko8apDOFl2aFe2Cz_qVg9TLYuCQPltcAdMkBm_4oOdHD2oe5Az4lqFeJBuRGKdpiulOPCyPPhXQ1BzvHdZFS15AZlch8qVU8LvF39z-vYc6fqRa9fodDMPAOghGCOYDrFWxVO7lIOLTwqttvFKUNt_ceZnQkvYvNw" rel="nofollow">How to Use FAISS to Build Your First Similarity Search-medium</a></p> 
<h3><a id="Milvus_584"></a>Milvus</h3> 
<p>Reference</p> 
<p><a href="https://milvus.io/docs/quickstart.md" rel="nofollow">milvus.io/docs</a></p> 
<p><a href="https://zhuanlan.zhihu.com/p/666930387" rel="nofollow">Milvus性能优化提速之道：揭秘优化技巧，避开十大误区- 知乎</a></p> 
<p>https://github.com/milvus-io/pymilvus/tree/2.2/examples</p> 
<p>在 Milvus 中，<code>collection</code> 和 <code>index</code> 是两个核心概念，它们分别负责数据存储和数据检索的组织和优化。</p> 
<ul><li><strong>Collection 与 Index 的关系</strong>: 
  <ul><li>每个 collection 可以有多个字段，其中一个字段通常是向量字段。为了加速对该向量字段的检索，可以为其创建索引。</li><li>索引是基于 collection 中的向量数据构建的，创建索引后，检索操作会显著加速。</li></ul> </li></ul> 
<h4><a id="_604"></a>示例应用</h4> 
<ol><li><strong>创建 Collection</strong>:</li></ol> 
<pre><code class="prism language-python"><span class="token keyword">from</span> pymilvus <span class="token keyword">import</span> CollectionSchema<span class="token punctuation">,</span> FieldSchema<span class="token punctuation">,</span> DataType<span class="token punctuation">,</span> Collection

<span class="token comment"># 定义字段</span>
id_field <span class="token operator">=</span> FieldSchema<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">"id"</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>DataType<span class="token punctuation">.</span>INT64<span class="token punctuation">,</span> is_primary<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
vector_field <span class="token operator">=</span> FieldSchema<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">"vector"</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>DataType<span class="token punctuation">.</span>FLOAT_VECTOR<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">)</span>

<span class="token comment"># 定义 schema</span>
schema <span class="token operator">=</span> CollectionSchema<span class="token punctuation">(</span>fields<span class="token operator">=</span><span class="token punctuation">[</span>id_field<span class="token punctuation">,</span> vector_field<span class="token punctuation">]</span><span class="token punctuation">,</span> description<span class="token operator">=</span><span class="token string">"example collection"</span><span class="token punctuation">)</span>

<span class="token comment"># 创建 collection</span>
collection <span class="token operator">=</span> Collection<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">"example_collection"</span><span class="token punctuation">,</span> schema<span class="token operator">=</span>schema<span class="token punctuation">)</span>
</code></pre> 
<ol start="2"><li><strong>创建 Index</strong>:</li></ol> 
<pre><code class="prism language-python">index_params <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token string">"index_type"</span><span class="token punctuation">:</span> <span class="token string">"IVF_FLAT"</span><span class="token punctuation">,</span>
    <span class="token string">"params"</span><span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">"nlist"</span><span class="token punctuation">:</span> <span class="token number">128</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token string">"metric_type"</span><span class="token punctuation">:</span> <span class="token string">"L2"</span>
<span class="token punctuation">}</span>
collection<span class="token punctuation">.</span>create_index<span class="token punctuation">(</span>field_name<span class="token operator">=</span><span class="token string">"vector"</span><span class="token punctuation">,</span> index_params<span class="token operator">=</span>index_params<span class="token punctuation">)</span>
</code></pre> 
<p>通过理解 collection 和 index 的概念及其功能，可以更好地在 Milvus 中组织和优化向量数据的存储和检索。</p> 
<h4><a id="__collection_637"></a>查看 collection</h4> 
<pre><code class="prism language-python"><span class="token comment"># 查看index</span>
<span class="token keyword">from</span> pymilvus <span class="token keyword">import</span> Collection
collection <span class="token operator">=</span> Collection<span class="token punctuation">(</span><span class="token string">"book"</span><span class="token punctuation">)</span>  <span class="token comment"># Get an existing collection.</span>

<span class="token comment"># 查看collection</span>
collection<span class="token punctuation">.</span>schema                <span class="token comment"># Return the schema.CollectionSchema of the collection.</span>
collection<span class="token punctuation">.</span>description           <span class="token comment"># Return the description of the collection.</span>
collection<span class="token punctuation">.</span>name                  <span class="token comment"># Return the name of the collection.</span>
collection<span class="token punctuation">.</span>is_empty              <span class="token comment"># Return the boolean value that indicates if the collection is empty.</span>
collection<span class="token punctuation">.</span>num_entities          <span class="token comment"># Return the number of entities in the collection.</span>
collection<span class="token punctuation">.</span>primary_field         <span class="token comment"># Return the schema.FieldSchema of the primary key field.</span>
collection<span class="token punctuation">.</span>partitions            <span class="token comment"># Return the list[Partition] object.</span>
collection<span class="token punctuation">.</span>indexes               <span class="token comment"># Return the list[Index] object.</span>
collection<span class="token punctuation">.</span>properties       <span class="token comment"># Return the expiration time of data in the collection.</span>
</code></pre> 
<h4><a id="_collection_656"></a>加载到内存 collection</h4> 
<p>Milvus 中的所有搜索和查询操作都是在内存中执行的。因此在执行搜索或查询之前需要将集合加载到内存。</p> 
<p>这个加载过程发生在Milvus服务所在的服务器上，而不是客户端。</p> 
<pre><code class="prism language-python"><span class="token comment"># Get an existing collection.</span>
collection <span class="token operator">=</span> Collection<span class="token punctuation">(</span><span class="token string">"book"</span><span class="token punctuation">)</span>      
collection<span class="token punctuation">.</span>load<span class="token punctuation">(</span>replica_number<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>

utility<span class="token punctuation">.</span>loading_progress<span class="token punctuation">(</span><span class="token string">"book"</span><span class="token punctuation">)</span>
<span class="token comment"># Output: {'loading_progress': 100%}</span>
</code></pre> 
<p>在搜索或查询之后从内存中释放集合以减少内存使用量。</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> pymilvus <span class="token keyword">import</span> Collection
collection <span class="token operator">=</span> Collection<span class="token punctuation">(</span><span class="token string">"book"</span><span class="token punctuation">)</span>      <span class="token comment"># Get an existing collection.</span>
collection<span class="token punctuation">.</span>release<span class="token punctuation">(</span><span class="token punctuation">)</span>	
</code></pre> 
<h4><a id="_collection_679"></a>数据写入和更新 collection</h4> 
<pre><code class="prism language-python"><span class="token keyword">from</span> pymilvus <span class="token keyword">import</span> Collection
collection <span class="token operator">=</span> Collection<span class="token punctuation">(</span><span class="token string">"book"</span><span class="token punctuation">)</span>      <span class="token comment"># Get an existing collection.</span>
mr <span class="token operator">=</span> collection<span class="token punctuation">.</span>insert<span class="token punctuation">(</span>data<span class="token punctuation">)</span>

<span class="token comment"># 批量插入 API</span>
<span class="token comment"># 使用 NumPy 数组将数据集的每一列组织到单独的文件中。在这种情况下，使用每列的字段名称来命名 NumPy 文件。</span>
<span class="token keyword">from</span> pymilvus <span class="token keyword">import</span> utility
task_id <span class="token operator">=</span> utility<span class="token punctuation">.</span>do_bulk_insert<span class="token punctuation">(</span>
    collection_name<span class="token operator">=</span><span class="token string">"book"</span><span class="token punctuation">,</span>
    partition_name<span class="token operator">=</span><span class="token string">"2022"</span><span class="token punctuation">,</span>
    files<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"book_id.npy"</span><span class="token punctuation">,</span> <span class="token string">"word_count.npy"</span><span class="token punctuation">,</span> <span class="token string">"book_intro.npy"</span><span class="token punctuation">,</span> <span class="token string">"book_props.npy"</span><span class="token punctuation">]</span>
<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">flush_collection</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">""" 刷新数据 """</span>
    self<span class="token punctuation">.</span>collection<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 这个方法用于将 collection 加载到内存中，以便进行查询，如果 collection 已经在内存中，则此操作不会重复加载。</span>
    self<span class="token punctuation">.</span>collection<span class="token punctuation">.</span>flush<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 这个方法用于将内存中的数据刷新到磁盘上，确保所有在内存中的变更（例如插入或删除操作）都持久化到磁盘。</span>
    logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">"Success flush collection"</span><span class="token punctuation">)</span>
</code></pre> 
<h4><a id="Milvus__702"></a>Milvus 刷新数据到磁盘</h4> 
<p>当插入的数据加载到消息队列中时，Milvus 返回成功，但数据还未刷入磁盘。此时，Milvus 的数据节点会将消息队列中的数据以增量日志的形式写入持久化存储。如果<code>flush()</code>调用，则强制数据节点立即将消息队列中的所有数据写入持久化存储。如果您**<u>需要在插入后立即搜索数据</u>**，则可以在数据插入后调用该<code>flush()</code>方法。</p> 
<blockquote> 
 <p>Milvus 会自动触发该<code>flush()</code>操作。大多数情况下，无需手动调用此操作。</p> 
</blockquote> 
<p>如果需要**<u>全量更新一个 Collection</u>** 的数据，<strong>推荐使用新建表 + 导入数据 + Alias 切换的方案</strong></p> 
<h4><a id="MilvusHelper_712"></a>MilvusHelper</h4> 
<pre><code class="prism language-python"><span class="token keyword">import</span> os
<span class="token keyword">import</span> sys
<span class="token keyword">from</span> loguru <span class="token keyword">import</span> logger
<span class="token keyword">from</span> pymilvus <span class="token keyword">import</span> <span class="token punctuation">(</span>
    connections<span class="token punctuation">,</span>
    FieldSchema<span class="token punctuation">,</span> CollectionSchema<span class="token punctuation">,</span> DataType<span class="token punctuation">,</span>
    Collection<span class="token punctuation">,</span> utility<span class="token punctuation">,</span>
    BulkInsertState
<span class="token punctuation">)</span>

<span class="token keyword">class</span> <span class="token class-name">MilvusHandler</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>
            self<span class="token punctuation">,</span>
            host<span class="token operator">=</span>MILVUS_HOST<span class="token punctuation">,</span>
            port<span class="token operator">=</span>MILVUS_PORT
    <span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>host <span class="token operator">=</span> host
        self<span class="token punctuation">.</span>port <span class="token operator">=</span> port
        self<span class="token punctuation">.</span>connect<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">connect</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        connections<span class="token punctuation">.</span>connect<span class="token punctuation">(</span><span class="token string">"default"</span><span class="token punctuation">,</span> host<span class="token operator">=</span>self<span class="token punctuation">.</span>host<span class="token punctuation">,</span> port<span class="token operator">=</span>self<span class="token punctuation">.</span>port<span class="token punctuation">)</span>
        logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">"Successfully connected to Milvus"</span><span class="token punctuation">)</span>

    <span class="token decorator annotation punctuation">@staticmethod</span>
    <span class="token keyword">def</span> <span class="token function">disconnect</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 断开连接</span>
        connections<span class="token punctuation">.</span>disconnect<span class="token punctuation">(</span><span class="token string">"default"</span><span class="token punctuation">)</span>
        logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">"Successfully disconnected from Milvus"</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">create_collection</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> collection_name<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> collection_dim<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 初始化 Collection 对象</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>has_collection<span class="token punctuation">(</span>collection_name<span class="token operator">=</span>collection_name<span class="token punctuation">)</span><span class="token punctuation">:</span>
            collection <span class="token operator">=</span> Collection<span class="token punctuation">(</span>name<span class="token operator">=</span>collection_name<span class="token punctuation">)</span>
            logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Connected to existing collection:</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>collection_name<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            fields <span class="token operator">=</span> <span class="token punctuation">[</span>
                FieldSchema<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">"id"</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>DataType<span class="token punctuation">.</span>VARCHAR<span class="token punctuation">,</span> description<span class="token operator">=</span><span class="token string">"text name"</span><span class="token punctuation">,</span> max_length<span class="token operator">=</span><span class="token number">500</span><span class="token punctuation">,</span> is_primary<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                            auto_id<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                FieldSchema<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">"vec"</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>DataType<span class="token punctuation">.</span>FLOAT_VECTOR<span class="token punctuation">,</span> description<span class="token operator">=</span><span class="token string">"text embedding vectors"</span><span class="token punctuation">,</span>
                            dim<span class="token operator">=</span>collection_dim<span class="token punctuation">)</span>
            <span class="token punctuation">]</span>
            schema <span class="token operator">=</span> CollectionSchema<span class="token punctuation">(</span>fields<span class="token punctuation">,</span> <span class="token string">"Collection for text embeddings"</span><span class="token punctuation">)</span>
            collection <span class="token operator">=</span> Collection<span class="token punctuation">(</span>name<span class="token operator">=</span>collection_name<span class="token punctuation">,</span> schema<span class="token operator">=</span>schema<span class="token punctuation">,</span> using<span class="token operator">=</span><span class="token string">'default'</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>create_index<span class="token punctuation">(</span>collection<span class="token operator">=</span>collection<span class="token punctuation">,</span> filed_name<span class="token operator">=</span><span class="token string">"vec"</span><span class="token punctuation">)</span>
            logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Successfully created collection :</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>collection_name<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> collection

    <span class="token decorator annotation punctuation">@staticmethod</span>
    <span class="token keyword">def</span> <span class="token function">create_alias</span><span class="token punctuation">(</span>collection_name<span class="token punctuation">,</span> alias<span class="token punctuation">)</span><span class="token punctuation">:</span>
        utility<span class="token punctuation">.</span>create_alias<span class="token punctuation">(</span>collection_name<span class="token operator">=</span>collection_name<span class="token punctuation">,</span> alias<span class="token operator">=</span>alias<span class="token punctuation">)</span>

    <span class="token decorator annotation punctuation">@staticmethod</span>
    <span class="token keyword">def</span> <span class="token function">drop_alias</span><span class="token punctuation">(</span>alias<span class="token punctuation">)</span><span class="token punctuation">:</span>
        utility<span class="token punctuation">.</span>drop_alias<span class="token punctuation">(</span>alias<span class="token operator">=</span>alias<span class="token punctuation">)</span>

    <span class="token decorator annotation punctuation">@staticmethod</span>
    <span class="token keyword">def</span> <span class="token function">drop_collection</span><span class="token punctuation">(</span>collection_name<span class="token punctuation">)</span><span class="token punctuation">:</span>
        utility<span class="token punctuation">.</span>drop_collection<span class="token punctuation">(</span>collection_name<span class="token punctuation">)</span>
        logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Dropped collection: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>collection_name<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">has_collection</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> collection_name<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> utility<span class="token punctuation">.</span>has_collection<span class="token punctuation">(</span>collection_name<span class="token punctuation">)</span>

    <span class="token decorator annotation punctuation">@staticmethod</span>
    <span class="token keyword">def</span> <span class="token function">list_collections</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        collections <span class="token operator">=</span> utility<span class="token punctuation">.</span>list_collections<span class="token punctuation">(</span><span class="token punctuation">)</span>
        logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"List of collections: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>collections<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> collections

    <span class="token decorator annotation punctuation">@staticmethod</span>
    <span class="token keyword">def</span> <span class="token function">create_index</span><span class="token punctuation">(</span>collection<span class="token punctuation">,</span> filed_name<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> index_param<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> index_param<span class="token punctuation">:</span>
            index_param <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
                <span class="token string">"index_type"</span><span class="token punctuation">:</span> <span class="token string">"FLAT"</span><span class="token punctuation">,</span>
                <span class="token string">"metric_type"</span><span class="token punctuation">:</span> <span class="token string">"IP"</span><span class="token punctuation">,</span>
                <span class="token string">"params"</span><span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span>
            <span class="token punctuation">}</span>
        collection<span class="token punctuation">.</span>create_index<span class="token punctuation">(</span>filed_name<span class="token punctuation">,</span> index_param<span class="token punctuation">)</span>
        logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Success create index"</span></span><span class="token punctuation">)</span>

    <span class="token decorator annotation punctuation">@staticmethod</span>
    <span class="token keyword">def</span> <span class="token function">drop_index</span><span class="token punctuation">(</span>collection<span class="token punctuation">)</span><span class="token punctuation">:</span>
        collection<span class="token punctuation">.</span>drop_index<span class="token punctuation">(</span><span class="token punctuation">)</span>
        logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Success drop index"</span></span><span class="token punctuation">)</span>

    <span class="token decorator annotation punctuation">@staticmethod</span>
    <span class="token keyword">def</span> <span class="token function">load_collection</span><span class="token punctuation">(</span>collection<span class="token punctuation">)</span><span class="token punctuation">:</span>
        collection<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token decorator annotation punctuation">@staticmethod</span>
    <span class="token keyword">def</span> <span class="token function">flush_collection</span><span class="token punctuation">(</span>collection<span class="token punctuation">)</span><span class="token punctuation">:</span>
        collection<span class="token punctuation">.</span>flush<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token decorator annotation punctuation">@staticmethod</span>
    <span class="token keyword">def</span> <span class="token function">load_and_flush_collection</span><span class="token punctuation">(</span>collection<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">""" 刷新数据 """</span>
        <span class="token comment"># 测试加载速度</span>
        <span class="token keyword">import</span> time
        start_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
        collection<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token punctuation">)</span>
        end_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Loading time: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>end_time <span class="token operator">-</span> start_time<span class="token punctuation">}</span></span><span class="token string"> seconds"</span></span><span class="token punctuation">)</span>
        collection<span class="token punctuation">.</span>flush<span class="token punctuation">(</span><span class="token punctuation">)</span>
        logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">"Success flush collection"</span><span class="token punctuation">)</span>

    <span class="token decorator annotation punctuation">@staticmethod</span>
    <span class="token keyword">def</span> <span class="token function">release_collection</span><span class="token punctuation">(</span>collection<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""释放内存中加载的collection"""</span>
        collection<span class="token punctuation">.</span>release<span class="token punctuation">(</span><span class="token punctuation">)</span>
        logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">"Success release collection"</span><span class="token punctuation">)</span>

    <span class="token decorator annotation punctuation">@staticmethod</span>
    <span class="token keyword">def</span> <span class="token function">compact_collection</span><span class="token punctuation">(</span>collection<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""合并segement"""</span>
        collection<span class="token punctuation">.</span>compact<span class="token punctuation">(</span><span class="token punctuation">)</span>
        logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f" release collection status：</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>collection<span class="token punctuation">.</span>get_compaction_state<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

    <span class="token decorator annotation punctuation">@staticmethod</span>
    <span class="token keyword">def</span> <span class="token function">insert_entity</span><span class="token punctuation">(</span>collection<span class="token punctuation">,</span> entities<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        单次写入小于 10MB 以下，建议选择流式写入
        """</span>
        <span class="token comment"># entities = [</span>
        <span class="token comment">#     {"name": "id", "values": ids, "type": DataType.VARCHAR},</span>
        <span class="token comment">#     {"name": "vec", "values": vectors, "type": DataType.FLOAT_VECTOR}</span>
        <span class="token comment"># ]</span>
        mr <span class="token operator">=</span> collection<span class="token punctuation">.</span>insert<span class="token punctuation">(</span>entities<span class="token punctuation">)</span>
        <span class="token comment"># (insert count: 10, delete count: 0, upsert count: 0, timestamp: {self._timestamp}, success count: {self.succ_count}, err count: {self.err_count})</span>
        logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Data inserted successfully.</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>mr<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> mr

    <span class="token decorator annotation punctuation">@staticmethod</span>
    <span class="token keyword">def</span> <span class="token function">bulk_insert</span><span class="token punctuation">(</span>collection_name<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> files<span class="token punctuation">:</span> <span class="token builtin">list</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"id.npy"</span><span class="token punctuation">,</span> <span class="token string">"vec.npy"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
         BulkInsert 不会对查询性能造成太大的影响
        :param collection_name:
        :param files:
        :return:
        """</span>
        task_id <span class="token operator">=</span> utility<span class="token punctuation">.</span>do_bulk_insert<span class="token punctuation">(</span>
            collection_name<span class="token operator">=</span>collection_name<span class="token punctuation">,</span>
            files<span class="token operator">=</span>files
        <span class="token punctuation">)</span>

        task <span class="token operator">=</span> utility<span class="token punctuation">.</span>get_bulk_insert_state<span class="token punctuation">(</span>task_id<span class="token operator">=</span>task_id<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Task state:"</span><span class="token punctuation">,</span> task<span class="token punctuation">.</span>state_name<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Imported files:"</span><span class="token punctuation">,</span> task<span class="token punctuation">.</span>files<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Collection name:"</span><span class="token punctuation">,</span> task<span class="token punctuation">.</span>collection_name<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Partition name:"</span><span class="token punctuation">,</span> task<span class="token punctuation">.</span>partition_name<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Start time:"</span><span class="token punctuation">,</span> task<span class="token punctuation">.</span>create_time_str<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Imported row count:"</span><span class="token punctuation">,</span> task<span class="token punctuation">.</span>row_count<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Entities ID array generated by this task:"</span><span class="token punctuation">,</span> task<span class="token punctuation">.</span>ids<span class="token punctuation">)</span>

        <span class="token keyword">if</span> task<span class="token punctuation">.</span>state <span class="token operator">==</span> BulkInsertState<span class="token punctuation">.</span>ImportFailed<span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Failed reason:"</span><span class="token punctuation">,</span> task<span class="token punctuation">.</span>failed_reason<span class="token punctuation">)</span>

    <span class="token decorator annotation punctuation">@staticmethod</span>
    <span class="token keyword">def</span> <span class="token function">delete_entity</span><span class="token punctuation">(</span>collection<span class="token punctuation">,</span> ids<span class="token punctuation">)</span><span class="token punctuation">:</span>
        expr <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f'id in </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>ids<span class="token punctuation">}</span></span><span class="token string">'</span></span>
        dr <span class="token operator">=</span> collection<span class="token punctuation">.</span>delete<span class="token punctuation">(</span>expr<span class="token punctuation">)</span>
        logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Data deleted successfully.</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>dr<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> dr

    <span class="token keyword">def</span> <span class="token function">update_entity</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> ids<span class="token punctuation">,</span> collection<span class="token punctuation">,</span> vectors<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>delete_entity<span class="token punctuation">(</span>collection<span class="token punctuation">,</span> ids<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>insert_entity<span class="token punctuation">(</span>collection<span class="token punctuation">,</span> entities<span class="token operator">=</span><span class="token punctuation">[</span>ids<span class="token punctuation">,</span> vectors<span class="token punctuation">]</span><span class="token punctuation">)</span>
        logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Data update successfully"</span></span><span class="token punctuation">)</span>

    <span class="token decorator annotation punctuation">@staticmethod</span>
    <span class="token keyword">def</span> <span class="token function">get_entity_num</span><span class="token punctuation">(</span>collection<span class="token punctuation">)</span><span class="token punctuation">:</span>
        entity_num <span class="token operator">=</span> collection<span class="token punctuation">.</span>num_entities
        logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Number of entities: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>entity_num<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> entity_num

    <span class="token decorator annotation punctuation">@staticmethod</span>
    <span class="token keyword">def</span> <span class="token function">search</span><span class="token punctuation">(</span>collection<span class="token punctuation">,</span> query_vector<span class="token punctuation">,</span> top_k<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

        <span class="token comment"># "param": {"metric_type":  "IP", "params": {"nprobe": _NPROBE}},</span>
        search_param <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
            <span class="token string">"data"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>query_vector<span class="token punctuation">]</span><span class="token punctuation">,</span>
            <span class="token string">"anns_field"</span><span class="token punctuation">:</span> <span class="token string">"vec"</span><span class="token punctuation">,</span>
            <span class="token string">"param"</span><span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">"metric_type"</span><span class="token punctuation">:</span> <span class="token string">"IP"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
            <span class="token string">"limit"</span><span class="token punctuation">:</span> top_k<span class="token punctuation">,</span>
            <span class="token string">"expr"</span><span class="token punctuation">:</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
            <span class="token string">"output_fields"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"id"</span><span class="token punctuation">]</span><span class="token punctuation">}</span>

        results <span class="token operator">=</span> collection<span class="token punctuation">.</span>search<span class="token punctuation">(</span><span class="token operator">**</span>search_param<span class="token punctuation">)</span>

        <span class="token comment"># results[0].ids</span>
        <span class="token comment">#</span>
        <span class="token comment"># results[0].distances</span>
        <span class="token comment">#</span>
        <span class="token comment"># hit = results[0][0]</span>
        <span class="token comment"># hit.entity.get('title')</span>
        <span class="token keyword">return</span> results

</code></pre> 
<ul><li><code>collection.num_entities</code> 返回的是逻辑上的总实体数，包括了已删除但尚未物理移除的实体。<code>compaction</code> 操作会合并数据段，并在此过程中移除标记为删除的数据。当前存在问题：删除未被计算 https://github.com/milvus-io/milvus/issues/17193</li></ul> 
<h3><a id="Milvus_Lite__Milvus_916"></a>Milvus Lite 和 Milvus</h3> 
<ol><li> <p><strong>架构</strong>：</p> 
  <ul><li><strong>Milvus</strong>：采用了分布式架构，适用于需要处理大规模数据和高并发请求的场景。它能够分布在多个节点上，提供高可用性和扩展性。</li><li><strong>Milvus Lite</strong>：是一个轻量级版本，适用于单节点部署，主要面向开发、测试和小规模应用场景。</li></ul> </li><li> <p><strong>资源需求</strong>：</p> 
  <ul><li><strong>Milvus</strong>：由于其分布式架构，通常需要更多的计算和存储资源来运行，需要集群环境和专业的运维支持。</li><li><strong>Milvus Lite</strong>：设计为轻量级，占用资源少，可以在单机上运行，适合资源有限的环境。</li></ul> </li><li> <p><strong>性能和扩展性</strong>：</p> 
  <ul><li><strong>Milvus</strong>：在性能和扩展性方面更强大，能够处理大规模数据和高并发请求，可以根据需要水平扩展集群。</li><li><strong>Milvus Lite</strong>：性能和扩展性有限，主要适用于小规模数据和低并发请求的场景。</li></ul> </li><li> <p><strong>运维复杂度</strong>：</p> 
  <ul><li><strong>Milvus</strong>：需要专业的运维管理，包括节点管理、负载均衡和故障恢复等。</li><li><strong>Milvus Lite</strong>：运维相对简单，适合开发者个人或小团队进行开发和测试。</li></ul> </li></ol> 
<p><strong>适用场景</strong></p> 
<ul><li><strong>Milvus</strong>：适用于需要处理大量数据、复杂查询以及高并发请求的大型生产环境，如搜索引擎、大数据分析、推荐系统等。</li><li><strong>Milvus Lite</strong>：适用于开发、测试、小规模应用场景或资源受限的环境，适合个人开发者、小团队、初创企业进行向量检索相关的开发和测试。</li></ul>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/faa145d997b9d99ff3d09acdc4a79a12/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Python for循环中的引用传递和值传递</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/e0d8c2e6a52657fd7be6fb12026df6d3/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【AI基础】租用云GPU之autoDL部署大模型ollama&#43;llama3</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>