<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>python作品 运动模糊图像修复算法(上) - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/15ba2fa16554120bac1c3f3b8a039a03/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="python作品 运动模糊图像修复算法(上)">
  <meta property="og:description" content="python作品 运动模糊图像修复算法(上)-CSDN博客 python作品 运动模糊图像修复算法(下)-CSDN博客 1.1研究背景和意义 由于各种不确定因素的影响，我们通过设备采集到的图像难免会产生不同程度的失真，图像的运动模糊就是一种典型的失真现象。运动模糊是指图像中的移动效果，通常会出现在长时间曝光或被拍摄物体快速移动的情形中，由于在拍摄时相机与被拍摄物体之间发生了相对位移，图像上就会出现运动模糊。图像作为重要的信息载体，让受众得到更加直观、迅速、高效、客观的视觉化信息。鉴于图像在传播信息时的优点与重要性，图像在各行各业中都扮演着重要的角色。如今，图像识别被广泛的应用于各个领域，如智能交通中的车牌识别，车辆识别等等，运动模糊会严重的影响识别效率。
由运动模糊的原理可知，通过缩短曝光时间可以减少运动模糊，但代价是噪声更高，对成像传感器质量和光线要求更高。这种方法并不总是可行或者所需成本较大，因此在后期处理阶段进行图像去模糊是一种重要的替代方案。
目前市场上，用户在线实时提交处理展示的web端图片处理网站较少，并且目前的图片处理功能中并没有运动图像去模糊的
1.2研究现状 目前，图像去模糊领域的研究主要包括数据集的构建和去模糊算法的研究等方面。（1）在机器学习领域中，数据集质量的高低直接影响实验结果的好坏。而相较于其他图像退化复原问题，图像去模糊的数据集更难获得，在现实环境中很难拍摄到各种因素完全相同的一对清晰图像和模糊图像。在数据集方面，现有的图像去模糊数据集中有一类是通过算法合成的模糊数据集，这类数据集在已获得的清晰图像上加以不同运动模糊模拟算法，得到相应的人工合成的模糊图像。另一种合成方法是用算法模拟生成运动轨迹，根据运动轨迹生成模糊核。（2）图像去模糊中因为模糊核通常是未知的。非盲目去模糊算法指在模糊核已知的情况下恢复清晰的图像，因为模糊核已知，去模糊的工作就会非常容易，只要利用有效的反卷积算法就可以，主要的挑战就是保持细节的情况下抑制噪声。盲目去模糊则主要是基于生成对抗网络的复原方法。
1.3课题研究的主要内容 （1）运动模糊图像修复。基于WGAN模型，训练300 epochs，保存模型，基于此模型预测得到一个较好地效果。
（2）黑白图像着色。使用了名为NoGAN的新型GAN训练方法，对生成器进行
了预先训练，使其利用常规损失函数，变得更强大、更快、更可靠。
（3）背景替换。运用U2Net模型，两级的U型嵌套结构，不需要预训练，而且保持了较高的分辨率。
（4）MySql数据库。存储数据。
2.1需求分析 运动模糊图像处理：由于各种不确定因素的影响，我们通过设备采集到的图像难免会产生不同程度的失真，图像的运动模糊就是一种典型的失真现象。由于在拍摄时相机与被拍摄物体之间发生了相对位移，图像上就会出现运动模糊。如今，图像识别被广泛的应用于各个领域，如智能交通中的车牌识别，车辆识别等等，运动模糊会严重的影响识别效率。并且，在如今主流的AI图像处理平台诸如：百度AI智能云等都没有运动模糊图像处理相关的功能,目前也没有专门处理运动模糊图像的网站，修复模糊图像的方法大部分是用滤波的方法来修复模糊图像的，效果并不理想。
黑白图像修复：老照片是追溯不可复现历史的重要渠道之一，在还原历史资料、保留珍贵回忆方面有巨大应用价值，但老照片存在大量缺损、模糊、颜色消褪等问题。随着移动摄像机和扫描仪的成熟发展，人们现在可以将照片数字化后通过专家手工修复，然而手工润色通常费时费力，使得成堆的旧照片无法恢复。因此通过数字技术进行修复成为保存珍贵材料的必要条件。老照片是多种图像降级问题的复合，近年来对其进行修补、着色、画质增强的相关研究逐渐增加，但都仅针对其一方面，实际应用性不强。而图像修补、图像着色、分辨率增强等深度学习网络的快速发展使得多模型结合修复成为可能。
2.2 可行性分析 （1）数据可行性
使用了两类数据，一类是GoPro数据集，这类数据集遵循 Borac-chi 和 Foi 描述的随机轨迹生成的想法，通过将子像素插值应用于轨迹矢量来生成核。一类是公开汽车图片MIT Cars dataset数据集，该数据集包含了516张大小为128*128像素的汽车静态图片。通过改变函数参数，生成不同模糊方向、大小的模糊图像，令实验实施更全面。
（2）技术可行性
参考了图像去模糊的最新论文，依照论文中的基础模型简单地进行了初步训练，基础模型以GAN和WGAN为基础，后期的模型修改也有了思路。
（3）硬件可行性
硬件上符合实验要求，预训练模型已经在机器上训练完毕，机器完全可以承担当
前工作量的数据训练；如果后期的训练时间过长，线上GPU租用平台是备用方案，可以保证在预算内完成训练。
2.3 项目设计制约因素 本项目对原有算法进行了改进和应用，软件前端的某些ui设计参考了模板，算法改进和优化模型的训练及测试、以及软件前后端交互代码的设计实现和前端关键部位功能的展示均为原创；软件的使用无安全隐患，软件的使用负荷较小，不会导致硬件电磁污染、不涉及电路材料对人体健康的影响；软件无违法违规行为，不触及道德层面的谴责和审判，无不良信息的传播行为；本项目尊重不同国家、地区、民族的风俗习惯，不同民族生活和风俗上的差异不会对软件系统的使用产生较大的影响。
3 详细设计 基于WGAN的运动模糊图像修复算法 3.1 WGAN方法 baseline我们选取的是基于GAN的WGAN模型。Arjovsky 等提出了使用 Wasserstein 距离衡量分布差异来改进 GAN。原始GAN中采用JS散度来衡量生成数据和真实数据间的差异，但当两者的分布完全不重叠时，JS散度的值将为一个常数，反映不了分布距离，也提供不了训练所需的梯度。其判别器损失函数为:
其中fω是一个含参数 ω 且最后一层不是非线性激活层的判别器网络。限制网络 fω 中的所有参数 ω 在［－c，c］的范围内，c 为一个常数，比如 c 为 0.01 时， 参数 ω 将被限制在［－0．01，0．01］，小于 －0.01 则取 －0．01，大于 0．01 则取 0．01。此时关于输入样本 x 的导数fω /x 也不会超过某个范围，即满足 Lipschitz 连续条件。然而 WGAN 使用的梯度裁剪( Gradient Clipping) 存在 2 个问题:">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-04-14T21:02:44+08:00">
    <meta property="article:modified_time" content="2024-04-14T21:02:44+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">python作品 运动模糊图像修复算法(上)</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2 style="margin-left:0px;text-align:justify;"><a href="https://blog.csdn.net/qq_45738761/article/details/137753059" title="python作品 运动模糊图像修复算法(上)-CSDN博客">python作品 运动模糊图像修复算法(上)-CSDN博客</a></h2> 
<h2><a href="https://blog.csdn.net/qq_45738761/article/details/137753234" title="python作品 运动模糊图像修复算法(下)-CSDN博客">python作品 运动模糊图像修复算法(下)-CSDN博客</a></h2> 
<h2 style="margin-left:0px;text-align:justify;">1.1研究背景和意义</h2> 
<p style="margin-left:0;text-align:justify;">    由于各种不确定因素的影响，我们通过设备采集到的图像难免会产生不同程度的失真，图像的运动模糊就是一种典型的失真现象。运动模糊是指图像中的移动效果，通常会出现在长时间曝光或被拍摄物体快速移动的情形中，由于在拍摄时相机与被拍摄物体之间发生了相对位移，图像上就会出现运动模糊。图像作为重要的信息载体，让受众得到更加直观、迅速、高效、客观的视觉化信息。鉴于图像在传播信息时的优点与重要性，图像在各行各业中都扮演着重要的角色。如今，图像识别被广泛的应用于各个领域，如智能交通中的车牌识别，车辆识别等等，运动模糊会严重的影响识别效率。</p> 
<p style="margin-left:0;text-align:justify;">    由运动模糊的原理可知，通过缩短曝光时间可以减少运动模糊，但代价是噪声更高，对成像传感器质量和光线要求更高。这种方法并不总是可行或者所需成本较大，因此在后期处理阶段进行图像去模糊是一种重要的替代方案。</p> 
<p style="margin-left:0;text-align:justify;">    目前市场上，用户在线实时提交处理展示的web端图片处理网站较少，并且目前的图片处理功能中并没有运动图像去模糊的</p> 
<h2 style="margin-left:0px;text-align:justify;">1.2研究现状</h2> 
<p style="margin-left:0;text-align:justify;">目前，图像去模糊领域的研究主要包括数据集的构建和去模糊算法的研究等方面。（1）在机器学习领域中，数据集质量的高低直接影响实验结果的好坏。而相较于其他图像退化复原问题，图像去模糊的数据集更难获得，在现实环境中很难拍摄到各种因素完全相同的一对清晰图像和模糊图像。在数据集方面，现有的图像去模糊数据集中有一类是通过算法合成的模糊数据集，这类数据集在已获得的清晰图像上加以不同运动模糊模拟算法，得到相应的人工合成的模糊图像。另一种合成方法是用算法模拟生成运动轨迹，根据运动轨迹生成模糊核。（2）图像去模糊中因为模糊核通常是未知的。非盲目去模糊算法指在模糊核已知的情况下恢复清晰的图像，因为模糊核已知，去模糊的工作就会非常容易，只要利用有效的反卷积算法就可以，主要的挑战就是保持细节的情况下抑制噪声。盲目去模糊则主要是基于生成对抗网络的复原方法。</p> 
<p style="margin-left:0;text-align:justify;"></p> 
<h2 style="margin-left:0px;text-align:justify;">1.3课题研究的主要内容</h2> 
<p style="margin-left:0;text-align:justify;">（1）运动模糊图像修复。基于WGAN模型，训练300 epochs，保存模型，基于此模型预测得到一个较好地效果。</p> 
<p style="margin-left:0;text-align:justify;">（2）黑白图像着色。使用了名为NoGAN的新型GAN训练方法，对生成器进行</p> 
<p style="margin-left:0;text-align:justify;">了预先训练，使其利用常规损失函数，变得更强大、更快、更可靠。</p> 
<p style="margin-left:0;text-align:justify;">（3）背景替换。运用U2Net模型，两级的U型嵌套结构，不需要预训练，而且保持了较高的分辨率。</p> 
<p style="margin-left:0;text-align:justify;">（4）MySql数据库。存储数据。</p> 
<h2 style="margin-left:0px;text-align:justify;">2.1需求分析</h2> 
<p style="margin-left:0;text-align:justify;">运动模糊图像处理：由于各种不确定因素的影响，我们通过设备采集到的图像难免会产生不同程度的失真，图像的运动模糊就是一种典型的失真现象。由于在拍摄时相机与被拍摄物体之间发生了相对位移，图像上就会出现运动模糊。如今，图像识别被广泛的应用于各个领域，如智能交通中的车牌识别，车辆识别等等，运动模糊会严重的影响识别效率。并且，在如今主流的AI图像处理平台诸如：百度AI智能云等都没有运动模糊图像处理相关的功能,目前也没有专门处理运动模糊图像的网站，修复模糊图像的方法大部分是用滤波的方法来修复模糊图像的，效果并不理想。</p> 
<p style="margin-left:0;text-align:justify;">黑白图像修复：老照片是追溯不可复现历史的重要渠道之一，在还原历史资料、保留珍贵回忆方面有巨大应用价值，但老照片存在大量缺损、模糊、颜色消褪等问题。随着移动摄像机和扫描仪的成熟发展，人们现在可以将照片数字化后通过专家手工修复，然而手工润色通常费时费力，使得成堆的旧照片无法恢复。因此通过数字技术进行修复成为保存珍贵材料的必要条件。老照片是多种图像降级问题的复合，近年来对其进行修补、着色、画质增强的相关研究逐渐增加，但都仅针对其一方面，实际应用性不强。而图像修补、图像着色、分辨率增强等深度学习网络的快速发展使得多模型结合修复成为可能。</p> 
<p style="margin-left:0;text-align:justify;"></p> 
<h2 style="margin-left:0px;text-align:justify;">2.2 可行性分析</h2> 
<p style="margin-left:0;text-align:justify;">（1）数据可行性</p> 
<p style="margin-left:0;text-align:justify;">使用了两类数据，一类是GoPro数据集，这类数据集遵循 Borac-chi 和 Foi 描述的随机轨迹生成的想法，通过将子像素插值应用于轨迹矢量来生成核。一类是公开汽车图片MIT Cars dataset数据集，该数据集包含了516张大小为128*128像素的汽车静态图片。通过改变函数参数，生成不同模糊方向、大小的模糊图像，令实验实施更全面。</p> 
<p style="margin-left:0;text-align:justify;">（2）技术可行性</p> 
<p style="margin-left:0;text-align:justify;">参考了图像去模糊的最新论文，依照论文中的基础模型简单地进行了初步训练，基础模型以GAN和WGAN为基础，后期的模型修改也有了思路。</p> 
<p style="margin-left:0;text-align:justify;">（3）硬件可行性</p> 
<p style="margin-left:0;text-align:justify;">硬件上符合实验要求，预训练模型已经在机器上训练完毕，机器完全可以承担当</p> 
<p style="margin-left:0;text-align:justify;">前工作量的数据训练；如果后期的训练时间过长，线上GPU租用平台是备用方案，可以保证在预算内完成训练。</p> 
<p style="margin-left:0;text-align:justify;"></p> 
<h2 style="margin-left:0px;text-align:justify;">2.3 项目设计制约因素</h2> 
<p style="margin-left:0;text-align:justify;">本项目对原有算法进行了改进和应用，软件前端的某些ui设计参考了模板，算法改进和优化模型的训练及测试、以及软件前后端交互代码的设计实现和前端关键部位功能的展示均为原创；软件的使用无安全隐患，软件的使用负荷较小，不会导致硬件电磁污染、不涉及电路材料对人体健康的影响；软件无违法违规行为，不触及道德层面的谴责和审判，无不良信息的传播行为；本项目尊重不同国家、地区、民族的风俗习惯，不同民族生活和风俗上的差异不会对软件系统的使用产生较大的影响。</p> 
<h2 style="margin-left:0px;text-align:justify;">3 详细设计</h2> 
<ul><li style="text-align:justify;">基于WGAN的运动模糊图像修复算法</li></ul> 
<h2 style="margin-left:0px;text-align:justify;">3.1 WGAN方法</h2> 
<p style="margin-left:0;text-align:justify;">   baseline我们选取的是基于GAN的WGAN模型。Arjovsky 等提出了使用 Wasserstein 距离衡量分布差异来改进 GAN。原始GAN中采用JS散度来衡量生成数据和真实数据间的差异，但当两者的分布完全不重叠时，JS散度的值将为一个常数，反映不了分布距离，也提供不了训练所需的梯度。其判别器损失函数为:</p> 
<p style="margin-left:0;text-align:center;"><img alt="" height="35" src="https://images2.imgbox.com/7a/96/RUG6KAos_o.png" width="388"></p> 
<p style="margin-left:0;text-align:justify;">其中fω是一个含参数 ω 且最后一层不是非线性激活层的判别器网络。限制网络 fω 中的所有参数 ω 在［－c，c］的范围内，c 为一个常数，比如 c 为 0.01 时， 参数 ω 将被限制在［－0．01，0．01］，小于 －0.01 则取 －0．01，大于 0．01 则取 0．01。此时关于输入样本 x 的导数fω /x 也不会超过某个范围，即满足 Lipschitz 连续条件。然而 WGAN 使用的梯度裁剪( Gradient Clipping) 存在 2 个问题:</p> 
<p style="margin-left:0;text-align:justify;">    1) 判别器希望尽可能扩大真假样本的分数差， 然而梯度裁剪独立地限制每一个网络参数的取值范围，在这种情况下，可预想的最优策略就是尽可能让所有参数走向极端，即要么取最大值，要么取最小值。</p> 
<p style="margin-left:0;text-align:justify;">    2) 梯度裁剪会导致梯度消失或梯度爆炸。Gulrajani 等提出的 WGAN-GP 通过梯度惩罚来控制梯度，解决了上述 2 个问题，通过设置额外的损失项来实现梯度与 Lipschitz 条件之间的联系，其判别器损失函数为:</p> 
<p style="margin-left:0;text-align:center;"><img alt="" height="43" src="https://images2.imgbox.com/3b/a1/q0ekzNJl_o.png" width="504"></p> 
<p style="margin-left:0;text-align:center;"><img alt="" height="42" src="https://images2.imgbox.com/a5/b6/SpkrEDKs_o.png" width="189"></p> 
<p style="margin-left:0;text-align:justify;">    其中，x是真假样本分布之间的随机采样，xg 和 xr 分别代表生成样本和真实样本，px 为x的分布，λ 为惩罚项因子，它用于避免过拟合现象的出现，这里取 λ 为 1，ε为［0，1］间的随机数。损失函 数 的 前 2 项 为WGAN的原始判别器损失，最后一项为增加的梯度惩罚，实现了对判别器的 1-Lipschitz 条件限制。当使用梯度惩罚时，梯度比较稳定，使用不同限制的梯度裁剪的情况下，会出现梯度消失和梯度爆炸。</p> 
<p style="margin-left:0;text-align:justify;">    VGG 网络</p> 
<p style="margin-left:0;text-align:justify;"><span style="color:#000000;">自深度学习进入人们的视野以来，越来越多的网络模 型 被 用 于 图 像 分 类。1994 年诞生了最早的 LeNet，之后又出现了AlexNet等。VGG-Net 是牛津大学和 Google Deep Mind 公司研究人员研发的深层卷积神经网络。VGG-Net 采用连续几个 3 × 3 的卷积核堆叠来代替 AlexNet 中较大的卷积核，在获取相同的感受野的同时提升了网络的深度。改进模型选用VGG-16 网络来提取深层特征。</span></p> 
<p style="margin-left:0;text-align:justify;"></p> 
<h2 style="margin-left:0px;text-align:justify;">3.2 WGAN-GP+感知损失和风格损失方法</h2> 
<p style="margin-left:0;text-align:justify;">     感知损失和风格损失</p> 
<p style="margin-left:0;text-align:justify;">     <span style="color:#000000;">Johnson </span><span style="color:#000000;">等提出的感知损失 Perceptual-loss 和风格损失 Style-loss 在图像风格转换领域取得了成功，将卷积神经网络提取出的图像深层特征作为目标函数的一部分，通过比较 2 幅图片的深层特征，使得待生成的图片与真实图片在语义上相对于像素级别的损失函数更加相似。感知损失和风格损失被应用于图像孔洞修复和照片恢复。本文中定义的感知损失使用 VGG-16 网络的第 3、第 6 与第 10 层( 即前 3 个最大池化层) 提取图像的深层特征，其公式为:</span></p> 
<p style="margin-left:0;text-align:center;"><img alt="" height="60" src="https://images2.imgbox.com/fc/2c/Usdc5iCe_o.png" width="303"></p> 
<p style="margin-left:0;text-align:justify;">    式中Ig 和It 分别为生成器生成的虚假图像和真实图像，ΦΙp* 为给定的I* 在第 p 个池化层的深层特征，NΦItp 为 ΦIt p 中的元素数量。感知损失衡量的是虚假图像和真实图像的深层特征之间的 L1 距离。风格损失首先计算深度特征的格拉姆矩阵(Gram Matrix)来衡量深度特征中每个元素的自相关程度，再计算其 L1 距离。与上述感知损失相同，本文中所使用的风格损失也是用 VGG 网络的前 3 个池化层提取图像的深层特征，其定义为:</p> 
<p style="margin-left:0;text-align:center;"><img alt="" height="56" src="https://images2.imgbox.com/89/ce/xeUrG4H8_o.png" width="448"></p> 
<p style="margin-left:0;text-align:center;">式中，首先定义在第 p 层池化层中提取到的特征矩阵的形状为 Hp × Wp × Cp，</p> 
<p style="margin-left:0;text-align:justify;">将其形状转换为( HpWp ) × Cp的矩阵即 Ψ*p 后计算得到形状为 Cp × Cp 的格拉姆矩阵，Kp 为第 p 层池化层的归一化参数 1 /( CpWpHp ) 。</p> 
<p style="margin-left:0;text-align:justify;">    改进后的WGAN-GP的网络结构</p> 
<p style="margin-left:0;text-align:justify;">    改进后的WGAN-GP 着重在于提升生成图像的细节质量，通过加入风格损失和感知损失提升生成图像和真实图像的相似度，同时保证生成图像在背景、轮廓等细节上保持一致。在训练过程中，判别器的参数较少，且结构较为简单，易于估计感知损失和风格损失，具体的 改进的WGAN-GP 结构如图所示。判别器接收来自真实数据集的图像 X 和生成器由随机噪声生成的虚假图像 G( z) ，并与生成器进行对抗训练，生成器接收随机噪声并学习真实图像的分布特征，生成虚假图像。随着训练的进行，生成器会不断优化参数提升判别器将虚假图像误判为真实图像的概率，而判别器会不断优化参数提升判断的准确度。与此同时，将真实图像和虚假图像同时输入 VGG 网络中并提取其前 3 层最大池化层得到的图像深层特征，计算风格损失和感知损失并对比虚假图像和真实图像的深层特征，通过训练减少两者的差异。</p> 
<p style="margin-left:0;text-align:justify;"><img alt="" height="297" src="https://images2.imgbox.com/b2/e2/KsyijtB2_o.png" width="851"></p> 
<p style="margin-left:0;text-align:justify;">   在判别数据真伪时，由于判别器会不断提高鉴别能力，其损失将会减小，判别器希望真假图像的风格损失和感知损失越大越好，因此风格损失和感知损失 使用负数超参数确保当两者数值较大时判别器损失减小。改进后的WGAN-GP 判别器的损失函数定义为:</p> 
<p style="margin-left:0;text-align:justify;">Ltotal = Lorigin + α1 Lperceptual + α2 Lstyle</p> 
<p style="margin-left:0;text-align:justify;">式中 Lorigin为 WGAN-GP 原本的损失函数。α1 和 α2 分别前面提到的感知损失和风格损失的超参数。由感知损失和风格损失的定义可以看出，风格损失经</p> 
<p style="margin-left:0;text-align:justify;">过了自相关计算以及多次归一化，在将输入图像数据归一化后的情况下，两者的结果数量级差距较大，需要通过超参数来将结果转换至与原 WGAN-GP 损失一致的数量级，以免训练时出现梯度爆炸的现象。通过超参搜索，确定两者的超参数 α1 为 － 0．05，α2 为 － 120。</p> 
<p style="margin-left:0;text-align:justify;">    生成器结构</p> 
<p style="margin-left:0;text-align:center;">    改进后的WGAN－GP 网络的生成器结构包含 5 个神经网络层，将随机噪声输</p> 
<p style="margin-left:0;text-align:justify;">入后通过堆叠的反卷积层( TransposeConv) 输出生成图像。每个反卷积层通过多个 5 × 5 的反卷积核来改变输入的维度，如图所示，反卷积层 1 将输入的噪声维度从 256 降低到 128，后续的反卷积层 2、反卷积层 3、反卷积层 4 每</p> 
<p style="margin-left:0;text-align:justify;">层将维度减少一半，最后一层的反卷积层 5 输入维度为 3，对应图像的 RGB 三通道。所有反卷积层均使用 ReLU 作为激活函数，且卷积步长均为 2 × 2。将该生成器应用到不同尺寸图像的数据集中时，只需改变输入噪声的尺寸即可，例如当输入噪声尺寸为 2 × 2 时，通过生成器产生的虚假图像尺寸为 64 × 64，而当输入噪声尺寸为 4 × 4 时，产生的虚假图像尺寸为128 × 128。</p> 
<p style="margin-left:0;text-align:justify;">    判别器结构</p> 
<p style="margin-left:0;text-align:justify;">    改进后的WGAN-GP 网络的判别器结构如图所示，首先输入 3 通道的图像，经过卷积层提取图像特征，为了使卷积层能够获得更大的感受野，不使用池化层。所有卷积层的步长均为 2 × 2，且填充方式为same，图像在经过卷积层后尺寸和维度均发生了改变，例如卷积层1将图像的尺寸改变为(Horigin /s)×(Worigin /s) ，其中 s 为卷积层的步长，Horigin和 Worigin为输入图像的尺寸。原图像的维度由 3 改变为 64。后续的卷积层 2、卷积层 3、卷积层 4 每层将图像的尺寸缩小 1 /2，并调整其输出维度。最后通过 2 个全连接层将图像特征转换为 64 维的向量后，再经过 1 个输出维度为 1 的全连接层输出判别器对该图像的评分。判别器网络中所有层均使用 LeakyReLU 作为激活函数，斜率均设置为 0．2。</p> 
<p style="margin-left:0;text-align:center;"><img alt="" height="588" src="https://images2.imgbox.com/0c/1f/5jNr0J02_o.png" width="480"></p> 
<p style="margin-left:0;text-align:justify;"></p> 
<p style="margin-left:0;text-align:justify;">    改进后的WGAN-GP算法过程</p> 
<p style="margin-left:0;text-align:center;">    在训练 改进的WGAN-GP 时，设定生成模型和判别模型的学习率为0．00005。使用 Adam优化器对判别器和生成器交替进行参数优化，即每更新 5 次判别器后</p> 
<p style="margin-left:0;text-align:justify;">再更新 1 次生成器。</p> 
<p style="margin-left:0;text-align:justify;">    输入: 批量大小 m，判别器迭代次数 ncritic，总迭代次数 Epoches，Adam 优化器的超参数 α、β1、β2，判别器待优化参数 w，生成器待优化参数θ，感知损失和风格损失超参数 α1、α2。</p> 
<p style="margin-left:0;text-align:center;"><img alt="" height="691" src="https://images2.imgbox.com/67/6e/smMXhrYP_o.png" width="632"></p> 
<p style="margin-left:0;text-align:justify;">    算法总结了改进的WGAN-GP 的过程，首先训练判别器，对真实数据和噪声分别采样，接着计算真实图像和虚假图像的感知损失、风格损失以及 Wasserstein距离，计算判别器参数的梯度并通过梯度惩罚确保其满足 Lipschitz 限制条件，并更新判别器参数。然后训练生成器并再次生成随机噪声、更新生成器参数，降低真假图像之间的差异，直到循环结束。</p> 
<h2 style="margin-left:0px;text-align:justify;"></h2>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/3fc86fc49555048911a0bddde4c86f49/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">PostgreSQL基本使用与数据备份</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/ecfbf37fb24204c7df9956965a2761fd/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【C&#43;&#43;庖丁解牛】哈希表/散列表的设计原理 | 哈希函数</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>