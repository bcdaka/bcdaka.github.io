<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>多语言声音克隆，CosyVoice模型最强部署 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/1afaa5d0e1a40c7717e2014f1f09a937/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="多语言声音克隆，CosyVoice模型最强部署">
  <meta property="og:description" content="CosyVoice是由阿里通义实验室开源的一款多语言语音理解模型，它主要聚焦于高质量的语音合成，能够生成自然且逼真的语音。
CosyVoice模型经过超过15万小时的数据训练，支持中文、英语、日语、粤语和韩语多种语言的合成，且在多语言语音生成、零样本语音生成、跨语言声音合成和指令执行能力方面表现卓越。
CosyVoice支持one-shot音色克隆技术，仅需3~10秒的原始音频即可生成模拟音色，包括韵律、情感等细节。
CosyVoice展现了零样本学习的能力，能够通过一个简短的参考语音样本复制任意声音，实现内容一致性和说话者相似度的高度还原。
CosyVoice能够对生成的语音进行细粒度的情感、语调、语速和音调控制，使合成的语音更加丰富和具有表现力。
github项目地址：https://github.com/FunAudioLLM/CosyVoice。
一、环境安装 1、python环境
建议安装python版本在3.10以上。
2、pip库安装
pip install torch==2.0.1&#43;cu118 torchvision==0.15.2&#43;cu118 torchaudio==2.0.2 --index-url https://download.pytorch.org/whl/cu118
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple
3、CosyVoice-300M模型下载：
git lfs install
git clone https://www.modelscope.cn/iic/CosyVoice-300M.git CosyVoice-300M
4、CosyVoice-300M-SFT模型下载：
git lfs install
git clone https://www.modelscope.cn/iic/CosyVoice-300M-SFT.git CosyVoice-300M-SFT
5、CosyVoice-300M-Instruct模型下载：
git lfs install
git clone https://www.modelscope.cn/iic/CosyVoice-300M-Instruct.git CosyVoice-300M-Instruct
当使用自然语音控制推理模式时，需要采用该模型。
6、CosyVoice-ttsfrd模型下载：
git lfs install
git clone https://www.modelscope.cn/iic/CosyVoice-ttsfrd.git CosyVoice-ttsfrd
二、功能测试 1、调用测试：
（1）调用接口测试代码
from cosyvoice.cli.cosyvoice import CosyVoice from cosyvoice.utils.file_utils import load_wav import torchaudio #初始化CosyVoice模型 cosyvoice = CosyVoice(&#39;pretrained_models/CosyVoice-300M-SFT&#39;) #列出可用的发音人 print(cosyvoice.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-07-19T06:00:00+08:00">
    <meta property="article:modified_time" content="2024-07-19T06:00:00+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">多语言声音克隆，CosyVoice模型最强部署</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>CosyVoice是由阿里通义实验室开源的一款多语言语音理解模型，它主要聚焦于高质量的语音合成，能够生成自然且逼真的语音。</p> 
<p>CosyVoice模型经过超过15万小时的数据训练，支持中文、英语、日语、粤语和韩语多种语言的合成，且在多语言语音生成、零样本语音生成、跨语言声音合成和指令执行能力方面表现卓越。</p> 
<p>CosyVoice支持one-shot音色克隆技术，仅需3~10秒的原始音频即可生成模拟音色，包括韵律、情感等细节。</p> 
<p>CosyVoice展现了零样本学习的能力，能够通过一个简短的参考语音样本复制任意声音，实现内容一致性和说话者相似度的高度还原。</p> 
<p>CosyVoice能够对生成的语音进行细粒度的情感、语调、语速和音调控制，使合成的语音更加丰富和具有表现力。</p> 
<p>github项目地址：https://github.com/FunAudioLLM/CosyVoice。</p> 
<h3><strong>一、环境安装</strong></h3> 
<p>1、<strong>python环境</strong></p> 
<p>建议安装python版本在3.10以上。</p> 
<p>2、<strong>pip库安装</strong></p> 
<p>pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 torchaudio==2.0.2 --index-url https://download.pytorch.org/whl/cu118</p> 
<p>pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple</p> 
<p>3、<strong>CosyVoice-300M模型下载</strong>：</p> 
<p>git lfs install</p> 
<p>git clone https://www.modelscope.cn/iic/CosyVoice-300M.git CosyVoice-300M</p> 
<p>4、<strong>CosyVoice-300M-SFT模型下载</strong>：</p> 
<p>git lfs install</p> 
<p>git clone https://www.modelscope.cn/iic/CosyVoice-300M-SFT.git CosyVoice-300M-SFT</p> 
<p>5、<strong>CosyVoice-300M-Instruct模型下载</strong>：</p> 
<p>git lfs install</p> 
<p>git clone https://www.modelscope.cn/iic/CosyVoice-300M-Instruct.git CosyVoice-300M-Instruct</p> 
<p>当使用自然语音控制推理模式时，需要采用该模型。</p> 
<p>6、<strong>CosyVoice-ttsfrd模型下载</strong>：</p> 
<p>git lfs install</p> 
<p>git clone https://www.modelscope.cn/iic/CosyVoice-ttsfrd.git CosyVoice-ttsfrd</p> 
<h3>二<strong>、功能测试</strong></h3> 
<p>1、<strong>调用测试</strong>：</p> 
<p>（1）<strong>调用接口测试代码</strong></p> 
<pre><code class="hljs">from cosyvoice.cli.cosyvoice import CosyVoice  
from cosyvoice.utils.file_utils import load_wav  
import torchaudio 

#初始化CosyVoice模型
cosyvoice = CosyVoice('pretrained_models/CosyVoice-300M-SFT')

#列出可用的发音人
print(cosyvoice.list_available_spks())

#使用SFT（Supervised Fine-Tuning）模式生成语音
output = cosyvoice.inference_sft(
    text='你好，我是通义生成式语音大模型，请问有什么可以帮您的吗？',
    speaker='中文女'
)
#将生成的语音保存为wav文件
torchaudio.save('sft.wav', output['tts_speech'], 22050)

#再次初始化CosyVoice模型，这次加载的是基础模型CosyVoice-300M
cosyvoice = CosyVoice('pretrained_models/CosyVoice-300M')

#加载用于Zero-Shot和Cross-Lingual任务的提示语音
prompt_speech_16k = load_wav('zero_shot_prompt.wav', 16000)

#使用Zero-Shot模式生成语音，此模式不需要特定的训练数据
output = cosyvoice.inference_zero_shot(
    main_text='收到好友从远方寄来的生日礼物，那份意外的惊喜与深深的祝福让我心中充满了甜蜜的快乐，笑容如花儿般绽放。',
    additional_text='希望你以后能够做的比我还好呦。',
    prompt_speech=prompt_speech_16k
)
#将生成的语音保存为wav文件
torchaudio.save('zero_shot.wav', output['tts_speech'], 22050)

#加载用于Cross-Lingual任务的提示语音
prompt_speech_16k = load_wav('cross_lingual_prompt.wav', 16000)

#使用Cross-Lingual模式生成语音，该模式支持跨语言语音合成
output = cosyvoice.inference_cross_lingual(
    text='&lt;|en|&gt;And then later on, fully acquiring that company. So keeping management in line, interest in line with the asset that\'s coming into the family is a reason why sometimes we don\'t buy the whole thing.',
    prompt_speech=prompt_speech_16k
)
#将生成的语音保存为wav文件
torchaudio.save('cross_lingual.wav', output['tts_speech'], 22050)

#最后，再次初始化CosyVoice模型，这次加载的是指令模型CosyVoice-300M-Instruct
cosyvoice = CosyVoice('pretrained_models/CosyVoice-300M-Instruct')

#使用Instruct模式生成语音，支持情感和语气的指令标签
output = cosyvoice.inference_instruct(
    text='在面对挑战时，他展现了非凡的&lt;bold&gt;勇气&lt;/bold&gt;与&lt;bold&gt;智慧&lt;/bold&gt;。',
    speaker='中文男',
    style='Theo \'Crimson\', is a fiery, passionate rebel leader. Fights with fervor for justice, but struggles with impulsiveness.'
)
#将生成的语音保存为wav文件
torchaudio.save('instruct.wav', output['tts_speech'], 22050)</code></pre> 
<p>（2）<strong>web端测试代码</strong></p> 
<p>未完......</p> 
<p>更多详细的内容欢迎关注：<strong>杰哥新技术</strong></p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/f3/da/I8tHYLT2_o.jpg"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/f41c6cef8a84f4dbc5b4061b4c020b80/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Docker-compose单机容器集群编排</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/93530b19509d19b00eee70f5baafc1f3/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">解密AI绘画与修图： Stable Diffusion&#43;Photoshop</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>