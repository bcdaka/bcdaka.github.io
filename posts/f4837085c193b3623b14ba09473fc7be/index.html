<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>数据科学、数据分析、人工智能必备知识汇总-----Python爬虫-----持续更新 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/f4837085c193b3623b14ba09473fc7be/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="数据科学、数据分析、人工智能必备知识汇总-----Python爬虫-----持续更新">
  <meta property="og:description" content="数据科学、数据分析、人工智能必备知识汇总-----主目录-----持续更新(进不去说明我没写完)：https://blog.csdn.net/grd_java/article/details/140174015 文章目录 一、基本配置和基础知识二、Urllib库三、解析库四、Selenium五、request 一、基本配置和基础知识 初期准备 安装ipython：进入python安装目录，进入Scripts文件夹，在这个文件夹进入cmd，执行pip install ipython命令即可安装
如果出现如下提示，就进入python安装目录，打开cmd执行它所提示的命令
为了保险起见，可以重新按照上面的步骤安装ipython，安装成功后，scripts文件夹会多出我们安装的脚本
如果安装的包太多，也可以选择执行pip list命令查看安装的包
2. 修改pip下载源 直接使用pip install命令会从默认的https://files.pythonnhosted.org/网站进行下载，这个是国外的网站，会比较慢我们只需要在命令后面加上 -i 国内源地址即可 pip install 包名 -i 国内源地址 #例如 pip install ipython -i https://pypi.mirrors.ustc.edu.cn/simple/ # 其中，常用国内源地址有 阿里云 http://mirrors.aliyun.com/pypi/simple/ 中国科技大学 https://pypi.mirrors.ustc.edu.cn/simple/ 豆瓣(douban) http://pypi.douban.com/simple/ 清华大学 https://pypi.tuna.tsinghua.edu.cn/simple/ 中国科学技术大学 http://pypi.mirrors.ustc.edu.cn/simple/ 设置模版 打开Pycharm软件，在设置中的Editor中的File and Code Templates选择.py文件，为其设置模版
每次我们创建.py文件时，会自动将其添加 # _*_ coding : utf-8 _*_ # @Time : ${DATE} ${TIME} # @Author : Taylor Sinclair（殷志鹏） # @File : ${NAME} # @Project : ${PROJECT_NAME} # @Description : 在这里书写本文件的作用 什么是爬虫 如果我们把互联网比作一张大的蜘蛛网，那一台计算机上的数据便是蜘蛛网上的一个猎物，而爬虫程序就是一只小蜘蛛，沿着蜘蛛网抓取自己想要的数据">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-08-05T09:06:25+08:00">
    <meta property="article:modified_time" content="2024-08-05T09:06:25+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">数据科学、数据分析、人工智能必备知识汇总-----Python爬虫-----持续更新</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-dracula">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <table><thead><tr><th>数据科学、数据分析、人工智能必备知识汇总-----主目录-----持续更新(进不去说明我没写完)：<kbd><a href="https://blog.csdn.net/grd_java/article/details/140174015">https://blog.csdn.net/grd_java/article/details/140174015</a></kbd></th></tr></thead></table> 
<p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#kbdkbd_5" rel="nofollow">一、<kbd>基本配置和基础知识</kbd></a></li><li><a href="#kbdUrllibkbd_113" rel="nofollow">二、<kbd>Urllib库</kbd></a></li><li><a href="#kbdkbd_118" rel="nofollow">三、<kbd>解析库</kbd></a></li><li><a href="#kbdSeleniumkbd_124" rel="nofollow">四、<kbd>Selenium</kbd></a></li><li><a href="#kbdrequestkbd_129" rel="nofollow">五、<kbd>request</kbd></a></li></ul> 
</div> 
<p></p> 
<h2><a id="kbdkbd_5"></a>一、<kbd>基本配置和基础知识</kbd></h2> 
<table><thead><tr><th>初期准备</th></tr></thead></table> 
<blockquote> 
 <ol><li><strong>安装ipython：进入python安装目录，进入Scripts文件夹，在这个文件夹进入cmd，执行pip install ipython命令即可安装</strong><br> <img src="https://images2.imgbox.com/c0/6e/6Ot0IdtZ_o.png" alt="在这里插入图片描述"></li></ol> 
 <blockquote> 
  <ol><li><strong>如果出现如下提示，就进入python安装目录，打开cmd执行它所提示的命令</strong><br> <img src="https://images2.imgbox.com/b3/b1/b8520Udw_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/6d/05/du3dgyf8_o.png" alt="在这里插入图片描述"></li><li><strong>为了保险起见，可以重新按照上面的步骤安装ipython，安装成功后，scripts文件夹会多出我们安装的脚本</strong><br> <img src="https://images2.imgbox.com/36/60/TdS26Ae7_o.png" alt="在这里插入图片描述"></li><li><strong>如果安装的包太多，也可以选择执行pip list命令查看安装的包</strong><br> <img src="https://images2.imgbox.com/f1/db/doytVAcJ_o.png" alt="在这里插入图片描述"></li></ol> 
 </blockquote> 
</blockquote> 
<table><thead><tr><th>2. 修改pip下载源</th></tr></thead></table> 
<blockquote> 
 <ol><li><strong>直接使用pip install命令会从默认的https://files.pythonnhosted.org/网站进行下载，这个是国外的网站，会比较慢</strong></li><li><strong>我们只需要在命令后面加上 -i 国内源地址即可</strong></li></ol> 
</blockquote> 
<pre><code class="prism language-shell">pip <span class="token function">install</span> 包名 <span class="token parameter variable">-i</span> 国内源地址
<span class="token comment">#例如</span>
pip <span class="token function">install</span> ipython <span class="token parameter variable">-i</span> https://pypi.mirrors.ustc.edu.cn/simple/
<span class="token comment"># 其中，常用国内源地址有</span>
阿里云 http://mirrors.aliyun.com/pypi/simple/
中国科技大学 https://pypi.mirrors.ustc.edu.cn/simple/
豆瓣<span class="token punctuation">(</span>douban<span class="token punctuation">)</span> http://pypi.douban.com/simple/
清华大学 https://pypi.tuna.tsinghua.edu.cn/simple/
中国科学技术大学 http://pypi.mirrors.ustc.edu.cn/simple/
</code></pre> 
<table><thead><tr><th>设置模版</th></tr></thead></table> 
<blockquote> 
 <ol><li><strong>打开Pycharm软件，在设置中的Editor中的File and Code Templates选择.py文件，为其设置模版</strong><br> <img src="https://images2.imgbox.com/87/9a/wtnzwvMY_o.png" alt="在这里插入图片描述"></li><li><strong>每次我们创建.py文件时，会自动将其添加</strong></li></ol> 
</blockquote> 
<pre><code class="prism language-python"><span class="token comment"># _*_ coding : utf-8 _*_</span>
<span class="token comment"># @Time : ${DATE} ${TIME}</span>
<span class="token comment"># @Author : Taylor Sinclair（殷志鹏）</span>
<span class="token comment"># @File : ${NAME}</span>
<span class="token comment"># @Project : ${PROJECT_NAME}</span>
<span class="token comment"># @Description : 在这里书写本文件的作用</span>
</code></pre> 
<table><thead><tr><th>什么是爬虫</th></tr></thead></table> 
<blockquote> 
 <p><img src="https://images2.imgbox.com/ab/2d/Jsu6TBZz_o.png" alt="在这里插入图片描述"></p> 
</blockquote> 
<blockquote> 
 <p><strong>如果我们把互联网比作一张大的蜘蛛网，那一台计算机上的数据便是蜘蛛网上的一个猎物，而爬虫程序就是一只小蜘蛛，沿着蜘蛛网抓取自己想要的数据</strong></p> 
 <ol><li><strong>通过一个程序，根据Url(http://www.taobao.com)进行爬取网页，获取有用信息</strong></li><li><strong>使用程序模拟浏览器，去向服务器发送请求，获取响应信息</strong></li></ol> 
</blockquote> 
<table><thead><tr><th>我们需要研究哪些问题</th></tr></thead></table> 
<blockquote> 
 <ol><li><strong>爬取网页：爬取整个网页,包含了网页中所有内容,这是你必须会的一步</strong></li><li><strong>解析数据：将网页中你得到的数据，进行解析。上一步爬取到的整个网页的数据，我们并不是全部都需要，此时需要将我们需要的数据解析出来</strong></li><li><strong>难点：爬虫和反爬虫之间的博弈。反爬虫就是你找他要数据，他不给你。而我们搞爬虫的如果让他给你数据呢？核心就是找到他不给你数据的原因，只要找到了这个，在爬虫时将其解决，就会给你数据了</strong></li></ol> 
 <blockquote> 
  <p><strong>例如我们要爬取一个网站的数据，这个网站不给你爬，因为你不是系统开放成员，他需要你有一个内部账号才能访问数据，此时你唯一的办法就是获取内部账号。</strong></p> 
 </blockquote> 
</blockquote> 
<table><thead><tr><th>爬虫的用途</th></tr></thead></table> 
<blockquote> 
 <ol><li><strong>数据分析/人工数据集：因为这些工作是建立在数据之上的，而爬虫是获取数据的有效手段</strong></li><li><strong>社交软件冷启动：有些社交软件初期用户不多，会通过爬虫爬取一些其它大社交网站的数据，将这些数据生成为假用户，让我们的社交软件显得不那么冷清清的。</strong></li><li><strong>舆情监控</strong></li><li><strong>竞争对手监控</strong></li><li><strong>下图是前几年爬虫很火的时候，大家写爬虫程序爬取数据的行业占比，可以发现出行数据和社交数据是重灾区</strong><br> <img src="https://images2.imgbox.com/9e/cc/VtrLpu5B_o.png" alt="在这里插入图片描述"></li></ol> 
</blockquote> 
<table><thead><tr><th>爬虫的分类</th></tr></thead></table> 
<blockquote> 
 <ol><li><strong>通用爬虫：我们不会学习这个，因为这些数据大部分是无用数据</strong></li></ol> 
 <blockquote> 
  <ol><li><strong>使用通用爬虫的实例有: 百度、360、google、sougou等搜索引擎‐‐‐伯乐在线。<mark>细心的人可以发现，使用这些搜索引擎搜索东西的时候，重复率很大。而且谁花钱谁放在前面</mark></strong></li><li><strong>功能: 访问网页‐&gt;抓取数据‐&gt;数据存储‐&gt;数据处理‐&gt;提供检索服务</strong></li><li><strong>robots协议: 一个约定俗成的协议，添加robots.txt文件，来说明本网站哪些内容不可以被抓取，起不到限制作用.自己写的爬虫无需遵守</strong></li><li><strong>网站排名(SEO):这个也是通用爬虫获取数据大部分是无用数据的原因</strong></li></ol> 
  <blockquote> 
   <ol><li><strong>本来网站排名应该是根据pagerank算法值进行排名（参考个网站流量、点击率等指标）</strong></li><li><strong>而现在的搜索引擎基本上就是百度竞价排名这一套，你去百度，前面的数据都是广告，非常影响我们的体验</strong></li></ol> 
  </blockquote> 
  <ol start="5"><li><strong>缺点</strong></li></ol> 
  <blockquote> 
   <ol><li><strong>抓取的数据大多是无用的</strong></li><li><strong>不能根据用户的需求来精准获取数据</strong></li></ol> 
  </blockquote> 
 </blockquote> 
 <ol start="2"><li><strong>聚焦爬虫：这是我们要研究的重点</strong></li></ol> 
 <blockquote> 
  <ol><li><strong>功能: 根据需求，实现爬虫程序，抓取需要的数据</strong></li><li><strong>设计思路</strong></li></ol> 
  <blockquote> 
   <ol><li><strong>确定要爬取的url。需要研究如何获取Url</strong></li><li><strong>模拟浏览器通过http协议访问url，获取服务器返回的html代码。需要研究如何访问</strong></li><li><strong>解析html字符串（根据一定规则提取需要的数据）。需要研究如何解析</strong></li></ol> 
  </blockquote> 
 </blockquote> 
</blockquote> 
<table><thead><tr><th>反爬手段</th></tr></thead></table> 
<blockquote> 
 <ol><li><strong>User‐Agent：中文名为用户代理，简称 UA，它是一个特殊字符串头，使得服务器能够识别客户使用的操作系统及版本、CPU 类型、浏览器及版本、浏览器渲染引擎、浏览器语言、浏览器插件等</strong></li></ol> 
 <blockquote> 
  <p><strong>这是我们爬虫的第一道大关，简称UA校验，简单来说，如果我们不做特殊处理，他能识别到我们是假数据，而不是真实的用户</strong></p> 
 </blockquote> 
 <ol start="2"><li><strong>代理IP：试想一下，你一个ip一秒钟点击一个网站200次，这显然不是人类用手能干出来的操作。如果你对网站的操作是异于人类的，那么我会封掉你的ip，让你无法进行访问</strong></li></ol> 
 <blockquote> 
  <ol><li><strong>西次代理</strong></li><li><strong>快代理</strong></li><li><strong>什么是高匿名、匿名和透明代理？它们有什么区别？</strong></li></ol> 
  <blockquote> 
   <ol><li><strong>使用透明代理，对方服务器可以知道你使用了代理，并且也知道你的真实IP</strong></li><li><strong>使用匿名代理，对方服务器可以知道你使用了代理，但不知道你的真实IP。</strong></li><li><strong>使用高匿名代理，对方服务器不知道你使用了代理，更不知道你的真实IP。</strong></li></ol> 
  </blockquote> 
 </blockquote> 
 <ol start="3"><li><strong>验证码访问：现在基本上大部分平台都有验证码校验了，有效限制大家爬虫，因为有验证码，你在登录的时候就已经有难度了</strong></li></ol> 
 <blockquote> 
  <ol><li><strong>打码平台</strong></li><li><strong>云打码平台</strong></li><li><strong>超级老鹰</strong></li></ol> 
 </blockquote> 
 <ol start="4"><li><strong>动态加载网页：网站返回的是js数据，并不是网页的真实数据。这种数据让我们很难爬取有效信息</strong></li></ol> 
 <blockquote> 
  <p><strong>selenium驱动真实的浏览器发送请求</strong></p> 
 </blockquote> 
 <ol start="5"><li><strong>数据加密：将数据加密后返回给你，尤其是ssh加密的，你没有密钥很难解开，这种数据如果你不是内部人员还是不要爬取的好，但是有些网站明明数据不重要，还搞这一出，我们就可以通过分析进行解密爬取</strong></li></ol> 
 <blockquote> 
  <p><strong>分析js代码</strong></p> 
 </blockquote> 
</blockquote> 
<h2><a id="kbdUrllibkbd_113"></a>二、<kbd>Urllib库</kbd></h2> 
<table><thead><tr><th>由于篇幅原因，我将其放在另一篇文章中：<kbd><a href="https://blog.csdn.net/grd_java/article/details/140589367">https://blog.csdn.net/grd_java/article/details/140589367</a></kbd></th></tr></thead></table> 
<blockquote> 
 <p><strong>根据请求将数据爬取下来</strong></p> 
</blockquote> 
<h2><a id="kbdkbd_118"></a>三、<kbd>解析库</kbd></h2> 
<table><thead><tr><th>由于篇幅原因，我将其放在另一篇文章中：<kbd><a href="https://blog.csdn.net/grd_java/article/details/140625643">https://blog.csdn.net/grd_java/article/details/140625643</a></kbd></th></tr></thead></table> 
<blockquote> 
 <p><strong>爬取到数据后，里面的大部分数据是我们不需要的，我们要对其进行解析，定位我们需要的数据，将其提取出来</strong></p> 
</blockquote> 
<h2><a id="kbdSeleniumkbd_124"></a>四、<kbd>Selenium</kbd></h2> 
<table><thead><tr><th>由于篇幅原因，我将其放在另一篇文章中：<kbd><a href="https://blog.csdn.net/grd_java/article/details/140770543">https://blog.csdn.net/grd_java/article/details/140770543</a></kbd></th></tr></thead></table> 
<blockquote> 
 <p><strong>前面都是用程序去模拟请求获取数据，而这个可以让我们操作真实浏览器去获取数据，不光如此，谷歌浏览器还提供无窗口模式（没有浏览器界面，但是操作了真实的浏览器）</strong></p> 
</blockquote> 
<h2><a id="kbdrequestkbd_129"></a>五、<kbd>request</kbd></h2> 
<table><thead><tr><th>由于篇幅原因，我将其放在另一篇文章中：<kbd></kbd></th></tr></thead></table>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/9e6c41855e00bbf8789b44a6c23b8f54/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">JAVA中实现线程安全的三种方式</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/bc238cd8826809489ee54732e496bc4f/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">IDEA如何去掉编辑框右侧的竖线</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>