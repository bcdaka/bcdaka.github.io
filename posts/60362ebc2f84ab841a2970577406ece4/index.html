<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Selenium 如何使用代理 IP 进行 Web 爬虫（包括无认证实现、有账号密码认证实现） - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/60362ebc2f84ab841a2970577406ece4/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="Selenium 如何使用代理 IP 进行 Web 爬虫（包括无认证实现、有账号密码认证实现）">
  <meta property="og:description" content="文章目录 版本无账号密码使用 Selenium 实现 HTTP 代理万万没想到加上账号密码会难度升级 &#43; NGPT 提供的带账号密码的 HTTP 代理解决方案代理 IP如何获取 Selenium-Chrome-HTTP-Private-Proxy HTTP 代理解决方案如何实现 总结总结个人简介 版本 Python 3.x 无账号密码使用 Selenium 实现 HTTP 代理 最近一个朋友私聊了我一个问题，Selenium 如何使用代理 IP 进行爬虫，我心想这不是很简单，马上让 GPT 帮忙写一个： 完整代码如下： from selenium import webdriver from selenium.webdriver.common.proxy import Proxy, ProxyType # 设置代理IP proxy_ip = &#34;your_proxy_ip&#34; proxy_port = &#34;your_proxy_port&#34; # 设置代理 proxy = Proxy() proxy.proxy_type = ProxyType.MANUAL proxy.http_proxy = f&#34;{proxy_ip}:{proxy_port}&#34; proxy.ssl_proxy = f&#34;{proxy_ip}:{proxy_port}&#34; # 配置浏览器选项 chrome_options = webdriver.ChromeOptions() chrome_options.add_argument(&#39;--proxy-server=http://{}:{}&#39;.format(proxy_ip, proxy_port)) # 启动浏览器 driver = webdriver.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-01-02T17:48:04+08:00">
    <meta property="article:modified_time" content="2024-01-02T17:48:04+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Selenium 如何使用代理 IP 进行 Web 爬虫（包括无认证实现、有账号密码认证实现）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#_1" rel="nofollow">版本</a></li><li><a href="#_Selenium__HTTP__4" rel="nofollow">无账号密码使用 Selenium 实现 HTTP 代理</a></li><li><a href="#__N_73" rel="nofollow">万万没想到加上账号密码会难度升级 + N</a></li><li><ul><li><a href="#GPT__HTTP__76" rel="nofollow">GPT 提供的带账号密码的 HTTP 代理解决方案</a></li><li><ul><li><a href="#_IP_127" rel="nofollow">代理 IP</a></li><li><ul><li><a href="#_131" rel="nofollow">如何获取</a></li></ul> 
   </li></ul> 
   </li><li><a href="#SeleniumChromeHTTPPrivateProxy_HTTP__178" rel="nofollow">Selenium-Chrome-HTTP-Private-Proxy HTTP 代理解决方案</a></li><li><ul><li><a href="#_183" rel="nofollow">如何实现</a></li></ul> 
  </li></ul> 
  </li><li><a href="#_323" rel="nofollow">总结</a></li><li><a href="#_325" rel="nofollow">总结</a></li><li><a href="#_327" rel="nofollow">个人简介</a></li></ul> 
</div> 
<p></p> 
<h2><a id="_1"></a>版本</h2> 
<ul><li>Python 3.x</li></ul> 
<h2><a id="_Selenium__HTTP__4"></a>无账号密码使用 Selenium 实现 HTTP 代理</h2> 
<ul><li>最近一个朋友私聊了我一个问题，Selenium 如何使用代理 IP 进行爬虫，我心想这不是很简单，马上让 GPT 帮忙写一个：</li></ul> 
<p><img src="https://images2.imgbox.com/c5/24/g3YfgSIb_o.png" alt="让 GPT 帮我写一个"></p> 
<ul><li>完整代码如下：</li></ul> 
<pre><code class="prism language-Python">from selenium import webdriver
from selenium.webdriver.common.proxy import Proxy, ProxyType

# 设置代理IP
proxy_ip = "your_proxy_ip"
proxy_port = "your_proxy_port"

# 设置代理
proxy = Proxy()
proxy.proxy_type = ProxyType.MANUAL
proxy.http_proxy = f"{proxy_ip}:{proxy_port}"
proxy.ssl_proxy = f"{proxy_ip}:{proxy_port}"

# 配置浏览器选项
chrome_options = webdriver.ChromeOptions()
chrome_options.add_argument('--proxy-server=http://{}:{}'.format(proxy_ip, proxy_port))

# 启动浏览器
driver = webdriver.Chrome(executable_path='path/to/chromedriver', options=chrome_options)

# 访问百度官网
driver.get('https://www.baidu.com')

# 在这里执行你的操作，比如查找元素、输入搜索关键词等

# 关闭浏览器
driver.quit()
</code></pre> 
<ul><li>GPT 提供的代码有时候并不准确，需要简单修改一下，运行成功：</li></ul> 
<pre><code class="prism language-Python">import time

from selenium import webdriver
from selenium.webdriver.chrome.service import Service

# 设置代理IP
proxy_ip = "127.0.0.1"
proxy_port = "1080"

# 配置浏览器选项
chrome_options = webdriver.ChromeOptions()
chrome_options.add_argument('--proxy-server=http://{}:{}'.format(proxy_ip, proxy_port))

# 启动浏览器
chrome_service = Service("./chromedriver.exe")
driver = webdriver.Chrome(service=chrome_service, options=chrome_options)

# 访问百度官网
driver.get('https://www.baidu.com')

# 在这里执行你的操作，比如查找元素、输入搜索关键词等
time.sleep(30)

# 关闭浏览器
driver.quit()
</code></pre> 
<p><img src="https://images2.imgbox.com/a4/bc/czMzX4yv_o.png" alt="无账号密码 Selenium 代理"></p> 
<h2><a id="__N_73"></a>万万没想到加上账号密码会难度升级 + N</h2> 
<ul><li>代码提供给朋友后，他突然回了一句，我的代理 IP 有账号密码，我心想这不简单，加上账号密码不就行了，然后我又转头把任务交给了 GPT，GPT 又给我提供了一份代码（下面的代码经过微调，还是上面的问题）：</li></ul> 
<h3><a id="GPT__HTTP__76"></a>GPT 提供的带账号密码的 HTTP 代理解决方案</h3> 
<pre><code class="prism language-Python">import time

from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.proxy import Proxy, ProxyType

# 设置代理IP
proxy_ip = "your_proxy_ip"
proxy_port = "your_proxy_port"
proxy_username = "your_proxy_username"
proxy_password = "your_proxy_password"

# 设置代理
proxy = Proxy()
proxy.proxy_type = ProxyType.MANUAL
proxy.http_proxy = f"{proxy_ip}:{proxy_port}"

# 配置代理的认证信息
capabilities = webdriver.DesiredCapabilities.CHROME.copy()
proxy_auth = f"{proxy_username}:{proxy_password}"
capabilities['proxy'] = {
    'httpProxy': proxy.http_proxy,
    'ftpProxy': proxy.http_proxy,
    'sslProxy': proxy.http_proxy,
    'proxyType': 'MANUAL',
    'socksUsername': proxy_username,
    'socksPassword': proxy_password
}

# 配置浏览器选项
chrome_options = webdriver.ChromeOptions()
chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
chrome_options.add_argument('--proxy-server=http://{}:{}'.format(proxy_ip, proxy_port))

# 启动浏览器
chrome_service = Service("./chromedriver.exe")
driver = webdriver.Chrome(service=chrome_service, options=chrome_options)

# 访问百度官网
driver.get('https://www.baidu.com')

# 在这里执行你的操作，比如查找元素、输入搜索关键词等
time.sleep(30)

# 关闭浏览器
driver.quit()
</code></pre> 
<h4><a id="_IP_127"></a>代理 IP</h4> 
<ul><li>代码写好后不想改本地正常稳定使用的代理配置，使用了最近常使用的一个免费代理 IP (一连代理)，支持主流的http/https/socks5协议，使用API快速拉取IP达到 50-300ms 响应时间，基本可以保证 99.99% 的IP可用性，有需要的小伙伴可以试试（有付费需求的小伙伴报暗号-Lorin洛林 可以打85折）。</li></ul> 
<h5><a id="_131"></a>如何获取</h5> 
<ul><li>前往官网进入套餐详情页（https://yilian.top）</li></ul> 
<p><img src="https://images2.imgbox.com/72/a1/phAEqWQe_o.png" alt=""></p> 
<ul><li>按需选择参数，领取4种见面礼</li></ul> 
<p><img src="https://images2.imgbox.com/b9/43/A483FZbq_o.png" alt=""></p> 
<ul><li>前往【控制台】—【产品管理】提取 IP</li></ul> 
<p><img src="https://images2.imgbox.com/c4/2e/7KHvhat0_o.png" alt=""></p> 
<ul><li>我使用的是 API 文档中的 simple 模式获取：</li></ul> 
<pre><code class="prism language-bash">http://api.yilian.top/v2/proxy/proxies?num<span class="token operator">=</span><span class="token number">1</span><span class="token operator">&amp;</span><span class="token assign-left variable">type</span><span class="token operator">=</span><span class="token number">1</span><span class="token operator">&amp;</span><span class="token assign-left variable">token</span><span class="token operator">=</span>XUzBRPIdCesGx7DYyaHerdaP2XkuXk2m<span class="token operator">&amp;</span><span class="token assign-left variable">format</span><span class="token operator">=</span>txt<span class="token punctuation">]</span>

<span class="token punctuation">{<!-- --></span>
    <span class="token string">"errcode"</span><span class="token builtin class-name">:</span> <span class="token number">0</span>,
    <span class="token string">"errmsg"</span><span class="token builtin class-name">:</span> <span class="token string">"获取ip地址成功,共1个"</span>,
    <span class="token string">"data"</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span>
        <span class="token punctuation">{<!-- --></span>
            <span class="token string">"real_ip"</span><span class="token builtin class-name">:</span> <span class="token string">"182.114.35.123"</span>,
            <span class="token string">"ip"</span><span class="token builtin class-name">:</span> <span class="token string">"182.114.35.123"</span>,
            <span class="token string">"prov"</span><span class="token builtin class-name">:</span> <span class="token string">"河南"</span>,
            <span class="token string">"city"</span><span class="token builtin class-name">:</span> <span class="token string">"三门峡"</span>,
            <span class="token string">"isp"</span><span class="token builtin class-name">:</span> <span class="token string">"联通"</span>,
            <span class="token string">"proxy_user"</span><span class="token builtin class-name">:</span> <span class="token string">"9ER62CtIr"</span>,
            <span class="token string">"proxy_pass"</span><span class="token builtin class-name">:</span> <span class="token string">"fGGVvqedX"</span>,
            <span class="token string">"proxy_port"</span><span class="token builtin class-name">:</span> <span class="token number">10007</span>,
            <span class="token string">"usage"</span><span class="token builtin class-name">:</span> <span class="token string">"curl -x 182.114.35.123:10007 -U 9ER62CtIr:fGGVvqedX https://www.baidu.com"</span>,
            <span class="token string">"expire_time"</span><span class="token builtin class-name">:</span> <span class="token string">"2023-12-31 17:49:59"</span>,
            <span class="token string">"expire_timestamp"</span><span class="token builtin class-name">:</span> <span class="token number">1704016199</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">]</span>
<span class="token punctuation">}</span>
</code></pre> 
<ul><li>申请好代理IP后替换代码中账号密码然后点击运行，发现并没有通过认证：</li></ul> 
<p><img src="https://images2.imgbox.com/5c/3c/W7DO0S7V_o.png" alt=""></p> 
<ul><li>为了排除是代理本身的问题，使用 curl 命令确认代理 IP 是否可以正常访问，说明是使用上的问题，经过15分钟的搜索和验证，最后让我找到了解决方案 - 使用 Selenium-Chrome-HTTP-Private-Proxy。</li></ul> 
<p><img src="https://images2.imgbox.com/3b/eb/WYDb5DYM_o.png" alt=""></p> 
<h3><a id="SeleniumChromeHTTPPrivateProxy_HTTP__178"></a>Selenium-Chrome-HTTP-Private-Proxy HTTP 代理解决方案</h3> 
<ul><li>默认情况下，Chrome的–proxy-server="http://ip:port"参数不支持设置用户名和密码认证。因此"Selenium + Chrome Driver"无法使用HTTP Basic Authentication的HTTP代理。一种变通的方式就是采用IP地址认证，但在国内网络环境下，大多数用户都采用ADSL形式网络接入，IP是变化的，也无法采用IP地址绑定认证。因此迫切需要找到一种让Chrome自动实现HTTP代理用户名密码认证的方案。</li><li>Stackoverflow上有人分享了一种利用Chrome插件实现自动代理用户密码认证的方案非常不错，详细地址：http://stackoverflow.com/questions/9888323/how-to-override-basic-authentication-in-selenium2-with-java-using-chrome-driver</li><li>鲲之鹏的技术人员在此思路的基础上用Python实现了自动化的Chrome插件创建过程，即根据指定的代理“username:password@ip:port”自动创建一个Chrome代理插件，然后可以在"Selenium + Chrome Driver"中通过安装该插件实现代理配置功能（插件地址：https://github.com/RobinDev/Selenium-Chrome-HTTP-Private-Proxy）</li></ul> 
<h4><a id="_183"></a>如何实现</h4> 
<ul><li>1、访问插件地址下载插件，放在项目目录中供使用</li><li>2、编写代码</li></ul> 
<pre><code class="prism language-Python">import time

from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service


def create_proxyauth_extension(proxy_host, proxy_port,
                               proxy_username, proxy_password,
                               scheme='http', plugin_path=None):
    """Proxy Auth Extension

    args:
        proxy_host (str): domain or ip address, ie proxy.domain.com
        proxy_port (int): port
        proxy_username (str): auth username
        proxy_password (str): auth password
    kwargs:
        scheme (str): proxy scheme, default http
        plugin_path (str): absolute path of the extension

    return str -&gt; plugin_path
    """
    import string
    import zipfile

    if plugin_path is None:
        plugin_path = 'Selenium-Chrome-HTTP-Private-Proxy.zip'

    manifest_json = """
    {
        "version": "1.0.0",
        "manifest_version": 2,
        "name": "Chrome Proxy",
        "permissions": [
            "proxy",
            "tabs",
            "unlimitedStorage",
            "storage",
            "&lt;all_urls&gt;",
            "webRequest",
            "webRequestBlocking"
        ],
        "background": {
            "scripts": ["background.js"]
        },
        "minimum_chrome_version":"22.0.0"
    }
    """

    background_js = string.Template(
        """
        var config = {
                mode: "fixed_servers",
                rules: {
                  singleProxy: {
                    scheme: "${scheme}",
                    host: "${host}",
                    port: parseInt(${port})
                  },
                  bypassList: ["foobar.com"]
                }
              };

        chrome.proxy.settings.set({value: config, scope: "regular"}, function() {});

        function callbackFn(details) {
            return {
                authCredentials: {
                    username: "${username}",
                    password: "${password}"
                }
            };
        }

        chrome.webRequest.onAuthRequired.addListener(
                    callbackFn,
                    {urls: ["&lt;all_urls&gt;"]},
                    ['blocking']
        );
        """
    ).substitute(
        host=proxy_host,
        port=proxy_port,
        username=proxy_username,
        password=proxy_password,
        scheme=scheme,
    )
    with zipfile.ZipFile(plugin_path, 'w') as zp:
        zp.writestr("manifest.json", manifest_json)
        zp.writestr("background.js", background_js)

    return plugin_path


def configure_headless_browser(proxy_config):
    chrome_options = Options()
    chrome_options.add_argument("--start-maximized")
    proxyauth_plugin_path = create_proxyauth_extension(
        proxy_host=proxy_config[0],
        proxy_port=proxy_config[1],
        proxy_username=proxy_config[2],
        proxy_password=proxy_config[3]
    )
    chrome_options.add_extension(proxyauth_plugin_path)
    # chrome_options.add_argument('--headless')
    # chrome_options.add_argument(
    #     "user-agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/95.0.4638.69 Safari/537.36'")
    chrome_service = Service("./chromedriver.exe")
    return webdriver.Chrome(service=chrome_service, options=chrome_options)


# 设置代理IP
proxy_config = ["175.153.142.127""", "10033", "9ER62CtIr", "fGGVvqedX"]

# 启动浏览器
driver = configure_headless_browser(proxy_config)

# 访问百度官网
driver.get('https://www.baidu.com')

# 在这里执行你的操作，比如查找元素、输入搜索关键词等
time.sleep(30)

# 关闭浏览器
driver.quit()
</code></pre> 
<ul><li>点击测试运行，运行成功，并确认正确使用代理IP：</li></ul> 
<p><img src="https://images2.imgbox.com/55/5a/UofJKq3G_o.png" alt=""></p> 
<p><img src="https://images2.imgbox.com/12/95/PEeYonfr_o.png" alt=""></p> 
<h2><a id="_323"></a>总结</h2> 
<ul><li>本文介绍了 Selenium 使用无账号和有账号密码进行代理爬虫的方式，无账号密码主要基于浏览器 --proxy-server 参数实现，而有账号密码的方式基于 Selenium-Chrome-HTTP-Private-Proxy 插件实现；同时分享了一种免费获取代理IP的方式（一连代理），感兴趣的朋友可以试试。</li></ul> 
<h2><a id="_325"></a>总结</h2> 
<ul><li>本文介绍了 Selenium 使用无账号和有账号密码进行代理爬虫的方式，无账号密码主要基于浏览器 --proxy-server 参数实现，而有账号密码的方式基于 Selenium-Chrome-HTTP-Private-Proxy 插件实现；同时分享了一种免费获取代理IP的方式（一连代理），感兴趣的朋友可以试试。</li></ul> 
<h2><a id="_327"></a>个人简介</h2> 
<p>👋 你好，我是 Lorin 洛林，一位 Java 后端技术开发者！座右铭：<strong>Technology has the power to make the world a better place.</strong></p> 
<p>🚀 我对技术的热情是我不断学习和分享的动力。我的博客是一个关于Java生态系统、后端开发和最新技术趋势的地方。</p> 
<p>🧠 作为一个 Java 后端技术爱好者，我不仅热衷于探索语言的新特性和技术的深度，还热衷于分享我的见解和最佳实践。我相信知识的分享和社区合作可以帮助我们共同成长。</p> 
<p>💡 在我的博客上，你将找到关于Java核心概念、JVM 底层技术、常用框架如Spring和Mybatis 、MySQL等数据库管理、RabbitMQ、Rocketmq等消息中间件、性能优化等内容的深入文章。我也将分享一些编程技巧和解决问题的方法，以帮助你更好地掌握Java编程。</p> 
<p>🌐 我鼓励互动和建立社区，因此请留下你的问题、建议或主题请求，让我知道你感兴趣的内容。此外，我将分享最新的互联网和技术资讯，以确保你与技术世界的最新发展保持联系。我期待与你一起在技术之路上前进，一起探讨技术世界的无限可能性。</p> 
<p>📖 保持关注我的博客，让我们共同追求技术卓越。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/d66fd20cc3b7f2af199d8fd74a1d04dd/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Mac 彻底删除 node 和 npm</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/9e8d9c7f651f7ff1a40f88564693ee14/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">SpringBoot使用WebSocket</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>