<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>多智能体强化学习 (MARL) 算法框架综述 (一) - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/684138e247aebba3b39822c811f62271/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="多智能体强化学习 (MARL) 算法框架综述 (一)">
  <meta property="og:description" content="多智能体强化学习问题不仅有环境交互问题，还有智能体之间的动态影响，因此为了得到最优策略，每个智能体都需要考察其他智能体的动作及状态得到联合动作值函数。以何种形式怎么获取其他智能体的信息成为了研究焦点。
本文主要关注协作学习。
文章目录 前言一、基于值函数的方法：1. [Value-Decomposition Networks For Cooperative Multi-Agent Learning (VDN)](https://arxiv.org/pdf/1706.05296.pdf)2. [QMIX: Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning](https://arxiv.org/pdf/1803.11485.pdf)3. [QTRAN: Learning to Factorize with Transformation for Cooperative Multi-Agent Reinforcement learning](https://arxiv.org/pdf/1905.05408.pdf)4. [Multi-Agent Determinantal Q-Learning （Q-DPP，Deep Q-DPP）](https://arxiv.org/abs/2006.01482)5. [Mean Field Multi-Agent Reinforcement Learning（MFMARL）面向大规模智能体](https://arxiv.org/abs/1802.05438v4) 二、基于演员-评论家的方法1. [Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments (MADDPG)](https://proceedings.neurips.cc/paper_files/paper/2017/file/68a9750337a418a86fe06c1991a1d64c-Paper.pdf)2. [Counterfactual Multi-Agent Policy Gradients (COMA)](https://arxiv.org/abs/1705.08926)3. [Multiagent Soft Q-Learning (MASQL)](https://arxiv.org/abs/1804.09817)4. [Actor-Attention-Critic for Multi-Agent Reinforcement Learning (MAAC)](https://arxiv.org/pdf/1810.02912.pdf) 三、基于经验回放（ER）缓存的方法：1. [Stabilising experience replay for deep multi-agent reinforcement learning (concurrent experience replay trajectories 的概念)](https://arxiv.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2023-05-30T17:42:32+08:00">
    <meta property="article:modified_time" content="2023-05-30T17:42:32+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">多智能体强化学习 (MARL) 算法框架综述 (一)</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <blockquote> 
 <p>多智能体强化学习问题不仅有环境交互问题，还有智能体之间的动态影响，因此为了得到最优策略，每个智能体都需要考察其他智能体的动作及状态得到联合动作值函数。以何种形式怎么获取其他智能体的信息成为了研究焦点。<br> <strong>本文主要关注协作学习</strong>。</p> 
</blockquote> 
<p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#_9" rel="nofollow">前言</a></li><li><a href="#_38" rel="nofollow">一、基于值函数的方法：</a></li><li><ul><li><a href="#1_ValueDecomposition_Networks_For_Cooperative_MultiAgent_Learning_VDNhttpsarxivorgpdf170605296pdf_41" rel="nofollow">1. [Value-Decomposition Networks For Cooperative Multi-Agent Learning (VDN)](https://arxiv.org/pdf/1706.05296.pdf)</a></li><li><a href="#2_QMIX_Monotonic_Value_Function_Factorisation_for_Deep_MultiAgent_Reinforcement_Learninghttpsarxivorgpdf180311485pdf_57" rel="nofollow">2. [QMIX: Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning](https://arxiv.org/pdf/1803.11485.pdf)</a></li><li><a href="#3_QTRAN_Learning_to_Factorize_with_Transformation_for_Cooperative_MultiAgent_Reinforcement_learninghttpsarxivorgpdf190505408pdf_68" rel="nofollow">3. [QTRAN: Learning to Factorize with Transformation for Cooperative Multi-Agent Reinforcement learning](https://arxiv.org/pdf/1905.05408.pdf)</a></li><li><a href="#4_MultiAgent_Determinantal_QLearning_QDPPDeep_QDPPhttpsarxivorgabs200601482_82" rel="nofollow">4. [Multi-Agent Determinantal Q-Learning （Q-DPP，Deep Q-DPP）](https://arxiv.org/abs/2006.01482)</a></li><li><a href="#5_Mean_Field_MultiAgent_Reinforcement_LearningMFMARLhttpsarxivorgabs180205438v4_95" rel="nofollow">5. [Mean Field Multi-Agent Reinforcement Learning（MFMARL）面向大规模智能体](https://arxiv.org/abs/1802.05438v4)</a></li></ul> 
  </li><li><a href="#_108" rel="nofollow">二、基于演员-评论家的方法</a></li><li><ul><li><a href="#1_MultiAgent_ActorCritic_for_Mixed_CooperativeCompetitive_Environments_MADDPGhttpsproceedingsneuripsccpaper_filespaper2017file68a9750337a418a86fe06c1991a1d64cPaperpdf_110" rel="nofollow">1. [Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments (MADDPG)](https://proceedings.neurips.cc/paper_files/paper/2017/file/68a9750337a418a86fe06c1991a1d64c-Paper.pdf)</a></li><li><a href="#2_Counterfactual_MultiAgent_Policy_Gradients_COMAhttpsarxivorgabs170508926_123" rel="nofollow">2. [Counterfactual Multi-Agent Policy Gradients (COMA)](https://arxiv.org/abs/1705.08926)</a></li><li><a href="#3_Multiagent_Soft_QLearning_MASQLhttpsarxivorgabs180409817_132" rel="nofollow">3. [Multiagent Soft Q-Learning (MASQL)](https://arxiv.org/abs/1804.09817)</a></li><li><a href="#4_ActorAttentionCritic_for_MultiAgent_Reinforcement_Learning_MAAChttpsarxivorgpdf181002912pdf_140" rel="nofollow">4. [Actor-Attention-Critic for Multi-Agent Reinforcement Learning (MAAC)](https://arxiv.org/pdf/1810.02912.pdf)</a></li></ul> 
  </li><li><a href="#ER_153" rel="nofollow">三、基于经验回放（ER）缓存的方法：</a></li><li><ul><li><a href="#1_Stabilising_experience_replay_for_deep_multiagent_reinforcement_learning_concurrent_experience_replay_trajectories_httpsarxivorgpdf170208887_156" rel="nofollow">1. [Stabilising experience replay for deep multi-agent reinforcement learning (concurrent experience replay trajectories 的概念)](https://arxiv.org/pdf/1702.08887)</a></li><li><a href="#2_Deep_decentralized_multitask_multiagent_reinforcement_learning_under_partial_observability_importance_sampling_httpsarxivorgpdf170306182_161" rel="nofollow">2. [Deep decentralized multi-task multi-agent reinforcement learning under partial observability (importance sampling 的角度)](https://arxiv.org/pdf/1703.06182)</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<hr> 
<h2><a id="_9"></a>前言</h2> 
<table><thead><tr><th>简写</th><th>全称</th><th>翻译</th></tr></thead><tbody><tr><td>Dec-POMDP</td><td>Decentralized-Partially Observable Markoc Decision Process</td><td>非中心部分可观马尔可夫决策过程</td></tr><tr><td><span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
        
         
          
          
            C 
           
          
         
           \mathbb C 
          
         
       </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6889em;"></span><span class="mord mathbb">C</span></span></span></span></span>Dec-POMDP</td><td>collective Dec-POMDP</td><td>形式化了不确定性下的集体多智能体顺序决策问题</td></tr><tr><td>CTDE</td><td>Centralized Training Decentralized Execution</td><td>中心化训练去中心化执行</td></tr><tr><td>CTCE</td><td>Centralized Training Centralized Execution</td><td>中心化训练中心化执行</td></tr></tbody></table> 
<ol><li><strong>多智能体强化学习核心问题</strong>：<br> 1）如何学习<strong>联合动作值函数</strong>。特别是当动作值函数的输入空间过大，则很难拟合出一个合适函数来表示真实的联合动作值函数，因为联合动作值函数的参数会随着智能体数量的增多而成<strong>指数</strong>增长。<br> 2）如何通过联合值函数提取出一个优秀的<strong>分布式的策略</strong>。</li><li>MARL的分类：<br> MARL简单的可以分为四类：<br> 1）<strong>Analysis of emergent behaviors（行为分析）</strong>（又可称为<strong>独立学习</strong>，IL。仅将其他主体对系统的影响视为环境的一部分。学习主体不仅面临着一个非平稳的环境，而且还遭受着虚假的奖励。该方法的一般做法是：将单智能体强化学习算法直接应用到多智能体环境之中，每个智能体之间相互独立，遵循 Independent Q-Learning（暴力的使每个智能体执行各自的Q-learning算法，但由于多智能体的环境其实在变，所以大部分情况下是无法收敛的）。e.g., <a href="https://pdfs.semanticscholar.org/83bf/91012997019f432179aad798e6d3fbb95c36.pdf" rel="nofollow">IQL+DQN</a>，<a href="https://platformlab.stanford.edu/pdf/ALA2017_Gupta.pdf" rel="nofollow">DQN/TRPO/DDPG+IQL</a>）。<br> 2）<strong>Learning communication（通信学习）</strong>（智能体之间存在显式的通信交互，在训练过程中学习如何根据自身的局部观察来生成信息，或者来确定是否需要通信、与哪些智能体通信等。训练完成后，要显式的依据其余智能体传递的信息进行决策。e.g., <a href="https://proceedings.neurips.cc/paper_files/paper/2016/file/c7635bfd99248a2cdef8249ef7bfbef4-Paper.pdf" rel="nofollow">RIAL and DIAL</a>，<a href="https://proceedings.neurips.cc/paper_files/paper/2016/file/55b1927fdafef39c48e5b73b5d61ea60-Paper.pdf" rel="nofollow">CommNet</a>，<a href="https://arxiv.org/pdf/1703.10069.pdf" rel="nofollow">BiCNet</a>，<a href="https://proceedings.neurips.cc/paper_files/paper/2018/file/6a8018b3a00b69c008601b8becae392b-Paper.pdf" rel="nofollow">基于注意力机制的通信模型 ATOC</a>，<a href="https://arxiv.org/pdf/1902.01554.pdf" rel="nofollow">SchedNet </a>）。<br> 3）<strong>Learning cooperation（协作学习）</strong>（隐式的学习智能体间通信，将多智能体领域一些思想引入MARL中。e.g., <a href="https://arxiv.org/pdf/1706.05296.pdf" rel="nofollow">VDN </a>，<a href="https://arxiv.org/pdf/1803.11485.pdf" rel="nofollow">QMIX</a>，<a href="https://arxiv.org/pdf/1905.05408.pdf" rel="nofollow">QTRAN</a>；<a href="https://proceedings.neurips.cc/paper_files/paper/2017/file/68a9750337a418a86fe06c1991a1d64c-Paper.pdf" rel="nofollow">MADDPG</a>，<a href="https://arxiv.org/abs/1705.08926" rel="nofollow">COMA</a>，<a href="https://arxiv.org/abs/1804.09817" rel="nofollow">MASQL</a>，<a href="https://arxiv.org/pdf/1810.02912.pdf" rel="nofollow">MAAC</a>；<a href="https://arxiv.org/pdf/1702.08887" rel="nofollow">concurrent experience replay trajectories 的概念</a>，<a href="https://arxiv.org/pdf/1703.06182" rel="nofollow">importance sampling 的角度</a>）。<br> 4）<strong>Agents modeling agents（智能体建模）</strong>（聚焦于通过对其他智能体的策略、目标、类别等等建模来进行更好的协作或者更快地打败竞争对手。e.g., <a href="https://arxiv.org/pdf/1702.08887" rel="nofollow">episode 索引号+exploration rate</a>, <a href="https://arxiv.org/pdf/1802.07740.pdf" rel="nofollow">预测智能体未来行为</a>）。</li></ol> 
<p><code>本文主要关注协作学习</code></p> 
<p><a href="https://arxiv.org/abs/2006.01482" rel="nofollow">[Multi-Agent Determinantal Q-Learning]</a> 给出了另一种分类方式：<br> <img src="https://images2.imgbox.com/72/09/TxHyNV00_o.png" alt="在这里插入图片描述"><br> 3. 协作学习简单的可以分为三种方式：</p> 
<ul><li>基于<strong>值函数</strong>的方法：通过 value decomposition 方式来解决可扩展性问题。（<code>VDN，QMIX，QTRAN</code>）</li><li>基于<strong>演员-评论家</strong>的方法：由于其结构的特殊性，可以通过中心化学习（共享/独立）评论家但是每个智能体独立的演员，来很好的处理算法可扩展性问题的同时，拥有很好的抗环境非平稳能力。（<code>MADDPG，COMA，MASQL，MAAC</code>）</li><li>基于 <strong>经验回放 (ER)</strong> 的方法：使用 ER 训练 Q-function 时增加稳定性（CommNet 甚至因为 ER 在 multi-agent 环境下的不稳定性而禁用了 ER），所涉及的两个工作前者遵循 CTDE 框架，并且类似 MADDPG 方法一样，均假设每个智能体拥有自己独立的 Q-function；后者则是完全独立的 IQL。这两个方法都是基于 Q-Learning 算法。（<code>Stabilising experience replay, DRQN</code>）</li></ul> 
<ol start="4"><li><strong>Dec-POMDP问题</strong>：所有智能体共享一个全局的回报函数，且智能体只拥有自己的局部观察，而带来的种种问题。比如：<strong>多智能体信用分配问题</strong>（所有智能体共享同一个全局回报，因而每个智能体不知道自己的行为到底对这个全局回报产生了多大的影响）；<strong>relative overgeneralization问题</strong>（某智能体的执行某动作大于另一联合动作带来的期望收益，而导致智能体收敛到次优点）</li></ol> 
<h2><a id="_38"></a>一、基于值函数的方法：</h2> 
<blockquote> 
 <p>CTDE框架居多。基于值函数的方法中一个基本的挑战是：“<strong>如何正确地分解代理之间的联合值函数以进行分散执行</strong>。”<br> 对于协作任务是可去中心化的任务，要求<strong>每个代理的值函数上的局部最大值应该等于联合值函数上的全局最大值</strong>。</p> 
</blockquote> 
<h3><a id="1_ValueDecomposition_Networks_For_Cooperative_MultiAgent_Learning_VDNhttpsarxivorgpdf170605296pdf_41"></a>1. <a href="https://arxiv.org/pdf/1706.05296.pdf" rel="nofollow">Value-Decomposition Networks For Cooperative Multi-Agent Learning (VDN)</a></h3> 
<p><code>解决Dec-POMDP问题。</code><br> <code>满足联合值函数与局部值函数单调性相同的可以进行分布化策略的条件，即使得’局部值函数最大对应的动作也使得联合动作值函数最大’。</code></p> 
<p><code>核心思想：联合Q函数等于所有智能体的局部值函数求和。</code></p> 
<p><strong>基本思想</strong>：对每个智能体的Q函数相加，整合为一个联合的Q函数。其中局部Q函数只依赖于每个智能体的局部观测。联合的Q函数等于局部值函数的累加。For example，联合动作-值函数 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          Q 
         
         
         
           t 
          
         
           o 
          
         
           t 
          
         
        
       
         = 
        
        
        
          ∑ 
         
         
         
           i 
          
         
           = 
          
         
           1 
          
         
        
          n 
         
        
        
        
          Q 
         
        
          i 
         
        
       
         ( 
        
        
        
          τ 
         
        
          i 
         
        
       
         , 
        
        
        
          a 
         
        
          i 
         
        
       
         ; 
        
        
        
          θ 
         
        
          i 
         
        
       
         ) 
        
       
      
        Q_{tot}=\sum_{i=1}^{n}Q_i(\tau_i,a_i;\theta_i) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8778em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2806em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1.104em; vertical-align: -0.2997em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position: relative; top: 0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.8043em;"><span class="" style="top: -2.4003em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span class="" style="top: -3.2029em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2997em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1132em;">τ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.1132em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.0278em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>，其中<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         τ 
        
       
         = 
        
       
         ( 
        
        
        
          τ 
         
        
          1 
         
        
       
         , 
        
       
         . 
        
       
         . 
        
       
         . 
        
       
         , 
        
        
        
          τ 
         
        
          n 
         
        
       
         ) 
        
       
      
        \tau=(\tau_1,...,\tau_n) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal" style="margin-right: 0.1132em;">τ</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1132em;">τ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.1132em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1132em;">τ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.1132em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>为联合动作-观测历史，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          τ 
         
        
          i 
         
        
       
         = 
        
       
         ( 
        
        
        
          a 
         
         
         
           i 
          
         
           , 
          
         
           0 
          
         
        
       
         , 
        
        
        
          o 
         
         
         
           i 
          
         
           , 
          
         
           0 
          
         
        
       
         . 
        
       
         . 
        
       
         . 
        
       
         , 
        
        
        
          a 
         
         
         
           i 
          
         
           , 
          
         
           t 
          
         
        
       
         , 
        
        
        
          o 
         
         
         
           i 
          
         
           , 
          
         
           t 
          
         
        
       
         ) 
        
       
      
        \tau_i=(a_{i,0},o_{i,0}...,a_{i,t},o_{i,t}) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5806em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1132em;">τ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.1132em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1.0361em; vertical-align: -0.2861em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">o</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">o</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>, <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         i 
        
       
      
        i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span></span> 为agent的索引，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         t 
        
       
      
        t 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6151em;"></span><span class="mord mathnormal">t</span></span></span></span></span> 是step的索引。</p> 
<ul><li>基本原理：中心化地训练一个联合的 Q network，但是这个联合的网络是由所有智能体局部的 Q networks 加和得到，这样不仅可以通过中心化训练处理由于环境非平稳带来的问题，而且由于实际是在学习每个智能体的局部模型，因而解耦智能体之间复杂的相互关系。最后，由于训练完毕后每个智能体拥有只基于自己局部观察的 Q network，可以实现去中心化执行，即 VDN 遵循 CTDE 框架，并且解决的是 Dec-POMDP 问题。</li><li>Q network 是使用 <strong>LSTM</strong> 构建。</li><li>可以保证训练完毕后去中心化执行时，即使整个系统只基于局部观察进行决策，其策略也是与基于全局观察进行决策是一致的。</li><li>VDN 采用了 <strong>parameter sharing</strong> 方法，并因此提出了 <strong>Agent Invariance</strong>，来解决大规模环境下的可扩展性和部分懒惰的智能体的问题。</li><li>引入了类似于<strong>智能体索引号</strong>这样的额外信息来表示智能体的不同角色。整个多智能体系统是 <strong>conditionally agent invariant</strong>。</li><li>为了减小 value decompostion 带来的误差，显式加入了<strong>通信模块</strong>，并分为高层通信以及低层通信（低层通信其实是互相共享局部观察）。</li></ul> 
<h3><a id="2_QMIX_Monotonic_Value_Function_Factorisation_for_Deep_MultiAgent_Reinforcement_Learninghttpsarxivorgpdf180311485pdf_57"></a>2. <a href="https://arxiv.org/pdf/1803.11485.pdf" rel="nofollow">QMIX: Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning</a></h3> 
<p><code>是 VDN 算法的后续工作，它的出发点是 VDN 做联合 Q-value 分解时只是进行简单的加和（线性），没有办法捕捉到智能体之间更复杂的相互关系。QMIX的主要创新是采用一个混合网络对单智能体局部值函数进行合并，并在训练学习过程中加入全局状态信息辅助，来提高算法性能。</code></p> 
<p><code>核心思想：用 Mixed network（一个神经网络）拟合所有智能体的局部值函数与联合值函数的非线性关系，来替代VDN中线性的加和。</code></p> 
<ul><li>多智能体共用一个奖励（由联合动作和状态得到），<strong>只能用于合作不能用于竞争环境</strong>。针对分布式多智能体Dec-POMDP。</li><li>包含 agent network（为了合并各智能体的Q值得到联合的Q值。DRQN网络，输入自己的局部观测和上一时刻自己的动作来拟合自身的Q值）、mixing network（非线性。表达能力超过VDN中的加和。其中每一个局部 Q-value 的权重必须非负，因此会加绝对值操作或者 ReLU 操作） 以及 hypernetworks（为了更多的利用整个系统的状态信息，将系统的状态作为输入，输出混合网络的权值及偏移量）的架构。</li><li><strong>CTDE</strong>框架。<strong>训练</strong>的每个时刻的<strong>全局状态</strong>作为 mixing network 的额外输入来提高算法效果（相对VDN改进之一）。</li><li>每个整体求得自己的局部Q值函数仅使用自己的局部观测（这一步是分布式的），选出累计期望奖励最大的动作执行。（算法使联合动作值函数与每个局部值函数的单调性相同，因此对<strong>局部值函数取最大动作也就是使联合动作值函数最大</strong>）。</li><li>针对联合Q值函数用<strong>神经网络</strong>整合（而不是像VDN那样直接对Q函数求和，改进二）。</li><li><a href="https://zhuanlan.zhihu.com/p/55003734" rel="nofollow">更详细的</a>。</li></ul> 
<h3><a id="3_QTRAN_Learning_to_Factorize_with_Transformation_for_Cooperative_MultiAgent_Reinforcement_learninghttpsarxivorgpdf190505408pdf_68"></a>3. <a href="https://arxiv.org/pdf/1905.05408.pdf" rel="nofollow">QTRAN: Learning to Factorize with Transformation for Cooperative Multi-Agent Reinforcement learning</a></h3> 
<p><code>VDN是对局部Q函数加和得到联合Q函数，指导多智能体行动，是线性的；</code><br> <code>QMIX认为VDN这种线性的合并方式无法拟合复杂的函数关系，比如非线性的。因此他提出了更一般的单调性条件，i.e., 联合Q函数对局部Q函数的偏导≥0；</code><br> <code>QTRAN的动机是他认为VDN和QMIX无法处理非单调收益的合作问题。作者声称其所提的QTRAN能分解任何可分解的任务。</code></p> 
<p><code>在QMIX的基础上引入了一个改进的学习目标，以及特定的网络设计。</code><br> <code>对 VDN 以及 QMIX 算法的进一步改进。将根据局部 Q 函数采用神经网络去逼近联合 Q 函数分为两步</code></p> 
<ul><li>首先采用 VDN 的方式得到加和的局部 Q 函数，来作为联合 Q 函数的近似；</li><li>接着拟合局部 Q 函数与联合 Q 函数的差值。</li><li>定义一个 <strong>transformed joint-action value function</strong> (其实就是加和，用来逼近联合 Q 函数)。</li><li><strong>QTRAN-base</strong>：独立 Q 网络；联合 Q 网络；联合 V 网络</li><li><strong>QTRAN-alt</strong>：对QTRAN-base的进一步增强。</li></ul> 
<h3><a id="4_MultiAgent_Determinantal_QLearning_QDPPDeep_QDPPhttpsarxivorgabs200601482_82"></a>4. <a href="https://arxiv.org/abs/2006.01482" rel="nofollow">Multi-Agent Determinantal Q-Learning （Q-DPP，Deep Q-DPP）</a></h3> 
<p><code>文章认为现有的 value-based CTDE 方法，例如 VDN / QMIX / QTRAN 的性能会受到其定义的函数族的限制。具体地，限制了集中值函数的表征能力；并且阻碍了在应用于值函数分解时的有效探索。</code><br> <code>为了解决这个问题，文章认为如果在算法执行的过程中，每个智能体执行的动作之间差异足够大，那么可以认为对于每个智能体而言其最优动作不受到其余智能体动作的影响。这样就意味着在每个智能体的值函数上分别求得的局部最优等价于在联合值函数上求得的全局最优。</code></p> 
<ul><li>由于结构约束（如QMIX中的单调性假设），在多智能体设置中，增加随机探索只会降低获得最优值函数的概率。</li><li>CTDE框架，解决Dec-POMDP问题。</li><li>引入了 <strong>Determinant Point Process (DPP)</strong> 这样一个一般性的概率模型，以使算法能够为每个智能体执行<strong>差异足够大的动作</strong>，且算法的性能<strong>不受到所选函数族的限制</strong>。这个概率模型衡量的是从一个 <strong>ground set</strong> 中采样出一个 <strong>subset</strong> 的概率。这个概率的大小会受到这个 subset 中各元素的<strong>质量</strong>以及元素之间的<strong>多样性</strong>的影响。</li><li>采用 <strong>Q-DPP</strong> 作为中心化价值函数的函数逼近器。</li><li>MARL中Ground set <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          Y 
         
        
          = 
         
         
         
           { 
          
          
          
            ( 
           
           
           
             o 
            
           
             1 
            
           
             1 
            
           
          
            , 
           
           
           
             a 
            
           
             1 
            
           
             1 
            
           
          
            ) 
           
          
         
           , 
          
         
           … 
          
         
           , 
          
          
          
            ( 
           
           
           
             o 
            
           
             N 
            
            
            
              ∣ 
             
            
              O 
             
            
              ∣ 
             
            
           
          
            , 
           
           
           
             a 
            
           
             N 
            
            
            
              ∣ 
             
            
              A 
             
            
              ∣ 
             
            
           
          
            ) 
           
          
         
           } 
          
         
        
       
         \mathcal{Y}=\left\{\left(o_1^1, a_1^1\right), \ldots,\left(o_N^{|\mathcal{O}|}, a_N^{|\mathcal{A}|}\right)\right\} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7805em; vertical-align: -0.0972em;"></span><span class="mord mathcal" style="margin-right: 0.0822em;">Y</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1.8em; vertical-align: -0.65em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;"><span class="delimsizing size2">{<!-- --></span></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord mathnormal">o</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.8141em;"><span class="" style="top: -2.4519em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2481em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.8141em;"><span class="" style="top: -2.4519em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2481em;"><span class=""></span></span></span></span></span></span><span class="mclose delimcenter" style="top: 0em;"><span class="delimsizing size1">)</span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;"><span class="delimsizing size2">(</span></span><span class="mord"><span class="mord mathnormal">o</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.0448em;"><span class="" style="top: -2.4065em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.109em;">N</span></span></span><span class="" style="top: -3.2198em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∣</span><span class="mord mathcal mtight" style="margin-right: 0.0278em;">O</span><span class="mord mtight">∣</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2935em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.0448em;"><span class="" style="top: -2.4065em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.109em;">N</span></span></span><span class="" style="top: -3.2198em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">∣</span><span class="mord mathcal mtight">A</span><span class="mord mtight">∣</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2935em;"><span class=""></span></span></span></span></span></span><span class="mclose delimcenter" style="top: 0em;"><span class="delimsizing size2">)</span></span></span><span class="mclose delimcenter" style="top: 0em;"><span class="delimsizing size2">}</span></span></span></span></span></span></span>,将<strong>所有</strong>智能体<strong>所有</strong>可能的观测-动作对定义为Ground set. <code>因此，本文也是仅考虑了离散状态和空间</code>。</li><li>然后将<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          Y 
         
        
       
         \mathcal{Y} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7805em; vertical-align: -0.0972em;"></span><span class="mord mathcal" style="margin-right: 0.0822em;">Y</span></span></span></span></span>分为每个智能体各自的集合 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           Y 
          
         
           i 
          
         
        
       
         \mathcal{Y}_i 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathcal" style="margin-right: 0.0822em;">Y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.0822em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>。随后定义DPP。该函数表明了在<strong>给定联合观测的情况下，所有智能体每一种联合动作被采样的概率</strong>，这样一来，我们就可以把上述 DPP 模型 “看作” MARL 中的联合策略。</li><li>随后定义了该假设下的Q函数。用Q-learning最大化这个Q函数。</li><li>文中提到，Q-DPP可以拓展到连续动作&amp;状态。但并没有细说。</li><li><a href="https://zhuanlan.zhihu.com/p/146751574" rel="nofollow">更详细的</a></li></ul> 
<h3><a id="5_Mean_Field_MultiAgent_Reinforcement_LearningMFMARLhttpsarxivorgabs180205438v4_95"></a>5. <a href="https://arxiv.org/abs/1802.05438v4" rel="nofollow">Mean Field Multi-Agent Reinforcement Learning（MFMARL）面向大规模智能体</a></h3> 
<p><code>随着智能体数量的增多，其状态空间跟动作空间迅速扩大，这给计算以及探索带来了非常大的困难。</code><br> <code>借用平均场论（Mean Field Theory，MFT）的思想，将一个智能体与其邻居智能体之间的相互作用简化为两个智能体之间的相互作用（该智能体与其所有邻居的均值），以极大地简化智能体数量带来的模型空间的增大</code><br> <code>成立的前提是：单个智能体的最优策略的学习是基于智能体群体的动态；同时，集体的动态也根据个体的策略进行更新。</code><br> <code>由于每个智能体的策略还是需要全局的状态信息，并不算真正的分布式算法，并且算法的性能依赖于通信获取邻居智能体的动作</code>i.e., <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          a 
         
        
          k 
         
        
       
      
        a_k 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5806em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0315em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>。 不可否认的是，这是一个解决<code>大规模MA学习的方法，并且理论证明很严格。</code></p> 
<ul><li>Nash-Q算法：在每个状态s处的阶段博弈中找到一个<strong>纳什平衡点</strong>，使得<strong>每个智能体的策略是在其他智能体策略下的最优策略</strong>，这样就可以保证策略在特定情况下<strong>收敛</strong>。</li><li>用于<code>集中式</code>MARL中，联合动作<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          a 
         
        
       
         a 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal">a</span></span></span></span></span>的维度随智能体数量<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          n 
         
        
       
         n 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span></span>的增多极速扩大的情况。因为每个智能体是同时根据联合策略估计自身的值函数，因此当联合动作空间很大时，学习效率及学习效果非常差.</li><li>算法核心是将值函数<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           Q 
          
         
           π 
          
         
           j 
          
         
        
          ( 
         
        
          s 
         
        
          , 
         
        
          a 
         
        
          ) 
         
        
       
         Q_{\pi}^j(s,a) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.0747em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.8247em;"><span class="" style="top: -2.453em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">π</span></span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.247em;"><span class=""></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal">a</span><span class="mclose">)</span></span></span></span></span> 转化为只包含邻居之间相互作用的形式。则每个智能体<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          j 
         
        
       
         j 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.854em; vertical-align: -0.1944em;"></span><span class="mord mathnormal" style="margin-right: 0.0572em;">j</span></span></span></span></span>的局部值函数为 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           Q 
          
         
           j 
          
         
        
          ( 
         
        
          s 
         
        
          , 
         
        
          a 
         
        
          ) 
         
        
          = 
         
         
         
           1 
          
          
          
            N 
           
          
            j 
           
          
         
         
         
           ∑ 
          
          
          
            k 
           
          
            ∈ 
           
          
            N 
           
          
            ( 
           
          
            j 
           
          
            ) 
           
          
         
         
         
           Q 
          
         
           j 
          
         
         
         
           ( 
          
         
           s 
          
         
           , 
          
          
          
            a 
           
          
            j 
           
          
         
           , 
          
          
          
            a 
           
          
            k 
           
          
         
           ) 
          
         
        
       
         Q_j(s, a)=\frac{1}{N_j} \sum_{k \in N(j)} Q_j\left(s, a_j, a_k\right) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.0361em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal">a</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1.3874em; vertical-align: -0.5423em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.8451em;"><span class="" style="top: -2.655em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.109em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3281em;"><span class="" style="top: -2.357em; margin-left: -0.109em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2819em;"><span class=""></span></span></span></span></span></span></span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.394em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.5423em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position: relative; top: 0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2253em;"><span class="" style="top: -2.4003em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0315em;">k</span><span class="mrel mtight">∈</span><span class="mord mathnormal mtight" style="margin-right: 0.109em;">N</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.4747em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;">(</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0315em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose delimcenter" style="top: 0em;">)</span></span></span></span></span></span>， <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           N 
          
         
           j 
          
         
        
       
         {N_j} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.9694em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right: 0.109em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.109em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span></span></span></span></span></span>表示邻居节点的个数。<code>仅对联合动作a做了近似，状态信息s仍然是全局信息。</code></li><li>假定所有智能体都是<strong>同构</strong>的，其<strong>动作空间相同</strong>，并且动作空间是<strong>离散</strong>的，采用one-hot编码。<code>paper中同时提到了连续的算法也可以用该思想设计，比如说DPG</code></li><li>设智能体 <em>j</em> 的动作<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           a 
          
         
           j 
          
         
        
       
         {a}_j 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7167em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">a</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span></span></span></span></span>是one-hot编码的，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
          
          
            a 
           
          
            ˉ 
           
          
         
           j 
          
         
        
       
         \bar{a}_j 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8539em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.5678em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mathnormal">a</span></span><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.25em;"><span class="mord">ˉ</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span></span></span></span></span> 是智能体 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          j 
         
        
       
         j 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.854em; vertical-align: -0.1944em;"></span><span class="mord mathnormal" style="margin-right: 0.0572em;">j</span></span></span></span></span> 邻居 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          N 
         
        
          ( 
         
        
          j 
         
        
          ) 
         
        
       
         N(j) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.109em;">N</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0572em;">j</span><span class="mclose">)</span></span></span></span></span> 的平均动作，其邻居 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          k 
         
        
       
         k 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord mathnormal" style="margin-right: 0.0315em;">k</span></span></span></span></span> 的one-hot编码动作 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           a 
          
         
           k 
          
         
        
       
         a_k 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5806em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0315em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>可以表示为 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
          
          
            a 
           
          
            ˉ 
           
          
         
           j 
          
         
        
       
         \bar{a}_j 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8539em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.5678em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mathnormal">a</span></span><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.25em;"><span class="mord">ˉ</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span></span></span></span></span> 与一个波动<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          δ 
         
         
         
           a 
          
          
          
            j 
           
          
            , 
           
          
            k 
           
          
         
        
       
         \delta a_{j, k} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.9805em; vertical-align: -0.2861em;"></span><span class="mord mathnormal" style="margin-right: 0.0379em;">δ</span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right: 0.0315em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span></span></span></span></span>的形式 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           a 
          
         
           k 
          
         
        
          = 
         
         
          
          
            a 
           
          
            ˉ 
           
          
         
           j 
          
         
        
          + 
         
        
          δ 
         
         
         
           a 
          
          
          
            j 
           
          
            , 
           
          
            k 
           
          
         
        
          , 
         
         
        
       
         a_k=\bar{a}_j+\delta a_{j, k}, \quad 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5806em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0315em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.8694em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.5678em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mathnormal">a</span></span><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.25em;"><span class="mord">ˉ</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.9805em; vertical-align: -0.2861em;"></span><span class="mord mathnormal" style="margin-right: 0.0379em;">δ</span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right: 0.0315em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 1em;"></span></span></span></span></span> where <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
          
          
            a 
           
          
            ˉ 
           
          
         
           j 
          
         
        
          = 
         
         
         
           1 
          
          
          
            N 
           
          
            j 
           
          
         
         
         
           ∑ 
          
         
           k 
          
         
         
         
           a 
          
         
           k 
          
         
        
       
         \bar{a}_j=\frac{1}{N^j} \sum_k a^k 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8539em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.5678em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mathnormal">a</span></span><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.25em;"><span class="mord">ˉ</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1.1941em; vertical-align: -0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.8451em;"><span class="" style="top: -2.655em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.109em;">N</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.7571em;"><span class="" style="top: -2.786em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span></span></span></span></span></span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.394em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.345em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position: relative; top: 0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1864em;"><span class="" style="top: -2.4003em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0315em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2997em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8491em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0315em;">k</span></span></span></span></span></span></span></span></span></span></span></span>。推导后可得<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           Q 
          
         
           j 
          
         
        
          ( 
         
        
          s 
         
        
          , 
         
        
          a 
         
        
          ) 
         
        
          ≈ 
         
         
         
           Q 
          
         
           j 
          
         
        
          ( 
         
        
          s 
         
        
          , 
         
         
         
           a 
          
         
           j 
          
         
        
          , 
         
         
          
          
            a 
           
          
            ˉ 
           
          
         
           j 
          
         
        
          ) 
         
        
       
         Q_j (s, a) \approx Q^ j (s, a_j,\bar{a}_j) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.0361em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal">a</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1.1108em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8247em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.5678em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mathnormal">a</span></span><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.25em;"><span class="mord">ˉ</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>。<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           Q 
          
         
           j 
          
         
        
          ( 
         
        
          s 
         
        
          , 
         
         
         
           a 
          
         
           j 
          
         
        
          , 
         
         
          
          
            a 
           
          
            ˉ 
           
          
         
           j 
          
         
        
          ) 
         
        
       
         Q^ j (s, a_j,\bar{a}_j) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.1108em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8247em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.5678em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mathnormal">a</span></span><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.25em;"><span class="mord">ˉ</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span> 称为MF-Q函数。因此将智能体之间两两作用求和转化为中心智能体j与一个虚拟智能体的动作<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
          
          
            a 
           
          
            ˉ 
           
          
         
           j 
          
         
        
       
         \bar{a}_j 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8539em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.5678em;"><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord mathnormal">a</span></span><span class="" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="accent-body" style="left: -0.25em;"><span class="mord">ˉ</span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span></span></span></span></span>的相互作用。更具体的更新公式请见 <a href="https://arxiv.org/abs/1802.05438v4" rel="nofollow">paper</a>。</li><li><a href="https://zhuanlan.zhihu.com/p/146751574" rel="nofollow">更详细的</a></li></ul> 
<h2><a id="_108"></a>二、基于演员-评论家的方法</h2> 
<p><code>充分利用Actor-critic的架构，中心化学习（共享/独立）Critic 但是每个智能体独立的 Actor，处理算法可扩展性问题，提高抗环境非平稳能力</code></p> 
<h3><a id="1_MultiAgent_ActorCritic_for_Mixed_CooperativeCompetitive_Environments_MADDPGhttpsproceedingsneuripsccpaper_filespaper2017file68a9750337a418a86fe06c1991a1d64cPaperpdf_110"></a>1. <a href="https://proceedings.neurips.cc/paper_files/paper/2017/file/68a9750337a418a86fe06c1991a1d64c-Paper.pdf" rel="nofollow">Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments (MADDPG)</a></h3> 
<ul><li> <p><code>通过中心化学习一个联合的critic解决以下问题：由于策略梯度是由根据其余智能体当前策略得到的一个期望联合 Q-value 来进行放缩的，其余智能体的当前策略不一定是最优的回应该智能体的策略，会导致策略梯度估计不准确。仍然存在relative overgeneralization问题</code></p> </li><li> <p>每个Agent的Critic部分能够获取其余所有Agent的动作信息，进行中心化训练和非中心化执行，即在训练的时候，引入可以观察全局的Critic来指导Actor训练，而测试的时候只使用有局部观测的actor采取行动。</p> </li><li> <p>MADDPG的一个启发就是，如果我们知道<strong>所有的智能体的动作</strong>，那么环境就是稳定的，就算策略在不断更新环境也是恒定的，因为模型动力学是稳定的。</p> </li><li> <p>假定每一个智能体拥有自己独立的 <strong>critic- and actor-network</strong>，并且有独立的<strong>回报函数</strong>，可以同时解决协作、竞争以及混合环境下的多智能体问题。</p> </li><li> <p><strong>CTDE</strong>框架：假定每个智能体在训练时都能够获取<strong>其余所有智能体</strong>的局部观察以及动作，因而 critic network 独立，但需要中心化训练。</p> </li><li> <p>由于每个智能体的 critic 网络是基于全局信息的，因而可以处理环境非平稳问题。也就是每个智能体i的Q函数<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
       
        
         
          
          
            Q 
           
          
            i 
           
          
         
        
          Q_i 
         
        
      </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8778em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>是由<strong>所有的智能体的联合动作和观测</strong>所求得的。</p> </li><li> <p>提出<strong>估计其余智能体 policy</strong> 的方法。（因为假设中心化训练每个智能体的 critic network 时，需要知晓所有智能体当前时间步的局部观察以及动作，知晓每个智能体的动作（即策略）是一个比较强的假设。）每个智能体均维护一个<strong>其余智能体 actor network 的估计</strong>，通过历史每个智能体的数据，使用损失函数监督训练这个估计的 actor network。</p> </li><li> <p><strong>Policies Ensemble</strong>：给每个智能体<strong>同时训练 k 个 actor network</strong> 的方式，使得智能体对于其他智能体策略的变化更加鲁棒。（因为训练出的针对每个智能体的 policy 容易对其余智能体过拟合，但是其余智能体的 policy 随着训练过程的进行是不断更新的。其中每个 actor 都有独立的 experience replay）</p> </li><li> <p>只有一个buffer。其中存储的是<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
       
        
         
         
           ( 
          
         
           s 
          
         
           , 
          
         
           a 
          
         
           , 
          
         
           r 
          
         
           , 
          
          
          
            s 
           
          
            ′ 
           
          
         
           ) 
          
         
        
          (\mathbf s,\mathbf a,\mathbf r,\mathbf s') 
         
        
      </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.0019em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord mathbf">s</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathbf">a</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathbf">r</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathbf">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.7519em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>，<strong>所有智能体</strong>的联合观测、动作和奖励。</p> </li><li> <p>更详细的：<a href="https://zhuanlan.zhihu.com/p/53811876" rel="nofollow">多智能体强化学习：MADDPG算法</a></p> </li></ul> 
<h3><a id="2_Counterfactual_MultiAgent_Policy_Gradients_COMAhttpsarxivorgabs170508926_123"></a>2. <a href="https://arxiv.org/abs/1705.08926" rel="nofollow">Counterfactual Multi-Agent Policy Gradients (COMA)</a></h3> 
<p><code>旨在解决 Dec-POMDP 问题中的 multi-agent credit assignment 问题</code><br> <strong>multi-agent credit assignment</strong> 问题：多智能体信用分配问题。这个问题简单概括来说，由于 Dec-POMDP 问题中所有智能体共享同一个全局回报，因而每个智能体不知道自己的行为到底对这个全局回报产生了多大的影响</p> 
<ul><li><strong>CTDE</strong> 框架：所有的智能体<strong>共享一个联合的 critic network</strong>，该 network 与 MADDPG 一样，基于所有智能体的局部观察以及动作，但是 <strong>actor network 是独立的并且只基于局部观察</strong>。（为了解决<strong>Dec-POMDP</strong> 问题）i.e., COMA employs a central critic to train distributed actors.</li><li><strong>Actor</strong>：使用的是 <strong>GRU</strong> 网络，以更好的处理局部观察问题。（MADDPG使用的是DNN）</li><li>引入了一个 <strong>counterfactual 的 baseline 函数</strong>（受<strong>difference rewards</strong> 方法启发）通过智能体遵循当前 actor network 进行决策得到的全局回报与遵循某个默认策略进行决策得到的全局回报的对比，解决多智能体信用分配问题。但是它的<strong>弊端</strong>在于：由于需要知道遵循某个默认策略得到的全局回报，需要<strong>重复访问仿真环境</strong> （<code>信令消耗</code>）；默认策略得到的回报可能并不在仿真器的建模之中，因而需要进行<strong>估计</strong>；默认策略的选取是完全<strong>主观</strong>的。</li><li>通过使用<strong>联合的 critic</strong> 来去计算每个智能体独自的优势函数来解决上述问题，该优势函数计算的是智能体遵循<strong>当前</strong> actor 决策得到的全局回报与一个<strong>反事实 baseline</strong> 之间的差值。</li></ul> 
<h3><a id="3_Multiagent_Soft_QLearning_MASQLhttpsarxivorgabs180409817_132"></a>3. <a href="https://arxiv.org/abs/1804.09817" rel="nofollow">Multiagent Soft Q-Learning (MASQL)</a></h3> 
<p><code>类似于 MADDPG 的遵循 CTDE 框架的 MASQL（论文中没有这样进行缩写） 算法，本质上是将 Soft Q-Learning 算法迁移到多智能体环境中，因而与将 DDPG 算法迁移到多智能体环境中的 MADDPG 算法类似，不过 MASQL 算法解决的是 Dec-POMDP 问题。</code></p> 
<ul><li>相比MADDPG，不是简单的迁移单智能体到多智能体算法中，而为了解决<strong>relative overgeneralization 问题</strong> （连续场景下，联合动作<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          M 
         
        
       
         M 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord mathnormal" style="margin-right: 0.109em;">M</span></span></span></span></span>相比于联合动作<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          N 
         
        
       
         N 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord mathnormal" style="margin-right: 0.109em;">N</span></span></span></span></span>有更高的全局回报，但对某智能体i来说，执行动作<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           i 
          
         
           M 
          
         
        
       
         i_M 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8095em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.109em;">M</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>带来的期望收益低于执行动作<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           i 
          
         
           N 
          
         
        
       
         i_N 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8095em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">i</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.109em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>带来的期望收益 ，那么整体会收敛到次优点<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          N 
         
        
       
         N 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord mathnormal" style="margin-right: 0.109em;">N</span></span></span></span></span>）</li><li>中心化的critic。（与MADDPG相同）</li><li>每个智能体输出所有智能体的 <strong>joint action</strong>，而不像MADDPG每个智能体输出自己的动作。</li><li><strong>SQL</strong>方法目的在于解决<strong>最优策略不是唯一</strong>的的任务，因而尝试学习一个最优策略的分布，从而学到所有可能的最优策略。</li></ul> 
<h3><a id="4_ActorAttentionCritic_for_MultiAgent_Reinforcement_Learning_MAAChttpsarxivorgpdf181002912pdf_140"></a>4. <a href="https://arxiv.org/pdf/1810.02912.pdf" rel="nofollow">Actor-Attention-Critic for Multi-Agent Reinforcement Learning (MAAC)</a></h3> 
<p><code>将 MADDPG 采用的 DDPG 算法替换为 SAC（soft actor-critic）算法，并将 COMA 提出的 counterfactual baseline 引入进来，因而可以同时处理协作、竞争以及混合环境，遵循 CTDE 框架。</code></p> 
<p><code>核心思想体现在: 将注意力机制引入到 Q function 的构建之中，并在critic网络进行参数共享。</code>（MADDPG中每个智能体对应的 Q function 都是将其余智能体的局部观察以及动作无差别的作为输入，但是在现实场景中，智能体对于其余智能体的关注度是不一样的。）</p> 
<ul><li>与MADDPG类似，每个agent有自己的一套actor-critic网络，均为集中式的训练所有智能体的critic网络。MADDPG是基于<strong>观测共享</strong>，即每个智能体的critic可以看到所有智能体的观测+动作，并作为输入；MAAC使用了多个attention heads，每个head使用一套独立的参数 (Wk,Wq,V)，将每个head得到的vj连接后作为critic的输入。**参数(Wk,Wq,V)**在所有智能体之间共享。</li><li><strong>将其他智能体的观测-动作先embedding，然后利用注意力权重加权，相加，再与自身的局部观测+动作连接起来作为critic的输入。<code>注意力权重度量了两个智能体embedding的相似程度</code>。这样可使智能体更多关注与自己<em>相似的智能体</em>，提高信息利用率。</strong></li><li>所有智能体的观测-动作合并成一个单维向量，提高可拓展性</li><li>用一个联合的损失函数来训练各个critic，这是因为不同critic之间用到了共享的采纳数</li><li>借鉴了<strong>COMA</strong>中用counterfactual baseline计算优势函数的方法来解决信用分配问题。</li></ul> 
<hr> 
<h2><a id="ER_153"></a>三、基于经验回放（ER）缓存的方法：</h2> 
<p><code>聚焦于使用 ER 训练 Q-function 时增加稳定性</code>。</p> 
<h3><a id="1_Stabilising_experience_replay_for_deep_multiagent_reinforcement_learning_concurrent_experience_replay_trajectories_httpsarxivorgpdf170208887_156"></a>1. <a href="https://arxiv.org/pdf/1702.08887" rel="nofollow">Stabilising experience replay for deep multi-agent reinforcement learning (concurrent experience replay trajectories 的概念)</a></h3> 
<ul><li><strong>CTDE</strong>框架。</li><li>类似MADDPG，即假设每个智能体拥有自己独立的 Q-function；后者则是完全独立的 IQL。</li><li>从 importance sampling 的角度：发现不同时刻收集的数据 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           π 
          
          
          
            − 
           
          
            a 
           
          
         
        
          ( 
         
         
         
           u 
          
          
          
            − 
           
          
            a 
           
          
         
        
          ∣ 
         
        
          s 
         
        
          ) 
         
        
       
         \pi_{-a}(u_{-a}|s) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2583em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathnormal mtight">a</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">u</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2583em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathnormal mtight">a</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span><span class="mord">∣</span><span class="mord mathnormal">s</span><span class="mclose">)</span></span></span></span></span> 不同（部分原因），而这导致了ER在多智能体环境下不稳定。因此将每一时刻的该项作为额外项存入ER。其新的Q function基于全局观察。</li></ul> 
<h3><a id="2_Deep_decentralized_multitask_multiagent_reinforcement_learning_under_partial_observability_importance_sampling_httpsarxivorgpdf170306182_161"></a>2. <a href="https://arxiv.org/pdf/1703.06182" rel="nofollow">Deep decentralized multi-task multi-agent reinforcement learning under partial observability (importance sampling 的角度)</a></h3> 
<p>解决 <code>partial observation</code> 的问题, 采用 DRQN 算法。<br> 提出了 <code>concurrent experience replay trajectories</code> 的概念，即每个智能体在独立训练自己的 Q-function 时，从 ER 中 sample 出来的数据需要从 <strong>episode 层面</strong>以及<strong>时间层面</strong>上对齐。</p> 
<hr>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/d1fb0bde196a8413c44b2f7799978eb9/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">vscode配置flutter开发环境，不需要安装第三方安卓模拟器</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/166e7b883d09310b8c6e4d213db45d93/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">基于Java的界面开发【用户注册登录】</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>