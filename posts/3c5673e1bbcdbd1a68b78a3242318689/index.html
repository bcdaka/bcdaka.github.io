<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【大模型API调用初尝试一】智谱AI &amp;&amp; 通义千问 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/3c5673e1bbcdbd1a68b78a3242318689/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="【大模型API调用初尝试一】智谱AI && 通义千问">
  <meta property="og:description" content="大模型API调用初尝试一 调用大模型API能干什么智谱AI大模型API调用的过程获取API_KEYGLM_4同步调用GLM_4异步调用文生图大模型API调用 阿里云通义千问API调用过程单轮会话多轮会话 调用大模型API能干什么 大模型的参数非常庞大，功能非常强大，但是训练成本高昂，因此个人或者小企业自己去训练一个大模型是不可能的。我们可以通过直接调用大模型的API，将大模型集成到自己的应用中。 大模型的API就是一个接口，类似MaaS，用户通过调用API访问大模型，获得大模型针对用户prompt（问题）的输出，一般输出是json格式的，然后我们利用这个输出进行后续的操作。
但是大模型是一个已经训练好的模型，类似一个封装好的盒子，其能够运用的知识是有限的，比如chatgpt的知识截至2021年9月，让它提供实时的天气预报是不可行的，因此现在的大模型API中还增加了外部API/函数的调用功能，大模型能够根据用户的prompt确定要去调用的外部API/function–&gt;调用外部API/function并获得结果–&gt;大模型整合结果再输出，如下图所示：
我们可以参考某一个大模型对应的官方文档，学习如何调用其API。
智谱AI大模型API调用的过程 智谱AI是清华大学计算机系技术成果转化而来的公司，公司产品包括：中英双语千亿级超大规模预训练模型GLM-130B，并基于此推出对话模型ChatGLM；高效率代码模型CodeGeeX；多模态理解模型CogVLM和文生图模型CogView等。
获取API_KEY 调用API首先需要获取API，每个用户需要自己注册申请对应的API。进入智谱AI官网，注册后申请API，复制API_KEY以便后续调用：
现在打开API调用参考文档：通用大模型和图像大模型，直接复制其代码，看看输出是什么样的！
GLM_4同步调用 同步调用就是创建一个调用任务后，一直运行这个任务直到收到大模型的响应输出；对应的是异步调用，创建调用任务后获得这个任务的request-id，之后可以去干其他事情，后续通过这个任务ID查看模型的输出。
from zhipuai import ZhipuAI # 先安装ZhipuAI的包 pip install ZhipuAI client = ZhipuAI(api_key=&#34;xxxx&#34;) # 填写您自己的APIKey response = client.chat.completions.create( model=&#34;glm-4&#34;, # 填写需要调用的模型名称 messages=[ # messages是json格式的数据，大模型逐条响应 {&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;作为一名营销专家，请为我的产品创作一个吸引人的slogan&#34;}, {&#34;role&#34;: &#34;assistant&#34;, &#34;content&#34;: &#34;当然，为了创作一个吸引人的slogan，请告诉我一些关于您产品的信息&#34;}, {&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;智谱AI开放平台&#34;}, {&#34;role&#34;: &#34;assistant&#34;, &#34;content&#34;: &#34;智启未来，谱绘无限一智谱AI，让创新触手可及!&#34;}, {&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;创造一个更精准、吸引人的slogan&#34;} ], ) # 直接输出response，查看响应的具体内容 print(response) 输出的完整json数据：
如果只关注最终输出的message的content，可以只取response.choices[0].message.content。
上面例子传入大模型的message列表里面，有user的信息，也有assistant的信息，大模型实际响应的只有user对应的content，但是assistant的内容可以为大模型提供一些上下文或者提示。
message只传入用户的输入，并多次问答的例子如下：
from zhipuai import ZhipuAI client = ZhipuAI(api_key=&#34;">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-03-13T14:10:50+08:00">
    <meta property="article:modified_time" content="2024-03-13T14:10:50+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【大模型API调用初尝试一】智谱AI &amp;&amp; 通义千问</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>大模型API调用初尝试一</h4> 
 <ul><li><a href="#API_2" rel="nofollow">调用大模型API能干什么</a></li><li><a href="#AIAPI_8" rel="nofollow">智谱AI大模型API调用的过程</a></li><li><ul><li><a href="#API_KEY_10" rel="nofollow">获取API_KEY</a></li><li><a href="#GLM_4_14" rel="nofollow">GLM_4同步调用</a></li><li><a href="#GLM_4_62" rel="nofollow">GLM_4异步调用</a></li><li><a href="#API_96" rel="nofollow">文生图大模型API调用</a></li></ul> 
  </li><li><a href="#API_112" rel="nofollow">阿里云通义千问API调用过程</a></li><li><ul><li><a href="#_116" rel="nofollow">单轮会话</a></li><li><a href="#_175" rel="nofollow">多轮会话</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h2><a id="API_2"></a>调用大模型API能干什么</h2> 
<p>大模型的参数非常庞大，功能非常强大，但是训练成本高昂，因此个人或者小企业自己去训练一个大模型是不可能的。我们可以通过直接调用大模型的API，将大模型集成到自己的应用中。 大模型的API就是一个接口，类似MaaS，用户通过调用API访问大模型，获得大模型针对用户prompt（问题）的输出，一般输出是json格式的，然后我们利用这个输出进行后续的操作。<br> 但是大模型是一个已经训练好的模型，类似一个封装好的盒子，其能够运用的知识是有限的，比如chatgpt的知识截至2021年9月，让它提供实时的天气预报是不可行的，因此现在的大模型API中还增加了外部API/函数的调用功能，大模型能够根据用户的prompt确定要去调用的外部API/function–&gt;调用外部API/function并获得结果–&gt;大模型整合结果再输出，如下图所示：<br> <img src="https://images2.imgbox.com/80/ec/0Q986bCH_o.png" alt="在这里插入图片描述" width="600"></p> 
<p>我们可以参考某一个大模型对应的官方文档，学习如何调用其API。</p> 
<h2><a id="AIAPI_8"></a>智谱AI大模型API调用的过程</h2> 
<p>智谱AI是清华大学计算机系技术成果转化而来的公司，公司产品包括：中英双语千亿级超大规模预训练模型GLM-130B，并基于此推出对话模型ChatGLM；高效率代码模型CodeGeeX；多模态理解模型CogVLM和文生图模型CogView等。</p> 
<h3><a id="API_KEY_10"></a>获取API_KEY</h3> 
<p>调用API首先需要获取API，每个用户需要自己注册申请对应的API。进入<a href="https://open.bigmodel.cn/" rel="nofollow">智谱AI官网</a>，注册后申请API，复制API_KEY以便后续调用：<br> <img src="https://images2.imgbox.com/22/1b/OQE0f7WW_o.png" alt="在这里插入图片描述"><br> 现在打开API调用参考文档：<a href="https://open.bigmodel.cn/dev/api#glm-4" rel="nofollow">通用大模型</a>和<a href="https://open.bigmodel.cn/dev/api#multimodal" rel="nofollow">图像大模型</a>，直接复制其代码，看看输出是什么样的！</p> 
<h3><a id="GLM_4_14"></a>GLM_4同步调用</h3> 
<p>同步调用就是创建一个调用任务后，一直运行这个任务直到收到大模型的响应输出；对应的是异步调用，创建调用任务后获得这个任务的request-id，之后可以去干其他事情，后续通过这个任务ID查看模型的输出。</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> zhipuai <span class="token keyword">import</span> ZhipuAI  <span class="token comment"># 先安装ZhipuAI的包 pip install ZhipuAI</span>
client <span class="token operator">=</span> ZhipuAI<span class="token punctuation">(</span>api_key<span class="token operator">=</span><span class="token string">"xxxx"</span><span class="token punctuation">)</span> <span class="token comment"># 填写您自己的APIKey</span>
response <span class="token operator">=</span> client<span class="token punctuation">.</span>chat<span class="token punctuation">.</span>completions<span class="token punctuation">.</span>create<span class="token punctuation">(</span>
    model<span class="token operator">=</span><span class="token string">"glm-4"</span><span class="token punctuation">,</span>  <span class="token comment"># 填写需要调用的模型名称</span>
    messages<span class="token operator">=</span><span class="token punctuation">[</span>
    <span class="token comment"># messages是json格式的数据，大模型逐条响应</span>
        <span class="token punctuation">{<!-- --></span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> <span class="token string">"作为一名营销专家，请为我的产品创作一个吸引人的slogan"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
        <span class="token punctuation">{<!-- --></span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"assistant"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> <span class="token string">"当然，为了创作一个吸引人的slogan，请告诉我一些关于您产品的信息"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
        <span class="token punctuation">{<!-- --></span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> <span class="token string">"智谱AI开放平台"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
        <span class="token punctuation">{<!-- --></span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"assistant"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> <span class="token string">"智启未来，谱绘无限一智谱AI，让创新触手可及!"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
        <span class="token punctuation">{<!-- --></span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> <span class="token string">"创造一个更精准、吸引人的slogan"</span><span class="token punctuation">}</span>
    <span class="token punctuation">]</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
<span class="token comment"># 直接输出response，查看响应的具体内容</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">)</span>
</code></pre> 
<p>输出的完整json数据：<br> <img src="https://images2.imgbox.com/ac/6b/iJG0Yoat_o.png" alt="在这里插入图片描述"><br> 如果只关注最终输出的message的content，可以只取<code>response.choices[0].message.content</code>。</p> 
<p>上面例子传入大模型的message列表里面，有user的信息，也有assistant的信息，大模型实际响应的只有user对应的content，但是assistant的内容可以为大模型提供一些上下文或者提示。</p> 
<p>message只传入用户的输入，并多次问答的例子如下：</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> zhipuai <span class="token keyword">import</span> ZhipuAI
 
client <span class="token operator">=</span> ZhipuAI<span class="token punctuation">(</span>api_key<span class="token operator">=</span><span class="token string">"xxxxxx"</span><span class="token punctuation">)</span> <span class="token comment"># 填写您自己的APIKey</span>
<span class="token comment"># 循环提问/对话</span>
<span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>
	<span class="token comment"># 接收用户输入作为问题</span>
    prompt <span class="token operator">=</span> <span class="token builtin">input</span><span class="token punctuation">(</span><span class="token string">"\nuser:"</span><span class="token punctuation">)</span>
    response <span class="token operator">=</span> client<span class="token punctuation">.</span>chat<span class="token punctuation">.</span>completions<span class="token punctuation">.</span>create<span class="token punctuation">(</span>
        model<span class="token operator">=</span><span class="token string">"glm-4"</span><span class="token punctuation">,</span>  <span class="token comment"># 填写需要调用的模型名称</span>
        messages<span class="token operator">=</span><span class="token punctuation">[</span>
            <span class="token punctuation">{<!-- --></span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> prompt<span class="token punctuation">}</span>
        <span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span>
    answer <span class="token operator">=</span> response<span class="token punctuation">.</span>choices<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>message<span class="token punctuation">.</span>content
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\nZhipuAI:"</span><span class="token punctuation">,</span>answer<span class="token punctuation">)</span> <span class="token comment"># 只输出大模型响应的message.context</span>
</code></pre> 
<p>结果：<br> <img src="https://images2.imgbox.com/18/ff/ymguyzXS_o.png" alt="在这里插入图片描述"><br> 上述例子虽然user能够无限次的与大模型进行对话（交互），但由于message中只有用户单次的问题，没有保存上下文的信息，因此如果前后问题有衔接，这样的方式是不行的。应该使用多轮对话，将每轮对话的问答保存在message中，传给大模型为其提供对话的上下文。</p> 
<h3><a id="GLM_4_62"></a>GLM_4异步调用</h3> 
<p>参考官方文档，异步调用获取结果包括两步：①获取模型的响应ID，②根据ID查询响应结果；</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> time
<span class="token keyword">from</span> zhipuai <span class="token keyword">import</span> ZhipuAI
client <span class="token operator">=</span> ZhipuAI<span class="token punctuation">(</span>api_key<span class="token operator">=</span><span class="token string">"xxxxxx"</span><span class="token punctuation">)</span> <span class="token comment"># 请填写您自己的APIKey</span>

response <span class="token operator">=</span> client<span class="token punctuation">.</span>chat<span class="token punctuation">.</span>asyncCompletions<span class="token punctuation">.</span>create<span class="token punctuation">(</span>
    model<span class="token operator">=</span><span class="token string">"glm-4"</span><span class="token punctuation">,</span>  <span class="token comment"># 填写需要调用的模型名称</span>
    messages<span class="token operator">=</span><span class="token punctuation">[</span>
        <span class="token punctuation">{<!-- --></span>
            <span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span>
            <span class="token string">"content"</span><span class="token punctuation">:</span> <span class="token string">"请你作为童话故事大王，写一篇短篇童话故事，故事的主题是要永远保持一颗善良的心，要能够激发儿童的学习兴趣和想象力，同时也能够帮助儿童更好地理解和接受故事中所蕴含的道理和价值观。"</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">]</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
<span class="token comment"># 获取响应ID</span>
task_id <span class="token operator">=</span> response<span class="token punctuation">.</span><span class="token builtin">id</span>
task_status <span class="token operator">=</span> <span class="token string">''</span>
get_cnt <span class="token operator">=</span> <span class="token number">0</span>

<span class="token keyword">while</span> task_status <span class="token operator">!=</span> <span class="token string">'SUCCESS'</span> <span class="token keyword">and</span> task_status <span class="token operator">!=</span> <span class="token string">'FAILED'</span> <span class="token keyword">and</span> get_cnt <span class="token operator">&lt;=</span> <span class="token number">40</span><span class="token punctuation">:</span>
    <span class="token comment"># 查询响应结果</span>
    result_response <span class="token operator">=</span> client<span class="token punctuation">.</span>chat<span class="token punctuation">.</span>asyncCompletions<span class="token punctuation">.</span>retrieve_completion_result<span class="token punctuation">(</span><span class="token builtin">id</span><span class="token operator">=</span>task_id<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>result_response<span class="token punctuation">)</span>
    task_status <span class="token operator">=</span> result_response<span class="token punctuation">.</span>task_status

    time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>
    get_cnt <span class="token operator">+=</span> <span class="token number">1</span>
</code></pre> 
<p>运行输出如下：<br> <img src="https://images2.imgbox.com/d6/8b/733dgBDV_o.png" alt="在这里插入图片描述"><br> 可以看到在得到大模型的响应输出前，状态一直是processing；知道大模型响应。</p> 
<h3><a id="API_96"></a>文生图大模型API调用</h3> 
<p>Cogview是文生图的大模型，直接复制的官方文档的代码：</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> zhipuai <span class="token keyword">import</span> ZhipuAI
client <span class="token operator">=</span> ZhipuAI<span class="token punctuation">(</span>api_key<span class="token operator">=</span><span class="token string">"xxxxx"</span><span class="token punctuation">)</span> <span class="token comment"># 请填写您自己的APIKey</span>

response <span class="token operator">=</span> client<span class="token punctuation">.</span>images<span class="token punctuation">.</span>generations<span class="token punctuation">(</span>
    model<span class="token operator">=</span><span class="token string">"cogview-3"</span><span class="token punctuation">,</span> <span class="token comment">#填写需要调用的模型名称</span>
    prompt<span class="token operator">=</span><span class="token string">"一只可爱的小猫咪"</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>url<span class="token punctuation">)</span>

</code></pre> 
<p>结果（0.25一张照片呜呜呜呜呜呜呜）返回图片url：https://sfile.chatglm.cn/testpath/b158178b-e00c-5ea0-92bb-f2962922b877_0.png 👇：<br> <img src="https://images2.imgbox.com/09/c0/40DUPW95_o.png" alt="在这里插入图片描述" width="600"></p> 
<h2><a id="API_112"></a>阿里云通义千问API调用过程</h2> 
<p>通义千问是阿里云开发的基于QWen模型的聊天模型，<a href="https://github.com/QwenLM/Qwen">QWen模型</a>是开源的。调用API同样需要先获取API_KEY——首先注册阿里云的账号，然后进入<a href="https://dashscope.console.aliyun.com/overview?spm=a2c4g.11186623.0.0.5df34e4eRGDR9r" rel="nofollow">灵积平台</a>创建API-KEY：<br> <img src="https://images2.imgbox.com/64/52/4Qq6y40M_o.png" alt="在这里插入图片描述"><br> 之后查看通义千问的官方API调用文档👉<a href="https://help.aliyun.com/zh/dashscope/developer-reference/api-details?disableWebsiteRedirect=true" rel="nofollow">快速入门</a>，会话可以分为单轮会话和多轮会话：</p> 
<h3><a id="_116"></a>单轮会话</h3> 
<p>可以通过message和prompt两种方式调用API：</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> random
<span class="token keyword">from</span> http <span class="token keyword">import</span> HTTPStatus <span class="token comment"># 通义千问API是通过HTTP调用的 </span>
<span class="token keyword">import</span> dashscope

dashscope<span class="token punctuation">.</span>api_key <span class="token operator">=</span> <span class="token string">'xxxxx'</span> <span class="token comment"># 设置自己申请的API_KEY; 这个方式设置有泄露api的可能</span>

<span class="token keyword">def</span> <span class="token function">call_with_messages</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    prompt <span class="token operator">=</span> <span class="token builtin">input</span><span class="token punctuation">(</span><span class="token string">"user:"</span><span class="token punctuation">)</span>
    messages <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">{<!-- --></span><span class="token string">'role'</span><span class="token punctuation">:</span> <span class="token string">'system'</span><span class="token punctuation">,</span> <span class="token string">'content'</span><span class="token punctuation">:</span> <span class="token string">'You are a helpful assistant.'</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
                <span class="token punctuation">{<!-- --></span><span class="token string">'role'</span><span class="token punctuation">:</span> <span class="token string">'user'</span><span class="token punctuation">,</span> <span class="token string">'content'</span><span class="token punctuation">:</span> prompt<span class="token punctuation">}</span><span class="token punctuation">]</span>
    response <span class="token operator">=</span> dashscope<span class="token punctuation">.</span>Generation<span class="token punctuation">.</span>call<span class="token punctuation">(</span>
        dashscope<span class="token punctuation">.</span>Generation<span class="token punctuation">.</span>Models<span class="token punctuation">.</span>qwen_turbo<span class="token punctuation">,</span> <span class="token comment"># 选择模型</span>
        messages<span class="token operator">=</span>messages<span class="token punctuation">,</span>
        <span class="token comment"># set the random seed, optional, default to 1234 if not set</span>
        seed<span class="token operator">=</span>random<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10000</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        result_format<span class="token operator">=</span><span class="token string">'message'</span><span class="token punctuation">,</span>  <span class="token comment"># set the result to be "message" format.</span>
    <span class="token punctuation">)</span>
    <span class="token comment"># 之后HTTPStatus为OK时，才是调用成功</span>
    <span class="token keyword">if</span> response<span class="token punctuation">.</span>status_code <span class="token operator">==</span> HTTPStatus<span class="token punctuation">.</span>OK<span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Request id: %s, Status code: %s, error code: %s, error message: %s'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>
            response<span class="token punctuation">.</span>request_id<span class="token punctuation">,</span> response<span class="token punctuation">.</span>status_code<span class="token punctuation">,</span>
            response<span class="token punctuation">.</span>code<span class="token punctuation">,</span> response<span class="token punctuation">.</span>message
        <span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># For prerequisites running the following sample, visit https://help.aliyun.com/document_detail/611472.html</span>

<span class="token keyword">def</span> <span class="token function">call_with_prompt</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    prompt <span class="token operator">=</span> <span class="token builtin">input</span><span class="token punctuation">(</span><span class="token string">"user:"</span><span class="token punctuation">)</span>
    response <span class="token operator">=</span> dashscope<span class="token punctuation">.</span>Generation<span class="token punctuation">.</span>call<span class="token punctuation">(</span>
        model<span class="token operator">=</span>dashscope<span class="token punctuation">.</span>Generation<span class="token punctuation">.</span>Models<span class="token punctuation">.</span>qwen_turbo<span class="token punctuation">,</span> <span class="token comment"># 选择模型</span>
        prompt<span class="token operator">=</span>prompt
    <span class="token punctuation">)</span>
    <span class="token comment"># The response status_code is HTTPStatus.OK indicate success,</span>
    <span class="token comment"># otherwise indicate request is failed, you can get error code</span>
    <span class="token comment"># and message from code and message.</span>
    <span class="token keyword">if</span> response<span class="token punctuation">.</span>status_code <span class="token operator">==</span> HTTPStatus<span class="token punctuation">.</span>OK<span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>output<span class="token punctuation">)</span>  <span class="token comment"># The output text</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>usage<span class="token punctuation">)</span>  <span class="token comment"># The usage information</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>code<span class="token punctuation">)</span>  <span class="token comment"># The error code.</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>message<span class="token punctuation">)</span>  <span class="token comment"># The error message.</span>

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>

    call_with_messages<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n"</span><span class="token punctuation">)</span>
    call_with_prompt<span class="token punctuation">(</span><span class="token punctuation">)</span>

</code></pre> 
<p>两种方式的单轮会话输出如下：<br> <img src="https://images2.imgbox.com/4d/cf/OEzwIkqP_o.png" alt="在这里插入图片描述"><br> 这里需要注意通过message和prompt调用，这两种方式对应的输出Json格式是不同的。</p> 
<h3><a id="_175"></a>多轮会话</h3> 
<p>通过messages调用API，每轮会话用户的问题（the content of user）和大模型的输出（content of assistant）会存储在messages这个列表中，之后的输出会参考前面的内容，体现了大模型的记忆性！（可以在<a href="https://dashscope.console.aliyun.com/playground" rel="nofollow">体验中心</a>，选择多轮会话，注意观察代码中<code>messages</code>的变化）：<br> <img src="https://images2.imgbox.com/5a/15/8ujcQ4q1_o.png" alt="在这里插入图片描述"><br> 观察对应的代码，每轮会话结束后，user的问题和模型的响应都会append在messages中：</p> 
<p><img src="https://images2.imgbox.com/c8/95/RXicyFvk_o.png" alt="在这里插入图片描述" width="700"><br> 可以用下面的代码调用API实现多轮会话：</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> http <span class="token keyword">import</span> HTTPStatus
<span class="token keyword">import</span> dashscope
<span class="token keyword">from</span> dashscope <span class="token keyword">import</span> Generation
<span class="token keyword">from</span> dashscope<span class="token punctuation">.</span>api_entities<span class="token punctuation">.</span>dashscope_response <span class="token keyword">import</span> Role

dashscope<span class="token punctuation">.</span>api_key <span class="token operator">=</span> <span class="token string">'xxxxx'</span> <span class="token comment"># 设置API_KEY</span>

<span class="token keyword">def</span> <span class="token function">conversation_with_messages</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    messages <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">{<!-- --></span><span class="token string">'role'</span><span class="token punctuation">:</span> Role<span class="token punctuation">.</span>SYSTEM<span class="token punctuation">,</span> <span class="token string">'content'</span><span class="token punctuation">:</span> <span class="token string">'You are a helpful assistant.'</span><span class="token punctuation">}</span>  <span class="token punctuation">]</span>
    <span class="token comment"># 循环实现多轮会话</span>
    <span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>
        prompt <span class="token operator">=</span> <span class="token builtin">input</span><span class="token punctuation">(</span><span class="token string">"USER:"</span><span class="token punctuation">)</span>
        <span class="token comment"># 添加新一轮会话用户的问题</span>
        messages<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span><span class="token string">'role'</span><span class="token punctuation">:</span> Role<span class="token punctuation">.</span>USER<span class="token punctuation">,</span> <span class="token string">'content'</span><span class="token punctuation">:</span> prompt<span class="token punctuation">}</span><span class="token punctuation">)</span>
        response <span class="token operator">=</span> Generation<span class="token punctuation">.</span>call<span class="token punctuation">(</span>
            Generation<span class="token punctuation">.</span>Models<span class="token punctuation">.</span>qwen_turbo<span class="token punctuation">,</span> <span class="token comment">#选择响应的模型</span>
            messages<span class="token operator">=</span>messages<span class="token punctuation">,</span>
            result_format<span class="token operator">=</span><span class="token string">'message'</span><span class="token punctuation">,</span>  <span class="token comment"># set the result to be "message" format.</span>
        <span class="token punctuation">)</span>
        <span class="token keyword">if</span> response<span class="token punctuation">.</span>status_code <span class="token operator">==</span> HTTPStatus<span class="token punctuation">.</span>OK<span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">)</span>
            <span class="token comment"># 把模型的输出添加到messages中</span>
            messages<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span><span class="token string">'role'</span><span class="token punctuation">:</span> response<span class="token punctuation">.</span>output<span class="token punctuation">.</span>choices<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'message'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'role'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                             <span class="token string">'content'</span><span class="token punctuation">:</span> response<span class="token punctuation">.</span>output<span class="token punctuation">.</span>choices<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'message'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'content'</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Request id: %s, Status code: %s, error code: %s, error message: %s'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>
                response<span class="token punctuation">.</span>request_id<span class="token punctuation">,</span> response<span class="token punctuation">.</span>status_code<span class="token punctuation">,</span>
                response<span class="token punctuation">.</span>code<span class="token punctuation">,</span> response<span class="token punctuation">.</span>message
            <span class="token punctuation">)</span><span class="token punctuation">)</span>
            exit<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    conversation_with_messages<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p>结果如下：<br> <img src="https://images2.imgbox.com/6b/b1/F2FJmYib_o.png" alt="在这里插入图片描述"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/0bc5145d20e8e3acb64cae24299c452c/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">轻松上手MacOS：HomeBrew安装全指南</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/0072f6002a06664e4128febd91506a00/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">一键美化ppt的ai工具有哪些？推荐5款自动生成PPT的ai软件！</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>