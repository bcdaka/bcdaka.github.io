<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>AI学习指南机器学习篇-KNN算法超参数选择与调优 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/e2e6079b665a380d9bb7c6c693022e41/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="AI学习指南机器学习篇-KNN算法超参数选择与调优">
  <meta property="og:description" content="AI学习指南机器学习篇-KNN算法超参数选择与调优 在机器学习领域中，K最近邻（KNN）算法是一种简单而又常用的分类和回归方法。它的工作原理是通过计算样本之间的距离来进行分类或预测。在实际应用中，KNN算法的性能很大程度上取决于超参数的选择和调优。本文将详细探讨KNN算法中的超参数选择和调优问题，包括K值的选择和距离度量方法的选择，并介绍如何通过交叉验证等方法进行超参数调优。
KNN算法简介 KNN算法是一种基于实例的学习方法，它的核心思想是样本的类别由其最近邻居的类别决定。在KNN算法中，要预测一个新样本的类别或值，首先需要找到训练集中离该样本最近的K个样本，然后根据这K个最近邻居的类别或值来进行预测。KNN算法的优点是易于理解和实现，适用于多分类和回归问题，但同时也存在着计算复杂度高、对异常值敏感等缺点。
KNN算法中的超参数 在KNN算法中，有两个重要的超参数需要进行选择和调优，即K值和距离度量方法。K值表示在进行预测时需要考虑的最近邻居的数量，而距离度量方法用来衡量样本之间的距离，常见的距离度量方法包括欧式距离、曼哈顿距离、闵可夫斯基距离等。超参数的选择对KNN算法的性能有着重要的影响，下面将分别介绍这两个超参数的选择原则。
K值的选择 K值的选择是KNN算法中最关键的超参数之一，不恰当的K值会导致模型的过拟合或欠拟合。通常来说，K值较小会使模型对噪声敏感，容易受到单一异常值的影响，而K值较大则会使模型的决策面更加平缓，容易受到样本分布不均匀的影响。因此，选择合适的K值对于KNN算法的性能至关重要。
K值的选择可以通过交叉验证方法来进行。通常通过将训练集划分为若干份，然后分别对每一份数据进行KNN算法的训练和验证，最后取性能最佳的K值作为最终的选择。在实际应用中，一般采用K折交叉验证或留一交叉验证等方法。
距离度量方法的选择 在KNN算法中，距离度量方法是用来衡量样本之间的距离，从而找到最近的K个邻居。常用的距离度量方法包括欧式距离、曼哈顿距离、闵可夫斯基距离等。不同的距离度量方法适用于不同的数据类型和分布，因此选择合适的距离度量方法对于KNN算法的性能也非常重要。
对于距离度量方法的选择，一般需要根据实际数据的特点进行调整。在多数情况下，欧式距离是最常用的距离度量方法，特别适用于连续型数据。而曼哈顿距离适用于城市街区间的样本距离度量。在实际应用中，我们也可以结合交叉验证等方法来选择最适合的距离度量方法。
超参数调优 超参数的选择和调优对于模型的性能有着重要的影响，是机器学习中的一个重要环节。在KNN算法中，通过选择合适的K值和距离度量方法可以提高模型的性能。在实际应用中，超参数的调优可以通过网格搜索、随机搜索和贝叶斯优化等方法来实现。
网格搜索 网格搜索是一种基于遍历的超参数搜索方法，它的原理是通过定义一个超参数空间，然后对该空间进行穷举搜索，最终找到最优的超参数组合。在KNN算法中，可以通过定义K值的范围和距离度量方法的选择范围，然后对这两个超参数空间进行穷举搜索，最终找到最优的超参数组合。
from sklearn.model_selection import GridSearchCV from sklearn.neighbors import KNeighborsClassifier param_grid = {&#34;n_neighbors&#34;: [3, 5, 7], &#34;metric&#34;: [&#34;euclidean&#34;, &#34;manhattan&#34;]} knn = KNeighborsClassifier() grid_search = GridSearchCV(knn, param_grid, cv=5) grid_search.fit(X_train, y_train) print(&#34;Best parameters: {}&#34;.format(grid_search.best_params_)) 随机搜索 随机搜索是一种基于随机抽样的超参数搜索方法，它的原理是通过对超参数空间进行随机抽样，然后根据预先定义的搜索次数找到最优的超参数组合。在KNN算法中，可以通过随机抽样K值和距离度量方法，然后根据预先定义的搜索次数找到最优的超参数组合。
from sklearn.model_selection import RandomizedSearchCV from scipy.stats import randint param_dist = {&#34;n_neighbors&#34;: randint(3, 10), &#34;metric&#34;: [&#34;euclidean&#34;, &#34;manhattan&#34;]} knn = KNeighborsClassifier() random_search = RandomizedSearchCV(knn, param_dist, n_iter=10, cv=5) random_search.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-06-18T06:30:00+08:00">
    <meta property="article:modified_time" content="2024-06-18T06:30:00+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">AI学习指南机器学习篇-KNN算法超参数选择与调优</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="AIKNN_0"></a>AI学习指南机器学习篇-KNN算法超参数选择与调优</h2> 
<p>在机器学习领域中，K最近邻（KNN）算法是一种简单而又常用的分类和回归方法。它的工作原理是通过计算样本之间的距离来进行分类或预测。在实际应用中，KNN算法的性能很大程度上取决于超参数的选择和调优。本文将详细探讨KNN算法中的超参数选择和调优问题，包括K值的选择和距离度量方法的选择，并介绍如何通过交叉验证等方法进行超参数调优。</p> 
<h3><a id="KNN_4"></a>KNN算法简介</h3> 
<p>KNN算法是一种基于实例的学习方法，它的核心思想是样本的类别由其最近邻居的类别决定。在KNN算法中，要预测一个新样本的类别或值，首先需要找到训练集中离该样本最近的K个样本，然后根据这K个最近邻居的类别或值来进行预测。KNN算法的优点是易于理解和实现，适用于多分类和回归问题，但同时也存在着计算复杂度高、对异常值敏感等缺点。</p> 
<h3><a id="KNN_8"></a>KNN算法中的超参数</h3> 
<p>在KNN算法中，有两个重要的超参数需要进行选择和调优，即K值和距离度量方法。K值表示在进行预测时需要考虑的最近邻居的数量，而距离度量方法用来衡量样本之间的距离，常见的距离度量方法包括欧式距离、曼哈顿距离、闵可夫斯基距离等。超参数的选择对KNN算法的性能有着重要的影响，下面将分别介绍这两个超参数的选择原则。</p> 
<h4><a id="K_12"></a>K值的选择</h4> 
<p>K值的选择是KNN算法中最关键的超参数之一，不恰当的K值会导致模型的过拟合或欠拟合。通常来说，K值较小会使模型对噪声敏感，容易受到单一异常值的影响，而K值较大则会使模型的决策面更加平缓，容易受到样本分布不均匀的影响。因此，选择合适的K值对于KNN算法的性能至关重要。</p> 
<p>K值的选择可以通过交叉验证方法来进行。通常通过将训练集划分为若干份，然后分别对每一份数据进行KNN算法的训练和验证，最后取性能最佳的K值作为最终的选择。在实际应用中，一般采用K折交叉验证或留一交叉验证等方法。</p> 
<h4><a id="_18"></a>距离度量方法的选择</h4> 
<p>在KNN算法中，距离度量方法是用来衡量样本之间的距离，从而找到最近的K个邻居。常用的距离度量方法包括欧式距离、曼哈顿距离、闵可夫斯基距离等。不同的距离度量方法适用于不同的数据类型和分布，因此选择合适的距离度量方法对于KNN算法的性能也非常重要。</p> 
<p>对于距离度量方法的选择，一般需要根据实际数据的特点进行调整。在多数情况下，欧式距离是最常用的距离度量方法，特别适用于连续型数据。而曼哈顿距离适用于城市街区间的样本距离度量。在实际应用中，我们也可以结合交叉验证等方法来选择最适合的距离度量方法。</p> 
<h3><a id="_24"></a>超参数调优</h3> 
<p>超参数的选择和调优对于模型的性能有着重要的影响，是机器学习中的一个重要环节。在KNN算法中，通过选择合适的K值和距离度量方法可以提高模型的性能。在实际应用中，超参数的调优可以通过网格搜索、随机搜索和贝叶斯优化等方法来实现。</p> 
<h4><a id="_28"></a>网格搜索</h4> 
<p>网格搜索是一种基于遍历的超参数搜索方法，它的原理是通过定义一个超参数空间，然后对该空间进行穷举搜索，最终找到最优的超参数组合。在KNN算法中，可以通过定义K值的范围和距离度量方法的选择范围，然后对这两个超参数空间进行穷举搜索，最终找到最优的超参数组合。</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> GridSearchCV
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>neighbors <span class="token keyword">import</span> KNeighborsClassifier

param_grid <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">"n_neighbors"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"metric"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"euclidean"</span><span class="token punctuation">,</span> <span class="token string">"manhattan"</span><span class="token punctuation">]</span><span class="token punctuation">}</span>
knn <span class="token operator">=</span> KNeighborsClassifier<span class="token punctuation">(</span><span class="token punctuation">)</span>
grid_search <span class="token operator">=</span> GridSearchCV<span class="token punctuation">(</span>knn<span class="token punctuation">,</span> param_grid<span class="token punctuation">,</span> cv<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>
grid_search<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Best parameters: {}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>grid_search<span class="token punctuation">.</span>best_params_<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<h4><a id="_44"></a>随机搜索</h4> 
<p>随机搜索是一种基于随机抽样的超参数搜索方法，它的原理是通过对超参数空间进行随机抽样，然后根据预先定义的搜索次数找到最优的超参数组合。在KNN算法中，可以通过随机抽样K值和距离度量方法，然后根据预先定义的搜索次数找到最优的超参数组合。</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> RandomizedSearchCV
<span class="token keyword">from</span> scipy<span class="token punctuation">.</span>stats <span class="token keyword">import</span> randint

param_dist <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">"n_neighbors"</span><span class="token punctuation">:</span> randint<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"metric"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"euclidean"</span><span class="token punctuation">,</span> <span class="token string">"manhattan"</span><span class="token punctuation">]</span><span class="token punctuation">}</span>
knn <span class="token operator">=</span> KNeighborsClassifier<span class="token punctuation">(</span><span class="token punctuation">)</span>
random_search <span class="token operator">=</span> RandomizedSearchCV<span class="token punctuation">(</span>knn<span class="token punctuation">,</span> param_dist<span class="token punctuation">,</span> n_iter<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> cv<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>
random_search<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Best parameters: {}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>random_search<span class="token punctuation">.</span>best_params_<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<h4><a id="_60"></a>贝叶斯优化</h4> 
<p>贝叶斯优化是一种基于贝叶斯模型的超参数搜索方法，它的原理是通过对超参数空间进行随机抽样，然后根据已有的样本信息和高斯过程模型预测下一个最优的超参数组合。在KNN算法中，可以通过贝叶斯优化来找到最优的超参数组合。</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> skopt <span class="token keyword">import</span> BayesSearchCV
<span class="token keyword">from</span> skopt<span class="token punctuation">.</span>space <span class="token keyword">import</span> Integer<span class="token punctuation">,</span> Categorical

opt <span class="token operator">=</span> BayesSearchCV<span class="token punctuation">(</span>
    knn<span class="token punctuation">,</span>
    <span class="token punctuation">{<!-- --></span>
        <span class="token string">"n_neighbors"</span><span class="token punctuation">:</span> Integer<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token string">"metric"</span><span class="token punctuation">:</span> Categorical<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"euclidean"</span><span class="token punctuation">,</span> <span class="token string">"manhattan"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    n_iter<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>
    cv<span class="token operator">=</span><span class="token number">5</span>
<span class="token punctuation">)</span>

opt<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Best parameters: {}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>opt<span class="token punctuation">.</span>best_params_<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="_83"></a>实例分析</h3> 
<p>在本节中，我们将通过一个实例来演示KNN算法中超参数的选择和调优。我们将使用Python中的scikit-learn库来完成KNN算法的超参数选择和调优。首先，我们需要加载所需的库和数据，然后进行KNN算法的超参数选择和调优。</p> 
<pre><code class="prism language-python"><span class="token comment"># 加载库和数据</span>
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> load_iris
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScaler

<span class="token comment"># 加载数据</span>
iris <span class="token operator">=</span> load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span>
X<span class="token punctuation">,</span> y <span class="token operator">=</span> iris<span class="token punctuation">.</span>data<span class="token punctuation">,</span> iris<span class="token punctuation">.</span>target

<span class="token comment"># 数据预处理</span>
scaler <span class="token operator">=</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>
X <span class="token operator">=</span> scaler<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span>

<span class="token comment"># 划分训练集和测试集</span>
X_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span>

<span class="token comment"># 网格搜索</span>
param_grid <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">"n_neighbors"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"metric"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"euclidean"</span><span class="token punctuation">,</span> <span class="token string">"manhattan"</span><span class="token punctuation">]</span><span class="token punctuation">}</span>
knn <span class="token operator">=</span> KNeighborsClassifier<span class="token punctuation">(</span><span class="token punctuation">)</span>
grid_search <span class="token operator">=</span> GridSearchCV<span class="token punctuation">(</span>knn<span class="token punctuation">,</span> param_grid<span class="token punctuation">,</span> cv<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>
grid_search<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Best parameters: {}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>grid_search<span class="token punctuation">.</span>best_params_<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 随机搜索</span>
param_dist <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">"n_neighbors"</span><span class="token punctuation">:</span> randint<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"metric"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">"euclidean"</span><span class="token punctuation">,</span> <span class="token string">"manhattan"</span><span class="token punctuation">]</span><span class="token punctuation">}</span>
knn <span class="token operator">=</span> KNeighborsClassifier<span class="token punctuation">(</span><span class="token punctuation">)</span>
random_search <span class="token operator">=</span> RandomizedSearchCV<span class="token punctuation">(</span>knn<span class="token punctuation">,</span> param_dist<span class="token punctuation">,</span> n_iter<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> cv<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>
random_search<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Best parameters: {}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>random_search<span class="token punctuation">.</span>best_params_<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 贝叶斯优化</span>
opt <span class="token operator">=</span> BayesSearchCV<span class="token punctuation">(</span>
    knn<span class="token punctuation">,</span>
    <span class="token punctuation">{<!-- --></span>
        <span class="token string">"n_neighbors"</span><span class="token punctuation">:</span> Integer<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token string">"metric"</span><span class="token punctuation">:</span> Categorical<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"euclidean"</span><span class="token punctuation">,</span> <span class="token string">"manhattan"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    n_iter<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>
    cv<span class="token operator">=</span><span class="token number">5</span>
<span class="token punctuation">)</span>

opt<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Best parameters: {}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>opt<span class="token punctuation">.</span>best_params_<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p>在本示例中，我们加载了鸢尾花数据集，并对数据进行了预处理，然后使用KNN算法进行了超参数选择和调优。我们分别使用了网格搜索、随机搜索和贝叶斯优化三种方法，最终找到了最优的超参数组合。</p> 
<h3><a id="_139"></a>结论</h3> 
<p>在本文中，我们详细介绍了KNN算法中的超参数选择和调优问题，包括K值的选择和距离度量方法的选择，并介绍了通过交叉验证等方法进行超参数调优。通过具体的实例分析，我们演示了如何使用Python中的scikit-learn库来完成KNN算法的超参数选择和调优。合理地选择和调优超参数可以提高模型的性能，对于KNN算法而言也非常重要。</p> 
<p>通过本文的学习，相信读者们已经对KNN算法中超参数的选择和调优有了更深入的了解。希望本文对大家有所帮助，谢谢阅读！</p> 
<p>参考资料：</p> 
<ul><li><a href="https://towardsdatascience.com/introduction-to-k-nearest-neighbors-3b534bb11e7c" rel="nofollow">Introduction to K-Nearest Neighbors</a></li><li><a href="http://faculty.marshall.usc.edu/gareth-james/ISL/" rel="nofollow">An Introduction to Statistical Learning</a></li><li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html" rel="nofollow">sklearn KNeighborsClassifier Documentation</a></li></ul> 
<p>希望本文对读者们有所帮助，谢谢！</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/46b912b049dd7b4ce12b7d29df3e7770/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">SQLite Delete 语句</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/442083f707863a1b74cc36ab36e13c11/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">SpringBoot3整合SpringDoc实现在线接口文档</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>