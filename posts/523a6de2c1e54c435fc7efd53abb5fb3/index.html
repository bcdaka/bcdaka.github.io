<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>基于Llama 3的最强开源医疗AI模型OpenBioLLM-Llama3，刷新榜单 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/523a6de2c1e54c435fc7efd53abb5fb3/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="基于Llama 3的最强开源医疗AI模型OpenBioLLM-Llama3，刷新榜单">
  <meta property="og:description" content="项目概述 OpenBioLLM-70B是一款先进的开源生物医学大型语言模型，由Saama AI实验室基于Llama 3技术精心开发并微调。此模型专为生物医学领域设计，利用尖端技术，在多种生物医学任务中实现了最先进的性能表现。
背景： Saama AI实验室推出的OpenBioLLM-Llama3-70B和OpenBioLLM-Llama3-8B在Hugging Face榜单中刷新了医疗AI大模型的记录，位居榜首。此模型的生物医学领域测试性能超越了GPT-4、Gemini、Meditron-70B、Med-PaLM-2等行业领先模型，展示了其卓越的专业能力和广泛的应用前景。
主要功能： 🏥 医学专业化：OpenBioLLM-70B针对医疗和生命科学领域的特定语言和知识需求进行了定制，通过在广泛的高质量生物医学数据上进行精细微调，使其能够以领域特定的准确性和流畅性理解和生成文本。🎓 卓越性能：OpenBioLLM-70B具备700亿参数，性能优于其他同规模的开源生物医学语言模型，并在生物医学基准测试中比GPT-4等大型专有及开源模型表现更佳。🧠 先进的训练技术：此模型在Meta-Llama-3-70B-Instruct的基础上进一步构建，整合了DPO（直接偏好优化）数据集和定制的医学指导数据集。其训练过程包括了策略优化和精确微调，以适应生物医学应用的关键能力和偏好。 发布详情： 模型规模：700亿参数量化：提供了优化的量化版本，以便于部署语言：英语（NLP）开发团队：Saama AI实验室的Ankit Pal（Aaditya Ura）领导开发许可证：Meta-Llama许可证基于模型：从Meta-Llama-3-70B-Instruct微调而来 OpenBioLLM-70B标志着在为生物医学社区民主化先进语言AI方面迈出了重要一步。通过利用Llama-3等领先开源项目的最先进架构和训练技术，我们创造了一个强大的工具，加速了在医疗保健和生命科学中的创新与发现。我们非常高兴能将OpenBioLLM-70B与全球的研究人员和开发者共享。
安装与配置 前提条件 需要Python环境，并安装transformers和torch库。 安装步骤 克隆仓库：
git clone https://github.com/aaditya/OpenBioLLM-Llama3-70B.git 安装依赖：
pip install -r requirements.txt 运行项目：
python run_model.py 配置说明 确保所有配置文件根据您的系统环境正确设置。
使用指南 使用Transformers库 在使用OpenBioLLM-70B时，请确保使用由Llama-3指令版本提供的确切聊天模板。若不按此模板使用，可能会导致模型性能下降。模型输出在少数情况下可能较为详细，建议将温度参数设置为0，以减少此类情况的发生。
示例代码 使用Transformers库来加载和运行OpenBioLLM-70B模型的示例：
import transformers import torch model_id = &#34;aaditya/OpenBioLLM-Llama3-70B&#34; pipeline = transformers.pipeline( &#34;text-generation&#34;, model=model_id, model_kwargs={&#34;torch_dtype&#34;: torch.bfloat16}, device=&#34;auto&#34;, ) messages = [ {&#34;role&#34;: &#34;system&#34;, &#34;content&#34;: &#34;You are an expert and experienced from the healthcare and biomedical domain with extensive medical knowledge and practical experience.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-06-07T15:29:02+08:00">
    <meta property="article:modified_time" content="2024-06-07T15:29:02+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">基于Llama 3的最强开源医疗AI模型OpenBioLLM-Llama3，刷新榜单</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_1"></a>项目概述</h2> 
<p>OpenBioLLM-70B是一款先进的开源生物医学大型语言模型，由Saama AI实验室基于Llama 3技术精心开发并微调。此模型专为生物医学领域设计，利用尖端技术，在多种生物医学任务中实现了最先进的性能表现。</p> 
<p><img src="https://images2.imgbox.com/64/cf/ra5UHwVX_o.jpg" alt="图片"></p> 
<h4><a id="_7"></a>背景：</h4> 
<p>Saama AI实验室推出的OpenBioLLM-Llama3-70B和OpenBioLLM-Llama3-8B在Hugging Face榜单中刷新了医疗AI大模型的记录，位居榜首。此模型的生物医学领域测试性能超越了GPT-4、Gemini、Meditron-70B、Med-PaLM-2等行业领先模型，展示了其卓越的专业能力和广泛的应用前景。</p> 
<h4><a id="_11"></a>主要功能：</h4> 
<ul><li>🏥 <strong>医学专业化</strong>：OpenBioLLM-70B针对医疗和生命科学领域的特定语言和知识需求进行了定制，通过在广泛的高质量生物医学数据上进行精细微调，使其能够以领域特定的准确性和流畅性理解和生成文本。</li><li>🎓 <strong>卓越性能</strong>：OpenBioLLM-70B具备700亿参数，性能优于其他同规模的开源生物医学语言模型，并在生物医学基准测试中比GPT-4等大型专有及开源模型表现更佳。</li><li>🧠 <strong>先进的训练技术</strong>：此模型在Meta-Llama-3-70B-Instruct的基础上进一步构建，整合了DPO（直接偏好优化）数据集和定制的医学指导数据集。其训练过程包括了策略优化和精确微调，以适应生物医学应用的关键能力和偏好。</li></ul> 
<p><img src="https://images2.imgbox.com/fe/1f/yDnS2zxz_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="_20"></a>发布详情：</h4> 
<ul><li><strong>模型规模</strong>：700亿参数</li><li><strong>量化</strong>：提供了优化的量化版本，以便于部署</li><li><strong>语言</strong>：英语（NLP）</li><li><strong>开发团队</strong>：Saama AI实验室的Ankit Pal（Aaditya Ura）领导开发</li><li><strong>许可证</strong>：Meta-Llama许可证</li><li><strong>基于模型</strong>：从Meta-Llama-3-70B-Instruct微调而来</li></ul> 
<p>OpenBioLLM-70B标志着在为生物医学社区民主化先进语言AI方面迈出了重要一步。通过利用Llama-3等领先开源项目的最先进架构和训练技术，我们创造了一个强大的工具，加速了在医疗保健和生命科学中的创新与发现。我们非常高兴能将OpenBioLLM-70B与全球的研究人员和开发者共享。</p> 
<h3><a id="_31"></a>安装与配置</h3> 
<h4><a id="_33"></a>前提条件</h4> 
<ul><li>需要Python环境，并安装transformers和torch库。</li></ul> 
<h4><a id="_37"></a>安装步骤</h4> 
<ul><li> <p><strong>克隆仓库</strong>：</p> <pre><code>git clone https://github.com/aaditya/OpenBioLLM-Llama3-70B.git
</code></pre> </li><li> <p><strong>安装依赖</strong>：</p> <pre><code>pip install -r requirements.txt
</code></pre> </li><li> <p><strong>运行项目</strong>：</p> <pre><code>python run_model.py
</code></pre> </li></ul> 
<h4><a id="_63"></a>配置说明</h4> 
<p>确保所有配置文件根据您的系统环境正确设置。</p> 
<h3><a id="_67"></a>使用指南</h3> 
<h4><a id="Transformers_69"></a>使用Transformers库</h4> 
<p>在使用OpenBioLLM-70B时，请确保使用由Llama-3指令版本提供的确切聊天模板。若不按此模板使用，可能会导致模型性能下降。模型输出在少数情况下可能较为详细，建议将温度参数设置为0，以减少此类情况的发生。</p> 
<h5><a id="_73"></a>示例代码</h5> 
<p>使用Transformers库来加载和运行OpenBioLLM-70B模型的示例：</p> 
<pre><code>import transformers
import torch

model_id = "aaditya/OpenBioLLM-Llama3-70B"
pipeline = transformers.pipeline(    
    "text-generation",    
    model=model_id,    
    model_kwargs={"torch_dtype": torch.bfloat16},    
    device="auto",
)

messages = [    
    {"role": "system", "content": "You are an expert and experienced from the healthcare and biomedical domain with extensive medical knowledge and practical experience. Your name is OpenBioLLM, and you were developed by Saama AI Labs. who's willing to help answer the user's query with explanation. In your explanation, leverage your deep medical expertise such as relevant anatomical structures, physiological processes, diagnostic criteria, treatment guidelines, or other pertinent medical concepts. Use precise medical terminology while still aiming to make the explanation clear and accessible to a general audience."},    
    {"role": "user", "content": "How can i split a 3mg or 4mg waefin pill so i can get a 2.5mg pill?"},
    ]
prompt = pipeline.tokenizer.apply_chat_template(    
    messages,     
    tokenize=False,     
    add_generation_prompt=True
)
terminators = [    
    pipeline.tokenizer.eos_token_id,    
    pipeline.tokenizer.convert_tokens_to_ids("")
]
outputs = pipeline(    
    prompt,    
    max_new_tokens=256,    
    eos_token_id=terminators,    
    do_sample=True,    
    temperature=0.0,    
    top_p=0.9,
)
print(outputs[0]["generated_text"][len(prompt):])
</code></pre> 
<h4><a id="_115"></a>训练过程和性能</h4> 
<p>OpenBioLLM-70B的训练采用了以下超参数：</p> 
<ul><li>学习率：0.0002</li><li>学习率调度器：余弦衰减</li><li>训练批次大小：12</li><li>评估批次大小：8</li><li>GPU类型：H100 80GB SXM5</li><li>设备数量：8</li><li>优化器：adamw_bnb_8bit</li><li>学习率预热步数：100</li><li>训练周期数：4</li></ul> 
<p>框架版本：</p> 
<ul><li>Transformers 4.39.3</li><li>Pytorch 2.1.2+cu121</li><li>Datasets 2.18.0</li><li>Tokenizers 0.15.1</li></ul> 
<h4><a id="_136"></a>基准测试结果</h4> 
<p>OpenBioLLM-70B在多个生物医学领域的基准测试中展示了卓越性能，与GPT-4、Gemini、Meditron-70B、Med-PaLM-1和Med-PaLM-2等较大模型相比，其在9个不同的生物医学数据集上取得了领先的成绩，平均得分为86.06%，尽管其参数数量显著较少。模型在领域特定任务，如Clinical KG、Medical Genetics和PubMedQA中的强劲表现，凸显了其在捕捉和应用生物医学知识方面的有效性。</p> 
<p>🔥 <strong>详细医学科目精确度</strong>：OpenBioLLM-70B在以下领域显示了其优越的专业能力：</p> 
<ul><li><strong>Clinical KG</strong>：对临床知识图谱的理解和生成能力突出。</li><li><strong>Medical Genetics</strong>：在医学遗传学领域的应用表现优异，能够处理复杂的遗传信息。</li><li><strong>PubMedQA</strong>：在解答基于PubMed数据库的问题上显示了高效的信息检索和回答能力。</li></ul> 
<p><img src="https://images2.imgbox.com/7b/8f/YTnnbEr4_o.png" alt="图片"></p> 
<p>此外，对于Med-PaLM-1和Med-PaLM-2的比较，由于这些模型官方论文中未提供零次射击（zero-shot）准确率，我们采用其五次射击（5-shot）准确率进行对比。所有其他结果均在零次射击设置下展示。</p> 
<p><img src="https://images2.imgbox.com/2a/3a/jEjfFAB6_o.png" alt="图片"></p> 
<p>通过这些详尽的测试和比较，OpenBioLLM-70B证实了其在处理具体医学任务时的精确性和高效性，使其成为生物医学研究和应用中的有力工具。</p> 
<p><img src="https://images2.imgbox.com/77/9d/1Ul4DGwG_o.png" alt="图片"></p> 
<h4><a id="_156"></a>应用案例与示例</h4> 
<h5><a id="Summarize_Clinical_Notes_158"></a><strong>Summarize Clinical Notes</strong></h5> 
<p>OpenBioLLM-70B能够高效分析并总结复杂的临床笔记、电子健康记录(EHR)和出院摘要，提取关键信息并生成简洁、结构化的总结。</p> 
<p><img src="https://images2.imgbox.com/4d/35/P9oX3J3w_o.png" alt="图片"></p> 
<h5><a id="Answer_Medical_Questions_164"></a><strong>Answer Medical Questions</strong></h5> 
<p>OpenBioLLM-70B能够回答广泛的医疗问题，展示其在医学知识问答方面的应用潜力。</p> 
<p><img src="https://images2.imgbox.com/c4/80/w6LCACSl_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/b4/1a/dkW7HjFI_o.png" alt="图片"></p> 
<h5><a id="Clinical_Entity_Recognition_173"></a><strong>Clinical Entity Recognition</strong></h5> 
<p>OpenBioLLM-70B能够执行高级的临床实体识别，通过识别和提取未结构化临床文本中的关键医学概念（如疾病、症状、药物、程序和解剖结构），准确注释和分类临床实体。这种能力可以支持临床决策支持、药物监测和医学研究等多种下游应用。</p> 
<p><img src="https://images2.imgbox.com/e3/09/p8jCHjBA_o.png" alt="图片"></p> 
<p><img src="https://images2.imgbox.com/20/2c/CRyS0Ulw_o.png" alt="图片"><img src="https://images2.imgbox.com/15/c9/lyzTv9eu_o.png" alt="图片"></p> 
<h5><a id="Biomarkers_Extraction_181"></a><strong>Biomarkers Extraction</strong></h5> 
<p>OpenBioLLM-70B可以从医学文献和临床记录中提取生物标记物，支持疾病诊断和治疗过程中的关键决策。</p> 
<p><img src="https://images2.imgbox.com/ac/8b/D9p892tJ_o.png" alt="图片"></p> 
<h5><a id="Classification_187"></a><strong>Classification</strong></h5> 
<p>OpenBioLLM-70B可以执行多种生物医学分类任务，如疾病预测、情感分析和医学文档分类。</p> 
<p><img src="https://images2.imgbox.com/ab/06/XvLyjbu4_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="DeIdentification_193"></a><strong>De-Identification</strong></h5> 
<p>OpenBioLLM-70B能够检测并移除医疗记录中的个人身份信息(PII)，确保患者隐私并符合HIPAA等数据保护法规的要求。</p> 
<p><img src="https://images2.imgbox.com/b8/3f/7DBxOwRU_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="_199"></a>咨询须知</h4> 
<p>尽管OpenBioLLM-70B利用了高质量的数据源，但其输出可能仍含有不准确性、偏见或不对齐现象，若在未经进一步测试和微调的情况下依赖此模型进行医疗决策，可能存在风险。目前，该模型在随机对照试验或真实世界的医疗环境中的性能尚未经过严格评估。</p> 
<p>因此，我们强烈建议目前不要将OpenBioLLM-70B用于任何直接的病人护理、临床决策支持或其他专业医疗目的。其使用应限于具备相关限制认识的合格个人的研究、开发和探索性应用。OpenBioLLM-70B仅作为研究工具，以协助医疗专业人士，并且绝不能视为取代合格医疗医生的专业判断和专长。</p> 
<p>适当地适应和验证OpenBioLLM-70B针对特定医疗用例需要大量额外工作，可能包括：</p> 
<ul><li>在相关临床场景中进行彻底的测试和评估</li><li>与基于证据的指导方针和最佳实践的对齐</li><li>缓解潜在的偏见和故障模式</li><li>与人类监督和解释的整合</li><li>符合监管和伦理标准</li></ul> 
<p>在个人医疗需求上，始终应咨询合格的医疗服务提供者。</p> 
<p>​</p> 
<h3><a id="AI_217"></a>如何学习AI大模型？</h3> 
<p>作为一名热心肠的互联网老兵，我决定把宝贵的AI知识分享给大家。 至于能学习到多少就看你的学习毅力和能力了 。我已将重要的AI大模型资料包括AI大模型入门学习思维导图、精品AI大模型学习书籍手册、视频教程、实战学习等录播视频免费分享出来。</p> 
<p><strong>这份完整版的大模型 AI 学习资料已经上传CSDN，朋友们如果需要可以微信扫描下方CSDN官方认证二维码免费领取【<code>保证100%免费</code>】</strong></p> 
<img src="https://images2.imgbox.com/42/c2/VpHtnU63_o.png"> 
<h4><a id="AGI_227"></a>一、全套AGI大模型学习路线</h4> 
<p><strong>AI大模型时代的学习之旅：从基础到前沿，掌握人工智能的核心技能！</strong></p> 
<p><img src="https://images2.imgbox.com/e1/66/zq2rTDw2_o.png" alt="img"></p> 
<h4><a id="640AI_233"></a>二、640套AI大模型报告合集</h4> 
<p>这套包含640份报告的合集，涵盖了AI大模型的理论研究、技术实现、行业应用等多个方面。无论您是科研人员、工程师，还是对AI大模型感兴趣的爱好者，这套报告合集都将为您提供宝贵的信息和启示。</p> 
<p><img src="https://images2.imgbox.com/ef/d8/cHfvhRR9_o.png" alt="img"></p> 
<h4><a id="AIPDF_241"></a>三、AI大模型经典PDF籍</h4> 
<p>随着人工智能技术的飞速发展，AI大模型已经成为了当今科技领域的一大热点。这些大型预训练模型，如GPT-3、BERT、XLNet等，以其强大的语言理解和生成能力，正在改变我们对人工智能的认识。 那以下这些PDF籍就是非常不错的学习资源。</p> 
<p><img src="https://images2.imgbox.com/ac/d6/gBR2sd0w_o.png" alt="img"></p> 
<h4><a id="AI_247"></a>四、AI大模型商业化落地方案</h4> 
<p><img src="https://images2.imgbox.com/da/3b/Hr1hVHhL_o.png" alt="img"></p> 
<p>作为普通人，入局大模型时代需要持续学习和实践，不断提高自己的技能和认知水平，同时也需要有责任感和伦理意识，为人工智能的健康发展贡献力量。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/0a8e2191c051ce132855d78cb4d827fa/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">最新 HUAWEI DevEco Studio 使用技巧</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/7e9f43700fff34ee7cde3be5d87ac0b8/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【MySQL数据库基础】</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>