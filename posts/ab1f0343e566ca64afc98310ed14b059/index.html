<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>[深度学习]基于C&#43;&#43;和onnxruntime部署yolov10的onnx模型 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/ab1f0343e566ca64afc98310ed14b059/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="[深度学习]基于C&#43;&#43;和onnxruntime部署yolov10的onnx模型">
  <meta property="og:description" content="基于C&#43;&#43;和ONNX Runtime部署YOLOv10的ONNX模型，可以遵循以下步骤：
准备环境：首先，确保已经下载后指定版本opencv和onnruntime的C&#43;&#43;库。
模型转换：按照官方源码：https://github.com/THU-MIG/yolov10 安装好yolov10环境并将YOLOv10模型转换为ONNX格式。这通常涉及使用深度学习框架（如PyTorch或TensorFlow）加载原始模型，并导出为ONNX格式。转换指令
# End-to-End ONNX yolo export model=jameslahm/yolov10{n/s/m/b/l/x} format=onnx opset=13 simplify # Predict with ONNX yolo predict model=yolov10n/s/m/b/l/x.onnx C&#43;&#43;环境配置：在CMakeLists.txt项目中正确引用了opencv和ONNX Runtime的头文件，并链接到相应的库。这允许在C&#43;&#43;代码中使用ONNX Runtime的功能。
加载模型：使用ONNX Runtime的API加载转换后的YOLOv10 ONNX模型。
执行推理：通过ONNX Runtime的推理引擎，将图像数据输入到模型中，并执行目标检测任务。
处理结果：解析模型输出的结果，这通常涉及将输出的张量数据转换为可理解的检测结果，如边界框坐标和类别标签。
通过这些步骤，可以在C&#43;&#43;环境中利用ONNX Runtime高效地部署YOLOv10模型，实现实时的目标检测功能。
【测试环境】
windows10 x64
vs2019
cmake==2.24.3
onnxruntime==1.12.0
opencv==4.7.0
【使用步骤】
首先cmake生成exe文件，然后将onnxruntime.dll和onnxruntime_providers_shared.dll放到exe一起，不然会提示报错0xc000007b，这是因为系统目录也有个onnxruntime.dll引发冲突，并把car.mp4也放到exe一起。运行直接输入
yolov10.exe C:\Users\Administrator\Desktop\yolov10-onnx-cplus\models\yolov10n.onnx
注意onnx路径要是你真实路径我的onnx路径是我桌面上地址
【代码调用】
注意onnxruntime使用的cpu版本库，如需使用GPU还需要修改代码才行
#include &#34;YOlov10Manager.h&#34; #include &lt;iostream&gt; #include &lt;opencv2/opencv.hpp&gt; int main(int argc, char const *argv[]) { std::string model_path = argv[1]; cv::namedWindow(&#34;yolov10&#34;, cv::WINDOW_AUTOSIZE); Yolov10Manager detector(model_path); cv::VideoCapture cap(&#34;car.mp4&#34;);//这个地方也可以修改成视频路径或者摄像头索引 if (!">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-06-13T13:34:23+08:00">
    <meta property="article:modified_time" content="2024-06-13T13:34:23+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">[深度学习]基于C&#43;&#43;和onnxruntime部署yolov10的onnx模型</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>基于C++和ONNX Runtime部署YOLOv10的ONNX模型，可以遵循以下步骤：</p> 
<ol><li> <p><strong>准备环境</strong>：首先，确保已经下载后指定版本opencv和onnruntime的C++库。</p> </li><li> <p><strong>模型转换</strong>：按照官方源码：<a href="https://github.com/THU-MIG/yolov10" title="https://github.com/THU-MIG/yolov10">https://github.com/THU-MIG/yolov10</a> 安装好yolov10环境并将YOLOv10模型转换为ONNX格式。这通常涉及使用深度学习框架（如PyTorch或TensorFlow）加载原始模型，并导出为ONNX格式。转换指令</p> <pre><code class="hljs"># End-to-End ONNX
yolo export model=jameslahm/yolov10{n/s/m/b/l/x} format=onnx opset=13 simplify
# Predict with ONNX
yolo predict model=yolov10n/s/m/b/l/x.onnx</code></pre> </li><li> <p><strong>C++环境配置</strong>：在CMakeLists.txt项目中正确引用了opencv和ONNX Runtime的头文件，并链接到相应的库。这允许在C++代码中使用ONNX Runtime的功能。</p> </li><li> <p><strong>加载模型</strong>：使用ONNX Runtime的API加载转换后的YOLOv10 ONNX模型。</p> </li><li> <p><strong>执行推理</strong>：通过ONNX Runtime的推理引擎，将图像数据输入到模型中，并执行目标检测任务。</p> </li><li> <p><strong>处理结果</strong>：解析模型输出的结果，这通常涉及将输出的张量数据转换为可理解的检测结果，如边界框坐标和类别标签。</p> </li></ol> 
<p>通过这些步骤，可以在C++环境中利用ONNX Runtime高效地部署YOLOv10模型，实现实时的目标检测功能。</p> 
<p>【测试环境】</p> 
<p>windows10 x64<br> vs2019<br> cmake==2.24.3<br> onnxruntime==1.12.0<br> opencv==4.7.0<br> 【使用步骤】<br> 首先cmake生成exe文件，然后将onnxruntime.dll和onnxruntime_providers_shared.dll放到exe一起，不然会提示报错0xc000007b，这是因为系统目录也有个onnxruntime.dll引发冲突，并把car.mp4也放到exe一起。运行直接输入<br> yolov10.exe C:\Users\Administrator\Desktop\yolov10-onnx-cplus\models\yolov10n.onnx<br> 注意onnx路径要是你真实路径我的onnx路径是我桌面上地址</p> 
<p>【代码调用】</p> 
<p>注意onnxruntime使用的cpu版本库，如需使用GPU还需要修改代码才行</p> 
<pre><code class="hljs">#include "YOlov10Manager.h"
#include &lt;iostream&gt;
#include &lt;opencv2/opencv.hpp&gt;

int main(int argc, char const *argv[])
{
    std::string model_path = argv[1];
    cv::namedWindow("yolov10", cv::WINDOW_AUTOSIZE);
    Yolov10Manager detector(model_path);
    
    cv::VideoCapture cap("car.mp4");//这个地方也可以修改成视频路径或者摄像头索引
    if (!cap.isOpened())
    {
        std::cerr &lt;&lt; "ERROR! Unable to open camera\n";
        return -1;
    }
    cv::Mat frame;
    std::cout &lt;&lt; "Start detect" &lt;&lt; std::endl &lt;&lt; "Press any key to terminate" &lt;&lt; std::endl;

    for (;;)
    {
        cap.read(frame);
        if (frame.empty())
        {
            std::cerr &lt;&lt; "ERROR! blank frame grabbed\n";
            break;
        }

        auto timer = cv::getTickCount();
        std::vector&lt;Detection&gt; detections = detector.Inference(frame);
        double fps = cv::getTickFrequency() / ((double)cv::getTickCount() - timer);
        cv::putText(frame, "FPS: " + std::to_string(fps), cv::Point(10, 30), cv::FONT_HERSHEY_SIMPLEX, 1, cv::Scalar(0, 255, 0), 2, 8);
        cv::Mat resultImg = detector.DrawImage(frame, detections);
        cv::imshow("yolov10", resultImg);
        if (cv::waitKey(5) &gt;= 0)
            break;
    }

    return 0;
}
</code></pre> 
<p>【视频演示】</p> 
<p><a class="has-card" href="https://www.bilibili.com/video/BV1Zw4m1v7iz/?vd_source=989ae2b903ea1b5acebbe2c4c4a635ee" rel="nofollow" title="基于C++和onnxruntime部署yolov10的onnx模型_哔哩哔哩_bilibili"><span class="link-card-box"><span class="link-title">基于C++和onnxruntime部署yolov10的onnx模型_哔哩哔哩_bilibili</span><span class="link-desc">测试环境：windows10 x64vs2019cmake==2.24.3onnxruntime==1.12.0opencv==4.7.0使用步骤：首先cmake生成exe文件，然后将onnxruntime.dll和onnxruntime_providers_shared.dll放到exe一起，不然会提示报错0xc000007b，这是因为系统目录也有个onnxruntime.dll引发冲突，并把c, 视频播放量 4、弹幕量 0、点赞数 0、投硬币枚数 0、收藏人数 1、转发人数 0, 视频作者 未来自主研究中心, 作者简介 未来自主研究中心，相关视频：易语言部署yolox的onnx模型，yolov5最新版onnx部署Android安卓ncnn，C#使用纯opencvsharp部署yolov8-onnx图像分类模型，老师可真会玩！，使用C#部署yolov8的目标检测tensorrt模型，C# winform部署yolov10的onnx模型，YOLOv8检测界面-PyQt5实现，2024年新版【YOLOV5从入门到实战教程】B站最良心的YOLOV5全套教程（适合小白）含源码！—YOLOV5、YOLOV5实战、目标检测、计算机视觉，C#使用onnxruntime部署Detic检测2万1千种类别的物体，使用纯opencv部署yolov8目标检测模型onnx</span><span class="link-link"><img class="link-link-icon" src="https://images2.imgbox.com/3b/e6/o89pfLJC_o.png" alt="icon-default.png?t=N7T8">https://www.bilibili.com/video/BV1Zw4m1v7iz/?vd_source=989ae2b903ea1b5acebbe2c4c4a635ee</span></span></a></p> 
<p>【源码下载】</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/6f1212427cf7c18efce57eb475e3b4aa/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【JavaEE精炼宝库】多线程（5）单例模式 | 指令重排序 | 阻塞队列</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/f024fe699dbc769b6a59078cb54803f3/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">C# WPF入门学习主线篇（二十四）—— 数据绑定基础</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>