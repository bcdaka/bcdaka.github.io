<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Qualcomm® AI Engine Direct 使用手册（20） - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/cadf3b922f702983a5e3e15f09ac4ee3/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="Qualcomm® AI Engine Direct 使用手册（20）">
  <meta property="og:description" content="Qualcomm® AI Engine Direct 使用手册（20） 7 转换器7.1 概述7.2 张量流转换7.2.1 模式匹配7.2.2 额外必需的参数7.2.3 有关 Tensorflow 2.x 支持的说明7.2.4 例子 7.3 TFLite 转换7.3.1 额外必需的参数 7.4 PyTorch 转换7.4.1 额外必需的参数7.4.2 例子 7.5 Onnx 转换7.6 自定义操作输出形状推断7.7 自定义输入/输出7.8 保留 I/O 7 转换器 7.1 概述 Qualcomm® AI Engine Direct目前支持四种框架的转换器：Tensorflow、TFLite、PyTorch 和 Onnx。每个转换器至少需要原始框架模型作为输入来生成 Qualcomm® AI Engine 直接模型。有关其他所需的输入，请参阅下面的框架特定部分。
每个转换器的流程是相同的：
转换器工作流程 每个转换器有四个主要部分：
前端翻译，负责将原始框架模型转换为通用中间表示（IR）
通用 IR 代码包含图形和 IR 操作定义以及可应用于翻译图形的各种图形优化。
量化器，可以选择调用它来在最终降低为 QNN 之前量化模型。有关详细信息，请参阅量化。
Qnn 转换器后端负责将 IR 降低到最终的 QnnModel API 调用中。
所有转换器共享相同的 IR 代码和 QNN 转换器后端。每个转换器的输出都是相同的，即model.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-01-11T17:31:55+08:00">
    <meta property="article:modified_time" content="2024-01-11T17:31:55+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Qualcomm® AI Engine Direct 使用手册（20）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>Qualcomm® AI Engine Direct 使用手册（20）</h4> 
 <ul><li><a href="#7__3" rel="nofollow">7 转换器</a></li><li><ul><li><a href="#71__4" rel="nofollow">7.1 概述</a></li><li><a href="#72__157" rel="nofollow">7.2 张量流转换</a></li><li><ul><li><a href="#721__161" rel="nofollow">7.2.1 模式匹配</a></li><li><a href="#722__183" rel="nofollow">7.2.2 额外必需的参数</a></li><li><a href="#723__Tensorflow_2x__204" rel="nofollow">7.2.3 有关 Tensorflow 2.x 支持的说明</a></li><li><a href="#724__228" rel="nofollow">7.2.4 例子</a></li></ul> 
   </li><li><a href="#73_TFLite__237" rel="nofollow">7.3 TFLite 转换</a></li><li><ul><li><a href="#731__241" rel="nofollow">7.3.1 额外必需的参数</a></li></ul> 
   </li><li><a href="#74_PyTorch__260" rel="nofollow">7.4 PyTorch 转换</a></li><li><ul><li><a href="#741__265" rel="nofollow">7.4.1 额外必需的参数</a></li><li><a href="#742__274" rel="nofollow">7.4.2 例子</a></li></ul> 
   </li><li><a href="#75_Onnx__282" rel="nofollow">7.5 Onnx 转换</a></li><li><a href="#76__294" rel="nofollow">7.6 自定义操作输出形状推断</a></li><li><a href="#77__314" rel="nofollow">7.7 自定义输入/输出</a></li><li><a href="#78__IO_421" rel="nofollow">7.8 保留 I/O</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<hr> 
<h2><a id="7__3"></a>7 转换器</h2> 
<h3><a id="71__4"></a>7.1 概述</h3> 
<p>Qualcomm® AI Engine Direct目前支持四种框架的转换器：Tensorflow、TFLite、PyTorch 和 Onnx。每个转换器至少需要原始框架模型作为输入来生成 Qualcomm® AI Engine 直接模型。有关其他所需的输入，请参阅下面的框架特定部分。</p> 
<p>每个转换器的流程是相同的：</p> 
<center>
  转换器工作流程 
</center> 
<p><img src="https://images2.imgbox.com/7c/d9/qAxmeEAs_o.png" alt="请添加图片描述"><br> 每个转换器有四个主要部分：</p> 
<ol><li> <p>前端翻译，负责将原始框架模型转换为通用中间表示（IR）</p> </li><li> <p>通用 IR 代码包含图形和 IR 操作定义以及可应用于翻译图形的各种图形优化。</p> </li><li> <p>量化器，可以选择调用它来在最终降低为 QNN 之前量化模型。有关详细信息，请参阅量化。</p> </li><li> <p>Qnn 转换器后端负责将 IR 降低到最终的 QnnModel API 调用中。</p> </li></ol> 
<p>所有转换器共享相同的 IR 代码和 QNN 转换器后端。每个转换器的输出都是相同的，即model.cpp或model.cpp/model.bin，其中包含最终转换的 QNN 图。转换后的model.cpp包含两个函数：QnnModel_composeGraphs和QnnModel_freeGraphsInfo。这两个函数利用 下面描述的工具实用程序 API。此外，还保存了model_net.json ，它是model.cpp的 json 格式变体。</p> 
<p><strong>QNN 模型 JSON 格式</strong></p> 
<blockquote> 
 <p>笔记<br> 所有 QNN 枚举/宏值都在字段中解析。<br> 所有输入/输出张量都存储在“tensors”配置部分中，张量名称稍后用于定义节点输入/输出。节点配置中定义的唯一张量是张量参数。<br> 静态输入张量数据不存储在 JSON 中。</p> 
</blockquote> 
<pre><code class="prism language-c"><span class="token punctuation">{<!-- --></span>
  <span class="token string">"model.cpp"</span><span class="token operator">:</span> <span class="token string">"&lt;CPP filename goes here&gt;"</span><span class="token punctuation">,</span>
  <span class="token string">"model.bin"</span><span class="token operator">:</span> <span class="token string">"&lt;BIN filename goes here if applicable else NA&gt;"</span><span class="token punctuation">,</span>
  <span class="token string">"coverter_command"</span><span class="token operator">:</span> <span class="token string">"&lt;command line used goes here&gt;"</span><span class="token punctuation">,</span>
  <span class="token string">"copyright_str"</span><span class="token operator">:</span> <span class="token string">"&lt;copyright str goes here if applicable else "</span><span class="token string">"&gt;"</span><span class="token punctuation">,</span>
  <span class="token string">"op_types"</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token string">"list of unique op types found in graph"</span><span class="token punctuation">]</span>
  <span class="token string">"Total parameters"</span><span class="token operator">:</span> <span class="token string">"total parameter count in graph ( value in MB assuming single precision float)"</span><span class="token punctuation">,</span>
  <span class="token string">"Total MACs per inference"</span><span class="token operator">:</span> "total multiply and accumulates in graph count in M<span class="token punctuation">)</span><span class="token punctuation">,</span>
  <span class="token string">"graph"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span>
     <span class="token string">"tensors"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span>
       "<span class="token operator">&lt;</span>tensor_name<span class="token operator">&gt;</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span>
         <span class="token string">"id"</span><span class="token operator">:</span> <span class="token operator">&lt;</span>generated_id<span class="token operator">&gt;</span><span class="token punctuation">,</span>
         <span class="token string">"type"</span><span class="token operator">:</span> <span class="token operator">&lt;</span>tensor_type<span class="token operator">&gt;</span><span class="token punctuation">,</span>
         <span class="token string">"dataFormat"</span><span class="token operator">:</span> <span class="token operator">&lt;</span>tensor_memory_layout<span class="token operator">&gt;</span><span class="token punctuation">,</span>
         <span class="token string">"data_type"</span><span class="token operator">:</span> <span class="token operator">&lt;</span>tensor_data_type<span class="token operator">&gt;</span><span class="token punctuation">,</span>
         <span class="token string">"quant_params"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span>
           <span class="token string">"definition"</span><span class="token operator">:</span> <span class="token operator">&lt;</span>enum_value<span class="token operator">&gt;</span><span class="token punctuation">,</span>
           <span class="token string">"encoding"</span><span class="token operator">:</span> <span class="token operator">&lt;</span>enum_value<span class="token operator">&gt;</span><span class="token punctuation">,</span>
           <span class="token string">"scale_offset"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span>
             <span class="token string">"offset"</span><span class="token operator">:</span> <span class="token operator">&lt;</span>val<span class="token operator">&gt;</span><span class="token punctuation">,</span>
             <span class="token string">"scale"</span><span class="token operator">:</span>  <span class="token operator">&lt;</span>val<span class="token operator">&gt;</span>
           <span class="token punctuation">}</span>
         <span class="token punctuation">}</span>
         <span class="token string">"current_dims"</span><span class="token operator">:</span> <span class="token operator">&lt;</span>list_val<span class="token operator">&gt;</span><span class="token punctuation">,</span>
         <span class="token string">"max_dims"</span><span class="token operator">:</span> <span class="token operator">&lt;</span>list_val<span class="token operator">&gt;</span><span class="token punctuation">,</span>
         <span class="token string">"params_count"</span><span class="token operator">:</span> <span class="token operator">&lt;</span>val<span class="token operator">&gt;</span> <span class="token punctuation">(</span><span class="token string">"parameter count for node, along with value/total percentage. (only where applicable)"</span><span class="token punctuation">)</span>
       <span class="token punctuation">}</span><span class="token punctuation">,</span>
       "<span class="token operator">&lt;</span>tensor_name_with_axis_scale_offset_variant<span class="token operator">&gt;</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span>
         <span class="token string">"id"</span><span class="token operator">:</span> <span class="token operator">&lt;</span>generated_id<span class="token operator">&gt;</span><span class="token punctuation">,</span>
         <span class="token string">"type"</span><span class="token operator">:</span> <span class="token operator">&lt;</span>tensor_type<span class="token operator">&gt;</span><span class="token punctuation">,</span>
         <span class="token string">"dataFormat"</span><span class="token operator">:</span> <span class="token operator">&lt;</span>tensor_memory_layout<span class="token operator">&gt;</span><span class="token punctuation">,</span>
         <span class="token string">"data_type"</span><span class="token operator">:</span> <span class="token operator">&lt;</span>tensor_data_type<span class="token operator">&gt;</span><span class="token punctuation">,</span>
         <span class="token string">"quant_params"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span>
           <span class="token string">"definition"</span><span class="token operator">:</span> <span class="token operator">&lt;</span>enum_value<span class="token operator">&gt;</span><span class="token punctuation">,</span>
           <span class="token string">"encoding"</span><span class="token operator">:</span> <span class="token operator">&lt;</span>enum_value<span class="token operator">&gt;</span><span class="token punctuation">,</span>
           <span class="token string">"axis_scale_offset"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span>
             <span class="token string">"axis"</span><span class="token operator">:</span> <span class="token operator">&lt;</span>val<span class="token operator">&gt;</span><span class="token punctuation">,</span>
             <span class="token string">"num_scale_offsets"</span><span class="token operator">:</span> <span class="token operator">&lt;</span>val<span class="token operator">&gt;</span><span class="token punctuation">,</span>
             <span class="token string">"scale_offsets"</span><span class="token operator">:</span> <span class="token punctuation">[</span>
               <span class="token punctuation">{<!-- --></span>
                 <span class="token string">"scale"</span><span class="token operator">:</span> <span class="token operator">&lt;</span>val<span class="token operator">&gt;</span><span class="token punctuation">,</span>
                 <span class="token string">"offset"</span><span class="token operator">:</span> <span class="token operator">&lt;</span>val<span class="token operator">&gt;</span>
               <span class="token punctuation">}</span><span class="token punctuation">,</span>
               <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
             <span class="token punctuation">]</span>
           <span class="token punctuation">}</span>
         <span class="token punctuation">}</span>
         <span class="token string">"current_dims"</span><span class="token operator">:</span> <span class="token operator">&lt;</span>list_val<span class="token operator">&gt;</span><span class="token punctuation">,</span>
         <span class="token string">"max_dims"</span><span class="token operator">:</span> <span class="token operator">&lt;</span>list_val<span class="token operator">&gt;</span>
        <span class="token punctuation">}</span><span class="token punctuation">,</span>
       <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
    <span class="token punctuation">}</span>
    <span class="token string">"nodes"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span>
       "<span class="token operator">&lt;</span>node_name<span class="token operator">&gt;</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span>
         <span class="token string">"package"</span><span class="token operator">:</span> <span class="token operator">&lt;</span>str_val<span class="token operator">&gt;</span><span class="token punctuation">,</span>
         <span class="token string">"type"</span><span class="token operator">:</span> <span class="token operator">&lt;</span>str_val<span class="token operator">&gt;</span><span class="token punctuation">,</span>
         <span class="token string">"tensor_params"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span>
           <span class="token string">"&lt;param_name&gt;"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span>
             "<span class="token operator">&lt;</span>tensor_name_<span class="token operator">*</span><span class="token operator">&gt;</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span>
                 <span class="token string">"id"</span><span class="token operator">:</span> <span class="token operator">&lt;</span>generated_id<span class="token operator">&gt;</span><span class="token punctuation">,</span>
                 <span class="token string">"type"</span><span class="token operator">:</span> <span class="token operator">&lt;</span>tensor_type<span class="token operator">&gt;</span><span class="token punctuation">,</span>
                 <span class="token string">"dataFormat"</span><span class="token operator">:</span> <span class="token operator">&lt;</span>tensor_memory_layout<span class="token operator">&gt;</span><span class="token punctuation">,</span>
                 <span class="token string">"data_type"</span><span class="token operator">:</span> <span class="token operator">&lt;</span>tensor_data_type<span class="token operator">&gt;</span><span class="token punctuation">,</span>
                 <span class="token string">"quant_params"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span>
                    <span class="token string">"definition"</span><span class="token operator">:</span> <span class="token operator">&lt;</span>enum_value<span class="token operator">&gt;</span><span class="token punctuation">,</span>
                    <span class="token string">"encoding"</span><span class="token operator">:</span> <span class="token operator">&lt;</span>enum_value<span class="token operator">&gt;</span><span class="token punctuation">,</span>
                    <span class="token string">"scale_offset"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span>
                      <span class="token string">"offset"</span><span class="token operator">:</span> <span class="token operator">&lt;</span>val<span class="token operator">&gt;</span><span class="token punctuation">,</span>
                      <span class="token string">"scale"</span><span class="token operator">:</span>  <span class="token operator">&lt;</span>val<span class="token operator">&gt;</span>
                    <span class="token punctuation">}</span>
                 <span class="token string">"current_dims"</span><span class="token operator">:</span> <span class="token operator">&lt;</span>list_val<span class="token operator">&gt;</span><span class="token punctuation">,</span>
                 <span class="token string">"max_dims"</span><span class="token operator">:</span> <span class="token operator">&lt;</span>list_val<span class="token operator">&gt;</span><span class="token punctuation">,</span>
                 <span class="token string">"data"</span><span class="token operator">:</span> <span class="token operator">&lt;</span>list_val<span class="token operator">&gt;</span>
               <span class="token punctuation">}</span>
           <span class="token punctuation">}</span>
           <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
         <span class="token punctuation">}</span><span class="token punctuation">,</span>
         <span class="token string">"scalar_params"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span>
           <span class="token string">"param_name"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span>
              <span class="token string">"param_data_type"</span><span class="token operator">:</span> <span class="token operator">&lt;</span>val<span class="token operator">&gt;</span>
            <span class="token punctuation">}</span>
           <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
         <span class="token punctuation">}</span><span class="token punctuation">,</span>
         <span class="token string">"input_names"</span><span class="token operator">:</span> <span class="token operator">&lt;</span>list_str_val<span class="token operator">&gt;</span><span class="token punctuation">,</span>
         <span class="token string">"output_names"</span><span class="token operator">:</span> <span class="token operator">&lt;</span>list_str_val<span class="token operator">&gt;</span><span class="token punctuation">,</span>
         <span class="token string">"macs_per_inference"</span><span class="token operator">:</span> <span class="token operator">&lt;</span>val<span class="token operator">&gt;</span> <span class="token punctuation">(</span><span class="token string">"multiply and accumulate value for node, along with value/total percentage. (only where applicable)"</span><span class="token punctuation">)</span>
       <span class="token punctuation">}</span>
       <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

</code></pre> 
<p><strong>工具 实用程序 API</strong></p> 
<p>工具实用程序 API 包含用于生成 QNN API 调用的帮助程序模块。这些 API 是核心 QNN API 之上的轻量级包装器，旨在减少创建 QNN 图的重复步骤。</p> 
<ul><li> <p>工具实用程序 C++ API：</p> 
  <ul><li>类层次结构</li><li>文件层次结构</li><li>完整的API</li></ul> </li><li> <p>QNN Core C API 参考：C</p> </li></ul> 
<center>
  QNN 模型类 
</center> 
<p><img src="https://images2.imgbox.com/f4/11/sKfokEGr_o.png" alt="请添加图片描述"></p> 
<ul><li> <p>QnnModel：此类类似于给定上下文中的 QnnGraph 及其张量。应在初始化时提供上下文，并在其中创建一个新的 QnnGraph。有关这些类 API 的更多详细信息，请参阅 QnnModel.hpp、 QnnWrapperUtils.hpp</p> </li><li> <p>GraphConfigInfo：此结构用于从客户端传递 QNN 图配置列表（如果适用）。 有关可用图形配置选项的详细信息，请参阅QnnGraph API 。</p> </li><li> <p>GraphInfo：此结构用于将构造的图及其输入和输出张量传递给客户端。</p> </li><li> <p>QnnModel_composeGraphs：负责使用 QnnModel 类在提供的 QNN 后端上构建 QNN 图。它将通过 graphsInfo 返回构造的图。</p> </li><li> <p>QnnModel_freeGraphsInfo：只有在图表不再使用时才应该调用。</p> </li></ul> 
<p>有关将模型集成到应用程序中的更多信息，请参阅集成工作流程。</p> 
<h3><a id="72__157"></a>7.2 张量流转换</h3> 
<p>与许多其他神经网络运行时引擎一样，QNN 支持低级操作（如元素乘法）和高级操作（如 Prelu）。另一方面，TensorFlow 通常通过将高级操作表示为低级操作的子图来支持高级操作。为了协调这些差异，转换器有时必须将小型操作的子图模式匹配为可在 QNN 中利用的更大的“类层”操作。</p> 
<h4><a id="721__161"></a>7.2.1 模式匹配</h4> 
<p>以下是 QNN Tensorflow 转换器中发生的模式匹配的几个示例。在每种情况下，该模式通常由落在层输入和输出之间的任何操作组成，并且权重和偏差等附加参数被吸收到最终的 IR 操作中。</p> 
<p><img src="https://images2.imgbox.com/9b/13/QPvqnAAr_o.png" alt="请添加图片描述"><br> 卷积示例：</p> 
<p><img src="https://images2.imgbox.com/1d/22/z23AKIpn_o.png" alt="请添加图片描述"><br> 前奏示例：</p> 
<p><img src="https://images2.imgbox.com/22/73/neM66tlu_o.png" alt="请添加图片描述"></p> 
<p>需要记住的重要一点是，这些模式是硬编码在转换器中的。影响这些模式中操作的连接性和顺序的模型更改也可能会破坏转换，因为转换器将无法识别子图并将其映射到适当的层。</p> 
<p>TF 转换器还支持将量化感知训练 (QAT) 模型参数传播到最终的 QNN 模型。当调用量化时，这会在转换过程中自动发生。请注意，量化节点的放置也决定了它们是否会被传播。在模式内插入量化节点将导致模式匹配中断和转换失败。插入节点的安全位置是在“类似层”的层之后，以捕获层的激活信息。此外，在权重和偏差之后插入的量化节点可以捕获静态参数的量化信息。</p> 
<p>在卷积后插入量化节点的示例：</p> 
<p><img src="https://images2.imgbox.com/f0/e4/3wunU8qV_o.png" alt="请添加图片描述"><br> 有关在转换过程中启动量化的更多信息，请参阅量化。</p> 
<h4><a id="722__183"></a>7.2.2 额外必需的参数</h4> 
<p>由于 Tensorflow 图通常包含一般推理不需要的无关节点，因此需要提供输入节点和维度以及推理所需的最终输出节点。然后，转换器将从图中删除不必要的节点，以确保图形更加紧凑和高效。</p> 
<p>要指定转换器的图形输入，请在命令行上传递以下命令：</p> 
<pre><code class="prism language-c"><span class="token operator">--</span>input_dim <span class="token operator">&lt;</span>input_name<span class="token operator">&gt;</span> <span class="token operator">&lt;</span>comma separated dims<span class="token operator">&gt;</span>

</code></pre> 
<p>要指定图形的输出节点，只需传递：</p> 
<pre><code class="prism language-c"><span class="token operator">--</span>out_node <span class="token operator">&lt;</span>output_name<span class="token operator">&gt;</span>

</code></pre> 
<p>Tensorflow也有多种输入格式，但仅支持冻结图（.pb文件）或.meta文件。转换器不支持保存的培训课程。</p> 
<h4><a id="723__Tensorflow_2x__204"></a>7.2.3 有关 Tensorflow 2.x 支持的说明</h4> 
<p>qnn-tensorflow-converter 已更新，支持 Tensorflow 2.3 模型的转换。请注意，虽然某些 TF 1.x 模型可能使用 Tensorflow 2.3 作为转换框架进行转换，但通常建议使用与训练模型相同的 TF 版本进行转换。某些较旧的 1.x 模型可能根本无法使用 TF 2.3 进行转换，并且可能需要 TF 1.x 实例才能成功转换。</p> 
<p>请注意，一些选项已更新或添加以支持 Tensorflow 2.x 模型。第一个是支持 SavedModel 格式的更改。用户可以通过将目录传递给相同的 input_network 选项来提供 SavedModel 文件的目录：</p> 
<pre><code class="prism language-c"><span class="token operator">--</span>input_network <span class="token operator">&lt;</span>SavedModel path<span class="token operator">&gt;</span>
</code></pre> 
<p>用户可以选择传递saved_model_tag来指示来自SavedModel的标签和关联的MetaGraph。默认为“服务”</p> 
<pre><code class="prism language-c"><span class="token operator">--</span>saved_model_tag <span class="token operator">&lt;</span>tag<span class="token operator">&gt;</span>
</code></pre> 
<p>最后，用户可以使用签名密钥选择模型的输入和输出。默认值为“默认服务”</p> 
<pre><code class="prism language-c"><span class="token operator">--</span>saved_model_signature_key <span class="token operator">&lt;</span>signature_key<span class="token operator">&gt;</span>
</code></pre> 
<h4><a id="724__228"></a>7.2.4 例子</h4> 
<p>下面是一个 SSD 模型的示例，需要一张图像输入，但有 4 个输出节点。</p> 
<pre><code class="prism language-c">qnn<span class="token operator">-</span>tensorflow<span class="token operator">-</span>converter <span class="token operator">--</span>input_network frozen_graph<span class="token punctuation">.</span>pb <span class="token operator">--</span>input_dim Preprocessor<span class="token operator">/</span>sub <span class="token number">1</span><span class="token punctuation">,</span><span class="token number">300</span><span class="token punctuation">,</span><span class="token number">300</span><span class="token punctuation">,</span><span class="token number">3</span> <span class="token operator">--</span>output_path ssd_model<span class="token punctuation">.</span>cpp <span class="token operator">--</span>out_node detection_scores <span class="token operator">--</span>out_node detection_boxes <span class="token operator">--</span>out_node detection_classes <span class="token operator">--</span>out_node Postprocessor<span class="token operator">/</span>BatchMultiClassNonMaxSuppression<span class="token operator">/</span>map<span class="token operator">/</span>TensorArrayStack_2<span class="token operator">/</span>TensorArrayGatherV3 <span class="token operator">-</span>p <span class="token string">"qti.aisw"</span>

</code></pre> 
<h3><a id="73_TFLite__237"></a>7.3 TFLite 转换</h3> 
<p>将qnn-tflite-converterTFLite 模型转换为等效的 QNN 表示。它采用 .tflite 模型作为输入。</p> 
<h4><a id="731__241"></a>7.3.1 额外必需的参数</h4> 
<p>TFlite 转换器需要在命令行提供输入节点的名称和尺寸以进行转换。每个输入必须使用相同的参数单独传递。</p> 
<p>要指定转换器的图形输入，请在命令行上传递以下命令：</p> 
<pre><code class="prism language-c"><span class="token operator">--</span>input_dim <span class="token operator">&lt;</span>input_name_1<span class="token operator">&gt;</span> <span class="token operator">&lt;</span>comma separated dims<span class="token operator">&gt;</span> <span class="token operator">--</span>input_dim <span class="token operator">&lt;</span>input_name_2<span class="token operator">&gt;</span> <span class="token operator">&lt;</span>comma separated dims<span class="token operator">&gt;</span>
</code></pre> 
<p>例子<br> 以下是转换 Inception_v3 模型的示例，需要一张图像输入</p> 
<pre><code class="prism language-c">qnn<span class="token operator">-</span>tflite<span class="token operator">-</span>converter <span class="token operator">--</span>input_network model<span class="token punctuation">.</span>tflite <span class="token operator">--</span>input_dim <span class="token string">"input"</span> <span class="token number">1</span><span class="token punctuation">,</span><span class="token number">299</span><span class="token punctuation">,</span><span class="token number">299</span><span class="token punctuation">,</span><span class="token number">3</span> <span class="token operator">--</span>output_path model<span class="token punctuation">.</span>cpp

</code></pre> 
<h3><a id="74_PyTorch__260"></a>7.4 PyTorch 转换</h3> 
<p>将qnn-pytorch-converterPyTorch 模型转换为等效的 QNN 表示。它采用 TorchScript 模型 (.pt) 作为输入。</p> 
<h4><a id="741__265"></a>7.4.1 额外必需的参数</h4> 
<p>PyTorch 转换器需要在命令行提供输入节点的名称和尺寸以进行转换。每个输入必须使用相同的参数单独传递。</p> 
<p>要指定转换器的图形输入，请在命令行上传递以下命令：</p> 
<pre><code class="prism language-c"><span class="token operator">--</span>input_dim <span class="token operator">&lt;</span>input_name_1<span class="token operator">&gt;</span> <span class="token operator">&lt;</span>comma separated dims<span class="token operator">&gt;</span> <span class="token operator">--</span>input_dim <span class="token operator">&lt;</span>input_name_2<span class="token operator">&gt;</span> <span class="token operator">&lt;</span>comma separated dims<span class="token operator">&gt;</span>
</code></pre> 
<h4><a id="742__274"></a>7.4.2 例子</h4> 
<p>以下是转换 Inception_v3 模型的示例，需要一张图像输入</p> 
<pre><code class="prism language-c">qnn<span class="token operator">-</span>pytorch<span class="token operator">-</span>converter <span class="token operator">--</span>input_network model<span class="token punctuation">.</span>pt <span class="token operator">--</span>input_dim <span class="token string">"input"</span> <span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">299</span><span class="token punctuation">,</span><span class="token number">299</span> <span class="token operator">--</span>output_path model<span class="token punctuation">.</span>cpp
</code></pre> 
<h3><a id="75_Onnx__282"></a>7.5 Onnx 转换</h3> 
<p>将qnn-onnx-converter序列化 ONNX 模型转换为等效的 QNN 表示。默认情况下，如果用户环境中可用，它还会运行 onnx-simplifier（请参阅设置）。此外，onnx-simplifier 仅在用户未提供量化覆盖/自定义操作时默认运行，因为简化过程可能会挤压图层，从而阻止使用自定义操作或量化覆盖。如果模型包含 ONNX 函数，转换器始终会内联函数节点。注意：如果转换失败，onnx 转换器支持附加选项“–dry_run”，它将转储有关不支持的操作和关联参数的详细信息。</p> 
<p>例子</p> 
<pre><code class="prism language-c">qnn<span class="token operator">-</span>onnx<span class="token operator">-</span>converter <span class="token operator">--</span>input_network model<span class="token punctuation">.</span>onnx <span class="token operator">--</span>output_path model<span class="token punctuation">.</span>cpp
</code></pre> 
<h3><a id="76__294"></a>7.6 自定义操作输出形状推断</h3> 
<p>QNN 转换器要求模型中存在所有操作的输出形状才能成功转换。如果模型中存在自定义操作的输出形状，则可以从模型中推断出来，或者使用框架的形状推断脚本进行推断。当模型中不存在自定义操作的输出形状或无法从框架的形状推断脚本推断出自定义操作的输出形状时，可以通过使用Convter Op Package Generation编译的共享库向转换器提供推断自定义操作输出形状的逻辑 。–converter_op_package_lib编译库可以通过或选项提供， -cpl后跟编译库的绝对路径。转换器采用该库并推断成功模型转换所需的自定义操作的输出形状。多个库必须以逗号分隔。</p> 
<blockquote> 
 <p>笔记<br> –converter_op_package_libor-cpl是一个可选参数，当模型中不存在自定义操作的输出形状或无法从框架的形状推断脚本推断出时，应使用该参数。</p> 
</blockquote> 
<p>例子</p> 
<pre><code class="prism language-c">qnn<span class="token operator">-</span>onnx<span class="token operator">-</span>converter <span class="token operator">--</span>input_network model<span class="token punctuation">.</span>onnx <span class="token operator">--</span>converter_op_package_lib libExampleLibrary<span class="token punctuation">.</span>so
</code></pre> 
<blockquote> 
 <p>笔记<br> 有关库生成和编译说明，请参阅Convter Op Package Generation 。<br> 仅 ONNX 和 PyTorch 转换器支持自定义操作输出形状推断。<br> Tensorflow和TFLite转换器不支持自定义操作输出形状推断。</p> 
</blockquote> 
<h3><a id="77__314"></a>7.7 自定义输入/输出</h3> 
<p>介绍<br> 自定义 I/O 功能允许用户在加载网络时为输入和输出提供所需的布局和数据类型。网络不是针对模型中指定的输入和输出编译网络，而是针对自定义配置中描述的输入和输出进行编译。当用户打算预处理（在 GPU/CDSP 或任何其他方法上）或离线处理（如 ML commons 允许的）输入数据并避免输入处理中的某些步骤时，可以使用此功能。如果用户了解输入预处理步骤，则可以避免冗余转置和数据类型转换。类似地，在后处理方面，如果要将模型输出馈送到管道中的下一个阶段，则可以将所需的格式和类型配置为当前阶段的输出。</p> 
<p>在本节中，术语“模型I/O”是指原始模型的输入和输出数据类型和格式。术语“自定义 I/O”是指用户所需的输入和输出数据类型和格式。</p> 
<p>自定义 I/O 配置文件<br> 可以使用配置 yaml 文件来应用自定义 I/O，该文件包含需要修改的每个输入和输出的以下字段。</p> 
<ul><li> <p>IOName：模型中需要根据自定义要求加载的输入或输出的名称。</p> </li><li> <p>布局：布局字段（可选）有两个子字段：模型和自定义。模型和自定义字段支持有效的 QNN 布局。接受的值为：NCDHW、NDHWC、NCHW、NHWC、NFC、NCF、NTF、TNF、NF、NC、F、NONTRIVIAL，其中，N = 批次、C = 通道、D = 深度、H = 高度、W = 宽度， F = 特征，T = 时间</p> 
  <ul><li> <p>模型：指定原始模型中缓冲区的布局。这相当于 –input_layout 选项，并且两者不能一起使用。</p> </li><li> <p>自定义：指定缓冲区所需的自定义布局。该字段需要由用户填写。</p> </li></ul> </li><li> <p>数据类型：数据类型字段（可选）支持 float32、float16 和 uint8 数据类型。</p> </li><li> <p>QuantParam：QuantParam 字段（可选）具有三个子字段：Type、Scale 和 Offset。</p> 
  <ul><li> <p>类型：如果比例和偏移由用户提供，则设置为 QNN_DEFINITION_DEFINED（默认），否则设置为 QNN_DEFINITION_UNDEFINED。</p> </li><li> <p>比例：用户所需的缓冲区比例的浮点值。</p> </li><li> <p>偏移量：用户所需的偏移量的整数值。</p> </li></ul> </li></ul> 
<p>例子<br> 考虑具有原始模型 I/O 和自定义 I/O 配置的 ONNX 模型，如下表所示：</p> 
<table><thead><tr><th>输入/输出名称</th><th>型号输入/输出</th><th>自定义输入/输出</th></tr></thead><tbody><tr><td>“输入_0”</td><td>浮动NCHW</td><td>int8 NHWC</td></tr><tr><td>“输出_0”</td><td>浮动NHWC</td><td>浮动NCHW</td></tr></tbody></table> 
<p>那么，需要提供的自定义I/O配置yaml文件内容为</p> 
<pre><code class="prism language-c"><span class="token operator">-</span> IOName<span class="token operator">:</span> input_0
  Layout<span class="token operator">:</span>
    Model<span class="token operator">:</span> NCHW
    Custom<span class="token operator">:</span> NCHW
  Datatype<span class="token operator">:</span> uint8
  QuantParam<span class="token operator">:</span>
    Type<span class="token operator">:</span>
       QNN_DEFINITION_DEFINED
    Scale<span class="token operator">:</span>
       <span class="token number">0.12</span>
    Offset<span class="token operator">:</span>
       <span class="token number">2</span>

<span class="token operator">-</span> IOName<span class="token operator">:</span> output_0
  Layout<span class="token operator">:</span>
    Model<span class="token operator">:</span> NHWC
    Custom<span class="token operator">:</span> NCHW

</code></pre> 
<blockquote> 
 <p>笔记：<br> 如果输入或输出不需要更改，则可以在配置文件中跳过。<br> 仅当模型输入或输出数据类型为 float、float16、int8 或 uint8 时，才可以使用自定义 I/O 功能修改数据类型。对于其他数据类型，应在配置文件中跳过“数据类型”字段。</p> 
</blockquote> 
<p>用法<br> –custom_io可以使用选项提供自定义 IO 配置 YAMl 文件qnn-onnx-converter。使用示例如下：</p> 
<pre><code class="prism language-c">$ $<span class="token punctuation">{<!-- --></span>QNN_SDK_ROOT<span class="token punctuation">}</span><span class="token operator">/</span>bin<span class="token operator">/</span>x86_64<span class="token operator">-</span>linux<span class="token operator">-</span>clang<span class="token operator">/</span>qnn<span class="token operator">-</span>onnx<span class="token operator">-</span>converter \
  <span class="token operator">--</span>custom_io <span class="token operator">&lt;</span>path<span class="token operator">/</span>to<span class="token operator">/</span>YAML<span class="token operator">/</span>file<span class="token operator">&gt;</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
</code></pre> 
<p>自定义 IO 配置模板文件<br> –dump_custom_io_config_template可以使用选项获取填充有默认值的自定义 IO 配置文件qnn-onnx-converter。</p> 
<pre><code class="prism language-c">$ $<span class="token punctuation">{<!-- --></span>QNN_SDK_ROOT<span class="token punctuation">}</span><span class="token operator">/</span>bin<span class="token operator">/</span>x86_64<span class="token operator">-</span>linux<span class="token operator">-</span>clang<span class="token operator">/</span>qnn<span class="token operator">-</span>onnx<span class="token operator">-</span>converter \
  <span class="token operator">--</span>input_network $<span class="token punctuation">{<!-- --></span>QNN_SDK_ROOT<span class="token punctuation">}</span><span class="token operator">/</span>examples<span class="token operator">/</span>Models<span class="token operator">/</span>InceptionV3<span class="token operator">/</span>tensorflow<span class="token operator">/</span>model<span class="token punctuation">.</span>onnx \
  <span class="token operator">--</span>dump_custom_io_config_template <span class="token operator">&lt;</span>output_folder<span class="token operator">&gt;</span><span class="token operator">/</span>config<span class="token punctuation">.</span>yaml
</code></pre> 
<p>转储的模板文件对于所提供的模型的每个输入和输出都有一个条目。模板文件中的每个字段都填充从该特定输入或输出的模型中获得的默认值。模板文件还包含为用户描述每个字段的注释。</p> 
<p>支持的用例</p> 
<ol><li> <p>模型的输入和输出缓冲区的布局转换。有效的布局转换是以下之间的相互转换：</p> 
  <ul><li> <p>NCDHW 和 NDHWC</p> </li><li> <p>NHWC 和 NCHW</p> </li><li> <p>NFC 和 NCF</p> </li><li> <p>NTF 和 TNF</p> </li></ul> </li><li> <p>将数据类型 uint8 或 int8 的量化输入传递给非量化模型。在这种情况下，用户必须提供量化输入的比例和偏移量。</p> </li><li> <p>用户可以为量化模型的输入和输出提供自定义比例和偏移。量化器生成的比例和偏移量将被用户在 YAML 文件中提供的比例和偏移量覆盖。</p> </li></ol> 
<p>用户可以使用–input_data_type和–output_data_type选项qnn-net-run来提供 float 或 uint8_t 类型数据来建模输入/输出。用户可以使用该native选项向模型传递和获取 int8/uint8 数据。默认情况下，qnn-net-run假设数据为 float32 类型，并在量化模型的情况下在输入处执行量化并在输出处执行去量化。</p> 
<p>局限性</p> 
<ul><li> <p>自定义 IO 仅支持提供以下数据类型：float32、float16、uint8、int8。</p> </li><li> <p>如果用户需要将量化输入（即 int8 或 uint8 类型）传递给非量化模型，则用户必须在 YAML 文件中提供比例和偏移量。在这种情况下，不提供比例和偏移量会引发错误。</p> </li></ul> 
<h3><a id="78__IO_421"></a>7.8 保留 I/O</h3> 
<p>介绍<br> 保留 I/O 功能允许用户保留原始 ONNX 模型中存在的输入和输出的布局和数据类型。由于 QNN 转换器在模型输入和输出处的默认行为，此功能允许用户避免任何将数据转换为布局和数据类型的预处理或后处理步骤。</p> 
<p>用法<br> 使用此选项的不同方法如下：</p> 
<ol><li> <p>用户可以通过传递–preserve_io以下选项来选择保留所有 IO 张量的布局和数据类型：</p> <pre><code class="prism language-c">$ $<span class="token punctuation">{<!-- --></span>QNN_SDK_ROOT<span class="token punctuation">}</span><span class="token operator">/</span>bin<span class="token operator">/</span>x86_64<span class="token operator">-</span>linux<span class="token operator">-</span>clang<span class="token operator">/</span>qnn<span class="token operator">-</span>onnx<span class="token operator">-</span>converter \
  <span class="token operator">--</span>preserve_io <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
</code></pre> </li><li> <p>用户可以选择为图表的所有输入和输出保留唯一的布局或数据类型，如下所示：</p> <pre><code class="prism language-c">$ $<span class="token punctuation">{<!-- --></span>QNN_SDK_ROOT<span class="token punctuation">}</span><span class="token operator">/</span>bin<span class="token operator">/</span>x86_64<span class="token operator">-</span>linux<span class="token operator">-</span>clang<span class="token operator">/</span>qnn<span class="token operator">-</span>onnx<span class="token operator">-</span>converter \
  <span class="token operator">--</span>preserve_io layout <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>

or<span class="token punctuation">,</span>

$ $<span class="token punctuation">{<!-- --></span>QNN_SDK_ROOT<span class="token punctuation">}</span><span class="token operator">/</span>bin<span class="token operator">/</span>x86_64<span class="token operator">-</span>linux<span class="token operator">-</span>clang<span class="token operator">/</span>qnn<span class="token operator">-</span>onnx<span class="token operator">-</span>converter \
  <span class="token operator">--</span>preserve_io datatype<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
</code></pre> </li><li> <p>用户可以选择仅保留图形的少数输入和输出的布局或数据类型，如下所示：</p> <pre><code class="prism language-c">$ $<span class="token punctuation">{<!-- --></span>QNN_SDK_ROOT<span class="token punctuation">}</span><span class="token operator">/</span>bin<span class="token operator">/</span>x86_64<span class="token operator">-</span>linux<span class="token operator">-</span>clang<span class="token operator">/</span>qnn<span class="token operator">-</span>onnx<span class="token operator">-</span>converter \
  <span class="token operator">--</span>preserve_io layout <span class="token operator">&lt;</span>space separated list of names of inputs and outputs of the graph<span class="token operator">&gt;</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>

or<span class="token punctuation">,</span>

$ $<span class="token punctuation">{<!-- --></span>QNN_SDK_ROOT<span class="token punctuation">}</span><span class="token operator">/</span>bin<span class="token operator">/</span>x86_64<span class="token operator">-</span>linux<span class="token operator">-</span>clang<span class="token operator">/</span>qnn<span class="token operator">-</span>onnx<span class="token operator">-</span>converter \
  <span class="token operator">--</span>preserve_io datatype <span class="token operator">&lt;</span>space separated list of names of inputs and outputs of the graph<span class="token operator">&gt;</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
</code></pre> </li><li> <p>用户可以传递和的组合，如下所示：–preserve_io layout–preserve_io datatype</p> <pre><code class="prism language-c">$ $<span class="token punctuation">{<!-- --></span>QNN_SDK_ROOT<span class="token punctuation">}</span><span class="token operator">/</span>bin<span class="token operator">/</span>x86_64<span class="token operator">-</span>linux<span class="token operator">-</span>clang<span class="token operator">/</span>qnn<span class="token operator">-</span>onnx<span class="token operator">-</span>converter \
  <span class="token operator">--</span>preserve_io layout <span class="token operator">&lt;</span>space separated list of names of inputs and outputs of the graph<span class="token operator">&gt;</span> \
  <span class="token operator">--</span>preserve_io datatype <span class="token operator">&lt;</span>space separated list of names of inputs and outputs of the graph<span class="token operator">&gt;</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
</code></pre> </li></ol> 
<p>仅仅并一起通过是有效的并且等同于仅通过。第 3 点中的用法不能与第 1 点或第 2 点中的用法结合使用，如果一起使用将导致错误。–preserve_io layout–preserve_io datatype–preserve_io</p> 
<p>与其他转换器选项一起使用</p> 
<ol><li> <p>–keep_int64_inputs如果使用保留 IO 来保留此类输入的数据类型，则不需要传递。</p> </li><li> <p>–use_native_input_files如果使用保留 IO 来保留数据类型，则在量化的情况下设置为 True。</p> </li><li> <p>–input_layout遵循指定使用的布局。</p> </li><li> <p>–input_dtype如果任何 IO 张量的数据类型不匹配，则与保留 IO 一起使用可能会导致错误。</p> </li><li> <p>使用 指定的布局和数据类型的–custom_io优先级高于–preserve_io。</p> </li></ol> 
<p>由于保留 IO 保留原始模型中 IO 张量的数据类型，因此用户必须使用–use_native_input_filesor 。–native_input_tensor_namesqnn-net-run</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/8f4849a4c285b29503a6edcfbf78191f/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Windows安装Rust环境（详细教程）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/09d79854f25f0fa64346e62c33112d3d/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">手把手教你调用文心一言API，含py调用示例代码</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>