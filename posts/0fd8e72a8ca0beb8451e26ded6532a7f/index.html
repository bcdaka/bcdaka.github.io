<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Hadoop集群中如何通过web访问HDFS（以及上传下载测试） - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/0fd8e72a8ca0beb8451e26ded6532a7f/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="Hadoop集群中如何通过web访问HDFS（以及上传下载测试）">
  <meta property="og:description" content="如何通过Web查看hadoop的运行状态 一共有几小部分组成，但是前提你得先在集群系统的hosts文件中添加集群IP映射不难，上操作
首先得关闭虚拟机（hadoop集群）的防火墙，以下是代码，直接复制粘贴即可
systemctl stop firewalld //关闭防火墙 systemctl disable firewalld //禁止开机自启动 其次就是IP映射以及查看本机ip地址，我这里使用的是集群1中的ip进行演示
如何配置ip映射？
vi /etc/hosts //进入文件后按i编辑，在最后另起一行写入你需要映射的IP地址 如何在etc/sysconfig/network-scripts/ifcfg-ens33中编辑IP？进入文件后按照如图红色/黄色画线进行添加，最后对所有代码进行检查
vi /etc/sysconfig/network-scripts/ifcfg-ens33 修改后别忘记重启网卡
nmcli c reload //重新加载配置文件 nmcli c up ens33 //重新启动ens33网卡 查看IP地址
ip add //或者 fconfig 也可以 在输入命令后，在下方找到inet，后面的就是你的ip地址
最后一步，也是最重要的一步来啦
在计算机浏览器中输入http://&lt;刚刚查询到自己的IP&gt;:8088/cluster 和http://&lt;自己IP&gt;:50070/dfshealth.html#tab-overview 如果我的：
http://192.168.000.000:8088/cluster http://192.168.000.000:50070/dfshealth.html#tab-overview 如何进行上传下载测试 如何上传？ 首先我们手动设置 Hadoop 环境变量，具体方法如下
在Hadoop的安装目录下修改环境变量
vi ~/.bashrc 在打开的文件末尾添加
export HADOOP_HOME=/usr/local/hadoop export PATH=$PATH:$HADOOP_HOME/bin 其中/usr/local/hadoop是你自己的hadoop安装路径，列如我的是 /export/servers/wfb-hadoop/hadoop-2.7.4，那就替换我自己的路径即可，害怕出错的可以参考一下图片
保存并退出文件。然后执行以下命令使配置生效
source ~/.bashrc 然后尝试使用 hdfs 命令上传文件在hadoop目录下的bin目录里运行
hdfs dfs -put &lt;自己需要上传的文件的地址&gt; /path/to/hdfs/directory/ ** 如果在上传过程中出现“ls: `.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2023-12-20T17:00:32+08:00">
    <meta property="article:modified_time" content="2023-12-20T17:00:32+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Hadoop集群中如何通过web访问HDFS（以及上传下载测试）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="Webhadoop_0"></a>如何通过Web查看hadoop的运行状态</h2> 
<p>一共有几小部分组成，但是前提你得先在集群系统的<mark>hosts文件中添加集群IP映射</mark>不难，上操作</p> 
<p><strong>首先得关闭虚拟机（hadoop集群）的防火墙，以下是代码，直接复制粘贴即可</strong></p> 
<pre><code>systemctl stop firewalld              //关闭防火墙
</code></pre> 
<pre><code>systemctl disable firewalld           //禁止开机自启动
</code></pre> 
<p><strong>其次就是IP映射以及查看本机ip地址，我这里使用的是集群1中的ip进行演示</strong><br> 如何配置ip映射？</p> 
<pre><code>vi /etc/hosts         //进入文件后按i编辑，在最后另起一行写入你需要映射的IP地址
</code></pre> 
<p><strong>如何在etc/sysconfig/network-scripts/ifcfg-ens33中编辑IP？进入文件后按照如图红色/黄色画线进行添加，最后对所有代码进行检查</strong></p> 
<pre><code> vi /etc/sysconfig/network-scripts/ifcfg-ens33
</code></pre> 
<p><img src="https://images2.imgbox.com/24/03/1P07a4K4_o.png" alt="在这里插入图片描述"></p> 
<p><mark>修改后别忘记重启网卡</mark></p> 
<pre><code>
nmcli c reload    //重新加载配置文件
nmcli c up ens33      //重新启动ens33网卡
</code></pre> 
<p><strong>查看IP地址</strong></p> 
<pre><code>ip add         //或者   fconfig   也可以
</code></pre> 
<p>在输入命令后，在下方找到<mark>inet</mark>，后面的就是你的ip地址<br> <img src="https://images2.imgbox.com/f7/f8/873zaAIr_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="%0AhttpIP8088cluster_45"></a><strong>最后一步，也是最重要的一步来啦</strong><br> <mark>在计算机浏览器中输入http://&lt;刚刚查询到自己的IP&gt;:8088/cluster</mark></h2> 
<h2><a id="httpIP50070dfshealthhtmltaboverview_48"></a><mark>和http://&lt;自己IP&gt;:50070/dfshealth.html#tab-overview</mark></h2> 
<p>如果我的：</p> 
<pre><code>http://192.168.000.000:8088/cluster
</code></pre> 
<pre><code>http://192.168.000.000:50070/dfshealth.html#tab-overview
</code></pre> 
<h2><a id="_61"></a>如何进行上传下载测试</h2> 
<h3><a id="_62"></a>如何上传？</h3> 
<p><strong>首先我们手动设置 Hadoop 环境变量，具体方法如下</strong><br> 在Hadoop的安装目录下修改环境变量</p> 
<pre><code>vi ~/.bashrc
</code></pre> 
<p>在打开的文件末尾添加</p> 
<pre><code>export HADOOP_HOME=/usr/local/hadoop
export PATH=$PATH:$HADOOP_HOME/bin
</code></pre> 
<p><mark>其中/usr/local/hadoop是你自己的hadoop安装路径，列如我的是 /export/servers/wfb-hadoop/hadoop-2.7.4，那就替换我自己的路径即可，害怕出错的可以参考一下图片</mark><br> <img src="https://images2.imgbox.com/f8/8e/8RbWoZbt_o.png" alt="在这里插入图片描述"></p> 
<p>保存并退出文件。然后执行以下命令使配置生效</p> 
<pre><code>source ~/.bashrc
</code></pre> 
<p><strong>然后尝试使用 hdfs 命令上传文件<mark>在hadoop目录下的bin目录里运行</mark></strong></p> 
<pre><code>hdfs dfs -put &lt;自己需要上传的文件的地址&gt; /path/to/hdfs/directory/
</code></pre> 
<p>** 如果在上传过程中出现“ls: `.': No such file or directory”如何处理？**<br> == 这个错误提示表明目标路径 /path/to/hdfs/directory/ 不存在。你需要确保该路径是正确的，并且在 HDFS 中已经存在。==</p> 
<p>==如果该路径不存在，可以使用 hdfs dfs -mkdir 命令创建该路径。例如，以下命令可以在 HDFS 中创建一个名为 /path/to/hdfs/directory 的目录 ==</p> 
<pre><code>hdfs dfs -mkdir -p /path/to/hdfs/directory
</code></pre> 
<p>如何在进行上传即可</p> 
<h3><a id="_98"></a>如何下载？</h3> 
<p>要从 HDFS 下载文件，可以使用 hdfs dfs -get 命令。该命令的语法如下</p> 
<pre><code>hdfs dfs -get &lt;需要下载文件的目录&gt; &lt;下载到的目录&gt;
</code></pre> 
<p><mark>可能会出现的问题，实例：“get: `/path/to/hdfs/directory/123/321/556.txt’: No such file or directory”应该如何解决</mark><br> ** 这个错误提示表明 HDFS 中的目标文件路径不存在。可能原因是你指定的路径不正确，或者文件在上传过程中出现了错误。**</p> 
<p>**你可以通过运行 hdfs dfs -ls 命令来检查目标路径是否存在，并查看路径下的文件列表。例如，以下命令可以列出 <mark>/path/to/hdfs/directory/</mark> 目录下的所有文件 **</p> 
<pre><code> hdfs dfs -ls /path/to/hdfs/directory/
</code></pre> 
<p><mark>/path/to/hdfs/directory/是我个人的文件目录，各位根据自身情况进行更改</mark></p> 
<p>over！over！over！关注走起！！！！</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/a4a0653fbbea08487332e5d14e8cd0e0/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【密码学】使用mkcert安装CA、自签名ssl证书，配置nginx的https 证书笔记</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/ed69a0598bba99d1e6939149df0a0295/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">如何在Windows中的Rabbitmq如何启动</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>