<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>数据湖Iceberg介绍和使用(集成Hive、SparkSQL、FlinkSQL) - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/04e13a0ef90ea69c6fbb95e37f73aab8/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="数据湖Iceberg介绍和使用(集成Hive、SparkSQL、FlinkSQL)">
  <meta property="og:description" content="文章目录 简介概述作用特性数据存储、计算引擎插件化实时流批一体数据表演化（Table Evolution）模式演化（Schema Evolution）分区演化（Partition Evolution）列顺序演化（Sort Order Evolution）隐藏分区（Hidden Partition）镜像数据查询（Time Travel）支持事务（ACID）基于乐观锁的并发支持文件级数据剪裁 其他数据湖框架的对比 存储结构数据文件 data files表快照 Snapshot清单列表 Manifest list清单文件 Manifest file 与 Hive集成环境准备创建和管理 Catalog默认使用 HiveCatalog指定 Catalog 类型指定路径加载 基本操作创建表修改表插入表删除表 与 Spark SQL集成环境准备Spark 配置 CatalogHive CatalogHadoop Catalog SQL 操作创建表删除表修改表插入数据查询数据存储过程 DataFrame 操作环境准备读取表检查表写入表维护表 与 Flink SQL 集成环境准备创建和使用 Catalog语法说明Hive CatalogHadoop Catalog配置sql-client初始化文件 DDL 语句创建数据库创建表修改表删除表 插入语句INSERT INTOINSERT OVERWRITEUPSERT 查询语句Batch模式Streaming模式 与Flink集成的不足 与 Flink DataStream 集成环境准备读取数据常规Source写法FLIP-27 Source写法 写入数据合并小文件 简介 概述 为了解决数据存储和计算引擎之间的适配的问题，Netflix开发了Iceberg，2018年11月16日进入Apache孵化器，2020 年5月19日从孵化器毕业，成为Apache的顶级项目。
Iceberg是一个面向海量数据分析场景的开放表格式（Table Format）。表格式（Table Format）可以理解为元数据以及数据文件的一种组织方式，处于计算框架（Flink，Spark…）之下，数据文件之上。
作用 大数据领域发展至今已经经历了相当长时间的发展和探索，虽然大数据技术的出现和迭代降低了用户处理海量数据的门槛，但是有一个问题不能忽视，数据格式对不同引擎适配的对接。
也就是说我们在使用不同的引擎进行计算时，需要将数据根据引擎进行适配。这是相当棘手的问题。
为此出现了一种新的解决方案：介于上层计算引擎和底层存储格式之间的一个中间层。这个中间层不是数据存储的方式，只是定义了数据的元数据组织方式，并且向引擎层面提供统一的类似传统数据库中&#34;表&#34;的语义。它的底层仍然是Parquet、ORC等存储格式。基于此，Netflix开发了Iceberg，目前已经是Apache的顶级项目。
特性 数据存储、计算引擎插件化 Iceberg提供一个开放通用的表格式（Table Format）实现方案，不和特定的数据存储、计算引擎绑定。目前大数据领域的常见数据存储（HDFS、S3…），计算引擎（Flink、Spark…）都可以接入Iceberg。">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2023-07-01T10:51:27+08:00">
    <meta property="article:modified_time" content="2023-07-01T10:51:27+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">数据湖Iceberg介绍和使用(集成Hive、SparkSQL、FlinkSQL)</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-tomorrow-night">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><ul><li><a href="#_1" rel="nofollow">简介</a></li><li><ul><li><a href="#_3" rel="nofollow">概述</a></li><li><a href="#_11" rel="nofollow">作用</a></li><li><a href="#_21" rel="nofollow">特性</a></li><li><ul><li><a href="#_23" rel="nofollow">数据存储、计算引擎插件化</a></li><li><a href="#_29" rel="nofollow">实时流批一体</a></li><li><a href="#Table_Evolution_33" rel="nofollow">数据表演化（Table Evolution）</a></li><li><a href="#Schema_Evolution_39" rel="nofollow">模式演化（Schema Evolution）</a></li><li><a href="#Partition_Evolution_67" rel="nofollow">分区演化（Partition Evolution）</a></li><li><a href="#Sort_Order_Evolution_83" rel="nofollow">列顺序演化（Sort Order Evolution）</a></li><li><a href="#Hidden_Partition_87" rel="nofollow">隐藏分区（Hidden Partition）</a></li><li><a href="#Time_Travel_93" rel="nofollow">镜像数据查询（Time Travel）</a></li><li><a href="#ACID_97" rel="nofollow">支持事务（ACID）</a></li><li><a href="#_101" rel="nofollow">基于乐观锁的并发支持</a></li><li><a href="#_105" rel="nofollow">文件级数据剪裁</a></li></ul> 
    </li><li><a href="#_111" rel="nofollow">其他数据湖框架的对比</a></li></ul> 
   </li><li><a href="#_119" rel="nofollow">存储结构</a></li><li><ul><li><a href="#_data_files_129" rel="nofollow">数据文件 data files</a></li><li><a href="#_Snapshot_139" rel="nofollow">表快照 Snapshot</a></li><li><a href="#_Manifest_list_145" rel="nofollow">清单列表 Manifest list</a></li><li><a href="#_Manifest_file_153" rel="nofollow">清单文件 Manifest file</a></li></ul> 
   </li><li><a href="#_Hive_161" rel="nofollow">与 Hive集成</a></li><li><ul><li><a href="#_163" rel="nofollow">环境准备</a></li><li><a href="#_Catalog_234" rel="nofollow">创建和管理 Catalog</a></li><li><ul><li><a href="#_HiveCatalog_252" rel="nofollow">默认使用 HiveCatalog</a></li><li><a href="#_Catalog__264" rel="nofollow">指定 Catalog 类型</a></li><li><a href="#_297" rel="nofollow">指定路径加载</a></li></ul> 
    </li><li><a href="#_310" rel="nofollow">基本操作</a></li><li><ul><li><a href="#_312" rel="nofollow">创建表</a></li><li><a href="#_346" rel="nofollow">修改表</a></li><li><a href="#_356" rel="nofollow">插入表</a></li><li><a href="#_369" rel="nofollow">删除表</a></li></ul> 
   </li></ul> 
   </li><li><a href="#_Spark_SQL_377" rel="nofollow">与 Spark SQL集成</a></li><li><ul><li><a href="#_379" rel="nofollow">环境准备</a></li><li><a href="#Spark__Catalog_421" rel="nofollow">Spark 配置 Catalog</a></li><li><ul><li><a href="#Hive_Catalog_431" rel="nofollow">Hive Catalog</a></li><li><a href="#Hadoop_Catalog_443" rel="nofollow">Hadoop Catalog</a></li></ul> 
    </li><li><a href="#SQL__455" rel="nofollow">SQL 操作</a></li><li><ul><li><a href="#_457" rel="nofollow">创建表</a></li><li><a href="#_570" rel="nofollow">删除表</a></li><li><a href="#_613" rel="nofollow">修改表</a></li><li><a href="#_836" rel="nofollow">插入数据</a></li><li><a href="#_870" rel="nofollow">查询数据</a></li><li><a href="#_898" rel="nofollow">存储过程</a></li></ul> 
    </li><li><a href="#DataFrame__1031" rel="nofollow">DataFrame 操作</a></li><li><ul><li><a href="#_1033" rel="nofollow">环境准备</a></li><li><a href="#_1160" rel="nofollow">读取表</a></li><li><a href="#_1214" rel="nofollow">检查表</a></li><li><a href="#_1234" rel="nofollow">写入表</a></li><li><a href="#_1285" rel="nofollow">维护表</a></li></ul> 
   </li></ul> 
   </li><li><a href="#_Flink_SQL__1375" rel="nofollow">与 Flink SQL 集成</a></li><li><ul><li><a href="#_1379" rel="nofollow">环境准备</a></li><li><a href="#_Catalog_1464" rel="nofollow">创建和使用 Catalog</a></li><li><ul><li><a href="#_1466" rel="nofollow">语法说明</a></li><li><a href="#Hive_Catalog_1487" rel="nofollow">Hive Catalog</a></li><li><a href="#Hadoop_Catalog_1532" rel="nofollow">Hadoop Catalog</a></li><li><a href="#sqlclient_1551" rel="nofollow">配置sql-client初始化文件</a></li></ul> 
    </li><li><a href="#DDL__1574" rel="nofollow">DDL 语句</a></li><li><ul><li><a href="#_1576" rel="nofollow">创建数据库</a></li><li><a href="#_1585" rel="nofollow">创建表</a></li><li><a href="#_1630" rel="nofollow">修改表</a></li><li><a href="#_1646" rel="nofollow">删除表</a></li></ul> 
    </li><li><a href="#_1654" rel="nofollow">插入语句</a></li><li><ul><li><a href="#INSERT_INTO_1656" rel="nofollow">INSERT INTO</a></li><li><a href="#INSERT_OVERWRITE_1665" rel="nofollow">INSERT OVERWRITE</a></li><li><a href="#UPSERT_1677" rel="nofollow">UPSERT</a></li></ul> 
    </li><li><a href="#_1727" rel="nofollow">查询语句</a></li><li><ul><li><a href="#Batch_1731" rel="nofollow">Batch模式</a></li><li><a href="#Streaming_1738" rel="nofollow">Streaming模式</a></li></ul> 
    </li><li><a href="#Flink_1766" rel="nofollow">与Flink集成的不足</a></li></ul> 
   </li><li><a href="#_Flink_DataStream__1797" rel="nofollow">与 Flink DataStream 集成</a></li><li><ul><li><a href="#_1799" rel="nofollow">环境准备</a></li><li><a href="#_1976" rel="nofollow">读取数据</a></li><li><ul><li><a href="#Source_1978" rel="nofollow">常规Source写法</a></li><li><a href="#FLIP27_Source_2021" rel="nofollow">FLIP-27 Source写法</a></li></ul> 
    </li><li><a href="#_2078" rel="nofollow">写入数据</a></li><li><a href="#_2140" rel="nofollow">合并小文件</a></li></ul> 
  </li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h3><a id="_1"></a>简介</h3> 
<h4><a id="_3"></a>概述</h4> 
<p>为了解决数据存储和计算引擎之间的适配的问题，Netflix开发了Iceberg，2018年11月16日进入Apache孵化器，2020 年5月19日从孵化器毕业，成为Apache的顶级项目。</p> 
<p>Iceberg是一个面向海量数据分析场景的<strong>开放表格式（Table Format）</strong>。表格式（Table Format）可以理解为<strong>元数据以及数据文件的一种组织方式，处于计算框架（Flink，Spark…）之下，数据文件之上</strong>。</p> 
<h4><a id="_11"></a>作用</h4> 
<p>大数据领域发展至今已经经历了相当长时间的发展和探索，虽然大数据技术的出现和迭代降低了用户处理海量数据的门槛，但是有一个问题不能忽视，数据格式对不同引擎适配的对接。</p> 
<p>也就是说我们在使用不同的引擎进行计算时，需要将数据根据引擎进行适配。这是相当棘手的问题。</p> 
<p>为此出现了一种新的解决方案：介于上层计算引擎和底层存储格式之间的一个中间层。这个中间层不是数据存储的方式，只是定义了数据的元数据组织方式，并且向引擎层面提供统一的类似传统数据库中"表"的语义。它的底层仍然是Parquet、ORC等存储格式。基于此，Netflix开发了Iceberg，目前已经是Apache的顶级项目。</p> 
<h4><a id="_21"></a>特性</h4> 
<h5><a id="_23"></a>数据存储、计算引擎插件化</h5> 
<p>Iceberg提供一个开放通用的表格式（Table Format）实现方案，不和特定的数据存储、计算引擎绑定。目前大数据领域的常见数据存储（HDFS、S3…），计算引擎（Flink、Spark…）都可以接入Iceberg。</p> 
<p>在生产环境中，可选择不同的组件搭使用。甚至可以不通过计算引擎，直接读取存在文件系统上的数据。</p> 
<h5><a id="_29"></a>实时流批一体</h5> 
<p>Iceberg上游组件将数据写入完成后，下游组件及时可读，可查询。可以满足实时场景。并且Iceberg同时提供了流/批读接口、流/批写接口。可以在同一个流程里, 同时处理流数据和批数据，大大简化了ETL链路。</p> 
<h5><a id="Table_Evolution_33"></a>数据表演化（Table Evolution）</h5> 
<p>Iceberg可以通过SQL的方式进行表级别模式演进。进行这些操作的时候，代价极低。 不存在读出数据重新写入或者迁移数据这种费时费力的操作。</p> 
<p>比如在常用的Hive中，如果我们需要把一个按天分区的表，改成按小时分区。此时，不能再原表之上直接修改，只能新建一个按小时分区的表，然后再把数据Insert到新的小时分区表。而且，即使我们通过Rename的命令把新表的名字改为原表，使用原表的上次层应用, 也可能由于分区字段修改，导致需要修改 SQL，这样花费的经历是非常繁琐的。</p> 
<h5><a id="Schema_Evolution_39"></a>模式演化（Schema Evolution）</h5> 
<p>Iceberg支持下面几种模式演化：</p> 
<ul><li> <p>ADD：向表或者嵌套结构增加新列</p> </li><li> <p>Drop：从表中或者嵌套结构中移除一列</p> </li><li> <p>Rename：重命名表中或者嵌套结构中的一列</p> </li><li> <p>Update：将复杂结构(struct, map&lt;key, value&gt;, list)中的基本类型扩展类型长度, 比如tinyint修改成int.</p> </li><li> <p>Reorder：改变列或者嵌套结构中字段的排列顺序</p> </li></ul> 
<p>Iceberg保证模式演化（Schema Evolution）是没有副作用的独立操作流程, 一个元数据操作, 不会涉及到重写数据文件的过程。具体的如下:</p> 
<ul><li> <p>增加列时候，不会从另外一个列中读取已存在的的数据</p> </li><li> <p>删除列或者嵌套结构中字段的时候，不会改变任何其他列的值</p> </li><li> <p>更新列或者嵌套结构中字段的时候，不会改变任何其他列的值</p> </li><li> <p>改变列列或者嵌套结构中字段顺序的时候，不会改变相关联的值</p> </li></ul> 
<p>在表中Iceberg 使用唯一ID来定位每一列的信息。新增一个列的时候,会新分配给它一个唯一ID, 并且绝对不会使用已经被使用的ID。</p> 
<p>使用名称或者位置信息来定位列的, 都会存在一些问题, 比如使用名称的话,名称可能会重复, 使用位置的话, 不能修改顺序并且废弃的字段也不能删除。</p> 
<h5><a id="Partition_Evolution_67"></a>分区演化（Partition Evolution）</h5> 
<p>Iceberg可以在一个已存在的表上直接修改，因为Iceberg的查询流程并不和分区信息直接关联。</p> 
<p>当我们改变一个表的分区策略时，对应修改分区之前的数据不会改变, 依然会采用老的分区策略，新的数据会采用新的分区策略，也就是说同一个表会有两种分区策略，旧数据采用旧分区策略，新数据采用新新分区策略, 在元数据里两个分区策略相互独立，不重合。</p> 
<p>在查询数据的时候，如果存在跨分区策略的情况，则会解析成两个不同执行计划，如Iceberg官网提供图所示：</p> 
<p><img src="https://images2.imgbox.com/92/a1/b2vCn3aG_o.png" alt="MMSIZE"></p> 
<p>图中booking_table表2008年按月分区，进入2009年后改为按天分区，这种中分区策略共存于该表中。</p> 
<p>借助Iceberg的隐藏分区（Hidden Partition），在写SQL 查询的时候，不需要在SQL中特别指定分区过滤条件，Iceberg会自动分区，过滤掉不需要的数据。</p> 
<p>Iceberg分区演化操作同样是一个元数据操作, 不会重写数据文件。</p> 
<h5><a id="Sort_Order_Evolution_83"></a>列顺序演化（Sort Order Evolution）</h5> 
<p>Iceberg可以在一个已经存在的表上修改排序策略。修改了排序策略之后, 旧数据依旧采用老排序策略不变。往Iceberg里写数据的计算引擎总是会选择最新的排序策略, 但是当排序的代价极其高昂的时候, 就不进行排序了。</p> 
<h5><a id="Hidden_Partition_87"></a>隐藏分区（Hidden Partition）</h5> 
<p>Iceberg的分区信息并不需要人工维护, 它可以被隐藏起来. 不同其他类似Hive 的分区策略, Iceberg的分区字段/策略（通过某一个字段计算出来），可以不是表的字段和表数据存储目录也没有关系。在建表或者修改分区策略之后，新的数据会自动计算所属于的分区。在查询的时候同样不用关系表的分区是什么字段/策略，只需要关注业务逻辑，Iceberg会自动过滤不需要的分区数据。</p> 
<p>正是由于Iceberg的分区信息和表数据存储目录是独立的，使得Iceberg的表分区可以被修改,而且不和涉及到数据迁移。</p> 
<h5><a id="Time_Travel_93"></a>镜像数据查询（Time Travel）</h5> 
<p>Iceberg提供了查询表历史某一时间点数据镜像（snapshot）的能力。通过该特性可以将最新的SQL逻辑，应用到历史数据上。</p> 
<h5><a id="ACID_97"></a>支持事务（ACID）</h5> 
<p>Iceberg通过提供事务（ACID）的机制，使其具备了upsert的能力并且使得边写边读成为可能，从而数据可以更快的被下游组件消费。通过事务保证了下游组件只能消费已commit的数据，而不会读到部分甚至未提交的数据。</p> 
<h5><a id="_101"></a>基于乐观锁的并发支持</h5> 
<p>Iceberg基于乐观锁提供了多个程序并发写入的能力并且保证数据线性一致。</p> 
<h5><a id="_105"></a>文件级数据剪裁</h5> 
<p>Iceberg的元数据里面提供了每个数据文件的一些统计信息，比如最大值，最小值，Count计数等等。因此，查询SQL的过滤条件除了常规的分区，列过滤，甚至可以下推到文件级别，大大加快了查询效率。</p> 
<h4><a id="_111"></a>其他数据湖框架的对比</h4> 
<p><img src="https://images2.imgbox.com/cd/c0/70o6pk9r_o.png" alt="MMSIZE"></p> 
<p><img src="https://images2.imgbox.com/8a/d8/htNX9EWm_o.png" alt="MMSIZE"></p> 
<h3><a id="_119"></a>存储结构</h3> 
<p><img src="https://images2.imgbox.com/e9/e4/L8R7jYsw_o.png" alt="MMSIZE"></p> 
<p><img src="https://images2.imgbox.com/0b/39/v0RyDDeS_o.png" alt="MMSIZE"></p> 
<h4><a id="_data_files_129"></a>数据文件 data files</h4> 
<p>数据文件是Apache Iceberg表真实存储数据的文件，一般是在表的数据存储目录的data目录下，如果我们的文件格式选择的是parquet,那么文件是以“.parquet”结尾。</p> 
<p>例如：00000-0-atguigu_20230203160458_22ee74c9-643f-4b27-8fc1-9cbd5f64dad4-job_1675409881387_0007-00001.parquet 就是一个数据文件。</p> 
<p>Iceberg每次更新会产生多个数据文件（data files）。</p> 
<h4><a id="_Snapshot_139"></a>表快照 Snapshot</h4> 
<p>快照代表一张表在某个时刻的状态。每个快照里面会列出表在某个时刻的所有 data files 列表。data files是存储在不同的manifest files里面，manifest files是存储在一个Manifest list文件里面，而一个Manifest list文件代表一个快照。</p> 
<h4><a id="_Manifest_list_145"></a>清单列表 Manifest list</h4> 
<p>manifest list是一个元数据文件，它列出构建表快照（Snapshot）的清单（Manifest file）。这个元数据文件中存储的是Manifest file列表，每个Manifest file占据一行。每行中存储了Manifest file的路径、其存储的数据文件（data files）的分区范围，增加了几个数文件、删除了几个数据文件等信息，这些信息可以用来在查询时提供过滤，加快速度。</p> 
<p>例如：snap-6746266566064388720-1-52f2f477-2585-4e69-be42-bbad9a46ed17.avro就是一个Manifest List文件。</p> 
<h4><a id="_Manifest_file_153"></a>清单文件 Manifest file</h4> 
<p>Manifest file也是一个元数据文件，它列出组成快照（snapshot）的数据文件（data files）的列表信息。每行都是每个数据文件的详细描述，包括数据文件的状态、文件路径、分区信息、列级别的统计信息（比如每列的最大最小值、空值数等）、文件的大小以及文件里面数据行数等信息。其中列级别的统计信息可以在扫描表数据时过滤掉不必要的文件。</p> 
<p>Manifest file是以avro格式进行存储的，以“.avro”后缀结尾，例如：52f2f477-2585-4e69-be42-bbad9a46ed17-m0.avro。</p> 
<h3><a id="_Hive_161"></a>与 Hive集成</h3> 
<h4><a id="_163"></a>环境准备</h4> 
<p><strong>（1）Hive与Iceberg的版本对应关系如下</strong></p> 
<table><thead><tr><th>Hive 版本</th><th>官方推荐Hive版本</th><th>Iceberg 版本</th></tr></thead><tbody><tr><td>2.x</td><td>2.3.8</td><td>0.8.0-incubating – 1.1.0</td></tr><tr><td>3.x</td><td>3.1.2</td><td>0.10.0 – 1.1.0</td></tr></tbody></table> 
<p>Iceberg与Hive 2和Hive 3.1.2/3的集成，支持以下特性：</p> 
<ul><li> <p>创建表</p> </li><li> <p>删除表</p> </li><li> <p>读取表</p> </li><li> <p>插入表（INSERT into）</p> </li></ul> 
<blockquote> 
 <p>更多功能需要Hive 4.x（目前alpha版本）才能支持。</p> 
</blockquote> 
<p><strong>（2）上传jar包，拷贝到Hive的auxlib目录中</strong></p> 
<pre><code class="prism language-bash"><span class="token function">mkdir</span> auxlib
<span class="token function">cp</span> iceberg-hive-runtime-1.1.0.jar /opt/module/hive/auxlib
<span class="token function">cp</span> libfb303-0.9.3.jar /opt/module/hive/auxlibcp iceberg-hive-runtime-1.1.0.jar /opt/module/hive/auxlibcp libfb303-0.9.3.jar /opt/module/hive/auxlib
</code></pre> 
<p><strong>（3）修改hive-site.xml，添加配置项</strong></p> 
<pre><code class="prism language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>iceberg.engine.hive.enabled<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>true<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>hive.aux.jars.path<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>/opt/module/hive/auxlib<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
</code></pre> 
<p>使用TEZ引擎注意事项：</p> 
<ul><li> <p>使用Hive版本&gt;=3.1.2，需要TEZ版本&gt;=0.10.1</p> </li><li> <p>指定tez更新配置：</p> <pre><code class="prism language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>tez.mrreader.config.update.properties<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>hive.io.file.readcolumn.names,hive.io.file.readcolumn.ids<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
</code></pre> </li><li> <p>从Iceberg 0.11.0开始，如果Hive使用Tez引擎，需要关闭向量化执行：</p> <pre><code class="prism language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>hive.vectorized.execution.enabled<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>false<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
</code></pre> </li></ul> 
<p><strong>（4）启动HMS服务</strong></p> 
<p><strong>（5）启动 Hadoop</strong></p> 
<h4><a id="_Catalog_234"></a>创建和管理 Catalog</h4> 
<p>Iceberg支持多种不同的Catalog类型，例如:Hive、Hadoop、亚马逊的AWS Glue和自定义Catalog。</p> 
<p>根据不同配置，分为三种情况：</p> 
<ul><li>没有设置iceberg.catalog，默认使用HiveCatalog</li></ul> 
<table><thead><tr><th>配置项</th><th>说明</th></tr></thead><tbody><tr><td>iceberg.catalog.&lt;catalog_name&gt;.type</td><td>Catalog的类型: hive, hadoop, 如果使用自定义Catalog，则不设置</td></tr><tr><td>iceberg.catalog.&lt;catalog_name&gt;.catalog-impl</td><td>Catalog的实现类, 如果上面的type没有设置，则此参数必须设置</td></tr><tr><td>iceberg.catalog.&lt;catalog_name&gt;.&lt;key&gt;</td><td>Catalog的其他配置项</td></tr></tbody></table> 
<ul><li> <p>设置了 iceberg.catalog的类型，使用指定的Catalog类型，如下表格：</p> </li><li> <p>设置 iceberg.catalog=location_based_table，直接通过指定的根路径来加载Iceberg表</p> </li></ul> 
<h5><a id="_HiveCatalog_252"></a>默认使用 HiveCatalog</h5> 
<pre><code class="prism language-bash">CREATE TABLE iceberg_test1 <span class="token punctuation">(</span>i int<span class="token punctuation">)</span> STORED BY <span class="token string">'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler'</span><span class="token punctuation">;</span>
 
INSERT INTO iceberg_test1 values<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>查看HDFS可以发现，表目录在默认的hive仓库路径下。</p> 
<h5><a id="_Catalog__264"></a>指定 Catalog 类型</h5> 
<p><strong>（1）使用 HiveCatalog</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> iceberg<span class="token punctuation">.</span>catalog<span class="token punctuation">.</span>iceberg_hive<span class="token punctuation">.</span><span class="token keyword">type</span><span class="token operator">=</span>hive<span class="token punctuation">;</span>
<span class="token keyword">set</span> iceberg<span class="token punctuation">.</span>catalog<span class="token punctuation">.</span>iceberg_hive<span class="token punctuation">.</span>uri<span class="token operator">=</span>thrift:<span class="token comment">//hadoop1:9083;</span>
<span class="token keyword">set</span> iceberg<span class="token punctuation">.</span>catalog<span class="token punctuation">.</span>iceberg_hive<span class="token punctuation">.</span>clients<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">;</span>
<span class="token keyword">set</span> iceberg<span class="token punctuation">.</span>catalog<span class="token punctuation">.</span>iceberg_hive<span class="token punctuation">.</span>warehouse<span class="token operator">=</span>hdfs:<span class="token comment">//hadoop1:8020/warehouse/iceberg-hive;</span>

<span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> iceberg_test2 <span class="token punctuation">(</span>i <span class="token keyword">int</span><span class="token punctuation">)</span> 
STORED <span class="token keyword">BY</span> <span class="token string">'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler'</span>
TBLPROPERTIES<span class="token punctuation">(</span><span class="token string">'iceberg.catalog'</span><span class="token operator">=</span><span class="token string">'iceberg_hive'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
 
<span class="token keyword">INSERT</span> <span class="token keyword">INTO</span> iceberg_test2 <span class="token keyword">values</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p><strong>（2）使用 HadoopCatalog</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> iceberg<span class="token punctuation">.</span>catalog<span class="token punctuation">.</span>iceberg_hadoop<span class="token punctuation">.</span><span class="token keyword">type</span><span class="token operator">=</span>hadoop<span class="token punctuation">;</span>
<span class="token keyword">set</span> iceberg<span class="token punctuation">.</span>catalog<span class="token punctuation">.</span>iceberg_hadoop<span class="token punctuation">.</span>warehouse<span class="token operator">=</span>hdfs:<span class="token comment">//hadoop1:8020/warehouse/iceberg-hadoop;</span>

<span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> iceberg_test3 <span class="token punctuation">(</span>i <span class="token keyword">int</span><span class="token punctuation">)</span> 
STORED <span class="token keyword">BY</span> <span class="token string">'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler'</span> 
LOCATION <span class="token string">'hdfs://hadoop1:8020/warehouse/iceberg-hadoop/default/iceberg_test3'</span>
TBLPROPERTIES<span class="token punctuation">(</span><span class="token string">'iceberg.catalog'</span><span class="token operator">=</span><span class="token string">'iceberg_hadoop'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token keyword">INSERT</span> <span class="token keyword">INTO</span> iceberg_test3 <span class="token keyword">values</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<h5><a id="_297"></a>指定路径加载</h5> 
<p>如果HDFS中已经存在iceberg格式表，我们可以通过在Hive中创建Icerberg格式表指定对应的location路径映射数据。</p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> EXTERNAL <span class="token keyword">TABLE</span> iceberg_test4 <span class="token punctuation">(</span>i <span class="token keyword">int</span><span class="token punctuation">)</span>
STORED <span class="token keyword">BY</span> <span class="token string">'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler'</span>
LOCATION <span class="token string">'hdfs://hadoop1:8020/warehouse/iceberg-hadoop/default/iceberg_test3'</span>
TBLPROPERTIES <span class="token punctuation">(</span><span class="token string">'iceberg.catalog'</span><span class="token operator">=</span><span class="token string">'location_based_table'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<h4><a id="_310"></a>基本操作</h4> 
<h5><a id="_312"></a>创建表</h5> 
<p><strong>（1）创建外部表</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> EXTERNAL <span class="token keyword">TABLE</span> iceberg_create1 <span class="token punctuation">(</span>i <span class="token keyword">int</span><span class="token punctuation">)</span> 
STORED <span class="token keyword">BY</span> <span class="token string">'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler'</span><span class="token punctuation">;</span>

<span class="token keyword">describe</span> formatted iceberg_create1<span class="token punctuation">;</span>
</code></pre> 
<p><strong>（2）创建内部表</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> iceberg_create2 <span class="token punctuation">(</span>i <span class="token keyword">int</span><span class="token punctuation">)</span> 
STORED <span class="token keyword">BY</span> <span class="token string">'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler'</span><span class="token punctuation">;</span>

<span class="token keyword">describe</span> formatted iceberg_create2<span class="token punctuation">;</span>
</code></pre> 
<p><strong>（3）创建分区表</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> EXTERNAL <span class="token keyword">TABLE</span> iceberg_create3 <span class="token punctuation">(</span>id <span class="token keyword">int</span><span class="token punctuation">,</span>name string<span class="token punctuation">)</span>
PARTITIONED <span class="token keyword">BY</span> <span class="token punctuation">(</span>age <span class="token keyword">int</span><span class="token punctuation">)</span>
STORED <span class="token keyword">BY</span> <span class="token string">'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler'</span><span class="token punctuation">;</span>

<span class="token keyword">describe</span> formatted iceberg_create3<span class="token punctuation">;</span>
</code></pre> 
<p>Hive语法创建分区表，不会在HMS中创建分区，而是将分区数据转换为Iceberg标识分区。这种情况下不能使用Iceberg的分区转换，例如：days(timestamp)，如果想要使用Iceberg格式表的分区转换标识分区，需要使用Spark或者Flink引擎创建表。</p> 
<h5><a id="_346"></a>修改表</h5> 
<p>只支持HiveCatalog表修改表属性，Iceberg表属性和Hive表属性存储在HMS中是同步的。</p> 
<pre><code class="prism language-bash">ALTER TABLE iceberg_create1 SET TBLPROPERTIES<span class="token punctuation">(</span><span class="token string">'external.table.purge'</span><span class="token operator">=</span><span class="token string">'FALSE'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<h5><a id="_356"></a>插入表</h5> 
<p>支持标准单表INSERT INTO操作：</p> 
<pre><code class="prism language-bash">INSERT INTO iceberg_create2 VALUES <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
INSERT INTO iceberg_create1 <span class="token keyword">select</span> * from iceberg_create2<span class="token punctuation">;</span>
</code></pre> 
<p>在HIVE 3.x中，INSERT OVERWRITE虽然能执行，但其实是追加。</p> 
<h5><a id="_369"></a>删除表</h5> 
<pre><code class="prism language-sql"><span class="token keyword">DROP</span> <span class="token keyword">TABLE</span> iceberg_create1<span class="token punctuation">;</span>
</code></pre> 
<h3><a id="_Spark_SQL_377"></a>与 Spark SQL集成</h3> 
<h4><a id="_379"></a>环境准备</h4> 
<p><strong>（1）安装 Spark</strong></p> 
<p><strong>1）Spark与Iceberg的版本对应关系如下</strong></p> 
<table><thead><tr><th>Spark 版本</th><th>Iceberg 版本</th></tr></thead><tbody><tr><td>2.4</td><td>0.7.0-incubating – 1.1.0</td></tr><tr><td>3.0</td><td>0.9.0 – 1.0.0</td></tr><tr><td>3.1</td><td>0.12.0 – 1.1.0</td></tr><tr><td>3.2</td><td>0.13.0 – 1.1.0</td></tr><tr><td>3.3</td><td>0.14.0 – 1.1.0</td></tr></tbody></table> 
<p><strong>2）上传并解压Spark安装包</strong></p> 
<pre><code class="prism language-bash"><span class="token function">tar</span> -zxvf spark-3.3.1-bin-hadoop3.tgz -C /opt/module/
<span class="token function">mv</span> /opt/module/spark-3.3.1-bin-hadoop3 /opt/module/spark-3.3.1
</code></pre> 
<p><strong>3）配置环境变量</strong></p> 
<pre><code class="prism language-bash"><span class="token function">sudo</span> <span class="token function">vim</span> /etc/profile.d/my_env.sh

<span class="token builtin class-name">export</span> <span class="token assign-left variable">SPARK_HOME</span><span class="token operator">=</span>/opt/module/spark-3.3.1
<span class="token builtin class-name">export</span> <span class="token assign-left variable"><span class="token environment constant">PATH</span></span><span class="token operator">=</span><span class="token environment constant">$PATH</span><span class="token builtin class-name">:</span><span class="token variable">$SPARK_HOME</span>/bin

<span class="token builtin class-name">source</span> /etc/profile.d/my_env.sh
</code></pre> 
<p><strong>4）拷贝iceberg的jar包到Spark的jars目录</strong></p> 
<pre><code class="prism language-bash"><span class="token function">cp</span> /opt/software/iceberg/iceberg-spark-runtime-3.3_2.12-1.1.0.jar /opt/module/spark-3.3.1/jars
</code></pre> 
<p><strong>（2）启动 Hadoop</strong></p> 
<h4><a id="Spark__Catalog_421"></a>Spark 配置 Catalog</h4> 
<p>Spark中支持两种Catalog的设置：hive和hadoop，Hive Catalog就是Iceberg表存储使用Hive默认的数据路径，Hadoop Catalog需要指定Iceberg格式表存储路径。</p> 
<pre><code class="prism language-bash"><span class="token function">vim</span> spark-defaults.conf
</code></pre> 
<h5><a id="Hive_Catalog_431"></a>Hive Catalog</h5> 
<pre><code class="prism language-bash">spark.sql.catalog.hive_prod <span class="token operator">=</span> org.apache.iceberg.spark.SparkCatalog
spark.sql.catalog.hive_prod.type <span class="token operator">=</span> hive
spark.sql.catalog.hive_prod.uri <span class="token operator">=</span> thrift://hadoop1:9083

use hive_prod.db<span class="token punctuation">;</span>
</code></pre> 
<h5><a id="Hadoop_Catalog_443"></a>Hadoop Catalog</h5> 
<pre><code class="prism language-bash">spark.sql.catalog.hadoop_prod <span class="token operator">=</span> org.apache.iceberg.spark.SparkCatalog
spark.sql.catalog.hadoop_prod.type <span class="token operator">=</span> hadoop
spark.sql.catalog.hadoop_prod.warehouse <span class="token operator">=</span> hdfs://hadoop1:8020/warehouse/spark-iceberg

use hadoop_prod.db<span class="token punctuation">;</span>
</code></pre> 
<h4><a id="SQL__455"></a>SQL 操作</h4> 
<h5><a id="_457"></a>创建表</h5> 
<pre><code class="prism language-sql"><span class="token keyword">use</span> hadoop_prod<span class="token punctuation">;</span>
<span class="token keyword">create</span> <span class="token keyword">database</span> <span class="token keyword">default</span><span class="token punctuation">;</span>
<span class="token keyword">use</span> <span class="token keyword">default</span><span class="token punctuation">;</span>

<span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample1 <span class="token punctuation">(</span>
    id <span class="token keyword">bigint</span> <span class="token keyword">COMMENT</span> <span class="token string">'unique id'</span><span class="token punctuation">,</span>
    <span class="token keyword">data</span> string<span class="token punctuation">)</span>
<span class="token keyword">USING</span> iceberg
</code></pre> 
<ul><li> <p>PARTITIONED BY (partition-expressions) ：配置分区</p> </li><li> <p>LOCATION ‘(fully-qualified-uri)’ ：指定表路径</p> </li><li> <p>COMMENT ‘table documentation’ ：配置表备注</p> </li><li> <p>TBLPROPERTIES (‘key’=‘value’, …) ：配置表属性</p> </li></ul> 
<p>表属性：<a href="https://iceberg.apache.org/docs/latest/configuration/" rel="nofollow">https://iceberg.apache.org/docs/latest/configuration/</a></p> 
<p>对Iceberg表的每次更改都会生成一个新的元数据文件（json文件）以提供原子性。默认情况下，旧元数据文件作为历史文件保存不会删除。</p> 
<p>如果要自动清除元数据文件，在表属性中设置write.metadata.delete-after-commit.enabled=true。这将保留一些元数据文件（直到write.metadata.previous-versions-max），并在每个新创建的元数据文件之后删除旧的元数据文件。</p> 
<p><strong>（1）创建分区表</strong></p> 
<p>1）分区表</p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample2 <span class="token punctuation">(</span>
    id <span class="token keyword">bigint</span><span class="token punctuation">,</span>
    <span class="token keyword">data</span> string<span class="token punctuation">,</span>
    category string<span class="token punctuation">)</span>
<span class="token keyword">USING</span> iceberg
PARTITIONED <span class="token keyword">BY</span> <span class="token punctuation">(</span>category<span class="token punctuation">)</span>
</code></pre> 
<p>2）创建隐藏分区表</p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample3 <span class="token punctuation">(</span>
    id <span class="token keyword">bigint</span><span class="token punctuation">,</span>
    <span class="token keyword">data</span> string<span class="token punctuation">,</span>
    category string<span class="token punctuation">,</span>
    ts <span class="token keyword">timestamp</span><span class="token punctuation">)</span>
<span class="token keyword">USING</span> iceberg
PARTITIONED <span class="token keyword">BY</span> <span class="token punctuation">(</span>bucket<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> id<span class="token punctuation">)</span><span class="token punctuation">,</span> days<span class="token punctuation">(</span>ts<span class="token punctuation">)</span><span class="token punctuation">,</span> category<span class="token punctuation">)</span>
</code></pre> 
<p>支持的转换有:</p> 
<ul><li> <p>years(ts):按年划分</p> </li><li> <p>months(ts):按月划分</p> </li><li> <p>days(ts)或date(ts):等效于dateint分区</p> </li><li> <p>hours(ts)或date_hour(ts):等效于dateint和hour分区</p> </li><li> <p>bucket(N, col):按哈希值划分mod N个桶</p> </li><li> <p>truncate(L, col):按截断为L的值划分</p> </li></ul> 
<p>字符串被截断为给定的长度</p> 
<p>整型和长型截断为bin: truncate(10, i)生成分区0,10,20,30，…</p> 
<p><strong>（2）使用 CTAS 语法建表</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample4
<span class="token keyword">USING</span> iceberg
<span class="token keyword">AS</span> <span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">from</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample3
</code></pre> 
<p>不指定分区就是无分区，需要重新指定分区、表属性：</p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample5
<span class="token keyword">USING</span> iceberg
PARTITIONED <span class="token keyword">BY</span> <span class="token punctuation">(</span>bucket<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span> id<span class="token punctuation">)</span><span class="token punctuation">,</span> hours<span class="token punctuation">(</span>ts<span class="token punctuation">)</span><span class="token punctuation">,</span> category<span class="token punctuation">)</span>
TBLPROPERTIES <span class="token punctuation">(</span><span class="token string">'key'</span><span class="token operator">=</span><span class="token string">'value'</span><span class="token punctuation">)</span>
<span class="token keyword">AS</span> <span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">from</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample3
</code></pre> 
<p><strong>（3）使用 Replace table 建表</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">REPLACE</span> <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample5
<span class="token keyword">USING</span> iceberg
<span class="token keyword">AS</span> <span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">from</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample3

<span class="token keyword">REPLACE</span> <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample5
<span class="token keyword">USING</span> iceberg
PARTITIONED <span class="token keyword">BY</span> <span class="token punctuation">(</span>part<span class="token punctuation">)</span>
TBLPROPERTIES <span class="token punctuation">(</span><span class="token string">'key'</span><span class="token operator">=</span><span class="token string">'value'</span><span class="token punctuation">)</span>
<span class="token keyword">AS</span> <span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">from</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample3


<span class="token keyword">CREATE</span> <span class="token operator">OR</span> <span class="token keyword">REPLACE</span> <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample6
<span class="token keyword">USING</span> iceberg
<span class="token keyword">AS</span> <span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">from</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample3
</code></pre> 
<h5><a id="_570"></a>删除表</h5> 
<p>对于HadoopCatalog而言，运行DROP TABLE将从catalog中删除表并删除表内容。</p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> EXTERNAL <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample7 <span class="token punctuation">(</span>
    id <span class="token keyword">bigint</span> <span class="token keyword">COMMENT</span> <span class="token string">'unique id'</span><span class="token punctuation">,</span>
    <span class="token keyword">data</span> string<span class="token punctuation">)</span>
<span class="token keyword">USING</span> iceberg

<span class="token keyword">INSERT</span> <span class="token keyword">INTO</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample7 <span class="token keyword">values</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token string">'a'</span><span class="token punctuation">)</span>
<span class="token keyword">DROP</span> <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample7
</code></pre> 
<p>对于HiveCatalog而言：</p> 
<ul><li> <p>在0.14之前，运行DROP TABLE将从catalog中删除表并删除表内容。</p> </li><li> <p>从0.14开始，DROP TABLE只会从catalog中删除表，不会删除数据。为了删除表内容，应该使用DROP table PURGE。</p> </li></ul> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> hive_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample7 <span class="token punctuation">(</span>
    id <span class="token keyword">bigint</span> <span class="token keyword">COMMENT</span> <span class="token string">'unique id'</span><span class="token punctuation">,</span>
    <span class="token keyword">data</span> string<span class="token punctuation">)</span>
<span class="token keyword">USING</span> iceberg

<span class="token keyword">INSERT</span> <span class="token keyword">INTO</span> hive_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample7 <span class="token keyword">values</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token string">'a'</span><span class="token punctuation">)</span>
</code></pre> 
<p><strong>（1）删除表</strong></p> 
<pre><code class="prism language-bash">DROP TABLE hive_prod.default.sample7
</code></pre> 
<p><strong>（2）删除表和数据</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">DROP</span> <span class="token keyword">TABLE</span> hive_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample7 <span class="token keyword">PURGE</span>
</code></pre> 
<h5><a id="_613"></a>修改表</h5> 
<p>Iceberg在Spark 3中完全支持ALTER TABLE，包括:</p> 
<ul><li> <p>重命名表</p> </li><li> <p>设置或删除表属性</p> </li><li> <p>添加、删除和重命名列</p> </li><li> <p>添加、删除和重命名嵌套字段</p> </li><li> <p>重新排序顶级列和嵌套结构字段</p> </li><li> <p>扩大int、float和decimal字段的类型</p> </li><li> <p>将必选列变为可选列</p> </li></ul> 
<p>此外，还可以使用SQL扩展来添加对分区演变的支持和设置表的写顺序。</p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> hive_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample1 <span class="token punctuation">(</span>
    id <span class="token keyword">bigint</span> <span class="token keyword">COMMENT</span> <span class="token string">'unique id'</span><span class="token punctuation">,</span>
    <span class="token keyword">data</span> string<span class="token punctuation">)</span>
<span class="token keyword">USING</span> iceberg
</code></pre> 
<p><strong>（1）修改表名（不支持修改HadoopCatalog的表名）</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> hive_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample1 <span class="token keyword">RENAME</span> <span class="token keyword">TO</span> hive_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample2
</code></pre> 
<p><strong>（2）修改表属性</strong></p> 
<ul><li> <p>修改表属性</p> <pre><code class="prism language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> hive_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample1 <span class="token keyword">SET</span> TBLPROPERTIES <span class="token punctuation">(</span>
    <span class="token string">'read.split.target-size'</span><span class="token operator">=</span><span class="token string">'268435456'</span>
<span class="token punctuation">)</span>

<span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> hive_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample1 <span class="token keyword">SET</span> TBLPROPERTIES <span class="token punctuation">(</span>
    <span class="token string">'comment'</span> <span class="token operator">=</span> <span class="token string">'A table comment.'</span>
<span class="token punctuation">)</span>
</code></pre> </li><li> <p>删除表属性</p> <pre><code class="prism language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> hive_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample1 UNSET TBLPROPERTIES <span class="token punctuation">(</span><span class="token string">'read.split.target-size'</span><span class="token punctuation">)</span>
</code></pre> </li></ul> 
<p><strong>（3）添加列</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample1
<span class="token keyword">ADD</span> <span class="token keyword">COLUMNS</span> <span class="token punctuation">(</span>
    category string <span class="token keyword">comment</span> <span class="token string">'new_column'</span>
<span class="token punctuation">)</span>

<span class="token comment">-- 添加struct类型的列</span>
<span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample1
<span class="token keyword">ADD</span> <span class="token keyword">COLUMN</span> <span class="token keyword">point</span> struct<span class="token operator">&lt;</span>x: <span class="token keyword">double</span><span class="token punctuation">,</span> y: <span class="token keyword">double</span><span class="token operator">&gt;</span><span class="token punctuation">;</span>

<span class="token comment">-- 往struct类型的列中添加字段</span>
<span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample1
<span class="token keyword">ADD</span> <span class="token keyword">COLUMN</span> <span class="token keyword">point</span><span class="token punctuation">.</span>z <span class="token keyword">double</span>

<span class="token comment">-- 创建struct的嵌套数组列</span>
<span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample1
<span class="token keyword">ADD</span> <span class="token keyword">COLUMN</span> points array<span class="token operator">&lt;</span>struct<span class="token operator">&lt;</span>x: <span class="token keyword">double</span><span class="token punctuation">,</span> y: <span class="token keyword">double</span><span class="token operator">&gt;&gt;</span><span class="token punctuation">;</span>

<span class="token comment">-- 在数组中的结构中添加一个字段。使用关键字'element'访问数组的元素列。</span>
<span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample1
<span class="token keyword">ADD</span> <span class="token keyword">COLUMN</span> points<span class="token punctuation">.</span>element<span class="token punctuation">.</span>z <span class="token keyword">double</span>

<span class="token comment">-- 创建一个包含Map类型的列，key和value都为struct类型</span>
<span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample1
<span class="token keyword">ADD</span> <span class="token keyword">COLUMN</span> pointsm map<span class="token operator">&lt;</span>struct<span class="token operator">&lt;</span>x: <span class="token keyword">int</span><span class="token operator">&gt;</span><span class="token punctuation">,</span> struct<span class="token operator">&lt;</span>a: <span class="token keyword">int</span><span class="token operator">&gt;&gt;</span><span class="token punctuation">;</span>

<span class="token comment">-- 在Map类型的value的struct中添加一个字段。</span>
<span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample1
<span class="token keyword">ADD</span> <span class="token keyword">COLUMN</span> pointsm<span class="token punctuation">.</span><span class="token keyword">value</span><span class="token punctuation">.</span>b <span class="token keyword">int</span>
</code></pre> 
<p>在Spark 2.4.4及以后版本中，可以通过添加FIRST或AFTER子句在任何位置添加列:</p> 
<pre><code class="prism language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample1
<span class="token keyword">ADD</span> <span class="token keyword">COLUMN</span> new_column1 <span class="token keyword">bigint</span> <span class="token keyword">AFTER</span> id

<span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample1
<span class="token keyword">ADD</span> <span class="token keyword">COLUMN</span> new_column2 <span class="token keyword">bigint</span> <span class="token keyword">FIRST</span>
</code></pre> 
<p><strong>（4）修改列</strong></p> 
<ul><li> <p>修改列名</p> <pre><code class="prism language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample1 <span class="token keyword">RENAME</span> <span class="token keyword">COLUMN</span> <span class="token keyword">data</span> <span class="token keyword">TO</span> data1
</code></pre> </li><li> <p>Alter Column修改类型（只允许安全的转换）</p> <pre><code class="prism language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample1
<span class="token keyword">ADD</span> <span class="token keyword">COLUMNS</span> <span class="token punctuation">(</span>
    idd <span class="token keyword">int</span>
  <span class="token punctuation">)</span>
<span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample1 <span class="token keyword">ALTER</span> <span class="token keyword">COLUMN</span> idd <span class="token keyword">TYPE</span> <span class="token keyword">bigint</span>
</code></pre> </li><li> <p>Alter Column 修改列的注释</p> <pre><code class="prism language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample1 <span class="token keyword">ALTER</span> <span class="token keyword">COLUMN</span> id <span class="token keyword">TYPE</span> <span class="token keyword">double</span> <span class="token keyword">COMMENT</span> <span class="token string">'a'</span>
<span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample1 <span class="token keyword">ALTER</span> <span class="token keyword">COLUMN</span> id <span class="token keyword">COMMENT</span> <span class="token string">'b'</span>
</code></pre> </li><li> <p>Alter Column修改列的顺序</p> <pre><code class="prism language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample1 <span class="token keyword">ALTER</span> <span class="token keyword">COLUMN</span> id <span class="token keyword">FIRST</span>
<span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample1 <span class="token keyword">ALTER</span> <span class="token keyword">COLUMN</span> new_column2 <span class="token keyword">AFTER</span> new_column1
</code></pre> </li><li> <p>Alter Column修改列是否允许为null</p> <pre><code class="prism language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample1 <span class="token keyword">ALTER</span> <span class="token keyword">COLUMN</span> id <span class="token keyword">DROP</span> <span class="token operator">NOT</span> <span class="token boolean">NULL</span>
</code></pre> <p>ALTER COLUMN不用于更新struct类型。使用ADD COLUMN和DROP COLUMN添加或删除struct类型的字段。</p> </li></ul> 
<p><strong>（5）删除列</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample1 <span class="token keyword">DROP</span> <span class="token keyword">COLUMN</span> idd
<span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample1 <span class="token keyword">DROP</span> <span class="token keyword">COLUMN</span> <span class="token keyword">point</span><span class="token punctuation">.</span>z
</code></pre> 
<p><strong>（6）添加分区（Spark3，需要配置扩展）</strong></p> 
<pre><code class="prism language-sql">vim spark<span class="token operator">-</span><span class="token keyword">default</span><span class="token punctuation">.</span>conf
spark<span class="token punctuation">.</span><span class="token keyword">sql</span><span class="token punctuation">.</span>extensions <span class="token operator">=</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>iceberg<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>extensions<span class="token punctuation">.</span>IcebergSparkSessionExtensions
</code></pre> 
<p>重新进入spark-sql shell：</p> 
<pre><code class="prism language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample1 <span class="token keyword">ADD</span> <span class="token keyword">PARTITION</span> FIELD category 

<span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample1 <span class="token keyword">ADD</span> <span class="token keyword">PARTITION</span> FIELD bucket<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> id<span class="token punctuation">)</span>
<span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample1 <span class="token keyword">ADD</span> <span class="token keyword">PARTITION</span> FIELD <span class="token keyword">truncate</span><span class="token punctuation">(</span><span class="token keyword">data</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
<span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample1 <span class="token keyword">ADD</span> <span class="token keyword">PARTITION</span> FIELD years<span class="token punctuation">(</span>ts<span class="token punctuation">)</span>

<span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample1 <span class="token keyword">ADD</span> <span class="token keyword">PARTITION</span> FIELD bucket<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> id<span class="token punctuation">)</span> <span class="token keyword">AS</span> shard
</code></pre> 
<p><strong>（7）删除分区（Spark3，需要配置扩展）</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample1 <span class="token keyword">DROP</span> <span class="token keyword">PARTITION</span> FIELD category
<span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample1 <span class="token keyword">DROP</span> <span class="token keyword">PARTITION</span> FIELD bucket<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> id<span class="token punctuation">)</span>
<span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample1 <span class="token keyword">DROP</span> <span class="token keyword">PARTITION</span> FIELD <span class="token keyword">truncate</span><span class="token punctuation">(</span><span class="token keyword">data</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
<span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample1 <span class="token keyword">DROP</span> <span class="token keyword">PARTITION</span> FIELD years<span class="token punctuation">(</span>ts<span class="token punctuation">)</span>
<span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample1 <span class="token keyword">DROP</span> <span class="token keyword">PARTITION</span> FIELD shard
</code></pre> 
<p>注意，尽管删除了分区，但列仍然存在于表结构中。</p> 
<p>删除分区字段是元数据操作，不会改变任何现有的表数据。新数据将被写入新的分区，但现有数据将保留在旧的分区布局中。</p> 
<p>当分区发生变化时，动态分区覆盖行为也会发生变化。例如，如果按天划分分区，而改为按小时划分分区，那么覆盖将覆盖每小时划分的分区，而不再覆盖按天划分的分区。</p> 
<p>删除分区字段时要小心，可能导致元数据查询失败或产生不同的结果。</p> 
<p><strong>（8）修改分区（Spark3，需要配置扩展）</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample1 <span class="token keyword">REPLACE</span> <span class="token keyword">PARTITION</span> FIELD bucket<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> id<span class="token punctuation">)</span> <span class="token keyword">WITH</span> bucket<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span> id<span class="token punctuation">)</span>
</code></pre> 
<p><strong>（9）修改表的写入顺序</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample1 <span class="token keyword">WRITE</span> ORDERED <span class="token keyword">BY</span> category<span class="token punctuation">,</span> id
<span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample1 <span class="token keyword">WRITE</span> ORDERED <span class="token keyword">BY</span> category <span class="token keyword">ASC</span><span class="token punctuation">,</span> id <span class="token keyword">DESC</span>
<span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample1 <span class="token keyword">WRITE</span> ORDERED <span class="token keyword">BY</span> category <span class="token keyword">ASC</span> NULLS <span class="token keyword">LAST</span><span class="token punctuation">,</span> id <span class="token keyword">DESC</span> NULLS <span class="token keyword">FIRST</span>
</code></pre> 
<p>表写顺序不能保证查询的数据顺序。它只影响数据写入表的方式。</p> 
<p>WRITE ORDERED BY设置了一个全局排序，即跨任务的行排序，就像在INSERT命令中使用ORDER BY一样:</p> 
<pre><code class="prism language-sql"><span class="token keyword">INSERT</span> <span class="token keyword">INTO</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample1
<span class="token keyword">SELECT</span> id<span class="token punctuation">,</span> <span class="token keyword">data</span><span class="token punctuation">,</span> category<span class="token punctuation">,</span> ts <span class="token keyword">FROM</span> another_table
<span class="token keyword">ORDER</span> <span class="token keyword">BY</span> ts<span class="token punctuation">,</span> category
</code></pre> 
<p>要在每个任务内排序，而不是跨任务排序，使用local ORDERED BY:</p> 
<pre><code class="prism language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample1 <span class="token keyword">WRITE</span> LOCALLY ORDERED <span class="token keyword">BY</span> category<span class="token punctuation">,</span> id
</code></pre> 
<p><strong>（10）按分区并行写入</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample1 <span class="token keyword">WRITE</span> <span class="token keyword">DISTRIBUTED</span> <span class="token keyword">BY</span> <span class="token keyword">PARTITION</span>
<span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>sample1 <span class="token keyword">WRITE</span> <span class="token keyword">DISTRIBUTED</span> <span class="token keyword">BY</span> <span class="token keyword">PARTITION</span> LOCALLY ORDERED <span class="token keyword">BY</span> category<span class="token punctuation">,</span> id
</code></pre> 
<h5><a id="_836"></a>插入数据</h5> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>a <span class="token punctuation">(</span>
    id <span class="token keyword">bigint</span><span class="token punctuation">,</span>
    count <span class="token keyword">bigint</span><span class="token punctuation">)</span>
<span class="token keyword">USING</span> iceberg

<span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>b <span class="token punctuation">(</span>
    id <span class="token keyword">bigint</span><span class="token punctuation">,</span>
    count <span class="token keyword">bigint</span><span class="token punctuation">,</span>
    flag string<span class="token punctuation">)</span>
<span class="token keyword">USING</span> iceberg
</code></pre> 
<p><strong>（1）Insert Into</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">INSERT</span> <span class="token keyword">INTO</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>a <span class="token keyword">VALUES</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">INSERT</span> <span class="token keyword">INTO</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>b <span class="token keyword">VALUES</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token string">'d'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p><strong>（2）MERGE INTO行级更新</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">MERGE</span> <span class="token keyword">INTO</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>a t 
<span class="token keyword">USING</span> <span class="token punctuation">(</span><span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>b<span class="token punctuation">)</span> u <span class="token keyword">ON</span> t<span class="token punctuation">.</span>id <span class="token operator">=</span> u<span class="token punctuation">.</span>id
<span class="token keyword">WHEN</span> <span class="token keyword">MATCHED</span> <span class="token operator">AND</span> u<span class="token punctuation">.</span>flag<span class="token operator">=</span><span class="token string">'b'</span> <span class="token keyword">THEN</span> <span class="token keyword">UPDATE</span> <span class="token keyword">SET</span> t<span class="token punctuation">.</span>count <span class="token operator">=</span> t<span class="token punctuation">.</span>count <span class="token operator">+</span> u<span class="token punctuation">.</span>count
<span class="token keyword">WHEN</span> <span class="token keyword">MATCHED</span> <span class="token operator">AND</span> u<span class="token punctuation">.</span>flag<span class="token operator">=</span><span class="token string">'a'</span> <span class="token keyword">THEN</span> <span class="token keyword">DELETE</span>
<span class="token keyword">WHEN</span> <span class="token operator">NOT</span> <span class="token keyword">MATCHED</span> <span class="token keyword">THEN</span> <span class="token keyword">INSERT</span> <span class="token punctuation">(</span>id<span class="token punctuation">,</span>count<span class="token punctuation">)</span> <span class="token keyword">values</span> <span class="token punctuation">(</span>u<span class="token punctuation">.</span>id<span class="token punctuation">,</span>u<span class="token punctuation">.</span>count<span class="token punctuation">)</span>
</code></pre> 
<h5><a id="_870"></a>查询数据</h5> 
<p><strong>（1）普通查询</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">SELECT</span> <span class="token function">count</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token keyword">as</span> count<span class="token punctuation">,</span> <span class="token keyword">data</span>
<span class="token keyword">FROM</span> <span class="token keyword">local</span><span class="token punctuation">.</span>db<span class="token punctuation">.</span><span class="token keyword">table</span>
<span class="token keyword">GROUP</span> <span class="token keyword">BY</span> <span class="token keyword">data</span>
</code></pre> 
<p><strong>（2）查询元数据</strong></p> 
<pre><code class="prism language-sql"><span class="token comment">// 查询表快照</span>
<span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>a<span class="token punctuation">.</span>snapshots

<span class="token comment">// 查询数据文件信息</span>
<span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>a<span class="token punctuation">.</span>files

<span class="token comment">// 查询表历史</span>
<span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>a<span class="token punctuation">.</span>history

<span class="token comment">// 查询 manifest</span>
ELECT <span class="token operator">*</span> <span class="token keyword">FROM</span> hadoop_prod<span class="token punctuation">.</span><span class="token keyword">default</span><span class="token punctuation">.</span>a<span class="token punctuation">.</span>manifests
</code></pre> 
<h5><a id="_898"></a>存储过程</h5> 
<p>Procedures可以通过CALL从任何已配置的Iceberg Catalog中使用。所有Procedures都在namespace中。</p> 
<p>（1）<strong>语法</strong></p> 
<p>按照参数名传参</p> 
<pre><code class="prism language-sql"><span class="token keyword">CALL</span> catalog_name<span class="token punctuation">.</span>system<span class="token punctuation">.</span>procedure_name<span class="token punctuation">(</span>arg_name_2 <span class="token operator">=</span><span class="token operator">&gt;</span> arg_2<span class="token punctuation">,</span> arg_name_1 <span class="token operator">=</span><span class="token operator">&gt;</span> arg_1<span class="token punctuation">)</span>
</code></pre> 
<p>当按位置传递参数时，如果结束参数是可选的，则只有结束参数可以省略。</p> 
<pre><code class="prism language-sql"><span class="token keyword">CALL</span> catalog_name<span class="token punctuation">.</span>system<span class="token punctuation">.</span>procedure_name<span class="token punctuation">(</span>arg_1<span class="token punctuation">,</span> arg_2<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> arg_n<span class="token punctuation">)</span>
</code></pre> 
<p><strong>（2）快照管理</strong></p> 
<ul><li> <p>回滚到指定的快照id</p> <pre><code class="prism language-sql"><span class="token keyword">CALL</span> hadoop_prod<span class="token punctuation">.</span>system<span class="token punctuation">.</span>rollback_to_snapshot<span class="token punctuation">(</span><span class="token string">'default.a'</span><span class="token punctuation">,</span> <span class="token number">7601163594701794741</span><span class="token punctuation">)</span>
</code></pre> </li><li> <p>回滚到指定时间的快照</p> <pre><code class="prism language-sql"><span class="token keyword">CALL</span> hadoop_prod<span class="token punctuation">.</span>system<span class="token punctuation">.</span>rollback_to_timestamp<span class="token punctuation">(</span><span class="token string">'db.sample'</span><span class="token punctuation">,</span> <span class="token keyword">TIMESTAMP</span> <span class="token string">'2021-06-30 00:00:00.000'</span><span class="token punctuation">)</span>
</code></pre> </li><li> <p>设置表的当前快照ID</p> <pre><code class="prism language-sql"><span class="token keyword">CALL</span> hadoop_prod<span class="token punctuation">.</span>system<span class="token punctuation">.</span>set_current_snapshot<span class="token punctuation">(</span><span class="token string">'db.sample'</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
</code></pre> </li><li> <p>从快照变为当前表状态</p> <pre><code class="prism language-sql"><span class="token keyword">CALL</span> hadoop_prod<span class="token punctuation">.</span>system<span class="token punctuation">.</span>cherrypick_snapshot<span class="token punctuation">(</span><span class="token string">'default.a'</span><span class="token punctuation">,</span> <span class="token number">7629160535368763452</span><span class="token punctuation">)</span>
<span class="token keyword">CALL</span> hadoop_prod<span class="token punctuation">.</span>system<span class="token punctuation">.</span>cherrypick_snapshot<span class="token punctuation">(</span>snapshot_id <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token number">7629160535368763452</span><span class="token punctuation">,</span> <span class="token keyword">table</span> <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token string">'default.a'</span> <span class="token punctuation">)</span>
</code></pre> </li></ul> 
<p><strong>（3）元数据管理</strong></p> 
<ul><li> <p>删除早于指定日期和时间的快照，但保留最近100个快照：</p> <pre><code class="prism language-sql"><span class="token keyword">CALL</span> hive_prod<span class="token punctuation">.</span>system<span class="token punctuation">.</span>expire_snapshots<span class="token punctuation">(</span><span class="token string">'db.sample'</span><span class="token punctuation">,</span> <span class="token keyword">TIMESTAMP</span> <span class="token string">'2021-06-30 00:00:00.000'</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span>
</code></pre> </li><li> <p>删除Iceberg表中任何元数据文件中没有引用的文件</p> <pre><code class="prism language-sql"><span class="token comment">#列出所有需要删除的候选文件</span>
<span class="token keyword">CALL</span> catalog_name<span class="token punctuation">.</span>system<span class="token punctuation">.</span>remove_orphan_files<span class="token punctuation">(</span><span class="token keyword">table</span> <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token string">'db.sample'</span><span class="token punctuation">,</span> dry_run <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token boolean">true</span><span class="token punctuation">)</span>
<span class="token comment">#删除指定目录中db.sample表不知道的任何文件</span>
<span class="token keyword">CALL</span> catalog_name<span class="token punctuation">.</span>system<span class="token punctuation">.</span>remove_orphan_files<span class="token punctuation">(</span><span class="token keyword">table</span> <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token string">'db.sample'</span><span class="token punctuation">,</span> location <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token string">'tablelocation/data'</span><span class="token punctuation">)</span>
</code></pre> </li><li> <p>合并数据文件（合并小文件）</p> <pre><code class="prism language-sql"><span class="token keyword">CALL</span> catalog_name<span class="token punctuation">.</span>system<span class="token punctuation">.</span>rewrite_data_files<span class="token punctuation">(</span><span class="token string">'db.sample'</span><span class="token punctuation">)</span>
<span class="token keyword">CALL</span> catalog_name<span class="token punctuation">.</span>system<span class="token punctuation">.</span>rewrite_data_files<span class="token punctuation">(</span><span class="token keyword">table</span> <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token string">'db.sample'</span><span class="token punctuation">,</span> strategy <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token string">'sort'</span><span class="token punctuation">,</span> sort_order <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token string">'id DESC NULLS LAST,name ASC NULLS FIRST'</span><span class="token punctuation">)</span>
<span class="token keyword">CALL</span> catalog_name<span class="token punctuation">.</span>system<span class="token punctuation">.</span>rewrite_data_files<span class="token punctuation">(</span><span class="token keyword">table</span> <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token string">'db.sample'</span><span class="token punctuation">,</span> strategy <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token string">'sort'</span><span class="token punctuation">,</span> sort_order <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token string">'zorder(c1,c2)'</span><span class="token punctuation">)</span>
<span class="token keyword">CALL</span> catalog_name<span class="token punctuation">.</span>system<span class="token punctuation">.</span>rewrite_data_files<span class="token punctuation">(</span><span class="token keyword">table</span> <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token string">'db.sample'</span><span class="token punctuation">,</span> options <span class="token operator">=</span><span class="token operator">&gt;</span> map<span class="token punctuation">(</span><span class="token string">'min-input-files'</span><span class="token punctuation">,</span><span class="token string">'2'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">CALL</span> catalog_name<span class="token punctuation">.</span>system<span class="token punctuation">.</span>rewrite_data_files<span class="token punctuation">(</span><span class="token keyword">table</span> <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token string">'db.sample'</span><span class="token punctuation">,</span> <span class="token keyword">where</span> <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token string">'id = 3 and name = "foo"'</span><span class="token punctuation">)</span>
</code></pre> </li><li> <p>重写表清单来优化执行计划</p> <pre><code class="prism language-sql"><span class="token keyword">CALL</span> catalog_name<span class="token punctuation">.</span>system<span class="token punctuation">.</span>rewrite_manifests<span class="token punctuation">(</span><span class="token string">'db.sample'</span><span class="token punctuation">)</span>

<span class="token comment">#重写表db中的清单。并禁用Spark缓存的使用。这样做可以避免执行程序上的内存问题。</span>
<span class="token keyword">CALL</span> catalog_name<span class="token punctuation">.</span>system<span class="token punctuation">.</span>rewrite_manifests<span class="token punctuation">(</span><span class="token string">'db.sample'</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span>
</code></pre> </li></ul> 
<p><strong>（4）迁移表</strong></p> 
<ul><li> <p>快照</p> <pre><code class="prism language-sql"><span class="token keyword">CALL</span> catalog_name<span class="token punctuation">.</span>system<span class="token punctuation">.</span><span class="token keyword">snapshot</span><span class="token punctuation">(</span><span class="token string">'db.sample'</span><span class="token punctuation">,</span> <span class="token string">'db.snap'</span><span class="token punctuation">)</span>
<span class="token keyword">CALL</span> catalog_name<span class="token punctuation">.</span>system<span class="token punctuation">.</span><span class="token keyword">snapshot</span><span class="token punctuation">(</span><span class="token string">'db.sample'</span><span class="token punctuation">,</span> <span class="token string">'db.snap'</span><span class="token punctuation">,</span> <span class="token string">'/tmp/temptable/'</span><span class="token punctuation">)</span>
</code></pre> </li><li> <p>迁移</p> <pre><code class="prism language-sql"><span class="token keyword">CALL</span> catalog_name<span class="token punctuation">.</span>system<span class="token punctuation">.</span>migrate<span class="token punctuation">(</span><span class="token string">'spark_catalog.db.sample'</span><span class="token punctuation">,</span> map<span class="token punctuation">(</span><span class="token string">'foo'</span><span class="token punctuation">,</span> <span class="token string">'bar'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">CALL</span> catalog_name<span class="token punctuation">.</span>system<span class="token punctuation">.</span>migrate<span class="token punctuation">(</span><span class="token string">'db.sample'</span><span class="token punctuation">)</span>
</code></pre> </li><li> <p>添加数据文件</p> <pre><code class="prism language-sql"><span class="token keyword">CALL</span> spark_catalog<span class="token punctuation">.</span>system<span class="token punctuation">.</span>add_files<span class="token punctuation">(</span>
    <span class="token keyword">table</span> <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token string">'db.tbl'</span><span class="token punctuation">,</span>
    source_table <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token string">'db.src_tbl'</span><span class="token punctuation">,</span>
    partition_filter <span class="token operator">=</span><span class="token operator">&gt;</span> map<span class="token punctuation">(</span><span class="token string">'part_col_1'</span><span class="token punctuation">,</span> <span class="token string">'A'</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span>

<span class="token keyword">CALL</span> spark_catalog<span class="token punctuation">.</span>system<span class="token punctuation">.</span>add_files<span class="token punctuation">(</span>
    <span class="token keyword">table</span> <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token string">'db.tbl'</span><span class="token punctuation">,</span>
    source_table <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token string">'`parquet`.`path/to/table`'</span>
<span class="token punctuation">)</span>
</code></pre> </li></ul> 
<p><strong>（5）元数据信息</strong></p> 
<ul><li> <p>获取指定快照的父快照id</p> <pre><code class="prism language-sql"><span class="token keyword">CALL</span> spark_catalog<span class="token punctuation">.</span>system<span class="token punctuation">.</span>ancestors_of<span class="token punctuation">(</span><span class="token string">'db.tbl'</span><span class="token punctuation">)</span>
</code></pre> </li><li> <p>获取指定快照的所有祖先快照</p> <pre><code class="prism language-sql"><span class="token keyword">CALL</span> spark_catalog<span class="token punctuation">.</span>system<span class="token punctuation">.</span>ancestors_of<span class="token punctuation">(</span><span class="token string">'db.tbl'</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">CALL</span> spark_catalog<span class="token punctuation">.</span>system<span class="token punctuation">.</span>ancestors_of<span class="token punctuation">(</span>snapshot_id <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token keyword">table</span> <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token string">'db.tbl'</span><span class="token punctuation">)</span>
</code></pre> </li></ul> 
<h4><a id="DataFrame__1031"></a>DataFrame 操作</h4> 
<h5><a id="_1033"></a>环境准备</h5> 
<p><strong>（1）创建maven工程，配置pom文件</strong></p> 
<pre><code class="prism language-xml"><span class="token prolog">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>project</span> <span class="token attr-name">xmlns</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>http://maven.apache.org/POM/4.0.0<span class="token punctuation">"</span></span>
         <span class="token attr-name"><span class="token namespace">xmlns:</span>xsi</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>http://www.w3.org/2001/XMLSchema-instance<span class="token punctuation">"</span></span>
         <span class="token attr-name"><span class="token namespace">xsi:</span>schemaLocation</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>modelVersion</span><span class="token punctuation">&gt;</span></span>4.0.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>modelVersion</span><span class="token punctuation">&gt;</span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>com.atguigu.iceberg<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>spark-iceberg-demo<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>1.0-SNAPSHOT<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>properties</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>scala.binary.version</span><span class="token punctuation">&gt;</span></span>2.12<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>scala.binary.version</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>spark.version</span><span class="token punctuation">&gt;</span></span>3.3.1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>spark.version</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>maven.compiler.source</span><span class="token punctuation">&gt;</span></span>8<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>maven.compiler.source</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>maven.compiler.target</span><span class="token punctuation">&gt;</span></span>8<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>maven.compiler.target</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>properties</span><span class="token punctuation">&gt;</span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependencies</span><span class="token punctuation">&gt;</span></span>
        <span class="token comment">&lt;!-- Spark的依赖引入 --&gt;</span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.spark<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>spark-core_${scala.binary.version}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>scope</span><span class="token punctuation">&gt;</span></span>provided<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>scope</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>${spark.version}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.spark<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>spark-sql_${scala.binary.version}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>scope</span><span class="token punctuation">&gt;</span></span>provided<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>scope</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>${spark.version}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.spark<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>spark-hive_${scala.binary.version}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>scope</span><span class="token punctuation">&gt;</span></span>provided<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>scope</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>${spark.version}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>

        <span class="token comment">&lt;!--fastjson &lt;= 1.2.80 存在安全漏洞,--&gt;</span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>com.alibaba<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>fastjson<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>1.2.83<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>


        <span class="token comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.iceberg/iceberg-spark-runtime-3.3 --&gt;</span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.iceberg<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>iceberg-spark-runtime-3.3_2.12<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>1.1.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>


    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependencies</span><span class="token punctuation">&gt;</span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>build</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugins</span><span class="token punctuation">&gt;</span></span>
            <span class="token comment">&lt;!-- assembly打包插件 --&gt;</span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugin</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.maven.plugins<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>maven-assembly-plugin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>3.0.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>executions</span><span class="token punctuation">&gt;</span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>execution</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>id</span><span class="token punctuation">&gt;</span></span>make-assembly<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>id</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>phase</span><span class="token punctuation">&gt;</span></span>package<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>phase</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goals</span><span class="token punctuation">&gt;</span></span>
                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goal</span><span class="token punctuation">&gt;</span></span>single<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goal</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goals</span><span class="token punctuation">&gt;</span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>execution</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>executions</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">&gt;</span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>archive</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>manifest</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>manifest</span><span class="token punctuation">&gt;</span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>archive</span><span class="token punctuation">&gt;</span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>descriptorRefs</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>descriptorRef</span><span class="token punctuation">&gt;</span></span>jar-with-dependencies<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>descriptorRef</span><span class="token punctuation">&gt;</span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>descriptorRefs</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugin</span><span class="token punctuation">&gt;</span></span>

            <span class="token comment">&lt;!--Maven编译scala所需依赖--&gt;</span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugin</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>net.alchim31.maven<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>scala-maven-plugin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>3.2.2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>executions</span><span class="token punctuation">&gt;</span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>execution</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goals</span><span class="token punctuation">&gt;</span></span>
                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goal</span><span class="token punctuation">&gt;</span></span>compile<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goal</span><span class="token punctuation">&gt;</span></span>
                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goal</span><span class="token punctuation">&gt;</span></span>testCompile<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goal</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goals</span><span class="token punctuation">&gt;</span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>execution</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>executions</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugin</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugins</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>build</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>project</span><span class="token punctuation">&gt;</span></span>
</code></pre> 
<p><strong>（2）配置Catalog</strong></p> 
<pre><code class="prism language-sql">val spark: SparkSession <span class="token operator">=</span> SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>master<span class="token punctuation">(</span><span class="token string">"local"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>appName<span class="token punctuation">(</span>this<span class="token punctuation">.</span>getClass<span class="token punctuation">.</span>getSimpleName<span class="token punctuation">)</span>
  <span class="token comment">//指定hive catalog, catalog名称为iceberg_hive</span>
  <span class="token punctuation">.</span>config<span class="token punctuation">(</span><span class="token string">"spark.sql.catalog.iceberg_hive"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.iceberg.spark.SparkCatalog"</span><span class="token punctuation">)</span>
  <span class="token punctuation">.</span>config<span class="token punctuation">(</span><span class="token string">"spark.sql.catalog.iceberg_hive.type"</span><span class="token punctuation">,</span> <span class="token string">"hive"</span><span class="token punctuation">)</span>
  <span class="token punctuation">.</span>config<span class="token punctuation">(</span><span class="token string">"spark.sql.catalog.iceberg_hive.uri"</span><span class="token punctuation">,</span> <span class="token string">"thrift://hadoop1:9083"</span><span class="token punctuation">)</span>
  <span class="token comment">//    .config("iceberg.engine.hive.enabled", "true")</span>
  <span class="token comment">//指定hadoop catalog，catalog名称为iceberg_hadoop </span>
  <span class="token punctuation">.</span>config<span class="token punctuation">(</span><span class="token string">"spark.sql.catalog.iceberg_hadoop"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.iceberg.spark.SparkCatalog"</span><span class="token punctuation">)</span>
  <span class="token punctuation">.</span>config<span class="token punctuation">(</span><span class="token string">"spark.sql.catalog.iceberg_hadoop.type"</span><span class="token punctuation">,</span> <span class="token string">"hadoop"</span><span class="token punctuation">)</span>
  <span class="token punctuation">.</span>config<span class="token punctuation">(</span><span class="token string">"spark.sql.catalog.iceberg_hadoop.warehouse"</span><span class="token punctuation">,</span> <span class="token string">"hdfs://hadoop1:8020/warehouse/spark-iceberg"</span><span class="token punctuation">)</span>
  <span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<h5><a id="_1160"></a>读取表</h5> 
<p><strong>（1）加载表</strong></p> 
<pre><code class="prism language-scala">spark<span class="token punctuation">.</span>read
<span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">"iceberg"</span><span class="token punctuation">)</span>
<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"hdfs://hadoop1:8020/warehouse/spark-iceberg/default/a"</span><span class="token punctuation">)</span>
<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p><strong>或</strong></p> 
<pre><code class="prism language-sql"><span class="token comment">// 仅支持Spark3.0以上</span>
spark<span class="token punctuation">.</span><span class="token keyword">table</span><span class="token punctuation">(</span><span class="token string">"iceberg_hadoop.default.a"</span><span class="token punctuation">)</span>
<span class="token punctuation">.</span><span class="token keyword">show</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p><strong>（2）时间旅行：指定时间查询</strong></p> 
<pre><code class="prism language-sql">spark<span class="token punctuation">.</span><span class="token keyword">read</span>
    <span class="token punctuation">.</span><span class="token keyword">option</span><span class="token punctuation">(</span><span class="token string">"as-of-timestamp"</span><span class="token punctuation">,</span> <span class="token string">"499162860000"</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span><span class="token string">"iceberg"</span><span class="token punctuation">)</span>
<span class="token punctuation">.</span><span class="token keyword">load</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop1:8020/warehouse/spark-iceberg/default/a"</span><span class="token punctuation">)</span>
<span class="token punctuation">.</span><span class="token keyword">show</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p><strong>（3）时间旅行：指定快照id查询</strong></p> 
<pre><code class="prism language-sql">spark<span class="token punctuation">.</span><span class="token keyword">read</span>
    <span class="token punctuation">.</span><span class="token keyword">option</span><span class="token punctuation">(</span><span class="token string">"snapshot-id"</span><span class="token punctuation">,</span> <span class="token number">7601163594701794741</span>L<span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span><span class="token string">"iceberg"</span><span class="token punctuation">)</span>
<span class="token punctuation">.</span><span class="token keyword">load</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop1:8020/warehouse/spark-iceberg/default/a"</span><span class="token punctuation">)</span>
<span class="token punctuation">.</span><span class="token keyword">show</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p><strong>（4）增量查询</strong></p> 
<pre><code class="prism language-sql">spark<span class="token punctuation">.</span><span class="token keyword">read</span>
<span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span><span class="token string">"iceberg"</span><span class="token punctuation">)</span>
<span class="token punctuation">.</span><span class="token keyword">option</span><span class="token punctuation">(</span><span class="token string">"start-snapshot-id"</span><span class="token punctuation">,</span> <span class="token string">"10963874102873"</span><span class="token punctuation">)</span>
<span class="token punctuation">.</span><span class="token keyword">option</span><span class="token punctuation">(</span><span class="token string">"end-snapshot-id"</span><span class="token punctuation">,</span> <span class="token string">"63874143573109"</span><span class="token punctuation">)</span>
<span class="token punctuation">.</span><span class="token keyword">load</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop1:8020/warehouse/spark-iceberg/default/a"</span><span class="token punctuation">)</span>
<span class="token punctuation">.</span><span class="token keyword">show</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p>查询的表只能是append的方式写数据，不支持replace, overwrite, delete操作。</p> 
<h5><a id="_1214"></a>检查表</h5> 
<p><strong>（1）查询元数据</strong></p> 
<pre><code class="prism language-scala">spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">"iceberg"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"iceberg_hadoop.default.a.files"</span><span class="token punctuation">)</span>
spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">"iceberg"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"hdfs://hadoop1:8020/warehouse/spark-iceberg/default/a#files"</span><span class="token punctuation">)</span>
</code></pre> 
<p><strong>（2）元数据表时间旅行查询</strong></p> 
<pre><code class="prism language-scala">spark<span class="token punctuation">.</span>read
<span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">"iceberg"</span><span class="token punctuation">)</span>
<span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"snapshot-id"</span><span class="token punctuation">,</span> <span class="token number">7601163594701794741L</span><span class="token punctuation">)</span>
<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"iceberg_hadoop.default.a.files"</span><span class="token punctuation">)</span>
</code></pre> 
<h5><a id="_1234"></a>写入表</h5> 
<p><strong>（1）创建样例类，准备DF</strong></p> 
<pre><code class="prism language-scala"><span class="token keyword">case</span> <span class="token keyword">class</span> Sample<span class="token punctuation">(</span>id<span class="token operator">:</span><span class="token builtin">Int</span><span class="token punctuation">,</span>data<span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">,</span>category<span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">)</span>

<span class="token keyword">val</span> df<span class="token operator">:</span> DataFrame <span class="token operator">=</span> spark<span class="token punctuation">.</span>createDataFrame<span class="token punctuation">(</span>Seq<span class="token punctuation">(</span>Sample<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token char">'A'</span><span class="token punctuation">,</span> <span class="token char">'a'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Sample<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token char">'B'</span><span class="token punctuation">,</span> <span class="token char">'b'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Sample<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token char">'C'</span><span class="token punctuation">,</span> <span class="token char">'c'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p><strong>（2）插入数据并建表</strong></p> 
<pre><code class="prism language-scala">df<span class="token punctuation">.</span>writeTo<span class="token punctuation">(</span><span class="token string">"iceberg_hadoop.default.table1"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>create<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">import</span> <span class="token namespace">spark<span class="token punctuation">.</span>implicits<span class="token punctuation">.</span></span>_
df<span class="token punctuation">.</span>writeTo<span class="token punctuation">(</span><span class="token string">"iceberg_hadoop.default.table1"</span><span class="token punctuation">)</span>
  <span class="token punctuation">.</span>tableProperty<span class="token punctuation">(</span><span class="token string">"write.format.default"</span><span class="token punctuation">,</span> <span class="token string">"orc"</span><span class="token punctuation">)</span>
  <span class="token punctuation">.</span>partitionedBy<span class="token punctuation">(</span>$<span class="token string">"category"</span><span class="token punctuation">)</span>
  <span class="token punctuation">.</span>createOrReplace<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p><strong>（3）append追加</strong></p> 
<pre><code class="prism language-scala">df<span class="token punctuation">.</span>writeTo<span class="token punctuation">(</span><span class="token string">"iceberg_hadoop.default.table1"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p><strong>（4）动态分区覆盖</strong></p> 
<pre><code class="prism language-sql">df<span class="token punctuation">.</span>writeTo<span class="token punctuation">(</span><span class="token string">"iceberg_hadoop.default.table1"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>overwritePartitions<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p><strong>（5）静态分区覆盖</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">import</span> spark<span class="token punctuation">.</span>implicits<span class="token punctuation">.</span>_
df<span class="token punctuation">.</span>writeTo<span class="token punctuation">(</span><span class="token string">"iceberg_hadoop.default.table1"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>overwrite<span class="token punctuation">(</span>$<span class="token string">"category"</span> <span class="token operator">=</span><span class="token operator">=</span><span class="token operator">=</span> <span class="token string">"c"</span><span class="token punctuation">)</span>
</code></pre> 
<p><strong>（6）插入分区表且分区内排序</strong></p> 
<pre><code class="prism language-sql">df<span class="token punctuation">.</span>sortWithinPartitions<span class="token punctuation">(</span><span class="token string">"category"</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span>writeTo<span class="token punctuation">(</span><span class="token string">"iceberg_hadoop.default.table1"</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<h5><a id="_1285"></a>维护表</h5> 
<p><strong>（1）获取Table对象</strong></p> 
<p>1）HadoopCatalog</p> 
<pre><code class="prism language-sql"><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span>Configuration<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>iceberg<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>HadoopCatalog<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>iceberg<span class="token punctuation">.</span><span class="token keyword">Table</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>iceberg<span class="token punctuation">.</span>catalog<span class="token punctuation">.</span>TableIdentifier<span class="token punctuation">;</span>

val conf <span class="token operator">=</span> new Configuration<span class="token punctuation">(</span><span class="token punctuation">)</span>
val catalog <span class="token operator">=</span> new HadoopCatalog<span class="token punctuation">(</span>conf<span class="token punctuation">,</span><span class="token string">"hdfs://hadoop1:8020/warehouse/spark-iceberg"</span><span class="token punctuation">)</span>
val <span class="token keyword">table</span>: <span class="token keyword">Table</span> <span class="token operator">=</span> catalog<span class="token punctuation">.</span>loadTable<span class="token punctuation">(</span>TableIdentifier<span class="token punctuation">.</span><span class="token keyword">of</span><span class="token punctuation">(</span><span class="token string">"db"</span><span class="token punctuation">,</span><span class="token string">"table1"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p>2）HiveCatalog</p> 
<pre><code class="prism language-sql"><span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>iceberg<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>HiveCatalog<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>iceberg<span class="token punctuation">.</span><span class="token keyword">Table</span><span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>iceberg<span class="token punctuation">.</span>catalog<span class="token punctuation">.</span>TableIdentifier<span class="token punctuation">;</span>

val catalog <span class="token operator">=</span> new HiveCatalog<span class="token punctuation">(</span><span class="token punctuation">)</span>
catalog<span class="token punctuation">.</span>setConf<span class="token punctuation">(</span>spark<span class="token punctuation">.</span>sparkContext<span class="token punctuation">.</span>hadoopConfiguration<span class="token punctuation">)</span>

val properties <span class="token operator">=</span> new util<span class="token punctuation">.</span>HashMap<span class="token punctuation">[</span>String<span class="token punctuation">,</span>String<span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
properties<span class="token punctuation">.</span>put<span class="token punctuation">(</span><span class="token string">"warehouse"</span><span class="token punctuation">,</span> <span class="token string">"hdfs://hadoop1:8020/warehouse/spark-iceberg"</span><span class="token punctuation">)</span>
properties<span class="token punctuation">.</span>put<span class="token punctuation">(</span><span class="token string">"uri"</span><span class="token punctuation">,</span> <span class="token string">"thrift://hadoop1:9083"</span><span class="token punctuation">)</span>

catalog<span class="token punctuation">.</span>initialize<span class="token punctuation">(</span><span class="token string">"hive"</span><span class="token punctuation">,</span> properties<span class="token punctuation">)</span>
val <span class="token keyword">table</span>: <span class="token keyword">Table</span> <span class="token operator">=</span> catalog<span class="token punctuation">.</span>loadTable<span class="token punctuation">(</span>TableIdentifier<span class="token punctuation">.</span><span class="token keyword">of</span><span class="token punctuation">(</span><span class="token string">"db"</span><span class="token punctuation">,</span> <span class="token string">"table1"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p><strong>（2）快照过期清理</strong></p> 
<p>每次写入Iceberg表都会创建一个表的新快照或版本。快照可以用于时间旅行查询，或者可以将表回滚到任何有效的快照。建议设置快照过期时间，过期的旧快照将从元数据中删除（不再可用于时间旅行查询）。</p> 
<pre><code class="prism language-scala"><span class="token comment">// 1天过期时间</span>
<span class="token keyword">val</span> tsToExpire<span class="token operator">:</span> <span class="token builtin">Long</span> <span class="token operator">=</span> System<span class="token punctuation">.</span>currentTimeMillis<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token punctuation">(</span><span class="token number">1000</span> <span class="token operator">*</span> <span class="token number">60</span> <span class="token operator">*</span> <span class="token number">60</span> <span class="token operator">*</span> <span class="token number">24</span><span class="token punctuation">)</span>

table<span class="token punctuation">.</span>expireSnapshots<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">.</span>expireOlderThan<span class="token punctuation">(</span>tsToExpire<span class="token punctuation">)</span>
  <span class="token punctuation">.</span>commit<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p>或使用SparkActions来设置过期：</p> 
<pre><code class="prism language-sql"><span class="token comment">//SparkActions可以并行运行大型表的表过期设置</span>
SparkActions<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token punctuation">.</span>expireSnapshots<span class="token punctuation">(</span><span class="token keyword">table</span><span class="token punctuation">)</span>
  <span class="token punctuation">.</span>expireOlderThan<span class="token punctuation">(</span>tsToExpire<span class="token punctuation">)</span>
  <span class="token punctuation">.</span><span class="token keyword">execute</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p><strong>（3）删除无效文件</strong></p> 
<p>在Spark和其他分布式处理引擎中，任务或作业失败可能会留下未被表元数据引用的文件，在某些情况下，正常的快照过期可能无法确定不再需要并删除该文件。</p> 
<pre><code class="prism language-scala">SparkActions
    <span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span>deleteOrphanFiles<span class="token punctuation">(</span>table<span class="token punctuation">)</span>
    <span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p><strong>（4）合并小文件</strong></p> 
<p>数据文件过多会导致更多的元数据存储在清单文件中，而较小的数据文件会导致不必要的元数据量和更低效率的文件打开成本。</p> 
<pre><code class="prism language-scala">SparkActions
    <span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span>rewriteDataFiles<span class="token punctuation">(</span>table<span class="token punctuation">)</span>
    <span class="token punctuation">.</span>filter<span class="token punctuation">(</span>Expressions<span class="token punctuation">.</span>equal<span class="token punctuation">(</span><span class="token string">"category"</span><span class="token punctuation">,</span> <span class="token string">"a"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"target-file-size-bytes"</span><span class="token punctuation">,</span> <span class="token number">1024L</span><span class="token punctuation">.</span>toString<span class="token punctuation">)</span> <span class="token comment">//1KB</span>
    <span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="_Flink_SQL__1375"></a>与 Flink SQL 集成</h3> 
<p>Apache Iceberg同时支持Apache Flink的DataStream API和Table API。</p> 
<h4><a id="_1379"></a>环境准备</h4> 
<p><strong>（1）安装 Flink</strong></p> 
<p><strong>1）Flink与Iceberg的版本对应关系如下</strong></p> 
<table><thead><tr><th>Flink 版本</th><th>Iceberg 版本</th></tr></thead><tbody><tr><td>1.11</td><td>0.9.0 – 0.12.1</td></tr><tr><td>1.12</td><td>0.12.0 – 0.13.1</td></tr><tr><td>1.13</td><td>0.13.0 – 1.0.0</td></tr><tr><td>1.14</td><td>0.13.0 – 1.1.0</td></tr><tr><td>1.15</td><td>0.14.0 – 1.1.0</td></tr><tr><td>1.16</td><td>1.1.0 – 1.1.0</td></tr></tbody></table> 
<p><strong>2）上传并解压Flink安装包</strong></p> 
<pre><code class="prism language-bash"><span class="token function">tar</span> -zxvf flink-1.16.0-bin-scala_2.12.tgz -C /opt/module/
</code></pre> 
<p><strong>3）配置环境变量</strong></p> 
<pre><code class="prism language-bash"><span class="token function">sudo</span> <span class="token function">vim</span> /etc/profile.d/my_env.sh
<span class="token builtin class-name">export</span> <span class="token assign-left variable">HADOOP_CLASSPATH</span><span class="token operator">=</span><span class="token variable"><span class="token variable">`</span>hadoop classpath<span class="token variable">`</span></span>
<span class="token builtin class-name">source</span> /etc/profile.d/my_env.sh
</code></pre> 
<p><strong>4）拷贝iceberg的jar包到Flink的lib目录</strong></p> 
<pre><code class="prism language-bash"><span class="token function">cp</span> /opt/software/iceberg/iceberg-flink-runtime-1.16-1.1.0.jar /opt/module/flink-1.16.0/lib
</code></pre> 
<p><strong>（2）启动 Hadoop</strong></p> 
<p><strong>（3）启动 sql-client</strong></p> 
<p><strong>1）修改flink-conf.yaml配置</strong></p> 
<pre><code class="prism language-bash"><span class="token function">vim</span> /opt/module/flink-1.16.0/conf/flink-conf.yaml

classloader.check-leaked-classloader: <span class="token boolean">false</span>
taskmanager.numberOfTaskSlots: <span class="token number">4</span>

state.backend: rocksdb
execution.checkpointing.interval: <span class="token number">30000</span>
state.checkpoints.dir: hdfs://hadoop1:8020/ckps
state.backend.incremental: <span class="token boolean">true</span>
</code></pre> 
<p><strong>2）local模式</strong></p> 
<p>（1）修改workers</p> 
<pre><code class="prism language-bash"><span class="token function">vim</span> /opt/module/flink-1.16.0/conf/workers
<span class="token comment">#表示：会在本地启动3个TaskManager的 local集群</span>
localhost
localhost
localhost
</code></pre> 
<p>（2）启动Flink</p> 
<pre><code class="prism language-bash">/opt/module/flink-1.16.0/bin/start-cluster.sh
</code></pre> 
<p>查看webui：<a href="http://hadoop1:8081" rel="nofollow">http://hadoop1:8081</a></p> 
<p>（3）启动Flink的sql-client</p> 
<pre><code class="prism language-bash">/opt/module/flink-1.16.0/bin/sql-client.sh embedded
</code></pre> 
<h4><a id="_Catalog_1464"></a>创建和使用 Catalog</h4> 
<h5><a id="_1466"></a>语法说明</h5> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> CATALOG <span class="token operator">&lt;</span>catalog_name<span class="token operator">&gt;</span> <span class="token keyword">WITH</span> <span class="token punctuation">(</span>
  <span class="token string">'type'</span><span class="token operator">=</span><span class="token string">'iceberg'</span><span class="token punctuation">,</span>
  <span class="token identifier"><span class="token punctuation">`</span>&lt;config_key&gt;<span class="token punctuation">`</span></span><span class="token operator">=</span><span class="token identifier"><span class="token punctuation">`</span>&lt;config_value&gt;<span class="token punctuation">`</span></span>
<span class="token punctuation">)</span><span class="token punctuation">;</span> 
</code></pre> 
<ul><li> <p>type: 必须是iceberg。（必须）</p> </li><li> <p>catalog-type: 内置了hive和hadoop两种catalog，也可以使用catalog-impl来自定义catalog。（可选）</p> </li><li> <p>catalog-impl: 自定义catalog实现的全限定类名。如果未设置catalog-type，则必须设置。（可选）</p> </li><li> <p>property-version: 描述属性版本的版本号。此属性可用于向后兼容，以防属性格式更改。当前属性版本为1。（可选）</p> </li><li> <p>cache-enabled: 是否启用目录缓存，默认值为true。（可选）</p> </li><li> <p>cache.expiration-interval-ms: 本地缓存catalog条目的时间(以毫秒为单位)；负值，如-1表示没有时间限制，不允许设为0。默认值为-1。（可选）</p> </li></ul> 
<h5><a id="Hive_Catalog_1487"></a>Hive Catalog</h5> 
<p><strong>（1）上传hive connector到flink的lib中</strong></p> 
<pre><code class="prism language-bash"><span class="token function">cp</span> flink-sql-connector-hive-3.1.2_2.12-1.16.0.jar /opt/module/flink-1.16.0/lib/
</code></pre> 
<p><strong>（2）启动hive metastore服务</strong></p> 
<pre><code class="prism language-bash">hive --service metastore
</code></pre> 
<p><strong>（3）创建hive catalog</strong></p> 
<p>重启flink集群，重新进入sql-client</p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> CATALOG hive_catalog <span class="token keyword">WITH</span> <span class="token punctuation">(</span>
  <span class="token string">'type'</span><span class="token operator">=</span><span class="token string">'iceberg'</span><span class="token punctuation">,</span>
  <span class="token string">'catalog-type'</span><span class="token operator">=</span><span class="token string">'hive'</span><span class="token punctuation">,</span>
  <span class="token string">'uri'</span><span class="token operator">=</span><span class="token string">'thrift://hadoop1:9083'</span><span class="token punctuation">,</span>
  <span class="token string">'clients'</span><span class="token operator">=</span><span class="token string">'5'</span><span class="token punctuation">,</span>
  <span class="token string">'property-version'</span><span class="token operator">=</span><span class="token string">'1'</span><span class="token punctuation">,</span>
  <span class="token string">'warehouse'</span><span class="token operator">=</span><span class="token string">'hdfs://hadoop1:8020/warehouse/iceberg-hive'</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token keyword">use</span> catalog hive_catalog<span class="token punctuation">;</span>
</code></pre> 
<p>use catalog hive_catalog;</p> 
<ul><li> <p>uri: Hive metastore的thrift uri。(必选)</p> </li><li> <p>clients:Hive metastore客户端池大小，默认为2。(可选)</p> </li><li> <p>warehouse: 数仓目录。</p> </li><li> <p>hive-conf-dir:包含hive-site.xml配置文件的目录路径，hive-site.xml中hive.metastore.warehouse.dir 的值会被warehouse覆盖。</p> </li><li> <p>hadoop-conf-dir:包含core-site.xml和hdfs-site.xml配置文件的目录路径。</p> </li></ul> 
<h5><a id="Hadoop_Catalog_1532"></a>Hadoop Catalog</h5> 
<p>Iceberg还支持HDFS中基于目录的catalog，可以使用’catalog-type’='hadoop’配置。</p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> CATALOG hadoop_catalog <span class="token keyword">WITH</span> <span class="token punctuation">(</span>
  <span class="token string">'type'</span><span class="token operator">=</span><span class="token string">'iceberg'</span><span class="token punctuation">,</span>
  <span class="token string">'catalog-type'</span><span class="token operator">=</span><span class="token string">'hadoop'</span><span class="token punctuation">,</span>
  <span class="token string">'warehouse'</span><span class="token operator">=</span><span class="token string">'hdfs://hadoop1:8020/warehouse/iceberg-hadoop'</span><span class="token punctuation">,</span>
  <span class="token string">'property-version'</span><span class="token operator">=</span><span class="token string">'1'</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token keyword">use</span> catalog hadoop_catalog<span class="token punctuation">;</span>
</code></pre> 
<ul><li>warehouse:存放元数据文件和数据文件的HDFS目录。（必需）</li></ul> 
<h5><a id="sqlclient_1551"></a>配置sql-client初始化文件</h5> 
<pre><code class="prism language-sql">vim <span class="token operator">/</span>opt<span class="token operator">/</span>module<span class="token operator">/</span>flink<span class="token operator">-</span><span class="token number">1.16</span><span class="token number">.0</span><span class="token operator">/</span>conf<span class="token operator">/</span><span class="token keyword">sql</span><span class="token operator">-</span>client<span class="token operator">-</span>init<span class="token punctuation">.</span><span class="token keyword">sql</span>

<span class="token keyword">CREATE</span> CATALOG hive_catalog <span class="token keyword">WITH</span> <span class="token punctuation">(</span>
  <span class="token string">'type'</span><span class="token operator">=</span><span class="token string">'iceberg'</span><span class="token punctuation">,</span>
  <span class="token string">'catalog-type'</span><span class="token operator">=</span><span class="token string">'hive'</span><span class="token punctuation">,</span>
  <span class="token string">'uri'</span><span class="token operator">=</span><span class="token string">'thrift://hadoop1:9083'</span><span class="token punctuation">,</span>
  <span class="token string">'warehouse'</span><span class="token operator">=</span><span class="token string">'hdfs://hadoop1:8020/warehouse/iceberg-hive'</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token keyword">USE</span> CATALOG hive_catalog<span class="token punctuation">;</span>
</code></pre> 
<p>后续启动sql-client时，加上 -i sql文件路径 即可完成catalog的初始化。</p> 
<pre><code class="prism language-bash">/opt/module/flink-1.16.0/bin/sql-client.sh embedded -i conf/sql-client-init.sql
</code></pre> 
<h4><a id="DDL__1574"></a>DDL 语句</h4> 
<h5><a id="_1576"></a>创建数据库</h5> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">DATABASE</span> iceberg_db<span class="token punctuation">;</span>
<span class="token keyword">USE</span> iceberg_db<span class="token punctuation">;</span>
</code></pre> 
<h5><a id="_1585"></a>创建表</h5> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> <span class="token identifier"><span class="token punctuation">`</span>hive_catalog<span class="token punctuation">`</span></span><span class="token punctuation">.</span><span class="token identifier"><span class="token punctuation">`</span>default<span class="token punctuation">`</span></span><span class="token punctuation">.</span><span class="token identifier"><span class="token punctuation">`</span>sample<span class="token punctuation">`</span></span> <span class="token punctuation">(</span>
    id <span class="token keyword">BIGINT</span> <span class="token keyword">COMMENT</span> <span class="token string">'unique id'</span><span class="token punctuation">,</span>
    <span class="token keyword">data</span> STRING
<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>建表命令现在支持最常用的flink建表语法，包括:</p> 
<ul><li> <p>PARTITION BY (column1, column2, …)：配置分区，apache flink还不支持隐藏分区。</p> </li><li> <p>COMMENT ‘table document’：指定表的备注</p> </li><li> <p>WITH (‘key’=‘value’, …)：设置表属性</p> </li></ul> 
<blockquote> 
 <p>目前，不支持计算列、watermark（支持主键）。</p> 
</blockquote> 
<p><strong>（1）创建分区表</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> <span class="token identifier"><span class="token punctuation">`</span>hive_catalog<span class="token punctuation">`</span></span><span class="token punctuation">.</span><span class="token identifier"><span class="token punctuation">`</span>default<span class="token punctuation">`</span></span><span class="token punctuation">.</span><span class="token identifier"><span class="token punctuation">`</span>sample<span class="token punctuation">`</span></span> <span class="token punctuation">(</span>
    id <span class="token keyword">BIGINT</span> <span class="token keyword">COMMENT</span> <span class="token string">'unique id'</span><span class="token punctuation">,</span>
    <span class="token keyword">data</span> STRING
<span class="token punctuation">)</span> PARTITIONED <span class="token keyword">BY</span> <span class="token punctuation">(</span><span class="token keyword">data</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>Apache Iceberg支持隐藏分区，但Apache flink不支持在列上通过函数进行分区，现在无法在flink DDL中支持隐藏分区。</p> 
<p><strong>（2）使用LIKE语法建表</strong></p> 
<p>LIKE语法用于创建一个与另一个表具有相同schema、分区和属性的表。</p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> <span class="token identifier"><span class="token punctuation">`</span>hive_catalog<span class="token punctuation">`</span></span><span class="token punctuation">.</span><span class="token identifier"><span class="token punctuation">`</span>default<span class="token punctuation">`</span></span><span class="token punctuation">.</span><span class="token identifier"><span class="token punctuation">`</span>sample<span class="token punctuation">`</span></span> <span class="token punctuation">(</span>
    id <span class="token keyword">BIGINT</span> <span class="token keyword">COMMENT</span> <span class="token string">'unique id'</span><span class="token punctuation">,</span>
    <span class="token keyword">data</span> STRING
<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span>  <span class="token identifier"><span class="token punctuation">`</span>hive_catalog<span class="token punctuation">`</span></span><span class="token punctuation">.</span><span class="token identifier"><span class="token punctuation">`</span>default<span class="token punctuation">`</span></span><span class="token punctuation">.</span><span class="token identifier"><span class="token punctuation">`</span>sample_like<span class="token punctuation">`</span></span> <span class="token operator">LIKE</span> <span class="token identifier"><span class="token punctuation">`</span>hive_catalog<span class="token punctuation">`</span></span><span class="token punctuation">.</span><span class="token identifier"><span class="token punctuation">`</span>default<span class="token punctuation">`</span></span><span class="token punctuation">.</span><span class="token identifier"><span class="token punctuation">`</span>sample<span class="token punctuation">`</span></span><span class="token punctuation">;</span>
</code></pre> 
<h5><a id="_1630"></a>修改表</h5> 
<p><strong>（1）修改表属性</strong></p> 
<pre><code class="prism language-bash">ALTER TABLE <span class="token variable"><span class="token variable">`</span>hive_catalog<span class="token variable">`</span></span><span class="token builtin class-name">.</span><span class="token variable"><span class="token variable">`</span>default<span class="token variable">`</span></span><span class="token builtin class-name">.</span><span class="token variable"><span class="token variable">`</span>sample<span class="token variable">`</span></span> SET <span class="token punctuation">(</span><span class="token string">'write.format.default'</span><span class="token operator">=</span><span class="token string">'avro'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p><strong>（2）修改表名</strong></p> 
<pre><code class="prism language-bash">ALTER TABLE <span class="token variable"><span class="token variable">`</span>hive_catalog<span class="token variable">`</span></span><span class="token builtin class-name">.</span><span class="token variable"><span class="token variable">`</span>default<span class="token variable">`</span></span><span class="token builtin class-name">.</span><span class="token variable"><span class="token variable">`</span>sample<span class="token variable">`</span></span> RENAME TO <span class="token variable"><span class="token variable">`</span>hive_catalog<span class="token variable">`</span></span><span class="token builtin class-name">.</span><span class="token variable"><span class="token variable">`</span>default<span class="token variable">`</span></span><span class="token builtin class-name">.</span><span class="token variable"><span class="token variable">`</span>new_sample<span class="token variable">`</span></span><span class="token punctuation">;</span>
</code></pre> 
<h5><a id="_1646"></a>删除表</h5> 
<pre><code class="prism language-bash">DROP TABLE <span class="token variable"><span class="token variable">`</span>hive_catalog<span class="token variable">`</span></span><span class="token builtin class-name">.</span><span class="token variable"><span class="token variable">`</span>default<span class="token variable">`</span></span><span class="token builtin class-name">.</span><span class="token variable"><span class="token variable">`</span>sample<span class="token variable">`</span></span><span class="token punctuation">;</span>
</code></pre> 
<h4><a id="_1654"></a>插入语句</h4> 
<h5><a id="INSERT_INTO_1656"></a>INSERT INTO</h5> 
<pre><code class="prism language-sql"><span class="token keyword">INSERT</span> <span class="token keyword">INTO</span> <span class="token identifier"><span class="token punctuation">`</span>hive_catalog<span class="token punctuation">`</span></span><span class="token punctuation">.</span><span class="token identifier"><span class="token punctuation">`</span>default<span class="token punctuation">`</span></span><span class="token punctuation">.</span><span class="token identifier"><span class="token punctuation">`</span>sample<span class="token punctuation">`</span></span> <span class="token keyword">VALUES</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">INSERT</span> <span class="token keyword">INTO</span> <span class="token identifier"><span class="token punctuation">`</span>hive_catalog<span class="token punctuation">`</span></span><span class="token punctuation">.</span><span class="token identifier"><span class="token punctuation">`</span>default<span class="token punctuation">`</span></span><span class="token punctuation">.</span><span class="token identifier"><span class="token punctuation">`</span>sample<span class="token punctuation">`</span></span> <span class="token keyword">SELECT</span> id<span class="token punctuation">,</span> <span class="token keyword">data</span> <span class="token keyword">from</span> sample2<span class="token punctuation">;</span>
</code></pre> 
<h5><a id="INSERT_OVERWRITE_1665"></a>INSERT OVERWRITE</h5> 
<p>仅支持Flink的Batch模式：</p> 
<pre><code class="prism language-sql"><span class="token keyword">SET</span> execution<span class="token punctuation">.</span>runtime<span class="token operator">-</span><span class="token keyword">mode</span> <span class="token operator">=</span> batch<span class="token punctuation">;</span>
<span class="token keyword">INSERT</span> OVERWRITE sample <span class="token keyword">VALUES</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">INSERT</span> OVERWRITE <span class="token identifier"><span class="token punctuation">`</span>hive_catalog<span class="token punctuation">`</span></span><span class="token punctuation">.</span><span class="token identifier"><span class="token punctuation">`</span>default<span class="token punctuation">`</span></span><span class="token punctuation">.</span><span class="token identifier"><span class="token punctuation">`</span>sample<span class="token punctuation">`</span></span> <span class="token keyword">PARTITION</span><span class="token punctuation">(</span><span class="token keyword">data</span><span class="token operator">=</span><span class="token string">'a'</span><span class="token punctuation">)</span> <span class="token keyword">SELECT</span> <span class="token number">6</span><span class="token punctuation">;</span>
</code></pre> 
<h5><a id="UPSERT_1677"></a>UPSERT</h5> 
<p>当将数据写入v2表格式时，Iceberg支持基于主键的UPSERT。有两种方法可以启用upsert。</p> 
<p><strong>（1）建表时指定</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> <span class="token identifier"><span class="token punctuation">`</span>hive_catalog<span class="token punctuation">`</span></span><span class="token punctuation">.</span><span class="token identifier"><span class="token punctuation">`</span>test1<span class="token punctuation">`</span></span><span class="token punctuation">.</span><span class="token identifier"><span class="token punctuation">`</span>sample5<span class="token punctuation">`</span></span> <span class="token punctuation">(</span>
    <span class="token identifier"><span class="token punctuation">`</span>id<span class="token punctuation">`</span></span>  <span class="token keyword">INT</span> <span class="token keyword">UNIQUE</span> <span class="token keyword">COMMENT</span> <span class="token string">'unique id'</span><span class="token punctuation">,</span>
    <span class="token identifier"><span class="token punctuation">`</span>data<span class="token punctuation">`</span></span> STRING <span class="token operator">NOT</span> <span class="token boolean">NULL</span><span class="token punctuation">,</span>
    <span class="token keyword">PRIMARY</span> <span class="token keyword">KEY</span><span class="token punctuation">(</span><span class="token identifier"><span class="token punctuation">`</span>id<span class="token punctuation">`</span></span><span class="token punctuation">)</span> <span class="token operator">NOT</span> ENFORCED
<span class="token punctuation">)</span> <span class="token keyword">with</span> <span class="token punctuation">(</span>
    <span class="token string">'format-version'</span><span class="token operator">=</span><span class="token string">'2'</span><span class="token punctuation">,</span> 
    <span class="token string">'write.upsert.enabled'</span><span class="token operator">=</span><span class="token string">'true'</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p><strong>（2）插入时指定</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">INSERT</span> <span class="token keyword">INTO</span> tableName <span class="token comment">/*+ OPTIONS('upsert-enabled'='true') */</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
</code></pre> 
<p>插入的表，format-version需要为2。</p> 
<p>OVERWRITE和UPSERT不能同时设置。在UPSERT模式下，如果对表进行分区，则分区字段必须也是主键。</p> 
<p><strong>（3）读取Kafka流，upsert插入到iceberg表中</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">create</span> <span class="token keyword">table</span> default_catalog<span class="token punctuation">.</span>default_database<span class="token punctuation">.</span>kafka<span class="token punctuation">(</span>
    id <span class="token keyword">int</span><span class="token punctuation">,</span>
    <span class="token keyword">data</span> string
<span class="token punctuation">)</span> <span class="token keyword">with</span> <span class="token punctuation">(</span>
    <span class="token string">'connector'</span> <span class="token operator">=</span> <span class="token string">'kafka'</span>
    <span class="token punctuation">,</span><span class="token string">'topic'</span> <span class="token operator">=</span> <span class="token string">'test111'</span>
    <span class="token punctuation">,</span><span class="token string">'properties.zookeeper.connect'</span> <span class="token operator">=</span> <span class="token string">'hadoop1:2181'</span>
    <span class="token punctuation">,</span><span class="token string">'properties.bootstrap.servers'</span> <span class="token operator">=</span> <span class="token string">'hadoop1:9092'</span>
    <span class="token punctuation">,</span><span class="token string">'format'</span> <span class="token operator">=</span> <span class="token string">'json'</span>
    <span class="token punctuation">,</span><span class="token string">'properties.group.id'</span><span class="token operator">=</span><span class="token string">'iceberg'</span>
    <span class="token punctuation">,</span><span class="token string">'scan.startup.mode'</span><span class="token operator">=</span><span class="token string">'earliest-offset'</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span>


<span class="token keyword">INSERT</span> <span class="token keyword">INTO</span> hive_catalog<span class="token punctuation">.</span>test1<span class="token punctuation">.</span>sample5 <span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> default_catalog<span class="token punctuation">.</span>default_database<span class="token punctuation">.</span>kafka<span class="token punctuation">;</span>
</code></pre> 
<h4><a id="_1727"></a>查询语句</h4> 
<p>Iceberg支持Flink的流式和批量读取。</p> 
<h5><a id="Batch_1731"></a>Batch模式</h5> 
<pre><code class="prism language-bash">SET execution.runtime-mode <span class="token operator">=</span> batch<span class="token punctuation">;</span>
<span class="token keyword">select</span> * from sample<span class="token punctuation">;</span>
</code></pre> 
<h5><a id="Streaming_1738"></a>Streaming模式</h5> 
<pre><code class="prism language-bash">SET execution.runtime-mode <span class="token operator">=</span> streaming<span class="token punctuation">;</span>
SET table.dynamic-table-options.enabled<span class="token operator">=</span>true<span class="token punctuation">;</span>
SET sql-client.execution.result-mode<span class="token operator">=</span>tableau<span class="token punctuation">;</span>
</code></pre> 
<p><strong>（1）从当前快照读取所有记录，然后从该快照读取增量数据</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> sample5 <span class="token comment">/*+ OPTIONS('streaming'='true', 'monitor-interval'='1s')*/</span> <span class="token punctuation">;</span>
</code></pre> 
<p><strong>（2）读取指定快照id（不包含）后的增量数据</strong></p> 
<pre><code class="prism language-sql"><span class="token keyword">SELECT</span> <span class="token operator">*</span> <span class="token keyword">FROM</span> sample <span class="token comment">/*+ OPTIONS('streaming'='true', 'monitor-interval'='1s', 'start-snapshot-id'='3821550127947089987')*/</span> <span class="token punctuation">;</span>
</code></pre> 
<ul><li> <p>monitor-interval: 连续监控新提交数据文件的时间间隔（默认为10s）。</p> </li><li> <p>start-snapshot-id: 流作业开始的快照id。</p> </li></ul> 
<p>**注意：**如果是无界数据流式upsert进iceberg表（读kafka，upsert进iceberg表），那么再去流读iceberg表会存在读不出数据的问题。如果无界数据流式append进iceberg表（读kafka，append进iceberg表），那么流读该iceberg表可以正常看到结果。</p> 
<h4><a id="Flink_1766"></a>与Flink集成的不足</h4> 
<table><thead><tr><th>支持的特性</th><th>Flink</th><th>备注</th></tr></thead><tbody><tr><td><a href="https://iceberg.apache.org/docs/latest/flink/#creating-catalogs-and-using-catalogs" rel="nofollow">SQL create catalog</a></td><td>√</td><td></td></tr><tr><td><a href="https://iceberg.apache.org/docs/latest/flink/#create-database" rel="nofollow">SQL create database</a></td><td>√</td><td></td></tr><tr><td><a href="https://iceberg.apache.org/docs/latest/flink/#create-table" rel="nofollow">SQL create table</a></td><td>√</td><td></td></tr><tr><td><a href="https://iceberg.apache.org/docs/latest/flink/#create-table-like" rel="nofollow">SQL create table like</a></td><td>√</td><td></td></tr><tr><td><a href="https://iceberg.apache.org/docs/latest/flink/#alter-table" rel="nofollow">SQL alter table</a></td><td>√</td><td>只支持修改表属性，不支持更改列和分区</td></tr><tr><td><a href="https://iceberg.apache.org/docs/latest/flink/#drop-table" rel="nofollow">SQL drop_table</a></td><td>√</td><td></td></tr><tr><td><a href="https://iceberg.apache.org/docs/latest/flink/#querying-with-sql" rel="nofollow">SQL select</a></td><td>√</td><td>支持流式和批处理模式</td></tr><tr><td><a href="https://iceberg.apache.org/docs/latest/flink/#insert-into" rel="nofollow">SQL insert into</a></td><td>√</td><td>支持流式和批处理模式</td></tr><tr><td><a href="https://iceberg.apache.org/docs/latest/flink/#insert-overwrite" rel="nofollow">SQL insert overwrite</a></td><td>√</td><td></td></tr><tr><td><a href="https://iceberg.apache.org/docs/latest/flink/#reading-with-datastream" rel="nofollow">DataStream read</a></td><td>√</td><td></td></tr><tr><td><a href="https://iceberg.apache.org/docs/latest/flink/#appending-data" rel="nofollow">DataStream append</a></td><td>√</td><td></td></tr><tr><td><a href="https://iceberg.apache.org/docs/latest/flink/#overwrite-data" rel="nofollow">DataStream overwrite</a></td><td>√</td><td></td></tr><tr><td><a href="https://iceberg.apache.org/docs/latest/flink/#inspecting-tables" rel="nofollow">Metadata tables</a></td><td></td><td>支持Java API，不支持Flink SQL</td></tr><tr><td><a href="https://iceberg.apache.org/docs/latest/flink/#rewrite-files-action" rel="nofollow">Rewrite files action</a></td><td>√</td><td></td></tr></tbody></table> 
<ul><li> <p>不支持创建隐藏分区的Iceberg表。</p> </li><li> <p>不支持创建带有计算列的Iceberg表。</p> </li><li> <p>不支持创建带watermark的Iceberg表。</p> </li><li> <p>不支持添加列，删除列，重命名列，更改列。</p> </li><li> <p>Iceberg目前不支持Flink SQL 查询表的元数据信息，需要使用Java API 实现。</p> </li></ul> 
<h3><a id="_Flink_DataStream__1797"></a>与 Flink DataStream 集成</h3> 
<h4><a id="_1799"></a>环境准备</h4> 
<p><strong>（1）配置pom文件</strong></p> 
<p>新建Maven工程，pom文件配置如下：</p> 
<pre><code class="prism language-xml"><span class="token prolog">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>project</span> <span class="token attr-name">xmlns</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>http://maven.apache.org/POM/4.0.0<span class="token punctuation">"</span></span>
         <span class="token attr-name"><span class="token namespace">xmlns:</span>xsi</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>http://www.w3.org/2001/XMLSchema-instance<span class="token punctuation">"</span></span>
         <span class="token attr-name"><span class="token namespace">xsi:</span>schemaLocation</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>modelVersion</span><span class="token punctuation">&gt;</span></span>4.0.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>modelVersion</span><span class="token punctuation">&gt;</span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>com.atguigu.iceberg<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>flink-iceberg-demo<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>1.0-SNAPSHOT<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>


    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>properties</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>maven.compiler.source</span><span class="token punctuation">&gt;</span></span>8<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>maven.compiler.source</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>maven.compiler.target</span><span class="token punctuation">&gt;</span></span>8<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>maven.compiler.target</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>flink.version</span><span class="token punctuation">&gt;</span></span>1.16.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>flink.version</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>java.version</span><span class="token punctuation">&gt;</span></span>1.8<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>java.version</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>scala.binary.version</span><span class="token punctuation">&gt;</span></span>2.12<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>scala.binary.version</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>slf4j.version</span><span class="token punctuation">&gt;</span></span>1.7.30<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>slf4j.version</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>properties</span><span class="token punctuation">&gt;</span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependencies</span><span class="token punctuation">&gt;</span></span>

        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>flink-java<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>${flink.version}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>scope</span><span class="token punctuation">&gt;</span></span>provided<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>scope</span><span class="token punctuation">&gt;</span></span>   <span class="token comment">&lt;!--不会打包到依赖中，只参与编译，不参与运行 --&gt;</span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>flink-streaming-java<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>${flink.version}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>scope</span><span class="token punctuation">&gt;</span></span>provided<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>scope</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>flink-clients<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>${flink.version}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>scope</span><span class="token punctuation">&gt;</span></span>provided<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>scope</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>

        <span class="token comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.flink/flink-table-planner --&gt;</span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>flink-table-planner_${scala.binary.version}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>${flink.version}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>scope</span><span class="token punctuation">&gt;</span></span>provided<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>scope</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>

        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>flink-connector-files<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>${flink.version}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>scope</span><span class="token punctuation">&gt;</span></span>provided<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>scope</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>

        <span class="token comment">&lt;!--idea运行时也有webui--&gt;</span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>flink-runtime-web<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>${flink.version}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>scope</span><span class="token punctuation">&gt;</span></span>provided<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>scope</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>

        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.slf4j<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>slf4j-api<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>${slf4j.version}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>scope</span><span class="token punctuation">&gt;</span></span>provided<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>scope</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.slf4j<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>slf4j-log4j12<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>${slf4j.version}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>scope</span><span class="token punctuation">&gt;</span></span>provided<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>scope</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.logging.log4j<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>log4j-to-slf4j<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>2.14.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>scope</span><span class="token punctuation">&gt;</span></span>provided<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>scope</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>


        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>flink-statebackend-rocksdb<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>${flink.version}<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>

        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.hadoop<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>hadoop-client<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>3.1.3<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>scope</span><span class="token punctuation">&gt;</span></span>provided<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>scope</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>

        <span class="token comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.iceberg/iceberg-flink-runtime-1.16 --&gt;</span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.iceberg<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>iceberg-flink-runtime-1.16<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>1.1.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependencies</span><span class="token punctuation">&gt;</span></span>


    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>build</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugins</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>plugin</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.maven.plugins<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>maven-shade-plugin<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>3.2.4<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>executions</span><span class="token punctuation">&gt;</span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>execution</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>phase</span><span class="token punctuation">&gt;</span></span>package<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>phase</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goals</span><span class="token punctuation">&gt;</span></span>
                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>goal</span><span class="token punctuation">&gt;</span></span>shade<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goal</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>goals</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">&gt;</span></span>
                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactSet</span><span class="token punctuation">&gt;</span></span>
                                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>excludes</span><span class="token punctuation">&gt;</span></span>
                                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>exclude</span><span class="token punctuation">&gt;</span></span>com.google.code.findbugs:jsr305<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>exclude</span><span class="token punctuation">&gt;</span></span>
                                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>exclude</span><span class="token punctuation">&gt;</span></span>org.slf4j:*<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>exclude</span><span class="token punctuation">&gt;</span></span>
                                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>exclude</span><span class="token punctuation">&gt;</span></span>log4j:*<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>exclude</span><span class="token punctuation">&gt;</span></span>
                                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>exclude</span><span class="token punctuation">&gt;</span></span>org.apache.hadoop:*<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>exclude</span><span class="token punctuation">&gt;</span></span>
                                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>excludes</span><span class="token punctuation">&gt;</span></span>
                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactSet</span><span class="token punctuation">&gt;</span></span>
                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>filters</span><span class="token punctuation">&gt;</span></span>
                                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>filter</span><span class="token punctuation">&gt;</span></span>
                                    <span class="token comment">&lt;!-- Do not copy the signatures in the META-INF folder.
                                    Otherwise, this might cause SecurityExceptions when using the JAR. --&gt;</span>
                                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifact</span><span class="token punctuation">&gt;</span></span>*:*<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifact</span><span class="token punctuation">&gt;</span></span>
                                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>excludes</span><span class="token punctuation">&gt;</span></span>
                                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>exclude</span><span class="token punctuation">&gt;</span></span>META-INF/*.SF<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>exclude</span><span class="token punctuation">&gt;</span></span>
                                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>exclude</span><span class="token punctuation">&gt;</span></span>META-INF/*.DSA<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>exclude</span><span class="token punctuation">&gt;</span></span>
                                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>exclude</span><span class="token punctuation">&gt;</span></span>META-INF/*.RSA<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>exclude</span><span class="token punctuation">&gt;</span></span>
                                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>excludes</span><span class="token punctuation">&gt;</span></span>
                                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>filter</span><span class="token punctuation">&gt;</span></span>
                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>filters</span><span class="token punctuation">&gt;</span></span>
                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>transformers</span> <span class="token attr-name">combine.children</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>append<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span>
                                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>transformer</span>
                                             <span class="token attr-name">implementation</span><span class="token attr-value"><span class="token punctuation attr-equals">=</span><span class="token punctuation">"</span>org.apache.maven.plugins.shade.resource.ServicesResourceTransformer<span class="token punctuation">"</span></span><span class="token punctuation">&gt;</span></span>
                                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>transformer</span><span class="token punctuation">&gt;</span></span>
                            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>transformers</span><span class="token punctuation">&gt;</span></span>
                        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">&gt;</span></span>
                    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>execution</span><span class="token punctuation">&gt;</span></span>
                <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>executions</span><span class="token punctuation">&gt;</span></span>
            <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugin</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>plugins</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>build</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>project</span><span class="token punctuation">&gt;</span></span>
</code></pre> 
<p><strong>（2）配置log4j</strong></p> 
<p>resources目录下新建log4j.properties。</p> 
<pre><code class="prism language-properties">log4j.rootLogger=error,stdout
log4j.appender.stdout=org.apache.log4j.ConsoleAppender
log4j.appender.stdout.target=System.out
log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
log4j.appender.stdout.layout.ConversionPattern=%d %p [%c] - %m%n
</code></pre> 
<h4><a id="_1976"></a>读取数据</h4> 
<h5><a id="Source_1978"></a>常规Source写法</h5> 
<p><strong>（1）Batch方式</strong></p> 
<pre><code class="prism language-java"><span class="token class-name">StreamExecutionEnvironment</span> env <span class="token operator">=</span> <span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">.</span><span class="token function">getExecutionEnvironment</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token class-name">TableLoader</span> tableLoader <span class="token operator">=</span> <span class="token class-name">TableLoader</span><span class="token punctuation">.</span><span class="token function">fromHadoopTable</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop1:8020/warehouse/spark-iceberg/default/a"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token class-name">DataStream</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">RowData</span><span class="token punctuation">&gt;</span></span> batch <span class="token operator">=</span> <span class="token class-name">FlinkSource</span><span class="token punctuation">.</span><span class="token function">forRowData</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
     <span class="token punctuation">.</span><span class="token function">env</span><span class="token punctuation">(</span>env<span class="token punctuation">)</span>
     <span class="token punctuation">.</span><span class="token function">tableLoader</span><span class="token punctuation">(</span>tableLoader<span class="token punctuation">)</span>
     <span class="token punctuation">.</span><span class="token function">streaming</span><span class="token punctuation">(</span><span class="token boolean">false</span><span class="token punctuation">)</span>
     <span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

batch<span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>r <span class="token operator">-&gt;</span> <span class="token class-name">Tuple2</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span>r<span class="token punctuation">.</span><span class="token function">getLong</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>r<span class="token punctuation">.</span><span class="token function">getLong</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">returns</span><span class="token punctuation">(</span><span class="token class-name">Types</span><span class="token punctuation">.</span><span class="token function">TUPLE</span><span class="token punctuation">(</span><span class="token class-name">Types</span><span class="token punctuation">.</span>LONG<span class="token punctuation">,</span><span class="token class-name">Types</span><span class="token punctuation">.</span>LONG<span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

env<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token string">"Test Iceberg Read"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p><strong>（2）Streaming方式</strong></p> 
<pre><code class="prism language-java"><span class="token class-name">StreamExecutionEnvironment</span> env <span class="token operator">=</span> <span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">.</span><span class="token function">getExecutionEnvironment</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token class-name">TableLoader</span> tableLoader <span class="token operator">=</span> <span class="token class-name">TableLoader</span><span class="token punctuation">.</span><span class="token function">fromHadoopTable</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop1:8020/warehouse/spark-iceberg/default/a"</span><span class="token punctuation">)</span><span class="token punctuation">;</span> 
<span class="token class-name">DataStream</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">RowData</span><span class="token punctuation">&gt;</span></span> stream <span class="token operator">=</span> <span class="token class-name">FlinkSource</span><span class="token punctuation">.</span><span class="token function">forRowData</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">env</span><span class="token punctuation">(</span>env<span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">tableLoader</span><span class="token punctuation">(</span>tableLoader<span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">streaming</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">startSnapshotId</span><span class="token punctuation">(</span><span class="token number">3821550127947089987L</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

stream<span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>r <span class="token operator">-&gt;</span> <span class="token class-name">Tuple2</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span>r<span class="token punctuation">.</span><span class="token function">getLong</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>r<span class="token punctuation">.</span><span class="token function">getLong</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">returns</span><span class="token punctuation">(</span><span class="token class-name">Types</span><span class="token punctuation">.</span><span class="token function">TUPLE</span><span class="token punctuation">(</span><span class="token class-name">Types</span><span class="token punctuation">.</span>LONG<span class="token punctuation">,</span><span class="token class-name">Types</span><span class="token punctuation">.</span>LONG<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

env<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token string">"Test Iceberg Read"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<h5><a id="FLIP27_Source_2021"></a>FLIP-27 Source写法</h5> 
<p><strong>（1）Batch方式</strong></p> 
<pre><code class="prism language-java"><span class="token class-name">StreamExecutionEnvironment</span> env <span class="token operator">=</span> <span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">.</span><span class="token function">getExecutionEnvironment</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token class-name">TableLoader</span> tableLoader <span class="token operator">=</span> <span class="token class-name">TableLoader</span><span class="token punctuation">.</span><span class="token function">fromHadoopTable</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop1:8020/warehouse/spark-iceberg/default/a"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token class-name">IcebergSource</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">RowData</span><span class="token punctuation">&gt;</span></span> source1 <span class="token operator">=</span> <span class="token class-name">IcebergSource</span><span class="token punctuation">.</span><span class="token function">forRowData</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">tableLoader</span><span class="token punctuation">(</span>tableLoader<span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">assignerFactory</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">SimpleSplitAssignerFactory</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token class-name">DataStream</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">RowData</span><span class="token punctuation">&gt;</span></span> batch <span class="token operator">=</span> env<span class="token punctuation">.</span><span class="token function">fromSource</span><span class="token punctuation">(</span>
    <span class="token class-name">Source1</span><span class="token punctuation">,</span>
    <span class="token class-name">WatermarkStrategy</span><span class="token punctuation">.</span><span class="token function">noWatermarks</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token string">"My Iceberg Source"</span><span class="token punctuation">,</span>
    <span class="token class-name">TypeInformation</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span><span class="token class-name">RowData</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

batch<span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>r <span class="token operator">-&gt;</span> <span class="token class-name">Tuple2</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span>r<span class="token punctuation">.</span><span class="token function">getLong</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> r<span class="token punctuation">.</span><span class="token function">getLong</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">returns</span><span class="token punctuation">(</span><span class="token class-name">Types</span><span class="token punctuation">.</span><span class="token function">TUPLE</span><span class="token punctuation">(</span><span class="token class-name">Types</span><span class="token punctuation">.</span>LONG<span class="token punctuation">,</span> <span class="token class-name">Types</span><span class="token punctuation">.</span>LONG<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

env<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token string">"Test Iceberg Read"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p><strong>（2）Streaming方式</strong></p> 
<pre><code class="prism language-java"><span class="token class-name">StreamExecutionEnvironment</span> env <span class="token operator">=</span> <span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">.</span><span class="token function">getExecutionEnvironment</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token class-name">TableLoader</span> tableLoader <span class="token operator">=</span> <span class="token class-name">TableLoader</span><span class="token punctuation">.</span><span class="token function">fromHadoopTable</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop1:8020/warehouse/spark-iceberg/default/a"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token class-name">IcebergSource</span> source2 <span class="token operator">=</span> <span class="token class-name">IcebergSource</span><span class="token punctuation">.</span><span class="token function">forRowData</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">tableLoader</span><span class="token punctuation">(</span>tableLoader<span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">assignerFactory</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">SimpleSplitAssignerFactory</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">streaming</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">streamingStartingStrategy</span><span class="token punctuation">(</span><span class="token class-name">StreamingStartingStrategy</span><span class="token punctuation">.</span>INCREMENTAL_FROM_LATEST_SNAPSHOT<span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">monitorInterval</span><span class="token punctuation">(</span><span class="token class-name">Duration</span><span class="token punctuation">.</span><span class="token function">ofSeconds</span><span class="token punctuation">(</span><span class="token number">60</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">build</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token class-name">DataStream</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">RowData</span><span class="token punctuation">&gt;</span></span> stream <span class="token operator">=</span> env<span class="token punctuation">.</span><span class="token function">fromSource</span><span class="token punctuation">(</span>
    <span class="token class-name">Source2</span><span class="token punctuation">,</span>
    <span class="token class-name">WatermarkStrategy</span><span class="token punctuation">.</span><span class="token function">noWatermarks</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token string">"My Iceberg Source"</span><span class="token punctuation">,</span>
    <span class="token class-name">TypeInformation</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span><span class="token class-name">RowData</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

stream<span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span>r <span class="token operator">-&gt;</span> <span class="token class-name">Tuple2</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span>r<span class="token punctuation">.</span><span class="token function">getLong</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> r<span class="token punctuation">.</span><span class="token function">getLong</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">returns</span><span class="token punctuation">(</span><span class="token class-name">Types</span><span class="token punctuation">.</span><span class="token function">TUPLE</span><span class="token punctuation">(</span><span class="token class-name">Types</span><span class="token punctuation">.</span>LONG<span class="token punctuation">,</span> <span class="token class-name">Types</span><span class="token punctuation">.</span>LONG<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

env<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token string">"Test Iceberg Read"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<h4><a id="_2078"></a>写入数据</h4> 
<p>目前支持DataStream&lt;RowData&gt;和DataStream&lt;Row&gt;格式的数据流写入Iceberg表。</p> 
<p><strong>（1）写入方式支持 append、overwrite、upsert</strong></p> 
<pre><code class="prism language-java"><span class="token class-name">StreamExecutionEnvironment</span> env <span class="token operator">=</span> <span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">.</span><span class="token function">getExecutionEnvironment</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
env<span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>


<span class="token class-name">SingleOutputStreamOperator</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">RowData</span><span class="token punctuation">&gt;</span></span> input <span class="token operator">=</span> env<span class="token punctuation">.</span><span class="token function">fromElements</span><span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">MapFunction</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">RowData</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
        <span class="token annotation punctuation">@Override</span>
        <span class="token keyword">public</span> <span class="token class-name">RowData</span> <span class="token function">map</span><span class="token punctuation">(</span><span class="token class-name">String</span> s<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">{<!-- --></span>
            <span class="token class-name">GenericRowData</span> genericRowData <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">GenericRowData</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            genericRowData<span class="token punctuation">.</span><span class="token function">setField</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">99L</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            genericRowData<span class="token punctuation">.</span><span class="token function">setField</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">99L</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

            <span class="token keyword">return</span> genericRowData<span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token class-name">TableLoader</span> tableLoader <span class="token operator">=</span> <span class="token class-name">TableLoader</span><span class="token punctuation">.</span><span class="token function">fromHadoopTable</span><span class="token punctuation">(</span><span class="token string">"hdfs://hadoop1:8020/warehouse/spark-iceberg/default/a"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>


<span class="token class-name">FlinkSink</span><span class="token punctuation">.</span><span class="token function">forRowData</span><span class="token punctuation">(</span>input<span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">tableLoader</span><span class="token punctuation">(</span>tableLoader<span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">append</span><span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token comment">// append方式</span>
    <span class="token comment">//.overwrite(true)   // overwrite方式</span>
    <span class="token comment">//.upsert(true)       // upsert方式</span>
    <span class="token punctuation">;</span>

env<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token string">"Test Iceberg DataStream"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p><strong>（2）写入选项</strong></p> 
<pre><code class="prism language-java"><span class="token class-name">FlinkSink</span><span class="token punctuation">.</span><span class="token function">forRowData</span><span class="token punctuation">(</span>input<span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">tableLoader</span><span class="token punctuation">(</span>tableLoader<span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span><span class="token string">"write-format"</span><span class="token punctuation">,</span> <span class="token string">"orc"</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span><span class="token class-name">FlinkWriteOptions</span><span class="token punctuation">.</span>OVERWRITE_MODE<span class="token punctuation">,</span> <span class="token string">"true"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>可配置选项如下：</p> 
<table><thead><tr><th>选项</th><th>默认值</th><th>说明</th></tr></thead><tbody><tr><td>write-format</td><td>Parquet同write.format.default</td><td>写入操作使用的文件格式：Parquet, avro或orc</td></tr><tr><td>target-file-size-bytes</td><td>536870912（512MB）同write.target-file-size-bytes</td><td>控制生成的文件的大小，目标大约为这么多字节</td></tr><tr><td>upsert-enabled</td><td>同write.upsert.enabled，</td><td></td></tr><tr><td>overwrite-enabled</td><td>false</td><td>覆盖表的数据，不能和UPSERT模式同时开启</td></tr><tr><td>distribution-mode</td><td>None同 write.distribution-mode</td><td>定义写数据的分布方式: none:不打乱行; hash:按分区键散列分布;range：如果表有SortOrder，则通过分区键或排序键分配</td></tr><tr><td>compression-codec</td><td>同 write.(fileformat).compression-codec</td><td></td></tr><tr><td>compression-level</td><td>同 write.(fileformat).compression-level</td><td></td></tr><tr><td>compression-strategy</td><td>同write.orc.compression-strategy</td><td></td></tr></tbody></table> 
<h4><a id="_2140"></a>合并小文件</h4> 
<p>Iceberg现在不支持在flink sql中检查表，需要使用Iceberg提供的Java API来读取元数据来获得表信息。可以通过提交Flink批处理作业将小文件重写为大文件：</p> 
<pre><code class="prism language-java"><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>iceberg<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>actions<span class="token punctuation">.</span></span><span class="token class-name">Actions</span><span class="token punctuation">;</span>

<span class="token comment">// 1.获取 Table对象</span>
<span class="token comment">// 1.1 创建 catalog对象</span>
<span class="token class-name">Configuration</span> conf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token class-name">HadoopCatalog</span> hadoopCatalog <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">HadoopCatalog</span><span class="token punctuation">(</span>conf<span class="token punctuation">,</span> <span class="token string">"hdfs://hadoop1:8020/warehouse/spark-iceberg"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">// 1.2 通过 catalog加载 Table对象</span>
<span class="token class-name">Table</span> table <span class="token operator">=</span> hadoopCatalog<span class="token punctuation">.</span><span class="token function">loadTable</span><span class="token punctuation">(</span><span class="token class-name">TableIdentifier</span><span class="token punctuation">.</span><span class="token function">of</span><span class="token punctuation">(</span><span class="token string">"default"</span><span class="token punctuation">,</span> <span class="token string">"a"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token comment">// 有Table对象，就可以获取元数据、进行维护表的操作</span>
<span class="token comment">//        System.out.println(table.history());</span>
<span class="token comment">//        System.out.println(table.expireSnapshots().expireOlderThan());</span>

<span class="token comment">// 2.通过 Actions 来操作 合并</span>
<span class="token class-name">Actions</span><span class="token punctuation">.</span><span class="token function">forTable</span><span class="token punctuation">(</span>table<span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">rewriteDataFiles</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">targetSizeInBytes</span><span class="token punctuation">(</span><span class="token number">1024L</span><span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>得到Table对象，就可以获取元数据、进行维护表的操作。更多Iceberg提供的API操作，考：<a href="https://iceberg.apache.org/docs/latest/api/" rel="nofollow">https://iceberg.apache.org/docs/latest/api/</a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/bb230e6d7d0a1e2a9a0c555e9c6b7cd4/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">开发Android原生插件，引入自己打的jar报，编译报 Unsupported class file major version 61</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/65bc61f30c074f0fd8c3f2911c5d9075/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">十大基础算法</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>