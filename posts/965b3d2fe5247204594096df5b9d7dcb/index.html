<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>MMII 的多模态医学图像交互框架：更直观地理解人体解剖结构和疾病 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/965b3d2fe5247204594096df5b9d7dcb/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="MMII 的多模态医学图像交互框架：更直观地理解人体解剖结构和疾病">
  <meta property="og:description" content="医生在诊断和治疗过程中依赖于人体解剖图像，如磁共振成像（MRI），难以全面捕捉人体组织的复杂性，例如组织之间的空间关系、质地、大小等。然而，实时感知有关患者解剖结构和疾病的多模态信息对于医疗程序的成功和患者结果至关重要。本文介绍一个多模态医学图像交互（MMII）框架，允许医学专家在三维空间中与人体组织进行动态的视听交互。在虚拟现实环境中，用户接收到基于物理信息的视听反馈，以提高对解剖结构的空间感知。MMII使用基于模型的声音化方法，从组织的几何和物理属性生成声音，从而消除了手工制作声音设计的需要。
1 多模态MMII 框架 MMII 框架旨在通过多模态交互方式，帮助医疗专家更好地理解和感知人体解剖结构。该框架利用物理建模合成技术，将组织的物理属性和几何形状转换为音频信号，并与可视化模型相结合，为用户提供动态的音频视觉反馈。
1.1 框架结构 MMII 框架包含以下几个关键模块：
可视化模型：该模型将医学图像数据转换为 3D 模型，并通过缩放、颜色变化等方式提供视觉反馈。交互模块：该模块负责接收用户输入，并根据用户与模型的交互方式生成音频视觉反馈。声学模型：该模型根据组织的物理属性和几何形状生成声学模型，并通过物理建模合成技术生成音频信号。 1.2 工作原理 用户通过交互模块与 3D 模型进行交互，例如点击或触摸模型。交互模块将用户输入发送给声学模型，并触发声学模型的计算。声学模型根据组织的物理属性和几何形状生成音频信号，并通过物理建模合成技术生成声音。可视化模型根据用户输入和声学模型的输出提供视觉反馈，例如缩放、颜色变化等。用户通过音频和视觉反馈，更好地感知和理解人体解剖结构。 1.3 框架优势 多模态交互：MMII 框架利用音频和视觉两种模态，为用户提供更丰富的信息，并帮助用户更好地理解和感知人体解剖结构。物理信息：MMII 框架基于组织的物理属性和几何形状生成音频信号，使声音更具有真实感和直观性。动态反馈：MMII 框架可以实时生成音频视觉反馈，帮助用户动态地感知和理解人体解剖结构的变化。易于学习和理解：MMII 框架的用户研究结果表明，用户可以快速学习和理解解剖结构的音频视觉对应关系。 1.4 应用场景 MMII 框架可以应用于多种医学场景，例如：
手术导航：MMII 框架可以帮助医生在手术过程中更好地定位和识别解剖结构，从而提高手术精度和安全性。放射治疗计划：MMII 框架可以帮助医生更好地理解肿瘤的位置和形状，从而制定更精准的放射治疗方案。医学教育：MMII 框架可以帮助医学生更好地理解和学习人体解剖结构。 1.5 未来展望 更多解剖结构：未来研究可以将 MMII 框架应用于更多人体解剖结构，例如心脏、肺部等。更精细的物理模型：未来研究可以进一步改进物理模型，使其更精细、更准确。更复杂的交互方式：未来研究可以探索更复杂的交互方式，例如手势识别、语音识别等。与生理数据结合：未来研究可以将 MMII 框架与生理数据结合，例如心电图、血压等，为用户提供更全面的医学信息。 2 实验 2.1 实验1：多模态对应关系学习 研究目的：评估用户学习将视觉解剖结构表示与其听觉提示关联的能力。实验方法：进行了一项在线问卷调查，参与者通过视频和声音片段模拟 MMII 交互。实验参与者：34 名志愿者，包括具有医学和非医学背景的人。实验结果： 用户能够有效地将视觉和听觉表示的解剖结构进行关联，正确率显著提高（p &lt; 0.001）。
物理建模合成是创建解剖结构的可区分听觉表示的合适方法。
与视觉反馈相比，参与者在使用听觉反馈时感知到的任务负荷更低，表现更好，但认知负荷更高。
2.2 实验2：多模态脑肿瘤定位 研究目的：评估 MMII 在脑肿瘤定位等医学任务中的可用性和准确性。实验方法：开发了一个 VR 应用程序，让神经外科医生和神经放射科医生使用常规视觉交互和 MMII 进行脑肿瘤定位。实验参与者：9 名医学专家，包括神经外科医生和神经放射科医生。实验结果： 与视觉反馈相比，使用 MMII 的脑肿瘤定位精度显著提高（p &lt; 0.05）。
任务负荷没有显著差异，使用多模态交互时任务时间略有增加。">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-07-10T21:38:08+08:00">
    <meta property="article:modified_time" content="2024-07-10T21:38:08+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">MMII 的多模态医学图像交互框架：更直观地理解人体解剖结构和疾病</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p style="margin-left:.0001pt;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">        医生在诊断</span></span><span style="background-color:#ffffff;"><span style="color:#060607;">和治疗过程中依赖于人体解剖图像，如磁共振成像（MRI）</span></span><span style="background-color:#ffffff;"><span style="color:#060607;">，难以全面捕捉人体组织的复杂性，例如组织之间的空间关系、质地、大小等。</span></span><span style="background-color:#ffffff;"><span style="color:#060607;">然而，实时感知有关患者解剖结构和疾病的多模态信息对于医疗程序的成功和患者结果至关重要。</span></span><strong><u><span style="background-color:#ffffff;"><span style="color:#060607;"><strong><u>本文</u></strong></span></span></u></strong><strong><u><span style="background-color:#ffffff;"><span style="color:#060607;"><strong><u>介绍一个多模态医学图像交互（MMII）框架，允许医学专家在三维空间中与人体组织</u></strong></span></span></u></strong><u><span style="background-color:#ffffff;"><span style="color:#060607;"><u>进</u></span></span></u><u><span style="background-color:#ffffff;"><span style="color:#060607;"><u>行动态的视听交互。</u></span></span></u><span style="background-color:#ffffff;"><span style="color:#060607;">在虚拟现实环境中，用户接收到基于物理信息的视听反馈，以提高对解剖结构的空间感知。MMII使用基于模型的声音化方法，从组织的几何和物理属性生成声音，从而消除了手工制作声音设计的需要。</span></span></p> 
<p style="margin-left:.0001pt;text-align:justify;"><img alt="" height="394" src="https://images2.imgbox.com/d8/b0/1TW9Pq4U_o.png" width="830"></p> 
<h2 style="margin-left:.0001pt;text-align:justify;"><strong><span style="background-color:#ffffff;"><span style="color:#060607;"><strong>1 多模态MMII 框架</strong></span></span></strong></h2> 
<p style="margin-left:.0001pt;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">MMII 框架旨在通过多模态交互方式，帮助医疗专家更好地理解和感知人体解剖结构。该框架利用物理建模合成技术，将组织的物理属性和几何形状转换为音频信号，并与可视化模型相结合，为用户提供动态的音频视觉反馈。</span></span></p> 
<h3 style="margin-left:.0001pt;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">1.1 </span></span><span style="background-color:#ffffff;"><span style="color:#060607;">框架结构</span></span></h3> 
<p style="margin-left:.0001pt;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">MMII 框架包含以下几个关键模块：</span></span></p> 
<ul><li style="text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">可视化模型：该模型将医学图像数据转换为 3D 模型，并通过缩放、颜色变化等方式提供视觉反馈。</span></span></li><li style="text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">交互模块：该模块负责接收用户输入，并根据用户与模型的交互方式生成音频视觉反馈。</span></span></li><li style="text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">声学模型：该模型根据组织的物理属性和几何形状生成声学模型，并通过物理建模合成技术生成音频信号。</span></span></li></ul> 
<p style="margin-left:.0001pt;text-align:justify;"><img alt="" height="373" src="https://images2.imgbox.com/87/14/D3W94HSq_o.png" width="830"></p> 
<h3 style="margin-left:.0001pt;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">1.2 </span></span><span style="background-color:#ffffff;"><span style="color:#060607;">工作原理</span></span></h3> 
<ul><li style="text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">用户通过交互模块与 3D 模型进行交互，例如点击或触摸模型。</span></span></li><li style="text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">交互模块将用户输入发送给声学模型，并触发声学模型的计算。</span></span></li><li style="text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">声学模型根据组织的物理属性和几何形状生成音频信号，并通过物理建模合成技术生成声音。</span></span></li><li style="text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">可视化模型根据用户输入和声学模型的输出提供视觉反馈，例如缩放、颜色变化等。</span></span></li><li style="text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">用户通过音频和视觉反馈，更好地感知和理解人体解剖结构。</span></span></li></ul> 
<h3 style="margin-left:.0001pt;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">1.3 </span></span><span style="background-color:#ffffff;"><span style="color:#060607;">框架优势</span></span></h3> 
<ul><li style="text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">多模态交互：MMII 框架利用音频和视觉两种模态，为用户提供更丰富的信息，并帮助用户更好地理解和感知人体解剖结构。</span></span></li><li style="text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">物理信息：MMII 框架基于组织的物理属性和几何形状生成音频信号，使声音更具有真实感和直观性。</span></span></li><li style="text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">动态反馈：MMII 框架可以实时生成音频视觉反馈，帮助用户动态地感知和理解人体解剖结构的变化。</span></span></li><li style="text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">易于学习和理解：MMII 框架的用户研究结果表明，用户可以快速学习和理解解剖结构的音频视觉对应关系。</span></span></li></ul> 
<h3 style="margin-left:.0001pt;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">1.4 </span></span><span style="background-color:#ffffff;"><span style="color:#060607;">应用场景</span></span></h3> 
<p style="margin-left:.0001pt;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">MMII 框架可以应用于多种医学场景，例如：</span></span></p> 
<ul><li style="text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">手术导航：MMII 框架可以帮助医生在手术过程中更好地定位和识别解剖结构，从而提高手术精度和安全性。</span></span></li><li style="text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">放射治疗计划：MMII 框架可以帮助医生更好地理解肿瘤的位置和形状，从而制定更精准的放射治疗方案。</span></span></li><li style="text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">医学教育：MMII 框架可以帮助医学生更好地理解和学习人体解剖结构。</span></span></li></ul> 
<h3 style="margin-left:.0001pt;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">1.5 </span></span><span style="background-color:#ffffff;"><span style="color:#060607;">未来展望</span></span></h3> 
<ul><li style="text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">更多解剖结构：未来研究可以将 MMII 框架应用于更多人体解剖结构，例如心脏、肺部等。</span></span></li><li style="text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">更精细的物理模型：未来研究可以进一步改进物理模型，使其更精细、更准确。</span></span></li><li style="text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">更复杂的交互方式：未来研究可以探索更复杂的交互方式，例如手势识别、语音识别等。</span></span></li><li style="text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">与生理数据结合：未来研究可以将 MMII 框架与生理数据结合，例如心电图、血压等，为用户提供更全面的医学信息。</span></span></li></ul> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<h2 style="margin-left:.0001pt;text-align:justify;"><strong><span style="background-color:#ffffff;"><span style="color:#060607;"><strong>2 实验</strong></span></span></strong></h2> 
<h3 style="margin-left:.0001pt;text-align:justify;"><strong><span style="background-color:#ffffff;"><span style="color:#060607;"><strong>2.1 实验1：</strong></span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#060607;"><strong>多模态对应关系学习</strong></span></span></strong></h3> 
<ul><li style="text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">研究目的：评估用户学习将视觉解剖结构表示与其听觉提示关联的能力。</span></span></li><li style="text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">实验方法：进行了一项在线问卷调查，参与者通过视频和声音片段模拟 MMII 交互。</span></span></li><li style="text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">实验参与者：34 名志愿者，包括具有医学和非医学背景的人。</span></span></li><li style="text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">实验结果：</span></span></li></ul> 
<p style="margin-left:.0001pt;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">用户能够有效地将视觉和听觉表示的解剖结构进行关联，正确率显著提高（p &lt; 0.001）。</span></span></p> 
<p style="margin-left:.0001pt;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">物理建模合成是创建解剖结构的可区分听觉表示的合适方法。</span></span></p> 
<p style="margin-left:.0001pt;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">与视觉反馈相比，参与者在使用听觉反馈时感知到的任务负荷更低，表现更好，但认知负荷更高。</span></span></p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<h3 style="margin-left:.0001pt;text-align:justify;"><strong><span style="background-color:#ffffff;"><span style="color:#060607;"><strong>2.2 实验2：</strong></span></span></strong><strong><span style="background-color:#ffffff;"><span style="color:#060607;"><strong>多模态脑肿瘤定位</strong></span></span></strong></h3> 
<ul><li style="text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">研究目的：评估 MMII 在脑肿瘤定位等医学任务中的可用性和准确性。</span></span></li><li style="text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">实验方法：开发了一个 VR 应用程序，让神经外科医生和神经放射科医生使用常规视觉交互和 MMII 进行脑肿瘤定位。</span></span></li><li style="text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">实验参与者：9 名医学专家，包括神经外科医生和神经放射科医生。</span></span></li><li style="text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">实验结果：</span></span></li></ul> 
<p style="margin-left:.0001pt;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">与视觉反馈相比，使用 MMII 的脑肿瘤定位精度显著提高（p &lt; 0.05）。</span></span></p> 
<p style="margin-left:.0001pt;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">任务负荷没有显著差异，使用多模态交互时任务时间略有增加。</span></span></p> 
<p style="margin-left:.0001pt;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">参与者普遍认为 MMII 有助于更好地感知距离，并偏好使用听觉反馈。</span></span></p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<h3 style="margin-left:.0001pt;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">2.3 实验结果</span></span></h3> 
<ul><li style="text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">学习效果：两个</span></span><span style="background-color:#ffffff;"><span style="color:#060607;">实验</span></span><span style="background-color:#ffffff;"><span style="color:#060607;">都表明，用户可以有效地学习将视觉和听觉表示的解剖结构进行关联。</span></span></li><li style="text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">听觉反馈的优势：听觉反馈可以提供关于解剖结构的几何形状、纹理和大小等详细信息，有助于更好地感知距离和空间关系。</span></span></li><li style="text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">任务负荷：使用 MMII 可以降低任务负荷，提高任务表现，但可能需要更高的认知负荷。</span></span></li><li style="text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">准确性：使用 MMII 可以提高医学任务的准确性，例如脑肿瘤定位。</span></span></li><li style="text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#060607;">适用性：MMII 可以应用于各种医学任务，并有望提高手术精度和患者预后。</span></span></li></ul>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/48843f9826eeebb89f9799e1e9015fee/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【人工智能】Transformers之Pipeline（概述）：30w&#43;大模型极简应用</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/5e661c4e376b7e8bbdab97f2f5cf7d76/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">C&#43;&#43;：缺省参数|函数重载|引用|const引用</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>