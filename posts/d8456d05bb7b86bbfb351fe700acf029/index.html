<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>秋叶大佬24年最新的Stable Diffusion整合包V4.8来了～ - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/d8456d05bb7b86bbfb351fe700acf029/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="秋叶大佬24年最新的Stable Diffusion整合包V4.8来了～">
  <meta property="og:description" content="要说今年绘画圈最大的新秀
那妥妥的就Stable Diffution
V4升级版无需安装**，直接解压就能用**
*（在此要感谢秋葉aaaki大佬的分享！*）
比之前推送的更加智能、快速和简单
有多简单呢？这么说吧
之前的版本需要初中生级别
现在的V4加强版小学生也能上手！
SD安装包获取
1
背景信息 ▍****Stable Diffusion 是什么？ Stable Diffusion（简称SD）是一种生成式人工智能，于2022年发布，主要用于根据文本描述生成详细图像，也可用于其他任务，如图像的修补、扩展和通过文本提示指导图像到图像的转换。除图像外，您还可以使用该模型创建视频和动画。
这是AI绘画第一次能在可以在消费级显卡上运行，任何人都可以下载模型并生成自己的图像。另外，SD高质量的成图以及强大的自由度（自定义、个性化）受到诸多网友的追捧。Stable
Diffusion XL 1.0 (SDXL 1.0) 是Stable Diffusion的一个更为高级和优化的版本，它在模型规模、图像质量、语言理解和模型架构等方面都有显著的改进。
▍****Stable Diffusion 能做什么？ 首先，大家在入坑SD前，务必要清楚现阶段的SD到底能做什么？能否满足自己的需求？
Stable Diffusion 功能包括文本转图像、图像转图像、图形插图、图像编辑和视频创作。
**文本转图像生成：**最常见和最基础的功能。Stable Diffusion 会根据文本提示生成图像。图像转图像生成使用输入图像和文本提示，您可以根据输入图像创建新图像。典型的案例是使用草图和合适的提示。创作图形、插图和徽标使用一系列提示，可以创建各种风格的插图、图形和徽标。图像编辑和修正可以使用 Stable Diffusion 来编辑和修正照片。例如，可以修复旧照片、移除图片中的对象、更改主体特征以及向图片添加新元素。视频创作使用 GitHub 中的 Deforum 等功能，可以借助 Stable Diffusion 创作短视频片段和动画。另一种应用是为电影添加不同的风格。 还可以通过营造运动印象（例如流水）来为照片制作动画。 2
安装和部署Stable Diffusion **
**
介绍如何安装和部署Stable Diffusion。我使用的是秋葉aaaki的整合包，文章末尾提供180G整合包～
**
**
电脑系统：Windows10及以上/macOS Monterey (12.5)。
显卡：RTX3060及以上。
显存：8G及以上。
内存：16G及以上。
磁盘空间：500 SSD及以上
▍****操作步骤 步骤一：右键解压Stable Diffusion安装包。
步骤二：双击Stable Diffusion安装包进入文件夹中，解压sd-webui-aki-v4.2。
步骤三：双击启动器运行依赖-dotnet-6.0.11，安装所需依赖。">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-07-19T10:34:40+08:00">
    <meta property="article:modified_time" content="2024-07-19T10:34:40+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">秋叶大佬24年最新的Stable Diffusion整合包V4.8来了～</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>要说今年绘画圈最大的新秀</p> 
<p>那妥妥的就Stable Diffution</p> 
<p><strong>V4升级版无需安装</strong>**，直接解压就能用**</p> 
<p><strong><em>*（在此要感谢秋葉aaaki大佬的分享！*</em>）</strong></p> 
<p>比之前推送的更加智能、快速和简单</p> 
<p>有多简单呢？这么说吧</p> 
<p>之前的版本需要初中生级别</p> 
<p>现在的V4加强版小学生也能上手！</p> 
<p><strong>SD安装包获取</strong><br> <img src="https://images2.imgbox.com/b7/d8/JFlSgoTe_o.jpg" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/af/53/hCA4Nsr1_o.png" alt="图片"></p> 
<p>1</p> 
<h2><a id="_29"></a><strong>背景信息</strong></h2> 
<h3><a id="_31"></a></h3> 
<h3><a id="Stable_Diffusion__33"></a><strong>▍****Stable Diffusion 是什么？</strong></h3> 
<p>Stable Diffusion（简称SD）是一种生成式人工智能，于2022年发布，主要用于根据文本描述生成详细图像，也可用于其他任务，如图像的修补、扩展和通过文本提示指导图像到图像的转换。除图像外，您还可以使用该模型创建视频和动画。</p> 
<p>这是AI绘画第一次能在可以在消费级显卡上运行，任何人都可以下载模型并生成自己的图像。另外，SD高质量的成图以及强大的自由度（自定义、个性化）受到诸多网友的追捧。Stable</p> 
<p>Diffusion XL 1.0 (SDXL 1.0) 是Stable Diffusion的一个更为高级和优化的版本，它在模型规模、图像质量、语言理解和模型架构等方面都有显著的改进。</p> 
<h3><a id="_41"></a></h3> 
<h3><a id="Stable_Diffusion__43"></a><strong>▍****Stable Diffusion 能做什么？</strong></h3> 
<p>首先，大家在入坑SD前，务必要清楚现阶段的SD到底能做什么？能否满足自己的需求？</p> 
<p>Stable Diffusion 功能包括文本转图像、图像转图像、图形插图、图像编辑和视频创作。</p> 
<ul><li>**文本转图像生成：**最常见和最基础的功能。Stable Diffusion 会根据文本提示生成图像。</li><li><strong>图像转图像生成</strong>使用输入图像和文本提示，您可以根据输入图像创建新图像。典型的案例是使用草图和合适的提示。</li><li><strong>创作图形、插图和徽标</strong>使用一系列提示，可以创建各种风格的插图、图形和徽标。</li><li><strong>图像编辑和修正</strong>可以使用 Stable Diffusion 来编辑和修正照片。例如，可以修复旧照片、移除图片中的对象、更改主体特征以及向图片添加新元素。</li><li><strong>视频创作</strong>使用 GitHub 中的 Deforum 等功能，可以借助 Stable Diffusion 创作短视频片段和动画。另一种应用是为电影添加不同的风格。 还可以通过营造运动印象（例如流水）来为照片制作动画。</li></ul> 
<p>2</p> 
<h2><a id="Stable_Diffusion_59"></a><strong>安装和部署Stable Diffusion</strong></h2> 
<p>**<br> **</p> 
<p><strong>介绍如何安装和部署Stable Diffusion。我使用的是秋葉aaaki的整合包，文章末尾提供180G整合包～</strong></p> 
<p>**<br> **</p> 
<p>电脑系统：Windows10及以上/macOS Monterey (12.5)。<br> 显卡：RTX3060及以上。<br> 显存：8G及以上。<br> 内存：16G及以上。<br> 磁盘空间：500 SSD及以上</p> 
<h3><a id="_77"></a><strong>▍****操作步骤</strong></h3> 
<p><strong>步骤一</strong>：右键解压Stable Diffusion安装包。</p> 
<p><img src="https://images2.imgbox.com/54/53/dpECV5lJ_o.png" alt="图片"></p> 
<p><strong>步骤二</strong>：双击<strong>Stable Diffusion安装包</strong>进入文件夹中，解压<strong>sd-webui-aki-v4.2</strong>。</p> 
<p><img src="https://images2.imgbox.com/ee/70/6zJEuZex_o.png" alt="图片"></p> 
<p><strong>步骤三</strong>：双击<strong>启动器运行依赖-dotnet-6.0.11</strong>，安装所需依赖。</p> 
<p><img src="https://images2.imgbox.com/11/d2/czcRFoqn_o.png" alt="图片"></p> 
<p><strong>步骤四</strong>：双击<strong>sd-webui-aki-v4.xx</strong>进入该文件夹中，下拉找到<strong>A启动器</strong>并启动。</p> 
<blockquote> 
 <p>注：第一次启动，需要一些时间部署Python和Git环境，请耐心等待，后面启动就很快了。若未弹出WebUI界面，请将复制链接：http://127.0.0.1:7860 到浏览器中即可。</p> 
</blockquote> 
<p><img src="https://images2.imgbox.com/4a/c5/iOCUrSBs_o.png" alt="图片"></p> 
<p>若弹出Stable Diffusion WebUI界面，则表示启动成功。</p> 
<p><img src="https://images2.imgbox.com/0b/60/GzoAkg1t_o.png" alt="图片"></p> 
<p>3</p> 
<h2><a id="Stable_Diffusion_105"></a><strong>Stable Diffusion教程与模型</strong></h2> 
<p><img src="https://images2.imgbox.com/07/bc/njxTzhgR_o.png" alt="图片"></p> 
<h2><a id="Stable_Diffusion_WebUI_109"></a><strong>Stable Diffusion WebUI界面介绍</strong></h2> 
<h3><a id="Stable_Diffusion_WebUI__113"></a>**<em>*▍*<em>Stable Diffusion WebUI</em></em> <strong>介绍</strong></h3> 
<p>\1. Stable Diffusion WebUI界面主要分为三个区域：<strong>模型选择区</strong>、<strong>功能选择区</strong>、<strong>参数配置区</strong>。</p> 
<p><img src="https://images2.imgbox.com/9a/24/p4dbUCWA_o.png" alt="图片"></p> 
<p>\2. 里面的参数非常多，第一次看到定会眼花缭乱，我对此进行了一次归类分组，这些参数主要分为两类：</p> 
<p><strong>一是</strong>为了告诉AI，用户的需求是什么，进而完成作图任务，称为<strong>基础参数</strong>。如提示词框、模型选择，迭代步数，采样器，图片尺寸等。</p> 
<p><strong>二是</strong>为了高效率地完成这个任务而存在的参数，称为<strong>额外参数</strong>，是非必要的参数。如垃圾桶，一键清除提示词、文件夹、打包下载、预设样式等。</p> 
<p>那么，现在我们在看到某个参数时就知道它大致的作用是什么了。</p> 
<p><img src="https://images2.imgbox.com/28/35/PpE9e9cT_o.png" alt="图片"></p> 
<h3><a id="Stable_Diffusion__129"></a><strong>Stable Diffusion 布局/参数介绍</strong></h3> 
<p>接下来我将依次介绍Stable Diffusion文生图功能中的参数，指导用户快速了解和使用这些参数，以便更好地出图。</p> 
<blockquote> 
 <p>注：1. 这里的参数介绍只起到<strong>指导性作用</strong>，若想进一步了解各个参数的细节和原理，请阅读后续的文章。2. 由于这是整合包相比较原生的Stable Diffusion安装包，功能较多，且已经汉化了。</p> 
</blockquote> 
<h4><a id="_135"></a><strong>模型选择区</strong></h4> 
<p><img src="https://images2.imgbox.com/94/09/FM7wKxyD_o.png" alt="图片"></p> 
<p><strong>1. Stable Diffusion模型</strong>：下拉选择大模型，默认<strong>anyting-V5模型</strong>。请根据自身需求选择不同类型的模型，如现实主义风格的模型；动漫，二次元风格的模型。</p> 
<p><strong>2. 外挂VAE模型</strong>：下拉选择VAE模型，默认<strong>无</strong>。是可选操作，可以选择不同效果的VAE模型，对成图细节或颜色进行修复，同时选择VAE也可以起到节省电脑算力的作用。</p> 
<p><strong>3. CLIP终止层数（Clip Skip）</strong>：滑动确认或输入层数，层数范围为1~12层，默认层数为<strong>2</strong>。1层，成图更加精确；2层，成图更加平衡，即AI遵循提示词，也有一定自己的创意；3-12层，成图更加有创意。<strong>这里推荐2层</strong>。若你希望AI更加有自己的创意，还是请调节<strong>提示词引导系数（CFG Scale</strong>）参数，效果会更好。</p> 
<blockquote> 
 <p>注：选择模型时，需要提前下载模型并存储到对应的路径中。模型下载可前往：huggingface网站或Civital网站。Stable Diffusion模型存储位置是：<code>*\models\Stable-diffusion</code>。VAE模型存储位置是：<code>*\models\VAE</code>。存储完后，点击“🔄”即可。</p> 
</blockquote> 
<h4><a id="_149"></a><strong>功能配置区</strong></h4> 
<p><img src="https://images2.imgbox.com/8b/d5/JogyV6nr_o.png" alt="图片"></p> 
<h4><a id="_155"></a><strong>参数配置区</strong></h4> 
<p>简单介绍各个参数信息，分为基础参数、额外参数以及老版本的参数。 <img src="https://images2.imgbox.com/95/75/U4QDx8vt_o.png" alt="图片"></p> 
<h5><a id="_159"></a></h5> 
<h5><a id="_161"></a><strong>基础参数</strong></h5> 
<p><strong>1. 正向提示词（Prompt）</strong>：输入你希望图片中出现什么内容。仅支持英文输入。</p> 
<p><strong>2. 反向提示词（Negative prompt）</strong>：输入你不希望图片中出现什么内容，比如多手指。仅支持英文输入。</p> 
<p><strong>3. 迭代步数（Sampling Steps）</strong>：设置图片去噪的步数，步数越多画面越精细，出图时间也越长。步数范围1～150步，1～19步更加模糊，粗糙；20～40步，更加平衡；40～150步更加精细。其中并不是步数越多越好，为了避免过犹不及，这里<strong>推荐20～40步，更加平衡</strong>。</p> 
<p><strong>4. 采样方法（Sampler Method）</strong>：点击勾选采样方法。不同的采样方法，有不同效果，这里大家多次尝试即可。</p> 
<p><strong>5. 高分辨率修复（Hires. fix</strong>）：勾选即可将图片的分辨率放大。如从512<em>512px到1024</em>1024。</p> 
<p>请根据自身显卡性能，设置图片基础分辨率，请勿设置的过高，否则在勾选<strong>高分辨率修复</strong>后，会显示：Out Of Memory Error，爆显存了。</p> 
<p><strong>6. Refiner</strong>：待补充。</p> 
<p><strong>7. 尺寸（宽度、高度）</strong>：设置成图的尺寸。默认512<em>512px。推荐的尺寸有：512</em>768px、768<em>512px、768</em>1152。</p> 
<p><strong>8. 总批次数</strong>：指一次生成图片多少张，这里指陆续跑图。根据显卡性能，酌情设置，推荐1~4。</p> 
<p><strong>9. 单批数量</strong>：指一次同时生成几张图片，这里指同时跑图。显卡压力更大，不建议设置为2以上。</p> 
<p><strong>10. 提示词引导系数（CFG Scale）</strong>：AI遵循提示词的程度/成图与提示词相关度。数值越低更加精确，越高则更有创造力，这里推荐<strong>5~7更加平衡</strong>。</p> 
<blockquote> 
 <p>注：该参数类似于New Bing对话框中的选择对话样式，分为更有创造力、更平衡、更精确。提示词引导系数（CFG Scale）则是以具体的数值来供用户设置。</p> 
 <p><img src="https://images2.imgbox.com/95/24/XntbBK3O_o.png" alt="图片"></p> 
</blockquote> 
<p><strong>11. 随机种子数（Seed）</strong>：设置成图是否随机。文本框默认-1，表示随机产生不同的图片。点击“🎲”将随机种子设置为-1；点击“♻️”将成图的种子数（即唯一编码），设置为随机种子数，在其他参数不变的情况下生成的图片相似99%；点击“⏹️”则是进行更多设置。</p> 
<p><strong>12. 脚本（Script）</strong>：一键测试提示词或各个参数变化对成图的影响。选项默认<strong>无</strong>，分为<strong>提示词矩阵</strong>、<strong>从文本框或文件载入提示词</strong>、<strong>X/Y/Z图表</strong>、<strong>controlnet m2m</strong>。</p> 
<p><img src="https://images2.imgbox.com/30/26/bAjX31Na_o.png" alt="图片"></p> 
<p>这里直接将该软件分享出来给大家吧~</p> 
<h4><a id="1stable_diffusion_199"></a>1.stable diffusion安装包</h4> 
<p>随着技术的迭代，目前 Stable Diffusion 已经能够生成非常艺术化的图片了，完全有赶超人类的架势，已经有不少工作被这类服务替代，比如制作一个 logo 图片，画一张虚拟老婆照片，画质堪比相机。</p> 
<p>最新 Stable Diffusion 除了有win多个版本，就算说底端的显卡也能玩了哦！此外还带来了Mac版本，<strong>仅支持macOS 12.3或更高版本</strong>。</p> 
<p><img src="https://images2.imgbox.com/b3/30/u3S9TBVn_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="2stable_diffusion_207"></a>2.stable diffusion视频合集</h4> 
<p>我们在学习的时候，往往书籍源码难以理解，阅读困难，这时候视频教程教程是就很适合了，生动形象加上案例实战，一步步带你入坑stable diffusion，科学有趣才能更方便的学习下去。</p> 
<p><img src="https://images2.imgbox.com/12/91/B1KDNmO1_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="3stable_diffusion_213"></a>3.stable diffusion模型下载</h4> 
<p>stable diffusion往往一开始使用时图片等无法达到理想的生成效果，这时则需要通过使用大量训练数据，调整模型的超参数（如学习率、训练轮数、模型大小等），可以使得模型更好地适应数据集，并生成更加真实、准确、高质量的图像。</p> 
<p><img src="https://images2.imgbox.com/f7/f5/PGdlwNSr_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="4stable_diffusion_219"></a>4.stable diffusion提示词</h4> 
<p>提示词是构建由文本到图像模型解释和理解的单词的过程。可以把它理解为你告诉 AI 模型要画什么而需要说的语言，整个SD学习过程中都离不开这本提示词手册。</p> 
<p><img src="https://images2.imgbox.com/11/08/XrRSAeiD_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="5SD0_225"></a>5.SD从0到落地实战演练</h4> 
<p><img src="https://images2.imgbox.com/5f/dc/Ou2aBNys_o.png" alt="在这里插入图片描述"></p> 
<p>如果你能在15天内完成所有的任务，那你堪称天才。然而，如果你能完成 60-70% 的内容，你就已经开始具备成为一名SD大神的正确特征了。</p> 
<p>这份完整版的stable diffusion资料我已经打包好，需要的点击下方插件，即可前往免费领取！</p> 
<p><img src="https://images2.imgbox.com/26/79/ajRRc7rT_o.jpg" alt="在这里插入图片描述"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/ba0a5359cd1b21af0651b537e377134f/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">51.2T 800G 以太网交换机，赋能AI开放生态</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/b476b0694407c8807c4c9cc12c18ea27/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">AI让老照片动起来，日赚500&#43;，爆火项目拆解近，AI技术让老照片动起来火爆网络。</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>