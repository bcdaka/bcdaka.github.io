<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【AI工具】LM Studio 部署本地llama3以及python调用openai的API与llama3本地服务器进行问答... - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/0a24a488287f1e2ed8327d592a33ba1b/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="【AI工具】LM Studio 部署本地llama3以及python调用openai的API与llama3本地服务器进行问答...">
  <meta property="og:description" content="1. 下载LM Studio
https://lmstudio.ai/
2. 安装后打开主界面
3. 下载自己感兴趣的大模型
由于网络原因，通过IDM手动下载后拷贝到相应文件夹下
点击下载后，左下角点击“ 1 downloading”可以查看详情
从详情中提取出模型下载地址然后手动下载，比如“https://huggingface.co/TheBloke/phi-2-GGUF/resolve/main/phi-2.Q4_K_S.gguf”
下载完毕后，将模型拷贝到 模型文件夹所在目录，新建两级目录，参考下图：
以模型下载网址“https://huggingface.co/TheBloke/phi-2-GGUF/resolve/main/phi-2.Q4_K_S.gguf”为例，新建 “TheBloke”文件夹，然后在里面新建 “phi-2-GGUF”文件夹，最后把 模型文件“phi-2.Q4_K_S.gguf”拷贝到 “phi-2-GGUF”文件夹。
之后就可以打开聊天界面，加载模型后聊天了
4. 启动本地服务器
5. 使用 OpenAI 的 Python API 来与一个智能助手进行终端聊天
# 在终端中与智能助手聊天 from openai import OpenAI # 指向本地服务器 client = OpenAI(base_url=&#34;http://localhost:1234/v1&#34;, api_key=&#34;lm-studio&#34;) # 初始化历史记录列表，其中包含系统和用户的角色和内容 history = [ {&#34;role&#34;: &#34;system&#34;, &#34;content&#34;: &#34;你是一个聪明的助手。你总是提供合理、准确且有帮助的答案。总是用中文简体回答&#34;}, {&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;你好，向第一次开启这个程序的人介绍你自己。请简洁明了。请用中文回答&#34;}, ] # 使用while循环不断地接收用户输入并提供回答 while True: # 创建聊天完成请求，指定模型、历史消息和其他参数 completion = client.chat.completions.create( model=&#34;zhouzr/Llama3-8B-Chinese-Chat-GGUF&#34;, messages=history, temperature=0.7, stream=True, ) # 初始化新消息字典，用于存储助手的回答 new_message = {&#34;">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-04-23T19:30:41+08:00">
    <meta property="article:modified_time" content="2024-04-23T19:30:41+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【AI工具】LM Studio 部署本地llama3以及python调用openai的API与llama3本地服务器进行问答...</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div id="js_content"> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/e6/d2/suauSLAF_o.png" alt="0a38c796db1ce1c7cdfb0208e4621af9.png"></p> 
 <p><strong>1. 下载LM Studio</strong></p> 
 <p>https://lmstudio.ai/</p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/50/59/4mMq1xq2_o.png" alt="1ad7d093b91cbae271cc11904782afe2.png"></p> 
 <p><strong>2. 安装后打开主界面</strong><br></p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/5c/13/SS0vyMr5_o.png" alt="d5e472b7adcabe2fea1fe0a2779e86b3.png"></p> 
 <p><strong>3. 下载自己感兴趣的大模型</strong></p> 
 <p>由于网络原因，通过IDM手动下载后拷贝到相应文件夹下<br></p> 
 <p>点击下载后，左下角点击“ 1 downloading”可以查看详情</p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/89/9e/1FNQ4jCB_o.png" alt="b9475c9ac0484dd5a52c2d4c7abd22bc.png"></p> 
 <p>从详情中提取出模型下载地址然后手动下载，比如“https://huggingface.co/TheBloke/phi-2-GGUF/resolve/main/phi-2.Q4_K_S.gguf”</p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/44/bb/fncMqOHi_o.png" alt="daddc4aafc70b405e74efc81741808dc.png"></p> 
 <p>下载完毕后，将模型拷贝到 模型文件夹所在目录，新建两级目录，参考下图：</p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/3a/6f/UP208u7N_o.png" alt="25991d1a32881f91ea528235feed4a94.png"></p> 
 <p>以模型下载网址“https://huggingface.co/TheBloke/phi-2-GGUF/resolve/main/phi-2.Q4_K_S.gguf”为例，新建 “TheBloke”文件夹，然后在里面新建 “phi-2-GGUF”文件夹，最后把 模型文件“phi-2.Q4_K_S.gguf”拷贝到 “phi-2-GGUF”文件夹。</p> 
 <p>之后就可以打开聊天界面，加载模型后聊天了<br></p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/61/cf/tiPlk1w8_o.png" alt="01f2fbf072b2a318de44b17e94c9121f.png"></p> 
 <p style="text-align:left;"><strong>4. 启动本地服务器</strong></p> 
 <p><img src="https://images2.imgbox.com/c9/7f/6NGQOWND_o.jpg" alt="7376f4e9bf4772602c92e37c367ce2e8.jpeg"></p> 
 <p><strong>5. 使用 </strong><strong><code>OpenAI</code> 的 Python API 来与一个智能助手进行终端聊天</strong></p> 
 <pre class="has"><code class="language-python"># 在终端中与智能助手聊天
from openai import OpenAI


# 指向本地服务器
client = OpenAI(base_url="http://localhost:1234/v1", api_key="lm-studio")


# 初始化历史记录列表，其中包含系统和用户的角色和内容
history = [
    {"role": "system", "content": "你是一个聪明的助手。你总是提供合理、准确且有帮助的答案。总是用中文简体回答"},
    {"role": "user", "content": "你好，向第一次开启这个程序的人介绍你自己。请简洁明了。请用中文回答"},
]


# 使用while循环不断地接收用户输入并提供回答
while True:
    # 创建聊天完成请求，指定模型、历史消息和其他参数
    completion = client.chat.completions.create(
        model="zhouzr/Llama3-8B-Chinese-Chat-GGUF",
        messages=history,
        temperature=0.7,
        stream=True,
    )


    # 初始化新消息字典，用于存储助手的回答
    new_message = {"role": "assistant", "content": ""}


    # 遍历完成请求的结果，并打印内容
    for chunk in completion:
        if chunk.choices[0].delta.content:
            print(chunk.choices[0].delta.content, end="", flush=True)
            new_message["content"] += chunk.choices[0].delta.content


    # 将新消息添加到历史记录列表中
    history.append(new_message)


    # 如果需要查看聊天历史，可以取消注释以下代码
    # import json
    # gray_color = "\033[90m"
    # reset_color = "\033[0m"
    # print(f"{gray_color}\n{'-'*20} History dump {'-'*20}\n")
    # print(json.dumps(history, indent=2))
    # print(f"\n{'-'*55}\n{reset_color}")


    # 打印空行，并将用户的新输入作为消息添加到历史记录列表中
    print()
    history.append({"role": "user", "content": input("&gt; ")})</code></pre> 
 <p>上代码段目的在于演示如何使用 <code>OpenAI</code> 的 Python API 来与一个智能助手进行终端聊天。</p> 
 <p>代码首先导入了 <code>openai</code> 包，并使用 <code>OpenAI</code> 类指向了一个本地服务器，同时提供了 API 密钥。</p> 
 <p>接下来定义了一个 <code>history</code> 数组来记录会话历史，这个历史包含系统的自我介绍及用户的第一条信息。</p> 
 <p>在 <code>while True</code> 循环中，使用 <code>client.chat.completions.create</code> 方法来生成聊天回复，并将该回复打印到终端。然后新的用户输入被附加到 <code>history</code> 数组中以用于下一轮会话的生成。</p> 
 <p>最后，有一段注释代码，如果取消注释，它将打印整个会话历史，使用了一些 ANSI 转义码来给输出文字加上灰色。</p> 
 <p>功能总结：</p> 
 <p>此代码段旨在展示<strong>如何通过调用 </strong><strong><code>OpenAI</code> 的 API 来实现在终端内的智能助手聊天功能</strong>。它通过维护会话历史记录来生成连贯的对话，并实时向用户展示聊天助手的回复。代码中的执行流程大致如下：</p> 
 <ol><li><p>导入模块和设置客户端。</p></li><li><p>定义会话历史记录。</p></li><li><p>通过无限循环等待用户输入。</p></li><li><p>使用 <code>OpenAI</code> API 根据历史记录生成回复。</p></li><li><p>打印回复并等待用户的下一条信息。</p></li></ol> 
 <p>此代码模拟的是一个简单的命令行聊天界面，在终端与用户实时交互。</p> 
</div>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/dd7c8f4aa2dfe66ee8c9847ed2d1b513/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【大数据实训】基于当当网图书信息的数据分析与可视化(八)</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/9ae558f166db564cf8335a33ab794300/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">uniapp vue 多端开发 超链接 打开浏览器 打开外部网站 支持小程序、H5、APP</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>