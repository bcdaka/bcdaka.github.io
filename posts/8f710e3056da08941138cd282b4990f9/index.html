<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Datawhale AI夏令营- 讯飞机器翻译挑战赛baseline解析 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/8f710e3056da08941138cd282b4990f9/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="Datawhale AI夏令营- 讯飞机器翻译挑战赛baseline解析">
  <meta property="og:description" content="讯飞机器翻译挑战赛题 赛题数据分析NLP前置知识GRUSeq2SeqEncoder编码器Decoder解码器 数据处理思路数据清洗构建数据集类型TranslateDataset 模型搭建和训练基于seq2seq 的模型基于transformer的模型训练代码 基于BLUE4的评估指标BLEU4 的计算步骤：举个例子：1. 分词：2. 计算n-gram匹配：3. 计算精确度：4. 计算加权几何平均：5. 计算惩罚因子BP：6. 计算最终的BLEU4分数： 实现代码 推理参考 赛题数据分析 在官方提供的数据集中,我们可以了解到:训练集又14w条数据,同时官方也提供了一个测试集给我们用来模型评估。同时还提供了一个术语词典,作为一些特殊词语的翻译对照表。
了解到这些信息后,我们可以下载这些数据看看这些数据怎样的。
我们打开训练集train.txt后发现,英文和中文通过制表符\t来分割,我们后续就可以每一行读取,然后通过\t划分来拿到中文数据和英文数据。这些后续会在数据处理部分说明
NLP前置知识 本次baseline用的是seq2seq的模型, 然后Encode和decode部分使用的是GRU模型。下面我将一一讲解这两种模型
GRU 在讲GRU之前,需要先补充一下RNN是什么。如下图:
RNN模型在每个时间步接收一个字的输入，生成隐藏状态和输出，再将隐藏状态与下一个字输入到模型中，重复此过程。
GRU（门控循环单元）是RNN的变体，能够有效捕捉长序列语义关联，缓解梯度消失或爆炸现象，其核心结构由更新门和重置门两部分组成。
如果看不懂的话,可以直接理解为GRU的输入,输出都和RNN是一致的,但是比RNN更加厉害。
Seq2Seq 结构图如下:
Seq2Seq由两个结构组成,分别是Encoder和Decoder块
Seq2Seq模型由两个主要部分组成：Encoder（编码器）和Decoder（解码器），两者均为GRU网络。以下是该模型的详细介绍：
Encoder编码器 输入序列：模型接收输入序列 x = [ x 1 , x 2 , x 3 , x 4 ] x = [x_1, x_2, x_3, x_4] x=[x1​,x2​,x3​,x4​]。GRU网络：输入序列逐步传递给GRU单元，每个输入 x i x_i xi​ 生成相应的隐藏状态 h i h_i hi​。 第一个GRU单元接收 x 1 x_1 x1​，生成隐藏状态 h 1 h_1 h1​。第二个GRU单元接收 x 2 x_2 x2​和 h 1 h_1 h1​，生成隐藏状态 h 2 h_2 h2​。如此反复，直到最后一个输入 x 4 x_4 x4​ 生成隐藏状态 h 4 h_4 h4​。 上下文向量：最后一个隐藏状态 h 4 h_4 h4​ 作为上下文向量 c c c，用于解码阶段。 Decoder解码器 初始状态：解码器的初始隐藏状态由编码器生成的上下文向量 c c c 初始化。GRU网络：解码器逐步生成输出序列 y = [ y 1 , y 2 , y 3 , y 4 ] y = [y_1, y_2, y_3, y_4] y=[y1​,y2​,y3​,y4​]。 解码器的第一个GRU单元接收上下文向量 c c c 和初始隐藏状态，生成第一个隐藏状态 h 1 ′ h&#39;_1 h1′​和输出 y 1 y_1 y1​。第二个GRU单元接收第一个隐藏状态 h 1 ′ h&#39;_1 h1′​，生成第二个隐藏状态 h 2 ′ h&#39;_2 h2′​ 和输出 y 2 y_2 y2​。如此反复，直到生成最后一个隐藏状态 h 4 ′ h&#39;_4 h4′​和输出 y 4 y_4 y4​。 过程描述">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-07-15T21:06:37+08:00">
    <meta property="article:modified_time" content="2024-07-15T21:06:37+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Datawhale AI夏令营- 讯飞机器翻译挑战赛baseline解析</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>讯飞机器翻译挑战赛题</h4> 
 <ul><li><a href="#_3" rel="nofollow">赛题数据分析</a></li><li><a href="#NLP_11" rel="nofollow">NLP前置知识</a></li><li><ul><li><a href="#GRU_13" rel="nofollow">GRU</a></li><li><a href="#Seq2Seq_25" rel="nofollow">Seq2Seq</a></li><li><ul><li><a href="#Encoder_31" rel="nofollow">Encoder编码器</a></li><li><a href="#Decoder_39" rel="nofollow">Decoder解码器</a></li></ul> 
  </li></ul> 
  </li><li><a href="#_53" rel="nofollow">数据处理思路</a></li><li><ul><li><a href="#_65" rel="nofollow">数据清洗</a></li><li><a href="#TranslateDataset_112" rel="nofollow">构建数据集类型TranslateDataset</a></li></ul> 
  </li><li><a href="#_181" rel="nofollow">模型搭建和训练</a></li><li><ul><li><a href="#seq2seq__182" rel="nofollow">基于seq2seq 的模型</a></li><li><a href="#transformer_283" rel="nofollow">基于transformer的模型</a></li><li><a href="#_289" rel="nofollow">训练代码</a></li></ul> 
  </li><li><a href="#BLUE4_373" rel="nofollow">基于BLUE4的评估指标</a></li><li><ul><li><a href="#BLEU4__377" rel="nofollow">BLEU4 的计算步骤：</a></li><li><a href="#_385" rel="nofollow">举个例子：</a></li><li><ul><li><a href="#1__392" rel="nofollow">1. 分词：</a></li><li><a href="#2_ngram_396" rel="nofollow">2. 计算n-gram匹配：</a></li><li><a href="#3__402" rel="nofollow">3. 计算精确度：</a></li><li><a href="#4__408" rel="nofollow">4. 计算加权几何平均：</a></li><li><a href="#5_BP_413" rel="nofollow">5. 计算惩罚因子BP：</a></li><li><a href="#6_BLEU4_416" rel="nofollow">6. 计算最终的BLEU4分数：</a></li></ul> 
   </li><li><a href="#_423" rel="nofollow">实现代码</a></li></ul> 
  </li><li><a href="#_517" rel="nofollow">推理</a></li><li><a href="#_581" rel="nofollow">参考</a></li></ul> 
</div> 
<p></p> 
<h2><a id="_3"></a>赛题数据分析</h2> 
<p><img src="https://images2.imgbox.com/3b/d1/wY7BwjdH_o.png" alt="在这里插入图片描述"><br> 在官方提供的数据集中,我们可以了解到:训练集又14w条数据,同时官方也提供了一个测试集给我们用来模型评估。同时还提供了一个术语词典,作为一些特殊词语的翻译对照表。</p> 
<p>了解到这些信息后,我们可以下载这些数据看看这些数据怎样的。<br> <img src="https://images2.imgbox.com/a9/02/IpsFDA0b_o.png" alt="在这里插入图片描述"><br> 我们打开训练集train.txt后发现,英文和中文通过制表符\t来分割,我们后续就可以每一行读取,然后通过\t划分来拿到中文数据和英文数据。这些后续会在数据处理部分说明</p> 
<h2><a id="NLP_11"></a>NLP前置知识</h2> 
<p>本次baseline用的是seq2seq的模型, 然后Encode和decode部分使用的是GRU模型。下面我将一一讲解这两种模型</p> 
<h3><a id="GRU_13"></a>GRU</h3> 
<p>在讲GRU之前,需要先补充一下RNN是什么。如下图:<br> <img src="https://images2.imgbox.com/e3/55/BOHm1NNr_o.png" alt="在这里插入图片描述"><br> RNN模型在每个时间步接收一个字的输入，生成隐藏状态和输出，再将隐藏状态与下一个字输入到模型中，重复此过程。<br> <img src="https://images2.imgbox.com/52/ee/Rr10AKab_o.png" alt="在这里插入图片描述"></p> 
<p>GRU（门控循环单元）是RNN的变体，能够有效捕捉长序列语义关联，缓解梯度消失或爆炸现象，其核心结构由更新门和重置门两部分组成。<br> <img src="https://images2.imgbox.com/11/da/LxwfeMei_o.png" alt="在这里插入图片描述"><br> 如果看不懂的话,可以直接理解为GRU的输入,输出都和RNN是一致的,但是比RNN更加厉害。</p> 
<h3><a id="Seq2Seq_25"></a>Seq2Seq</h3> 
<p>结构图如下:<br> <img src="https://images2.imgbox.com/1c/69/G7hXpZTf_o.png" alt=""><br> Seq2Seq由两个结构组成,分别是Encoder和Decoder块<br> Seq2Seq模型由两个主要部分组成：Encoder（编码器）和Decoder（解码器），两者均为GRU网络。以下是该模型的详细介绍：</p> 
<h4><a id="Encoder_31"></a>Encoder编码器</h4> 
<ol><li><strong>输入序列</strong>：模型接收输入序列 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          x 
         
        
          = 
         
        
          [ 
         
         
         
           x 
          
         
           1 
          
         
        
          , 
         
         
         
           x 
          
         
           2 
          
         
        
          , 
         
         
         
           x 
          
         
           3 
          
         
        
          , 
         
         
         
           x 
          
         
           4 
          
         
        
          ] 
         
        
       
         x = [x_1, x_2, x_3, x_4] 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">]</span></span></span></span></span>。</li><li><strong>GRU网络</strong>：输入序列逐步传递给GRU单元，每个输入 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           x 
          
         
           i 
          
         
        
       
         x_i 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5806em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span> 生成相应的隐藏状态<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           h 
          
         
           i 
          
         
        
       
         h_i 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>。 
  <ul><li>第一个GRU单元接收 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
        
         
          
           
           
             x 
            
           
             1 
            
           
          
         
           x_1 
          
         
       </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5806em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>，生成隐藏状态<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
        
         
          
           
           
             h 
            
           
             1 
            
           
          
         
           h_1 
          
         
       </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>。</li><li>第二个GRU单元接收 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
        
         
          
           
           
             x 
            
           
             2 
            
           
          
         
           x_2 
          
         
       </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5806em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>和<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
        
         
          
           
           
             h 
            
           
             1 
            
           
          
         
           h_1 
          
         
       </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>，生成隐藏状态<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
        
         
          
           
           
             h 
            
           
             2 
            
           
          
         
           h_2 
          
         
       </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>。</li><li>如此反复，直到最后一个输入<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
        
         
          
           
           
             x 
            
           
             4 
            
           
          
         
           x_4 
          
         
       </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5806em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span> 生成隐藏状态<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
        
         
          
           
           
             h 
            
           
             4 
            
           
          
         
           h_4 
          
         
       </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>。</li></ul> </li><li><strong>上下文向量</strong>：最后一个隐藏状态<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           h 
          
         
           4 
          
         
        
       
         h_4 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span> 作为上下文向量<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          c 
         
        
       
         c 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal">c</span></span></span></span></span>，用于解码阶段。</li></ol> 
<h4><a id="Decoder_39"></a>Decoder解码器</h4> 
<ol><li><strong>初始状态</strong>：解码器的初始隐藏状态由编码器生成的上下文向量 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          c 
         
        
       
         c 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal">c</span></span></span></span></span> 初始化。</li><li><strong>GRU网络</strong>：解码器逐步生成输出序列 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          y 
         
        
          = 
         
        
          [ 
         
         
         
           y 
          
         
           1 
          
         
        
          , 
         
         
         
           y 
          
         
           2 
          
         
        
          , 
         
         
         
           y 
          
         
           3 
          
         
        
          , 
         
         
         
           y 
          
         
           4 
          
         
        
          ] 
         
        
       
         y = [y_1, y_2, y_3, y_4] 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord mathnormal" style="margin-right: 0.0359em;">y</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">[</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">]</span></span></span></span></span>。 
  <ul><li>解码器的第一个GRU单元接收上下文向量 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
        
         
          
          
            c 
           
          
         
           c 
          
         
       </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal">c</span></span></span></span></span> 和初始隐藏状态，生成第一个隐藏状态<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
        
         
          
           
           
             h 
            
           
             1 
            
           
             ′ 
            
           
          
         
           h'_1 
          
         
       </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.2481em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.7519em;"><span class="" style="top: -2.4519em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2481em;"><span class=""></span></span></span></span></span></span></span></span></span></span>和输出<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
        
         
          
           
           
             y 
            
           
             1 
            
           
          
         
           y_1 
          
         
       </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>。</li><li>第二个GRU单元接收第一个隐藏状态<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
        
         
          
           
           
             h 
            
           
             1 
            
           
             ′ 
            
           
          
         
           h'_1 
          
         
       </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.2481em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.7519em;"><span class="" style="top: -2.4519em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2481em;"><span class=""></span></span></span></span></span></span></span></span></span></span>，生成第二个隐藏状态 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
        
         
          
           
           
             h 
            
           
             2 
            
           
             ′ 
            
           
          
         
           h'_2 
          
         
       </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.2481em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.7519em;"><span class="" style="top: -2.4519em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2481em;"><span class=""></span></span></span></span></span></span></span></span></span></span> 和输出 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
        
         
          
           
           
             y 
            
           
             2 
            
           
          
         
           y_2 
          
         
       </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>。</li><li>如此反复，直到生成最后一个隐藏状态 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
        
         
          
           
           
             h 
            
           
             4 
            
           
             ′ 
            
           
          
         
           h'_4 
          
         
       </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.2481em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.7519em;"><span class="" style="top: -2.4519em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2481em;"><span class=""></span></span></span></span></span></span></span></span></span></span>和输出<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
        
         
          
           
           
             y 
            
           
             4 
            
           
          
         
           y_4 
          
         
       </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>。</li></ul> </li></ol> 
<p>过程描述</p> 
<ol><li><strong>编码过程</strong>：输入序列 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          x 
         
        
       
         x 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span></span>被编码器处理，生成最终的上下文向量 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          c 
         
        
       
         c 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal">c</span></span></span></span></span>。</li><li><strong>解码过程</strong>：解码器利用上下文向量 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          c 
         
        
       
         c 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal">c</span></span></span></span></span>和初始状态生成目标输出序列<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          y 
         
        
       
         y 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord mathnormal" style="margin-right: 0.0359em;">y</span></span></span></span></span>。</li></ol> 
<p>此模型的目的是将一个序列（如一句话）转换为另一个序列（如另一种语言的翻译），其中编码器将输入序列编码为固定大小的上下文向量，解码器再将该向量解码为目标序列。Seq2Seq模型广泛应用于机器翻译、文本摘要等任务。</p> 
<h2><a id="_53"></a>数据处理思路</h2> 
<p>记住我们正常的神经网络是无法直接识别中文或者英文的字符串输入的。所以这一步我们的目标只有一个,那就是将数据变成神经网络可以识别到的数据类型。</p> 
<p>因此在这个阶段,我们要做的是:</p> 
<ol><li>数据清洗</li><li>构建数据集类型TranslateDataset</li><li>分词构建词表</li><li>将术语词典引入到训练集中</li></ol> 
<h3><a id="_65"></a>数据清洗</h3> 
<p>这一步baseline没有,个人自行扩充的,可以参考一下。</p> 
<p>我们在获取到数据集后,首先要做的就是一个数据探查任务。我们打开train.txt可以看到</p> 
<blockquote> 
 <p>There’s a tight and surprising link between the ocean’s health and ours, says marine biologist Stephen Palumbi. He shows how toxins at the bottom of the ocean food chain find their way into our bodies, with a shocking story of toxic contamination from a Japanese fish market. His work points a way forward for saving the oceans’ health – and humanity’s. <br> 生物学家史蒂芬·帕伦认为，海洋的健康和我们的健康之间有着紧密而神奇的联系。他通过日本一个渔场发生的让人震惊的有毒污染的事件，展示了位于海洋食物链底部的有毒物质是如何进入我们的身体的。他的工作主要是未来拯救海洋健康的方法——同时也包括人类的。</p> 
</blockquote> 
<p>There’s这些,如果我们直接构建词表的话,有可能出现分词为’的情况。所以我们要将这些There’s变成There is。<br> 除此之外,我们要删除一些特殊字符,只保留一些标点符号和数字等。代码如下:</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> contractions

<span class="token keyword">def</span> <span class="token function">unicodeToAscii</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token string">''</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>c <span class="token keyword">for</span> c <span class="token keyword">in</span> unicodedata<span class="token punctuation">.</span>normalize<span class="token punctuation">(</span><span class="token string">'NFD'</span><span class="token punctuation">,</span> text<span class="token punctuation">)</span> <span class="token keyword">if</span> unicodedata<span class="token punctuation">.</span>category<span class="token punctuation">(</span>c<span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token string">'Mn'</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">preprocess_en</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>
    text <span class="token operator">=</span> unicodeToAscii<span class="token punctuation">(</span>text<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    text <span class="token operator">=</span> contractions<span class="token punctuation">.</span>fix<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
    text <span class="token operator">=</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">r'\（[^）]*\）'</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">,</span> text<span class="token punctuation">)</span>
    text <span class="token operator">=</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">r"[^a-zA-Z0-9.!?]+"</span><span class="token punctuation">,</span> <span class="token string">r" "</span><span class="token punctuation">,</span> text<span class="token punctuation">)</span>  <span class="token comment"># 保留数字</span>
    <span class="token keyword">return</span> text
</code></pre> 
<p>处理后的数据</p> 
<blockquote> 
 <p>There is a tight and surprising link between the ocean s health and ours says marine biologist Stephen Palumbi . He shows how toxins at the bottom of the ocean food chain find their way into our bodies with a shocking story of toxic contamination from a Japanese fish market . His work points a way forward for saving the oceans health and humanity s .</p> 
</blockquote> 
<p>可以看出There’s 已经变成了There is了</p> 
<p>接着对中文数据进行处理。在中文数据中,经过探查,竟然发现有(掌声)这种不该出现在翻译文本中的脏数据。比如:</p> 
<blockquote> 
 <p>他指着我碗底的三粒米， 然后说"吃干净。" (笑声）<br> 他说，“如果你要回你的车，那么我就要tase(用高压眩晕枪射击）你<br> Okay. Good. 好，很好!(笑）<br> But many people see the same thing and think things differently, and one of them is here, Ratan Tata. 看到的是同样的东西， 但很多人的想法却不一样， 其中一个就是，Ratan Tata (Tata集团的现任主席）。</p> 
</blockquote> 
<p>这些脏数据可以使用正则表达式剔除,代码如下:</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">preprocess_zh</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 去除(掌声)这些脏数据</span>
    text <span class="token operator">=</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">r'\（[^）]*\）'</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">,</span> text<span class="token punctuation">)</span>
    text <span class="token operator">=</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">r"[^\u4e00-\u9fa5，。！？0-9]"</span><span class="token punctuation">,</span> <span class="token string">""</span><span class="token punctuation">,</span> text<span class="token punctuation">)</span>  <span class="token comment"># 保留数字</span>
    <span class="token keyword">return</span> text
</code></pre> 
<p>这一步操作虽然会删除一些可能真的需要()翻译的内容,但是也是小部分,比如:</p> 
<blockquote> 
 <p>Kary Mullis: They might have done it for the teddy bear, yeah. (Kary Mullis回答：）那他们可能也会吧。</p> 
</blockquote> 
<h3><a id="TranslateDataset_112"></a>构建数据集类型TranslateDataset</h3> 
<p>代码如下:</p> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">TranslationDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> filename<span class="token punctuation">,</span> terminology<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>filename<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
            <span class="token keyword">for</span> line <span class="token keyword">in</span> f<span class="token punctuation">:</span>
                en<span class="token punctuation">,</span> zh <span class="token operator">=</span> line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\t'</span><span class="token punctuation">)</span>
                self<span class="token punctuation">.</span>data<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>en<span class="token punctuation">,</span> zh<span class="token punctuation">)</span><span class="token punctuation">)</span>
        
        self<span class="token punctuation">.</span>terminology <span class="token operator">=</span> terminology
        
        <span class="token comment"># 创建词汇表，注意这里需要确保术语词典中的词也被包含在词汇表中</span>
        self<span class="token punctuation">.</span>en_tokenizer <span class="token operator">=</span> get_tokenizer<span class="token punctuation">(</span><span class="token string">'basic_english'</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>zh_tokenizer <span class="token operator">=</span> <span class="token builtin">list</span>  <span class="token comment"># 使用字符级分词</span>
        
        en_vocab <span class="token operator">=</span> Counter<span class="token punctuation">(</span>self<span class="token punctuation">.</span>terminology<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 确保术语在词汇表中</span>
        zh_vocab <span class="token operator">=</span> Counter<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
        <span class="token keyword">for</span> en<span class="token punctuation">,</span> zh <span class="token keyword">in</span> self<span class="token punctuation">.</span>data<span class="token punctuation">:</span>
            en_vocab<span class="token punctuation">.</span>update<span class="token punctuation">(</span>self<span class="token punctuation">.</span>en_tokenizer<span class="token punctuation">(</span>en<span class="token punctuation">)</span><span class="token punctuation">)</span>
            zh_vocab<span class="token punctuation">.</span>update<span class="token punctuation">(</span>self<span class="token punctuation">.</span>zh_tokenizer<span class="token punctuation">(</span>zh<span class="token punctuation">)</span><span class="token punctuation">)</span>
        
        <span class="token comment"># 添加术语到词汇表</span>
        self<span class="token punctuation">.</span>en_vocab <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'&lt;pad&gt;'</span><span class="token punctuation">,</span> <span class="token string">'&lt;sos&gt;'</span><span class="token punctuation">,</span> <span class="token string">'&lt;eos&gt;'</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token builtin">list</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>terminology<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">[</span>word <span class="token keyword">for</span> word<span class="token punctuation">,</span> _ <span class="token keyword">in</span> en_vocab<span class="token punctuation">.</span>most_common<span class="token punctuation">(</span><span class="token number">10000</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>zh_vocab <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'&lt;pad&gt;'</span><span class="token punctuation">,</span> <span class="token string">'&lt;sos&gt;'</span><span class="token punctuation">,</span> <span class="token string">'&lt;eos&gt;'</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">[</span>word <span class="token keyword">for</span> word<span class="token punctuation">,</span> _ <span class="token keyword">in</span> zh_vocab<span class="token punctuation">.</span>most_common<span class="token punctuation">(</span><span class="token number">10000</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
        
        self<span class="token punctuation">.</span>en_word2idx <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>word<span class="token punctuation">:</span> idx <span class="token keyword">for</span> idx<span class="token punctuation">,</span> word <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>en_vocab<span class="token punctuation">)</span><span class="token punctuation">}</span>
        self<span class="token punctuation">.</span>zh_word2idx <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>word<span class="token punctuation">:</span> idx <span class="token keyword">for</span> idx<span class="token punctuation">,</span> word <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>zh_vocab<span class="token punctuation">)</span><span class="token punctuation">}</span>


    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>data<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">:</span>
        en<span class="token punctuation">,</span> zh <span class="token operator">=</span> self<span class="token punctuation">.</span>data<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>
        en_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>en_word2idx<span class="token punctuation">.</span>get<span class="token punctuation">(</span>word<span class="token punctuation">,</span> self<span class="token punctuation">.</span>en_word2idx<span class="token punctuation">[</span><span class="token string">'&lt;sos&gt;'</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> word <span class="token keyword">in</span> self<span class="token punctuation">.</span>en_tokenizer<span class="token punctuation">(</span>en<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">[</span>self<span class="token punctuation">.</span>en_word2idx<span class="token punctuation">[</span><span class="token string">'&lt;eos&gt;'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        zh_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>zh_word2idx<span class="token punctuation">.</span>get<span class="token punctuation">(</span>word<span class="token punctuation">,</span> self<span class="token punctuation">.</span>zh_word2idx<span class="token punctuation">[</span><span class="token string">'&lt;sos&gt;'</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> word <span class="token keyword">in</span> self<span class="token punctuation">.</span>zh_tokenizer<span class="token punctuation">(</span>zh<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">[</span>self<span class="token punctuation">.</span>zh_word2idx<span class="token punctuation">[</span><span class="token string">'&lt;eos&gt;'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> en_tensor<span class="token punctuation">,</span> zh_tensor
</code></pre> 
<p>这个代码主要完成了以下几件事情:</p> 
<ol><li>读入了训练集的路径, 将训练集划分为中文和英文文本对</li><li>加载了术语词表</li><li>对中英文句子进行分词</li><li>构建词表(同时添加特殊符号进去词表)</li><li>构建继承了Dateset类所需要重写的函数__len__和__getitem__</li></ol> 
<p>通过这一步，我们可以构建一个数据集对象。这个对象包含了词表和数据内容。</p> 
<p>在我们的认知中，神经网络的输入通常是数字信息，那么如何将字符信息转化为数字信息呢？这时我们就需要用到词表。我们可以将句子进行分词，然后对照词表将每个词转化为对应的序号。例如：<br> 假设有以下句子：“我爱自然语言处理”。我们首先进行分词，得到 [“我”, “爱”, “自然”, “语言”, “处理”]。假设词表如下：</p> 
<table><thead><tr><th>词语</th><th>序号</th></tr></thead><tbody><tr><td>我</td><td>1</td></tr><tr><td>爱</td><td>2</td></tr><tr><td>自然</td><td>3</td></tr><tr><td>语言</td><td>4</td></tr><tr><td>处理</td><td>5</td></tr></tbody></table> 
<p>通过词表，我们可以将句子中的每个词转化为相应的数字序号，得到 [1, 2, 3, 4, 5]。这样，字符信息就成功地转化为神经网络可以处理的数字信息了。</p> 
<p>然后神经网络同样预测的也是数字,然后我们根据词表再将神经网络的输出转化为对应的语言。这就完成了预测过程。</p> 
<p>这一步在上面代码的__init__和__getitem__完成了</p> 
<h2><a id="_181"></a>模型搭建和训练</h2> 
<h3><a id="seq2seq__182"></a>基于seq2seq 的模型</h3> 
<p>我们使用的是Seq2Seq结构的模型,结构如图所示<br> <img src="https://images2.imgbox.com/dc/d1/fISUgrMI_o.png" alt=""><br> 两个模块:</p> 
<ol><li>Encoder模块</li><li>Decoder模块</li></ol> 
<p>每个模块中由一个GRU网络组成。</p> 
<p>这里的原理是Encoder将输入的英文的信息压缩成一个隐藏语义变量c,这个c大概可以理解为下图红框的内容:<br> <img src="https://images2.imgbox.com/a8/13/hQBHqsjx_o.png" alt="在这里插入图片描述"><br> 然后将c传入解码器Decoder后,解码器根据这个语义信息和来预测我们的中文。</p> 
<p>代码如下:</p> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">Encoder</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_dim<span class="token punctuation">,</span> emb_dim<span class="token punctuation">,</span> hid_dim<span class="token punctuation">,</span> n_layers<span class="token punctuation">,</span> dropout<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>input_dim<span class="token punctuation">,</span> emb_dim<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>rnn <span class="token operator">=</span> nn<span class="token punctuation">.</span>GRU<span class="token punctuation">(</span>emb_dim<span class="token punctuation">,</span> hid_dim<span class="token punctuation">,</span> n_layers<span class="token punctuation">,</span> dropout<span class="token operator">=</span>dropout<span class="token punctuation">,</span> batch_first<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>dropout<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> src<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># src shape: [batch_size, src_len]</span>
        embedded <span class="token operator">=</span> self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span>src<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment"># embedded shape: [batch_size, src_len, emb_dim]</span>
        outputs<span class="token punctuation">,</span> hidden <span class="token operator">=</span> self<span class="token punctuation">.</span>rnn<span class="token punctuation">(</span>embedded<span class="token punctuation">)</span>
        <span class="token comment"># outputs shape: [batch_size, src_len, hid_dim]</span>
        <span class="token comment"># hidden shape: [n_layers, batch_size, hid_dim]</span>
        <span class="token keyword">return</span> outputs<span class="token punctuation">,</span> hidden

<span class="token keyword">class</span> <span class="token class-name">Decoder</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> output_dim<span class="token punctuation">,</span> emb_dim<span class="token punctuation">,</span> hid_dim<span class="token punctuation">,</span> n_layers<span class="token punctuation">,</span> dropout<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>output_dim <span class="token operator">=</span> output_dim
        self<span class="token punctuation">.</span>embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>output_dim<span class="token punctuation">,</span> emb_dim<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>rnn <span class="token operator">=</span> nn<span class="token punctuation">.</span>GRU<span class="token punctuation">(</span>emb_dim<span class="token punctuation">,</span> hid_dim<span class="token punctuation">,</span> n_layers<span class="token punctuation">,</span> dropout<span class="token operator">=</span>dropout<span class="token punctuation">,</span> batch_first<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc_out <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hid_dim<span class="token punctuation">,</span> output_dim<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>dropout<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">,</span> hidden<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># input shape: [batch_size, 1]</span>
        <span class="token comment"># hidden shape: [n_layers, batch_size, hid_dim]</span>
        
        embedded <span class="token operator">=</span> self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>self<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment"># embedded shape: [batch_size, 1, emb_dim]</span>
        
        output<span class="token punctuation">,</span> hidden <span class="token operator">=</span> self<span class="token punctuation">.</span>rnn<span class="token punctuation">(</span>embedded<span class="token punctuation">,</span> hidden<span class="token punctuation">)</span>
        <span class="token comment"># output shape: [batch_size, 1, hid_dim]</span>
        <span class="token comment"># hidden shape: [n_layers, batch_size, hid_dim]</span>
        
        prediction <span class="token operator">=</span> self<span class="token punctuation">.</span>fc_out<span class="token punctuation">(</span>output<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment"># prediction shape: [batch_size, output_dim]</span>
        
        <span class="token keyword">return</span> prediction<span class="token punctuation">,</span> hidden
</code></pre> 
<p>然后将Encoder和Decoder拼接在一起,形成Seq2Seq结构</p> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">Seq2Seq</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> encoder<span class="token punctuation">,</span> decoder<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>encoder <span class="token operator">=</span> encoder
        self<span class="token punctuation">.</span>decoder <span class="token operator">=</span> decoder
        self<span class="token punctuation">.</span>device <span class="token operator">=</span> device

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> src<span class="token punctuation">,</span> trg<span class="token punctuation">,</span> teacher_forcing_ratio<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># src 的形状：[batch_size, src_len]</span>
        <span class="token comment"># trg 的形状：[batch_size, trg_len]</span>
        
        batch_size <span class="token operator">=</span> src<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>  <span class="token comment"># 获取批次大小</span>
        trg_len <span class="token operator">=</span> trg<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>  <span class="token comment"># 获取目标序列的长度</span>
        trg_vocab_size <span class="token operator">=</span> self<span class="token punctuation">.</span>decoder<span class="token punctuation">.</span>output_dim  <span class="token comment"># 获取目标词汇表的大小</span>

        <span class="token comment"># 初始化输出张量，形状为 [batch_size, trg_len, trg_vocab_size]</span>
        outputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> trg_len<span class="token punctuation">,</span> trg_vocab_size<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>self<span class="token punctuation">.</span>device<span class="token punctuation">)</span>
        
        <span class="token comment"># 将源序列输入编码器，获得隐藏状态</span>
        _<span class="token punctuation">,</span> hidden <span class="token operator">=</span> self<span class="token punctuation">.</span>encoder<span class="token punctuation">(</span>src<span class="token punctuation">)</span>
        
        <span class="token comment"># 取目标序列的第一个词作为解码器的初始输入，通常是开始标记</span>
        <span class="token builtin">input</span> <span class="token operator">=</span> trg<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># Start token</span>
        
        <span class="token comment"># 循环遍历目标序列长度，逐步生成输出</span>
        <span class="token keyword">for</span> t <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> trg_len<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># 将当前输入和隐藏状态输入解码器，获取输出和新的隐藏状态</span>
            output<span class="token punctuation">,</span> hidden <span class="token operator">=</span> self<span class="token punctuation">.</span>decoder<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> hidden<span class="token punctuation">)</span>
            <span class="token comment"># 将当前时间步的输出保存到 outputs 张量中</span>
            outputs<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> t<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> output
            <span class="token comment"># 确定是否使用教师强制</span>
            teacher_force <span class="token operator">=</span> random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> teacher_forcing_ratio
            <span class="token comment"># 获取输出中概率最高的词的索引</span>
            top1 <span class="token operator">=</span> output<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
            <span class="token comment"># 如果使用教师强制，下一步的输入为目标序列中的下一个词，否则使用当前时间步输出中概率最高的词</span>
            <span class="token builtin">input</span> <span class="token operator">=</span> trg<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> t<span class="token punctuation">]</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token keyword">if</span> teacher_force <span class="token keyword">else</span> top1<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>

        <span class="token keyword">return</span> outputs  <span class="token comment"># 返回所有时间步的输出</span>

</code></pre> 
<p>这样我们的Seq2Seq构建的模型已经完成</p> 
<p>由于Seq2Seq是NLP比较基础的一个模型,结构简单,无法并行处理。导致训练速度比较慢,而且效果可能比较智障。测了一下全部训练集跑20轮,大概要几小时。最后成绩只有不到2分。上限比较低。所以升级框架为transform框架</p> 
<h3><a id="transformer_283"></a>基于transformer的模型</h3> 
<p>后续补充…</p> 
<p>4090全数据训练了10个epoch,大概一个小时。效果能去到13.9分</p> 
<h3><a id="_289"></a>训练代码</h3> 
<p>就很经典的结构,流程如下:</p> 
<ol><li>通过dataloader拿到这一轮的训练数据</li><li>输入进去模型,得到预测结果</li><li>拿预测结果和目标句子做交叉熵损失</li><li>更新梯度</li><li>不断循环</li></ol> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> iterator<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> criterion<span class="token punctuation">,</span> clip<span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    epoch_loss <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>src<span class="token punctuation">,</span> trg<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>iterator<span class="token punctuation">)</span><span class="token punctuation">:</span>
        src<span class="token punctuation">,</span> trg <span class="token operator">=</span> src<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> trg<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        output <span class="token operator">=</span> model<span class="token punctuation">(</span>src<span class="token punctuation">,</span> trg<span class="token punctuation">)</span>
        output_dim <span class="token operator">=</span> output<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
        output <span class="token operator">=</span> output<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> output_dim<span class="token punctuation">)</span>
        trg <span class="token operator">=</span> trg<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>output<span class="token punctuation">,</span> trg<span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>clip_grad_norm_<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> clip<span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        epoch_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> epoch_loss <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>iterator<span class="token punctuation">)</span>
</code></pre> 
<p>main代码</p> 
<pre><code class="prism language-python"><span class="token comment"># 主函数</span>
<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    start_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 开始计时</span>

    device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cuda'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span><span class="token punctuation">)</span>

    <span class="token comment">#terminology = load_terminology_dictionary('../dataset/en-zh.dic')</span>
    terminology <span class="token operator">=</span> load_terminology_dictionary<span class="token punctuation">(</span><span class="token string">'./data/en-zh.dic'</span><span class="token punctuation">)</span>

    <span class="token comment"># 加载数据</span>
    dataset <span class="token operator">=</span> TranslationDataset<span class="token punctuation">(</span><span class="token string">'./data/train.txt'</span><span class="token punctuation">,</span>terminology <span class="token operator">=</span> terminology<span class="token punctuation">)</span>
    <span class="token comment"># 选择数据集的前N个样本进行训练</span>
    N <span class="token operator">=</span> <span class="token number">1000</span>  <span class="token comment">#int(len(dataset) * 1)  # 或者你可以设置为数据集大小的一定比例，如 int(len(dataset) * 0.1)</span>
    subset_indices <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span>N<span class="token punctuation">)</span><span class="token punctuation">)</span>
    subset_dataset <span class="token operator">=</span> Subset<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> subset_indices<span class="token punctuation">)</span>
    train_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>subset_dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> collate_fn<span class="token operator">=</span>collate_fn<span class="token punctuation">)</span>

    <span class="token comment"># 定义模型参数</span>
    INPUT_DIM <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataset<span class="token punctuation">.</span>en_vocab<span class="token punctuation">)</span>
    OUTPUT_DIM <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataset<span class="token punctuation">.</span>zh_vocab<span class="token punctuation">)</span>
    ENC_EMB_DIM <span class="token operator">=</span> <span class="token number">256</span>
    DEC_EMB_DIM <span class="token operator">=</span> <span class="token number">256</span>
    HID_DIM <span class="token operator">=</span> <span class="token number">512</span>
    N_LAYERS <span class="token operator">=</span> <span class="token number">2</span>
    ENC_DROPOUT <span class="token operator">=</span> <span class="token number">0.5</span>
    DEC_DROPOUT <span class="token operator">=</span> <span class="token number">0.5</span>

    <span class="token comment"># 初始化模型</span>
    enc <span class="token operator">=</span> Encoder<span class="token punctuation">(</span>INPUT_DIM<span class="token punctuation">,</span> ENC_EMB_DIM<span class="token punctuation">,</span> HID_DIM<span class="token punctuation">,</span> N_LAYERS<span class="token punctuation">,</span> ENC_DROPOUT<span class="token punctuation">)</span>
    dec <span class="token operator">=</span> Decoder<span class="token punctuation">(</span>OUTPUT_DIM<span class="token punctuation">,</span> DEC_EMB_DIM<span class="token punctuation">,</span> HID_DIM<span class="token punctuation">,</span> N_LAYERS<span class="token punctuation">,</span> DEC_DROPOUT<span class="token punctuation">)</span>
    model <span class="token operator">=</span> Seq2Seq<span class="token punctuation">(</span>enc<span class="token punctuation">,</span> dec<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

    <span class="token comment"># 定义优化器和损失函数</span>
    optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span>ignore_index<span class="token operator">=</span>dataset<span class="token punctuation">.</span>zh_word2idx<span class="token punctuation">[</span><span class="token string">'&lt;pad&gt;'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token comment"># 训练模型</span>
    N_EPOCHS <span class="token operator">=</span> <span class="token number">10</span>
    CLIP <span class="token operator">=</span> <span class="token number">1</span>

    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>N_EPOCHS<span class="token punctuation">)</span><span class="token punctuation">:</span>
        train_loss <span class="token operator">=</span> train<span class="token punctuation">(</span>model<span class="token punctuation">,</span> train_loader<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> criterion<span class="token punctuation">,</span> CLIP<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Epoch: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token format-spec">02</span><span class="token punctuation">}</span></span><span class="token string"> | Train Loss: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>train_loss<span class="token punctuation">:</span><span class="token format-spec">.3f</span><span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
        
    <span class="token comment"># 在训练循环结束后保存模型</span>
    torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'./translation_model_GRU.pth'</span><span class="token punctuation">)</span>
    
    end_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 结束计时</span>

    <span class="token comment"># 计算并打印运行时间</span>
    elapsed_time_minute <span class="token operator">=</span> <span class="token punctuation">(</span>end_time <span class="token operator">-</span> start_time<span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">60</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Total running time: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>elapsed_time_minute<span class="token punctuation">:</span><span class="token format-spec">.2f</span><span class="token punctuation">}</span></span><span class="token string"> minutes"</span></span><span class="token punctuation">)</span>
</code></pre> 
<h2><a id="BLUE4_373"></a>基于BLUE4的评估指标</h2> 
<p>BLEU是评估机器翻译和自然语言生成任务的一种标准指标。BLEU4是指采用4-gram的BLEU评分方法。BLEU评分的核心思想是通过计算机器生成的文本与参考文本之间的n-gram匹配程度来衡量生成文本的质量。具体而言，BLEU4会考虑1-gram到4-gram的匹配情况。</p> 
<h3><a id="BLEU4__377"></a>BLEU4 的计算步骤：</h3> 
<ol><li><strong>分词</strong>：将待评估的生成文本和参考文本分词。</li><li><strong>计算n-gram匹配</strong>：计算1-gram、2-gram、3-gram和4-gram的匹配情况。</li><li><strong>计算精确度</strong>：对于每个n-gram，计算生成文本中的n-gram与参考文本中的n-gram的匹配数量，然后除以生成文本中n-gram的总数，得到精确度。</li><li><strong>计算加权几何平均</strong>：将1-gram到4-gram的精确度取对数，然后计算它们的加权几何平均。</li><li><strong>惩罚因子</strong>：为了解决短文本可能获得较高分数的问题，引入惩罚因子BP（Brevity Penalty），BP的计算基于生成文本和参考文本的长度比值。</li><li><strong>计算最终的BLEU4分数</strong>：将加权几何平均与惩罚因子相乘得到最终的BLEU4分数。</li></ol> 
<h3><a id="_385"></a>举个例子：</h3> 
<p>假设生成句子和参考句子有些不同：</p> 
<p>参考句子：<code>"The cat is on the mat"</code><br> 生成句子：<code>"The cat sat on the mat"</code></p> 
<h4><a id="1__392"></a>1. 分词：</h4> 
<p>参考句子分词结果：[“The”, “cat”, “is”, “on”, “the”, “mat”]<br> 生成句子分词结果：[“The”, “cat”, “sat”, “on”, “the”, “mat”]</p> 
<h4><a id="2_ngram_396"></a>2. 计算n-gram匹配：</h4> 
<ul><li>1-gram匹配：5个 (“The”, “cat”, “on”, “the”, “mat”)</li><li>2-gram匹配：4个 (“The cat”, “on the”, “the mat”)</li><li>3-gram匹配：2个 (“on the mat”)</li><li>4-gram匹配：1个 (“on the mat”)</li></ul> 
<h4><a id="3__402"></a>3. 计算精确度：</h4> 
<ul><li>1-gram精确度：5/6 ≈ 0.833</li><li>2-gram精确度：4/5 = 0.8</li><li>3-gram精确度：2/4 = 0.5</li><li>4-gram精确度：1/3 ≈ 0.333</li></ul> 
<h4><a id="4__408"></a>4. 计算加权几何平均：</h4> 
<p><span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          BLEU4 
         
        
          = 
         
        
          exp 
         
        
          ⁡ 
         
         
         
           ( 
          
          
          
            1 
           
          
            4 
           
          
         
           ( 
          
         
           log 
          
         
           ⁡ 
          
         
           0.833 
          
         
           + 
          
         
           log 
          
         
           ⁡ 
          
         
           0.8 
          
         
           + 
          
         
           log 
          
         
           ⁡ 
          
         
           0.5 
          
         
           + 
          
         
           log 
          
         
           ⁡ 
          
         
           0.333 
          
         
           ) 
          
         
           ) 
          
         
        
          ≈ 
         
        
          0.599 
         
        
       
         \text{BLEU4} = \exp\left(\frac{1}{4} (\log 0.833 + \log 0.8 + \log 0.5 + \log 0.333)\right) ≈ 0.599 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord text"><span class="mord">BLEU4</span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 2.4em; vertical-align: -0.95em;"></span><span class="mop">exp</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.3214em;"><span class="" style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">4</span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.686em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mopen">(</span><span class="mop">lo<span style="margin-right: 0.0139em;">g</span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">0.833</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mop">lo<span style="margin-right: 0.0139em;">g</span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">0.8</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mop">lo<span style="margin-right: 0.0139em;">g</span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">0.5</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mop">lo<span style="margin-right: 0.0139em;">g</span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">0.333</span><span class="mclose">)</span><span class="mclose delimcenter" style="top: 0em;"><span class="delimsizing size3">)</span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">0.599</span></span></span></span></span></span></p> 
<h4><a id="5_BP_413"></a>5. 计算惩罚因子BP：</h4> 
<p>生成句子和参考句子长度相同，因此BP = 1。</p> 
<h4><a id="6_BLEU4_416"></a>6. 计算最终的BLEU4分数：</h4> 
<p>最终的BLEU4分数 ≈ 0.599（加权几何平均） * 1（BP） ≈ 0.599</p> 
<p>在这个例子中，生成句子和参考句子有一些不同，因此BLEU4得分相对较低，反映了生成句子与参考句子的匹配程度不高。</p> 
<h3><a id="_423"></a>实现代码</h3> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> sacrebleu<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> BLEU
<span class="token keyword">from</span> typing <span class="token keyword">import</span> List
<span class="token comment"># 假设我们已经定义了TranslationDataset, Encoder, Decoder, Seq2Seq类</span>

<span class="token keyword">def</span> <span class="token function">load_sentences</span><span class="token punctuation">(</span>file_path<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> List<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>file_path<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token punctuation">[</span>line<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> line <span class="token keyword">in</span> f<span class="token punctuation">]</span>

<span class="token comment"># 更新translate_sentence函数以考虑术语词典</span>
<span class="token keyword">def</span> <span class="token function">translate_sentence</span><span class="token punctuation">(</span>sentence<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> model<span class="token punctuation">:</span> Seq2Seq<span class="token punctuation">,</span> dataset<span class="token punctuation">:</span> TranslationDataset<span class="token punctuation">,</span> terminology<span class="token punctuation">,</span> device<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">,</span> max_length<span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token number">50</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    tokens <span class="token operator">=</span> dataset<span class="token punctuation">.</span>en_tokenizer<span class="token punctuation">(</span>sentence<span class="token punctuation">)</span>
    tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span><span class="token punctuation">[</span>dataset<span class="token punctuation">.</span>en_word2idx<span class="token punctuation">.</span>get<span class="token punctuation">(</span>token<span class="token punctuation">,</span> dataset<span class="token punctuation">.</span>en_word2idx<span class="token punctuation">[</span><span class="token string">'&lt;sos&gt;'</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> token <span class="token keyword">in</span> tokens<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>  <span class="token comment"># [1, seq_len]</span>
    
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        _<span class="token punctuation">,</span> hidden <span class="token operator">=</span> model<span class="token punctuation">.</span>encoder<span class="token punctuation">(</span>tensor<span class="token punctuation">)</span>

    translated_tokens <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    input_token <span class="token operator">=</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span>dataset<span class="token punctuation">.</span>zh_word2idx<span class="token punctuation">[</span><span class="token string">'&lt;sos&gt;'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>  <span class="token comment"># [1, 1]</span>

    <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>max_length<span class="token punctuation">)</span><span class="token punctuation">:</span>
        output<span class="token punctuation">,</span> hidden <span class="token operator">=</span> model<span class="token punctuation">.</span>decoder<span class="token punctuation">(</span>input_token<span class="token punctuation">,</span> hidden<span class="token punctuation">)</span>
        top_token <span class="token operator">=</span> output<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
        translated_token <span class="token operator">=</span> dataset<span class="token punctuation">.</span>zh_vocab<span class="token punctuation">[</span>top_token<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
        
        <span class="token keyword">if</span> translated_token <span class="token operator">==</span> <span class="token string">'&lt;eos&gt;'</span><span class="token punctuation">:</span>
            <span class="token keyword">break</span>
        
        <span class="token comment"># 如果翻译的词在术语词典中，则使用术语词典中的词</span>
        <span class="token keyword">if</span> translated_token <span class="token keyword">in</span> terminology<span class="token punctuation">.</span>values<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">for</span> en_term<span class="token punctuation">,</span> ch_term <span class="token keyword">in</span> terminology<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token keyword">if</span> translated_token <span class="token operator">==</span> ch_term<span class="token punctuation">:</span>
                    translated_token <span class="token operator">=</span> en_term
                    <span class="token keyword">break</span>
        
        translated_tokens<span class="token punctuation">.</span>append<span class="token punctuation">(</span>translated_token<span class="token punctuation">)</span>
        input_token <span class="token operator">=</span> top_token<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># [1, 1]</span>

    <span class="token keyword">return</span> <span class="token string">''</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>translated_tokens<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">evaluate_bleu</span><span class="token punctuation">(</span>model<span class="token punctuation">:</span> Seq2Seq<span class="token punctuation">,</span> dataset<span class="token punctuation">:</span> TranslationDataset<span class="token punctuation">,</span> src_file<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> ref_file<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> terminology<span class="token punctuation">,</span>device<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    src_sentences <span class="token operator">=</span> load_sentences<span class="token punctuation">(</span>src_file<span class="token punctuation">)</span>
    ref_sentences <span class="token operator">=</span> load_sentences<span class="token punctuation">(</span>ref_file<span class="token punctuation">)</span>
    
    translated_sentences <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> src <span class="token keyword">in</span> src_sentences<span class="token punctuation">:</span>
        translated <span class="token operator">=</span> translate_sentence<span class="token punctuation">(</span>src<span class="token punctuation">,</span> model<span class="token punctuation">,</span> dataset<span class="token punctuation">,</span> terminology<span class="token punctuation">,</span> device<span class="token punctuation">)</span>
        translated_sentences<span class="token punctuation">.</span>append<span class="token punctuation">(</span>translated<span class="token punctuation">)</span>
    
    bleu <span class="token operator">=</span> BLEU<span class="token punctuation">(</span><span class="token punctuation">)</span>
    score <span class="token operator">=</span> bleu<span class="token punctuation">.</span>corpus_score<span class="token punctuation">(</span>translated_sentences<span class="token punctuation">,</span> <span class="token punctuation">[</span>ref_sentences<span class="token punctuation">]</span><span class="token punctuation">)</span>
    
    <span class="token keyword">return</span> score
<span class="token comment"># 主函数</span>
<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cuda'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span><span class="token punctuation">)</span>

    <span class="token comment"># 加载术语词典</span>
    terminology <span class="token operator">=</span> load_terminology_dictionary<span class="token punctuation">(</span><span class="token string">'./data/en-zh.dic'</span><span class="token punctuation">)</span>
    
    <span class="token comment"># 创建数据集实例时传递术语词典</span>
    dataset <span class="token operator">=</span> TranslationDataset<span class="token punctuation">(</span><span class="token string">'./data/train.txt'</span><span class="token punctuation">,</span> terminology<span class="token punctuation">)</span>
    

    <span class="token comment"># 定义模型参数</span>
    INPUT_DIM <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataset<span class="token punctuation">.</span>en_vocab<span class="token punctuation">)</span>
    OUTPUT_DIM <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataset<span class="token punctuation">.</span>zh_vocab<span class="token punctuation">)</span>
    ENC_EMB_DIM <span class="token operator">=</span> <span class="token number">256</span>
    DEC_EMB_DIM <span class="token operator">=</span> <span class="token number">256</span>
    HID_DIM <span class="token operator">=</span> <span class="token number">512</span>
    N_LAYERS <span class="token operator">=</span> <span class="token number">2</span>
    ENC_DROPOUT <span class="token operator">=</span> <span class="token number">0.5</span>
    DEC_DROPOUT <span class="token operator">=</span> <span class="token number">0.5</span>

    <span class="token comment"># 初始化模型</span>
    enc <span class="token operator">=</span> Encoder<span class="token punctuation">(</span>INPUT_DIM<span class="token punctuation">,</span> ENC_EMB_DIM<span class="token punctuation">,</span> HID_DIM<span class="token punctuation">,</span> N_LAYERS<span class="token punctuation">,</span> ENC_DROPOUT<span class="token punctuation">)</span>
    dec <span class="token operator">=</span> Decoder<span class="token punctuation">(</span>OUTPUT_DIM<span class="token punctuation">,</span> DEC_EMB_DIM<span class="token punctuation">,</span> HID_DIM<span class="token punctuation">,</span> N_LAYERS<span class="token punctuation">,</span> DEC_DROPOUT<span class="token punctuation">)</span>
    model <span class="token operator">=</span> Seq2Seq<span class="token punctuation">(</span>enc<span class="token punctuation">,</span> dec<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

    <span class="token comment"># 加载训练好的模型</span>
    model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'./translation_model_GRU.pth'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment"># 评估BLEU分数</span>
    bleu_score <span class="token operator">=</span> evaluate_bleu<span class="token punctuation">(</span>model<span class="token punctuation">,</span> dataset<span class="token punctuation">,</span> <span class="token string">'./data/dev_en.txt'</span><span class="token punctuation">,</span> <span class="token string">'./data/dev_zh.txt'</span><span class="token punctuation">,</span> terminology <span class="token operator">=</span> terminology<span class="token punctuation">,</span>device <span class="token operator">=</span> device<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'BLEU-4 score: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>bleu_score<span class="token punctuation">.</span>score<span class="token punctuation">:</span><span class="token format-spec">.2f</span><span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
</code></pre> 
<p>这里是对验证集进行评估,由于Seq2Seq模型训练上限比较低,看上去有点像智障。所以BLEU为0也不是什么奇怪的事情</p> 
<h2><a id="_517"></a>推理</h2> 
<p>最后我们训练完这个模型后肯定要对模型进行推理,推理代码如下:</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">inference</span><span class="token punctuation">(</span>model<span class="token punctuation">:</span> Seq2Seq<span class="token punctuation">,</span> dataset<span class="token punctuation">:</span> TranslationDataset<span class="token punctuation">,</span> src_file<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> save_dir<span class="token punctuation">:</span><span class="token builtin">str</span><span class="token punctuation">,</span> terminology<span class="token punctuation">,</span> device<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    src_sentences <span class="token operator">=</span> load_sentences<span class="token punctuation">(</span>src_file<span class="token punctuation">)</span>
    
    translated_sentences <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> src <span class="token keyword">in</span> src_sentences<span class="token punctuation">:</span>
        translated <span class="token operator">=</span> translate_sentence<span class="token punctuation">(</span>src<span class="token punctuation">,</span> model<span class="token punctuation">,</span> dataset<span class="token punctuation">,</span> terminology<span class="token punctuation">,</span> device<span class="token punctuation">)</span>
        <span class="token comment">#print(translated)</span>
        translated_sentences<span class="token punctuation">.</span>append<span class="token punctuation">(</span>translated<span class="token punctuation">)</span>
        <span class="token comment">#print(translated_sentences)</span>

    <span class="token comment"># 将列表元素连接成一个字符串，每个元素后换行</span>
    text <span class="token operator">=</span> <span class="token string">'\n'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>translated_sentences<span class="token punctuation">)</span>

    <span class="token comment"># 打开一个文件，如果不存在则创建，'w'表示写模式</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>save_dir<span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        <span class="token comment"># 将字符串写入文件</span>
        f<span class="token punctuation">.</span>write<span class="token punctuation">(</span>text<span class="token punctuation">)</span>

    <span class="token comment">#return translated_sentences</span>
<span class="token comment"># 主函数</span>
<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cuda'</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">'cpu'</span><span class="token punctuation">)</span>

    <span class="token comment"># 加载术语词典</span>
    terminology <span class="token operator">=</span> load_terminology_dictionary<span class="token punctuation">(</span><span class="token string">'./data/en-zh.dic'</span><span class="token punctuation">)</span>
    <span class="token comment"># 加载数据集和模型</span>
    dataset <span class="token operator">=</span> TranslationDataset<span class="token punctuation">(</span><span class="token string">'./data/train.txt'</span><span class="token punctuation">,</span>terminology <span class="token operator">=</span> terminology<span class="token punctuation">)</span>

    <span class="token comment"># 定义模型参数</span>
    INPUT_DIM <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataset<span class="token punctuation">.</span>en_vocab<span class="token punctuation">)</span>
    OUTPUT_DIM <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataset<span class="token punctuation">.</span>zh_vocab<span class="token punctuation">)</span>
    ENC_EMB_DIM <span class="token operator">=</span> <span class="token number">256</span>
    DEC_EMB_DIM <span class="token operator">=</span> <span class="token number">256</span>
    HID_DIM <span class="token operator">=</span> <span class="token number">512</span>
    N_LAYERS <span class="token operator">=</span> <span class="token number">2</span>
    ENC_DROPOUT <span class="token operator">=</span> <span class="token number">0.5</span>
    DEC_DROPOUT <span class="token operator">=</span> <span class="token number">0.5</span>

    <span class="token comment"># 初始化模型</span>
    enc <span class="token operator">=</span> Encoder<span class="token punctuation">(</span>INPUT_DIM<span class="token punctuation">,</span> ENC_EMB_DIM<span class="token punctuation">,</span> HID_DIM<span class="token punctuation">,</span> N_LAYERS<span class="token punctuation">,</span> ENC_DROPOUT<span class="token punctuation">)</span>
    dec <span class="token operator">=</span> Decoder<span class="token punctuation">(</span>OUTPUT_DIM<span class="token punctuation">,</span> DEC_EMB_DIM<span class="token punctuation">,</span> HID_DIM<span class="token punctuation">,</span> N_LAYERS<span class="token punctuation">,</span> DEC_DROPOUT<span class="token punctuation">)</span>
    model <span class="token operator">=</span> Seq2Seq<span class="token punctuation">(</span>enc<span class="token punctuation">,</span> dec<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

    <span class="token comment"># 加载训练好的模型</span>
    model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'./translation_model_GRU.pth'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    
    save_dir <span class="token operator">=</span> <span class="token string">'./data/submit.txt'</span>
    inference<span class="token punctuation">(</span>model<span class="token punctuation">,</span> dataset<span class="token punctuation">,</span> src_file<span class="token operator">=</span><span class="token string">"./data/test_en.txt"</span><span class="token punctuation">,</span> save_dir <span class="token operator">=</span> save_dir<span class="token punctuation">,</span> terminology <span class="token operator">=</span> terminology<span class="token punctuation">,</span> device <span class="token operator">=</span> device<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"翻译完成！文件已保存到</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>save_dir<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
</code></pre> 
<p>运行完就会得到一个submit.txt文件,提交这个就可以拿到这个比赛的分数啦。</p> 
<p>一提交(被狠狠的打击到了):<br> <img src="https://images2.imgbox.com/24/5f/AAPkO6wn_o.png" alt="在这里插入图片描述"><br> 痛定思痛下马上写了一个transform框架的,然后狠狠的上了一把分(<br> <img src="https://images2.imgbox.com/2e/86/iewXJnuj_o.png" alt="在这里插入图片描述"><br> 关于transformer的baseline我有空在写多一篇文章发一下。</p> 
<h2><a id="_581"></a>参考</h2> 
<p><a href="https://datawhaler.feishu.cn/wiki/TObSwHZdFi2y0XktauWcolpcnyf" rel="nofollow">datawhale学习链接</a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/b2a86398635580a1f92cd9f6f362eb3d/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【C&#43;&#43;&amp;Python&amp;Java】字符处理详细解读_字符_ASCLL码_字母数字转换_算法竞赛_开发语言</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/1f6857b83f6420bccb288c92b704edd8/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【C语言初阶】探索编程基础：深入理解分支与循环语句的奥秘</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>