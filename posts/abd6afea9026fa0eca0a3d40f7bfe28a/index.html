<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>LLaMA-Factory：大语言模型微调框架（大模型） - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/abd6afea9026fa0eca0a3d40f7bfe28a/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="LLaMA-Factory：大语言模型微调框架（大模型）">
  <meta property="og:description" content="简介： LLaMA-Factory 是一个国内北航开源的低代码大模型训练框架，专为大型语言模型（LLMs）的微调而设计
LLaMA-Factory：大语言模型微调框架 一、功能特点 LLaMA-Factory 是一个国内北航开源的低代码大模型训练框架，专为大型语言模型（LLMs）的微调而设计。其主要功能特点包括：
高效且低成本：能够高效且低成本地支持对100多个模型进行微调，简化了模型微调的过程。易于访问和使用：提供了友好的用户界面，用户无需编写代码即可轻松定制和微调LLMs。丰富的数据集选项：支持多个数据集选项，用户可以选择自带的数据集或自己生成数据集进行微调。多样化的算法支持：集成了业界最广泛使用的微调方法和优化技术，如LoRA、GaLore、DoRA等。实时监控和评估：支持集成TensorBoard、VanDB和MLflow等监控工具，便于实时监控训练过程和评估模型性能。极速推理：提供了基于vLLM的OpenAI风格API、浏览器界面和命令行接口，实现快速推理。 二、安装 LLaMA-Factory 的安装相对简单，以下是一般的安装步骤（以conda环境为例）：
创建Python环境：
使用conda创建一个新的Python环境，并安装必要的依赖库，如PyTorch等。
克隆LLaMA-Factory项目：
通过Git克隆LLaMA-Factory的源代码到本地。
git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git 安装依赖：
进入项目目录，安装必要的Python依赖库。
cd LLaMA-Factory pip install -e &#34;.[torch,metrics]&#34; 启动服务：
在项目目录中运行python src/train_web.py启动服务，然后在浏览器中访问相应的端口（默认可能是7860）以访问训练界面。
三、支持的算法 LLaMA-Factory 支持多种先进的微调算法和模型，包括但不限于：
多种模型：LLaMA、LLaVA、Mistral、Mixtral-MoE、Qwen、Yi、Gemma、Baichuan、ChatGLM、Phi 等等。集成方法：（增量）预训练、（多模态）指令监督微调、奖励模型训练、PPO 训练、DPO 训练、KTO 训练、ORPO 训练等等。多种精度：16 比特全参数微调、冻结微调、LoRA 微调和基于 AQLM/AWQ/GPTQ/LLM.int8/HQQ/EETQ 的 2/3/4/5/6/8 比特 QLoRA 微调。先进算法：GaLore、BAdam、DoRA、LongLoRA、LLaMA Pro、Mixture-of-Depths、LoRA&#43;、LoftQ、PiSSA 和 Agent 微调。实用技巧：FlashAttention-2、Unsloth、RoPE scaling、NEFTune 和 rsLoRA。实验监控：LlamaBoard、TensorBoard、Wandb、MLflow 等等。极速推理：基于 vLLM 的 OpenAI 风格 API、浏览器界面和命令行接口。 四、性能指标 与 ChatGLM 官方的 P-Tuning 微调相比，LLaMA Factory 的 LoRA 微调提供了 3.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-07-18T11:30:29+08:00">
    <meta property="article:modified_time" content="2024-07-18T11:30:29+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">LLaMA-Factory：大语言模型微调框架（大模型）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p><strong>简介：</strong> LLaMA-Factory 是一个国内北航开源的低代码大模型训练框架，专为大型语言模型（LLMs）的微调而设计</p> 
<h2><a id="LLaMAFactory_2"></a>LLaMA-Factory：大语言模型微调框架</h2> 
<p><img src="https://images2.imgbox.com/c9/12/LUhrIedM_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="_5"></a><strong>一、功能特点</strong></h4> 
<p>LLaMA-Factory 是一个国内北航开源的低代码大模型训练框架，专为大型语言模型（LLMs）的微调而设计。其主要功能特点包括：</p> 
<ol><li><strong>高效且低成本</strong>：能够高效且低成本地支持对100多个模型进行微调，简化了模型微调的过程。</li><li><strong>易于访问和使用</strong>：提供了友好的用户界面，用户无需编写代码即可轻松定制和微调LLMs。</li><li><strong>丰富的数据集选项</strong>：支持多个数据集选项，用户可以选择自带的数据集或自己生成数据集进行微调。</li><li><strong>多样化的算法支持</strong>：集成了业界最广泛使用的微调方法和优化技术，如LoRA、GaLore、DoRA等。</li><li><strong>实时监控和评估</strong>：支持集成TensorBoard、VanDB和MLflow等监控工具，便于实时监控训练过程和评估模型性能。</li><li><strong>极速推理</strong>：提供了基于vLLM的OpenAI风格API、浏览器界面和命令行接口，实现快速推理。</li></ol> 
<h4><a id="_16"></a><strong>二、安装</strong></h4> 
<p>LLaMA-Factory 的安装相对简单，以下是一般的安装步骤（以conda环境为例）：</p> 
<ol><li> <p><strong>创建Python环境</strong>：<br> 使用conda创建一个新的Python环境，并安装必要的依赖库，如PyTorch等。</p> </li><li> <p><strong>克隆LLaMA-Factory项目</strong>：<br> 通过Git克隆LLaMA-Factory的源代码到本地。</p> <pre><code>git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git
</code></pre> </li><li> <p><strong>安装依赖</strong>：<br> 进入项目目录，安装必要的Python依赖库。</p> <pre><code>
 cd LLaMA-Factory
 pip install -e ".[torch,metrics]"
</code></pre> </li><li> <p><strong>启动服务</strong>：<br> 在项目目录中运行<code>python src/train_web.py</code>启动服务，然后在浏览器中访问相应的端口（默认可能是7860）以访问训练界面。</p> </li></ol> 
<p><img src="https://images2.imgbox.com/45/e5/EptfCnAm_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="_45"></a><strong>三、支持的算法</strong></h4> 
<p>LLaMA-Factory 支持多种先进的微调算法和模型，包括但不限于：</p> 
<ul><li>多种模型：LLaMA、LLaVA、Mistral、Mixtral-MoE、Qwen、Yi、Gemma、Baichuan、ChatGLM、Phi 等等。</li><li>集成方法：（增量）预训练、（多模态）指令监督微调、奖励模型训练、PPO 训练、DPO 训练、KTO 训练、ORPO 训练等等。</li><li>多种精度：16 比特全参数微调、冻结微调、LoRA 微调和基于 AQLM/AWQ/GPTQ/LLM.int8/HQQ/EETQ 的 2/3/4/5/6/8 比特 QLoRA 微调。</li><li>先进算法：GaLore、BAdam、DoRA、LongLoRA、LLaMA Pro、Mixture-of-Depths、LoRA+、LoftQ、PiSSA 和 Agent 微调。</li><li>实用技巧：FlashAttention-2、Unsloth、RoPE scaling、NEFTune 和 rsLoRA。</li><li>实验监控：LlamaBoard、TensorBoard、Wandb、MLflow 等等。</li><li>极速推理：基于 vLLM 的 OpenAI 风格 API、浏览器界面和命令行接口。</li></ul> 
<h4><a id="_57"></a><strong>四、性能指标</strong></h4> 
<p>与 ChatGLM 官方的 P-Tuning 微调相比，LLaMA Factory 的 LoRA 微调提供了 3.7 倍的加速比，同时在广告文案生成任务上取得了更高的 Rouge 分数。结合 4 比特量化技术，LLaMA Factory 的 QLoRA 微调进一步降低了 GPU 显存消耗。<br> <img src="https://images2.imgbox.com/c1/9f/5jrLm1gA_o.png" alt="在这里插入图片描述"></p> 
<p>GPU现存消耗：</p> 
<p><img src="https://images2.imgbox.com/8e/15/mNtEI0en_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="_68"></a><strong>五、微调例子</strong></h4> 
<p>以下是一个使用LLaMA-Factory对Yuan2.0模型进行LoRA微调的例子：</p> 
<ol><li><strong>准备数据集</strong>：<br> 准备自定义的数据集，可以是JSON格式，包含指令、输入和输出等信息。</li><li><strong>注册数据集</strong>：<br> 在LLaMA-Factory的数据集管理文件中注册自定义的数据集。</li><li><strong>启动Web UI服务</strong>：<br> 运行<code>python src/train_web.py</code>启动Web UI服务，并在浏览器中打开相应的地址。</li><li><strong>配置微调参数</strong>：<br> 在Web界面上配置模型路径、微调方法（选择LoRA）、数据集等参数。</li><li><strong>开始微调</strong>：<br> 点击“开始”按钮开始微调过程，可以在界面中查看训练进度和损失函数等信息。</li><li><strong>评估模型</strong>：<br> 微调完成后，使用LLaMA-Factory提供的评估工具对模型进行评估，检查模型性能是否有所提升。</li></ol> 
<p>通过以上步骤，用户可以利用LLaMA-Factory轻松实现LLMs的微调，提升模型在特定任务上的性能。</p> 
<h3><a id="LLM__87"></a>如何系统的去学习大模型LLM ？</h3> 
<p>作为一名热心肠的互联网老兵，我意识到有很多经验和知识值得分享给大家，也可以通过我们的能力和经验解答大家在人工智能学习中的很多困惑，所以在工作繁忙的情况下还是坚持各种整理和分享。</p> 
<p>但苦于知识传播途径有限，很多互联网行业朋友无法获得正确的资料得到学习提升，故此将并将<strong>重要的 <code>AI大模型资料</code> 包括AI大模型入门学习思维导图、精品AI大模型学习书籍手册、视频教程、实战学习等录播视频免费分享出来</strong>。</p> 
<p>所有资料 ⚡️ ，朋友们如果有需要全套 《<strong>LLM大模型入门+进阶学习资源包</strong>》，<strong>扫码获取~</strong></p> 
<blockquote> 
 <p>👉<a href="" rel="nofollow"><font color="#FF0000">CSDN大礼包</font>🎁：全网最全《LLM大模型入门+进阶学习资源包》免费分享<b><font color="#177f3e">（安全链接，放心点击）</font></b></a>👈</p> 
</blockquote> 
<p>​<img src="https://images2.imgbox.com/12/79/qnP5b7g8_o.jpg"></p> 
<h3><a id="AGI_101"></a>一、全套AGI大模型学习路线</h3> 
<p><strong>AI大模型时代的学习之旅：从基础到前沿，掌握人工智能的核心技能！</strong></p> 
<p><img src="https://images2.imgbox.com/60/6b/yQttTbhs_o.png" alt="img"></p> 
<h3><a id="640AI_107"></a>二、640套AI大模型报告合集</h3> 
<p>这套包含640份报告的合集，涵盖了AI大模型的理论研究、技术实现、行业应用等多个方面。无论您是科研人员、工程师，还是对AI大模型感兴趣的爱好者，这套报告合集都将为您提供宝贵的信息和启示。</p> 
<p><img src="https://images2.imgbox.com/58/fa/doYLeSkj_o.png" alt="img"></p> 
<h3><a id="AIPDF_113"></a>三、AI大模型经典PDF籍</h3> 
<p>随着人工智能技术的飞速发展，AI大模型已经成为了当今科技领域的一大热点。这些大型预训练模型，如GPT-3、BERT、XLNet等，以其强大的语言理解和生成能力，正在改变我们对人工智能的认识。 那以下这些PDF籍就是非常不错的学习资源。</p> 
<p><img src="https://images2.imgbox.com/68/46/TSeBA1ms_o.png" alt="img"></p> 
<p><img src="https://images2.imgbox.com/ad/6f/cNn0CRWr_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="AI_121"></a>四、AI大模型商业化落地方案</h4> 
<p><img src="https://images2.imgbox.com/67/e6/nniqnxmi_o.png" alt="img"></p> 
<h4><a id="1AI_125"></a>阶段1：AI大模型时代的基础理解</h4> 
<ul><li><strong>目标</strong>：了解AI大模型的基本概念、发展历程和核心原理。</li><li><strong>内容</strong>： 
  <ul><li>L1.1 人工智能简述与大模型起源</li><li>L1.2 大模型与通用人工智能</li><li>L1.3 GPT模型的发展历程</li><li>L1.4 模型工程<br> - L1.4.1 知识大模型<br> - L1.4.2 生产大模型<br> - L1.4.3 模型工程方法论<br> - L1.4.4 模型工程实践</li><li>L1.5 GPT应用案例</li></ul> </li></ul> 
<h4><a id="2AIAPI_137"></a>阶段2：AI大模型API应用开发工程</h4> 
<ul><li><strong>目标</strong>：掌握AI大模型API的使用和开发，以及相关的编程技能。</li><li><strong>内容</strong>： 
  <ul><li>L2.1 API接口<br> - L2.1.1 OpenAI API接口<br> - L2.1.2 Python接口接入<br> - L2.1.3 BOT工具类框架<br> - L2.1.4 代码示例</li><li>L2.2 Prompt框架<br> - L2.2.1 什么是Prompt<br> - L2.2.2 Prompt框架应用现状<br> - L2.2.3 基于GPTAS的Prompt框架<br> - L2.2.4 Prompt框架与Thought<br> - L2.2.5 Prompt框架与提示词</li><li>L2.3 流水线工程<br> - L2.3.1 流水线工程的概念<br> - L2.3.2 流水线工程的优点<br> - L2.3.3 流水线工程的应用</li><li>L2.4 总结与展望</li></ul> </li></ul> 
<h4><a id="3AI_156"></a>阶段3：AI大模型应用架构实践</h4> 
<ul><li><strong>目标</strong>：深入理解AI大模型的应用架构，并能够进行私有化部署。</li><li><strong>内容</strong>： 
  <ul><li>L3.1 Agent模型框架<br> - L3.1.1 Agent模型框架的设计理念<br> - L3.1.2 Agent模型框架的核心组件<br> - L3.1.3 Agent模型框架的实现细节</li><li>L3.2 MetaGPT<br> - L3.2.1 MetaGPT的基本概念<br> - L3.2.2 MetaGPT的工作原理<br> - L3.2.3 MetaGPT的应用场景</li><li>L3.3 ChatGLM<br> - L3.3.1 ChatGLM的特点<br> - L3.3.2 ChatGLM的开发环境<br> - L3.3.3 ChatGLM的使用示例</li><li>L3.4 LLAMA<br> - L3.4.1 LLAMA的特点<br> - L3.4.2 LLAMA的开发环境<br> - L3.4.3 LLAMA的使用示例</li><li>L3.5 其他大模型介绍</li></ul> </li></ul> 
<h4><a id="4AI_176"></a>阶段4：AI大模型私有化部署</h4> 
<ul><li><strong>目标</strong>：掌握多种AI大模型的私有化部署，包括多模态和特定领域模型。</li><li><strong>内容</strong>： 
  <ul><li>L4.1 模型私有化部署概述</li><li>L4.2 模型私有化部署的关键技术</li><li>L4.3 模型私有化部署的实施步骤</li><li>L4.4 模型私有化部署的应用场景</li></ul> </li></ul> 
<h4><a id="_183"></a>学习计划：</h4> 
<ul><li><strong>阶段1</strong>：1-2个月，建立AI大模型的基础知识体系。</li><li><strong>阶段2</strong>：2-3个月，专注于API应用开发能力的提升。</li><li><strong>阶段3</strong>：3-4个月，深入实践AI大模型的应用架构和私有化部署。</li><li><strong>阶段4</strong>：4-5个月，专注于高级模型的应用和部署。</li></ul> 
<h6><a id="___LLM_CSDNCSDN100_189"></a>这份完整版的所有 ⚡️ 大模型 LLM 学习资料已经上传CSDN，朋友们如果需要可以微信扫描下方CSDN官方认证二维码免费领取【<code>保证100%免费</code>】</h6> 
<p>全套 《<strong>LLM大模型入门+进阶学习资源包</strong>》<strong>↓↓↓</strong> <strong>获取~</strong></p> 
<blockquote> 
 <p>👉<a href="" rel="nofollow"><font color="#FF0000">CSDN大礼包</font>🎁：全网最全《LLM大模型入门+进阶学习资源包》免费分享<b><font color="#177f3e">（安全链接，放心点击）</font></b></a>👈</p> 
</blockquote> 
<p>​<img src="https://images2.imgbox.com/1c/a9/CbzmmV3A_o.jpg"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/4212695b4f3c99dc22bf51f753193767/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【前端8】element ui常见页面布局：注意事项</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/364f11ded0e2dd668809d5ecf5e6f270/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">一文详解数据仓库、数据湖、湖仓一体和数据网格</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>