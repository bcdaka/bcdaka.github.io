<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Spark的reduceByKey方法使用 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/249f1d95912abf573b6391667d905800/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="Spark的reduceByKey方法使用">
  <meta property="og:description" content="一、需求 在ODPS上我们有如下数据：
idcategory_idattr_idattr_nameattr_value205348100000462最优粘度[&#34;0W-40&#34;]205348100000461基础油类型[&#34;全合成&#34;]205348100000463级别[&#34;BMW Longlife 01&#34;] 我们希望得到的结果如下：
(205348, 10000046, &#34;基础油类型：全合成\n最优粘度：0W-40\n级别：BMW Longlife 01\n&#34;)
需求解读：
需要将(id, category_id)作为key，然后将(attr_id, attr_name, attr_value)进行reduce操作，在reduce之后的数据中对attr_id进行排序，再将attr_name和attr_value合并在一起。
二、reduce操作之字符串方式 这个是最简单的方式，大致思路如下：
首先，将(id, category_id)作为key。
然后，将attr_id、attr_name、attr_value合并成一个字符串attr_info：attr_id &#43; &#34;#&#34; &#43; attr_name &#43; &#34;#&#34; &#43; attr_value，然后attr_info再通过&#34;&amp;&#34;进行合并。
示例代码如下：
xx.map{case(id, category_id, attr_id, attr_name, attr_value) =&gt; ((id, category_id), attr_id &#43; &#34;#&#34; &#43; attr_name &#43; &#34;#&#34; &#43; attr_value)} .reduceByKey(_ &#43; &#34;&amp;&#34; &#43; _, 100) 然后在接下来的流程中首先split(&#34;#&#34;)得到不同的attr信息，再通过split(&#34;&amp;&#34;)得到不同的attr的列信息。这就要求attr_id，attr_name，attr_value中不能包含&#34;#&#34;和&#34;&amp;&#34;字符串。
所以这种方式有缺陷，就是当attr_id，attr_name，attr_value包含了&#34;#&#34;和&#34;&amp;&#34;字符串时需要先replace一下，这样就改变了原数据的值。
三、reduce操作之列表方式 这种方式相对复杂一点，需要对输入数据进行预处理，但是逻辑清晰。
输入数据中(id, category_id)是key保持不变，(item_id, item_name, item_value)是一组tuple。
reduce操作会在同一个partition中，不同的partition之间进行数据合并，这要求数据的输入、输出类型保持不变。
我们的初步想法：将item_id, item_name, item_value分别放到3个列表中，合并时就是列表之间的合并，合并完毕后使用时只需要遍历列表即可。
因为reduce操作的输入、输出类型不能变化，所以先放item_id, item_name, item_value初始化为一个列表，然后再进行列表之间的合并。
示例代码如下：">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-03-14T17:09:06+08:00">
    <meta property="article:modified_time" content="2024-03-14T17:09:06+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Spark的reduceByKey方法使用</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2>一、需求</h2> 
<p>在ODPS上我们有如下数据：</p> 
<table border="1" cellpadding="1" cellspacing="1" style="width:500px;"><tbody><tr><td>id</td><td>category_id</td><td>attr_id</td><td>attr_name</td><td>attr_value</td></tr><tr><td>205348</td><td>10000046</td><td>2</td><td>最优粘度</td><td>["0W-40"]</td></tr><tr><td>205348</td><td>10000046</td><td>1</td><td>基础油类型</td><td>["全合成"]</td></tr><tr><td>205348</td><td>10000046</td><td>3</td><td>级别</td><td>["BMW Longlife 01"]</td></tr></tbody></table> 
<p>我们希望得到的结果如下：</p> 
<p>(205348, 10000046, "基础油类型：全合成\n最优粘度：0W-40\n级别：BMW Longlife 01\n")</p> 
<p>需求解读：</p> 
<p>需要将(id, category_id)作为key，然后将(attr_id, attr_name, attr_value)进行reduce操作，在reduce之后的数据中对attr_id进行排序，再将attr_name和attr_value合并在一起。</p> 
<h2>二、reduce操作之字符串方式</h2> 
<p>这个是最简单的方式，大致思路如下：</p> 
<p>首先，将(id, category_id)作为key。</p> 
<p>然后，将attr_id、attr_name、attr_value合并成一个字符串attr_info：attr_id + "#" + attr_name + "#" + attr_value，然后attr_info再通过"&amp;"进行合并。</p> 
<p>示例代码如下：</p> 
<pre><code class="language-Scala">xx.map{case(id, category_id, attr_id, attr_name, attr_value) =&gt; ((id, category_id), attr_id + "#" + attr_name + "#" + attr_value)}
	.reduceByKey(_ + "&amp;" + _, 100)</code></pre> 
<p>然后在接下来的流程中首先split("#")得到不同的attr信息，再通过split("&amp;")得到不同的attr的列信息。这就要求attr_id，attr_name，attr_value中不能包含"#"和"&amp;"字符串。</p> 
<p>所以这种方式有缺陷，就是当attr_id，attr_name，attr_value包含了"#"和"&amp;"字符串时需要先replace一下，这样就改变了原数据的值。</p> 
<h2>三、reduce操作之列表方式</h2> 
<p>这种方式相对复杂一点，需要对输入数据进行预处理，但是逻辑清晰。</p> 
<p>输入数据中(id, category_id)是key保持不变，(item_id, item_name, item_value)是一组tuple。</p> 
<p>reduce操作会在同一个partition中，不同的partition之间进行数据合并，这<span style="color:#fe2c24;">要求数据的输入、输出类型保持不变</span>。</p> 
<p><img alt="" height="183" src="https://images2.imgbox.com/78/9e/Dogun1kt_o.png" width="245"></p> 
<p>我们的初步想法：将item_id, item_name, item_value分别放到3个列表中，合并时就是列表之间的合并，合并完毕后使用时只需要遍历列表即可。</p> 
<p>因为reduce操作的输入、输出类型不能变化，所以先放item_id, item_name, item_value初始化为一个列表，然后再进行列表之间的合并。</p> 
<p>示例代码如下：</p> 
<pre><code class="language-Scala">xx.map{case(id, category_id, attr_id, attr_name, attr_value) =&gt; 
	  val itemIdList = new ArrayList[Long]()
	  itemIdList.add(attr_id)
	  val itemNameList = new ArrayList[String]()
	  itemNameList.add(attr_name)
	  val itemValueList = new ArrayList[String]()
	  itemValueList.add(attr_value)
	  ((id, category_id), (itemIdList, itemNameList, itemValueList))

}.reduceByKey((x, y) =&gt; {
	  val itemIdList = new ArrayList[Long]()
	  for(i &lt;- 0 until x._1.size()){
		itemIdList.add(x._1.get(i))
	  }
	  for(i &lt;- 0 until y._1.size()){
		itemIdList.add(y._1.get(i))
	  }

	  val itemNameList = new ArrayList[String]()
	  for(i &lt;- 0 until x._2.size()){
		itemNameList.add(x._2.get(i))
	  }
	  for(i &lt;- 0 until y._2.size()){
		itemNameList.add(y._2.get(i))
	  }

	  val itemValueList = new ArrayList[String]()
	  for(i &lt;- 0 until x._3.size()){
		itemValueList.add(x._3.get(i))
	  }
	  for(i &lt;- 0 until y._3.size()){
		itemValueList.add(y._3.get(i))
	  }

	  (itemIdList, itemNameList, itemValueList)
}, 100)</code></pre> 
<p>再简单一点如下示例：</p> 
<p> </p> 
<pre><code class="language-Scala">carCaseRawInfo.map(x =&gt; {
      val stepInfoList = new util.ArrayList[(Long, String, String, String)]()
      stepInfoList.add((x._4, x._5, x._6, x._7))

      ((x._1, x._3, x._3), stepInfoList)
    })
      .reduceByKey((x, y) =&gt; {
        val stepInfoList = new ArrayList[(Long, String, String, String)]()
        for(i &lt;- 0 until x.size()){
          stepInfoList.add(x.get(i))
        }
        for(i &lt;- 0 until y.size()){
          stepInfoList.add(y.get(i))
        }

        stepInfoList
      }, GlobalConfig.DEFAULT_PARTITIONS_NUM)</code></pre> 
<h2></h2> 
<h2>四、reduce之partition属性</h2> 
<p>首先提一下Shuffle过程，它的本意是洗牌、混乱的意思，类似于java中的Colletions.shuffle(List)方法，它会随机地打乱参数list里地元素顺序。MapReduce的Shuffle过程大致可以理解成：数据从map task输出到reduce task输入的这段过程。</p> 
<p>而partition过程：分割map每个节点的结果，按照key分别映射给不同的reduce，这个是可以自定义的。</p> 
<p>通过设置reduce中的numPartitions值，会在reduce操作之后进行repartition，避免数据不均衡堆在一个partition中。</p> 
<h2>五、reduceByKey和groupByKey的区别</h2> 
<p><strong>从 shuffle 的角度</strong>： reduceByKey 和 groupByKey 都存在 shuffle 的操作，但是 reduceByKey可以在 shuffle 前对分区内相同 key 的数据进行预聚合（combine）功能，这样会减少落盘的数据量，而 groupByKey 只是进行分组，不存在数据量减少的问题，reduceByKey 性能比较高。</p> 
<p><strong>从功能的角度</strong>： reduceByKey 其实包含分组和聚合的功能。GroupByKey 只能分组，不能聚合，所以在分组聚合的场合下，推荐使用 reduceByKey，如果仅仅是分组而不需要聚合。那么还是只能使用 groupByKey 。reduceByKey的分区内和分区间的计算规则是一样的</p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/eff22e72bd309ce9f0906cf883c49157/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">本地idea连接Centos7kafka操作</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/47feb9125eb629167624f866e557eb09/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">解决新版Edge浏览器右上角不显示Copilot图标的问题</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>