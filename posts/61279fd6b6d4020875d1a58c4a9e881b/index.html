<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Window 下Mamba 环境安装踩坑问题汇总及解决方法 （无需绕过selective_scan_cuda） - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/61279fd6b6d4020875d1a58c4a9e881b/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="Window 下Mamba 环境安装踩坑问题汇总及解决方法 （无需绕过selective_scan_cuda）">
  <meta property="og:description" content="导航 Mamba 及 Vim 安装问题参看本人之前博客：Mamba 环境安装踩坑问题汇总及解决方法Windows 下 Vim 安装问题参看本人之前博客：Window 下 Vim 环境安装踩坑问题汇总及解决方法Linux 下Vmamba 安装教程参看本人之前博客：Vmamba 安装教程（无需更改base环境中的cuda版本）Windows 下 VMamba的安装参看本人之前博客：Windows 下 VMamba 安装教程（无需更改base环境中的cuda版本且可加速） 目录 导航背景Windows 下环境准备Windows 下 `mamba-ssm` 的编译Windows 下 `mamba_ssm` 的编译出现的问题及解决（20240714）1. 基本报错信息2. &#34;M_LOG2E&#34; is undefined3. error C2975: “kIsVariableC_”4. error C2975: “kNRows_” 20240724 更新5. ImportError: DLL load failed 背景 Mamba 官方代码链接为：https://github.com/state-spaces/mamba，在原来博客 “Mamba 环境安装踩坑问题汇总及解决方法” 基础上，不绕过selective_scan_cuda，进行 Mamba 环境安装，这样可以获得和 Linux 一样的速度1。
（安装问题 / 资源自取 / 论文合作想法请&#43;vx：931744281）
Windows 下环境准备 前期环境准备，同原来博客 “Mamba 环境安装踩坑问题汇总及解决方法” ，具体为： conda create -n mamba python=3.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-07-28T17:14:35+08:00">
    <meta property="article:modified_time" content="2024-07-28T17:14:35+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Window 下Mamba 环境安装踩坑问题汇总及解决方法 （无需绕过selective_scan_cuda）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_0"></a>导航</h2> 
<ul><li>Mamba 及 Vim 安装问题参看本人之前博客：<a href="https://blog.csdn.net/yyywxk/article/details/136071016">Mamba 环境安装踩坑问题汇总及解决方法</a></li><li>Windows 下 Vim 安装问题参看本人之前博客：<a href="https://blog.csdn.net/yyywxk/article/details/140751923">Window 下 Vim 环境安装踩坑问题汇总及解决方法</a></li><li>Linux 下Vmamba 安装教程参看本人之前博客：<a href="https://blog.csdn.net/yyywxk/article/details/140418043">Vmamba 安装教程（无需更改base环境中的cuda版本）</a></li><li>Windows 下 VMamba的安装参看本人之前博客：<a href="https://blog.csdn.net/yyywxk/article/details/140422758">Windows 下 VMamba 安装教程（无需更改base环境中的cuda版本且可加速）</a></li></ul> 
<p></p> 
<div class="toc"> 
 <h4>目录</h4> 
 <ul><li><a href="#_0" rel="nofollow">导航</a></li><li><a href="#_7" rel="nofollow">背景</a></li><li><a href="#Windows__12" rel="nofollow">Windows 下环境准备</a></li><li><a href="#Windows__mambassm__51" rel="nofollow">Windows 下 `mamba-ssm` 的编译</a></li><li><a href="#Windows__mamba_ssm_20240714_116" rel="nofollow">Windows 下 `mamba_ssm` 的编译出现的问题及解决（20240714）</a></li><li><ul><li><a href="#1__117" rel="nofollow">1. 基本报错信息</a></li><li><a href="#2_M_LOG2E_is_undefined_145" rel="nofollow">2. "M_LOG2E" is undefined</a></li><li><a href="#3_error_C2975_kIsVariableC__163" rel="nofollow">3. error C2975: “kIsVariableC_”</a></li><li><a href="#4_error_C2975_kNRows__171" rel="nofollow">4. error C2975: “kNRows_”</a></li></ul> 
  </li><li><a href="#20240724__179" rel="nofollow">20240724 更新</a></li><li><ul><li><a href="#5_ImportError_DLL_load_failed_180" rel="nofollow">5. ImportError: DLL load failed</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h2><a id="_7"></a>背景</h2> 
<p>Mamba 官方代码链接为：<a href="https://github.com/state-spaces/mamba">https://github.com/state-spaces/mamba</a>，在原来博客 “<a href="https://blog.csdn.net/yyywxk/article/details/136071016">Mamba 环境安装踩坑问题汇总及解决方法</a>” 基础上，不绕过selective_scan_cuda，进行 Mamba 环境安装，这样可以获得和 Linux 一样的速度<sup class="footnote-ref"><a href="#fn1" rel="nofollow" id="fnref1">1</a></sup>。</p> 
<p>（<mark>安装问题 / 资源自取 / 论文合作想法请+vx</mark>：<code>931744281</code>）</p> 
<h2><a id="Windows__12"></a>Windows 下环境准备</h2> 
<ol><li>前期环境准备，同原来博客 “<a href="https://blog.csdn.net/yyywxk/article/details/136071016">Mamba 环境安装踩坑问题汇总及解决方法</a>” ，具体为：</li></ol> 
<pre><code class="prism language-bash">conda create <span class="token parameter variable">-n</span> mamba <span class="token assign-left variable">python</span><span class="token operator">=</span><span class="token number">3.10</span>
conda activate mamba
conda <span class="token function">install</span> <span class="token assign-left variable">cudatoolkit</span><span class="token operator">==</span><span class="token number">11.8</span>
pip <span class="token function">install</span> <span class="token assign-left variable">torch</span><span class="token operator">==</span><span class="token number">2.1</span>.1 <span class="token assign-left variable">torchvision</span><span class="token operator">==</span><span class="token number">0.16</span>.1 <span class="token assign-left variable">torchaudio</span><span class="token operator">==</span><span class="token number">2.1</span>.1 --index-url https://download.pytorch.org/whl/cu118
pip <span class="token function">install</span> <span class="token assign-left variable">setuptools</span><span class="token operator">==</span><span class="token number">68.2</span>.2
conda <span class="token function">install</span> nvidia/label/cuda-11.8.0::cuda-nvcc_win-64
conda <span class="token function">install</span> packaging
pip <span class="token function">install</span> triton-2.0.0-cp310-cp310-win_amd64.whl
</code></pre> 
<p>其中 <code>triton-2.0.0-cp310-cp310-win_amd64.whl</code> 获取参看原来博客 “<a href="https://blog.csdn.net/yyywxk/article/details/136071016">Mamba 环境安装踩坑问题汇总及解决方法</a>” 。</p> 
<ol start="2"><li><code>causal-conv1d</code> 的安装，同原来博客 “<a href="https://blog.csdn.net/yyywxk/article/details/136071016">Mamba 环境安装踩坑问题汇总及解决方法</a>” ，具体细化为：</li></ol> 
<pre><code class="prism language-bash"><span class="token function">git</span> clone https://github.com/Dao-AILab/causal-conv1d.git
<span class="token builtin class-name">cd</span> causal-conv1d
<span class="token function">git</span> checkout v1.1.3  <span class="token comment"># 安装最新版的话，此步可省略</span>
<span class="token builtin class-name">set</span> <span class="token assign-left variable">CAUSAL_CONV1D_FORCE_BUILD</span><span class="token operator">=</span>TRUE
pip <span class="token function">install</span> <span class="token builtin class-name">.</span>
</code></pre> 
<p>官方没有编译好的适用于Windows版本的 whl，因此需要用上述步骤来手动编译。笔者编译好了 Windows 下的 <a href="https://download.csdn.net/download/yyywxk/89164209">causal_conv1d-1.1.1-cp310-cp310-win_amd64.whl</a>，亦可直接下载安装（只适用于torch 2.1）。</p> 
<pre><code class="prism language-bash">pip <span class="token function">install</span> causal_conv1d-1.1.1-cp310-cp310-win_amd64.whl
</code></pre> 
<p>成功安装之后，会在相应虚拟环境中（<code>xxx\conda\envs\xxx\Lib\site-packages\</code>）产生 <code>causal_conv1d_cuda.cp310-win_amd64.pyd </code> <a href="https://download.csdn.net/download/yyywxk/89398119">文件</a>，此文件对应 causal_conv1d_cuda 包。</p> 
<ol start="3"><li><code>mamba-ssm</code> 环境准备，下载工程文件，即</li></ol> 
<pre><code class="prism language-bash"><span class="token function">git</span> clone https://github.com/state-spaces/mamba.git
<span class="token builtin class-name">cd</span> mamba
<span class="token function">git</span> checkout v1.1.3   <span class="token comment"># 安装最新版的话，此步可省略</span>
</code></pre> 
<p>注意，上述过程中，新版 mamba-ssm 需要搭配新版 causal-conv1d，要不然函数不兼容。完成前期工作后进入下一步正式编译。</p> 
<h2><a id="Windows__mambassm__51"></a>Windows 下 <code>mamba-ssm</code> 的编译</h2> 
<ul><li>在mamba源码 <code>setup.py</code> 修改第41行配置：</li></ul> 
<pre><code class="prism language-bash">FORCE_BUILD <span class="token operator">=</span> os.getenv<span class="token punctuation">(</span><span class="token string">"MAMBA_FORCE_BUILD"</span>, <span class="token string">"TRUE"</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token string">"TRUE"</span>
</code></pre> 
<ul><li>将 <code>csrc/selective_scan/selective_scan_fwd_kernel.cuh</code> 的 <code>void selective_scan_fwd_launch</code> 函数改为</li></ul> 
<pre><code class="prism language-cpp"><span class="token keyword">void</span> <span class="token function">selective_scan_fwd_launch</span><span class="token punctuation">(</span>SSMParamsBase <span class="token operator">&amp;</span>params<span class="token punctuation">,</span> cudaStream_t stream<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
    <span class="token comment">// Only kNRows == 1 is tested for now, which ofc doesn't differ from previously when we had each block</span>
    <span class="token comment">// processing 1 row.</span>
    <span class="token keyword">static</span> <span class="token keyword">constexpr</span> <span class="token keyword">int</span> kNRows <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>
    <span class="token function">BOOL_SWITCH</span><span class="token punctuation">(</span>params<span class="token punctuation">.</span>seqlen <span class="token operator">%</span> <span class="token punctuation">(</span>kNThreads <span class="token operator">*</span> kNItems<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">,</span> kIsEvenLen<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">&amp;</span><span class="token punctuation">]</span> <span class="token punctuation">{<!-- --></span>
        <span class="token function">BOOL_SWITCH</span><span class="token punctuation">(</span>params<span class="token punctuation">.</span>is_variable_B<span class="token punctuation">,</span> kIsVariableB<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">&amp;</span><span class="token punctuation">]</span> <span class="token punctuation">{<!-- --></span>
            <span class="token function">BOOL_SWITCH</span><span class="token punctuation">(</span>params<span class="token punctuation">.</span>is_variable_C<span class="token punctuation">,</span> kIsVariableC<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">&amp;</span><span class="token punctuation">]</span> <span class="token punctuation">{<!-- --></span>
                <span class="token function">BOOL_SWITCH</span><span class="token punctuation">(</span>params<span class="token punctuation">.</span>z_ptr <span class="token operator">!=</span> <span class="token keyword">nullptr</span> <span class="token punctuation">,</span> kHasZ<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">&amp;</span><span class="token punctuation">]</span> <span class="token punctuation">{<!-- --></span>
                    <span class="token keyword">using</span> Ktraits <span class="token operator">=</span> Selective_Scan_fwd_kernel_traits<span class="token operator">&lt;</span>kNThreads<span class="token punctuation">,</span> kNItems<span class="token punctuation">,</span> kNRows<span class="token punctuation">,</span> kIsEvenLen<span class="token punctuation">,</span> kIsVariableB<span class="token punctuation">,</span> kIsVariableC<span class="token punctuation">,</span> kHasZ<span class="token punctuation">,</span> input_t<span class="token punctuation">,</span> weight_t<span class="token operator">&gt;</span><span class="token punctuation">;</span>
                    <span class="token comment">// constexpr int kSmemSize = Ktraits::kSmemSize;</span>
                    <span class="token keyword">static</span> <span class="token keyword">constexpr</span> <span class="token keyword">int</span> kSmemSize <span class="token operator">=</span> Ktraits<span class="token double-colon punctuation">::</span>kSmemSize <span class="token operator">+</span> kNRows <span class="token operator">*</span> MAX_DSTATE <span class="token operator">*</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">typename</span> <span class="token class-name">Ktraits</span><span class="token double-colon punctuation">::</span>scan_t<span class="token punctuation">)</span><span class="token punctuation">;</span>
                    <span class="token comment">// printf("smem_size = %d\n", kSmemSize);</span>
                    dim3 <span class="token function">grid</span><span class="token punctuation">(</span>params<span class="token punctuation">.</span>batch<span class="token punctuation">,</span> params<span class="token punctuation">.</span>dim <span class="token operator">/</span> kNRows<span class="token punctuation">)</span><span class="token punctuation">;</span>
                    <span class="token keyword">auto</span> kernel <span class="token operator">=</span> <span class="token operator">&amp;</span>selective_scan_fwd_kernel<span class="token operator">&lt;</span>Ktraits<span class="token operator">&gt;</span><span class="token punctuation">;</span>
                    <span class="token keyword">if</span> <span class="token punctuation">(</span>kSmemSize <span class="token operator">&gt;=</span> <span class="token number">48</span> <span class="token operator">*</span> <span class="token number">1024</span><span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
                        <span class="token function">C10_CUDA_CHECK</span><span class="token punctuation">(</span><span class="token function">cudaFuncSetAttribute</span><span class="token punctuation">(</span>
                            kernel<span class="token punctuation">,</span> cudaFuncAttributeMaxDynamicSharedMemorySize<span class="token punctuation">,</span> kSmemSize<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                    <span class="token punctuation">}</span>
                    kernel<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span>grid<span class="token punctuation">,</span> Ktraits<span class="token double-colon punctuation">::</span>kNThreads<span class="token punctuation">,</span> kSmemSize<span class="token punctuation">,</span> stream<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span>params<span class="token punctuation">)</span><span class="token punctuation">;</span>
                    <span class="token function">C10_CUDA_KERNEL_LAUNCH_CHECK</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
                <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre> 
<ul><li>将<code>csrc/selective_scan/static_switch.h</code> 的 <code>BOOL_SWITCH</code> 函数改为</li></ul> 
<pre><code class="prism language-cpp"><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">define</span> <span class="token macro-name function">BOOL_SWITCH</span><span class="token expression"><span class="token punctuation">(</span>COND<span class="token punctuation">,</span> CONST_NAME<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>                                           </span><span class="token punctuation">\</span>
    <span class="token expression"><span class="token punctuation">[</span><span class="token operator">&amp;</span><span class="token punctuation">]</span> <span class="token punctuation">{<!-- --></span>                                                                            </span><span class="token punctuation">\</span>
        <span class="token expression"><span class="token keyword">if</span> <span class="token punctuation">(</span>COND<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>                                                                  </span><span class="token punctuation">\</span>
            <span class="token expression"><span class="token keyword">static</span> <span class="token keyword">constexpr</span> <span class="token keyword">bool</span> CONST_NAME <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>                                        </span><span class="token punctuation">\</span>
            <span class="token expression"><span class="token keyword">return</span> <span class="token function">__VA_ARGS__</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                                                    </span><span class="token punctuation">\</span>
        <span class="token expression"><span class="token punctuation">}</span> <span class="token keyword">else</span> <span class="token punctuation">{<!-- --></span>                                                                     </span><span class="token punctuation">\</span>
            <span class="token expression"><span class="token keyword">static</span> <span class="token keyword">constexpr</span> <span class="token keyword">bool</span> CONST_NAME <span class="token operator">=</span> <span class="token boolean">false</span><span class="token punctuation">;</span>                                       </span><span class="token punctuation">\</span>
            <span class="token expression"><span class="token keyword">return</span> <span class="token function">__VA_ARGS__</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>                                                    </span><span class="token punctuation">\</span>
        <span class="token expression"><span class="token punctuation">}</span>                                                                            </span><span class="token punctuation">\</span>
    <span class="token expression"><span class="token punctuation">}</span><span class="token punctuation">(</span><span class="token punctuation">)</span></span></span>
</code></pre> 
<p>（这两步是将 <code>constexpr</code> 改为 <code>static constexpr</code>）</p> 
<ul><li>在 <code>csrc/selective_scan/cus/selective_scan_bwd_kernel.cuh</code> 和 <code>csrc/selective_scan/cus/selective_scan_fwd_kernel.cuh</code> 文件开头加入：</li></ul> 
<pre><code class="prism language-cpp"><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">ifndef</span> <span class="token expression">M_LOG2E</span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">define</span> <span class="token macro-name">M_LOG2E</span> <span class="token expression"><span class="token number">1.4426950408889634074</span></span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">endif</span></span>
</code></pre> 
<ul><li>完成上述修改后，执行 <code>pip install .</code> 一般即可顺利编译，成功安装。</li><li>本人编译好的Windows 下的whl 也有：<a href="https://download.csdn.net/download/yyywxk/89541209">mamba-ssm-1.1.3</a> （只适用于torch 2.1），可直接下载安装或联系本人vx自取。利用 whl 安装命令为：</li></ul> 
<pre><code class="prism language-bash">pip <span class="token function">install</span> mamba_ssm-1.1.3-cp310-cp310-win-amd64.whl
</code></pre> 
<p>由于此时没有绕过selective_scan_cuda，在虚拟环境中（<code>xxx\conda\envs\xxx\Lib\site-packages\</code>）产生了 <a href="https://download.csdn.net/download/yyywxk/89541212">selective-scan-cuda.cp310-win-amd64.pyd</a> 文件，所以运行速度较快。</p> 
<h2><a id="Windows__mamba_ssm_20240714_116"></a>Windows 下 <code>mamba_ssm</code> 的编译出现的问题及解决（20240714）</h2> 
<h3><a id="1__117"></a>1. 基本报错信息</h3> 
<p>如果不进行修改利用 `pip install .`` 直接编译源码时会出现如下报错：</p> 
<pre><code class="prism language-bash">subprocess.CalledProcessError: Command <span class="token string">'['</span>ninja<span class="token string">', '</span>-v<span class="token string">']'</span> returned non-zero <span class="token builtin class-name">exit</span> status <span class="token number">1</span>.
      
      The above exception was the direct cause of the following exception:
      
      Traceback <span class="token punctuation">(</span>most recent call last<span class="token punctuation">)</span>:

        File <span class="token string">"/data/xxx/anaconda3/envs/xxx/lib/python3.10/site-packages/torch/utils/cpp_extension.py"</span>, line <span class="token number">2116</span>, <span class="token keyword">in</span> _run_ninja_build
          raise RuntimeError<span class="token punctuation">(</span>message<span class="token punctuation">)</span> from e
      RuntimeError: Error compiling objects <span class="token keyword">for</span> extension
      <span class="token punctuation">[</span>end of output<span class="token punctuation">]</span>
</code></pre> 
<p>这是最基本的报错信息，只要编译出错就会输出这些，如果在其上面没有看到具体报错，可在 <code>setup.py</code> 里面，将</p> 
<pre><code class="prism language-python">cmdclass<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token string">"bdist_wheel"</span><span class="token punctuation">:</span> CachedWheelsCommand<span class="token punctuation">,</span> <span class="token string">"build_ext"</span><span class="token punctuation">:</span> BuildExtension<span class="token punctuation">}</span>
</code></pre> 
<p>改为</p> 
<pre><code class="prism language-python">cmdclass<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token string">"bdist_wheel"</span><span class="token punctuation">:</span> CachedWheelsCommand<span class="token punctuation">,</span> <span class="token string">"build_ext"</span><span class="token punctuation">:</span> BuildExtension<span class="token punctuation">.</span>with_options<span class="token punctuation">(</span>use_ninja<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
</code></pre> 
<p>pytorch默认使用ninjia作为backend<sup class="footnote-ref"><a href="#fn2" rel="nofollow" id="fnref2">2</a></sup>，禁用掉可以看到具体的报错，但是编译速度实测会变慢，所以解决bug后可以改回来。</p> 
<p>注：<a href="https://blog.csdn.net/baobei0112/article/details/114521271">有的博客</a>将 anaconda环境下的 lib/python3.6/site-packages/torch/utils/cpp_extension.py文件里的[‘ninja’,‘-v’]改成[‘ninja’,‘–v’] 或者[‘ninja’,‘–version’] 是错误的做法，治标不治本。</p> 
<h3><a id="2_M_LOG2E_is_undefined_145"></a>2. “M_LOG2E” is undefined</h3> 
<p>在Windows下会出现如下大量报错：</p> 
<pre><code class="prism language-bash"> xxx<span class="token punctuation">\</span>mamba-1.1.3<span class="token punctuation">\</span>csrc<span class="token punctuation">\</span>selective_scan<span class="token punctuation">\</span>selective_scan_bwd_kernel.cuh<span class="token punctuation">(</span><span class="token number">221</span><span class="token punctuation">)</span>: error: identifier <span class="token string">"M_LOG2E"</span> is undefined
</code></pre> 
<p>出现这种情况的原因，可参考 <a href="https://github.com/gsgen3d/gsgen/issues/3#issuecomment-1741591484">issue</a>：</p> 
<blockquote> 
 <p>Note for the owners: The reason for needing #define is stated here: https://stackoverflow.com/a/56974843:<br> “On windows it is using the Microsoft compiler for that. So the Microsoft compiler is correct to disallow VLA, and there is no way to avoid this AFAIK. Your code works on linux, because on linux nvcc uses the g++ host compiler, and it allows (in a non-standard-compliant way) the use of a VLA in C++ host code.”</p> 
</blockquote> 
<p>因此，只需在<code>csrc/selective_scan/cus/selective_scan_bwd_kernel.cuh</code> 和 <code>csrc/selective_scan/cus/selective_scan_fwd_kernel.cuh</code> 文件加入以下代码即可</p> 
<pre><code class="prism language-cpp"><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">ifndef</span> <span class="token expression">M_LOG2E</span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">define</span> <span class="token macro-name">M_LOG2E</span> <span class="token expression"><span class="token number">1.4426950408889634074</span></span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">endif</span></span>
</code></pre> 
<h3><a id="3_error_C2975_kIsVariableC__163"></a>3. error C2975: “kIsVariableC_”</h3> 
<p>在Windows下会出现如下大量报错：</p> 
<pre><code class="prism language-bash">error C2975: “kIsVariableC_”:“Selective_Scan_bwd_kernel_traits”的模板参数无效，应为编译时常量表达式
</code></pre> 
<p>将<code>csrc/selective_scan/static_switch.h</code> 函数里的 <code>constexpr</code> 改为 <code>static constexpr</code>，参考 <a href="https://github.com/MzeroMiko/VMamba/issues/95#issuecomment-2006282483">issue</a>。具体步骤参看前一节。</p> 
<h3><a id="4_error_C2975_kNRows__171"></a>4. error C2975: “kNRows_”</h3> 
<p>在Windows下会出现如下大量报错：</p> 
<pre><code class="prism language-bash">xxx<span class="token punctuation">\</span>mamba-1.1.3<span class="token punctuation">\</span>csrc<span class="token punctuation">\</span>selective_scan<span class="token punctuation">\</span>selective_scan_fwd_kernel.cuh<span class="token punctuation">(</span><span class="token number">314</span><span class="token punctuation">)</span>: error C2975: “kNRows_”:“Selective_Scan_fwd_kernel_traits”的模板参数无效，应为编译时常量表达式
</code></pre> 
<p>将<code>csrc/selective_scan/selective_scan_fwd_kernel.cuh</code> 函数 <code>void selective_scan_fwd_launch</code> 里的 <code>constexpr</code> 改为 <code>static constexpr</code>，参考 <a href="https://github.com/state-spaces/mamba/issues/12#issuecomment-1848835662">issue</a>。具体步骤参看前一节。</p> 
<h2><a id="20240724__179"></a>20240724 更新</h2> 
<h3><a id="5_ImportError_DLL_load_failed_180"></a>5. ImportError: DLL load failed</h3> 
<p>有的同学在安装好之后发现出现了以下报错：</p> 
<pre><code class="prism language-bash">ImportError: DLL load failed <span class="token keyword">while</span> importing causal_conv1d_cuda: 找不到指定的程序。
</code></pre> 
<p>或者是</p> 
<pre><code class="prism language-bash">ImportError: DLL load failed <span class="token keyword">while</span> importing selective_scan_cuda: 找不到指定的程序。
</code></pre> 
<p>虽然在虚拟环境的相应位置中，已经生成了 <code>causal_conv1d_cuda.cp310-win-amd64.pyd</code> 和 <code>selective-scan-cuda.cp310-win-amd64.pyd</code> 但是还是无法导入调用。</p> 
<p>查询这两个包的依赖项，发现<br> <img src="https://images2.imgbox.com/61/c0/SIMtiEbV_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/84/4e/DWOpOI8Z_o.png" alt="在这里插入图片描述"><br> 它们均高度依赖于torch的相关dll，因此推测出现报错是由于torch的版本发生冲突。卸载torch 并重新安装发现解决问题。（某同学环境中装了两个不同版本的torch，因此冲突）</p> 
<pre><code class="prism language-bash">pip uninstall torch
pip <span class="token function">install</span> <span class="token assign-left variable">torch</span><span class="token operator">==</span><span class="token number">2.1</span>.1 <span class="token assign-left variable">torchvision</span><span class="token operator">==</span><span class="token number">0.16</span>.1 <span class="token assign-left variable">torchaudio</span><span class="token operator">==</span><span class="token number">2.1</span>.1 --index-url https://download.pytorch.org/whl/cu118
</code></pre> 
<p>由于本人前面的编译的两个whl环境均为 torch 2.1，所以大家安装的环境必须也得是2.1，否则通过whl安装调用相关函数时就会报这个错误。</p> 
<hr class="footnotes-sep"> 
<section class="footnotes"> 
 <ol class="footnotes-list"><li id="fn1" class="footnote-item"><p><a href="https://github.com/state-spaces/mamba/issues/12#issuecomment-1848835662">Windows Support #12</a> <a href="#fnref1" rel="nofollow" class="footnote-backref">↩︎</a></p> </li><li id="fn2" class="footnote-item"><p><a href="https://blog.csdn.net/fq9200/article/details/125362088">出现错误“subprocess.CalledProcessError: Command ‘[‘ninja‘, ‘-v‘]‘ returned non-zero exit status 1”解决方法</a> <a href="#fnref2" rel="nofollow" class="footnote-backref">↩︎</a></p> </li></ol> 
</section>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/6a66348cc8cbfce5390b14ebf9e23257/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">AI大模型系列之一：大模型原理科普（深度好文）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/3d1e6ab3685f5e0004489940d8053c14/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Postman中的代理艺术：配置与使用指南</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>