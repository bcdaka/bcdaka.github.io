<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【生成式人工智能-四-chatgpt的训练过程-pretrain预训练&amp;自督导式学习&amp;督导式学习】 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/11e22f9bafe2b14a61c97f6a7e214416/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="【生成式人工智能-四-chatgpt的训练过程-pretrain预训练&自督导式学习&督导式学习】">
  <meta property="og:description" content="大模型是怎么被训练出来的具有人类智慧的 阶段一训练-自我学习-具备知识训练资料self-supervised learning（自督导式学习） 阶段二-怎么让模型具备人的智慧supervised learning 督导式学习预训练pretrain为什么要用预训练的模型？Adapter逆向工程开源的Pre-train参数 参考 一个语言模型是怎么训练出来的呢？它是怎么具备人类智慧的呢？ 它被训练的过程中到底有些什么困难？ 阶段一训练-自我学习-具备知识 我们之前就已经讲过，实际上我们要做的就是寻找一个函数，来实现一个文字接龙的功能：
它的做法，它会寻找要给函数：
输入：中国最高的山是，输出：珠输入：中国最高的山是珠，输出：穆…输入：中国最高的山是朗玛峰，输出：结束符 现在我们知道要实现这个功能我们使用的是一个类神经网络，这个网络有上亿个参数，来实现这样的功能。这上亿个参数是怎么得到的呢，就是通过大量的资料学习到的，就像是人的大脑一样，很难解释每个神经元是怎么作用的，但他们确实可以和谐办公。接下来的要给问题就是到底需要多少的资料才能学会人类的语言呢，又是怎么获取这些资料的呢？
训练资料 要让一个语言模型学会对话，必须具备文法知识以及世界知识，学会文法知识才会知道，“这是一个”这样的表达后面跟的是个名词，而仅仅只有文法知识，还是不够的，所以还需要知道一些世界知识，比如体重的衡量是用公斤数，温度使用摄氏度，不同压力下水的沸点不一样等等。
这篇论文里面可以看得出来，知道文法知识1亿个参数足够了，但是了解世界知识至少需要300亿个以上，那这么多的资料是怎么喂给大模型的呢
self-supervised learning（自督导式学习） 实际上资料的获取并不复杂，因为网络上的资料足够了，但是怎么喂给大模型呢。通常情况下，我们需要的资料是这样的：
输入：今天天气很好 输出：情感正面
也就是说这些数据是带有标签的，但是现在这么多数据我们是无法进行人工标注的。所以今天我们用的技术就是self-supervised learning（自督导式学习）。我们使用网络上爬到的资料，不需要人工标注，处理成如下格式：
比如我们搜到的是中国最高的山是珠穆朗玛峰，我们可以简单的写一个函数，把这个句子处理成：
输入：中国最高的山是，输出：珠输入：中国最高的山是珠，输出：穆…输入：中国最高的山是朗玛峰，输出：结束符 这种不需要人工标注的方式，我们就称为自督导式学习。
阶段二-怎么让模型具备人的智慧 学习了那么多资料，真的就可以有很好的答案了么？
答案是否定的。在GPT-3学习了580G的资料，参数有1750亿，但是答案依然是很难尽如人意，你问它一个问题，它甚至有可能会反问你一个问题，完全没有人类的智慧，跟现在的GPT-4是完全没法比。
其实我们想想也可以知道，从网络上爬来的资料，本身就没有告诉模型，怎么样的回答才是符合人类回复的。
supervised learning 督导式学习 为了让模型具备人类回答的智慧，必须要收集人类对话，进行资料标注，来教会模型该怎么回答。
这种人类标注的训练方法，我们就叫做督导式学习，这个过程就叫做Instructing Fine-tuning
比如从人类收集到的资料：
对于模型来说的输入输出就是：
那你可以说，我们完全使用人力标注的资料那不是更好么？答案确实是，但是人力能够标注的资料有限的，有限的资料训练出来的参数结果可能就会很奇怪。比如你问模型，中国最高的山是什么？ 它很有可能告诉你是：姚明。为什么会出现这样奇怪的答案呢？很有可能是因为资料太少，它只看过这样一个资料。篮球队里最高的人是姚明。
预训练pretrain 那我们有没有更好的方式既能有大量的知识，又能够接受人类的智慧呢？
那就是pretrain，我们使用第一阶段自督导式学习得到的参数，在这个基础上再使用人类标注的数据进行督导式学习，对参数进行微调。
为什么要用预训练的模型？ 因为经过预训练的模型具备很强的能力，它甚至能够达到举一反三的效果：
BERT模型上，如果它看过104种语言的资料，如果我们只用英文做Fine-tune，模型竟然可以做中文的QA，正确率可以达到78.7！！
但还是有一个问题，参数这么多微调一次也很费时间，另外微调过程种参数不会被修改太多，导致失去这些已经学会的知识了呢？Adapter技术就是来解决这个问题的。
Adapter Adapter，就是字面的意思，我在原模型的基础上，我还要再加上一个适配器，适配器的参数比原来的参数要少很多，微调的过程就会变的很快，且不会影响原来的参数。整个模型的输出就是在原来模型参数的基础上，又加上了少量Adapter的参数
LoRA就是一种Adapter技术，Adapter其实包括了很多种可以在https://arxiv.org/abs/2210.06175上找到很多种实现
LLAMA在它的论文中，曾指出自己只需要2万多笔资料，就可以训练好一个模型了,但是还有一个问题，有了它就能训练好一个大模型了么？
答案是不能。因为我们依然还是需要优质的微调资料。
逆向工程 显然不是随便标注就可以得到这些微调需要的优质资料，因为我们不知道用户会怎么问问题，那么怎么获取这部分数据呢？现在有种方法就叫做逆向工程，反问GPT，让他帮忙想问题，想答案，用反向生成出来的内容来微调模型。当GPT是不太喜欢这样的。
有了微调的资料，那参数也是很大的训练成本呀，别着急，有开源的参数
开源的Pre-train参数 Meta 23年开源了LLaMA的参数，我们可以用它来初始化自己的模型。由这个开源的参数，迅速衍生出了一系列的模型，可以说事半功倍
参考 李宏毅-生成式人工智能导论">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-08-07T19:50:50+08:00">
    <meta property="article:modified_time" content="2024-08-07T19:50:50+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【生成式人工智能-四-chatgpt的训练过程-pretrain预训练&amp;自督导式学习&amp;督导式学习】</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>大模型是怎么被训练出来的具有人类智慧的</h4> 
 <ul><li><a href="#_2" rel="nofollow">阶段一训练-自我学习-具备知识</a></li><li><ul><li><a href="#_14" rel="nofollow">训练资料</a></li><li><ul><li><a href="#selfsupervised_learning_19" rel="nofollow">self-supervised learning（自督导式学习）</a></li></ul> 
  </li></ul> 
  </li><li><a href="#_31" rel="nofollow">阶段二-怎么让模型具备人的智慧</a></li><li><ul><li><a href="#supervised_learning__36" rel="nofollow">supervised learning 督导式学习</a></li><li><a href="#pretrain_45" rel="nofollow">预训练pretrain</a></li><li><ul><li><a href="#_49" rel="nofollow">为什么要用预训练的模型？</a></li><li><a href="#Adapter_55" rel="nofollow">Adapter</a></li><li><a href="#_62" rel="nofollow">逆向工程</a></li><li><a href="#Pretrain_65" rel="nofollow">开源的Pre-train参数</a></li></ul> 
  </li></ul> 
  </li><li><a href="#_67" rel="nofollow">参考</a></li></ul> 
</div> 
<br> 一个语言模型是怎么训练出来的呢？它是怎么具备人类智慧的呢？ 它被训练的过程中到底有些什么困难？ 
<p></p> 
<h2><a id="_2"></a>阶段一训练-自我学习-具备知识</h2> 
<p>我们之前就已经讲过，实际上我们要做的就是寻找一个函数，来实现一个文字接龙的功能：<br> 它的做法，它会寻找要给函数：</p> 
<ol><li>输入：中国最高的山是，输出：珠</li><li>输入：中国最高的山是珠，输出：穆</li><li>…</li><li>输入：中国最高的山是朗玛峰，输出：结束符</li></ol> 
<p>现在我们知道要实现这个功能我们使用的是一个类神经网络，这个网络有上亿个参数，来实现这样的功能。这上亿个参数是怎么得到的呢，就是通过大量的资料学习到的，就像是人的大脑一样，很难解释每个神经元是怎么作用的，但他们确实可以和谐办公。接下来的要给问题就是到底需要多少的资料才能学会人类的语言呢，又是怎么获取这些资料的呢？</p> 
<h3><a id="_14"></a>训练资料</h3> 
<p>要让一个语言模型学会对话，必须具备文法知识以及世界知识，学会文法知识才会知道，“这是一个”这样的表达后面跟的是个名词，而仅仅只有文法知识，还是不够的，所以还需要知道一些世界知识，比如体重的衡量是用公斤数，温度使用摄氏度，不同压力下水的沸点不一样等等。<br> <img src="https://images2.imgbox.com/b3/ec/5vlH6XoS_o.png" alt="在这里插入图片描述"><br> 这篇论文里面可以看得出来，知道文法知识1亿个参数足够了，但是了解世界知识至少需要300亿个以上，那这么多的资料是怎么喂给大模型的呢</p> 
<h4><a id="selfsupervised_learning_19"></a>self-supervised learning（自督导式学习）</h4> 
<p>实际上资料的获取并不复杂，因为网络上的资料足够了，但是怎么喂给大模型呢。通常情况下，我们需要的资料是这样的：<br> 输入：今天天气很好 输出：情感正面<br> 也就是说这些数据是带有标签的，但是现在这么多数据我们是无法进行人工标注的。所以今天我们用的技术就是self-supervised learning（自督导式学习）。我们使用网络上爬到的资料，不需要人工标注，处理成如下格式：<br> 比如我们搜到的是中国最高的山是珠穆朗玛峰，我们可以简单的写一个函数，把这个句子处理成：</p> 
<ol><li>输入：中国最高的山是，输出：珠</li><li>输入：中国最高的山是珠，输出：穆</li><li>…</li><li>输入：中国最高的山是朗玛峰，输出：结束符</li></ol> 
<p>这种不需要人工标注的方式，我们就称为自督导式学习。</p> 
<h2><a id="_31"></a>阶段二-怎么让模型具备人的智慧</h2> 
<p>学习了那么多资料，真的就可以有很好的答案了么？<br> 答案是否定的。在GPT-3学习了580G的资料，参数有1750亿，但是答案依然是很难尽如人意，你问它一个问题，它甚至有可能会反问你一个问题，完全没有人类的智慧，跟现在的GPT-4是完全没法比。<br> 其实我们想想也可以知道，从网络上爬来的资料，本身就没有告诉模型，怎么样的回答才是符合人类回复的。</p> 
<h3><a id="supervised_learning__36"></a>supervised learning 督导式学习</h3> 
<p>为了让模型具备人类回答的智慧，必须要收集人类对话，进行资料标注，来教会模型该怎么回答。<br> 这种人类标注的训练方法，我们就叫做督导式学习，这个过程就叫做Instructing Fine-tuning<br> 比如从人类收集到的资料：<br> <img src="https://images2.imgbox.com/c6/05/ptHahBsO_o.png" alt="在这里插入图片描述"><br> 对于模型来说的输入输出就是：<br> <img src="https://images2.imgbox.com/b0/ae/rGB1VL5b_o.png" alt="在这里插入图片描述"><br> 那你可以说，我们完全使用人力标注的资料那不是更好么？答案确实是，但是人力能够标注的资料有限的，有限的资料训练出来的参数结果可能就会很奇怪。比如你问模型，中国最高的山是什么？ 它很有可能告诉你是：姚明。为什么会出现这样奇怪的答案呢？很有可能是因为资料太少，它只看过这样一个资料。篮球队里最高的人是姚明。</p> 
<h3><a id="pretrain_45"></a>预训练pretrain</h3> 
<p>那我们有没有更好的方式既能有大量的知识，又能够接受人类的智慧呢？<br> 那就是pretrain，我们使用第一阶段自督导式学习得到的参数，在这个基础上再使用人类标注的数据进行督导式学习，对参数进行微调。</p> 
<h4><a id="_49"></a>为什么要用预训练的模型？</h4> 
<p>因为经过预训练的模型具备很强的能力，它甚至能够达到举一反三的效果：<br> <img src="https://images2.imgbox.com/d8/fc/5uS6s78V_o.png" alt="在这里插入图片描述"><br> BERT模型上，如果它看过104种语言的资料，如果我们只用英文做Fine-tune，模型竟然可以做中文的QA，正确率可以达到78.7！！</p> 
<p>但还是有一个问题，参数这么多微调一次也很费时间，另外微调过程种参数不会被修改太多，导致失去这些已经学会的知识了呢？Adapter技术就是来解决这个问题的。</p> 
<h4><a id="Adapter_55"></a>Adapter</h4> 
<p>Adapter，就是字面的意思，我在原模型的基础上，我还要再加上一个适配器，适配器的参数比原来的参数要少很多，微调的过程就会变的很快，且不会影响原来的参数。整个模型的输出就是在原来模型参数的基础上，又加上了少量Adapter的参数<br> <img src="https://images2.imgbox.com/c1/46/Y7ZhJ7Mp_o.png" alt="在这里插入图片描述"><br> LoRA就是一种Adapter技术，Adapter其实包括了很多种可以在https://arxiv.org/abs/2210.06175上找到很多种实现<br> LLAMA在它的论文中，曾指出自己只需要2万多笔资料，就可以训练好一个模型了,但是还有一个问题，有了它就能训练好一个大模型了么？<br> 答案是不能。因为我们依然还是需要<strong>优质的</strong>微调资料。</p> 
<h4><a id="_62"></a>逆向工程</h4> 
<p>显然不是随便标注就可以得到这些微调需要的优质资料，因为我们不知道用户会怎么问问题，那么怎么获取这部分数据呢？现在有种方法就叫做逆向工程，反问GPT，让他帮忙想问题，想答案，用反向生成出来的内容来微调模型。当GPT是不太喜欢这样的。<br> 有了微调的资料，那参数也是很大的训练成本呀，别着急，有开源的参数</p> 
<h4><a id="Pretrain_65"></a>开源的Pre-train参数</h4> 
<p>Meta 23年开源了LLaMA的参数，我们可以用它来初始化自己的模型。由这个开源的参数，迅速衍生出了一系列的模型，可以说事半功倍</p> 
<h2><a id="_67"></a>参考</h2> 
<p>李宏毅-生成式人工智能导论</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/b7795bb1bbfc063bb659c11a3fc3b4cf/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">C#进阶-轻量级ORM框架Dapper的使用教程与原理详解</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/ab50c6082650f5c84e379a1c63dcef04/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Lambda 表达式：解锁编程世界的魔法之门</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>