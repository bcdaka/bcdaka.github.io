<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>提高Stable Diffusion十倍计算速度以及解决内存崩溃问题 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/f3dd078b180290da24896badb16abc9c/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="提高Stable Diffusion十倍计算速度以及解决内存崩溃问题">
  <meta property="og:description" content="在启动Stable Diffusion时一直报Torch not compiled with CUDA enabled警告，一开始没在意本着能用就行的态度凑活用，每个图都耗时十多秒，然后本着好奇Torch not compiled with CUDA enabled这个警告去搜索解决方案，都没说这个警告解决了有什么用，并且网上资料东拼西凑根本不能解决问题，本着专研解决问题的心态花一晚上解决这个警告，并将计算速度提高了十倍基本4G的模型2秒能出图。
在这发一个推广：GitHub - stablediffusion-website-online: stable diffusionAI绘画 AI画图生成平台，适合自己开绘画平台网站，包含图片生成及图片浏览
出现这个问题是两个方面一是的确显存不足
本地环境：windows11 13900k 32G Nvidia 3080ti
当前显卡驱动版本：
注意上面的CUDA12.0.147不一定要和CUDA Toolkit 版本一样，但是CUDA Toolkit一定要和pytorch中版本一样
我没用conda太麻烦了，直接裸装到本地python环境速度还快,下面是步骤：
正式开始
首先要安装cuda_11.6.0_511.23_windows.exe 这个版本必须要和pytorch官网对应(其实不一定非要安装最新的cuda老的也可以的只要版本对上），然后安装pytorch可以从官网或者本地，如果安装过程中出现以来报错，可以检查手动安装依赖再重新安装
网盘地址：
我用夸克网盘分享了「cuda驱动」，
链接：夸克网盘分享
关于CUDA Toolkit 与你的显卡驱动版本对应关系可以参考这个文档，他都是大于等于也就是说你的cuda老版本也没关系 CUDA 12.2 Release Notes 可以如上图看显卡版本或者cmd命令行执行nvidia-smi查看
1.下载CUDA Toolkit
CUDA Toolkit 11.6 Downloads | NVIDIA Developer
cuda_11.6.0_511.23_windows.exe （全部下一步）
2.安装pytorch
Start Locally | PyTorch 参考地址
pip都是在cmd命令行安装如果没pip去baidu查一下python pip安装教程，python版本我这里是10.0
组合脚本（在线安装）：
pip install protobuf==3.20.0 requests==2.28.2 torch==1.13.1 torchvision==0.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2023-08-24T22:06:37+08:00">
    <meta property="article:modified_time" content="2023-08-24T22:06:37+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">提高Stable Diffusion十倍计算速度以及解决内存崩溃问题</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>在启动Stable Diffusion时一直报Torch not compiled with CUDA enabled警告，一开始没在意本着能用就行的态度凑活用，每个图都耗时十多秒，然后本着好奇Torch not compiled with CUDA enabled这个警告去搜索解决方案，都没说这个警告解决了有什么用，并且网上资料东拼西凑根本不能解决问题，本着专研解决问题的心态花一晚上解决这个警告，并将计算速度提高了十倍基本4G的模型2秒能出图。</p> 
<p>在这发一个推广：<a href="https://github.com/newlxj/stablediffusion-website-online" title="GitHub - stablediffusion-website-online: stable diffusionAI绘画 AI画图生成平台，适合自己开绘画平台网站，包含图片生成及图片浏览">GitHub - stablediffusion-website-online: stable diffusionAI绘画 AI画图生成平台，适合自己开绘画平台网站，包含图片生成及图片浏览</a></p> 
<p></p> 
<p>出现这个问题是两个方面一是的确显存不足</p> 
<p>本地环境：windows11 13900k 32G Nvidia 3080ti</p> 
<p>当前显卡驱动版本：</p> 
<div> 
 <div> 
  <div> 
   <img alt="" src="https://images2.imgbox.com/6b/15/gQImmZLj_o.png" width="1013"> 
  </div> 
 </div> 
</div> 
<p>注意上面的CUDA12.0.147不一定要和CUDA Toolkit 版本一样，但是CUDA Toolkit一定要和pytorch中版本一样</p> 
<div> 
 <div> 
  <div> 
   <img alt="" src="https://images2.imgbox.com/db/d8/jixS6lAa_o.png" width="1200"> 
  </div> 
 </div> 
</div> 
<p></p> 
<p>我没用conda太麻烦了，直接裸装到本地python环境速度还快,下面是步骤：</p> 
<p></p> 
<p><span style="color:#c21c13;"><strong>正式开始</strong></span></p> 
<p>首先要安装cuda_11.6.0_511.23_windows.exe 这个版本必须要和pytorch官网对应(其实不一定非要安装最新的cuda老的也可以的只要版本对上），然后安装pytorch可以从官网或者本地，如果安装过程中出现以来报错，可以检查手动安装依赖再重新安装</p> 
<p>网盘地址：</p> 
<p>我用夸克网盘分享了「cuda驱动」，</p> 
<p>链接：<a class="kdocs-link" href="https://pan.quark.cn/s/678739c40a91" rel="nofollow" title="夸克网盘分享">夸克网盘分享</a></p> 
<p></p> 
<p>关于CUDA Toolkit 与你的显卡驱动版本对应关系可以参考这个文档，他都是大于等于也就是说你的cuda老版本也没关系 <a class="kdocs-link" href="https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html" rel="nofollow" title="CUDA 12.2 Release Notes">CUDA 12.2 Release Notes</a> 可以如上图看显卡版本或者cmd命令行执行nvidia-smi查看</p> 
<p>1.下载CUDA Toolkit</p> 
<p style="text-align:left;"><a class="kdocs-link" href="https://developer.nvidia.com/cuda-11-6-0-download-archive?target_os=Windows&amp;target_arch=x86_64&amp;target_version=11&amp;target_type=exe_local" rel="nofollow" title="CUDA Toolkit 11.6 Downloads | NVIDIA Developer">CUDA Toolkit 11.6 Downloads | NVIDIA Developer</a></p> 
<p style="text-align:left;">cuda_11.6.0_511.23_windows.exe （全部下一步）</p> 
<p></p> 
<p></p> 
<p>2.安装pytorch</p> 
<p style="text-align:left;"><a class="kdocs-link" href="https://pytorch.org/get-started/locally/" rel="nofollow" title="Start Locally | PyTorch">Start Locally | PyTorch</a> 参考地址</p> 
<p>pip都是在cmd命令行安装如果没pip去baidu查一下python pip安装教程，python版本我这里是10.0</p> 
<p style="text-align:left;">组合脚本（在线安装）：</p> 
<p style="text-align:left;">pip install protobuf==3.20.0 requests==2.28.2 torch==1.13.1 torchvision==0.14.1 torchaudio==0.13.1 --extra-index-url <a class="kdocs-link" href="https://download.pytorch.org/whl/cu116" rel="nofollow" title="https://download.pytorch.org/whl/cu116">https://download.pytorch.org/whl/cu116</a></p> 
<p></p> 
<p>本地安装（可选）</p> 
<p style="text-align:left;">下载地址：<a class="kdocs-link" href="https://download.pytorch.org/whl/cu116/torch-1.13.1%2Bcu116-cp310-cp310-win_amd64.whl" rel="nofollow" title="https://download.pytorch.org/whl/cu116/torch-1.13.1%2Bcu116-cp310-cp310-win_amd64.whl">https://download.pytorch.org/whl/cu116/torch-1.13.1%2Bcu116-cp310-cp310-win_amd64.whl</a></p> 
<p style="text-align:left;">pip install protobuf==3.20.0 requests==2.28.2 torch==1.13.1 torchvision==0.14.1 torchaudio==0.13.1 torch-1.13.1+cu116-cp310-cp310-win_amd64.whl</p> 
<p></p> 
<p>python命令行：</p> 
<p>import torch</p> 
<p>torch.cuda.is_available()</p> 
<p>如果返回true表示安装成功</p> 
<div> 
 <div> 
  <div> 
   <img alt="" src="https://images2.imgbox.com/e0/ee/y5WUESOc_o.png" width="397"> 
  </div> 
 </div> 
</div> 
<div> 
 <div> 
  <div> 
   <img alt="" src="https://images2.imgbox.com/2a/93/cD04Rjp0_o.png" width="1089"> 
  </div> 
 </div> 
</div> 
<p>50步加了很多关键词才19秒不到</p> 
<p></p> 
<div> 
 <div> 
  <div> 
   <img alt="" src="https://images2.imgbox.com/bc/24/Wi36XtI0_o.png" width="1200"> 
  </div> 
 </div> 
</div> 
<p>如果20步只要3秒，并且分辨率也高不会崩溃。</p> 
<div> 
 <div> 
  <div> 
   <img alt="" src="https://images2.imgbox.com/26/d9/QxrrWog1_o.png" width="816"> 
  </div> 
 </div> 
</div> 
<p></p> 
<div> 
 <div> 
  <div> 
   <img alt="" src="https://images2.imgbox.com/dd/9c/39BVsGk4_o.png" width="888"> 
  </div> 
 </div> 
</div> 
<p style="text-align:left;">另外补充就是分辨率采样过高报错问题：</p> 
<blockquote>
  RuntimeError: CUDA out of memory. Tried to allocate 31.29 GiB(GPU 0; 12.00 GiB total capacity; 4.29 GiBlready allocated; 5.1l GiB free; 4.37 GiB reserved in total by PyTorch) If reserved memory is &gt;&gt; allocated memory try setting max_split_size_mb to avoid fragmentation. See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF 
</blockquote> 
<p style="text-align:left;">————————————————</p> 
<p>解决思路作者地址：<a class="kdocs-link" href="https://blog.csdn.net/MirageTanker/article/details/127998036" title="通过设置PYTORCH_CUDA_ALLOC_CONF中的max_split_size_mb解决Pytorch的显存碎片化导致的CUDA:Out Of Memory问题_梦音Yune的博客-CSDN博客">通过设置PYTORCH_CUDA_ALLOC_CONF中的max_split_size_mb解决Pytorch的显存碎片化导致的CUDA:Out Of Memory问题_梦音Yune的博客-CSDN博客</a></p> 
<p></p> 
<p>对于小显存我设置成</p> 
<p>set PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:32 貌似也能解决问题，这个需要在启动bat里面加入一行就行了</p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/6ea2e792ca48f3fcf95723c294febf3a/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">AI 绘画Stable Diffusion 研究（十五）SD Embedding详解</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/82d79d7f99658cab5aae6bc5147d2859/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">LLM系列 | 19 : Llama 2实战(上篇)-本地部署(附代码)</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>