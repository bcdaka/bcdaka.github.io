<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Hadoop框架 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/ea2aa6bb21601eae04aca3259108d421/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="Hadoop框架">
  <meta property="og:description" content="Hadoop框架讲解 Hadoop是一个开源的分布式计算框架，广泛应用于大数据处理和分析领域。它提供了一个可靠、可扩展和高效的方式来处理大规模数据集。本文将介绍Hadoop的基本概念、核心组件和使用方法。
目录 Hadoop简介Hadoop核心组件Hadoop生态系统Hadoop安装与配置Hadoop使用示例总结 Hadoop简介 Hadoop由Apache Software Foundation开发，是一个用于存储和处理大数据的开源框架。它能够在计算机集群上分布式存储和处理大量数据，并具备高容错性和高可扩展性。Hadoop最初由Doug Cutting和Mike Cafarella开发，并以《指环王》中的角色“哈比人”（Hobbit）命名。
Hadoop的特点 分布式存储：将数据分布存储在集群的各个节点上。分布式计算：通过MapReduce编程模型并行处理数据。高容错性：数据在多个节点上进行复制，以保证数据的可靠性。高可扩展性：可以通过增加节点来扩展集群的存储和计算能力。 Hadoop核心组件 Hadoop框架主要包括两个核心组件：
2.1 Hadoop分布式文件系统（HDFS） HDFS是一个分布式文件系统，负责将数据分块存储在集群中的不同节点上。HDFS具有以下特点：
高容错性：数据块会在集群的多个节点上进行复制。高吞吐量：适合大规模数据集的批处理。流数据访问：支持以流式的方式读取数据。 HDFS架构由NameNode和DataNode组成：
NameNode：负责管理文件系统的元数据（如文件路径、数据块位置等）。DataNode：负责存储实际的数据块。 2.2 MapReduce MapReduce是一种分布式计算模型，负责在集群上并行处理大规模数据集。MapReduce编程模型包括两个主要阶段：
Map阶段：将输入数据分割成独立的块，并由Map函数处理生成中间结果。Reduce阶段：将中间结果进行合并处理，生成最终输出结果。 Hadoop生态系统 Hadoop生态系统包括一系列开源项目，用于扩展Hadoop的功能。这些项目包括但不限于：
YARN（Yet Another Resource Negotiator）：资源管理和调度框架。Hive：基于Hadoop的数据仓库，用于查询和管理大规模数据集。Pig：数据流处理语言和执行框架。HBase：分布式NoSQL数据库，基于HDFS构建。Spark：快速、通用的大数据处理引擎。Sqoop：用于在Hadoop和关系型数据库之间传输数据的工具。Flume：用于收集、聚合和移动大数据的分布式服务。 Hadoop安装与配置 4.1 安装前准备 在安装Hadoop之前，需要确保以下条件：
安装Java环境（Hadoop依赖Java）。配置SSH无密码登录（用于节点间通信）。 4.2 下载和安装Hadoop 下载Hadoop：
访问 Apache Hadoop官网 下载Hadoop二进制文件。 解压Hadoop：
tar -xzvf hadoop-x.y.z.tar.gz 配置Hadoop环境变量： 在~/.bashrc文件中添加以下内容：
export HADOOP_HOME=/path/to/hadoop export PATH=$PATH:$HADOOP_HOME/bin export JAVA_HOME=/path/to/java 配置Hadoop核心文件： 编辑$HADOOP_HOME/etc/hadoop/core-site.xml：
&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://localhost:9000&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 编辑$HADOOP_HOME/etc/hadoop/hdfs-site.xml：
&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 格式化HDFS文件系统： hdfs namenode -format 启动Hadoop服务： start-dfs.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-06-23T23:27:59+08:00">
    <meta property="article:modified_time" content="2024-06-23T23:27:59+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Hadoop框架</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="Hadoop_0"></a>Hadoop框架讲解</h2> 
<p>Hadoop是一个开源的分布式计算框架，广泛应用于大数据处理和分析领域。它提供了一个可靠、可扩展和高效的方式来处理大规模数据集。本文将介绍Hadoop的基本概念、核心组件和使用方法。</p> 
<h3><a id="_4"></a>目录</h3> 
<ol><li><a href="#Hadoop%E7%AE%80%E4%BB%8B" rel="nofollow">Hadoop简介</a></li><li><a href="#Hadoop%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6" rel="nofollow">Hadoop核心组件</a></li><li><a href="#Hadoop%E7%94%9F%E6%80%81%E7%B3%BB%E7%BB%9F" rel="nofollow">Hadoop生态系统</a></li><li><a href="#Hadoop%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE" rel="nofollow">Hadoop安装与配置</a></li><li><a href="#Hadoop%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B" rel="nofollow">Hadoop使用示例</a></li><li><a href="#%E6%80%BB%E7%BB%93" rel="nofollow">总结</a></li></ol> 
<h3><a id="Hadoop_13"></a>Hadoop简介</h3> 
<p>Hadoop由Apache Software Foundation开发，是一个用于存储和处理大数据的开源框架。它能够在计算机集群上分布式存储和处理大量数据，并具备高容错性和高可扩展性。Hadoop最初由Doug Cutting和Mike Cafarella开发，并以《指环王》中的角色“哈比人”（Hobbit）命名。</p> 
<h4><a id="Hadoop_17"></a>Hadoop的特点</h4> 
<ul><li><strong>分布式存储</strong>：将数据分布存储在集群的各个节点上。</li><li><strong>分布式计算</strong>：通过MapReduce编程模型并行处理数据。</li><li><strong>高容错性</strong>：数据在多个节点上进行复制，以保证数据的可靠性。</li><li><strong>高可扩展性</strong>：可以通过增加节点来扩展集群的存储和计算能力。</li></ul> 
<h3><a id="Hadoop_24"></a>Hadoop核心组件</h3> 
<p>Hadoop框架主要包括两个核心组件：</p> 
<h4><a id="21_HadoopHDFS_28"></a>2.1 Hadoop分布式文件系统（HDFS）</h4> 
<p>HDFS是一个分布式文件系统，负责将数据分块存储在集群中的不同节点上。HDFS具有以下特点：</p> 
<ul><li><strong>高容错性</strong>：数据块会在集群的多个节点上进行复制。</li><li><strong>高吞吐量</strong>：适合大规模数据集的批处理。</li><li><strong>流数据访问</strong>：支持以流式的方式读取数据。</li></ul> 
<p>HDFS架构由NameNode和DataNode组成：</p> 
<ul><li><strong>NameNode</strong>：负责管理文件系统的元数据（如文件路径、数据块位置等）。</li><li><strong>DataNode</strong>：负责存储实际的数据块。</li></ul> 
<h4><a id="22_MapReduce_40"></a>2.2 MapReduce</h4> 
<p>MapReduce是一种分布式计算模型，负责在集群上并行处理大规模数据集。MapReduce编程模型包括两个主要阶段：</p> 
<ul><li><strong>Map阶段</strong>：将输入数据分割成独立的块，并由Map函数处理生成中间结果。</li><li><strong>Reduce阶段</strong>：将中间结果进行合并处理，生成最终输出结果。</li></ul> 
<h3><a id="Hadoop_47"></a>Hadoop生态系统</h3> 
<p>Hadoop生态系统包括一系列开源项目，用于扩展Hadoop的功能。这些项目包括但不限于：</p> 
<ul><li><strong>YARN</strong>（Yet Another Resource Negotiator）：资源管理和调度框架。</li><li><strong>Hive</strong>：基于Hadoop的数据仓库，用于查询和管理大规模数据集。</li><li><strong>Pig</strong>：数据流处理语言和执行框架。</li><li><strong>HBase</strong>：分布式NoSQL数据库，基于HDFS构建。</li><li><strong>Spark</strong>：快速、通用的大数据处理引擎。</li><li><strong>Sqoop</strong>：用于在Hadoop和关系型数据库之间传输数据的工具。</li><li><strong>Flume</strong>：用于收集、聚合和移动大数据的分布式服务。</li></ul> 
<h3><a id="Hadoop_59"></a>Hadoop安装与配置</h3> 
<h4><a id="41__61"></a>4.1 安装前准备</h4> 
<p>在安装Hadoop之前，需要确保以下条件：</p> 
<ul><li>安装Java环境（Hadoop依赖Java）。</li><li>配置SSH无密码登录（用于节点间通信）。</li></ul> 
<h4><a id="42_Hadoop_68"></a>4.2 下载和安装Hadoop</h4> 
<ol><li> <p><strong>下载Hadoop</strong>：</p> 
  <ul><li>访问 <a href="http://hadoop.apache.org/" rel="nofollow">Apache Hadoop官网</a> 下载Hadoop二进制文件。</li></ul> </li><li> <p><strong>解压Hadoop</strong>：</p> </li></ol> 
<pre><code class="prism language-bash"><span class="token function">tar</span> <span class="token parameter variable">-xzvf</span> hadoop-x.y.z.tar.gz
</code></pre> 
<ol start="3"><li><strong>配置Hadoop环境变量</strong>：</li></ol> 
<p>在<code>~/.bashrc</code>文件中添加以下内容：</p> 
<pre><code class="prism language-bash"><span class="token builtin class-name">export</span> <span class="token assign-left variable">HADOOP_HOME</span><span class="token operator">=</span>/path/to/hadoop
<span class="token builtin class-name">export</span> <span class="token assign-left variable"><span class="token environment constant">PATH</span></span><span class="token operator">=</span><span class="token environment constant">$PATH</span><span class="token builtin class-name">:</span><span class="token variable">$HADOOP_HOME</span>/bin
<span class="token builtin class-name">export</span> <span class="token assign-left variable">JAVA_HOME</span><span class="token operator">=</span>/path/to/java
</code></pre> 
<ol start="4"><li><strong>配置Hadoop核心文件</strong>：</li></ol> 
<p>编辑<code>$HADOOP_HOME/etc/hadoop/core-site.xml</code>：</p> 
<pre><code class="prism language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>fs.defaultFS<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>hdfs://localhost:9000<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">&gt;</span></span>
</code></pre> 
<p>编辑<code>$HADOOP_HOME/etc/hadoop/hdfs-site.xml</code>：</p> 
<pre><code class="prism language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>dfs.replication<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">&gt;</span></span>
</code></pre> 
<ol start="5"><li><strong>格式化HDFS文件系统</strong>：</li></ol> 
<pre><code class="prism language-bash">hdfs namenode <span class="token parameter variable">-format</span>
</code></pre> 
<ol start="6"><li><strong>启动Hadoop服务</strong>：</li></ol> 
<pre><code class="prism language-bash">start-dfs.sh
start-yarn.sh
</code></pre> 
<h4><a id="43__126"></a>4.3 验证安装</h4> 
<p>打开浏览器，访问以下地址，验证Hadoop服务是否启动成功：</p> 
<ul><li>NameNode web界面：<code>http://localhost:9870</code></li><li>ResourceManager web界面：<code>http://localhost:8088</code></li></ul> 
<h3><a id="Hadoop_133"></a>Hadoop使用示例</h3> 
<h4><a id="51_HDFS_135"></a>5.1 上传文件到HDFS</h4> 
<pre><code class="prism language-bash">hdfs dfs <span class="token parameter variable">-mkdir</span> /user
hdfs dfs <span class="token parameter variable">-mkdir</span> /user/username
hdfs dfs <span class="token parameter variable">-put</span> localfile.txt /user/username/
</code></pre> 
<h4><a id="52_MapReduce_143"></a>5.2 运行MapReduce示例</h4> 
<p>Hadoop自带了一些MapReduce示例，可以通过以下命令运行WordCount示例：</p> 
<pre><code class="prism language-bash">hadoop jar <span class="token variable">$HADOOP_HOME</span>/share/hadoop/mapreduce/hadoop-mapreduce-examples-x.y.z.jar wordcount /user/username/input /user/username/output
</code></pre> 
<h4><a id="53__151"></a>5.3 查看结果</h4> 
<pre><code class="prism language-bash">hdfs dfs <span class="token parameter variable">-cat</span> /user/username/output/part-r-00000
</code></pre> 
<h3><a id="_157"></a>总结</h3> 
<p>Hadoop是一个强大的分布式计算框架，适用于处理大规模数据集。通过掌握Hadoop的核心组件（HDFS和MapReduce）以及其生态系统中的工具，可以高效地存储和处理大数据。在实际应用中，Hadoop已经成为大数据处理的标准工具，希望这篇博文对你理解和使用Hadoop有所帮助。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/e2bf324e7dc0c6db928fad79788ac223/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">在 Java 中，JDK、JRE、JVM 分别代表什么，有何关系和区别？</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/dbee0e5f87355e4d322e971380880d8f/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">深入分析 Android BroadcastReceiver (二)</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>