<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Kafka 安装教程和基本操作 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/652f9080ec36bda1ae8ed3e787123769/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="Kafka 安装教程和基本操作">
  <meta property="og:description" content="一、简介 Kafka 是最初由 Linkedin 公司开发，是一个分布式、分区的、多副本的、多订阅者，基于 zookeeper 协调的分布式日志系统（也可以当做 MQ 系统），常见可以用于 web/nginx 日志、访问日志，消息服务等等，Linkedin于2010年12月贡献给了 Apache基金会 并成为顶级开源项目。
应用特性 分布式存储：数据被自动分区并分布在集群的节点中。消息有序性：Kafka 能确保从生产者传到消费者的记录都是有序的。高容错性：允许集群中节点失败（若副本数量为n,则允许n-1个节点失败）。高吞吐量：Kafka 支持单机每秒至少处理10万以上消息，通常可以达到数百万条消息。易扩展性：支持集群热扩展。高并发：支持数千个客户端同时读写。持久性：支持消息数据持久化到本地磁盘 并支持数据备份和灵活配置数据的持久化时间。实时处理/低延迟：在数据写入的同时对进行处理，消息延迟最低只有几毫秒。 应用场景 Kafka 本质是 支持分布式的消息系统/消息中间件 。分析 Kafka 的应用场景等同于分析 消息中级件 的应用场景。通常，使用 消息系统 的 发布/订阅模型 功能来连接 生产者 和 消费者。实现以下三大功能：
生产者和消费者的解耦消息持久化 / 消息冗余消息缓冲 / 流量消峰 具体应用场景有：
日志收集或数据管道：作为日志收集系统或数据处理管道的一部分，以处理大量的日志数据或实时数据流。负载均衡：如果系统收到大量请求或数据流，可以使用消息队列把这些任务平均分配给多个处理器或服务，从而实现负载均衡。系统解耦：消息队列经常用作不同服务间的通信机制，以解耦系统的不同部分。分布式事务：如果一个事务需要跨多个服务进行，可以使用消息队列来协调不同服务之间的通信，确保事务的原子性。实时流数据处理：比如实时日志分析或者实时数据报警。Kafka 能接收实时数据流并保证它的可靠性和持久性，这样就可以在上游源源不断生产数据的同时，下游可以实时地进行分析。通知和实时更新：消息队列可以用作通知的中介，比如告知用户完成某个任务，或者在后端数据更新时实时通知前端。 设计目标 高性能：以时间复杂度为O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间的访问性能。高吞吐率：即使在非常廉价的商用机器上也能做到单机支持每秒100K条消息的传输。消息系统：支持Kafka Server间的消息分区，及分布式消费，同时保证每个partition内的消息顺序传输。横向扩展：支持在线水平热扩展 二、kafka安装和配置 1. zookeeper安装配置 需要说明一下， 为了支持 Kafka 的集群功能， Zookeeper 必须使用集群模式部署。
本文以部署 3 个Zookeeper 实例的伪集群为例。具体安装步骤参阅之前的文章：Zookeeper 安装教程和使用指南
2. kafka安装配置 下载链接：Kafka Downloads
下载页面中包含两种下载方式
: kafka-[version]-src.tgz：包含 Kafka 源码和API源码，需要自己编译 a) 安装 [root@Ali ~]# wget https://downloads.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-05-23T17:17:10+08:00">
    <meta property="article:modified_time" content="2024-05-23T17:17:10+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Kafka 安装教程和基本操作</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_0"></a>一、简介</h2> 
<p><code>Kafka</code> 是最初由 <strong>Linkedin</strong> 公司开发，是一个分布式、分区的、多副本的、多订阅者，基于 <code>zookeeper</code> 协调的分布式日志系统（也可以当做 <code>MQ</code> 系统），常见可以用于 <code>web/nginx</code> 日志、访问日志，消息服务等等，<strong>Linkedin</strong>于2010年12月贡献给了 <strong>Apache基金会</strong> 并成为顶级开源项目。</p> 
<h3><a id="_4"></a>应用特性</h3> 
<ul><li><strong>分布式存储</strong>：数据被自动分区并分布在集群的节点中。</li><li><strong>消息有序性</strong>：<code>Kafka</code> 能确保从生产者传到消费者的记录都是有序的。</li><li><strong>高容错性</strong>：允许集群中节点失败（若副本数量为n,则允许n-1个节点失败）。</li><li><strong>高吞吐量</strong>：<code>Kafka</code> 支持单机每秒至少处理10万以上消息，通常可以达到数百万条消息。</li><li><strong>易扩展性</strong>：支持集群热扩展。</li><li><strong>高并发</strong>：支持数千个客户端同时读写。</li><li><strong>持久性</strong>：支持消息数据持久化到本地磁盘 并支持数据备份和灵活配置数据的持久化时间。</li><li><strong>实时处理/低延迟</strong>：在数据写入的同时对进行处理，消息延迟最低只有几毫秒。</li></ul> 
<h3><a id="_14"></a>应用场景</h3> 
<p><code>Kafka</code> 本质是 支持分布式的<code>消息系统/消息中间件</code> 。分析 <code>Kafka</code> 的应用场景等同于分析 <code>消息中级件</code> 的应用场景。通常，使用 <code>消息系统</code> 的 发布/订阅模型 功能来连接 <code>生产者</code> 和 <code>消费者</code>。实现以下三大功能：</p> 
<ul><li>生产者和消费者的解耦</li><li>消息持久化 / 消息冗余</li><li>消息缓冲 / 流量消峰</li></ul> 
<p>具体应用场景有：</p> 
<ul><li><strong>日志收集或数据管道</strong>：作为日志收集系统或数据处理管道的一部分，以处理大量的日志数据或实时数据流。</li><li><strong>负载均衡</strong>：如果系统收到大量请求或数据流，可以使用消息队列把这些任务平均分配给多个处理器或服务，从而实现负载均衡。</li><li><strong>系统解耦</strong>：消息队列经常用作不同服务间的通信机制，以解耦系统的不同部分。</li><li><strong>分布式事务</strong>：如果一个事务需要跨多个服务进行，可以使用消息队列来协调不同服务之间的通信，确保事务的原子性。</li><li><strong>实时流数据处理</strong>：比如实时日志分析或者实时数据报警。Kafka 能接收实时数据流并保证它的可靠性和持久性，这样就可以在上游源源不断生产数据的同时，下游可以实时地进行分析。</li><li><strong>通知和实时更新</strong>：消息队列可以用作通知的中介，比如告知用户完成某个任务，或者在后端数据更新时实时通知前端。</li></ul> 
<h3><a id="_28"></a>设计目标</h3> 
<ul><li><strong>高性能</strong>：以时间复杂度为O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间的访问性能。</li><li><strong>高吞吐率</strong>：即使在非常廉价的商用机器上也能做到单机支持每秒100K条消息的传输。</li><li><strong>消息系统</strong>：支持Kafka Server间的消息分区，及分布式消费，同时保证每个partition内的消息顺序传输。</li><li><strong>横向扩展</strong>：支持在线水平热扩展</li></ul> 
<h2><a id="kafka_34"></a>二、kafka安装和配置</h2> 
<h3><a id="1_zookeeper_35"></a>1. zookeeper安装配置</h3> 
<p>需要说明一下， 为了支持 <code>Kafka</code> 的集群功能， <code>Zookeeper</code> 必须使用集群模式部署。<br> 本文以部署 3 个Zookeeper 实例的伪集群为例。具体安装步骤参阅之前的文章：<a href="https://blog.csdn.net/wengjianhong2099/article/details/139081448">Zookeeper 安装教程和使用指南</a></p> 
<h3><a id="2_kafka_39"></a>2. kafka安装配置</h3> 
<p>下载链接：<a href="https://kafka.apache.org/downloads" rel="nofollow">Kafka Downloads</a></p> 
<blockquote> 
 <p>下载页面中包含两种下载方式</p> 
 <ul><li>: kafka-[version]-src.tgz：包含 Kafka 源码和API源码，需要自己编译</li></ul> 
</blockquote> 
<h4><a id="a__44"></a>a) 安装</h4> 
<pre><code class="prism language-bash"><span class="token punctuation">[</span>root@Ali ~<span class="token punctuation">]</span><span class="token comment"># wget https://downloads.apache.org/kafka/3.6.2/kafka_2.12-3.6.2.tgz</span>
<span class="token punctuation">[</span>root@Ali ~<span class="token punctuation">]</span><span class="token comment"># tar xzvf kafka_2.12-3.6.2.tgz</span>
<span class="token punctuation">[</span>root@Ali ~<span class="token punctuation">]</span><span class="token comment"># mv /usr/local/kafka_2.12-3.6.2 /usr/local/kafka</span>
</code></pre> 
<h4><a id="b__50"></a>b) 配置实例</h4> 
<p>配置第一个 <code>Kafka</code> 实例</p> 
<pre><code class="prism language-bash"><span class="token comment"># broker 编号，集群内必须唯一</span>
<span class="token assign-left variable">broker.id</span><span class="token operator">=</span><span class="token number">1</span>
<span class="token comment"># 监听所有ip的9091端口，PLAINTEXT表示明文传输</span>
<span class="token assign-left variable">listeners</span><span class="token operator">=</span>PLAINTEXT://:9091
<span class="token comment"># 相当于listeners=PLAINTEXT://0.0.0.0:9091</span>
<span class="token comment"># 消息日志存放地址</span>
<span class="token assign-left variable">log.dirs</span><span class="token operator">=</span>/usr/local/kafka/logs
<span class="token comment"># ZooKeeper 地址，多个用,分隔   /kafka指定在zk上的目录</span>
<span class="token assign-left variable">zookeeper.connect</span><span class="token operator">=</span>localhost:12181/kafka,localhost:22181/kafka
</code></pre> 
<p>配置第二个 <code>Kafka</code> 实例</p> 
<pre><code class="prism language-bash"><span class="token comment"># broker 编号，集群内必须唯一</span>
<span class="token assign-left variable">broker.id</span><span class="token operator">=</span><span class="token number">1</span>
<span class="token comment"># 监听所有ip的9092端口，PLAINTEXT表示明文传输</span>
<span class="token assign-left variable">listeners</span><span class="token operator">=</span>PLAINTEXT://:9092
<span class="token comment"># 消息日志存放地址</span>
<span class="token assign-left variable">log.dirs</span><span class="token operator">=</span>/opt/kafka/logs
<span class="token comment"># ZooKeeper 地址，多个用,分隔</span>
<span class="token assign-left variable">zookeeper.connect</span><span class="token operator">=</span>localhost:12181/kafka,localhost:22181/kafka
</code></pre> 
<blockquote> 
 <p>注：两个客户端的listeners中的port不能一样</p> 
</blockquote> 
<h4><a id="4__77"></a>4) 服务管理</h4> 
<pre><code class="prism language-bash"><span class="token comment"># 启动服务 -daemon 表示后台启动</span>
<span class="token variable">$KAFKA_HOME</span>/bin/kafka-server-start.sh <span class="token parameter variable">-daemon</span> config/server.properties


<span class="token comment"># 查看服务</span>
jps <span class="token parameter variable">-l</span>
	<span class="token number">43330</span> org.apache.zookeeper.server.quorum.QuorumPeerMain
	<span class="token number">14356</span> org.elasticsearch.bootstrap.Elasticsearch
	<span class="token number">14583</span> org.logstash.Logstash
	<span class="token number">45976</span> kafka.Kafka  <span class="token comment"># kafka服务进程</span>
	
<span class="token function">netstat</span> <span class="token parameter variable">-anlpt</span> <span class="token operator">|</span> <span class="token function">grep</span> <span class="token number">9091</span>
	tcp6       <span class="token number">0</span>      <span class="token number">0</span> :::9091                 :::*                    LISTEN      <span class="token number">45976</span>/java
	tcp6       <span class="token number">0</span>      <span class="token number">0</span> <span class="token number">192.168</span>.18.128:9091     <span class="token number">192.168</span>.18.128:49356    TIME_WAIT   -

<span class="token comment"># 关闭服务</span>
<span class="token variable">$KAFKA_HOME</span>/bin/kafka-server-stop.sh
</code></pre> 
<h3><a id="3__99"></a>3. 常用操作</h3> 
<h4><a id="1_topic_100"></a>1) 创建topic</h4> 
<pre><code class="prism language-bash"> <span class="token comment">#两条命令效果一样</span>
bin/kafka-topics.sh <span class="token parameter variable">--create</span> --bootstrap-server localhost:9091 <span class="token parameter variable">--partitions</span> <span class="token number">2</span> --replication-factor <span class="token number">2</span> <span class="token parameter variable">--topic</span> yumu
bin/kafka-topics.sh <span class="token parameter variable">--create</span> <span class="token parameter variable">--zookeeper</span> localhost:2181/kafka <span class="token parameter variable">--partitions</span> <span class="token number">2</span> --replication-factor <span class="token number">2</span> <span class="token parameter variable">--topic</span> yumu 
</code></pre> 
<blockquote> 
 <p>在kafka1上创建一个topic，会自动同步到其他客户端</p> 
 <ul><li><code>--create</code>表示创建操作</li><li><code>--zookeeper</code> 指定了 Kafka 连接的 ZooKeeper</li><li><code>--partitions</code> 表示每个主题4个分区</li><li><code>--replication-factor</code> 表示创建每个分区创建2个副本（副本因子）</li><li><code>--topic</code> 表示主题名称。<br> 注：副本因子不能超过存活的broker数量，否则报错：<code>Replication factor: 20 larger than available brokers: xxx.</code></li></ul> 
</blockquote> 
<h4><a id="2_topic_114"></a>2) 查看topic</h4> 
<pre><code class="prism language-bash"><span class="token comment"># 查看topic列表     #两条命令效果一样</span>
bin/kafka-topics.sh <span class="token parameter variable">--list</span> --bootstrap-server localhost:9092
bin/kafka-topics.sh <span class="token parameter variable">--list</span> <span class="token parameter variable">--zookeeper</span> localhost:2181/kafka 
	__consumer_offsets
	topic-demo
	yumu

<span class="token comment"># 查看topic详细信息   #两条命令效果一样</span>
bin/kafka-topics.sh --bootstrap-server localhost:9092 <span class="token parameter variable">--describe</span> <span class="token parameter variable">--topic</span> yumu
bin/kafka-topics.sh <span class="token parameter variable">--zookeeper</span> localhost:2181/kafka <span class="token parameter variable">--describe</span> <span class="token parameter variable">--topic</span> yumu 
	Topic: yumu	PartitionCount: <span class="token number">2</span>	ReplicationFactor: <span class="token number">2</span>	Configs:
		Topic: yumu	Partition: <span class="token number">0</span>	Leader: <span class="token number">1</span>	Replicas: <span class="token number">1,2</span>	Isr: <span class="token number">1,2</span>
		Topic: yumu	Partition: <span class="token number">1</span>	Leader: <span class="token number">1</span>	Replicas: <span class="token number">2,1</span>	Isr: <span class="token number">1,2</span>
</code></pre> 
<h4><a id="3__131"></a>3) 测试通信</h4> 
<pre><code class="prism language-bash"><span class="token comment"># 窗口1，启动生产者，向yumu主题发送消息</span>
bin/kafka-console-producer.sh --bootstrap-server localhost:9092 <span class="token parameter variable">--topic</span> yumu

<span class="token comment"># 窗口2，启动消费者，订阅yumu主题</span>
bin/kafka-console-consumer.sh --bootstrap-server localhost:9091 <span class="token parameter variable">--topic</span> yumu

<span class="token comment"># 窗口3，启动消费者，订阅yumu主题</span>
bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 <span class="token parameter variable">--topic</span> yumu

<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span>结果<span class="token operator">==</span><span class="token operator">==</span><span class="token operator">=</span>
<span class="token comment"># 生产者</span>
bin/kafka-console-producer.sh --bootstrap-server localhost:9092 <span class="token parameter variable">--topic</span> yumu
<span class="token operator">&gt;</span>hello, kafka<span class="token operator">!</span>
<span class="token operator">&gt;</span>once again.
<span class="token operator">&gt;</span>
<span class="token comment"># 消费者1</span>
bin/kafka-console-consumer.sh --bootstrap-server localhost:9091 <span class="token parameter variable">--topic</span> yumu
hello, kafka<span class="token operator">!</span>
once again.

<span class="token comment"># 消费者2</span>
bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 <span class="token parameter variable">--topic</span> yumu
hello, kafka<span class="token operator">!</span>
once again.

<span class="token comment"># 查看所有消息</span>
bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 <span class="token parameter variable">--topic</span> yumu --from-beginning

<span class="token comment"># 删除topic</span>
bin/kafka-topics.sh <span class="token parameter variable">--delete</span> --bootstrap-server localhost:9091  <span class="token parameter variable">--topic</span> yumu
</code></pre> 
<h2><a id="_166"></a>三、遇到的问题</h2> 
<p><strong>1. 第一次启动kafka成功后，关闭kafka并修改配置，再次启动失败，报错如下：</strong></p> 
<pre><code class="prism language-bash"><span class="token punctuation">[</span><span class="token number">2020</span>-11-07 <span class="token number">20</span>:43:00,866<span class="token punctuation">]</span> INFO Cluster ID <span class="token operator">=</span> MChFWWMBT9GJClVEriND5A <span class="token punctuation">(</span>kafka.server.KafkaServer<span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token number">2020</span>-11-07 <span class="token number">20</span>:43:00,873<span class="token punctuation">]</span> ERROR Fatal error during KafkaServer startup. Prepare to <span class="token function">shutdown</span> <span class="token punctuation">(</span>kafka.server.KafkaServer<span class="token punctuation">)</span>
kafka.common.InconsistentClusterIdException: The Cluster ID MChFWWMBT9GJClVEriND5A doesn't match stored clusterId Some<span class="token punctuation">(</span>c6QPfvqlS6C3gtsYZptQ8Q<span class="token punctuation">)</span> <span class="token keyword">in</span> meta.properties. The broker is trying to <span class="token function">join</span> the wrong cluster. Configured zookeeper.connect may be wrong.
        at kafka.server.KafkaServer.startup<span class="token punctuation">(</span>KafkaServer.scala:235<span class="token punctuation">)</span>
        at kafka.server.KafkaServerStartable.startup<span class="token punctuation">(</span>KafkaServerStartable.scala:44<span class="token punctuation">)</span>
        at kafka.Kafka$.main<span class="token punctuation">(</span>Kafka.scala:82<span class="token punctuation">)</span>
        at kafka.Kafka.main<span class="token punctuation">(</span>Kafka.scala<span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token number">2020</span>-11-07 <span class="token number">20</span>:43:00,875<span class="token punctuation">]</span> INFO shutting down <span class="token punctuation">(</span>kafka.server.KafkaServer<span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token number">2020</span>-11-07 <span class="token number">20</span>:43:00,877<span class="token punctuation">]</span> INFO <span class="token punctuation">[</span>ZooKeeperClient Kafka server<span class="token punctuation">]</span> Closing. <span class="token punctuation">(</span>kafka.zookeeper.ZooKeeperClient<span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token number">2020</span>-11-07 <span class="token number">20</span>:43:00,986<span class="token punctuation">]</span> INFO Session: 0x1000da0dde2000c closed <span class="token punctuation">(</span>org.apache.zookeeper.ZooKeeper<span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token number">2020</span>-11-07 <span class="token number">20</span>:43:00,986<span class="token punctuation">]</span> INFO EventThread shut down <span class="token keyword">for</span> session: 0x1000da0dde2000c <span class="token punctuation">(</span>org.apache.zookeeper.ClientCnxn<span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token number">2020</span>-11-07 <span class="token number">20</span>:43:00,987<span class="token punctuation">]</span> INFO <span class="token punctuation">[</span>ZooKeeperClient Kafka server<span class="token punctuation">]</span> Closed. <span class="token punctuation">(</span>kafka.zookeeper.ZooKeeperClient<span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token number">2020</span>-11-07 <span class="token number">20</span>:43:00,992<span class="token punctuation">]</span> INFO shut down completed <span class="token punctuation">(</span>kafka.server.KafkaServer<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">2020</span>-11-07 <span class="token number">20</span>:43:00,992<span class="token punctuation">]</span> ERROR Exiting Kafka. <span class="token punctuation">(</span>kafka.server.KafkaServerStartable<span class="token punctuation">)</span>
<span class="token punctuation">[</span><span class="token number">2020</span>-11-07 <span class="token number">20</span>:43:00,993<span class="token punctuation">]</span> INFO shutting down <span class="token punctuation">(</span>kafka.server.KafkaServer<span class="token punctuation">)</span>
</code></pre> 
<blockquote> 
 <p>原因：<br> kafka启动之后会生成一些日志和配置，导致这个问题的原因是第一次启动之后生成了log/meta.properties文件</p> 
</blockquote> 
<pre><code class="prism language-bash"><span class="token function">cat</span> meta.properties
<span class="token comment">#</span>
<span class="token comment">#Sat Nov 07 21:43:51 CST 2020</span>
<span class="token assign-left variable">broker.id</span><span class="token operator">=</span><span class="token number">1</span>
<span class="token assign-left variable">version</span><span class="token operator">=</span><span class="token number">0</span>
<span class="token assign-left variable">cluster.id</span><span class="token operator">=</span>MChFWWMBT9GJClVEriND5A
</code></pre> 
<blockquote> 
 <p>第二次改完配置后再去启动的时候生成应该会生成一个新的id，新的id和旧的ID不一致导致无法启动，删除log/meta.properties文件后重新启动即可（疑问：是不是我关闭的方法不对呢？）</p> 
</blockquote> 
<p>推荐阅读：</p> 
<ul><li><a href="https://www.cnblogs.com/qingyunzong/p/9004509.html" rel="nofollow">Kafka介绍</a></li><li><a href="https://zhuanlan.zhihu.com/p/122493703" rel="nofollow">ELK介绍</a></li><li><a href="https://www.jianshu.com/p/430454d9e30b" rel="nofollow">Kafka安装</a></li><li><a href="https://zhuanlan.zhihu.com/p/610916585" rel="nofollow">C语言操作kafka以及安装librdkafka库</a></li></ul> 
<p>下一篇：Kafka消息系统原理</p> 
<p><img src="https://images2.imgbox.com/64/de/hJQFJQpZ_o.png" alt="在这里插入图片描述"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/dde535b1b850cf955e01d6f685537498/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">[自动驾驶技术]-5 Tesla自动驾驶方案之算法（AI Day 2021）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/6bccb0d21620f210af022bd366e7906c/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Helm安装kafka3.7.0无持久化（KRaft 模式集群）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>