<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Spark调度底层执行原理详解（第35天） - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/75e810f1e86e51b43087558ef162cb35/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="Spark调度底层执行原理详解（第35天）">
  <meta property="og:description" content="系列文章目录 一、Spark应用程序启动与资源申请
二、DAG（有向无环图）的构建与划分
三、Task的生成与调度
四、Task的执行与结果返回
五、监控与容错
六、优化策略
文章目录 系列文章目录前言一、Spark应用程序启动与资源申请1. SparkContext的创建2. 资源申请 二、DAG（有向无环图）的构建与划分1. DAG的构建2. DAG的划分3. DAG的调度执行4. DAG调度的优化 三、Task的生成与调度1. Task的生成2. Task的调度 四、Task的执行与结果返回1. Task的执行2. 结果的返回 五、监控与容错1. 监控2. 容错 六、优化策略1. 内存计算2. 智能Shuffle机制3. 资源管理与调度 前言 Spark调度底层执行原理是一个复杂而精细的过程，它涉及到多个组件的交互和协同工作，以实现大数据处理的高效性和灵活性。本文主要对Spark调度底层执行原理进行详细解析。
Spark调度底层执行原理详解图
一、Spark应用程序启动与资源申请 1. SparkContext的创建 当Spark应用程序启动时，首先会创建SparkContext对象。SparkContext是Spark的入口点，负责初始化与资源管理器（如YARN、Mesos等）的连接，注册应用，并请求分配Executor资源。
2. 资源申请 SparkContext向资源管理器注册并向其申请运行Executor。资源管理器分配Executor资源后，启动Executor进程。这些Executor是Spark在每个Worker节点上启动的进程，负责执行具体的Task。
二、DAG（有向无环图）的构建与划分 Spark的DAG（Directed Acyclic Graph，有向无环图）调度原理是Spark作业调度机制的核心部分，它负责将复杂的作业分解成可并行执行的任务集，并通过任务调度器进行高效执行。以下是Spark DAG调度原理的详细解释：
1. DAG的构建 用户代码中包含Transformations（转换操作）和Actions（行动操作）时，Spark会构建一个DAG来表示RDD（弹性分布式数据集）之间的依赖关系。这些依赖关系决定了数据处理的流程。
RDD的依赖关系：
在Spark中，RDD（弹性分布式数据集）是数据处理的基本单位。RDD之间的依赖关系决定了数据处理的流程和顺序。这些依赖关系是有向的，总是由子RDD指向父RDD。DAG的生成：
当用户提交一个Spark作业时，Spark会根据RDD之间的依赖关系构建一个DAG。这个DAG表示了作业中所有RDD之间的转换和行动操作，以及它们之间的数据流动关系。 2. DAG的划分 DAG Scheduler负责将DAG划分为多个Stage（阶段）。Stage的划分依据是RDD依赖关系中的宽依赖（如shuffle操作）。宽依赖标志着数据重分布的需求，自然成为Stage的边界。每个Stage包含一组可以并行执行的Task。Stage的划分：
如果RDD之间的依赖是窄依赖（即一个父RDD的分区只会被一个子RDD的分区使用），则它们会被划分到同一个Stage中。如果依赖是宽依赖（即一个父RDD的分区会被多个子RDD的分区使用，通常涉及shuffle操作），则会在宽依赖处进行Stage的划分。
Task的生成：
每个Stage会被进一步划分为多个Task（任务）。这些Task是Spark实际执行的最小单元，它们将被分发到集群中的Executor上执行。 3. DAG的调度执行 Task的提交与执行：
DAG Scheduler将划分好的Stage提交给Task Scheduler。Task Scheduler负责将Stage中的Task分发到集群的Executor上执行。Executor多线程地执行Task，每个线程负责一个Task。执行结果的收集：
当Task执行完成后，会将结果返回给Task Scheduler。Task Scheduler将结果汇总后，通知DAG Scheduler。DAG Scheduler根据Task的执行结果和Stage的依赖关系，决定是否提交下一个Stage执行。容错与重试：">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-07-14T07:15:00+08:00">
    <meta property="article:modified_time" content="2024-07-14T07:15:00+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Spark调度底层执行原理详解（第35天）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-tomorrow-night">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_0"></a>系列文章目录</h2> 
<p>一、Spark应用程序启动与资源申请<br> 二、DAG（有向无环图）的构建与划分<br> 三、Task的生成与调度<br> 四、Task的执行与结果返回<br> 五、监控与容错<br> 六、优化策略<br> </p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#_0" rel="nofollow">系列文章目录</a></li><li><a href="#_11" rel="nofollow">前言</a></li><li><a href="#Spark_17" rel="nofollow">一、Spark应用程序启动与资源申请</a></li><li><ul><li><a href="#1_SparkContext_18" rel="nofollow">1. SparkContext的创建</a></li><li><a href="#2__20" rel="nofollow">2. 资源申请</a></li></ul> 
  </li><li><a href="#DAG_22" rel="nofollow">二、DAG（有向无环图）的构建与划分</a></li><li><ul><li><a href="#1_DAG_26" rel="nofollow">1. DAG的构建</a></li><li><a href="#2_DAG_32" rel="nofollow">2. DAG的划分</a></li><li><a href="#3_DAG_38" rel="nofollow">3. DAG的调度执行</a></li><li><a href="#4_DAG_45" rel="nofollow">4. DAG调度的优化</a></li></ul> 
  </li><li><a href="#Task_51" rel="nofollow">三、Task的生成与调度</a></li><li><ul><li><a href="#1_Task_52" rel="nofollow">1. Task的生成</a></li><li><a href="#2_Task_54" rel="nofollow">2. Task的调度</a></li></ul> 
  </li><li><a href="#Task_56" rel="nofollow">四、Task的执行与结果返回</a></li><li><ul><li><a href="#1_Task_57" rel="nofollow">1. Task的执行</a></li><li><a href="#2__59" rel="nofollow">2. 结果的返回</a></li></ul> 
  </li><li><a href="#_63" rel="nofollow">五、监控与容错</a></li><li><ul><li><a href="#1__64" rel="nofollow">1. 监控</a></li><li><a href="#2__66" rel="nofollow">2. 容错</a></li></ul> 
  </li><li><a href="#_68" rel="nofollow">六、优化策略</a></li><li><ul><li><a href="#1__69" rel="nofollow">1. 内存计算</a></li><li><a href="#2_Shuffle_71" rel="nofollow">2. 智能Shuffle机制</a></li><li><a href="#3__73" rel="nofollow">3. 资源管理与调度</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<hr> 
<h2><a id="_11"></a>前言</h2> 
<p>Spark调度底层执行原理是一个复杂而精细的过程，它涉及到多个组件的交互和协同工作，以实现大数据处理的高效性和灵活性。本文主要对Spark调度底层执行原理进行详细解析。</p> 
<ul><li>Spark调度底层执行原理详解图<br> <img src="https://images2.imgbox.com/b4/6e/go7E0P4j_o.jpg" alt="在这里插入图片描述"></li></ul> 
<h2><a id="Spark_17"></a>一、Spark应用程序启动与资源申请</h2> 
<h3><a id="1_SparkContext_18"></a>1. SparkContext的创建</h3> 
<p>当Spark应用程序启动时，首先会创建SparkContext对象。SparkContext是Spark的入口点，负责初始化与资源管理器（如YARN、Mesos等）的连接，注册应用，并请求分配Executor资源。</p> 
<h3><a id="2__20"></a>2. 资源申请</h3> 
<p>SparkContext向资源管理器注册并向其申请运行Executor。资源管理器分配Executor资源后，启动Executor进程。这些Executor是Spark在每个Worker节点上启动的进程，负责执行具体的Task。</p> 
<h2><a id="DAG_22"></a>二、DAG（有向无环图）的构建与划分</h2> 
<p>Spark的DAG（Directed Acyclic Graph，有向无环图）调度原理是Spark作业调度机制的核心部分，它负责将复杂的作业分解成可并行执行的任务集，并通过任务调度器进行高效执行。以下是Spark DAG调度原理的详细解释：<br> <img src="https://images2.imgbox.com/72/90/ddUQhgIs_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="1_DAG_26"></a>1. DAG的构建</h3> 
<p>用户代码中包含Transformations（转换操作）和Actions（行动操作）时，Spark会构建一个DAG来表示RDD（弹性分布式数据集）之间的依赖关系。这些依赖关系决定了数据处理的流程。</p> 
<ul><li>RDD的依赖关系：<br> 在Spark中，RDD（弹性分布式数据集）是数据处理的基本单位。RDD之间的依赖关系决定了数据处理的流程和顺序。这些依赖关系是有向的，总是由子RDD指向父RDD。</li><li>DAG的生成：<br> 当用户提交一个Spark作业时，Spark会根据RDD之间的依赖关系构建一个DAG。这个DAG表示了作业中所有RDD之间的转换和行动操作，以及它们之间的数据流动关系。</li></ul> 
<h3><a id="2_DAG_32"></a>2. DAG的划分</h3> 
<ul><li>DAG Scheduler负责将DAG划分为多个Stage（阶段）。Stage的划分依据是RDD依赖关系中的宽依赖（如shuffle操作）。宽依赖标志着数据重分布的需求，自然成为Stage的边界。每个Stage包含一组可以并行执行的Task。</li><li>Stage的划分：<br> 如果RDD之间的依赖是窄依赖（即一个父RDD的分区只会被一个子RDD的分区使用），则它们会被划分到同一个Stage中。如果依赖是宽依赖（即一个父RDD的分区会被多个子RDD的分区使用，通常涉及shuffle操作），则会在宽依赖处进行Stage的划分。<br> Task的生成：<br> 每个Stage会被进一步划分为多个Task（任务）。这些Task是Spark实际执行的最小单元，它们将被分发到集群中的Executor上执行。</li></ul> 
<h3><a id="3_DAG_38"></a>3. DAG的调度执行</h3> 
<ol><li>Task的提交与执行：<br> DAG Scheduler将划分好的Stage提交给Task Scheduler。Task Scheduler负责将Stage中的Task分发到集群的Executor上执行。Executor多线程地执行Task，每个线程负责一个Task。</li><li>执行结果的收集：<br> 当Task执行完成后，会将结果返回给Task Scheduler。Task Scheduler将结果汇总后，通知DAG Scheduler。DAG Scheduler根据Task的执行结果和Stage的依赖关系，决定是否提交下一个Stage执行。</li><li>容错与重试：<br> 如果某个Task执行失败，Task Scheduler会负责重试该Task。如果某个Stage中的所有Task都执行失败，DAG Scheduler会重新提交该Stage执行。这种容错机制保证了Spark作业的健壮性和可靠性。</li></ol> 
<h3><a id="4_DAG_45"></a>4. DAG调度的优化</h3> 
<ol><li>本地性优化：<br> Spark在调度Task时，会尽量将Task分配到存储了所需数据的节点上执行，以减少数据的网络传输开销。这种本地性优化策略提高了Spark作业的执行效率。</li><li>资源动态分配：<br> Spark支持资源的动态分配，即根据作业的执行情况和集群的负载情况动态调整Executor的数量和资源。这种动态分配策略有助于充分利用集群资源，提高资源利用率。<br> 综上所述，Spark的DAG调度原理是一个复杂而高效的过程，它通过将作业分解成可并行执行的Stage和Task，并利用DAG Scheduler和Task Scheduler进行高效的调度执行。同时，Spark还通过本地性优化和资源动态分配等策略来优化DAG调度的性能。</li></ol> 
<h2><a id="Task_51"></a>三、Task的生成与调度</h2> 
<h3><a id="1_Task_52"></a>1. Task的生成</h3> 
<p>DAG Scheduler将每个Stage转换为一个或多个TaskSet（任务集），Task Scheduler负责将这些TaskSet分配到各个Executor上执行。</p> 
<h3><a id="2_Task_54"></a>2. Task的调度</h3> 
<p>Task Scheduler接收DAG Scheduler提交过来的TaskSet，并将Task分发到集群中的Executor上运行。Executor多线程地执行Task，每个线程负责一个Task。</p> 
<h2><a id="Task_56"></a>四、Task的执行与结果返回</h2> 
<h3><a id="1_Task_57"></a>1. Task的执行</h3> 
<p>Task在Executor上执行，处理数据，并将结果返回给Driver。对于ShuffleMapTask，计算结果会写入BlockManager中，并返回给DAG Scheduler一个MapStatus对象，存储BlockManager的基本信息，这些信息将成为下一个阶段任务获取输入数据的依据。</p> 
<h3><a id="2__59"></a>2. 结果的返回</h3> 
<p>对于ResultTask（最终任务），返回的是func函数的计算结果。这些结果会被发送到Driver端，供用户程序进一步处理或展示。</p> 
<h2><a id="_63"></a>五、监控与容错</h2> 
<h3><a id="1__64"></a>1. 监控</h3> 
<p>DAGScheduler监控Job与Task的完成情况，通过回调函数接收TaskScheduler的通知，了解任务的开始、结束、失败等信息，以维护作业和调度阶段的状态信息。</p> 
<h3><a id="2__66"></a>2. 容错</h3> 
<p>如果某个Executor失败，DAGScheduler会根据RDD的依赖关系重新计算丢失的分区。Spark通过RDD的Lineage（血统）进行容错，确保数据的完整性和一致性。</p> 
<h2><a id="_68"></a>六、优化策略</h2> 
<h3><a id="1__69"></a>1. 内存计算</h3> 
<p>Spark利用内存进行计算加速，通过存储RDD的分区在内存中来避免频繁的磁盘读写。这大大提高了数据处理的效率。</p> 
<h3><a id="2_Shuffle_71"></a>2. 智能Shuffle机制</h3> 
<p>在涉及宽依赖的Stage间，数据需经过Shuffle过程重分布。Spark使用了基于排序的Shuffle机制，优化了数据处理的效率和内存使用。</p> 
<h3><a id="3__73"></a>3. 资源管理与调度</h3> 
<p>Spark通过智能的资源管理与调度策略，如FIFO调度策略等，确保任务的高效执行。同时，Spark还优化了数据处理的本地性，优先安排Task在数据所在的节点上执行，以减少网络传输和提高执行效率。<br> 综上所述，Spark调度底层执行原理是一个复杂而精细的过程，它通过高度优化的DAG执行模型、内存计算、智能的Shuffle机制和强大的资源管理与调度策略，实现了大数据处理的高效性和灵活性。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/1f3376c8dafaa68b534770d63b32a689/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Docker 安装 RabbitMQ，自定义数据卷位置启动失败，分析过程</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/7420ea4b1aeca7d7895c19c279daa66d/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【python】Pandas中`ValueError: cannot reindex from a duplicate axis`错误分析</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>