<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【人工智能】本地搭建AI模型Gemma - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/e787c017df9022322c418474ae5d70f4/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="【人工智能】本地搭建AI模型Gemma">
  <meta property="og:description" content="文章目录 前言一、安装条件二、安装ollama优化存储路径(不用优化也行)ollama命令详解：模型命令详解： 三、安装WebUiwindows安装不了docker解决测试 前言 最近看到google的gemma模型很火，因为模型较小对于但功能强大，大模型虽然很好但对于我们普通人来说过于遥远，不管是训练的token来说还是模型的复杂度，小模型都比不上，但是小模型的对于我们的训练成本没有那么高但是可以体验到不一样的感觉。
一、安装条件 最低条件：
2B版本需要2G显存
7B版本需要4G显存
7B的其他版本需要更大
7B我这里使用3050 Laptop测试可以运行但生成速度很慢
二、安装ollama 下载ollama：
https://ollama.com/download
直接安装
安装完成后启动：
使用windows键&#43;R打开运行窗口：
ollama 或者ollama help 优化存储路径(不用优化也行) ollama有个问题是没有选择路径，导致我们如果使用windows下载会下载到c盘中容易c盘爆满，现在来优化这个问题：设置》系统》高级系统设置》环境变量》新建系统变量
名称OLLAMA_MODELS路径给到自己创建新建文件夹：
如果打开了程序重新启动即可生效
ollama命令详解： 命令注释：
serve: 启动 ollama，用于提供模型服务。 create: 从模型文件创建一个模型。 show: 显示模型的信息。 run: 运行一个模型。 pull: 从注册表中拉取一个模型。 push: 将一个模型推送到注册中心 list: 列出模型。 cp: 复制一个模型。 rm: 删除一个模型。 help: 获取有关任何命令的帮助。 常用命令：
ollama run 模型名称:版本 ollama run gemma:2b 模型lib：https://ollama.com/library/
这里选择版本copy命令直接粘贴命令即可下载：
如果优化了存储路径直接可以在文件夹下看到下载的模型
完成后直接可以对话了：
这里运行的2b（版本来看应该是3B）的模型，因为我显卡比较垃圾返回速度比较慢：
模型命令详解： /set: 设置会话变量。
/show: 显示模型信息。
/load : 加载一个会话或模型。
/save : 保存当前会话。">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-03-10T09:30:00+08:00">
    <meta property="article:modified_time" content="2024-03-10T09:30:00+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【人工智能】本地搭建AI模型Gemma</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-dracula">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#_4" rel="nofollow">前言</a></li><li><a href="#_7" rel="nofollow">一、安装条件</a></li><li><a href="#ollama_14" rel="nofollow">二、安装ollama</a></li><li><ul><li><a href="#_25" rel="nofollow">优化存储路径(不用优化也行)</a></li><li><a href="#ollama_35" rel="nofollow">ollama命令详解：</a></li><li><a href="#_67" rel="nofollow">模型命令详解：</a></li></ul> 
  </li><li><a href="#WebUi_80" rel="nofollow">三、安装WebUi</a></li><li><ul><li><a href="#windowsdocker_89" rel="nofollow">windows安装不了docker解决</a></li><li><a href="#_102" rel="nofollow">测试</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<hr> 
<h2><a id="_4"></a>前言</h2> 
<p>最近看到google的gemma模型很火，因为模型较小对于但功能强大，大模型虽然很好但对于我们普通人来说过于遥远，不管是训练的token来说还是模型的复杂度，小模型都比不上，但是小模型的对于我们的训练成本没有那么高但是可以体验到不一样的感觉。</p> 
<h2><a id="_7"></a>一、安装条件</h2> 
<p>最低条件：<br> 2B版本需要2G显存<br> 7B版本需要4G显存<br> 7B的其他版本需要更大<br> 7B我这里使用3050 Laptop测试可以运行但生成速度很慢</p> 
<h2><a id="ollama_14"></a>二、安装ollama</h2> 
<p>下载ollama：<br> https://ollama.com/download<br> 直接安装<br> <img src="https://images2.imgbox.com/c2/44/y7XvhX0a_o.png" alt="在这里插入图片描述"><br> 安装完成后启动：<br> 使用windows键+R打开运行窗口：</p> 
<pre><code>ollama 或者ollama help
</code></pre> 
<p><img src="https://images2.imgbox.com/d2/8a/h13M6HAl_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="_25"></a>优化存储路径(不用优化也行)</h3> 
<p>ollama有个问题是没有选择路径，导致我们如果使用windows下载会下载到c盘中容易c盘爆满，现在来优化这个问题：设置》系统》高级系统设置》环境变量》新建系统变量</p> 
<p><img src="https://images2.imgbox.com/b0/e3/QYcqi8le_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/06/3d/6kFTMgc8_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/75/dd/KBhRJWA6_o.png" alt="在这里插入图片描述"><br> 名称<code>OLLAMA_MODELS</code>路径给到自己创建新建文件夹：<br> <img src="https://images2.imgbox.com/c0/57/q7yJZDAR_o.png" alt="在这里插入图片描述"><br> 如果打开了程序重新启动即可生效</p> 
<h3><a id="ollama_35"></a>ollama命令详解：</h3> 
<p>命令注释：</p> 
<pre><code>serve: 启动 ollama，用于提供模型服务。
create: 从模型文件创建一个模型。
show: 显示模型的信息。
run: 运行一个模型。
pull: 从注册表中拉取一个模型。
push: 将一个模型推送到注册中心
list: 列出模型。
cp: 复制一个模型。
rm: 删除一个模型。
help: 获取有关任何命令的帮助。
</code></pre> 
<p>常用命令：</p> 
<pre><code>ollama run 模型名称:版本          
ollama run gemma:2b

</code></pre> 
<p><img src="https://images2.imgbox.com/4e/ca/CSxsdmO7_o.png" alt="在这里插入图片描述"><br> 模型lib：<a href="https://ollama.com/library/" rel="nofollow">https://ollama.com/library/</a><br> 这里选择版本copy命令直接粘贴命令即可下载：<br> <img src="https://images2.imgbox.com/0d/09/j9DLHSZQ_o.png" alt="在这里插入图片描述"><br> 如果优化了存储路径直接可以在文件夹下看到下载的模型<br> <img src="https://images2.imgbox.com/46/5c/fZoKmCUT_o.png" alt="在这里插入图片描述"></p> 
<p>完成后直接可以对话了：<br> <img src="https://images2.imgbox.com/fc/5e/R2OiVnra_o.png" alt="在这里插入图片描述"><br> 这里运行的2b（版本来看应该是3B）的模型，因为我显卡比较垃圾返回速度比较慢：<br> <img src="https://images2.imgbox.com/06/c6/6gIFsff0_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="_67"></a>模型命令详解：</h3> 
<p>/set: 设置会话变量。<br> /show: 显示模型信息。<br> /load : 加载一个会话或模型。<br> /save : 保存当前会话。<br> /bye: 退出。<br> /?, /help: 获取命令的帮助。<br> /? shortcuts: 获取键盘快捷键的帮助。</p> 
<p>这里的命令会/bye退出就行</p> 
<p>到这里模型已经可以正常运行和返回了</p> 
<h2><a id="WebUi_80"></a>三、安装WebUi</h2> 
<p>项目地址：https://github.com/open-webui/open-webui</p> 
<p>使用docker安装：</p> 
<pre><code>docker run -d -p 8080:8080 -e OLLAMA_API_BASE_URL=http://127.0.0.1:11434/api -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main
</code></pre> 
<p>这里我已经拉取过镜像了如果没拉取这里也会直接拉取的：<br> <img src="https://images2.imgbox.com/f0/e4/Wz5WrjM4_o.png" alt="在这里插入图片描述">启动后访问：http://127.0.0.1:8080/auth/</p> 
<h3><a id="windowsdocker_89"></a>windows安装不了docker解决</h3> 
<p>如果windows没有安装docker可以使用虚拟机Linux安装只需要在调用的时候将API换成本地的地址即可OLLAMA_API_BASE_URL=http://192.168.10.1:11434/api<br> <img src="https://images2.imgbox.com/cf/7d/xgke7EGf_o.png" alt="在这里插入图片描述"><br> 我这里是windows已经有docker了直接访问本地：<br> <img src="https://images2.imgbox.com/1c/29/9HFVU44K_o.png" alt="在这里插入图片描述"><br> 随便注册一个号：<br> <img src="https://images2.imgbox.com/a2/68/N7fD0i0w_o.png" alt="在这里插入图片描述"><br> 注册完成后直接登录：<br> <img src="https://images2.imgbox.com/1b/21/LWeH4341_o.png" alt="在这里插入图片描述"><br> 这里选择下载的模型：<br> <img src="https://images2.imgbox.com/82/5e/RYA5z9id_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/a8/63/uLMjs2cW_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="_102"></a>测试</h3> 
<p>这里的测试不是严格意义上准确：</p> 
<p>在运行2b时花费接近2G显存，回复速度很快，但明显有一些问题如理解问题能力不够：<br> <img src="https://images2.imgbox.com/d0/c1/9isG4hB9_o.png" alt="在这里插入图片描述"></p> 
<p>在运行3B时花费2.5G显存回复速度很慢：回答效果还行</p> 
<p><img src="https://images2.imgbox.com/bf/fc/miavtnSb_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/84/be/c5Z9sXgF_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/67/ff/RrHmgrAL_o.png" alt="在这里插入图片描述"><br> 7B版本<br> <img src="https://images2.imgbox.com/3e/47/UGDFyjUO_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/f2/0e/osRnI3JC_o.png" alt="在这里插入图片描述"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/9b2ca371e7308d055db11dbc864b4d5f/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">GPT-SoVITS-WebUI可以中文声音克隆开源AI工具简介</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/577159e078dafd6c5161c2d5d9b1e941/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">TimescaleDB 开源时序数据库</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>