<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Kafka批量消费 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/5521324c165597bedd4666eb3dbeafe4/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="Kafka批量消费">
  <meta property="og:description" content="在Spring Kafka中，使用@KafkaListener注解处理批量信息时，首先需要开启批量监听模式，并配置相应的consumer参数来控制批量消费行为。以下是配置和处理批量消息的基本步骤：
配置Kafka消费者工厂：
设置batchListener属性为true，使@KafkaListener支持批量消费。
@Bean public ConcurrentKafkaListenerContainerFactory&lt;String, String&gt; kafkaListenerContainerFactory() { ConcurrentKafkaListenerContainerFactory&lt;String, String&gt; factory = new ConcurrentKafkaListenerContainerFactory&lt;&gt;(); factory.setConsumerFactory(consumerFactory()); // 开启批量监听模式 factory.setBatchListener(true); // 其他相关配置，比如并发度、错误处理等 return factory; } 配置消费者参数：
设置ConsumerConfig.MAX_POLL_RECORDS_CONFIG，指定每次poll请求从Kafka服务器获取的最大记录数。并且关闭offset自动提交enable-auto-commit: false
# application.properties 或 application.yml spring: kafka: consumer: bootstrap-servers: localhost:9092 group-id: my-group max-poll-records: 100 # 其他配置项，如enable-auto-commit, auto-offset-reset等 编写批量处理方法：
定义一个方法，其参数是一个包含多条消息的列表，@KafkaListener注解下的方法将会接收到批量的消息。
@KafkaListener(topics = &#34;my-topic&#34;) public void processMessages(List&lt;ConsumerRecord&lt;String, String&gt;&gt; records, Acknowledgment acknowledgment) { try { // 处理批量消息 for (ConsumerRecord&lt;String, String&gt; record : records) { // 对每条消息进行处理 } // 成功处理后手动提交偏移量 acknowledgment.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-03-22T23:10:49+08:00">
    <meta property="article:modified_time" content="2024-03-22T23:10:49+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Kafka批量消费</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>在Spring Kafka中，使用<code>@KafkaListener</code>注解处理批量信息时，首先需要开启批量监听模式，并配置相应的consumer参数来控制批量消费行为。以下是配置和处理批量消息的基本步骤：</p> 
<ol><li> <p><strong>配置Kafka消费者工厂</strong>：<br> 设置<code>batchListener</code>属性为<code>true</code>，使<code>@KafkaListener</code>支持批量消费。</p> <pre><code class="prism language-java"><span class="token annotation punctuation">@Bean</span>
<span class="token keyword">public</span> <span class="token class-name">ConcurrentKafkaListenerContainerFactory</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> <span class="token function">kafkaListenerContainerFactory</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
    <span class="token class-name">ConcurrentKafkaListenerContainerFactory</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> factory <span class="token operator">=</span>
            <span class="token keyword">new</span> <span class="token class-name">ConcurrentKafkaListenerContainerFactory</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    factory<span class="token punctuation">.</span><span class="token function">setConsumerFactory</span><span class="token punctuation">(</span><span class="token function">consumerFactory</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment">// 开启批量监听模式</span>
    factory<span class="token punctuation">.</span><span class="token function">setBatchListener</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment">// 其他相关配置，比如并发度、错误处理等</span>
    <span class="token keyword">return</span> factory<span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre> </li><li> <p><strong>配置消费者参数</strong>：<br> 设置<code>ConsumerConfig.MAX_POLL_RECORDS_CONFIG</code>，指定每次<code>poll</code>请求从Kafka服务器获取的最大记录数。并且关闭offset自动提交enable-auto-commit: false</p> <pre><code class="prism language-properties"># application.properties 或 application.yml
spring:
  kafka:
    consumer:
      bootstrap-servers: localhost:9092
      group-id: my-group
      max-poll-records: 100
      # 其他配置项，如enable-auto-commit, auto-offset-reset等
</code></pre> </li><li> <p><strong>编写批量处理方法</strong>：<br> 定义一个方法，其参数是一个包含多条消息的列表，<code>@KafkaListener</code>注解下的方法将会接收到批量的消息。</p> <pre><code class="prism language-java"><span class="token annotation punctuation">@KafkaListener</span><span class="token punctuation">(</span>topics <span class="token operator">=</span> <span class="token string">"my-topic"</span><span class="token punctuation">)</span>
<span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">processMessages</span><span class="token punctuation">(</span><span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">ConsumerRecord</span><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span><span class="token punctuation">&gt;</span></span> records<span class="token punctuation">,</span>
                            <span class="token class-name">Acknowledgment</span> acknowledgment<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">try</span> <span class="token punctuation">{<!-- --></span>
        <span class="token comment">// 处理批量消息</span>
        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">ConsumerRecord</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> record <span class="token operator">:</span> records<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
            <span class="token comment">// 对每条消息进行处理</span>
        <span class="token punctuation">}</span>

        <span class="token comment">// 成功处理后手动提交偏移量</span>
        acknowledgment<span class="token punctuation">.</span><span class="token function">acknowledge</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span> <span class="token keyword">catch</span> <span class="token punctuation">(</span><span class="token class-name">Exception</span> e<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
        <span class="token comment">// 错误处理，记录错误，考虑是否重试或者有其他补偿措施</span>
        log<span class="token punctuation">.</span><span class="token function">error</span><span class="token punctuation">(</span><span class="token string">"Error processing message batch"</span><span class="token punctuation">,</span> e<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> </li><li> <p><strong>处理异常和偏移量提交</strong>：<br> 当批量处理消息时，需要注意的是，一旦消息处理完成且没有错误，应当手动提交偏移量，以确认这些消息已经被成功消费。如果有消息处理失败，则可能需要根据业务需求选择不同的策略，比如重新尝试处理整个批次、跳过错误消息或者记录错误信息稍后处理。</p> </li></ol> 
<p>通过以上步骤，<code>@KafkaListener</code>就能按照批处理的方式接收并处理Kafka主题中的消息了。</p> 
<p>批量消费Kafka中的消息，然后将这些消息放入队列中，最后利用线程池异步处理这些队列中的消息。这种方式有助于优化资源利用率，尤其是当消息处理逻辑较为耗时或者IO密集型时，可以有效提升系统的并行处理能力和吞吐量。</p> 
<pre><code>import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.kafka.support.Acknowledgment;
import org.springframework.stereotype.Component;
import org.springframework.util.concurrent.ListenableFuture;
import org.springframework.util.concurrent.ListenableFutureCallback;
import org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor;

import java.util.List;
import java.util.concurrent.BlockingQueue;
import java.util.concurrent.LinkedBlockingQueue;

@Component
public class BatchMessageProcessor {

    private final ThreadPoolTaskExecutor taskExecutor;
    private final BlockingQueue&lt;ConsumerRecord&lt;String, String&gt;&gt; messageQueue = new LinkedBlockingQueue&lt;&gt;();

    public BatchMessageProcessor(ThreadPoolTaskExecutor taskExecutor) {
        this.taskExecutor = taskExecutor;
    }

    @KafkaListener(topics = "my-topic", batch = true)
    public void consume(List&lt;ConsumerRecord&lt;String, String&gt;&gt; records, Acknowledgment acknowledgment) {
        for (ConsumerRecord&lt;String, String&gt; record : records) {
            // 将消费到的消息放入队列
            messageQueue.offer(record);
        }

        // 异步处理消息队列
        processMessageQueue(acknowledgment);
    }

    private void processMessageQueue(Acknowledgment acknowledgment) {
        List&lt;ConsumerRecord&lt;String, String&gt;&gt; messagesToProcess;
        synchronized (messageQueue) {
            // 从队列中批量取出消息
            messagesToProcess = new ArrayList&lt;&gt;(messageQueue.size());
            messageQueue.drainTo(messagesToProcess, 100); // 假设批量处理100条
        }

        if (!messagesToProcess.isEmpty()) {
            ListenableFuture&lt;?&gt; future = taskExecutor.submit(() -&gt; {
                for (ConsumerRecord&lt;String, String&gt; record : messagesToProcess) {
                    // 实际处理消息的逻辑
                    processSingleMessage(record);
                }
                // 所有消息处理完毕后提交偏移量
                acknowledgment.acknowledge();
            });

            // 可以添加回调函数，用于处理线程池任务执行后的结果
            future.addCallback(new ListenableFutureCallback&lt;Object&gt;() {
                @Override
                public void onSuccess(Object result) {
                    // 处理成功逻辑
                }

                @Override
                public void onFailure(Throwable ex) {
                    // 处理失败逻辑，如日志记录、重试等
                }
            });
        }
    }

    private void processSingleMessage(ConsumerRecord&lt;String, String&gt; record) {
        // 这里实现单个消息的具体处理逻辑
    }
}
</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/5751ef89573911fb1497c6e2f5721306/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">QT学习之路——Qt QMySQL driver not loaded问题（笔记）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/f9d687fbb877521f538144103ecc5215/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">（MATLAB）第二十一章 Simulink仿真设计初步</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>