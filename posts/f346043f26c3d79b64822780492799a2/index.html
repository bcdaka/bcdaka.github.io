<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Python 爬虫项目实战（一）：破解网易云 VIP 免费下载付费歌曲 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/f346043f26c3d79b64822780492799a2/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="Python 爬虫项目实战（一）：破解网易云 VIP 免费下载付费歌曲">
  <meta property="og:description" content="前言 网络爬虫（Web Crawler），也称为网页蜘蛛（Web Spider）或网页机器人（Web Bot），是一种按照既定规则自动浏览网络并提取信息的程序。爬虫的主要用途包括数据采集、网络索引、内容抓取等。
爬虫的基本原理
种子 URL：爬虫从一个或多个种子 URL 开始，这些 URL 是起点。发送请求：爬虫向这些种子 URL 发送 HTTP 请求，通常是 GET 请求。获取响应：服务器返回网页的 HTML 内容作为响应。解析内容：爬虫解析 HTML 内容，提取所需的数据（如文本、链接、图片等）。提取链接：从网页中提取出所有链接，并将这些链接加入待访问队列。重复过程：爬虫重复上述步骤，直到达到某个停止条件，如爬取了一定数量的页面，或所有页面都被爬取完毕。 爬虫的分类
通用爬虫
设计用于抓取整个互联网的大量网页。搜索引擎（如 Google、Bing）的爬虫就是通用爬虫。 聚焦爬虫
专注于特定主题或领域，抓取相关网页。比如，一个新闻爬虫只抓取新闻网站的内容。 增量爬虫
仅抓取自上次爬取以来发生变化或更新的网页，适用于动态内容更新频繁的网站。 爬虫的合法性和道德
在编写和运行爬虫时，必须遵循以下原则：
遵守网站的 robots.txt：
大多数网站都有一个 robots.txt 文件，规定了哪些页面允许被爬取，哪些不允许。爬虫应当尊重这些规则。
避免过度抓取：
设置适当的抓取频率，避免对服务器造成过大负担。 尊重版权和隐私：
不应抓取或使用受版权保护的内容，或涉及用户隐私的数据。 获取许可：
在某些情况下，最好获得网站管理员的许可，特别是当你打算频繁地抓取大量数据时。 通过以上方法和原则，可以编写高效、可靠且合规的网络爬虫来满足数据采集的需求。 侦察 打开页面
F12 检查定位关键元素
在网络中刷新页面
搜索关键字
查看在页面中的渲染情况是不是我们想要的数据，可以看到这里列出了200首歌那么就是的
在标头中确定数据来源地址及请求方法
源代码 import re import os import requests filename = &#39;music\\&#39; # 如果没有则创建文件夹 if not os.path.exists(filename): os.makedirs(filename) # 请求网址（如果想要爬取其他的榜单的歌曲内容，只需要改这个 url 即可） url = &#39;https://music.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-08-02T15:47:51+08:00">
    <meta property="article:modified_time" content="2024-08-02T15:47:51+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Python 爬虫项目实战（一）：破解网易云 VIP 免费下载付费歌曲</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2>前言</h2> 
<p>网络爬虫（Web Crawler），也称为网页蜘蛛（Web Spider）或网页机器人（Web Bot），是一种按照既定规则自动浏览网络并提取信息的程序。爬虫的主要用途包括数据采集、网络索引、内容抓取等。</p> 
<p><strong>爬虫的基本原理</strong></p> 
<ol><li><strong>种子 URL</strong>：爬虫从一个或多个种子 URL 开始，这些 URL 是起点。</li><li><strong>发送请求</strong>：爬虫向这些种子 URL 发送 HTTP 请求，通常是 GET 请求。</li><li><strong>获取响应</strong>：服务器返回网页的 HTML 内容作为响应。</li><li><strong>解析内容</strong>：爬虫解析 HTML 内容，提取所需的数据（如文本、链接、图片等）。</li><li><strong>提取链接</strong>：从网页中提取出所有链接，并将这些链接加入待访问队列。</li><li><strong>重复过程</strong>：爬虫重复上述步骤，直到达到某个停止条件，如爬取了一定数量的页面，或所有页面都被爬取完毕。</li></ol> 
<p><strong>爬虫的分类</strong></p> 
<ol><li> <p><strong>通用爬虫</strong></p> 
  <ul><li>设计用于抓取整个互联网的大量网页。搜索引擎（如 Google、Bing）的爬虫就是通用爬虫。</li></ul></li><li> <p><strong>聚焦爬虫</strong></p> 
  <ul><li>专注于特定主题或领域，抓取相关网页。比如，一个新闻爬虫只抓取新闻网站的内容。</li></ul></li><li> <p><strong>增量爬虫</strong></p> 
  <ul><li>仅抓取自上次爬取以来发生变化或更新的网页，适用于动态内容更新频繁的网站。</li></ul></li></ol> 
<p><strong>爬虫的合法性和道德</strong></p> 
<p>在编写和运行爬虫时，必须遵循以下原则：</p> 
<ol><li> <p><strong>遵守网站的 <code>robots.txt</code></strong>：</p> 
  <ul><li> <p>大多数网站都有一个 <code>robots.txt</code> 文件，规定了哪些页面允许被爬取，哪些不允许。爬虫应当尊重这些规则。</p> </li></ul></li><li> <p><strong>避免过度抓取</strong>：</p> 
  <ul><li>设置适当的抓取频率，避免对服务器造成过大负担。</li></ul></li><li> <p><strong>尊重版权和隐私</strong>：</p> 
  <ul><li>不应抓取或使用受版权保护的内容，或涉及用户隐私的数据。</li></ul></li><li> <p><strong>获取许可</strong>：</p> 
  <ul><li>在某些情况下，最好获得网站管理员的许可，特别是当你打算频繁地抓取大量数据时。</li></ul></li></ol> 
<p>通过以上方法和原则，可以编写高效、可靠且合规的网络爬虫来满足数据采集的需求。 </p> 
<h2>侦察</h2> 
<p>打开页面</p> 
<p class="img-center"><img alt="" height="1040" src="https://images2.imgbox.com/a3/3b/493fZCCw_o.png" width="1200"></p> 
<p>F12 检查定位关键元素</p> 
<p class="img-center"><img alt="" height="669" src="https://images2.imgbox.com/35/61/0a82ByXB_o.png" width="1019"></p> 
<p>在网络中刷新页面</p> 
<p class="img-center"><img alt="" height="480" src="https://images2.imgbox.com/ab/71/nxSSqFQz_o.png" width="1200"></p> 
<p>搜索关键字</p> 
<p class="img-center"><img alt="" height="325" src="https://images2.imgbox.com/2c/21/rxPzHd7d_o.png" width="430"></p> 
<p>查看在页面中的渲染情况是不是我们想要的数据，可以看到这里列出了200首歌那么就是的</p> 
<p class="img-center"><img alt="" height="445" src="https://images2.imgbox.com/1c/ca/yPOUOj7z_o.png" width="915"></p> 
<p>在标头中确定数据来源地址及请求方法</p> 
<p class="img-center"><img alt="" height="243" src="https://images2.imgbox.com/ab/18/yw44x6Vl_o.png" width="832"></p> 
<h2>源代码</h2> 
<pre><code class="language-python">import re
import os
import requests


filename = 'music\\'

# 如果没有则创建文件夹
if not os.path.exists(filename):
    os.makedirs(filename)

# 请求网址（如果想要爬取其他的榜单的歌曲内容，只需要改这个 url 即可）
url = 'https://music.163.com/playlist?id=3778678'

# 伪造请求头
headers = {
    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36'
}

# 发送请求
response = requests.get(url, headers=headers)

# re.findall
# 这个函数用于在字符串中查找所有与正则表达式模式匹配的部分，并返回一个包含所有匹配项的列表
# r 前缀表示这是一个原始字符串，其中的反斜杠不会被解释为转义字符
# (\d+): 捕获组，匹配一个或多个数字
# (.*?): 捕获组，非贪婪匹配任何字符（包括空字符），直到遇到 &lt;/a&gt;
html_data = re.findall(r'&lt;li&gt;&lt;a href="/song\?id=(\d+)"&gt;(.*?)&lt;/a&gt;', response.text)

# 正则表达式提取出来的一个内容返回是列表 里面每一个元素都是元组
for num_id, title in html_data:
    # 调用接口
    music_url = f'https://music.163.com/song/media/outer/url?id={num_id}.mp3'

    # 发送请求获取二进制数据
    music_content = requests.get(music_url, headers=headers)

    # 保存
    with open('music\\' + title + '.mp3', 'wb') as f:
        f.write(music_content.content)
        print(num_id, title)
</code></pre> 
<h2>项目效果</h2> 
<p class="img-center"><img alt="" height="932" src="https://images2.imgbox.com/85/a2/GuwAI5sA_o.png" width="853"></p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/3964064f6f205f3c374db1a6699228e9/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">llama-factory源码详解——以DPO为例</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/bb282b4a69e61ad8959fe5aa4f6b41df/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">手搓交换排序、归并排序、计数排序</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>