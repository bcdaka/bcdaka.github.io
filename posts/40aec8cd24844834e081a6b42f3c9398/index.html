<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>大数据-84 Spark 集群 RDD创建 RDD-Transformation操作算子 详解 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/40aec8cd24844834e081a6b42f3c9398/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="大数据-84 Spark 集群 RDD创建 RDD-Transformation操作算子 详解">
  <meta property="og:description" content="点一下关注吧！！！非常感谢！！持续更新！！！ 目前已经更新到了： Hadoop（已更完）HDFS（已更完）MapReduce（已更完）Hive（已更完）Flume（已更完）Sqoop（已更完）Zookeeper（已更完）HBase（已更完）Redis （已更完）Kafka（已更完）Spark（正在更新！） 章节内容 上节我们完成了如下的内容：
RDD的介绍RDD的特点、特点介绍Spark 编程模型的介绍 RDD 的创建 SparkContext SparkContext是编写Spark程序用到的第一个类，是Spark的主要入口点，它负责和整个集群的交互。
如果把Spark集群当做服务端，那么Driver就是客户端，SparkContext是客户端的核心SparkContext是Spark对外的接口，负责向调用者提供Spark的各种功能SparkContext用于连接Spark集群、创建RDD、累加器、广播变量 从集合创建RDD 我们在集群的节点上启动 Spark-Shell 进行学习和测试
spark-shell --master local[*] 如果顺利启动，你就可以看到如下的画面：
尝试运行如下的指令，感受一下
Using Scala version 2.12.10 (OpenJDK 64-Bit Server VM, Java 1.8.0_412) Type in expressions to have them evaluated. Type :help for more information. scala&gt; val rdd1 = sc.parallelize(Array(1,2,3,4,5)) rdd1: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[0] at parallelize at &lt;console&gt;:24 scala&gt; rdd2.getNumPartitions res1: Int = 2 scala&gt; rdd2.partitions.length res2: Int = 2 scala&gt; val rdd3 = sc.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-08-15T09:20:19+08:00">
    <meta property="article:modified_time" content="2024-08-15T09:20:19+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">大数据-84 Spark 集群 RDD创建 RDD-Transformation操作算子 详解</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_0"></a>点一下关注吧！！！非常感谢！！持续更新！！！</h2> 
<h2><a id="_1"></a>目前已经更新到了：</h2> 
<ul><li>Hadoop（已更完）</li><li>HDFS（已更完）</li><li>MapReduce（已更完）</li><li>Hive（已更完）</li><li>Flume（已更完）</li><li>Sqoop（已更完）</li><li>Zookeeper（已更完）</li><li>HBase（已更完）</li><li>Redis （已更完）</li><li>Kafka（已更完）</li><li>Spark（正在更新！）</li></ul> 
<h2><a id="_14"></a>章节内容</h2> 
<p>上节我们完成了如下的内容：</p> 
<ul><li>RDD的介绍</li><li>RDD的特点、特点介绍</li><li>Spark 编程模型的介绍</li></ul> 
<p><img src="https://images2.imgbox.com/07/f4/URskOskf_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="RDD__22"></a>RDD 的创建</h2> 
<h3><a id="SparkContext_23"></a>SparkContext</h3> 
<p>SparkContext是编写Spark程序用到的第一个类，是Spark的主要入口点，它负责和整个集群的交互。</p> 
<ul><li>如果把Spark集群当做服务端，那么Driver就是客户端，SparkContext是客户端的核心</li><li>SparkContext是Spark对外的接口，负责向调用者提供Spark的各种功能</li><li>SparkContext用于连接Spark集群、创建RDD、累加器、广播变量</li></ul> 
<h2><a id="RDD_29"></a>从集合创建RDD</h2> 
<p>我们在集群的节点上启动 Spark-Shell 进行学习和测试</p> 
<pre><code class="prism language-shell">spark-shell <span class="token parameter variable">--master</span> local<span class="token punctuation">[</span>*<span class="token punctuation">]</span>
</code></pre> 
<p>如果顺利启动，你就可以看到如下的画面：<br> <img src="https://images2.imgbox.com/e4/22/XehPdvoQ_o.png" alt="在这里插入图片描述"></p> 
<p>尝试运行如下的指令，感受一下</p> 
<pre><code class="prism language-shell">Using Scala version <span class="token number">2.12</span>.10 <span class="token punctuation">(</span>OpenJDK <span class="token number">64</span>-Bit Server VM, Java <span class="token number">1.8</span>.0_412<span class="token punctuation">)</span>
Type <span class="token keyword">in</span> expressions to have them evaluated.
Type :help <span class="token keyword">for</span> <span class="token function">more</span> information.

scala<span class="token operator">&gt;</span> val rdd1 <span class="token operator">=</span> sc.parallelize<span class="token punctuation">(</span>Array<span class="token punctuation">(</span><span class="token number">1,2</span>,3,4,5<span class="token punctuation">))</span>
rdd1: org.apache.spark.rdd.RDD<span class="token punctuation">[</span>Int<span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> at parallelize at <span class="token operator">&lt;</span>console<span class="token operator">&gt;</span>:24

scala<span class="token operator">&gt;</span> rdd2.getNumPartitions
res1: Int <span class="token operator">=</span> <span class="token number">2</span>

scala<span class="token operator">&gt;</span> rdd2.partitions.length
res2: Int <span class="token operator">=</span> <span class="token number">2</span>

scala<span class="token operator">&gt;</span> val rdd3 <span class="token operator">=</span> sc.makeRDD<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token number">1,2</span>,3,4,5<span class="token punctuation">))</span>
rdd3: org.apache.spark.rdd.RDD<span class="token punctuation">[</span>Int<span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> at makeRDD at <span class="token operator">&lt;</span>console<span class="token operator">&gt;</span>:24

scala<span class="token operator">&gt;</span> val rdd4 <span class="token operator">=</span> sc.makeRDD<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">100</span><span class="token punctuation">)</span>
rdd4: org.apache.spark.rdd.RDD<span class="token punctuation">[</span>Int<span class="token punctuation">]</span> <span class="token operator">=</span> ParallelCollectionRDD<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span> at makeRDD at <span class="token operator">&lt;</span>console<span class="token operator">&gt;</span>:24

scala<span class="token operator">&gt;</span> rdd4.getNumPartitions
res3: Int <span class="token operator">=</span> <span class="token number">2</span>

scala<span class="token operator">&gt;</span> 
</code></pre> 
<p>对应的截图如下：<br> <img src="https://images2.imgbox.com/06/2f/zOTQKzuH_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="RDD_66"></a>从文件系统创建RDD</h3> 
<p>用 textFile() 方法来从文件系统中加载数据创建RDD，方法将文件的URI作为参数：</p> 
<ul><li>本地文件系统</li><li>分布式文件系统 HDFS</li><li>Amazon S3的地址</li></ul> 
<pre><code class="prism language-shell"><span class="token comment"># 本地系统 注意文件要确保存在</span>
val lines <span class="token operator">=</span> sc.textFile<span class="token punctuation">(</span><span class="token string">"file:///opt/wzk/1.txt"</span><span class="token punctuation">)</span>
<span class="token comment"># 从分布式文件系统加载</span>
val lines <span class="token operator">=</span> sc.textFile<span class="token punctuation">(</span><span class="token string">"hdfs://h121.wzk.icu:9000/wcinput/wordcount.txt"</span><span class="token punctuation">)</span>
</code></pre> 
<p>运行结果如下图所示：<br> <img src="https://images2.imgbox.com/98/96/bBuxUZ5N_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="RDDRDD_82"></a>从RDD创建RDD</h3> 
<p>本质是将一个RDD转换为另一个RDD，从 Transformation</p> 
<h2><a id="Transformation_86"></a>Transformation</h2> 
<p>RDD的操作算子分为两类：</p> 
<ul><li>Transformation，用来对RDD进行转换，这个操作时延迟执行的（或者是Lazy），Transformation，返回一个新的RDD</li><li>Action，用来触发RDD的计算，得到相关计算结果或者将结果保存到外部系统中，Action：返回int、double、集合（不会返回新的RDD）</li></ul> 
<p>每一个Transformation操作都会产生新的RDD，供给下一个“转换”使用<br> 转换得到RDD是惰性求值，也就是说，整个转换过程只有记录了转换的轨迹，并不会发生真正的计算，只有遇到Action操作时，才会发生真正的计算，开始从学院关系（lineage）源头开始，进行物理的转换操作。</p> 
<p><img src="https://images2.imgbox.com/c7/27/NNr3UTfH_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="1_96"></a>常见转换算子1</h3> 
<ul><li>map(func)：对数据集中的每个元素都用func，然后返回一个新的RDD</li><li>filter(func)：对数据集中的每个元素都是用func，然后返回一个包含使func为true的元素构成RDD</li><li>flatMap(func)：与map类似，每个输入元素被映射为0或多个输出元素</li><li>mapPartitions(func)：和map很像，但是map是将func作用在每个元素上，而mapPartitions是func作用在整个分区上。假设一个RDD有N个元素，M个分区（N &gt;&gt; M），那么map的函数将被调用N次，而mapPartitions中的函数仅被调用M次，一次处理一个分区中的所有元素</li><li>mapPartitionsWithIndex(func)：与mapPartitions类似，多了分区索引值信息</li></ul> 
<h3><a id="1_103"></a>转换算子1测试</h3> 
<h3><a id="map_filter_104"></a>map filter</h3> 
<p>测试如下的代码：</p> 
<pre><code class="prism language-shell">val rdd1 <span class="token operator">=</span> sc.parallelize<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">10</span><span class="token punctuation">)</span>
val rdd2 <span class="token operator">=</span> rdd1.map<span class="token punctuation">(</span>_*2<span class="token punctuation">)</span>
val rdd3 <span class="token operator">=</span> rdd2.filter<span class="token punctuation">(</span>_<span class="token operator">&gt;</span><span class="token number">10</span><span class="token punctuation">)</span>
</code></pre> 
<p>执行结果如下图：<br> <img src="https://images2.imgbox.com/86/51/1WYVGQ3J_o.png" alt="在这里插入图片描述"><br> 我们可以查看当前的结果，但是当前的操作都是Transformation的，并没有真正的执行。<br> 我们需要通过 collect 触发执行，拿到最终的结果</p> 
<pre><code class="prism language-shell">rdd2.collect
rdd3.collect
</code></pre> 
<p>将会触发执行，可以看到结果为：<br> <img src="https://images2.imgbox.com/c4/b8/jgQ7X5EH_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="flatMap_121"></a>flatMap</h3> 
<p>我们从HDFS加载一个文件过来</p> 
<pre><code class="prism language-shell">val rdd4 <span class="token operator">=</span> sc.textFile<span class="token punctuation">(</span><span class="token string">"hdfs://h121.wzk.icu:9000/wcinput/wordcount.txt"</span><span class="token punctuation">)</span>
rdd4.collect
</code></pre> 
<p>执行结果如下图：<br> <img src="https://images2.imgbox.com/79/f1/3Kk3LmRA_o.png" alt=""><br> 我们使用“a”作为分隔符，对这段内容进行分割：</p> 
<pre><code class="prism language-shell">rdd4.flatMap<span class="token punctuation">(</span>_.split<span class="token punctuation">(</span><span class="token string">"a"</span><span class="token punctuation">))</span>.collect
</code></pre> 
<p>执行结果如下图：<br> <img src="https://images2.imgbox.com/d2/b5/teEyfhEj_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="mapPartitions_135"></a>mapPartitions</h4> 
<pre><code class="prism language-shell">val rdd5 <span class="token operator">=</span> rdd1.mapPartitions<span class="token punctuation">(</span>iter <span class="token operator">=</span><span class="token operator">&gt;</span> iter.map<span class="token punctuation">(</span>_*2<span class="token punctuation">))</span>
</code></pre> 
<p>执行结果如下<br> <img src="https://images2.imgbox.com/5d/ac/TvPL1h0F_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="_map__mapPartitions_141"></a>对比 map 和 mapPartitions</h4> 
<p>上面我们用：</p> 
<ul><li>rdd1.map(_*2)</li><li>rdd1.mapPartitions(iter =&gt; iter.map(_*2))</li></ul> 
<p>那么这两种有什么区别呢？</p> 
<ul><li>map：每次只处理一条数据</li><li>mapPartitions：每次处理一个分区的数据，分区的数据处理完成后，数据才能释放，资源不足时容易OOM</li><li>当资源充足时，建议使用 mapPartitions，充分提高处理效率</li></ul> 
<h3><a id="2_151"></a>常见转换算子2</h3> 
<ul><li>groupBy（func）：按照传入函数的返回值进行分组，将key相同的值放入一个迭代器</li><li>glom（）：将每一个分区形成一个数组，形成新的RDD类型RDD[Array[T]]</li><li>sample（withReplacement,fraction,seed）：采样算子，以指定的随机数种子seed随机抽样出数量为fraction的数据，withReplacenent表示抽出数据是否放回，true则放回，false不放回</li><li>distinct（[numTasks]）：对RDD元素去重后，返回一个新的RDD，可传入numTasks参数改变RDD分区数</li><li>coalesce（numPartitions）：缩减分区数，没有shuffle</li><li>repartition（numPartitions）：增加或减少分区数，有shuffle</li><li>sortBy（func，[ascending], [numTasks]）：使用func对数据进行处理，对处理后的结果进行排序</li></ul> 
<p>宽依赖的算子（shuffle）：groupBy，distinct、repartition、sortBy</p> 
<h3><a id="2_162"></a>转换算子2测试</h3> 
<h4><a id="group_by_163"></a>group by</h4> 
<pre><code class="prism language-shell">val rdd1 <span class="token operator">=</span> sc.parallelize<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">10</span><span class="token punctuation">)</span>
val group <span class="token operator">=</span> rdd1.groupBy<span class="token punctuation">(</span>_%3<span class="token punctuation">)</span>
group.collect
</code></pre> 
<p>执行的结果如下图：<br> <img src="https://images2.imgbox.com/f2/98/9sJ75QFq_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="glommap_172"></a>glom.map</h4> 
<p>将 RDD 中元素的每10个元素分组</p> 
<pre><code class="prism language-shell">val rdd1 <span class="token operator">=</span> sc.parallelize<span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">101</span><span class="token punctuation">)</span>
val rdd2 <span class="token operator">=</span> rdd1.glom.map<span class="token punctuation">(</span>_.sliding<span class="token punctuation">(</span><span class="token number">10</span>, <span class="token number">10</span><span class="token punctuation">)</span>.toArray<span class="token punctuation">)</span>
rdd2.collect
</code></pre> 
<p>执行结果如下图：<br> <img src="https://images2.imgbox.com/78/d3/7fqUbCDQ_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="sample_181"></a>sample</h4> 
<p>对数据采样，fraction表示采样的百分比</p> 
<pre><code class="prism language-shell">rdd1.sample<span class="token punctuation">(</span>true, <span class="token number">0.2</span>, <span class="token number">2</span><span class="token punctuation">)</span>.collect
rdd1.sample<span class="token punctuation">(</span>false, <span class="token number">0.2</span>, <span class="token number">2</span><span class="token punctuation">)</span>.collect
rdd1.sample<span class="token punctuation">(</span>true, <span class="token number">0.2</span><span class="token punctuation">)</span>.collect
</code></pre> 
<p>执行结果如下图：<br> <img src="https://images2.imgbox.com/0e/38/bhlbFLqN_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="distinct_190"></a>distinct</h4> 
<p>对数据进行去重，我们生成一些随机数，然后对这些数值进行去重。</p> 
<pre><code class="prism language-shell">val random <span class="token operator">=</span> scala.util.Random
val arr <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span> to <span class="token number">20</span><span class="token punctuation">)</span>.map<span class="token punctuation">(</span>x <span class="token operator">=</span><span class="token operator">&gt;</span> random.nextInt<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">))</span>
val rdd <span class="token operator">=</span> sc.makeRDD<span class="token punctuation">(</span>arr<span class="token punctuation">)</span>
rdd.distinct.collect
</code></pre> 
<p>执行结果如下图：<br> <img src="https://images2.imgbox.com/7a/b2/EgeOGWbY_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="numSlices_201"></a>numSlices</h4> 
<p>对RDD重分区，我们需要多分一些区出来</p> 
<pre><code class="prism language-shell">val rdd1 <span class="token operator">=</span> sc.range<span class="token punctuation">(</span><span class="token number">1</span>, <span class="token number">1000</span>, <span class="token assign-left variable">numSlices</span><span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>
val rdd2 <span class="token operator">=</span> rdd1.filter<span class="token punctuation">(</span>_%2<span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">)</span>
rdd2.getNumPartitions
</code></pre> 
<p>执行结果如下图：<br> <img src="https://images2.imgbox.com/3e/ab/cFcE1EgG_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="repartition__coalesce_212"></a>repartition &amp; coalesce</h4> 
<p>增加或者减少分区</p> 
<pre><code class="prism language-shell">rdd2.getNumPartitions
<span class="token comment"># repartition 是增加和缩减分区数</span>
val rdd3 <span class="token operator">=</span> rdd2.repartition<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span>
<span class="token comment"># coalesce 是缩减分区数</span>
val rdd4 <span class="token operator">=</span> rdd2.coalesce<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span>
</code></pre> 
<p>执行结果如下图：<br> <img src="https://images2.imgbox.com/19/08/C3knKQTQ_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="sortBy_223"></a>sortBy</h4> 
<pre><code class="prism language-shell">rdd.sortBy<span class="token punctuation">(</span>x <span class="token operator">=</span><span class="token operator">&gt;</span> x<span class="token punctuation">)</span>.collect
rdd.sortBy<span class="token punctuation">(</span>x <span class="token operator">=</span><span class="token operator">&gt;</span> x<span class="token punctuation">)</span>.collect
</code></pre> 
<p>执行结果如下：<br> <img src="https://images2.imgbox.com/f4/d8/Iy1YqK2O_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="coalesce__repartition_230"></a>coalesce &amp; repartition</h4> 
<ul><li>repartition：增大或者减少分区数，有shuffle</li><li>coalesce：一般用于减少分区数（此时无shuffle）</li></ul>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/d3b60fc68e17be3e8f4c6b893d3d5a0e/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【Qt】QWidget的windowIcon属性</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/ad8bed6ce040cdd5884ebb40fe4fd3f9/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">使用PAI × LLaMA Factory 微调 Llama3 模型</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>