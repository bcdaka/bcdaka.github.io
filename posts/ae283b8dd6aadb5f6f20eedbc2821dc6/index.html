<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>基于大数据&#43;Spark电力能耗数据分析与可视化平台设计与实现 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/ae283b8dd6aadb5f6f20eedbc2821dc6/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="基于大数据&#43;Spark电力能耗数据分析与可视化平台设计与实现">
  <meta property="og:description" content="博主介绍：✌全网粉丝30W&#43;,csdn特邀作者、博客专家、CSDN新星计划导师、Java领域优质创作者,博客之星、掘金/华为云/阿里云/InfoQ等平台优质作者、专注于Java技术领域和学生毕业项目实战,高校老师/讲师/同行交流合作✌
主要内容：SpringBoot、Vue、SSM、HLMT、Jsp、PHP、Nodejs、Python、爬虫、数据可视化、小程序、安卓app、大数据、物联网、机器学习等设计与开发。
🍅文末获取源码联系🍅
👇🏻 精彩专栏推荐订阅👇🏻 不然下次找不到哟
2022-2024年最全的计算机软件毕业设计选题大全：1000个热门选题推荐✅
Java项目精品实战案例《100套》
Java微信小程序项目实战《100套》
感兴趣的可以先收藏起来，还有大家在毕设选题，项目以及论文编写等相关问题都可以给我留言咨询，希望帮助更多的人
目录
一、前言介绍：
二、功能设计：
三、功能实现：
四、库表设计：
五、关键代码：
六、论文参考：
七、其他案例： 八、推荐项目：
九、源码获取：
一、前言介绍： 随着经济的发展和人口的增加，能源消耗也在不断增加。电力作为人们生产和生活中不可或缺的一部分，对于能源消耗的贡献也非常大。传统的电力供应模式已经无法满足人们对电力的需求，同时也带来了环境污染等问题。如何优化电力供应模式，提高能源利用效率，成为了当前亟待解决的问题。而电力能耗数据分析正是解决这一问题的有效手段之一。本研究基于Spark技术对电力能耗数据进行分析，旨在为电力企业提供决策支持，优化能源消耗结构，提高能源利用效率。通过对历史用电数据的分析，可以得到不同时间段内的用电趋势、用电负荷分布、能源消耗结构等信息，为电力企业的生产管理和决策提供科学依据。该系统可以帮助政府制定合理的能源政策，促进可持续发展。还可以为普通用户提供更加智能化的用电服务，提高用电效率，节约能源。因此，本研究具有重要的理论和实践意义。
近年来，随着大数据技术的快速发展，电力能耗数据分析系统在国内得到了广泛的关注和应用。国内学者和研究人员在电力能耗数据分析领域开展了大量的研究工作，涉及到数据清洗、特征提取、模型训练等方面。基于Spark技术的电力能耗数据分析系统成为了研究的热点之一。许多研究者利用Spark技术对电力能耗数据进行分析，得出了不同时间段内的用电趋势、用电负荷分布、能源消耗结构等信息，为电力企业的生产管理和决策提供了科学依据。
在国外，电力能耗数据分析也受到了广泛的关注和应用。许多国外的研究机构和企业都在开展相关的研究工作。其中，美国、欧洲等发达国家在电力能耗数据分析领域的研究处于领先地位。这些国家的研究者们利用先进的技术和方法对电力能耗数据进行分析，探索出了一些新的模型和方法，如深度学习、神经网络等。这些国家还注重将研究成果应用到实际生产中，为电力企业提供更加智能化的决策支持。
二、功能设计： 三、功能实现： 四、库表设计： 五、关键代码： # # -*- coding: utf-8 -*- # 数据爬取文件 import scrapy import pymysql import pymssql from ..items import DianlixinxiItem import time from datetime import datetime,timedelta import datetime as formattime import re import random import platform import json import os import urllib from urllib.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-05-28T09:44:54+08:00">
    <meta property="article:modified_time" content="2024-05-28T09:44:54+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">基于大数据&#43;Spark电力能耗数据分析与可视化平台设计与实现</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <blockquote> 
 <p><strong>博主介绍</strong>：<strong>✌</strong>全网粉丝30W+,csdn特邀作者、博客专家、CSDN新星计划导师、Java领域优质创作者,博客之星、掘金/华为云/阿里云/InfoQ等平台优质作者、专注于Java技术领域和学生毕业项目实战,高校老师/讲师/同行交流合作<strong>✌</strong></p> 
 <p><strong>主要内容：</strong>SpringBoot、Vue、SSM、HLMT、Jsp、PHP、Nodejs、Python、爬虫、数据可视化、小程序、安卓app、大数据、物联网、机器学习等设计与开发。</p> 
 <p>🍅<span style="color:#fe2c24;"><strong>文末获取源码联系</strong></span>🍅</p> 
 <p><strong>👇🏻 精彩专栏<span style="color:#fe2c24;">推荐订阅</span>👇🏻 不然下次找不到哟</strong></p> 
 <p><strong><strong><a href="https://blog.csdn.net/weixin_39709134/article/details/131338298" title="2022-2024年最全的计算机软件毕业设计选题大全：1000个热门选题推荐✅">2022-2024年最全的计算机软件毕业设计选题大全：1000个热门选题推荐✅</a></strong></strong></p> 
 <p><strong><strong><a class="link-info" href="https://blog.csdn.net/weixin_39709134/category_11128297.html" title="Java项目精品实战案例《100套》">Java项目精品实战案例《100套》</a></strong></strong></p> 
 <p><a class="link-info" href="https://blog.csdn.net/weixin_39709134/category_12022111.html" title="Java微信小程序项目实战《100套》">Java微信小程序项目实战《100套》</a></p> 
 <p><strong>感兴趣的可以<span style="color:#fe2c24;">先收藏起来</span>，还有大家在毕设选题，项目以及论文编写等相关问题都可以<span style="color:#fe2c24;">给我留言咨询</span>，希望帮助更多的人</strong></p> 
</blockquote> 
<p id="main-toc"><strong>目录</strong></p> 
<p id="%E4%B8%80%E3%80%81%E5%89%8D%E8%A8%80%E4%BB%8B%E7%BB%8D%EF%BC%9A-toc" style="margin-left:0px;"><a href="#%E4%B8%80%E3%80%81%E5%89%8D%E8%A8%80%E4%BB%8B%E7%BB%8D%EF%BC%9A" rel="nofollow">一、前言介绍：</a></p> 
<p id="%E4%BA%8C%E3%80%81%E5%8A%9F%E8%83%BD%E8%AE%BE%E8%AE%A1%EF%BC%9A-toc" style="margin-left:0px;"><a href="#%E4%BA%8C%E3%80%81%E5%8A%9F%E8%83%BD%E8%AE%BE%E8%AE%A1%EF%BC%9A" rel="nofollow">二、功能设计：</a></p> 
<p id="%E4%B8%89%E3%80%81%E5%8A%9F%E8%83%BD%E5%AE%9E%E7%8E%B0%EF%BC%9A-toc" style="margin-left:0px;"><a href="#%E4%B8%89%E3%80%81%E5%8A%9F%E8%83%BD%E5%AE%9E%E7%8E%B0%EF%BC%9A" rel="nofollow">三、功能实现：</a></p> 
<p id="%E5%9B%9B%E3%80%81%E5%BA%93%E8%A1%A8%E8%AE%BE%E8%AE%A1%EF%BC%9A-toc" style="margin-left:0px;"><a href="#%E5%9B%9B%E3%80%81%E5%BA%93%E8%A1%A8%E8%AE%BE%E8%AE%A1%EF%BC%9A" rel="nofollow">四、库表设计：</a></p> 
<p id="%E4%BA%94%E3%80%81%E5%85%B3%E9%94%AE%E4%BB%A3%E7%A0%81%EF%BC%9A-toc" style="margin-left:0px;"><a href="#%E4%BA%94%E3%80%81%E5%85%B3%E9%94%AE%E4%BB%A3%E7%A0%81%EF%BC%9A" rel="nofollow">五、关键代码：</a></p> 
<p id="%E5%85%AD%E3%80%81%E8%AE%BA%E6%96%87%E5%8F%82%E8%80%83%EF%BC%9A-toc" style="margin-left:0px;"><a href="#%E5%85%AD%E3%80%81%E8%AE%BA%E6%96%87%E5%8F%82%E8%80%83%EF%BC%9A" rel="nofollow">六、论文参考：</a></p> 
<p id="%E4%B8%83%E3%80%81%E5%85%B6%E4%BB%96%E6%A1%88%E4%BE%8B%EF%BC%9A%C2%A0-toc" style="margin-left:0px;"><a href="#%E4%B8%83%E3%80%81%E5%85%B6%E4%BB%96%E6%A1%88%E4%BE%8B%EF%BC%9A%C2%A0" rel="nofollow">七、其他案例： </a></p> 
<p id="%E5%85%AB%E3%80%81%E6%8E%A8%E8%8D%90%E9%A1%B9%E7%9B%AE%EF%BC%9A-toc" style="margin-left:0px;"><a href="#%E5%85%AB%E3%80%81%E6%8E%A8%E8%8D%90%E9%A1%B9%E7%9B%AE%EF%BC%9A" rel="nofollow">八、推荐项目：</a></p> 
<p id="%E4%B9%9D%E3%80%81%E6%BA%90%E7%A0%81%E8%8E%B7%E5%8F%96%EF%BC%9A-toc" style="margin-left:0px;"><a href="#%E4%B9%9D%E3%80%81%E6%BA%90%E7%A0%81%E8%8E%B7%E5%8F%96%EF%BC%9A" rel="nofollow">九、源码获取：</a></p> 
<hr id="hr-toc"> 
<p></p> 
<blockquote> 
 <h2 id="%E4%B8%80%E3%80%81%E5%89%8D%E8%A8%80%E4%BB%8B%E7%BB%8D%EF%BC%9A" style="background-color:transparent;">一、前言介绍：</h2> 
</blockquote> 
<p>    随着经济的发展和人口的增加，能源消耗也在不断增加。电力作为人们生产和生活中不可或缺的一部分，对于能源消耗的贡献也非常大。传统的电力供应模式已经无法满足人们对电力的需求，同时也带来了环境污染等问题。如何优化电力供应模式，提高能源利用效率，成为了当前亟待解决的问题。而电力能耗数据分析正是解决这一问题的有效手段之一。本研究基于Spark技术对电力能耗数据进行分析，旨在为电力企业提供决策支持，优化能源消耗结构，提高能源利用效率。通过对历史用电数据的分析，可以得到不同时间段内的用电趋势、用电负荷分布、能源消耗结构等信息，为电力企业的生产管理和决策提供科学依据。该系统可以帮助政府制定合理的能源政策，促进可持续发展。还可以为普通用户提供更加智能化的用电服务，提高用电效率，节约能源。因此，本研究具有重要的理论和实践意义。</p> 
<p><img alt="" height="872" src="https://images2.imgbox.com/f5/92/igj9X34P_o.png" width="1200"></p> 
<p>     近年来，随着大数据技术的快速发展，电力能耗数据分析系统在国内得到了广泛的关注和应用。国内学者和研究人员在电力能耗数据分析领域开展了大量的研究工作，涉及到数据清洗、特征提取、模型训练等方面。基于Spark技术的电力能耗数据分析系统成为了研究的热点之一。许多研究者利用Spark技术对电力能耗数据进行分析，得出了不同时间段内的用电趋势、用电负荷分布、能源消耗结构等信息，为电力企业的生产管理和决策提供了科学依据。</p> 
<p>      在国外，电力能耗数据分析也受到了广泛的关注和应用。许多国外的研究机构和企业都在开展相关的研究工作。其中，美国、欧洲等发达国家在电力能耗数据分析领域的研究处于领先地位。这些国家的研究者们利用先进的技术和方法对电力能耗数据进行分析，探索出了一些新的模型和方法，如深度学习、神经网络等。这些国家还注重将研究成果应用到实际生产中，为电力企业提供更加智能化的决策支持。</p> 
<blockquote> 
 <h2 id="%E4%BA%8C%E3%80%81%E5%8A%9F%E8%83%BD%E8%AE%BE%E8%AE%A1%EF%BC%9A" style="background-color:transparent;">二、功能设计：</h2> 
</blockquote> 
<p><img alt="" height="708" src="https://images2.imgbox.com/91/24/5UCTss3A_o.png" width="782"></p> 
<blockquote> 
 <h2 id="%E4%B8%89%E3%80%81%E5%8A%9F%E8%83%BD%E5%AE%9E%E7%8E%B0%EF%BC%9A">三、功能实现：</h2> 
</blockquote> 
<p> <img alt="" height="874" src="https://images2.imgbox.com/1b/77/NUgRzNDE_o.png" width="1200"></p> 
<p><img alt="" height="766" src="https://images2.imgbox.com/48/ee/Sk3Z9tJy_o.png" width="1200"></p> 
<p><img alt="" height="793" src="https://images2.imgbox.com/27/c1/DpSUzeSI_o.png" width="1200"></p> 
<p><img alt="" height="781" src="https://images2.imgbox.com/55/e5/73WOiocK_o.png" width="1200"><img alt="" height="872" src="https://images2.imgbox.com/f6/c4/etWuOJMh_o.png" width="1200"></p> 
<blockquote> 
 <h2 id="%E5%9B%9B%E3%80%81%E5%BA%93%E8%A1%A8%E8%AE%BE%E8%AE%A1%EF%BC%9A" style="background-color:transparent;">四、库表设计：</h2> 
</blockquote> 
<p><img alt="" height="395" src="https://images2.imgbox.com/1b/9e/n37A8cf1_o.png" width="889"></p> 
<blockquote> 
 <h2 id="%E4%BA%94%E3%80%81%E5%85%B3%E9%94%AE%E4%BB%A3%E7%A0%81%EF%BC%9A">五、关键代码：</h2> 
</blockquote> 
<pre><code class="language-python"># # -*- coding: utf-8 -*-

# 数据爬取文件

import scrapy
import pymysql
import pymssql
from ..items import DianlixinxiItem
import time
from datetime import datetime,timedelta
import datetime as formattime
import re
import random
import platform
import json
import os
import urllib
from urllib.parse import urlparse
import requests
import emoji
import numpy as np
import pandas as pd
from sqlalchemy import create_engine
from selenium.webdriver import ChromeOptions, ActionChains
from scrapy.http import TextResponse
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.support.wait import WebDriverWait
# 电力信息
class DianlixinxiSpider(scrapy.Spider):
    name = 'dianlixinxiSpider'
    spiderUrl = 'http://www.chinapower.com.cn/sj/index.html'
    start_urls = spiderUrl.split(";")
    protocol = ''
    hostname = ''
    realtime = False


    def __init__(self,realtime=False,*args, **kwargs):
        super().__init__(*args, **kwargs)
        self.realtime = realtime=='true'

    def start_requests(self):

        plat = platform.system().lower()
        if not self.realtime and (plat == 'linux' or plat == 'windows'):
            connect = self.db_connect()
            cursor = connect.cursor()
            if self.table_exists(cursor, '5129hf00_dianlixinxi') == 1:
                cursor.close()
                connect.close()
                self.temp_data()
                return
        pageNum = 1 + 1
        for url in self.start_urls:
            if '{}' in url:
                for page in range(1, pageNum):
                    next_link = url.format(page)
                    yield scrapy.Request(
                        url=next_link,
                        callback=self.parse
                    )
            else:
                yield scrapy.Request(
                    url=url,
                    callback=self.parse
                )

    # 列表解析
    def parse(self, response):
        _url = urlparse(self.spiderUrl)
        self.protocol = _url.scheme
        self.hostname = _url.netloc
        plat = platform.system().lower()
        if not self.realtime and (plat == 'linux' or plat == 'windows'):
            connect = self.db_connect()
            cursor = connect.cursor()
            if self.table_exists(cursor, '5129hf00_dianlixinxi') == 1:
                cursor.close()
                connect.close()
                self.temp_data()
                return
        list = response.css('div.list div.item')
        for item in list:
            fields = DianlixinxiItem()

            if '(.*?)' in '''h2 a::text''':
                try:
                    fields["title"] = str( re.findall(r'''h2 a::text''', item.extract(), re.DOTALL)[0].strip())

                except:
                    pass
            else:
                try:
                    fields["title"] = str( self.remove_html(item.css('h2 a::text').extract_first()))

                except:
                    pass
            if '(.*?)' in '''div.desc::text''':
                try:
                    fields["miaoshu"] = str( re.findall(r'''div.desc::text''', item.extract(), re.DOTALL)[0].strip())

                except:
                    pass
            else:
                try:
                    fields["miaoshu"] = str( self.remove_html(item.css('div.desc::text').extract_first()))

                except:
                    pass
            if '(.*?)' in '''div.info span::text''':
                try:
                    fields["faburiqi"] = str( re.findall(r'''div.info span::text''', item.extract(), re.DOTALL)[0].strip())

                except:
                    pass
            else:
                try:
                    fields["faburiqi"] = str( self.remove_html(item.css('div.info span::text').extract_first()))

                except:
                    pass
            if '(.*?)' in '''h2 a::attr(href)''':
                try:
                    fields["laiyuan"] = str('http://www.chinapower.com.cn' + re.findall(r'''h2 a::attr(href)''', item.extract(), re.DOTALL)[0].strip())

                except:
                    pass
            else:
                try:
                    fields["laiyuan"] = str('http://www.chinapower.com.cn' + self.remove_html(item.css('h2 a::attr(href)').extract_first()))

                except:
                    pass
            detailUrlRule = 'http://www.chinapower.com.cn' + item.css('h2 a::attr(href)').extract_first()
            if self.protocol in detailUrlRule:
                pass
            elif detailUrlRule.startswith('//'):
                detailUrlRule = self.protocol + ':' + detailUrlRule
            elif detailUrlRule.startswith('/'):
                detailUrlRule = self.protocol + '://' + self.hostname + detailUrlRule
                # fields["laiyuan"] = detailUrlRule
            else:
                detailUrlRule = self.protocol + '://' + self.hostname + '/' + detailUrlRule
            yield scrapy.Request(url=detailUrlRule, meta={'fields': fields},  callback=self.detail_parse, dont_filter=True)

    # 详情解析
    def detail_parse(self, response):
        fields = response.meta['fields']
        try:
            fields["fabuwang"] = str( response.xpath('''/html/body/div[2]/div[3]/div[1]/div[1]/text()[1]''').extract()[0].strip())

        except:
            pass
        try:
            if '(.*?)' in '''&lt;small&gt;&amp;nbsp;作者：(.*?)&lt;/small&gt;''':
                fields["zuozhe"] = str( re.findall(r'''&lt;small&gt;&amp;nbsp;作者：(.*?)&lt;/small&gt;''', response.text, re.S)[0].strip())

            else:
                if 'zuozhe' != 'xiangqing' and 'zuozhe' != 'detail' and 'zuozhe' != 'pinglun' and 'zuozhe' != 'zuofa':
                    fields["zuozhe"] = str( self.remove_html(response.css('''&lt;small&gt;&amp;nbsp;作者：(.*?)&lt;/small&gt;''').extract_first()))

                else:
                    try:
                        fields["zuozhe"] = str( emoji.demojize(response.css('''&lt;small&gt;&amp;nbsp;作者：(.*?)&lt;/small&gt;''').extract_first()))

                    except:
                        pass
        except:
            pass
        try:
            if '(.*?)' in '''div.content''':
                fields["detail"] = str( re.findall(r'''div.content''', response.text, re.S)[0].strip())

            else:
                if 'detail' != 'xiangqing' and 'detail' != 'detail' and 'detail' != 'pinglun' and 'detail' != 'zuofa':
                    fields["detail"] = str( self.remove_html(response.css('''div.content''').extract_first()))

                else:
                    try:
                        fields["detail"] = str( emoji.demojize(response.css('''div.content''').extract_first()))

                    except:
                        pass
        except:
            pass
        return fields

    # 数据清洗
    def pandas_filter(self):
        engine = create_engine('mysql+pymysql://root:123456@localhost/spider5129hf00?charset=UTF8MB4')
        df = pd.read_sql('select * from dianlixinxi limit 50', con = engine)

        # 重复数据过滤
        df.duplicated()
        df.drop_duplicates()

        #空数据过滤
        df.isnull()
        df.dropna()

        # 填充空数据
        df.fillna(value = '暂无')

        # 异常值过滤

        # 滤出 大于800 和 小于 100 的
        a = np.random.randint(0, 1000, size = 200)
        cond = (a&lt;=800) &amp; (a&gt;=100)
        a[cond]

        # 过滤正态分布的异常值
        b = np.random.randn(100000)
        # 3σ过滤异常值，σ即是标准差
        cond = np.abs(b) &gt; 3 * 1
        b[cond]

        # 正态分布数据
        df2 = pd.DataFrame(data = np.random.randn(10000,3))
        # 3σ过滤异常值，σ即是标准差
        cond = (df2 &gt; 3*df2.std()).any(axis = 1)
        # 不满⾜条件的⾏索引
        index = df2[cond].index
        # 根据⾏索引，进⾏数据删除
        df2.drop(labels=index,axis = 0)

    # 去除多余html标签
    def remove_html(self, html):
        if html == None:
            return ''
        pattern = re.compile(r'&lt;[^&gt;]+&gt;', re.S)
        return pattern.sub('', html).strip()

    # 数据库连接
    def db_connect(self):
        type = self.settings.get('TYPE', 'mysql')
        host = self.settings.get('HOST', 'localhost')
        port = int(self.settings.get('PORT', 3306))
        user = self.settings.get('USER', 'root')
        password = self.settings.get('PASSWORD', '123456')

        try:
            database = self.databaseName
        except:
            database = self.settings.get('DATABASE', '')

        if type == 'mysql':
            connect = pymysql.connect(host=host, port=port, db=database, user=user, passwd=password, charset='utf8')
        else:
            connect = pymssql.connect(host=host, user=user, password=password, database=database)
        return connect

    # 断表是否存在
    def table_exists(self, cursor, table_name):
        cursor.execute("show tables;")
        tables = [cursor.fetchall()]
        table_list = re.findall('(\'.*?\')',str(tables))
        table_list = [re.sub("'",'',each) for each in table_list]

        if table_name in table_list:
            return 1
        else:
            return 0

    # 数据缓存源
    def temp_data(self):

        connect = self.db_connect()
        cursor = connect.cursor()
        sql = '''
            insert into `dianlixinxi`(
                id
                ,title
                ,miaoshu
                ,faburiqi
                ,fabuwang
                ,zuozhe
                ,laiyuan
                ,detail
            )
            select
                id
                ,title
                ,miaoshu
                ,faburiqi
                ,fabuwang
                ,zuozhe
                ,laiyuan
                ,detail
            from `5129hf00_dianlixinxi`
            where(not exists (select
                id
                ,title
                ,miaoshu
                ,faburiqi
                ,fabuwang
                ,zuozhe
                ,laiyuan
                ,detail
            from `dianlixinxi` where
                `dianlixinxi`.id=`5129hf00_dianlixinxi`.id
            ))
        '''

        cursor.execute(sql)
        connect.commit()
        connect.close()
</code></pre> 
<blockquote> 
 <h2 id="%E5%85%AD%E3%80%81%E8%AE%BA%E6%96%87%E5%8F%82%E8%80%83%EF%BC%9A" style="background-color:transparent;">六、论文参考：</h2> 
</blockquote> 
<p> <img alt="" height="987" src="https://images2.imgbox.com/fb/57/6N1ceZvK_o.png" width="1200"><img alt="" height="960" src="https://images2.imgbox.com/c5/df/5um8QqtV_o.png" width="1200"></p> 
<blockquote> 
 <h2 id="%E4%B8%83%E3%80%81%E5%85%B6%E4%BB%96%E6%A1%88%E4%BE%8B%EF%BC%9A%C2%A0">七、其他案例： </h2> 
</blockquote> 
<p><img alt="" height="797" src="https://images2.imgbox.com/90/9c/mphqGAEl_o.jpg" width="1200"><img alt="" src="https://images2.imgbox.com/bd/85/jKUqmnj7_o.png"></p> 
<p><img alt="" src="https://images2.imgbox.com/ae/7c/6ahQOxTY_o.png"></p> 
<p><img alt="" src="https://images2.imgbox.com/fd/6b/POEAQ13s_o.png"> <img alt="" src="https://images2.imgbox.com/4a/f1/1QI5AHO6_o.png"></p> 
<p><img alt="" src="https://images2.imgbox.com/ae/70/jV4LfoaL_o.png"></p> 
<p><img alt="" height="670" src="https://images2.imgbox.com/c6/c4/gJkyG45G_o.png" width="1200"><img alt="" src="https://images2.imgbox.com/e8/9d/uiBzvZij_o.png"></p> 
<p><img alt="" src="https://images2.imgbox.com/10/83/hoUxVmER_o.png"></p> 
<p style="text-align:center;"><img alt="" height="723" src="https://images2.imgbox.com/2d/88/VrLhnloo_o.png" width="878"></p> 
<blockquote> 
 <h2 id="%E5%85%AB%E3%80%81%E6%8E%A8%E8%8D%90%E9%A1%B9%E7%9B%AE%EF%BC%9A">八、推荐项目：</h2> 
</blockquote> 
<p><a href="https://lyyong.blog.csdn.net/article/details/132844324" rel="nofollow" title="基于微信小程序+Springboot线上租房平台设计和实现-三端">基于微信小程序+Springboot线上租房平台设计和实现-三端</a></p> 
<p><a href="https://lyyong.blog.csdn.net/article/details/131338298" rel="nofollow" title="2022-2024年最全的计算机软件毕业设计选题大全">2022-2024年最全的计算机软件毕业设计选题大全</a></p> 
<p><a href="https://lyyong.blog.csdn.net/article/details/130144341" rel="nofollow" title="基于Java+SpringBoot+Vue前后端分离手机销售商城系统设计和实现">基于Java+SpringBoot+Vue前后端分离手机销售商城系统设计和实现</a></p> 
<p><a href="https://lyyong.blog.csdn.net/article/details/129943775" rel="nofollow" title="基于Java+SpringBoot+Vue前后端分离仓库管理系统设计实现">基于Java+SpringBoot+Vue前后端分离仓库管理系统设计实现</a></p> 
<p><a href="https://lyyong.blog.csdn.net/article/details/134302407" rel="nofollow" title="基于SpringBoot+uniapp微信小程序校园点餐平台详细设计和实现">基于SpringBoot+uniapp微信小程序校园点餐平台详细设计和实现</a></p> 
<p><a href="https://lyyong.blog.csdn.net/article/details/131901857" rel="nofollow" title="基于Java+SpringBoot+Vue+echarts健身房管理系统设计和实现">基于Java+SpringBoot+Vue+echarts健身房管理系统设计和实现</a></p> 
<p><a href="https://lyyong.blog.csdn.net/article/details/131508514" rel="nofollow" title="基于JavaSpringBoot+Vue+uniapp微信小程序实现鲜花商城购物系统">基于JavaSpringBoot+Vue+uniapp微信小程序实现鲜花商城购物系统</a></p> 
<p><a class="link-info" href="https://lyyong.blog.csdn.net/article/details/131128600" rel="nofollow" title="基于Java+SpringBoot+Vue前后端分离摄影分享网站平台系统 ">基于Java+SpringBoot+Vue前后端分离摄影分享网站平台系统 </a></p> 
<p><a href="https://lyyong.blog.csdn.net/article/details/130679318" rel="nofollow" title="基于Java+SpringBoot+Vue前后端分离餐厅点餐管理系统设计和实现">基于Java+SpringBoot+Vue前后端分离餐厅点餐管理系统设计和实现</a></p> 
<p><a href="https://lyyong.blog.csdn.net/article/details/131395785" rel="nofollow" title="基于Python热门旅游景点数据分析系统设计与实现">基于Python热门旅游景点数据分析系统设计与实现</a></p> 
<blockquote> 
 <h2 id="%E4%B9%9D%E3%80%81%E6%BA%90%E7%A0%81%E8%8E%B7%E5%8F%96%EF%BC%9A"><strong>九、源码获取：</strong></h2> 
 <p></p> 
 <p> 大家<span style="color:#fe2c24;"><strong>点赞、收藏、关注、评论</strong></span>啦 、<strong>查看</strong>👇🏻<span style="color:#fe2c24;"><strong>获取联系方式</strong></span>👇🏻</p> 
 <p><strong> 精彩专栏<span style="color:#fe2c24;">推荐订阅</span>：</strong>在<strong>下方专栏</strong>👇🏻</p> 
 <p><a href="https://blog.csdn.net/weixin_39709134/article/details/131338298" title="2022-2024年最全的计算机软件毕业设计选题大全：1000个热门选题推荐✅">2022-2024年最全的计算机软件毕业设计选题大全：1000个热门选题推荐✅</a></p> 
 <p><a href="https://blog.csdn.net/weixin_39709134/category_11128297.html" title="Java项目精品实战案例《100套》">Java项目精品实战案例《100套》</a></p> 
 <p><a href="https://blog.csdn.net/weixin_39709134/category_12022111.html?spm=1001.2014.3001.5482" title="Java微信小程序项目实战《100套》">Java微信小程序项目实战《100套》</a></p> 
</blockquote> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/4fe10b97025a9af48340f2c57e39f5bc/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【高阶数据结构(七)】B&#43;树, 索引原理讲解</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/0b71a5338b52a75df2f8883e76eba5e1/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">使用 Go 实现 HelloWorld 程序，并分析其结构</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>