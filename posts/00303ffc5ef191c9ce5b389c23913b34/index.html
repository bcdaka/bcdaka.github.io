<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Transformers x SwanLabï¼šå¯è§†åŒ–NLPæ¨¡å‹è®­ç»ƒ - ç¼–ç¨‹å¤§å’–</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/00303ffc5ef191c9ce5b389c23913b34/">
  <meta property="og:site_name" content="ç¼–ç¨‹å¤§å’–">
  <meta property="og:title" content="Transformers x SwanLabï¼šå¯è§†åŒ–NLPæ¨¡å‹è®­ç»ƒ">
  <meta property="og:description" content="HuggingFace çš„ Transformers æ˜¯ç›®å‰æœ€æµè¡Œçš„æ·±åº¦å­¦ä¹ è®­æ¡†æ¶ä¹‹ä¸€ï¼ˆ100k&#43; Starï¼‰ï¼Œç°åœ¨ä¸»æµçš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLaMaç³»åˆ—ã€Qwenç³»åˆ—ã€ChatGLMç³»åˆ—ç­‰ï¼‰ã€è‡ªç„¶è¯­è¨€å¤„ç†æ¨¡å‹ï¼ˆBertç³»åˆ—ï¼‰ç­‰ï¼Œéƒ½åœ¨ä½¿ç”¨Transformersæ¥è¿›è¡Œé¢„è®­ç»ƒã€å¾®è°ƒå’Œæ¨ç†ã€‚
SwanLabæ˜¯ä¸€ä¸ªæ·±åº¦å­¦ä¹ å®éªŒç®¡ç†ä¸è®­ç»ƒå¯è§†åŒ–å·¥å…·ï¼Œç”±è¥¿å®‰ç”µå­ç§‘æŠ€å¤§å­¦å›¢é˜Ÿæ‰“é€ ï¼Œèåˆäº†Weights &amp; Biasesä¸Tensorboardçš„ç‰¹ç‚¹ï¼Œèƒ½å¤Ÿæ–¹ä¾¿åœ°è¿›è¡Œ è®­ç»ƒå¯è§†åŒ–ã€å¤šå®éªŒå¯¹æ¯”ã€è¶…å‚æ•°è®°å½•ã€å¤§å‹å®éªŒç®¡ç†å’Œå›¢é˜Ÿåä½œï¼Œå¹¶æ”¯æŒç”¨ç½‘é¡µé“¾æ¥çš„æ–¹å¼åˆ†äº«ä½ çš„å®éªŒã€‚
ä½ å¯ä»¥ä½¿ç”¨Transformerså¿«é€Ÿè¿›è¡Œæ¨¡å‹è®­ç»ƒï¼ŒåŒæ—¶ä½¿ç”¨SwanLabè¿›è¡Œå®éªŒè·Ÿè¸ªä¸å¯è§†åŒ–ã€‚
ä¸‹é¢å°†ç”¨ä¸€ä¸ªBertè®­ç»ƒï¼Œæ¥ä»‹ç»å¦‚ä½•å°†Transformersä¸SwanLabé…åˆèµ·æ¥ï¼š
1. ä»£ç ä¸­å¼•å…¥SwanLabCallback from swanlab.integration.huggingface import SwanLabCallback SwanLabCallbackæ˜¯é€‚é…äºTransformersçš„æ—¥å¿—è®°å½•ç±»ã€‚
SwanLabCallbackå¯ä»¥å®šä¹‰çš„å‚æ•°æœ‰ï¼š
projectã€experiment_nameã€description ç­‰ä¸ swanlab.init æ•ˆæœä¸€è‡´çš„å‚æ•°, ç”¨äºSwanLabé¡¹ç›®çš„åˆå§‹åŒ–ã€‚ä½ ä¹Ÿå¯ä»¥åœ¨å¤–éƒ¨é€šè¿‡swanlab.initåˆ›å»ºé¡¹ç›®ï¼Œé›†æˆä¼šå°†å®éªŒè®°å½•åˆ°ä½ åœ¨å¤–éƒ¨åˆ›å»ºçš„é¡¹ç›®ä¸­ã€‚ 2. ä¼ å…¥Trainer from swanlab.integration.huggingface import SwanLabCallback from transformers import Trainer, TrainingArguments ... # å®ä¾‹åŒ–SwanLabCallback swanlab_callback = SwanLabCallback() trainer = Trainer( ... # ä¼ å…¥callbackså‚æ•° callbacks=[swanlab_callback], ) 3. æ¡ˆä¾‹-Bertè®­ç»ƒ æŸ¥çœ‹åœ¨çº¿å®éªŒè¿‡ç¨‹ï¼šBERT-SwanLab
ä¸‹é¢æ˜¯ä¸€ä¸ªåŸºäºTransformersæ¡†æ¶ï¼Œä½¿ç”¨BERTæ¨¡å‹åœ¨imdbæ•°æ®é›†ä¸Šåšå¾®è°ƒï¼ŒåŒæ—¶ç”¨SwanLabè¿›è¡Œå¯è§†åŒ–çš„æ¡ˆä¾‹ä»£ç 
&#34;&#34;&#34; ç”¨é¢„è®­ç»ƒçš„Bertæ¨¡å‹å¾®è°ƒIMDBæ•°æ®é›†ï¼Œå¹¶ä½¿ç”¨SwanLabCallbackå›è°ƒå‡½æ•°å°†ç»“æœä¸Šä¼ åˆ°SwanLabã€‚ IMDBæ•°æ®é›†çš„1æ˜¯positiveï¼Œ0æ˜¯negativeã€‚ &#34;&#34;&#34; import torch from datasets import load_dataset from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments from swanlab.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-05-28T20:08:26+08:00">
    <meta property="article:modified_time" content="2024-05-28T20:08:26+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="ç¼–ç¨‹å¤§å’–" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">ç¼–ç¨‹å¤§å’–</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Transformers x SwanLabï¼šå¯è§†åŒ–NLPæ¨¡å‹è®­ç»ƒ</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>HuggingFace çš„ Transformers æ˜¯ç›®å‰æœ€æµè¡Œçš„æ·±åº¦å­¦ä¹ è®­æ¡†æ¶ä¹‹ä¸€ï¼ˆ100k+ Starï¼‰ï¼Œç°åœ¨ä¸»æµçš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLaMaç³»åˆ—ã€Qwenç³»åˆ—ã€ChatGLMç³»åˆ—ç­‰ï¼‰ã€è‡ªç„¶è¯­è¨€å¤„ç†æ¨¡å‹ï¼ˆBertç³»åˆ—ï¼‰ç­‰ï¼Œéƒ½åœ¨ä½¿ç”¨Transformersæ¥è¿›è¡Œé¢„è®­ç»ƒã€å¾®è°ƒå’Œæ¨ç†ã€‚</p> 
<p><img src="https://images2.imgbox.com/07/15/78pL5KXJ_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"><br> SwanLabæ˜¯ä¸€ä¸ªæ·±åº¦å­¦ä¹ å®éªŒç®¡ç†ä¸è®­ç»ƒå¯è§†åŒ–å·¥å…·ï¼Œç”±è¥¿å®‰ç”µå­ç§‘æŠ€å¤§å­¦å›¢é˜Ÿæ‰“é€ ï¼Œèåˆäº†Weights &amp; Biasesä¸Tensorboardçš„ç‰¹ç‚¹ï¼Œèƒ½å¤Ÿæ–¹ä¾¿åœ°è¿›è¡Œ è®­ç»ƒå¯è§†åŒ–ã€å¤šå®éªŒå¯¹æ¯”ã€è¶…å‚æ•°è®°å½•ã€å¤§å‹å®éªŒç®¡ç†å’Œå›¢é˜Ÿåä½œï¼Œå¹¶æ”¯æŒç”¨ç½‘é¡µé“¾æ¥çš„æ–¹å¼åˆ†äº«ä½ çš„å®éªŒã€‚</p> 
<p><img src="https://images2.imgbox.com/d7/9c/Qv3VUBYl_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<p>ä½ å¯ä»¥ä½¿ç”¨Transformerså¿«é€Ÿè¿›è¡Œæ¨¡å‹è®­ç»ƒï¼ŒåŒæ—¶ä½¿ç”¨SwanLabè¿›è¡Œå®éªŒè·Ÿè¸ªä¸å¯è§†åŒ–ã€‚<br> ä¸‹é¢å°†ç”¨ä¸€ä¸ªBertè®­ç»ƒï¼Œæ¥ä»‹ç»å¦‚ä½•å°†Transformersä¸SwanLabé…åˆèµ·æ¥ï¼š</p> 
<h3><a id="1_SwanLabCallback_9"></a>1. ä»£ç ä¸­å¼•å…¥SwanLabCallback</h3> 
<pre><code class="prism language-python"><span class="token keyword">from</span> swanlab<span class="token punctuation">.</span>integration<span class="token punctuation">.</span>huggingface <span class="token keyword">import</span> SwanLabCallback
</code></pre> 
<p><strong>SwanLabCallback</strong>æ˜¯é€‚é…äºTransformersçš„æ—¥å¿—è®°å½•ç±»ã€‚</p> 
<p><strong>SwanLabCallback</strong>å¯ä»¥å®šä¹‰çš„å‚æ•°æœ‰ï¼š</p> 
<ul><li>projectã€experiment_nameã€description ç­‰ä¸ swanlab.init æ•ˆæœä¸€è‡´çš„å‚æ•°, ç”¨äºSwanLabé¡¹ç›®çš„åˆå§‹åŒ–ã€‚</li><li>ä½ ä¹Ÿå¯ä»¥åœ¨å¤–éƒ¨é€šè¿‡<code>swanlab.init</code>åˆ›å»ºé¡¹ç›®ï¼Œé›†æˆä¼šå°†å®éªŒè®°å½•åˆ°ä½ åœ¨å¤–éƒ¨åˆ›å»ºçš„é¡¹ç›®ä¸­ã€‚</li></ul> 
<h3><a id="2_Trainer_20"></a>2. ä¼ å…¥Trainer</h3> 
<pre><code class="prism language-python"><span class="token keyword">from</span> swanlab<span class="token punctuation">.</span>integration<span class="token punctuation">.</span>huggingface <span class="token keyword">import</span> SwanLabCallback
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> Trainer<span class="token punctuation">,</span> TrainingArguments
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>

<span class="token comment"># å®ä¾‹åŒ–SwanLabCallback</span>
swanlab_callback <span class="token operator">=</span> SwanLabCallback<span class="token punctuation">(</span><span class="token punctuation">)</span>

trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span>
    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
    <span class="token comment"># ä¼ å…¥callbackså‚æ•°</span>
    callbacks<span class="token operator">=</span><span class="token punctuation">[</span>swanlab_callback<span class="token punctuation">]</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
</code></pre> 
<h3><a id="3_Bert_37"></a>3. æ¡ˆä¾‹-Bertè®­ç»ƒ</h3> 
<p>æŸ¥çœ‹åœ¨çº¿å®éªŒè¿‡ç¨‹ï¼š<a href="https://swanlab.cn/@ZeyiLin/BERT/charts" rel="nofollow">BERT-SwanLab</a></p> 
<p><img src="https://images2.imgbox.com/7b/2b/1BZaRRab_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<p>ä¸‹é¢æ˜¯ä¸€ä¸ªåŸºäºTransformersæ¡†æ¶ï¼Œä½¿ç”¨BERTæ¨¡å‹åœ¨imdbæ•°æ®é›†ä¸Šåšå¾®è°ƒï¼ŒåŒæ—¶ç”¨SwanLabè¿›è¡Œå¯è§†åŒ–çš„æ¡ˆä¾‹ä»£ç </p> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">"""
ç”¨é¢„è®­ç»ƒçš„Bertæ¨¡å‹å¾®è°ƒIMDBæ•°æ®é›†ï¼Œå¹¶ä½¿ç”¨SwanLabCallbackå›è°ƒå‡½æ•°å°†ç»“æœä¸Šä¼ åˆ°SwanLabã€‚
IMDBæ•°æ®é›†çš„1æ˜¯positiveï¼Œ0æ˜¯negativeã€‚
"""</span>

<span class="token keyword">import</span> torch
<span class="token keyword">from</span> datasets <span class="token keyword">import</span> load_dataset
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer<span class="token punctuation">,</span> AutoModelForSequenceClassification<span class="token punctuation">,</span> Trainer<span class="token punctuation">,</span> TrainingArguments
<span class="token keyword">from</span> swanlab<span class="token punctuation">.</span>integration<span class="token punctuation">.</span>huggingface <span class="token keyword">import</span> SwanLabCallback
<span class="token keyword">import</span> swanlab

<span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>text<span class="token punctuation">,</span> model<span class="token punctuation">,</span> tokenizer<span class="token punctuation">,</span> CLASS_NAME<span class="token punctuation">)</span><span class="token punctuation">:</span>
    inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>text<span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">)</span>

    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>inputs<span class="token punctuation">)</span>
        logits <span class="token operator">=</span> outputs<span class="token punctuation">.</span>logits
        predicted_class <span class="token operator">=</span> torch<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>logits<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Input Text: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>text<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Predicted class: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span><span class="token builtin">int</span><span class="token punctuation">(</span>predicted_class<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string"> </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>CLASS_NAME<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>predicted_class<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token builtin">int</span><span class="token punctuation">(</span>predicted_class<span class="token punctuation">)</span>
<span class="token comment"># åŠ è½½IMDBæ•°æ®é›†</span>
dataset <span class="token operator">=</span> load_dataset<span class="token punctuation">(</span><span class="token string">'imdb'</span><span class="token punctuation">)</span>

<span class="token comment"># åŠ è½½é¢„è®­ç»ƒçš„BERT tokenizer</span>
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">'bert-base-uncased'</span><span class="token punctuation">)</span>

<span class="token comment"># å®šä¹‰tokenizeå‡½æ•°</span>
<span class="token keyword">def</span> <span class="token function">tokenize</span><span class="token punctuation">(</span>batch<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> tokenizer<span class="token punctuation">(</span>batch<span class="token punctuation">[</span><span class="token string">'text'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment"># å¯¹æ•°æ®é›†è¿›è¡Œtokenization</span>
tokenized_datasets <span class="token operator">=</span> dataset<span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span>tokenize<span class="token punctuation">,</span> batched<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment"># è®¾ç½®æ¨¡å‹è¾“å…¥æ ¼å¼</span>
tokenized_datasets <span class="token operator">=</span> tokenized_datasets<span class="token punctuation">.</span>rename_column<span class="token punctuation">(</span><span class="token string">"label"</span><span class="token punctuation">,</span> <span class="token string">"labels"</span><span class="token punctuation">)</span>
tokenized_datasets<span class="token punctuation">.</span>set_format<span class="token punctuation">(</span><span class="token string">'torch'</span><span class="token punctuation">,</span> columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'input_ids'</span><span class="token punctuation">,</span> <span class="token string">'attention_mask'</span><span class="token punctuation">,</span> <span class="token string">'labels'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># åŠ è½½é¢„è®­ç»ƒçš„BERTæ¨¡å‹</span>
model <span class="token operator">=</span> AutoModelForSequenceClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">'bert-base-uncased'</span><span class="token punctuation">,</span> num_labels<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>

<span class="token comment"># è®¾ç½®è®­ç»ƒå‚æ•°</span>
training_args <span class="token operator">=</span> TrainingArguments<span class="token punctuation">(</span>
    output_dir<span class="token operator">=</span><span class="token string">'./results'</span><span class="token punctuation">,</span>
    eval_strategy<span class="token operator">=</span><span class="token string">'epoch'</span><span class="token punctuation">,</span>
    save_strategy<span class="token operator">=</span><span class="token string">'epoch'</span><span class="token punctuation">,</span>
    learning_rate<span class="token operator">=</span><span class="token number">2e-5</span><span class="token punctuation">,</span>
    per_device_train_batch_size<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span>
    per_device_eval_batch_size<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span>
    logging_first_step<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span>
    <span class="token comment"># æ€»çš„è®­ç»ƒè½®æ•°</span>
    num_train_epochs<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>
    weight_decay<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">,</span>
    report_to<span class="token operator">=</span><span class="token string">"none"</span><span class="token punctuation">,</span>
    <span class="token comment"># å•å¡è®­ç»ƒ</span>
<span class="token punctuation">)</span>

CLASS_NAME <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token number">0</span><span class="token punctuation">:</span> <span class="token string">"negative"</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span> <span class="token string">"positive"</span><span class="token punctuation">}</span>

<span class="token comment"># è®¾ç½®swanlabå›è°ƒå‡½æ•°</span>
swanlab_callback <span class="token operator">=</span> SwanLabCallback<span class="token punctuation">(</span>project<span class="token operator">=</span><span class="token string">'BERT'</span><span class="token punctuation">,</span>
                                   experiment_name<span class="token operator">=</span><span class="token string">'BERT-IMDB'</span><span class="token punctuation">,</span>
                                   config<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token string">'dataset'</span><span class="token punctuation">:</span> <span class="token string">'IMDB'</span><span class="token punctuation">,</span> <span class="token string">"CLASS_NAME"</span><span class="token punctuation">:</span> CLASS_NAME<span class="token punctuation">}</span><span class="token punctuation">)</span>

<span class="token comment"># å®šä¹‰Trainer</span>
trainer <span class="token operator">=</span> Trainer<span class="token punctuation">(</span>
    model<span class="token operator">=</span>model<span class="token punctuation">,</span>
    args<span class="token operator">=</span>training_args<span class="token punctuation">,</span>
    train_dataset<span class="token operator">=</span>tokenized_datasets<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    eval_dataset<span class="token operator">=</span>tokenized_datasets<span class="token punctuation">[</span><span class="token string">'test'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    callbacks<span class="token operator">=</span><span class="token punctuation">[</span>swanlab_callback<span class="token punctuation">]</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

<span class="token comment"># è®­ç»ƒæ¨¡å‹</span>
trainer<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># ä¿å­˜æ¨¡å‹</span>
model<span class="token punctuation">.</span>save_pretrained<span class="token punctuation">(</span><span class="token string">'./sentiment_model'</span><span class="token punctuation">)</span>
tokenizer<span class="token punctuation">.</span>save_pretrained<span class="token punctuation">(</span><span class="token string">'./sentiment_model'</span><span class="token punctuation">)</span>

<span class="token comment"># æµ‹è¯•æ¨¡å‹</span>
test_reviews <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token string">"I absolutely loved this movie! The storyline was captivating and the acting was top-notch. A must-watch for everyone."</span><span class="token punctuation">,</span>
    <span class="token string">"This movie was a complete waste of time. The plot was predictable and the characters were poorly developed."</span><span class="token punctuation">,</span>
    <span class="token string">"An excellent film with a heartwarming story. The performances were outstanding, especially the lead actor."</span><span class="token punctuation">,</span>
    <span class="token string">"I found the movie to be quite boring. It dragged on and didn't really go anywhere. Not recommended."</span><span class="token punctuation">,</span>
    <span class="token string">"A masterpiece! The director did an amazing job bringing this story to life. The visuals were stunning."</span><span class="token punctuation">,</span>
    <span class="token string">"Terrible movie. The script was awful and the acting was even worse. I can't believe I sat through the whole thing."</span><span class="token punctuation">,</span>
    <span class="token string">"A delightful film with a perfect mix of humor and drama. The cast was great and the dialogue was witty."</span><span class="token punctuation">,</span>
    <span class="token string">"I was very disappointed with this movie. It had so much potential, but it just fell flat. The ending was particularly bad."</span><span class="token punctuation">,</span>
    <span class="token string">"One of the best movies I've seen this year. The story was original and the performances were incredibly moving."</span><span class="token punctuation">,</span>
    <span class="token string">"I didn't enjoy this movie at all. It was confusing and the pacing was off. Definitely not worth watching."</span>
<span class="token punctuation">]</span>

model<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cpu'</span><span class="token punctuation">)</span>
text_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> review <span class="token keyword">in</span> test_reviews<span class="token punctuation">:</span>
    label <span class="token operator">=</span> predict<span class="token punctuation">(</span>review<span class="token punctuation">,</span> model<span class="token punctuation">,</span> tokenizer<span class="token punctuation">,</span> CLASS_NAME<span class="token punctuation">)</span>
    text_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>swanlab<span class="token punctuation">.</span>Text<span class="token punctuation">(</span>review<span class="token punctuation">,</span> caption<span class="token operator">=</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>label<span class="token punctuation">}</span></span><span class="token string">-</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>CLASS_NAME<span class="token punctuation">[</span>label<span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">if</span> text_list<span class="token punctuation">:</span>
    swanlab<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span><span class="token string">"predict"</span><span class="token punctuation">:</span> text_list<span class="token punctuation">}</span><span class="token punctuation">)</span>

swanlab<span class="token punctuation">.</span>finish<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/d6/4d/MXh1Tssg_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"><br> <img src="https://images2.imgbox.com/6f/39/73aiJaG4_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"><br> <img src="https://images2.imgbox.com/65/6b/I16TMxIQ_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"><br> <img src="https://images2.imgbox.com/b0/1c/FmM8S5i3_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<h3><a id="4__155"></a>4. ç›¸å…³é“¾æ¥</h3> 
<ul><li>Transformersæ–‡æ¡£ï¼š<a href="https://huggingface.co/docs/transformers/index" rel="nofollow">ğŸ¤— Transformers</a></li><li>SwanLabå®˜ç½‘ï¼š<a href="https://swanlab.cn" rel="nofollow">SwanLab - åœ¨çº¿AIå®éªŒå¹³å°ï¼Œä¸€ç«™å¼è·Ÿè¸ªã€æ¯”è¾ƒã€åˆ†äº«ä½ çš„æ¨¡å‹</a></li><li>SwanLabå®˜æ–¹æ–‡æ¡£ï¼š<a href="https://docs.swanlab.cn" rel="nofollow">SwanLabå®˜æ–¹æ–‡æ¡£ | å…ˆè¿›çš„AIå›¢é˜Ÿåä½œä¸æ¨¡å‹åˆ›æ–°å¼•æ“</a></li></ul>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/26bc504490227eb88400ab0dba7ebe88/" rel="prev">
			<span class="pager__subtitle">Â«&thinsp;Previous</span>
			<p class="pager__title">Llamaæ¨¡å‹å®¶æ—è®­ç»ƒå¥–åŠ±æ¨¡å‹Reward ModelæŠ€æœ¯åŠä»£ç å®æˆ˜ï¼ˆä¸‰ï¼‰ ä½¿ç”¨ TRL è®­ç»ƒå¥–åŠ±æ¨¡å‹</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/79f6ce210f045d038c20a85ed2a6e37d/" rel="next">
			<span class="pager__subtitle">Next&thinsp;Â»</span>
			<p class="pager__title">åŸºäºjavaswingå’Œmysqlå®ç°çš„å‘˜å·¥å·¥èµ„ç®¡ç†ç³»ç»Ÿ</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 ç¼–ç¨‹å¤§å’–.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>