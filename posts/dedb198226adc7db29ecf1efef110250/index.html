<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>whisper使用 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/dedb198226adc7db29ecf1efef110250/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="whisper使用">
  <meta property="og:description" content="whisper使用 1. 直接调用 语音识别2. 语种识别 whisper.detect_language()和whisper.decode()3. 指定要识别的语种做语音识别**whisper 源码的transcribe函数** 函数解析1. transcript.py2. tokenizer.py3. audio.py4. __ init__.py github: https://gitcode.com/openai/whisper/overview 1. 直接调用 语音识别 ,transcribe()方法会读取整个文件，并使用一个30秒的滑动窗口对音频进行处理，对每个窗口进行自回归序列到序列的预测。
官网readme调用1
import whisper model = whisper.load_model(&#34;base&#34;) # 加载模型 result = model.transcribe(&#34;audio.mp3&#34;) # 指定音频路径 识别 print(result[&#34;text&#34;]) # 输出识别结果 load_model方法在__init__.py文件中有定义
{&#39;text&#39;: &#39; 你一定會笑著說 二百克芝麻能力好耐架&#39;, &#39;segments&#39;: [{&#39;id&#39;: 0, &#39;seek&#39;: 0, &#39;start&#39;: 0.0, &#39;end&#39;: 2.0, &#39;text&#39;: &#39; 你一定會笑著說&#39;, &#39;tokens&#39;: [50365, 10930, 24272, 6236, 11600, 19382, 4622, 50465], &#39;temperature&#39;: 0.0, &#39;avg_logprob&#39;: -0.5130815124511718, &#39;compression_ratio&#39;: 0.8253968253968254, &#39;no_speech_prob&#39;: 0.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-05-10T16:51:34+08:00">
    <meta property="article:modified_time" content="2024-05-10T16:51:34+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">whisper使用</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>whisper使用</h4> 
 <ul><li><a href="#1___2" rel="nofollow">1. 直接调用 语音识别</a></li><li><a href="#2___whisperdetect_languagewhisperdecode_16" rel="nofollow">2. 语种识别 whisper.detect_language()和whisper.decode()</a></li><li><a href="#3__48" rel="nofollow">3. 指定要识别的语种做语音识别</a></li><li><ul><li><a href="#whisper_transcribe_56" rel="nofollow">**whisper 源码的transcribe函数**</a></li></ul> 
  </li><li><a href="#_521" rel="nofollow">函数解析</a></li><li><ul><li><a href="#1_transcriptpy_522" rel="nofollow">1. transcript.py</a></li><li><a href="#2_tokenizerpy_550" rel="nofollow">2. tokenizer.py</a></li><li><a href="#3_audiopy_553" rel="nofollow">3. audio.py</a></li><li><a href="#4____init__py_557" rel="nofollow">4. __ init__.py</a></li></ul> 
 </li></ul> 
</div> 
<br> 
<strong>github:</strong> https://gitcode.com/openai/whisper/overview 
<p></p> 
<h2><a id="1___2"></a>1. 直接调用 语音识别</h2> 
<p>,transcribe()方法会读取整个文件，并使用一个30秒的滑动窗口对音频进行处理，对每个窗口进行自回归序列到序列的预测。<br> 官网readme调用1</p> 
<pre><code class="prism language-py"><span class="token keyword">import</span> whisper

model <span class="token operator">=</span> whisper<span class="token punctuation">.</span>load_model<span class="token punctuation">(</span><span class="token string">"base"</span><span class="token punctuation">)</span>  <span class="token comment"># 加载模型</span>
result <span class="token operator">=</span> model<span class="token punctuation">.</span>transcribe<span class="token punctuation">(</span><span class="token string">"audio.mp3"</span><span class="token punctuation">)</span>  <span class="token comment"># 指定音频路径 识别</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 输出识别结果</span>
</code></pre> 
<p><code>load_model方法在__init__.py文件中有定义</code></p> 
<pre><code class="prism language-json"><span class="token punctuation">{<!-- --></span><span class="token string-property property">'text'</span><span class="token operator">:</span> <span class="token string">' 你一定會笑著說 二百克芝麻能力好耐架'</span><span class="token punctuation">,</span> <span class="token string-property property">'segments'</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token punctuation">{<!-- --></span><span class="token string-property property">'id'</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string-property property">'seek'</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string-property property">'start'</span><span class="token operator">:</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token string-property property">'end'</span><span class="token operator">:</span> <span class="token number">2.0</span><span class="token punctuation">,</span> <span class="token string-property property">'text'</span><span class="token operator">:</span> <span class="token string">' 你一定會笑著說'</span><span class="token punctuation">,</span> <span class="token string-property property">'tokens'</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token number">50365</span><span class="token punctuation">,</span> <span class="token number">10930</span><span class="token punctuation">,</span> <span class="token number">24272</span><span class="token punctuation">,</span> <span class="token number">6236</span><span class="token punctuation">,</span> <span class="token number">11600</span><span class="token punctuation">,</span> <span class="token number">19382</span><span class="token punctuation">,</span> <span class="token number">4622</span><span class="token punctuation">,</span> <span class="token number">50465</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string-property property">'temperature'</span><span class="token operator">:</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token string-property property">'avg_logprob'</span><span class="token operator">:</span> <span class="token operator">-</span><span class="token number">0.5130815124511718</span><span class="token punctuation">,</span> <span class="token string-property property">'compression_ratio'</span><span class="token operator">:</span> <span class="token number">0.8253968253968254</span><span class="token punctuation">,</span> <span class="token string-property property">'no_speech_prob'</span><span class="token operator">:</span> <span class="token number">0.12529681622982025</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{<!-- --></span><span class="token string-property property">'id'</span><span class="token operator">:</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token string-property property">'seek'</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string-property property">'start'</span><span class="token operator">:</span> <span class="token number">2.0</span><span class="token punctuation">,</span> <span class="token string-property property">'end'</span><span class="token operator">:</span> <span class="token number">5.5</span><span class="token punctuation">,</span> <span class="token string-property property">'text'</span><span class="token operator">:</span> <span class="token string">' 二百克芝麻能力好耐架'</span><span class="token punctuation">,</span> <span class="token string-property property">'tokens'</span><span class="token operator">:</span> <span class="token punctuation">[</span><span class="token number">50465</span><span class="token punctuation">,</span> <span class="token number">220</span><span class="token punctuation">,</span> <span class="token number">11217</span><span class="token punctuation">,</span> <span class="token number">31906</span><span class="token punctuation">,</span> <span class="token number">24881</span><span class="token punctuation">,</span> <span class="token number">13778</span><span class="token punctuation">,</span> <span class="token number">251</span><span class="token punctuation">,</span> <span class="token number">38999</span><span class="token punctuation">,</span> <span class="token number">8225</span><span class="token punctuation">,</span> <span class="token number">13486</span><span class="token punctuation">,</span> <span class="token number">2131</span><span class="token punctuation">,</span> <span class="token number">4450</span><span class="token punctuation">,</span> <span class="token number">238</span><span class="token punctuation">,</span> <span class="token number">7360</span><span class="token punctuation">,</span> <span class="token number">114</span><span class="token punctuation">,</span> <span class="token number">50640</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string-property property">'temperature'</span><span class="token operator">:</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token string-property property">'avg_logprob'</span><span class="token operator">:</span> <span class="token operator">-</span><span class="token number">0.5130815124511718</span><span class="token punctuation">,</span> <span class="token string-property property">'compression_ratio'</span><span class="token operator">:</span> <span class="token number">0.8253968253968254</span><span class="token punctuation">,</span> <span class="token string-property property">'no_speech_prob'</span><span class="token operator">:</span> <span class="token number">0.12529681622982025</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string-property property">'language'</span><span class="token operator">:</span> <span class="token string">'yue'</span><span class="token punctuation">}</span>
</code></pre> 
<h2><a id="2___whisperdetect_languagewhisperdecode_16"></a>2. 语种识别 whisper.detect_language()和whisper.decode()</h2> 
<p>以下是使用whisper.detect_language()和whisper.decode()的示例用法，这些方法提供对模型的更低级别访问。更低级别可以说是更底层的调用。<br> 官网readme调用2</p> 
<pre><code class="prism language-py"><span class="token keyword">import</span> whisper

model <span class="token operator">=</span> whisper<span class="token punctuation">.</span>load_model<span class="token punctuation">(</span><span class="token string">"base"</span><span class="token punctuation">)</span> <span class="token comment"># 加载预训练的语音识别模型，这里使用了名为"base"的模型。</span>

<span class="token comment"># load audio and pad/trim it to fit 30 seconds</span>
audio <span class="token operator">=</span> whisper<span class="token punctuation">.</span>load_audio<span class="token punctuation">(</span><span class="token string">"audio.mp3"</span><span class="token punctuation">)</span>
audio <span class="token operator">=</span> whisper<span class="token punctuation">.</span>pad_or_trim<span class="token punctuation">(</span>audio<span class="token punctuation">)</span>  <span class="token comment"># 对加载的音频进行填充或裁剪，使其适合30秒的滑动窗口处理。</span>

<span class="token comment"># make log-Mel spectrogram and move to the same device as the model</span>
mel <span class="token operator">=</span> whisper<span class="token punctuation">.</span>log_mel_spectrogram<span class="token punctuation">(</span>audio<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>model<span class="token punctuation">.</span>device<span class="token punctuation">)</span> 
<span class="token comment"># 将音频转换为对数梅尔频谱图，并将其移动到与模型相同的设备（如GPU）上进行处理。</span>

<span class="token comment"># detect the spoken language</span>
_<span class="token punctuation">,</span> probs <span class="token operator">=</span> model<span class="token punctuation">.</span>detect_language<span class="token punctuation">(</span>mel<span class="token punctuation">)</span> <span class="token comment"># 使用模型进行语言检测，返回检测到的语言和对应的概率。</span>
<span class="token comment"># 打印检测到的语言，选取概率最高的语言作为结果。</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Detected language: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span><span class="token builtin">max</span><span class="token punctuation">(</span>probs<span class="token punctuation">,</span> key<span class="token operator">=</span>probs<span class="token punctuation">.</span>get<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

<span class="token comment"># decode the audio</span>
<span class="token comment"># 置解码的选项，如语言模型、解码器等。</span>
options <span class="token operator">=</span> whisper<span class="token punctuation">.</span>DecodingOptions<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># 使用模型对音频进行解码，生成识别结果。</span>
result <span class="token operator">=</span> whisper<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>model<span class="token punctuation">,</span> mel<span class="token punctuation">,</span> options<span class="token punctuation">)</span>

<span class="token comment"># print the recognized text</span>
<span class="token comment"># 打印识别结果，即模型识别出的文本内容。</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">.</span>text<span class="token punctuation">)</span>
</code></pre> 
<h2><a id="3__48"></a>3. 指定要识别的语种做语音识别</h2> 
<pre><code class="prism language-py"><span class="token keyword">from</span> whisper <span class="token keyword">import</span> load_model
<span class="token keyword">from</span> whisper<span class="token punctuation">.</span>transcribe <span class="token keyword">import</span> transcribe
model <span class="token operator">=</span> load_model<span class="token punctuation">(</span>model_path<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span>
<span class="token comment"># 指定model 音频路径 要识别的语言类型  yue--粤语</span>
result <span class="token operator">=</span> transcribe<span class="token punctuation">(</span>model<span class="token punctuation">,</span> audio_path<span class="token punctuation">,</span> language<span class="token operator">=</span><span class="token string">"yue"</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="whisper_transcribe_56"></a><strong>whisper 源码的transcribe函数</strong></h3> 
<pre><code class="prism language-py"><span class="token keyword">def</span> <span class="token function">transcribe</span><span class="token punctuation">(</span>
    model<span class="token punctuation">:</span> <span class="token string">"Whisper"</span><span class="token punctuation">,</span>
    audio<span class="token punctuation">:</span> Union<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token operator">*</span><span class="token punctuation">,</span>
    verbose<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span><span class="token builtin">bool</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    temperature<span class="token punctuation">:</span> Union<span class="token punctuation">[</span><span class="token builtin">float</span><span class="token punctuation">,</span> Tuple<span class="token punctuation">[</span><span class="token builtin">float</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">,</span> <span class="token number">0.4</span><span class="token punctuation">,</span> <span class="token number">0.6</span><span class="token punctuation">,</span> <span class="token number">0.8</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    compression_ratio_threshold<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span><span class="token builtin">float</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">2.4</span><span class="token punctuation">,</span>
    logprob_threshold<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span><span class="token builtin">float</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1.0</span><span class="token punctuation">,</span>
    no_speech_threshold<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span><span class="token builtin">float</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0.6</span><span class="token punctuation">,</span>
    condition_on_previous_text<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span>
    initial_prompt<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    word_timestamps<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span>
    prepend_punctuations<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> <span class="token string">"\"'“¿([{-"</span><span class="token punctuation">,</span>
    append_punctuations<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> <span class="token string">"\"'.。,，!！?？:：”)]}、"</span><span class="token punctuation">,</span>
    clip_timestamps<span class="token punctuation">:</span> Union<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">,</span> List<span class="token punctuation">[</span><span class="token builtin">float</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">"0"</span><span class="token punctuation">,</span>
    hallucination_silence_threshold<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span><span class="token builtin">float</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
    <span class="token operator">**</span>decode_options<span class="token punctuation">,</span>
<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    Transcribe an audio file using Whisper

    Parameters
    ----------
    model: Whisper
        The Whisper model instance

    audio: Union[str, np.ndarray, torch.Tensor]
        The path to the audio file to open, or the audio waveform

    verbose: bool
        Whether to display the text being decoded to the console. If True, displays all the details,
        If False, displays minimal details. If None, does not display anything

    temperature: Union[float, Tuple[float, ...]]
        Temperature for sampling. It can be a tuple of temperatures, which will be successively used
        upon failures according to either `compression_ratio_threshold` or `logprob_threshold`.

    compression_ratio_threshold: float
        If the gzip compression ratio is above this value, treat as failed

    logprob_threshold: float
        If the average log probability over sampled tokens is below this value, treat as failed

    no_speech_threshold: float
        If the no_speech probability is higher than this value AND the average log probability
        over sampled tokens is below `logprob_threshold`, consider the segment as silent

    condition_on_previous_text: bool
        if True, the previous output of the model is provided as a prompt for the next window;
        disabling may make the text inconsistent across windows, but the model becomes less prone to
        getting stuck in a failure loop, such as repetition looping or timestamps going out of sync.

    word_timestamps: bool
        Extract word-level timestamps using the cross-attention pattern and dynamic time warping,
        and include the timestamps for each word in each segment.

    prepend_punctuations: str
        If word_timestamps is True, merge these punctuation symbols with the next word

    append_punctuations: str
        If word_timestamps is True, merge these punctuation symbols with the previous word

    initial_prompt: Optional[str]
        Optional text to provide as a prompt for the first window. This can be used to provide, or
        "prompt-engineer" a context for transcription, e.g. custom vocabularies or proper nouns
        to make it more likely to predict those word correctly.

    decode_options: dict
        Keyword arguments to construct `DecodingOptions` instances

    clip_timestamps: Union[str, List[float]]
        Comma-separated list start,end,start,end,... timestamps (in seconds) of clips to process.
        The last end timestamp defaults to the end of the file.

    hallucination_silence_threshold: Optional[float]
        When word_timestamps is True, skip silent periods longer than this threshold (in seconds)
        when a possible hallucination is detected

    Returns
    -------
    A dictionary containing the resulting text ("text") and segment-level details ("segments"), and
    the spoken language ("language"), which is detected when `decode_options["language"]` is None.
    """</span>
    dtype <span class="token operator">=</span> torch<span class="token punctuation">.</span>float16 <span class="token keyword">if</span> decode_options<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"fp16"</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span> <span class="token keyword">else</span> torch<span class="token punctuation">.</span>float32
    <span class="token keyword">if</span> model<span class="token punctuation">.</span>device <span class="token operator">==</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cpu"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            warnings<span class="token punctuation">.</span>warn<span class="token punctuation">(</span><span class="token string">"Performing inference on CPU when CUDA is available"</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> dtype <span class="token operator">==</span> torch<span class="token punctuation">.</span>float16<span class="token punctuation">:</span>
            warnings<span class="token punctuation">.</span>warn<span class="token punctuation">(</span><span class="token string">"FP16 is not supported on CPU; using FP32 instead"</span><span class="token punctuation">)</span>
            dtype <span class="token operator">=</span> torch<span class="token punctuation">.</span>float32

    <span class="token keyword">if</span> dtype <span class="token operator">==</span> torch<span class="token punctuation">.</span>float32<span class="token punctuation">:</span>
        decode_options<span class="token punctuation">[</span><span class="token string">"fp16"</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">False</span>

    <span class="token comment"># Pad 30-seconds of silence to the input audio, for slicing</span>
    mel <span class="token operator">=</span> log_mel_spectrogram<span class="token punctuation">(</span>audio<span class="token punctuation">,</span> model<span class="token punctuation">.</span>dims<span class="token punctuation">.</span>n_mels<span class="token punctuation">,</span> padding<span class="token operator">=</span>N_SAMPLES<span class="token punctuation">)</span>
    content_frames <span class="token operator">=</span> mel<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">-</span> N_FRAMES
    content_duration <span class="token operator">=</span> <span class="token builtin">float</span><span class="token punctuation">(</span>content_frames <span class="token operator">*</span> HOP_LENGTH <span class="token operator">/</span> SAMPLE_RATE<span class="token punctuation">)</span>

    <span class="token keyword">if</span> decode_options<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"language"</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span> <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> model<span class="token punctuation">.</span>is_multilingual<span class="token punctuation">:</span>
            decode_options<span class="token punctuation">[</span><span class="token string">"language"</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">"en"</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> verbose<span class="token punctuation">:</span>
                <span class="token keyword">print</span><span class="token punctuation">(</span>
                    <span class="token string">"Detecting language using up to the first 30 seconds. Use `--language` to specify the language"</span>
                <span class="token punctuation">)</span>
            mel_segment <span class="token operator">=</span> pad_or_trim<span class="token punctuation">(</span>mel<span class="token punctuation">,</span> N_FRAMES<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>model<span class="token punctuation">.</span>device<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>dtype<span class="token punctuation">)</span>
            _<span class="token punctuation">,</span> probs <span class="token operator">=</span> model<span class="token punctuation">.</span>detect_language<span class="token punctuation">(</span>mel_segment<span class="token punctuation">)</span>
            decode_options<span class="token punctuation">[</span><span class="token string">"language"</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span>probs<span class="token punctuation">,</span> key<span class="token operator">=</span>probs<span class="token punctuation">.</span>get<span class="token punctuation">)</span>
            <span class="token keyword">if</span> verbose <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
                <span class="token keyword">print</span><span class="token punctuation">(</span>
                    <span class="token string-interpolation"><span class="token string">f"Detected language: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>LANGUAGES<span class="token punctuation">[</span>decode_options<span class="token punctuation">[</span><span class="token string">'language'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">"</span></span>
                <span class="token punctuation">)</span>

    language<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> decode_options<span class="token punctuation">[</span><span class="token string">"language"</span><span class="token punctuation">]</span>
    task<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> decode_options<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"task"</span><span class="token punctuation">,</span> <span class="token string">"transcribe"</span><span class="token punctuation">)</span>
    tokenizer <span class="token operator">=</span> get_tokenizer<span class="token punctuation">(</span>
        model<span class="token punctuation">.</span>is_multilingual<span class="token punctuation">,</span>
        num_languages<span class="token operator">=</span>model<span class="token punctuation">.</span>num_languages<span class="token punctuation">,</span>
        language<span class="token operator">=</span>language<span class="token punctuation">,</span>
        task<span class="token operator">=</span>task<span class="token punctuation">,</span>
    <span class="token punctuation">)</span>

    <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>clip_timestamps<span class="token punctuation">,</span> <span class="token builtin">str</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        clip_timestamps <span class="token operator">=</span> <span class="token punctuation">[</span>
            <span class="token builtin">float</span><span class="token punctuation">(</span>ts<span class="token punctuation">)</span> <span class="token keyword">for</span> ts <span class="token keyword">in</span> <span class="token punctuation">(</span>clip_timestamps<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">","</span><span class="token punctuation">)</span> <span class="token keyword">if</span> clip_timestamps <span class="token keyword">else</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token punctuation">]</span>
    seek_points<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token builtin">round</span><span class="token punctuation">(</span>ts <span class="token operator">*</span> FRAMES_PER_SECOND<span class="token punctuation">)</span> <span class="token keyword">for</span> ts <span class="token keyword">in</span> clip_timestamps<span class="token punctuation">]</span>
    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>seek_points<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        seek_points<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>seek_points<span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">2</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
        seek_points<span class="token punctuation">.</span>append<span class="token punctuation">(</span>content_frames<span class="token punctuation">)</span>
    seek_clips<span class="token punctuation">:</span> List<span class="token punctuation">[</span>Tuple<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">zip</span><span class="token punctuation">(</span>seek_points<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> seek_points<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    punctuation <span class="token operator">=</span> <span class="token string">"\"'“¿([{-\"'.。,，!！?？:：”)]}、"</span>

    <span class="token keyword">if</span> word_timestamps <span class="token keyword">and</span> task <span class="token operator">==</span> <span class="token string">"translate"</span><span class="token punctuation">:</span>
        warnings<span class="token punctuation">.</span>warn<span class="token punctuation">(</span><span class="token string">"Word-level timestamps on translations may not be reliable."</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">decode_with_fallback</span><span class="token punctuation">(</span>segment<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> DecodingResult<span class="token punctuation">:</span>
        temperatures <span class="token operator">=</span> <span class="token punctuation">(</span>
            <span class="token punctuation">[</span>temperature<span class="token punctuation">]</span> <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>temperature<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">,</span> <span class="token builtin">float</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">else</span> temperature
        <span class="token punctuation">)</span>
        decode_result <span class="token operator">=</span> <span class="token boolean">None</span>

        <span class="token keyword">for</span> t <span class="token keyword">in</span> temperatures<span class="token punctuation">:</span>
            kwargs <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token operator">**</span>decode_options<span class="token punctuation">}</span>
            <span class="token keyword">if</span> t <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">:</span>
                <span class="token comment"># disable beam_size and patience when t &gt; 0</span>
                kwargs<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">"beam_size"</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span>
                kwargs<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">"patience"</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                <span class="token comment"># disable best_of when t == 0</span>
                kwargs<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">"best_of"</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span>

            options <span class="token operator">=</span> DecodingOptions<span class="token punctuation">(</span><span class="token operator">**</span>kwargs<span class="token punctuation">,</span> temperature<span class="token operator">=</span>t<span class="token punctuation">)</span>
            decode_result <span class="token operator">=</span> model<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>segment<span class="token punctuation">,</span> options<span class="token punctuation">)</span>

            needs_fallback <span class="token operator">=</span> <span class="token boolean">False</span>
            <span class="token keyword">if</span> <span class="token punctuation">(</span>
                compression_ratio_threshold <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span>
                <span class="token keyword">and</span> decode_result<span class="token punctuation">.</span>compression_ratio <span class="token operator">&gt;</span> compression_ratio_threshold
            <span class="token punctuation">)</span><span class="token punctuation">:</span>
                needs_fallback <span class="token operator">=</span> <span class="token boolean">True</span>  <span class="token comment"># too repetitive</span>
            <span class="token keyword">if</span> <span class="token punctuation">(</span>
                logprob_threshold <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span>
                <span class="token keyword">and</span> decode_result<span class="token punctuation">.</span>avg_logprob <span class="token operator">&lt;</span> logprob_threshold
            <span class="token punctuation">)</span><span class="token punctuation">:</span>
                needs_fallback <span class="token operator">=</span> <span class="token boolean">True</span>  <span class="token comment"># average log probability is too low</span>
            <span class="token keyword">if</span> <span class="token punctuation">(</span>
                no_speech_threshold <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span>
                <span class="token keyword">and</span> decode_result<span class="token punctuation">.</span>no_speech_prob <span class="token operator">&gt;</span> no_speech_threshold
            <span class="token punctuation">)</span><span class="token punctuation">:</span>
                needs_fallback <span class="token operator">=</span> <span class="token boolean">False</span>  <span class="token comment"># silence</span>
            <span class="token keyword">if</span> <span class="token keyword">not</span> needs_fallback<span class="token punctuation">:</span>
                <span class="token keyword">break</span>

        <span class="token keyword">return</span> decode_result

    clip_idx <span class="token operator">=</span> <span class="token number">0</span>
    seek <span class="token operator">=</span> seek_clips<span class="token punctuation">[</span>clip_idx<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    input_stride <span class="token operator">=</span> exact_div<span class="token punctuation">(</span>
        N_FRAMES<span class="token punctuation">,</span> model<span class="token punctuation">.</span>dims<span class="token punctuation">.</span>n_audio_ctx
    <span class="token punctuation">)</span>  <span class="token comment"># mel frames per output token: 2</span>
    time_precision <span class="token operator">=</span> <span class="token punctuation">(</span>
        input_stride <span class="token operator">*</span> HOP_LENGTH <span class="token operator">/</span> SAMPLE_RATE
    <span class="token punctuation">)</span>  <span class="token comment"># time per output token: 0.02 (seconds)</span>
    all_tokens <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    all_segments <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    prompt_reset_since <span class="token operator">=</span> <span class="token number">0</span>

    <span class="token keyword">if</span> initial_prompt <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        initial_prompt_tokens <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>encode<span class="token punctuation">(</span><span class="token string">" "</span> <span class="token operator">+</span> initial_prompt<span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        all_tokens<span class="token punctuation">.</span>extend<span class="token punctuation">(</span>initial_prompt_tokens<span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        initial_prompt_tokens <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">new_segment</span><span class="token punctuation">(</span>
        <span class="token operator">*</span><span class="token punctuation">,</span> start<span class="token punctuation">:</span> <span class="token builtin">float</span><span class="token punctuation">,</span> end<span class="token punctuation">:</span> <span class="token builtin">float</span><span class="token punctuation">,</span> tokens<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">,</span> result<span class="token punctuation">:</span> DecodingResult
    <span class="token punctuation">)</span><span class="token punctuation">:</span>
        tokens <span class="token operator">=</span> tokens<span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span>
        text_tokens <span class="token operator">=</span> <span class="token punctuation">[</span>token <span class="token keyword">for</span> token <span class="token keyword">in</span> tokens <span class="token keyword">if</span> token <span class="token operator">&lt;</span> tokenizer<span class="token punctuation">.</span>eot<span class="token punctuation">]</span>
        <span class="token keyword">return</span> <span class="token punctuation">{<!-- --></span>
            <span class="token string">"seek"</span><span class="token punctuation">:</span> seek<span class="token punctuation">,</span>
            <span class="token string">"start"</span><span class="token punctuation">:</span> start<span class="token punctuation">,</span>
            <span class="token string">"end"</span><span class="token punctuation">:</span> end<span class="token punctuation">,</span>
            <span class="token string">"text"</span><span class="token punctuation">:</span> tokenizer<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>text_tokens<span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token string">"tokens"</span><span class="token punctuation">:</span> tokens<span class="token punctuation">,</span>
            <span class="token string">"temperature"</span><span class="token punctuation">:</span> result<span class="token punctuation">.</span>temperature<span class="token punctuation">,</span>
            <span class="token string">"avg_logprob"</span><span class="token punctuation">:</span> result<span class="token punctuation">.</span>avg_logprob<span class="token punctuation">,</span>
            <span class="token string">"compression_ratio"</span><span class="token punctuation">:</span> result<span class="token punctuation">.</span>compression_ratio<span class="token punctuation">,</span>
            <span class="token string">"no_speech_prob"</span><span class="token punctuation">:</span> result<span class="token punctuation">.</span>no_speech_prob<span class="token punctuation">,</span>
        <span class="token punctuation">}</span>

    <span class="token comment"># show the progress bar when verbose is False (if True, transcribed text will be printed)</span>
    <span class="token keyword">with</span> tqdm<span class="token punctuation">.</span>tqdm<span class="token punctuation">(</span>
        total<span class="token operator">=</span>content_frames<span class="token punctuation">,</span> unit<span class="token operator">=</span><span class="token string">"frames"</span><span class="token punctuation">,</span> disable<span class="token operator">=</span>verbose <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">False</span>
    <span class="token punctuation">)</span> <span class="token keyword">as</span> pbar<span class="token punctuation">:</span>
        last_speech_timestamp <span class="token operator">=</span> <span class="token number">0.0</span>
        <span class="token comment"># NOTE: This loop is obscurely flattened to make the diff readable.</span>
        <span class="token comment"># A later commit should turn this into a simpler nested loop.</span>
        <span class="token comment"># for seek_clip_start, seek_clip_end in seek_clips:</span>
        <span class="token comment">#     while seek &lt; seek_clip_end</span>
        <span class="token keyword">while</span> clip_idx <span class="token operator">&lt;</span> <span class="token builtin">len</span><span class="token punctuation">(</span>seek_clips<span class="token punctuation">)</span><span class="token punctuation">:</span>
            seek_clip_start<span class="token punctuation">,</span> seek_clip_end <span class="token operator">=</span> seek_clips<span class="token punctuation">[</span>clip_idx<span class="token punctuation">]</span>
            <span class="token keyword">if</span> seek <span class="token operator">&lt;</span> seek_clip_start<span class="token punctuation">:</span>
                seek <span class="token operator">=</span> seek_clip_start
            <span class="token keyword">if</span> seek <span class="token operator">&gt;=</span> seek_clip_end<span class="token punctuation">:</span>
                clip_idx <span class="token operator">+=</span> <span class="token number">1</span>
                <span class="token keyword">if</span> clip_idx <span class="token operator">&lt;</span> <span class="token builtin">len</span><span class="token punctuation">(</span>seek_clips<span class="token punctuation">)</span><span class="token punctuation">:</span>
                    seek <span class="token operator">=</span> seek_clips<span class="token punctuation">[</span>clip_idx<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
                <span class="token keyword">continue</span>
            time_offset <span class="token operator">=</span> <span class="token builtin">float</span><span class="token punctuation">(</span>seek <span class="token operator">*</span> HOP_LENGTH <span class="token operator">/</span> SAMPLE_RATE<span class="token punctuation">)</span>
            window_end_time <span class="token operator">=</span> <span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">(</span>seek <span class="token operator">+</span> N_FRAMES<span class="token punctuation">)</span> <span class="token operator">*</span> HOP_LENGTH <span class="token operator">/</span> SAMPLE_RATE<span class="token punctuation">)</span>
            segment_size <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span>N_FRAMES<span class="token punctuation">,</span> content_frames <span class="token operator">-</span> seek<span class="token punctuation">,</span> seek_clip_end <span class="token operator">-</span> seek<span class="token punctuation">)</span>
            mel_segment <span class="token operator">=</span> mel<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> seek <span class="token punctuation">:</span> seek <span class="token operator">+</span> segment_size<span class="token punctuation">]</span>
            segment_duration <span class="token operator">=</span> segment_size <span class="token operator">*</span> HOP_LENGTH <span class="token operator">/</span> SAMPLE_RATE
            mel_segment <span class="token operator">=</span> pad_or_trim<span class="token punctuation">(</span>mel_segment<span class="token punctuation">,</span> N_FRAMES<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>model<span class="token punctuation">.</span>device<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>dtype<span class="token punctuation">)</span>

            decode_options<span class="token punctuation">[</span><span class="token string">"prompt"</span><span class="token punctuation">]</span> <span class="token operator">=</span> all_tokens<span class="token punctuation">[</span>prompt_reset_since<span class="token punctuation">:</span><span class="token punctuation">]</span>
            result<span class="token punctuation">:</span> DecodingResult <span class="token operator">=</span> decode_with_fallback<span class="token punctuation">(</span>mel_segment<span class="token punctuation">)</span>
            tokens <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>result<span class="token punctuation">.</span>tokens<span class="token punctuation">)</span>

            <span class="token keyword">if</span> no_speech_threshold <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
                <span class="token comment"># no voice activity check</span>
                should_skip <span class="token operator">=</span> result<span class="token punctuation">.</span>no_speech_prob <span class="token operator">&gt;</span> no_speech_threshold
                <span class="token keyword">if</span> <span class="token punctuation">(</span>
                    logprob_threshold <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span>
                    <span class="token keyword">and</span> result<span class="token punctuation">.</span>avg_logprob <span class="token operator">&gt;</span> logprob_threshold
                <span class="token punctuation">)</span><span class="token punctuation">:</span>
                    <span class="token comment"># don't skip if the logprob is high enough, despite the no_speech_prob</span>
                    should_skip <span class="token operator">=</span> <span class="token boolean">False</span>

                <span class="token keyword">if</span> should_skip<span class="token punctuation">:</span>
                    seek <span class="token operator">+=</span> segment_size  <span class="token comment"># fast-forward to the next segment boundary</span>
                    <span class="token keyword">continue</span>

            previous_seek <span class="token operator">=</span> seek
            current_segments <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

            <span class="token comment"># anomalous words are very long/short/improbable</span>
            <span class="token keyword">def</span> <span class="token function">word_anomaly_score</span><span class="token punctuation">(</span>word<span class="token punctuation">:</span> <span class="token builtin">dict</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">float</span><span class="token punctuation">:</span>
                probability <span class="token operator">=</span> word<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"probability"</span><span class="token punctuation">,</span> <span class="token number">0.0</span><span class="token punctuation">)</span>
                duration <span class="token operator">=</span> word<span class="token punctuation">[</span><span class="token string">"end"</span><span class="token punctuation">]</span> <span class="token operator">-</span> word<span class="token punctuation">[</span><span class="token string">"start"</span><span class="token punctuation">]</span>
                score <span class="token operator">=</span> <span class="token number">0.0</span>
                <span class="token keyword">if</span> probability <span class="token operator">&lt;</span> <span class="token number">0.15</span><span class="token punctuation">:</span>
                    score <span class="token operator">+=</span> <span class="token number">1.0</span>
                <span class="token keyword">if</span> duration <span class="token operator">&lt;</span> <span class="token number">0.133</span><span class="token punctuation">:</span>
                    score <span class="token operator">+=</span> <span class="token punctuation">(</span><span class="token number">0.133</span> <span class="token operator">-</span> duration<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">15</span>
                <span class="token keyword">if</span> duration <span class="token operator">&gt;</span> <span class="token number">2.0</span><span class="token punctuation">:</span>
                    score <span class="token operator">+=</span> duration <span class="token operator">-</span> <span class="token number">2.0</span>
                <span class="token keyword">return</span> score

            <span class="token keyword">def</span> <span class="token function">is_segment_anomaly</span><span class="token punctuation">(</span>segment<span class="token punctuation">:</span> Optional<span class="token punctuation">[</span><span class="token builtin">dict</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token builtin">bool</span><span class="token punctuation">:</span>
                <span class="token keyword">if</span> segment <span class="token keyword">is</span> <span class="token boolean">None</span> <span class="token keyword">or</span> <span class="token keyword">not</span> segment<span class="token punctuation">[</span><span class="token string">"words"</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
                    <span class="token keyword">return</span> <span class="token boolean">False</span>
                words <span class="token operator">=</span> <span class="token punctuation">[</span>w <span class="token keyword">for</span> w <span class="token keyword">in</span> segment<span class="token punctuation">[</span><span class="token string">"words"</span><span class="token punctuation">]</span> <span class="token keyword">if</span> w<span class="token punctuation">[</span><span class="token string">"word"</span><span class="token punctuation">]</span> <span class="token keyword">not</span> <span class="token keyword">in</span> punctuation<span class="token punctuation">]</span>
                words <span class="token operator">=</span> words<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">8</span><span class="token punctuation">]</span>
                score <span class="token operator">=</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>word_anomaly_score<span class="token punctuation">(</span>w<span class="token punctuation">)</span> <span class="token keyword">for</span> w <span class="token keyword">in</span> words<span class="token punctuation">)</span>
                <span class="token keyword">return</span> score <span class="token operator">&gt;=</span> <span class="token number">3</span> <span class="token keyword">or</span> score <span class="token operator">+</span> <span class="token number">0.01</span> <span class="token operator">&gt;=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>words<span class="token punctuation">)</span>

            <span class="token keyword">def</span> <span class="token function">next_words_segment</span><span class="token punctuation">(</span>segments<span class="token punctuation">:</span> List<span class="token punctuation">[</span><span class="token builtin">dict</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> Optional<span class="token punctuation">[</span><span class="token builtin">dict</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
                <span class="token keyword">return</span> <span class="token builtin">next</span><span class="token punctuation">(</span><span class="token punctuation">(</span>s <span class="token keyword">for</span> s <span class="token keyword">in</span> segments <span class="token keyword">if</span> s<span class="token punctuation">[</span><span class="token string">"words"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span>

            timestamp_tokens<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>Tensor <span class="token operator">=</span> tokens<span class="token punctuation">.</span>ge<span class="token punctuation">(</span>tokenizer<span class="token punctuation">.</span>timestamp_begin<span class="token punctuation">)</span>
            single_timestamp_ending <span class="token operator">=</span> timestamp_tokens<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token punctuation">[</span><span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">]</span>

            consecutive <span class="token operator">=</span> torch<span class="token punctuation">.</span>where<span class="token punctuation">(</span>timestamp_tokens<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">&amp;</span> timestamp_tokens<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            consecutive<span class="token punctuation">.</span>add_<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
            <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>consecutive<span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">:</span>
                <span class="token comment"># if the output contains two consecutive timestamp tokens</span>
                slices <span class="token operator">=</span> consecutive<span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span>
                <span class="token keyword">if</span> single_timestamp_ending<span class="token punctuation">:</span>
                    slices<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>tokens<span class="token punctuation">)</span><span class="token punctuation">)</span>

                last_slice <span class="token operator">=</span> <span class="token number">0</span>
                <span class="token keyword">for</span> current_slice <span class="token keyword">in</span> slices<span class="token punctuation">:</span>
                    sliced_tokens <span class="token operator">=</span> tokens<span class="token punctuation">[</span>last_slice<span class="token punctuation">:</span>current_slice<span class="token punctuation">]</span>
                    start_timestamp_pos <span class="token operator">=</span> <span class="token punctuation">(</span>
                        sliced_tokens<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> tokenizer<span class="token punctuation">.</span>timestamp_begin
                    <span class="token punctuation">)</span>
                    end_timestamp_pos <span class="token operator">=</span> <span class="token punctuation">(</span>
                        sliced_tokens<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> tokenizer<span class="token punctuation">.</span>timestamp_begin
                    <span class="token punctuation">)</span>
                    current_segments<span class="token punctuation">.</span>append<span class="token punctuation">(</span>
                        new_segment<span class="token punctuation">(</span>
                            start<span class="token operator">=</span>time_offset <span class="token operator">+</span> start_timestamp_pos <span class="token operator">*</span> time_precision<span class="token punctuation">,</span>
                            end<span class="token operator">=</span>time_offset <span class="token operator">+</span> end_timestamp_pos <span class="token operator">*</span> time_precision<span class="token punctuation">,</span>
                            tokens<span class="token operator">=</span>sliced_tokens<span class="token punctuation">,</span>
                            result<span class="token operator">=</span>result<span class="token punctuation">,</span>
                        <span class="token punctuation">)</span>
                    <span class="token punctuation">)</span>
                    last_slice <span class="token operator">=</span> current_slice

                <span class="token keyword">if</span> single_timestamp_ending<span class="token punctuation">:</span>
                    <span class="token comment"># single timestamp at the end means no speech after the last timestamp.</span>
                    seek <span class="token operator">+=</span> segment_size
                <span class="token keyword">else</span><span class="token punctuation">:</span>
                    <span class="token comment"># otherwise, ignore the unfinished segment and seek to the last timestamp</span>
                    last_timestamp_pos <span class="token operator">=</span> <span class="token punctuation">(</span>
                        tokens<span class="token punctuation">[</span>last_slice <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> tokenizer<span class="token punctuation">.</span>timestamp_begin
                    <span class="token punctuation">)</span>
                    seek <span class="token operator">+=</span> last_timestamp_pos <span class="token operator">*</span> input_stride
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                duration <span class="token operator">=</span> segment_duration
                timestamps <span class="token operator">=</span> tokens<span class="token punctuation">[</span>timestamp_tokens<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
                <span class="token keyword">if</span> <span class="token punctuation">(</span>
                    <span class="token builtin">len</span><span class="token punctuation">(</span>timestamps<span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">0</span>
                    <span class="token keyword">and</span> timestamps<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">!=</span> tokenizer<span class="token punctuation">.</span>timestamp_begin
                <span class="token punctuation">)</span><span class="token punctuation">:</span>
                    <span class="token comment"># no consecutive timestamps but it has a timestamp; use the last one.</span>
                    last_timestamp_pos <span class="token operator">=</span> <span class="token punctuation">(</span>
                        timestamps<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> tokenizer<span class="token punctuation">.</span>timestamp_begin
                    <span class="token punctuation">)</span>
                    duration <span class="token operator">=</span> last_timestamp_pos <span class="token operator">*</span> time_precision

                current_segments<span class="token punctuation">.</span>append<span class="token punctuation">(</span>
                    new_segment<span class="token punctuation">(</span>
                        start<span class="token operator">=</span>time_offset<span class="token punctuation">,</span>
                        end<span class="token operator">=</span>time_offset <span class="token operator">+</span> duration<span class="token punctuation">,</span>
                        tokens<span class="token operator">=</span>tokens<span class="token punctuation">,</span>
                        result<span class="token operator">=</span>result<span class="token punctuation">,</span>
                    <span class="token punctuation">)</span>
                <span class="token punctuation">)</span>
                seek <span class="token operator">+=</span> segment_size

            <span class="token keyword">if</span> word_timestamps<span class="token punctuation">:</span>
                add_word_timestamps<span class="token punctuation">(</span>
                    segments<span class="token operator">=</span>current_segments<span class="token punctuation">,</span>
                    model<span class="token operator">=</span>model<span class="token punctuation">,</span>
                    tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">,</span>
                    mel<span class="token operator">=</span>mel_segment<span class="token punctuation">,</span>
                    num_frames<span class="token operator">=</span>segment_size<span class="token punctuation">,</span>
                    prepend_punctuations<span class="token operator">=</span>prepend_punctuations<span class="token punctuation">,</span>
                    append_punctuations<span class="token operator">=</span>append_punctuations<span class="token punctuation">,</span>
                    last_speech_timestamp<span class="token operator">=</span>last_speech_timestamp<span class="token punctuation">,</span>
                <span class="token punctuation">)</span>

                <span class="token keyword">if</span> <span class="token keyword">not</span> single_timestamp_ending<span class="token punctuation">:</span>
                    last_word_end <span class="token operator">=</span> get_end<span class="token punctuation">(</span>current_segments<span class="token punctuation">)</span>
                    <span class="token keyword">if</span> last_word_end <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span> <span class="token keyword">and</span> last_word_end <span class="token operator">&gt;</span> time_offset<span class="token punctuation">:</span>
                        seek <span class="token operator">=</span> <span class="token builtin">round</span><span class="token punctuation">(</span>last_word_end <span class="token operator">*</span> FRAMES_PER_SECOND<span class="token punctuation">)</span>

                <span class="token comment"># skip silence before possible hallucinations</span>
                <span class="token keyword">if</span> hallucination_silence_threshold <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
                    threshold <span class="token operator">=</span> hallucination_silence_threshold
                    <span class="token keyword">if</span> <span class="token keyword">not</span> single_timestamp_ending<span class="token punctuation">:</span>
                        last_word_end <span class="token operator">=</span> get_end<span class="token punctuation">(</span>current_segments<span class="token punctuation">)</span>
                        <span class="token keyword">if</span> last_word_end <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span> <span class="token keyword">and</span> last_word_end <span class="token operator">&gt;</span> time_offset<span class="token punctuation">:</span>
                            remaining_duration <span class="token operator">=</span> window_end_time <span class="token operator">-</span> last_word_end
                            <span class="token keyword">if</span> remaining_duration <span class="token operator">&gt;</span> threshold<span class="token punctuation">:</span>
                                seek <span class="token operator">=</span> <span class="token builtin">round</span><span class="token punctuation">(</span>last_word_end <span class="token operator">*</span> FRAMES_PER_SECOND<span class="token punctuation">)</span>
                            <span class="token keyword">else</span><span class="token punctuation">:</span>
                                seek <span class="token operator">=</span> previous_seek <span class="token operator">+</span> segment_size

                    <span class="token comment"># if first segment might be a hallucination, skip leading silence</span>
                    first_segment <span class="token operator">=</span> next_words_segment<span class="token punctuation">(</span>current_segments<span class="token punctuation">)</span>
                    <span class="token keyword">if</span> first_segment <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span> <span class="token keyword">and</span> is_segment_anomaly<span class="token punctuation">(</span>first_segment<span class="token punctuation">)</span><span class="token punctuation">:</span>
                        gap <span class="token operator">=</span> first_segment<span class="token punctuation">[</span><span class="token string">"start"</span><span class="token punctuation">]</span> <span class="token operator">-</span> time_offset
                        <span class="token keyword">if</span> gap <span class="token operator">&gt;</span> threshold<span class="token punctuation">:</span>
                            seek <span class="token operator">=</span> previous_seek <span class="token operator">+</span> <span class="token builtin">round</span><span class="token punctuation">(</span>gap <span class="token operator">*</span> FRAMES_PER_SECOND<span class="token punctuation">)</span>
                            <span class="token keyword">continue</span>

                    <span class="token comment"># skip silence before any possible hallucination that is surrounded</span>
                    <span class="token comment"># by silence or more hallucinations</span>
                    hal_last_end <span class="token operator">=</span> last_speech_timestamp
                    <span class="token keyword">for</span> si <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>current_segments<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                        segment <span class="token operator">=</span> current_segments<span class="token punctuation">[</span>si<span class="token punctuation">]</span>
                        <span class="token keyword">if</span> <span class="token keyword">not</span> segment<span class="token punctuation">[</span><span class="token string">"words"</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
                            <span class="token keyword">continue</span>
                        <span class="token keyword">if</span> is_segment_anomaly<span class="token punctuation">(</span>segment<span class="token punctuation">)</span><span class="token punctuation">:</span>
                            next_segment <span class="token operator">=</span> next_words_segment<span class="token punctuation">(</span>
                                current_segments<span class="token punctuation">[</span>si <span class="token operator">+</span> <span class="token number">1</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
                            <span class="token punctuation">)</span>
                            <span class="token keyword">if</span> next_segment <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
                                hal_next_start <span class="token operator">=</span> next_segment<span class="token punctuation">[</span><span class="token string">"words"</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">"start"</span><span class="token punctuation">]</span>
                            <span class="token keyword">else</span><span class="token punctuation">:</span>
                                hal_next_start <span class="token operator">=</span> time_offset <span class="token operator">+</span> segment_duration
                            silence_before <span class="token operator">=</span> <span class="token punctuation">(</span>
                                segment<span class="token punctuation">[</span><span class="token string">"start"</span><span class="token punctuation">]</span> <span class="token operator">-</span> hal_last_end <span class="token operator">&gt;</span> threshold
                                <span class="token keyword">or</span> segment<span class="token punctuation">[</span><span class="token string">"start"</span><span class="token punctuation">]</span> <span class="token operator">&lt;</span> threshold
                                <span class="token keyword">or</span> segment<span class="token punctuation">[</span><span class="token string">"start"</span><span class="token punctuation">]</span> <span class="token operator">-</span> time_offset <span class="token operator">&lt;</span> <span class="token number">2.0</span>
                            <span class="token punctuation">)</span>
                            silence_after <span class="token operator">=</span> <span class="token punctuation">(</span>
                                hal_next_start <span class="token operator">-</span> segment<span class="token punctuation">[</span><span class="token string">"end"</span><span class="token punctuation">]</span> <span class="token operator">&gt;</span> threshold
                                <span class="token keyword">or</span> is_segment_anomaly<span class="token punctuation">(</span>next_segment<span class="token punctuation">)</span>
                                <span class="token keyword">or</span> window_end_time <span class="token operator">-</span> segment<span class="token punctuation">[</span><span class="token string">"end"</span><span class="token punctuation">]</span> <span class="token operator">&lt;</span> <span class="token number">2.0</span>
                            <span class="token punctuation">)</span>
                            <span class="token keyword">if</span> silence_before <span class="token keyword">and</span> silence_after<span class="token punctuation">:</span>
                                seek <span class="token operator">=</span> <span class="token builtin">round</span><span class="token punctuation">(</span>
                                    <span class="token builtin">max</span><span class="token punctuation">(</span>time_offset <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> segment<span class="token punctuation">[</span><span class="token string">"start"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
                                    <span class="token operator">*</span> FRAMES_PER_SECOND
                                <span class="token punctuation">)</span>
                                <span class="token keyword">if</span> content_duration <span class="token operator">-</span> segment<span class="token punctuation">[</span><span class="token string">"end"</span><span class="token punctuation">]</span> <span class="token operator">&lt;</span> threshold<span class="token punctuation">:</span>
                                    seek <span class="token operator">=</span> content_frames
                                current_segments<span class="token punctuation">[</span>si<span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
                                <span class="token keyword">break</span>
                        hal_last_end <span class="token operator">=</span> segment<span class="token punctuation">[</span><span class="token string">"end"</span><span class="token punctuation">]</span>

                last_word_end <span class="token operator">=</span> get_end<span class="token punctuation">(</span>current_segments<span class="token punctuation">)</span>
                <span class="token keyword">if</span> last_word_end <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
                    last_speech_timestamp <span class="token operator">=</span> last_word_end

            <span class="token keyword">if</span> verbose<span class="token punctuation">:</span>
                <span class="token keyword">for</span> segment <span class="token keyword">in</span> current_segments<span class="token punctuation">:</span>
                    start<span class="token punctuation">,</span> end<span class="token punctuation">,</span> text <span class="token operator">=</span> segment<span class="token punctuation">[</span><span class="token string">"start"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> segment<span class="token punctuation">[</span><span class="token string">"end"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> segment<span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span>
                    line <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f"[</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>format_timestamp<span class="token punctuation">(</span>start<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string"> --&gt; </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>format_timestamp<span class="token punctuation">(</span>end<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">] </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>text<span class="token punctuation">}</span></span><span class="token string">"</span></span>
                    <span class="token keyword">print</span><span class="token punctuation">(</span>make_safe<span class="token punctuation">(</span>line<span class="token punctuation">)</span><span class="token punctuation">)</span>

            <span class="token comment"># if a segment is instantaneous or does not contain text, clear it</span>
            <span class="token keyword">for</span> i<span class="token punctuation">,</span> segment <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>current_segments<span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token keyword">if</span> segment<span class="token punctuation">[</span><span class="token string">"start"</span><span class="token punctuation">]</span> <span class="token operator">==</span> segment<span class="token punctuation">[</span><span class="token string">"end"</span><span class="token punctuation">]</span> <span class="token keyword">or</span> segment<span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>strip<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token string">""</span><span class="token punctuation">:</span>
                    segment<span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">""</span>
                    segment<span class="token punctuation">[</span><span class="token string">"tokens"</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
                    segment<span class="token punctuation">[</span><span class="token string">"words"</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

            all_segments<span class="token punctuation">.</span>extend<span class="token punctuation">(</span>
                <span class="token punctuation">[</span>
                    <span class="token punctuation">{<!-- --></span><span class="token string">"id"</span><span class="token punctuation">:</span> i<span class="token punctuation">,</span> <span class="token operator">**</span>segment<span class="token punctuation">}</span>
                    <span class="token keyword">for</span> i<span class="token punctuation">,</span> segment <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>
                        current_segments<span class="token punctuation">,</span> start<span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>all_segments<span class="token punctuation">)</span>
                    <span class="token punctuation">)</span>
                <span class="token punctuation">]</span>
            <span class="token punctuation">)</span>
            all_tokens<span class="token punctuation">.</span>extend<span class="token punctuation">(</span>
                <span class="token punctuation">[</span>token <span class="token keyword">for</span> segment <span class="token keyword">in</span> current_segments <span class="token keyword">for</span> token <span class="token keyword">in</span> segment<span class="token punctuation">[</span><span class="token string">"tokens"</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
            <span class="token punctuation">)</span>

            <span class="token keyword">if</span> <span class="token keyword">not</span> condition_on_previous_text <span class="token keyword">or</span> result<span class="token punctuation">.</span>temperature <span class="token operator">&gt;</span> <span class="token number">0.5</span><span class="token punctuation">:</span>
                <span class="token comment"># do not feed the prompt tokens if a high temperature was used</span>
                prompt_reset_since <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>all_tokens<span class="token punctuation">)</span>

            <span class="token comment"># update progress bar</span>
            pbar<span class="token punctuation">.</span>update<span class="token punctuation">(</span><span class="token builtin">min</span><span class="token punctuation">(</span>content_frames<span class="token punctuation">,</span> seek<span class="token punctuation">)</span> <span class="token operator">-</span> previous_seek<span class="token punctuation">)</span>

    <span class="token keyword">return</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>
        text<span class="token operator">=</span>tokenizer<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>all_tokens<span class="token punctuation">[</span><span class="token builtin">len</span><span class="token punctuation">(</span>initial_prompt_tokens<span class="token punctuation">)</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        segments<span class="token operator">=</span>all_segments<span class="token punctuation">,</span>
        language<span class="token operator">=</span>language<span class="token punctuation">,</span>
    <span class="token punctuation">)</span>
</code></pre> 
<h2><a id="_521"></a>函数解析</h2> 
<h3><a id="1_transcriptpy_522"></a>1. transcript.py</h3> 
<p><strong>kimichat：</strong><br> 这段代码是一个Python脚本，它使用了Whisper模型来进行音频转录。Whisper是一个由OpenAI开发的大型语音识别模型，能够处理多种语言和任务。以下是代码的主要功能和组件的逐行解释：</p> 
<p>1-7行：导入了所需的库和模块，包括argparse（命令行参数解析）、os（操作系统交互）、traceback（错误跟踪）、warnings（警告信息）、numpy（科学计算）、torch（PyTorch深度学习库）、tqdm（进度条显示）。</p> 
<p>9-14行：定义了一些常量和辅助函数，如<code>FRAMES_PER_SECOND</code>（每秒帧数）、<code>HOP_LENGTH</code>（帧跳跃长度）、<code>N_FRAMES</code>（每个音频段的帧数）、<code>N_SAMPLES</code>（音频样本数）、<code>SAMPLE_RATE</code>（采样率）等。</p> 
<p>16-25行：定义了<code>log_mel_spectrogram</code>函数，用于将音频信号转换为Mel频率倒谱系数，这是语音识别中常用的特征表示方法。</p> 
<p>27-36行：定义了<code>pad_or_trim</code>函数，用于对音频信号进行填充或裁剪，以匹配模型所需的输入长度。</p> 
<p><strong>38-55行：定义了<code>transcribe</code>函数，它是脚本的核心，负责加载音频、预处理、使用Whisper模型进行转录，并返回转录结果。它接受多种参数，如<code>verbose</code>（是否显示详细信息）、<code>temperature</code>（采样温度）、<code>compression_ratio_threshold</code>（压缩比阈值）等，这些参数影响转录过程和结果。<br> 57-82行：在<code>transcribe</code>函数中，首先检查设备类型和数据类型（是否使用半精度浮点数），然后对音频进行预处理，包括检测语言、加载tokenizer、处理音频剪辑时间戳等。<br> 84-131行：实现了一个循环，用于处理音频文件的每个剪辑段，进行转录，并更新进度条。<br> 133-174行：在<code>transcribe</code>函数中，还实现了对转录结果的处理，包括添加单词时间戳、处理可能的幻觉（hallucination）和沉默段。</strong></p> 
<p><strong>176-198行：定义了<code>cli</code>函数，它使用<code>argparse</code>解析命令行参数，并调用<code>transcribe</code>函数来处理音频文件。</strong></p> 
<p>200-206行：在<code>cli</code>函数中，根据用户输入的参数，加载了Whisper模型，并设置了输出格式和目录。</p> 
<p>208-213行：实现了对每个音频文件的循环处理，调用<code>transcribe</code>函数进行转录，并将结果写入到文件中。</p> 
<p>215-218行：最后，如果这个脚本作为主程序运行，它将执行<code>cli</code>函数，开始命令行界面。</p> 
<p>整体来看，这个脚本提供了一个完整的命令行界面，允许用户指定音频文件、模型、输出格式和其他参数，以执行音频转录任务。它使用了Whisper模型的强大功能，能够处理多种语言和语音识别任务。</p> 
<h3><a id="2_tokenizerpy_550"></a>2. tokenizer.py</h3> 
<p>根据缩写指定要识别的语言<br> <img src="https://images2.imgbox.com/9e/31/86CbyJwe_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="3_audiopy_553"></a>3. audio.py</h3> 
<p>处理音频用到了ffmpeg命令行工具，在运行环境要安装上ffmpeg命令行工具。<br> <img src="https://images2.imgbox.com/7d/52/VxMXr9Gs_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="4____init__py_557"></a>4. __ init__.py</h3> 
<p>指定要调用的模型， 可以把模型先下载到本地，直接指定模型路径加载本地模型。<br> grep -H “example” * 匹配内容的同时输出被匹配的文件名。<br> <img src="https://images2.imgbox.com/60/71/QIJljxym_o.jpg" alt="在这里插入图片描述"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/6019bf559ce166c185dda881af71df80/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【爱上C&#43;&#43;】详解类与对象1</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/2317a248128faa658f07e72f2c5b7930/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">快速上手文心一言指令</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>