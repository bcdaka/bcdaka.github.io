<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>手把手教你用LoRA训练自己的Stable Diffusion模型 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/b315e8317c4264316beb9fec74138395/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="手把手教你用LoRA训练自己的Stable Diffusion模型">
  <meta property="og:description" content="目录
写在前面
一、准备数据
二、数据打标签
三、执行训练
四、执行推理
1.LoRA推理
2.全参数推理
写在前面 Stable Diffusion大家已经很熟悉了，那么如何训练自己的sd模型呢，今天我就介绍一下用LoRA训练sd的方法。
建议先看一下这两篇文章，了解一些前置知识：
手把手教你在linux中部署stable-diffusion-webui
如何训练一个大模型：LoRA篇
我们以Chilloutmix为例，Chilloutmix可以生成好看的小姐姐。为了实验LoRA的能力，我们用小哥哥的图片对它进行微调，看效果如何。
一、准备数据 从网上找一些小帅的图片，需要脸部清晰的、多角度的、正脸的、侧脸的、最好是背景干净的、各种表情的，这样增加训练集的多样性，提高模型的泛化能力。
素材可以少（一般几十张就不少了，太多了也会过拟合），但是质量一定要高。 背景最好是纯色，想训练什么就突出什么，对于我们的任务，需要选取人脸为重点的图片。
搜集好训练用的图像后，需要进行大小的规范处理，需要是64的倍数。一般都处理为512*512，也可以是768*768，不建议超过1024，尺寸越大则越吃显存。
推荐一个批量处理图像尺寸的网站挺好用的：https://www.birme.net/ 处理后的图片长这样：
二、数据打标签 其实我们要训练的是ControlNet，现在图片有了，还差图片的描述或者叫标签。我们不需要自己手动给每张图片打标签，sd-webui有现成的工具（DeepBooru）生成图片的标签。
在sd-webui中进行如上操作，在3填写输入图片的目录，4填写输出目录，处理之后原图片和标签文件txt都会放在输出目录
txt中的内容长这样，都是一个一个的标签：
接下来我们要检查每张图片的标签，这里有两个简单的原则：
1.通用的特征标签需要去掉，比如人物的眼睛、眉毛、鼻子、头发长度等代表人物本身的属性。凡是绑定在人物身上的，就要把它们删除。再比如出图只要黑色头发，那训练数据都喂黑色头发，并且删掉类似“black_hair”的标签。
2.留下非通用的标签，比如不是每张训练数据都是微笑的，所以对于微笑的数据应该有“smile”标签；不是所有的数据背景都是白色，就要保留“white backgroud”。
具体保留或者增加什么标签其实没有硬性的规定，还是要根据具体情况反复尝试。
sd-webui是有打标签的插件的，但是我更喜欢一款小工具，方便多人使用，BooruDatasetTagManager，地址：https://pan.baidu.com/s/1Ff7nkwf95AziCcZWTofIzg?pwd=jfoe 数据和标签准备好后放在一个自定义的目录中待用，有一点需要注意，文件名的格式是数字_字母，前面的数字是每次训练过程中网络训练单张图片的次数，比如10_asianman。这个目录命名很重要，一定不要写错！！！
三、执行训练 LoRA训练我们使用kohya，kohya是日本人开发的，所以会经常出现日文，凑活这看吧。
1.下载kohya，别忘了下载sd-scripts目录中的项目：kohya-ss (Kohya S.) · GitHub，下载后执行:
pip install -r requirements.txt 2.因为我们是对Chilloutmix进行微调，所以先在这里下载Chilloutmix，并放在model目录下。
3.启动kohya:
python kohya_gui.py --listen 0.0.0.0 --server_port 12348 --inbrowser 4.打开地址http://[ip]:12348/ ，并填写配置信息：
同时Parameters菜单中还有一些高级设置，比如batch size、train steps、LoRA的秩、Alpha等：
一些注意： 1.训练时的总epoch数是算出来的，上面的Epoch好像没有用，计算公式是：
Max train steps * Train batch size / (数据总数 * 训练单张图片的次数)，这算法很奇怪，他把Train batch size当做了batch size per device">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-05-20T09:23:10+08:00">
    <meta property="article:modified_time" content="2024-05-20T09:23:10+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">手把手教你用LoRA训练自己的Stable Diffusion模型</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p id="main-toc"><strong>目录</strong></p> 
<p id="%E5%86%99%E5%9C%A8%E5%89%8D%E9%9D%A2-toc" style="margin-left:0px;"><a href="#%E5%86%99%E5%9C%A8%E5%89%8D%E9%9D%A2" rel="nofollow">写在前面</a></p> 
<p id="%E4%B8%80%E3%80%81%E5%87%86%E5%A4%87%E6%95%B0%E6%8D%AE-toc" style="margin-left:0px;"><a href="#%E4%B8%80%E3%80%81%E5%87%86%E5%A4%87%E6%95%B0%E6%8D%AE" rel="nofollow">一、准备数据</a></p> 
<p id="%E4%BA%8C%E3%80%81%E6%95%B0%E6%8D%AE%E6%89%93%E6%A0%87%E7%AD%BE-toc" style="margin-left:0px;"><a href="#%E4%BA%8C%E3%80%81%E6%95%B0%E6%8D%AE%E6%89%93%E6%A0%87%E7%AD%BE" rel="nofollow">二、数据打标签</a></p> 
<p id="%E4%B8%89%E3%80%81%E6%89%A7%E8%A1%8C%E8%AE%AD%E7%BB%83-toc" style="margin-left:0px;"><a href="#%E4%B8%89%E3%80%81%E6%89%A7%E8%A1%8C%E8%AE%AD%E7%BB%83" rel="nofollow">三、执行训练</a></p> 
<p id="%E5%9B%9B%E3%80%81%E6%89%A7%E8%A1%8C%E6%8E%A8%E7%90%86-toc" style="margin-left:0px;"><a href="#%E5%9B%9B%E3%80%81%E6%89%A7%E8%A1%8C%E6%8E%A8%E7%90%86" rel="nofollow">四、执行推理</a></p> 
<p id="1.LoRA%E6%8E%A8%E7%90%86-toc" style="margin-left:40px;"><a href="#1.LoRA%E6%8E%A8%E7%90%86" rel="nofollow">1.LoRA推理</a></p> 
<p id="2.%E5%85%A8%E5%8F%82%E6%95%B0%E6%8E%A8%E7%90%86-toc" style="margin-left:40px;"><a href="#2.%E5%85%A8%E5%8F%82%E6%95%B0%E6%8E%A8%E7%90%86" rel="nofollow">2.全参数推理</a></p> 
<p></p> 
<h2 id="%E5%86%99%E5%9C%A8%E5%89%8D%E9%9D%A2">写在前面</h2> 
<p>        Stable Diffusion大家已经很熟悉了，那么如何训练自己的sd模型呢，今天我就介绍一下用LoRA训练sd的方法。</p> 
<p>        建议先看一下这两篇文章，了解一些前置知识：</p> 
<p>        <a href="https://blog.csdn.net/xian0710830114/article/details/130124332" title="手把手教你在linux中部署stable-diffusion-webui">手把手教你在linux中部署stable-diffusion-webui</a></p> 
<p>        <a href="https://blog.csdn.net/xian0710830114/article/details/138710952" title="如何训练一个大模型：LoRA篇">如何训练一个大模型：LoRA篇</a></p> 
<p>        我们以Chilloutmix为例，Chilloutmix可以生成好看的小姐姐。为了实验LoRA的能力，我们用小哥哥的图片对它进行微调，看效果如何。</p> 
<p class="img-center"><img alt="" height="476" src="https://images2.imgbox.com/10/c9/jGKqikA1_o.png" width="954"></p> 
<h2 id="%E4%B8%80%E3%80%81%E5%87%86%E5%A4%87%E6%95%B0%E6%8D%AE">一、准备数据</h2> 
<p>        从网上找一些小帅的图片，需要脸部清晰的、多角度的、正脸的、侧脸的、最好是背景干净的、各种表情的，这样增加训练集的多样性，提高模型的泛化能力。</p> 
<p>        素材可以少（一般几十张就不少了，太多了也会过拟合），但是质量一定要高。 </p> 
<p>        背景最好是纯色，想训练什么就突出什么，对于我们的任务，需要选取人脸为重点的图片。</p> 
<p>        搜集好训练用的图像后，需要进行大小的规范处理，需要是64的倍数。一般都处理为512*512，也可以是768*768，不建议超过1024，尺寸越大则越吃显存。</p> 
<p>        推荐一个批量处理图像尺寸的网站挺好用的：https://www.birme.net/ </p> 
<p>        处理后的图片长这样：</p> 
<p><img alt="" height="840" src="https://images2.imgbox.com/8c/d5/gy27tFKJ_o.png" width="1200"></p> 
<h2 id="%E4%BA%8C%E3%80%81%E6%95%B0%E6%8D%AE%E6%89%93%E6%A0%87%E7%AD%BE">二、数据打标签</h2> 
<p>        其实我们要训练的是ControlNet，现在图片有了，还差图片的描述或者叫标签。我们不需要自己手动给每张图片打标签，sd-webui有现成的工具（DeepBooru）生成图片的标签。</p> 
<p><img alt="" height="518" src="https://images2.imgbox.com/28/bf/XF6l3J8S_o.png" width="700"></p> 
<p>        在sd-webui中进行如上操作，在3填写输入图片的目录，4填写输出目录，处理之后原图片和标签文件txt都会放在输出目录</p> 
<p class="img-center"><img alt="" height="168" src="https://images2.imgbox.com/79/13/HrEaHFwq_o.png" width="179"></p> 
<p>        txt中的内容长这样，都是一个一个的标签：</p> 
<p class="img-center"><img alt="" height="117" src="https://images2.imgbox.com/fe/cc/6RSO2Uhv_o.png" width="540"></p> 
<p>        接下来我们要检查每张图片的标签，这里有两个简单的原则：</p> 
<p>        1.通用的特征标签需要去掉，比如人物的眼睛、眉毛、鼻子、头发长度等代表人物本身的属性。凡是绑定在人物身上的，就要把它们删除。再比如出图只要黑色头发，那训练数据都喂黑色头发，并且删掉类似“black_hair”的标签。</p> 
<p>        2.留下非通用的标签，比如不是每张训练数据都是微笑的，所以对于微笑的数据应该有“smile”标签；不是所有的数据背景都是白色，就要保留“white backgroud”。</p> 
<p>        具体保留或者增加什么标签其实没有硬性的规定，还是要根据具体情况反复尝试。</p> 
<p>        sd-webui是有打标签的插件的，但是我更喜欢一款小工具，方便多人使用，BooruDatasetTagManager，地址：https://pan.baidu.com/s/1Ff7nkwf95AziCcZWTofIzg?pwd=jfoe </p> 
<p class="img-center"><img alt="" height="517" src="https://images2.imgbox.com/05/ad/8c1CdXNj_o.png" width="1147"></p> 
<p>        数据和标签准备好后放在一个自定义的目录中待用，有一点需要注意，文件名的格式是<strong>数字_字母</strong>，前面的数字是每次训练过程中网络训练单张图片的<strong>次数，</strong>比如10_asianman<strong>。</strong>这个目录命名很重要，一定不要写错！！！</p> 
<h2 id="%E4%B8%89%E3%80%81%E6%89%A7%E8%A1%8C%E8%AE%AD%E7%BB%83">三、执行训练</h2> 
<p>        LoRA训练我们使用kohya，kohya是日本人开发的，所以会经常出现日文，凑活这看吧。</p> 
<p>        1.下载kohya，别忘了下载sd-scripts目录中的项目：<a href="https://github.com/kohya-ss/" title="kohya-ss (Kohya S.) · GitHub">kohya-ss (Kohya S.) · GitHub</a>，下载后执行:</p> 
<pre><code>pip install -r requirements.txt</code></pre> 
<p>        2.因为我们是对Chilloutmix进行微调，所以先在这里下载Chilloutmix，并放在model目录下。</p> 
<p>        3.启动kohya:</p> 
<pre><code>python kohya_gui.py --listen 0.0.0.0 --server_port 12348 --inbrowser</code></pre> 
<p>        4.打开地址<a href="http://10.20.26.29:12348/" rel="nofollow" title="http://[ip]:12348/">http://[ip]:12348/</a> ，并填写配置信息：</p> 
<p><img alt="" height="917" src="https://images2.imgbox.com/04/54/UyPH7fdM_o.png" width="981"></p> 
<p>同时Parameters菜单中还有一些高级设置，比如batch size、train steps、LoRA的秩、Alpha等：</p> 
<p class="img-center"><img alt="" height="160" src="https://images2.imgbox.com/48/de/wce6AAkK_o.png" width="915"></p> 
<p class="img-center"><img alt="" height="96" src="https://images2.imgbox.com/9e/f3/ewTiGlD4_o.png" width="895"></p> 
<p>       <strong> 一些注意： </strong>       </p> 
<p>        1.训练时的总epoch数是算出来的，上面的Epoch好像没有用，计算公式是：</p> 
<p>Max train steps * Train batch size / (数据总数 * 训练单张图片的次数)，这算法很奇怪，他把Train batch size当做了batch size per device</p> 
<p class="img-center"><img alt="" height="128" src="https://images2.imgbox.com/24/d7/Jvhdaxa9_o.png" width="462"></p> 
<p>        2.LoRA的秩用8就可以了，Alpha训练人物一般都设32，64都可以；训练风格可以用到128。</p> 
<p>        3. 我看到有的文章说不能直接用safetensors文件直接训练，必须还要有config.json，但是我没有遇到这种情况。如果遇到了可以下载<a class="link-info" href="https://pan.baidu.com/s/1fD1yPD4eyIL2dj2CSHeuSg?pwd=fts2" rel="nofollow" title="这个">这个</a>，放在项目根目录的openai/clip-vit-large-patch14 和 laion/CLIP-ViT-bigG-14-laion2B-39B-b160k</p> 
<p><strong>        </strong>4.如果要全参数训练只需选择Dreambooth菜单，其它使用方式和LoRA基本相同：</p> 
<p class="img-center"><img alt="" height="912" src="https://images2.imgbox.com/42/e4/rSXXm3Dq_o.png" width="972"></p> 
<p>        5.如果报这个错的话：'FieldInfo' object has no attribute 'required'. Did you mean: 'is_required'?，是一些库的版本冲突了，可以试试如下命令：</p> 
<pre><code>pip install gradio==3.48.0
pip install pydantic==1.10.13 pydantic_core==2.14.6
pip install transformers==4.38.0
pip install accelerate==0.25.0
pip install torch==2.1.1
pip install xformers==0.0.23</code></pre> 
<h2 id="%E5%9B%9B%E3%80%81%E6%89%A7%E8%A1%8C%E6%8E%A8%E7%90%86">四、执行推理</h2> 
<p>        训练成功后模型会存在输出目录，比如叫做models/last-000007.safetensors。</p> 
<h3 id="1.LoRA%E6%8E%A8%E7%90%86">1.LoRA推理</h3> 
<p><strong>（1）安装additional-networks</strong></p> 
<p>        如果sd-weiui的“text2img”和“img2text”中已经有Additional Networks菜单，则之间跳过该步骤。</p> 
<p class="img-center"><img alt="" height="380" src="https://images2.imgbox.com/cd/b6/rN297cQQ_o.png" width="933"></p> 
<p>        安装additional-networks插件，有两种方式：<br>         a.在“Extensions-URL for extension's git repository”输入https://github.com/kohya-ss/sd-webui-additional-networks就可以安装了。</p> 
<p class="img-center"><img alt="" height="324" src="https://images2.imgbox.com/2e/bb/0dTJ4pQl_o.png" width="1021"></p> 
<p>        b.如果网络不允许的话，就自行下载压缩包解压放到SD的extensions目录下。</p> 
<p>        安装完之后一定要重启sd进程！之后我们可以看到选项卡上多了一个Additional Network选项。</p> 
<p>（2）将Chilloutmix基础模型放在models/Stable-diffusion目录</p> 
<p>（3）将训练完的LoRA模型放在sd-webui的extensions/sd-webui-additional-networks/models/lora目录</p> 
<p>（4）使用基础模型重绘一张图片看看，都是小姐姐：<img alt="" height="875" src="https://images2.imgbox.com/21/a6/AKFTh9Zp_o.png" width="1200"></p> 
<p>（5）使用LORA，再生成看看：</p> 
<p><img alt="" height="457" src="https://images2.imgbox.com/4a/b4/dsOF2X9H_o.png" width="805"></p> 
<p><img alt="" height="886" src="https://images2.imgbox.com/0b/8b/DG6HRalp_o.png" width="1200"></p> 
<p>        emmm，已经有很强的男性特征，证明LoRA生效了。</p> 
<h3 id="2.%E5%85%A8%E5%8F%82%E6%95%B0%E6%8E%A8%E7%90%86">2.全参数推理</h3> 
<p>        如果使用全参数训练的模型，模型结果比较大，有几个g。使用更简单了，放在models/Stable-diffusion中，直接选择这个模型就可以了。</p> 
<p class="img-center"><img alt="" height="647" src="https://images2.imgbox.com/01/ae/otIN1vpS_o.png" width="764"></p> 
<p>        用LoRA训练自己的SD模型就介绍到这里，关注不迷路(#^.^#)</p> 
<p style="text-align:center;"><strong>关注订阅号了解更多精品文章</strong></p> 
<p style="text-align:center;"><img alt="c168ea67aa0d45e4a8db954fd4eaa145.jpeg" src="https://images2.imgbox.com/62/ac/8x6Prmy7_o.jpg"><br><strong>交流探讨、商务合作请加微信</strong></p> 
<p style="text-align:center;"><img alt="ddac0a92f7884455ae19fa73f5bf6dbd.jpeg" src="https://images2.imgbox.com/64/bf/Xc5humeo_o.jpg"></p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/c768ffe408bf8d50ae645addaf5163b2/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">基于Doris的日志存储分析平台（同步Kafka日志数据）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/490dec8b5497e2b591719de67bf8238b/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">如何在Python中从路径中获取不带扩展名的文件名？</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>