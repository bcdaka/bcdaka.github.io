<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Kafka入门使用教程 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/50536635184398513907e5f07bf821d3/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="Kafka入门使用教程">
  <meta property="og:description" content="1. 前言 1.1. 什么是消息队列 消息队列（MQ）是消息传递中间件解决方案的一个组件，旨在支持独立的应用和服务之间的信息交换。 消息队列按发送顺序存储“消息”（由应用所创建、供其他应用使用的数据包），直到使用方应用能够处理它们为止。 这些消息安全地等待接收方应用做好准备，因此，即使网络或接收方应用出现问题，消息队列中的消息也不会丢失。
1.2. 为什么用消息队列 1.2.1. 解耦 生产者（客户端）发送消息到MQ中去，接受者（服务端）处理消息，需要消费的系统直接去MQ取消息进行消费即可而不需要和其他系统有耦合。
例如订单服务在电商订单创建后，发送扣减可用库存消息到MQ，库存系统在接受到消息后处理扣减可用库存。后续如果还需要扩展，通知其他第三方系统，只需要新增一个消费者去接收扣减信息处理即可。
1.2.2. 异步 将用户的请求数据存储到MQ之后就立即返回结果。随后，系统再对消息进行消费。
例如短信验证码业务，登录服务在接受到用户手机号之后，将手机号发送到MQ，短信服务接受消息后进行短信发送。登录服务不需要等待发送验证码完成，即可继续后续处理。
1.2.3. 削峰 先将短时间高并发产生的事务消息存储在MQ中，然后后端服务再慢慢根据自己的能力去消费这些消息。
例如电商大促时，可在订单服务前架设一层订单接收服务，只负责接收订单并将订单信息发送到MQ，订单服务根据自身消费能力来接收订单信息并创建订单。 这样就避免订单服务因过高流量而宕机。
1.3. Kafka Kafka是最初由Linkedin公司开发，是一个分布式、支持分区的（partition）、多副本的（replica），基于zookeeper协调的分布式消息系统，它的最大的特性就是可以实时的处理大量数据以满足各种需求场景：比如基于hadoop的批处理系统、低延迟的实时系统、storm/Spark流式处理引擎，web/nginx日志、访问日志，消息服务等等，用scala语言编写，Linkedin于2010年贡献给了Apache基金会并成为顶级开源项目。
2. 安装 2.1. 官网 Apache Kafka
2.2. docker安装 version: &#34;1&#34; services: kafka: image: &#39;bitnami/kafka:latest&#39; hostname: kafka ports: - 9092:9092 - 9093:9093 volumes: - &#39;D:\Docker\Kafka\data:/bitnami/kafka&#39; networks: - kafka_net environment: # KRaft settings - KAFKA_CFG_NODE_ID=0 - KAFKA_CFG_PROCESS_ROLES=controller,broker - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka:9093 # Listeners - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093 - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://192.168.2.51:9092 - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT networks: kafka_net: driver: bridge docker-compose -f .">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-04-23T23:53:08+08:00">
    <meta property="article:modified_time" content="2024-04-23T23:53:08+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Kafka入门使用教程</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h3 id="aNiR0">1. 前言</h3> 
<h4 id="H73ZW">1.1. 什么是消息队列</h4> 
<p id="u4e6b365a">消息队列（MQ）是消息传递<a href="https://www.ibm.com/cn-zh/topics/middleware" rel="nofollow" title="中间件">中间件</a>解决方案的一个组件，旨在支持独立的应用和服务之间的信息交换。 消息队列按发送顺序存储“消息”（由应用所创建、供其他应用使用的数据包），直到使用方应用能够处理它们为止。 这些消息安全地等待接收方应用做好准备，因此，即使网络或接收方应用出现问题，消息队列中的消息也不会丢失。</p> 
<h4 id="s7fcx">1.2. 为什么用消息队列</h4> 
<h5 id="siv0P">1.2.1. 解耦</h5> 
<p id="u03a441a2">生产者（客户端）发送消息到MQ中去，接受者（服务端）处理消息，需要消费的系统直接去MQ取消息进行消费即可而不需要和其他系统有耦合。</p> 
<p id="ua3661ba7">例如订单服务在电商订单创建后，发送扣减可用库存消息到MQ，库存系统在接受到消息后处理扣减可用库存。后续如果还需要扩展，通知其他第三方系统，只需要新增一个消费者去接收扣减信息处理即可。</p> 
<h5 id="LCieZ">1.2.2. 异步</h5> 
<p id="u2688bff4">将用户的请求数据存储到MQ之后就立即返回结果。随后，系统再对消息进行消费。</p> 
<p id="ube40b091">例如短信验证码业务，登录服务在接受到用户手机号之后，将手机号发送到MQ，短信服务接受消息后进行短信发送。登录服务不需要等待发送验证码完成，即可继续后续处理。</p> 
<h5 id="HnmWg">1.2.3. 削峰</h5> 
<p id="u8abbaefe">先将短时间高并发产生的事务消息存储在MQ中，然后后端服务再慢慢根据自己的能力去消费这些消息。</p> 
<p id="uf437b9d0">例如电商大促时，可在订单服务前架设一层订单接收服务，只负责接收订单并将订单信息发送到MQ，订单服务根据自身消费能力来接收订单信息并创建订单。 这样就避免订单服务因过高流量而宕机。</p> 
<h4 id="mW7gO">1.3. Kafka</h4> 
<p id="u66ca5296"><strong>Kafka</strong>是最初由Linkedin公司开发，是一个分布式、支持分区的（partition）、多副本的（replica），基于<a href="https://so.csdn.net/so/search?q=zookeeper&amp;spm=1001.2101.3001.7020" title="zookeeper">zookeeper</a>协调的分布式消息系统，它的最大的特性就是可以实时的处理大量数据以满足各种需求场景：比如基于hadoop的批处理系统、低延迟的实时系统、storm/Spark流式处理引擎，web/nginx日志、访问日志，消息服务等等，用scala语言编写，Linkedin于2010年贡献给了Apache基金会并成为顶级开源项目。</p> 
<h3 id="d8627">2. 安装</h3> 
<h4 id="jKRyE">2.1. 官网</h4> 
<p id="u396fd187"><a href="https://kafka.apache.org/documentation/#quickstart" rel="nofollow" title="Apache Kafka">Apache Kafka</a></p> 
<h4 id="nCHu7">2.2. docker安装</h4> 
<pre id="mMzQ0"><code>version: "1"
services:
  kafka:
    image: 'bitnami/kafka:latest'
    hostname: kafka
    ports:
      - 9092:9092
      - 9093:9093
    volumes:
      - 'D:\Docker\Kafka\data:/bitnami/kafka'
    networks:
      - kafka_net
    environment:
      # KRaft settings
      - KAFKA_CFG_NODE_ID=0
      - KAFKA_CFG_PROCESS_ROLES=controller,broker
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka:9093
      # Listeners
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://192.168.2.51:9092
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT
networks:
  kafka_net:
    driver: bridge</code></pre> 
<pre id="SeZdI"><code>docker-compose -f .\docker-compose.yml up -d</code></pre> 
<h3 id="NyzDz">3. 简单使用</h3> 
<h4 id="vgqux">3.1. 可视化工具</h4> 
<h5 id="NA3n4">3.1.1. offset explorer</h5> 
<p id="ua27c104a"><a href="https://offsetexplorer.com/index.html" rel="nofollow" title="Offset Explorer">Offset Explorer</a></p> 
<ul><li id="uc158160d">配置Cluster name名字,Bootrap servers地址等信息</li></ul> 
<p id="u11e0798c"></p> 
<p class="img-center"><img alt="" height="719" id="ud9d2d410" src="https://images2.imgbox.com/57/79/PWppGVnE_o.png" width="1200"></p> 
<ul><li id="u67977c19">可以查看kafka节点，topic主题和consumers消费者等信息。</li></ul> 
<p id="u81a29273"></p> 
<p class="img-center"><img alt="" height="623" id="u620821b5" src="https://images2.imgbox.com/8a/f4/rXgOWhUU_o.png" width="1200"></p> 
<h5 id="JIgMA">3.1.2. 可视化工具添加消息</h5> 
<ul><li id="u71db3f1d">创建topic</li></ul> 
<p id="u252eed90"></p> 
<p class="img-center"><img alt="" height="838" id="PzIwd" src="https://images2.imgbox.com/47/f0/1a0IMUwh_o.png" width="1200"></p> 
<ul><li id="u329d35da">修改内容类型为String（记得点Update）</li></ul> 
<p id="u6786e5c4"></p> 
<p class="img-center"><img alt="" height="620" id="gFINl" src="https://images2.imgbox.com/b8/82/DzCd7r4M_o.png" width="1200"></p> 
<ul><li id="ua3580d2c">选中Partition，点击加号，选择Add Single Message 。Key和Value都Enter Manualy，Key可不填。点击Add</li></ul> 
<p id="u37a0b896"></p> 
<p class="img-center"><img alt="" height="764" id="rTqqG" src="https://images2.imgbox.com/d1/e8/OwMiEHHy_o.png" width="1200"></p> 
<ul><li id="u24028ce7">点击绿色Retrieve按钮，刷新分区消息。</li></ul> 
<p id="ud7febc8a"></p> 
<p class="img-center"><img alt="" height="691" id="tFDn6" src="https://images2.imgbox.com/d5/a1/WQOOt4ql_o.png" width="1200"></p> 
<h4 id="o84lF">3.2. 简单应用</h4> 
<h5 id="BJh2N">3.2.1. 发送消息</h5> 
<ul><li id="u850a27f6">项目中添加Kafka依赖</li></ul> 
<pre id="bGu0x"><code>&lt;!-- https://mvnrepository.com/artifact/org.apache.kafka/kafka-clients --&gt;
&lt;dependency&gt;
  &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;
  &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt;
  &lt;version&gt;3.7.0&lt;/version&gt;
&lt;/dependency&gt;</code></pre> 
<ul><li id="u07b4daf1">构建生产者者，填写对应的配置信息，模拟发送五次消息，并打印发送的信息</li></ul> 
<pre id="w9ryH"><code>Properties properties = new Properties();
//修改为对应的bootstrap.servers
properties.put("bootstrap.servers", "192.168.2.51:9092");
properties.put("acks", "all");
properties.put("retries", 0);
properties.put("batch.size", 16384);
properties.put("linger.ms", 1);
properties.put("buffer.memory", 33554432);

//序列化类型。
properties.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
properties.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");
Producer&lt;String, String&gt; producer = null;
try {
    producer = new KafkaProducer&lt;&gt;(properties);
    for (int i = 0; i &lt; 5; i++) {
        String topic = "my-topic";
        String value = "My first message" + i;
        ProducerRecord&lt;String, String&gt; producerRecord = new ProducerRecord&lt;&gt;(topic, value);
        producer.send(producerRecord);
        System.out.println("Sent:" + producerRecord);
    }
} catch (Exception e) {
    e.printStackTrace();

} finally {
    producer.close();
}</code></pre> 
<ul><li id="ucc33c26a">效果展示</li></ul> 
<p id="u20476eec"></p> 
<p class="img-center"><img alt="" height="853" id="ISQEe" src="https://images2.imgbox.com/23/6a/PUHV6cmz_o.png" width="1200"></p> 
<ul><li id="uba095f85">工具查看Kafka中的消息</li></ul> 
<p id="u1710d239"></p> 
<p class="img-center"><img alt="" height="472" id="O2QsB" src="https://images2.imgbox.com/c3/f3/9Wzp7Ybe_o.png" width="1200"></p> 
<h5 id="l5sAf">3.2.2. 消费消息</h5> 
<ul><li id="u07f86c4d">构建消费者，填写对应的配置信息，while循环模拟消费线程，并打印消费的信息</li></ul> 
<pre id="tYmVe"><code>Properties properties = new Properties();
//修改为对应的bootstrap.servers
properties.put("bootstrap.servers", "192.168.2.51:9092");
//可自行修改，消费组名称
properties.put("group.id", "zzj.kafka");
properties.put("enable.auto.commit", "true");
properties.put("auto.commit.interval.ms", "1000");
properties.put("auto.offset.reset", "earliest");
properties.put("session.timeout.ms", "30000");
//反序列化
properties.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
properties.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
KafkaConsumer&lt;String, String&gt; kafkaConsumer = new KafkaConsumer&lt;&gt;(properties);
//制定消费的topic主题
kafkaConsumer.subscribe(Arrays.asList("my-topic"));
while (true) {
    ConsumerRecords&lt;String, String&gt; records = kafkaConsumer.poll(100);//100是超时时间
    for (ConsumerRecord&lt;String, String&gt; record : records) {
        System.out.printf("offset = %d, value = %s", record.offset(), record.value());
        System.out.println();
    }
}</code></pre> 
<ul><li id="u86e51599">效果展示</li></ul> 
<p id="u67e1bc78"></p> 
<p class="img-center"><img alt="" height="783" id="ApiUc" src="https://images2.imgbox.com/24/84/hURHK8jG_o.png" width="1200"></p> 
<ul><li id="u27179e48">工具查看消费记录，选择对应的group.id消费组。可查看offset偏移量等信息</li></ul> 
<p id="u4ed69489"></p> 
<p class="img-center"><img alt="" height="596" id="vW1Bl" src="https://images2.imgbox.com/a8/c6/1WoqsQzU_o.png" width="1200"></p> 
<h4 id="eMDtI">3.3. Springboot项目应用</h4> 
<h5 id="bmpga">3.3.1. Springboot集成Kafka</h5> 
<ul><li id="u6051d533">项目中添加Kafka依赖</li></ul> 
<pre id="nrH84"><code>&lt;dependency&gt;
  &lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt;
  &lt;artifactId&gt;spring-kafka&lt;/artifactId&gt;
&lt;/dependency&gt;</code></pre> 
<ul><li id="uaf9deb27">添加Kafka生成者和消费者配置</li></ul> 
<pre id="zGt87"><code>spring.kafka.bootstrap-servers=localhost:9092
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer</code></pre> 
<ul><li id="u8c0ae132">模拟生产者代码，使用spring-kafak封装的KafkaTemplate</li></ul> 
<pre id="G00nR"><code>import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.http.HttpStatus;
import org.springframework.http.ResponseEntity;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.web.bind.annotation.*;

@RestController
@RequestMapping("kafka")
@Slf4j
public class KafkaController {

    @Autowired
    private KafkaTemplate&lt;String, String&gt; kafkaTemplate;

    @RequestMapping(method = RequestMethod.POST, value = "/send")
    public ResponseEntity&lt;String&gt; send(@RequestBody String body){
        log.info("send message: {}", body);
        kafkaTemplate.send("my-springboot-topic", body);
        return new ResponseEntity&lt;&gt;("success", HttpStatus.OK);
    }
}</code></pre> 
<ul><li id="ufd00c816">消费者代码，使用@KafkaListener注解配置消费方法</li></ul> 
<pre id="urRwH"><code>package com.zzj.kafkademo.demos;

import lombok.extern.slf4j.Slf4j;
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.kafka.annotation.TopicPartition;
import org.springframework.kafka.support.KafkaHeaders;
import org.springframework.messaging.handler.annotation.Header;
import org.springframework.messaging.handler.annotation.Payload;
import org.springframework.stereotype.Component;

@Component
@Slf4j
public class KafkaConsumer {

    @KafkaListener(topics = {"my-springboot-topic"}, groupId = "springboot-consumer")
    public void listen(
            //接收消息体
            @Payload String data,

            //接收分区编号
            @Header(KafkaHeaders.RECEIVED_PARTITION_ID) int partition,

            //接收topic主题名
            @Header(KafkaHeaders.RECEIVED_TOPIC) String topic,

            //接收消息的时间戳
            @Header(KafkaHeaders.RECEIVED_TIMESTAMP) long ts
    ){
        log.info("data:{},partition:{},topic:{},ts:{}", data, partition, topic, ts);
    }
}
</code></pre> 
<h5 id="kh3go">3.3.2. 效果展示</h5> 
<ul><li id="ub68772d8">使用postman模拟发送消息</li></ul> 
<p id="u1344b236"></p> 
<p class="img-center"><img alt="" height="721" id="u11bd9a52" src="https://images2.imgbox.com/53/c4/5OJ5y3lG_o.png" width="1200"></p> 
<ul><li id="u0127c462">查看发送和消费记录，KafkaController中打印发送日志，KafkaConsumer打印消费日记</li></ul> 
<p id="u5c9f3066"></p> 
<p class="img-center"><img alt="" height="826" id="ub4513587" src="https://images2.imgbox.com/79/5f/5yozeZqO_o.png" width="1200"></p> 
<p id="u275620e6"></p> 
<p class="img-center"><img alt="" height="662" id="u221c25ca" src="https://images2.imgbox.com/be/6e/t05nyT36_o.png" width="1200"></p> 
<h3 id="a8Jb7">4. 问题总结</h3> 
<h4 id="twTWL">4.1. 系统可用性降低：</h4> 
<p id="u1ee50eb4">系统可用性在某种程度上说是降低了的，为什么这样说呢？在引入Kafka之后，就需要考虑Kafka的稳定性，如果突然挂了要如何处理，如何避免Kafka挂掉等问题。</p> 
<h4 id="wow1w">4.2. 系统复杂性提高：</h4> 
<p id="u7514dffd">引入Kafka之后，需要保证消息没有被重复消费、消息是否丢失、还要保证消息传递的顺序性，消息消费错误导致的数据一致性问题等情况。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/e9dbe4b8141a209a11215369f2c90da9/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">web大鱼海棠主题网页(6页)</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/554ab455185c5d47913685f01065359a/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">分布式hbase：status查看hbase shell时抱错：ERROR: KeeperErrorCode = NoNode for /hbase/master 问题。</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>