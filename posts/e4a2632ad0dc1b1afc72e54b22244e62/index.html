<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>WD1.4标签器：Stable Diffusion的提示词反推神器 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/e4a2632ad0dc1b1afc72e54b22244e62/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="WD1.4标签器：Stable Diffusion的提示词反推神器">
  <meta property="og:description" content="引言 在AI绘画领域，Stable Diffusion（SD）因其强大的生成能力而备受关注。然而，如何精准地控制和优化生成效果，常常是许多用户面临的问题。今天，我们将详细介绍一款实用的插件——WD1.4标签器，它可以帮助我们反推出图片背后的提示词，从而提升我们的AI绘画体验。
首先，访问好易智算平台，在这里可以直接选择“扩展”功能。在拓展列表中，您会发现WD 1.4标记器已经内置，无需额外下载安装。选择该标记器，点击“安装”，系统将自动完成安装过程。安装成功后，点击“应用”按钮，然后重启UI或WebUI，即可开始使用。
WD1.4标签器简介 WD1.4标签器是一款专为Stable Diffusion设计的插件，用于分析上传的图片并提取出其背后的提示词。通过这个工具，我们可以更深入地理解图片的元素和风格，并为二次创作提供有力的支持。此外，该插件还支持多种替代模型查询，类似于deepdanbooru查询。
例如：我们将这张图片放到插件中 参数 预设： 在Stable Diffusion的上下文中，预设是指一系列预先定义的设置，包括模型参数、生成图像的风格、尺寸等。这些预设可以帮助用户快速开始生成特定风格的图像，而无需从头开始调整所有参数。 反推： 在图像生成的语境中，“反推”通常指的是根据生成的图像推断出原始的文本提示（prompt）或参数。这可以用于分析模型如何响应特定的输入，或者帮助用户理解如何修改提示以获得期望的输出。 卸载反推所有模型： 这意味着允许用户从插件中移除所有用于反推功能的模型。这样做可以释放内存，或者是在不需要反推功能时优化性能。 阈值： 在图像生成中，阈值用于确定何时停止迭代过程，例如，当生成的图像质量达到某个预定水平时。它也可以用于过滤模型生成的结果，只保留那些超过特定置信度或质量标准的图像。 附件标签： 在插件的上下文中，附件标签是指与主要生成任务相关的额外标签或元数据。这些标签可以用于对生成的图像进行分类，或者提供额外的信息，帮助用户在浏览或筛选图像时找到特定的内容。 排除标签： 排除标签是一组关键词或主题，用户希望在生成图像时避免出现。例如，如果用户不希望生成的图像包含某些敏感内容，他们可以将这些内容作为排除标签，以指示模型在生成图像时避开这些元素。 生成效果：
solo, 1boy, male focus, shirt, looking at viewer, black hair, collared shirt, realistic, upper body, indoors, black eyes, short hair, closed mouth, window, white shirt, lips, buttons 我们看到这个翻译后的内容很不错的
我们将负面提示词输入进去，点击生成
我们其实可以发现，原图的内容已经较好的还原了，发型，纽克等关键内容，但似乎并没有达到想要的效果
我们这里可以选择ControlNet v1.1.445
并且更新了社区功能，可以社区镜像，心愿墙，晒作品进行分享
并且无论是从便捷性、资源优势、社区支持，还是持续更新和专业服务，好易智慧算平台都是我们使用的理想选择。
下面我们进行选择:
ControlNet ControlNet v1.1.445 是一款先进的神经网络插件，旨在提升图像生成过程中的控制和一致性，尤其针对 Stable Diffusion 模型。以下是对您提供的内容的优化版本：
专注于提升图像生成的质量和一致性。通过引入额外的控制条件，用户能够更精准地操控图像生成过程，不再需要依赖于不断尝试不同的提示词。这一创新使得基于单一提示词生成统一风格的高质量图像成为现实。
我们可以看到这样之后效果就好了很多，统一了风格
我们可以来了解一下ControlNet 的原理">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-07-25T20:47:28+08:00">
    <meta property="article:modified_time" content="2024-07-25T20:47:28+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">WD1.4标签器：Stable Diffusion的提示词反推神器</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-dracula">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_0"></a>引言</h2> 
<p>在AI绘画领域，Stable Diffusion（SD）因其强大的生成能力而备受关注。然而，如何精准地控制和优化生成效果，常常是许多用户面临的问题。今天，我们将详细介绍一款实用的插件——WD1.4标签器，它可以帮助我们反推出图片背后的提示词，从而提升我们的AI绘画体验。<br> <img src="https://images2.imgbox.com/60/85/FnYsdonV_o.png" alt="在这里插入图片描述"></p> 
<p>首先，访问<a href="https://www.haoee.com/?inviteCode=YSZS9NVL" rel="nofollow">好易智算平台</a>，在这里可以直接选择“扩展”功能。在拓展列表中，您会发现WD 1.4标记器已经内置，无需额外下载安装。选择该标记器，点击“安装”，系统将自动完成安装过程。安装成功后，点击“应用”按钮，然后重启UI或WebUI，即可开始使用。</p> 
<p><img src="https://images2.imgbox.com/27/f4/dyAZfaAg_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/75/6d/rV7LlJI2_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/61/4a/gmhgnEWR_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="WD14_10"></a>WD1.4标签器简介</h3> 
<p>WD1.4标签器是一款专为Stable Diffusion设计的插件，用于分析上传的图片并提取出其背后的提示词。通过这个工具，我们可以更深入地理解图片的元素和风格，并为二次创作提供有力的支持。此外，该插件还支持多种替代模型查询，类似于deepdanbooru查询。</p> 
<pre><code class="prism language-c">例如：我们将这张图片放到插件中
</code></pre> 
<p><img src="https://images2.imgbox.com/48/06/NqfCWW8k_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="_18"></a>参数</h3> 
<blockquote> 
 <p><img src="https://images2.imgbox.com/8e/da/qZ990X07_o.png" alt="在这里插入图片描述"></p> 
 <ol><li><strong>预设</strong>： 
   <ul><li>在Stable Diffusion的上下文中，预设是指一系列预先定义的设置，包括模型参数、生成图像的风格、尺寸等。这些预设可以帮助用户快速开始生成特定风格的图像，而无需从头开始调整所有参数。</li></ul> </li><li><strong>反推</strong>： 
   <ul><li>在图像生成的语境中，“反推”通常指的是根据生成的图像推断出原始的文本提示（prompt）或参数。这可以用于分析模型如何响应特定的输入，或者帮助用户理解如何修改提示以获得期望的输出。</li></ul> </li><li><strong>卸载反推所有模型</strong>： 
   <ul><li>这意味着允许用户从插件中移除所有用于反推功能的模型。这样做可以释放内存，或者是在不需要反推功能时优化性能。</li></ul> </li><li><strong>阈值</strong>： 
   <ul><li>在图像生成中，阈值用于确定何时停止迭代过程，例如，当生成的图像质量达到某个预定水平时。它也可以用于过滤模型生成的结果，只保留那些超过特定置信度或质量标准的图像。</li></ul> </li><li><strong>附件标签</strong>： 
   <ul><li>在插件的上下文中，附件标签是指与主要生成任务相关的额外标签或元数据。这些标签可以用于对生成的图像进行分类，或者提供额外的信息，帮助用户在浏览或筛选图像时找到特定的内容。</li></ul> </li><li><strong>排除标签</strong>： 
   <ul><li>排除标签是一组关键词或主题，用户希望在生成图像时避免出现。例如，如果用户不希望生成的图像包含某些敏感内容，他们可以将这些内容作为排除标签，以指示模型在生成图像时避开这些元素。</li></ul> </li></ol> 
</blockquote> 
<p>生成效果：<br> <img src="https://images2.imgbox.com/41/cc/eGY3am1B_o.png" alt="在这里插入图片描述"></p> 
<pre><code class="prism language-c">solo<span class="token punctuation">,</span> <span class="token number">1</span>boy<span class="token punctuation">,</span> male focus<span class="token punctuation">,</span> shirt<span class="token punctuation">,</span> looking at viewer<span class="token punctuation">,</span> black hair<span class="token punctuation">,</span> collared shirt<span class="token punctuation">,</span> realistic<span class="token punctuation">,</span> upper body<span class="token punctuation">,</span> indoors<span class="token punctuation">,</span> black eyes<span class="token punctuation">,</span> <span class="token keyword">short</span> hair<span class="token punctuation">,</span> closed mouth<span class="token punctuation">,</span> window<span class="token punctuation">,</span> white shirt<span class="token punctuation">,</span> lips<span class="token punctuation">,</span> buttons
</code></pre> 
<blockquote> 
 <p><img src="https://images2.imgbox.com/93/62/UUW78HOv_o.png" alt="在这里插入图片描述"><br> 我们看到这个翻译后的内容很不错的</p> 
</blockquote> 
<p>我们将负面提示词输入进去，<mark>点击生成</mark><br> <img src="https://images2.imgbox.com/68/33/OKUMuTAx_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/46/97/PpuDAVjs_o.png" alt="在这里插入图片描述"><br> 我们其实可以发现，原图的内容已经较好的还原了，发型，纽克等关键内容，但似乎并没有达到想要的效果<br> 我们这里可以选择<mark>ControlNet v1.1.445</mark></p> 
<p><img src="https://images2.imgbox.com/79/89/LBTR5TqM_o.png" alt="在这里插入图片描述"><br> 并且更新了<mark>社区功能</mark>，可以<strong>社区镜像，心愿墙，晒作品</strong>进行分享<br> <img src="https://images2.imgbox.com/44/1b/numxdQ3X_o.png" alt="在这里插入图片描述"></p> 
<p>并且无论是从<mark>便捷性、资源优势、社区支持，还是持续更新和专业服务</mark>，好易智慧算平台都是我们使用的<strong>理想选择</strong>。</p> 
<p>下面我们进行选择:<br> <img src="https://images2.imgbox.com/4d/44/N1PrdExg_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="ControlNet_59"></a>ControlNet</h3> 
<p>ControlNet v1.1.445 是一款先进的神经网络插件，旨在提升图像生成过程中的控制和一致性，尤其针对 Stable Diffusion 模型。以下是对您提供的内容的优化版本：</p> 
<blockquote> 
 <p>专注于<strong>提升图像生成的质量和一致性</strong>。通过引入额外的控制条件，用户能够更精准地操控图像生成过程，不再需要依赖于不断尝试不同的提示词。这一创新使得基于单一提示词生成统一风格的高质量图像成为现实。</p> 
 <p><img src="https://images2.imgbox.com/b5/06/nbGyjjqH_o.png" alt="在这里插入图片描述"></p> 
</blockquote> 
<blockquote> 
 <p><mark>我们可以看到这样之后效果就好了很多，统一了风格</mark><br> <img src="https://images2.imgbox.com/a7/23/HZrwrVQN_o.png" alt="在这里插入图片描述"></p> 
</blockquote> 
<p><mark>我们可以来了解一下ControlNet 的原理</mark></p> 
<p>ControlNet 引入的实时互锁与对称消息传递技术，是通过融合 Universal Remote I/O 和 DH+ 网络的优点而实现的。这种先进的网络架构不仅确保了关键控制数据（如 I/O 更新和控制器间的互锁）的高速传输，同时也支持非关键数据的流通，例如程序的上传下载和消息传递。</p> 
<blockquote> 
 <p>ControlNet 网络特点：</p> 
 <ul><li>开放性：便于与其他系统无缝集成。</li><li>高速性：确保时间敏感信息快速传输。</li><li>确定性：为实时控制提供可靠的通信保障。 网络功能：</li><li>集成 I/O 网络与对等消息传递网络，优化控制层通信。</li><li>提供实时控制和消息传递服务，支持点对点通信。 技术优势：</li><li>实时互锁技术：保障控制器间操作的同步性，降低因操作不同步引起的错误和故障风险，显著提升系统稳定性。</li><li>对称消息传递技术：通过高效的通信机制，确保消息的可靠性和一致性，即使在高负载环境下也能维持系统的稳定运行。 影响概述：</li><li>系统稳定性：实时互锁技术通过精确同步控制器操作，大幅减少了系统错误和故障，增强了整体稳定性。</li><li>性能优化：对称消息传递技术提升了数据传输的效率和可靠性，确保系统在面临高负载时依然保持出色的性能表现。</li></ul> 
</blockquote> 
<h3><a id="_85"></a>参数</h3> 
<p>ControlNet是一种用于控制三维模型运动的神经网络框架。它通过学习两个或多个输入图像之间的空间关系，来预测和调整模型在特定视角下的姿态和位置。<br> <img src="https://images2.imgbox.com/8a/f2/aZaDIOll_o.png" alt="在这里插入图片描述"><br> 以下是各个控制类型的详细解释：</p> 
<ol><li><strong>全部</strong>：启用所有可用的控制类型，以综合应用各种控制方法来生成或修改图像。</li><li><strong>模糊</strong>：应用模糊效果到图像上，可以减少图像的细节和清晰度，常用于模拟焦点不清晰或背景模糊的效果。</li><li><strong>Canny（硬边缘）</strong>：使用Canny边缘检测算法来识别图像中的边缘，突出显示物体的轮廓和结构，适用于需要清晰边缘的图像处理。</li><li><strong>Depth（深度）</strong>：利用深度信息来调整图像的透视和三维效果，可以创建出物体远近感和深度层次感。</li><li><strong>IP-Adapter</strong>：一种接口适配器，用于将不同网络协议或接口标准的数据转换为ControlNet可以处理的格式，以便在图像生成中使用。</li><li><strong>局部重绘</strong>：对图像的特定区域进行修复或重绘，常用于去除图像中的污点、物体或不需要的元素。</li><li><strong>Instant-ID</strong>：用于快速识别图像中的对象或元素，并为其分配唯一的标识符，以便于后续处理或分析。</li><li><strong>Lineart（线稿）</strong>：生成或处理图像的线条艺术，通常用于创建素描、漫画或矢量风格的图像。</li><li><strong>MLSD（直线）</strong>：最小直线段检测，用于识别图像中的直线段，适用于需要精确直线控制的图像生成。</li><li><strong>NormalMap（法线贴图）</strong>：生成或编辑法线贴图，用于在3D渲染中模拟表面细节和光照效果，无需增加额外的几何复杂度。</li><li><strong>OpenPose（姿态）</strong>：检测图像中人物的关键点，用于识别和生成具有特定姿态的人物图像。</li><li><strong>Recolor（重上色）</strong>：改变图像的颜色，可以用于给黑白图像上色、改变颜色风格或调整色彩平衡。</li><li><strong>Reference（参考）</strong>：使用参考图像来指导图像生成过程，确保生成图像在风格、内容或布局上与参考图像保持一致。</li><li><strong>Revision</strong>：对生成的图像进行迭代改进，通过细化或修正来提升图像质量或满足特定要求。</li><li><strong>Scribble（涂鸦）</strong>：使用简单的涂鸦来指导图像生成，涂鸦可以是颜色标记或线条，用于指定图像中的特定区域或特征。</li><li><strong>Segmentation（语义分割）</strong>：将图像分割成不同的语义区域，每个区域代表一个特定的类别，如人、车、天空等，用于图像分析和编辑。</li><li><strong>Shuffle（随机洗牌）</strong>：随机改变图像中元素的排列或组合，用于创建变化多样的图像或增加图像的随机性。</li><li><strong>涂鸦</strong>：与“Scribble”类似，使用手绘风格的涂鸦来指导图像生成或编辑。</li><li><strong>SoftEdge（软边缘）</strong>：应用软边缘效果到图像上，用于创建平滑过渡的边缘，减少图像的锐度。</li><li><strong>SparseCtrl</strong>：用于控制图像生成过程中的稀疏特征，可能涉及减少图像中的信息量或突出某些关键特征。</li><li><strong>T2I-Adapter</strong>：文本到图像适配器，用于将文本描述转换为图像生成过程中的控制信号，确保生成的图像符合文本描述。</li><li><strong>Tile（分块）</strong>：将图像分割成多个块或单元，每个块可以独立处理，常用于创建具有重复图案或模块化设计的图像。</li></ol> 
<p>使用ControlNet，确实可以在图像生成和处理方面实现更高级的功能，以下是如何利用ControlNet来实现更好的次元突破、固定场景等优化：</p> 
<h4><a id="_113"></a>次元突破</h4> 
<p>次元突破通常指的是在图像生成中打破现实与虚构、二维与三维之间的界限，创造出超现实或幻想风格的图像。以下是ControlNet如何帮助实现这一目标：</p> 
<ol><li><strong>深度控制（Depth Control）</strong>：通过调整深度信息，可以创建出具有强烈三维感的图像，使二维图像看起来像是突破了平面，具有深度和立体感。</li><li><strong>法线贴图（NormalMap）</strong>：使用法线贴图可以模拟复杂的表面细节和光照效果，使图像中的物体看起来更加真实和立体。</li><li><strong>姿态检测（OpenPose）</strong>：通过识别和调整人物姿态，可以实现人物在虚构场景中的自然融入，打破现实世界的物理限制。</li><li><strong>重上色（Recolor）</strong>：改变图像的颜色和色调，可以创造出不符合现实世界的色彩效果，增强次元突破的感觉。</li><li><strong>参考图像（Reference）</strong>：利用参考图像的风格和元素，可以将现实世界的图像转换为具有虚构世界特征的图像。<br> <img src="https://images2.imgbox.com/eb/92/sUnk6byz_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/71/7d/SZsWqoQy_o.png" alt="在这里插入图片描述"></li></ol> 
<h4><a id="_123"></a>固定场景优化</h4> 
<p>固定场景优化指的是在特定的场景或环境中进行图像生成时的优化策略。以下是ControlNet如何帮助实现这一点：</p> 
<ol><li><strong>语义分割（Segmentation）</strong>：通过语义分割，可以精确地控制场景中的各个元素，如天空、地面、人物等，确保它们在生成过程中保持一致。</li><li><strong>线稿（Lineart）</strong>：使用线稿控制可以固定场景的布局和结构，确保生成的图像符合预设的线条艺术风格。</li><li><strong>固定布局（Tile）</strong>：通过分块控制，可以创建具有重复图案或固定布局的图像，适用于需要一致场景的生成。</li><li><strong>局部重绘（Inpainting）</strong>：在固定场景中，可以使用局部重绘来修复或修改特定区域，而不影响整个场景的其他部分。</li><li><strong>控制网络（ControlNet）</strong>：通过ControlNet的其他控制类型，如模糊、Canny边缘检测等，可以进一步优化场景的视觉效果，使其更加符合预期的风格和氛围。<br> <img src="https://images2.imgbox.com/61/c8/mcfiiQZF_o.png" alt="在这里插入图片描述"></li></ol> 
<p><img src="https://images2.imgbox.com/e7/20/IXau4xPq_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="_133"></a>总结</h2> 
<p>通过本文的介绍，我们深入了解了WD1.4标签器在AI绘画领域，尤其是与Stable Diffusion模型结合使用时的强大功能。这款插件不仅能够帮助我们反推出图片背后的提示词，从而提升创作的精准度，还能通过ControlNet等先进技术，进一步优化图像生成的质量和风格一致性。无论是在次元突破还是固定场景优化方面，WD1.4标签器和ControlNet都展现出了其卓越的性能和无限的可能性。<br> <img src="https://images2.imgbox.com/8d/57/ssj3NgeT_o.png" alt="在这里插入图片描述"></p> 
<p>如果您对AI绘画充满热情，渴望探索更多创作潜能，不妨来<a href="https://www.haoee.com/?inviteCode=YSZS9NVL" rel="nofollow">好易智算平台</a>尝试一下WD1.4标签器。在这里，我们不仅提供了便捷的功能插件，还有活跃的社区和丰富的资源。让我们一起拥抱技术，释放创意，创作出更多令人惊叹的作品吧！</p> 
<p>以下是对好易智算平台特色服务的进一步优化描述：</p> 
<h5><a id="1_AI_141"></a>1. <strong>一站式AI绘画解决方案</strong></h5> 
<p>好易智算平台提供全面的AI绘画服务，覆盖了从模型选择、参数微调到图像生成的整个创作流程。用户可以在统一的操作环境中完成所有创作步骤，这种集成化的设计极大提升了创作效率，让艺术家们能够将更多精力投入到创意的构思与实现中。<br> <img src="https://images2.imgbox.com/3d/fc/qIKipEyT_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="2__144"></a>2. <strong>丰富的插件资源</strong></h5> 
<p>平台内置了众多功能强大的AI绘画插件，包括WD1.4标签器和ControlNet等，用户可以直接在平台内无缝接入和使用这些插件。这些丰富的插件资源极大地扩展了AI绘画的应用范围，增加了创作的灵活性和艺术表现力。</p> 
<h5><a id="3__146"></a>3. <strong>用户友好的操作界面</strong></h5> 
<p>好易智算平台的操作界面简洁明了，易于上手，即便是AI绘画的初学者也能迅速掌握。通过直观的拖拽和点击操作，用户可以轻松完成复杂的图像生成任务，无需担心技术门槛。</p> 
<h5><a id="4__148"></a>4. <strong>活跃的社区互动与资源共享</strong></h5> 
<p>平台社区是一个充满活力的交流空间，用户可以在这里展示自己的作品，分享创作经验，互相学习成长。社区内的资源共享机制确保了用户能够及时获取创作灵感。<br> <img src="https://images2.imgbox.com/3b/42/wx0CmoG1_o.png" alt="在这里插入图片描述"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/43838d5179695e9ffe5ab0fd78a66ba1/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">C语言：扫雷游戏实现</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/fd9fe914bc9edc4ca680c8a761c943cd/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Python练手小项目</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>