<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>GraphRAG如何使用ollama提供的llm model 和Embedding model服务构建本地知识库 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/90a745f24145779b0834dd2a440a63d9/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="GraphRAG如何使用ollama提供的llm model 和Embedding model服务构建本地知识库">
  <meta property="og:description" content="使用GraphRAG踩坑无数 在GraphRAG的使用过程中将需要踩的坑都踩了一遍（不得不吐槽下，官方代码有很多遗留问题，他们自己也承认工作重心在算法的优化而不是各种模型和框架的兼容性适配性上），经过了大量的查阅各种资料以及debug过程（Indexing的过程有点费机器），最终成功运行了GraphRAG项目。先后测试了两种方式，都成功了:
使用ollama提供本地llm model和Embedding model服务使用ollama提供llm model服务，使用lm-studio提供embedding model服务 之所以要使用ollama同时提供llm和Embedding模型服务，是因为ollama实在是太优雅了，使用超级简单，响应速度也超级快。
使用ollama提供服务的方式如下： 1、安装GraphRAG:
pip install graphrag -i https://pypi.tuna.tsinghua.edu.cn/simple 创建一个文件路径:./ragtest/input mkdir -p ./ragtest/input 将语料文本文件放在这个路径下， 文件格式为txt， 注意：txt文件必须是utf-8编码的，可以用记事本打开另存为得到。使用命令python -m graphrag.index --init --root ./ragtest初始化工程: python -m graphrag.index --init --root ./ragtest 修改.env文件内容如下: GRAPHRAG_API_KEY=ollama GRAPHRAG_CLAIM_EXTRACTION_ENABLED=True 注意：必须加上参数GRAPHRAG_CLAIM_EXTRACTION_ENABLED=True，否则无法生成协变量covariates， 在Local Search时会出错。
修改.setting.yaml文件，内容如下: encoding_model: cl100k_base skip_workflows: [] llm: api_key: ollama type: openai_chat # or azure_openai_chat model: qwen2 model_supports_json: true # recommended if this is available for your model. # max_tokens: 4000 # request_timeout: 180.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-08-30T09:43:49+08:00">
    <meta property="article:modified_time" content="2024-08-30T09:43:49+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">GraphRAG如何使用ollama提供的llm model 和Embedding model服务构建本地知识库</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h3><a id="GraphRAG_0"></a>使用GraphRAG踩坑无数</h3> 
<p>在GraphRAG的使用过程中将需要踩的坑都踩了一遍（不得不吐槽下，官方代码有很多遗留问题，他们自己也承认工作重心在算法的优化而不是各种模型和框架的兼容性适配性上），经过了大量的查阅各种资料以及debug过程（Indexing的过程有点费机器），最终成功运行了GraphRAG项目。先后测试了两种方式，都成功了:</p> 
<ol><li><strong>使用ollama提供本地llm model和Embedding model服务</strong></li><li><strong>使用ollama提供llm model服务，使用lm-studio提供embedding model服务</strong></li></ol> 
<p>之所以要使用ollama同时提供llm和Embedding模型服务，是因为<strong>ollama实在是太优雅了</strong>，使用超级简单，响应速度也超级快。</p> 
<h3><a id="ollama_8"></a>使用ollama提供服务的方式如下：</h3> 
<p>1、安装GraphRAG:</p> 
<pre><code class="prism language-shell">pip <span class="token function">install</span> graphrag <span class="token parameter variable">-i</span> https://pypi.tuna.tsinghua.edu.cn/simple
</code></pre> 
<ol start="2"><li>创建一个文件路径:<code>./ragtest/input</code></li></ol> 
<pre><code class="prism language-shell"><span class="token function">mkdir</span> <span class="token parameter variable">-p</span> ./ragtest/input
</code></pre> 
<ol start="3"><li>将语料文本文件放在这个路径下， 文件格式为txt， <strong>注意</strong>：txt文件必须是<code>utf-8</code>编码的，可以用记事本打开另存为得到。</li><li>使用命令<code>python -m graphrag.index --init --root ./ragtest</code>初始化工程:</li></ol> 
<pre><code class="prism language-shell">python <span class="token parameter variable">-m</span> graphrag.index <span class="token parameter variable">--init</span> <span class="token parameter variable">--root</span> ./ragtest
</code></pre> 
<ol start="5"><li>修改<code>.env</code>文件内容如下:</li></ol> 
<pre><code class="prism language-shell"><span class="token assign-left variable">GRAPHRAG_API_KEY</span><span class="token operator">=</span>ollama
<span class="token assign-left variable">GRAPHRAG_CLAIM_EXTRACTION_ENABLED</span><span class="token operator">=</span>True
</code></pre> 
<p><strong>注意</strong>：必须加上参数<code>GRAPHRAG_CLAIM_EXTRACTION_ENABLED=True</code>，否则无法生成协变量covariates， 在Local Search时会出错。</p> 
<ol start="6"><li>修改.<code>setting.yaml</code>文件，内容如下:</li></ol> 
<pre><code class="prism language-yaml"><span class="token key atrule">encoding_model</span><span class="token punctuation">:</span> cl100k_base
<span class="token key atrule">skip_workflows</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token key atrule">llm</span><span class="token punctuation">:</span>
  <span class="token key atrule">api_key</span><span class="token punctuation">:</span> ollama
  <span class="token key atrule">type</span><span class="token punctuation">:</span> openai_chat <span class="token comment"># or azure_openai_chat</span>
  <span class="token key atrule">model</span><span class="token punctuation">:</span> qwen2
  <span class="token key atrule">model_supports_json</span><span class="token punctuation">:</span> <span class="token boolean important">true</span> <span class="token comment"># recommended if this is available for your model.</span>
  <span class="token comment"># max_tokens: 4000</span>
  <span class="token comment"># request_timeout: 180.0</span>
  <span class="token key atrule">api_base</span><span class="token punctuation">:</span> http<span class="token punctuation">:</span>//localhost<span class="token punctuation">:</span>11434/v1/
  <span class="token comment"># api_version: 2024-02-15-preview</span>
  <span class="token comment"># organization: &lt;organization_id&gt;</span>
  <span class="token comment"># deployment_name: &lt;azure_model_deployment_name&gt;</span>
  <span class="token comment"># tokens_per_minute: 150_000 # set a leaky bucket throttle</span>
  <span class="token comment"># requests_per_minute: 10_000 # set a leaky bucket throttle</span>
  <span class="token comment"># max_retries: 10</span>
  <span class="token comment"># max_retry_wait: 10.0</span>
  <span class="token comment"># sleep_on_rate_limit_recommendation: true # whether to sleep when azure suggests wait-times</span>
  <span class="token comment"># concurrent_requests: 25 # the number of parallel inflight requests that may be made</span>

<span class="token key atrule">parallelization</span><span class="token punctuation">:</span>
  <span class="token key atrule">stagger</span><span class="token punctuation">:</span> <span class="token number">0.3</span>
  <span class="token comment"># num_threads: 50 # the number of threads to use for parallel processing</span>

<span class="token key atrule">async_mode</span><span class="token punctuation">:</span> threaded <span class="token comment"># or asyncio</span>

<span class="token key atrule">embeddings</span><span class="token punctuation">:</span>
  <span class="token comment">## parallelization: override the global parallelization settings for embeddings</span>
  <span class="token key atrule">async_mode</span><span class="token punctuation">:</span> threaded <span class="token comment"># or asyncio</span>
  <span class="token key atrule">llm</span><span class="token punctuation">:</span>
    <span class="token key atrule">api_key</span><span class="token punctuation">:</span> ollama
    <span class="token key atrule">type</span><span class="token punctuation">:</span> openai_embedding <span class="token comment"># or azure_openai_embedding</span>
    <span class="token key atrule">model</span><span class="token punctuation">:</span> nomic<span class="token punctuation">-</span>embed<span class="token punctuation">-</span>text
    <span class="token key atrule">api_base</span><span class="token punctuation">:</span> http<span class="token punctuation">:</span>//localhost<span class="token punctuation">:</span>11434/api
    <span class="token comment"># api_version: 2024-02-15-preview</span>
    <span class="token comment"># organization: &lt;organization_id&gt;</span>
    <span class="token comment"># deployment_name: &lt;azure_model_deployment_name&gt;</span>
    <span class="token comment"># tokens_per_minute: 150_000 # set a leaky bucket throttle</span>
    <span class="token comment"># requests_per_minute: 10_000 # set a leaky bucket throttle</span>
    <span class="token comment"># max_retries: 10</span>
    <span class="token comment"># max_retry_wait: 10.0</span>
    <span class="token comment"># sleep_on_rate_limit_recommendation: true # whether to sleep when azure suggests wait-times</span>
    <span class="token comment"># concurrent_requests: 25 # the number of parallel inflight requests that may be made</span>
    <span class="token comment"># batch_size: 16 # the number of documents to send in a single request</span>
    <span class="token comment"># batch_max_tokens: 8191 # the maximum number of tokens to send in a single request</span>
    <span class="token comment"># target: required # or optional</span>
    <span class="token punctuation">...</span>
  
</code></pre> 
<ol start="7"><li>使用ollama启动llm和Embedding服务，其中embedding 模型是<code>nomic-embed-text</code>:</li></ol> 
<pre><code class="prism language-shell">ollama pull qwen2
ollama pull nomic-embed-text
ollama serve
</code></pre> 
<ol start="8"><li>修改文件:<code>D:\ProgramData\miniconda3\envs\graphRAG\Lib\site-packages\graphrag\llm\openai\openai_embeddings_llm.py</code>内容(根据大家自己安装GraphRAG的路径查找)，调用ollama服务:</li></ol> 
<pre><code class="prism language-python"><span class="token keyword">import</span> ollama

<span class="token comment"># ....</span>

<span class="token keyword">class</span> <span class="token class-name">OpenAIEmbeddingsLLM</span><span class="token punctuation">(</span>BaseLLM<span class="token punctuation">[</span>EmbeddingInput<span class="token punctuation">,</span> EmbeddingOutput<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""A text-embedding generator LLM."""</span>

    _client<span class="token punctuation">:</span> OpenAIClientTypes
    _configuration<span class="token punctuation">:</span> OpenAIConfiguration

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> client<span class="token punctuation">:</span> OpenAIClientTypes<span class="token punctuation">,</span> configuration<span class="token punctuation">:</span> OpenAIConfiguration<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>client <span class="token operator">=</span> client
        self<span class="token punctuation">.</span>configuration <span class="token operator">=</span> configuration

    <span class="token keyword">async</span> <span class="token keyword">def</span> <span class="token function">_execute_llm</span><span class="token punctuation">(</span>
        self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">:</span> EmbeddingInput<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">:</span> Unpack<span class="token punctuation">[</span>LLMInput<span class="token punctuation">]</span>
    <span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> EmbeddingOutput <span class="token operator">|</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        args <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
            <span class="token string">"model"</span><span class="token punctuation">:</span> self<span class="token punctuation">.</span>configuration<span class="token punctuation">.</span>model<span class="token punctuation">,</span>
            <span class="token operator">**</span><span class="token punctuation">(</span>kwargs<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"model_parameters"</span><span class="token punctuation">)</span> <span class="token keyword">or</span> <span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">}</span>
        <span class="token triple-quoted-string string">'''
        embedding = await self.client.embeddings.create(
            input=input,
            **args,
        )
        return [d.embedding for d in embedding.data]
        '''</span>
        embedding_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> inp <span class="token keyword">in</span> <span class="token builtin">input</span><span class="token punctuation">:</span>
            embedding <span class="token operator">=</span> ollama<span class="token punctuation">.</span>embeddings<span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"nomic-embed-text"</span><span class="token punctuation">,</span>prompt<span class="token operator">=</span>inp<span class="token punctuation">)</span>
            embedding_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>embedding<span class="token punctuation">[</span><span class="token string">"embedding"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> embedding_list

</code></pre> 
<p>上面注释部分为官方原始代码，增加的代码是:</p> 
<pre><code class="prism language-python">        embedding_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> inp <span class="token keyword">in</span> <span class="token builtin">input</span><span class="token punctuation">:</span>
            embedding <span class="token operator">=</span> ollama<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"nomic-embed-text"</span><span class="token punctuation">,</span>prompt<span class="token operator">=</span>inp<span class="token punctuation">)</span>
            embedding_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>embedding<span class="token punctuation">[</span><span class="token string">"embedding"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> embedding_list
</code></pre> 
<ol start="9"><li>修改文件：<code>D:\ProgramData\miniconda3\envs\graphRAG\Lib\site-packages\graphrag\query\llm\oai\embedding.py</code>, 调用ollama提供的模型服务， 代码位置在:</li></ol> 
<pre><code class="prism language-python"><span class="token keyword">import</span> ollama
<span class="token comment">#.....</span>

embedding <span class="token operator">=</span> ollama<span class="token punctuation">.</span>embeddings<span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">'nomic-embed-text'</span><span class="token punctuation">,</span> prompt<span class="token operator">=</span>chunk<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">'embedding'</span><span class="token punctuation">]</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/b5/65/FmvxNWoa_o.png" alt="在这里插入图片描述"><br> 上面注释的是官方代码，箭头指向的是要新增的代码。</p> 
<ol start="10"><li>修改文件:<code>D:\ProgramData\miniconda3\envs\graphRAG\Lib\site-packages\graphrag\query\llm\text_utils.py</code>里关于<code>chunk_text()</code>函数的定义:</li></ol> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">chunk_text</span><span class="token punctuation">(</span>
    text<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> max_tokens<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span> token_encoder<span class="token punctuation">:</span> tiktoken<span class="token punctuation">.</span>Encoding <span class="token operator">|</span> <span class="token boolean">None</span> <span class="token operator">=</span> <span class="token boolean">None</span>
<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Chunk text by token length."""</span>
    <span class="token keyword">if</span> token_encoder <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        token_encoder <span class="token operator">=</span> tiktoken<span class="token punctuation">.</span>get_encoding<span class="token punctuation">(</span><span class="token string">"cl100k_base"</span><span class="token punctuation">)</span>
    tokens <span class="token operator">=</span> token_encoder<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>text<span class="token punctuation">)</span>  <span class="token comment"># type: ignore</span>
    tokens <span class="token operator">=</span> token_encoder<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>tokens<span class="token punctuation">)</span> <span class="token comment"># 将tokens解码成字符串</span>

    chunk_iterator <span class="token operator">=</span> batched<span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">(</span>tokens<span class="token punctuation">)</span><span class="token punctuation">,</span> max_tokens<span class="token punctuation">)</span>
    <span class="token keyword">yield</span> <span class="token keyword">from</span> chunk_iterator
</code></pre> 
<p>增加的语句是:</p> 
<pre><code class="prism language-python">tokens <span class="token operator">=</span> token_encoder<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>tokens<span class="token punctuation">)</span> <span class="token comment"># 将tokens解码成字符串</span>
</code></pre> 
<p>这里应该是GraphRAG官方代码里的bug，开发人员忘记将分词后的token解码成字符串，导致在后续Embedding处理过程中会报错：<code>ZeroDivisionError: Weights sum to zero, can't be normalized</code></p> 
<pre><code class="prism language-shell"><span class="token punctuation">(</span>graphrag<span class="token punctuation">)</span> D:<span class="token punctuation">\</span>Learn<span class="token punctuation">\</span>GraphRAG<span class="token operator">&gt;</span>python <span class="token parameter variable">-m</span> graphrag.query <span class="token parameter variable">--root</span> ./newTest12 <span class="token parameter variable">--method</span> <span class="token builtin class-name">local</span> <span class="token string">"谁是叶文洁"</span>


INFO: Reading settings from newTest12<span class="token punctuation">\</span>settings.yaml
creating llm client with <span class="token punctuation">{<!-- --></span><span class="token string">'api_key'</span><span class="token builtin class-name">:</span> <span class="token string">'REDACTED,len=6'</span>, <span class="token string">'type'</span><span class="token builtin class-name">:</span> <span class="token string">"openai_chat"</span>, <span class="token string">'model'</span><span class="token builtin class-name">:</span> <span class="token string">'qwen2'</span>, <span class="token string">'max_tokens'</span><span class="token builtin class-name">:</span> <span class="token number">4000</span>, <span class="token string">'temperature'</span><span class="token builtin class-name">:</span> <span class="token number">0.0</span>, <span class="token string">'top_p'</span><span class="token builtin class-name">:</span> <span class="token number">1.0</span>, <span class="token string">'n'</span><span class="token builtin class-name">:</span> <span class="token number">1</span>, <span class="token string">'request_timeout'</span><span class="token builtin class-name">:</span> <span class="token number">180.0</span>, <span class="token string">'api_base'</span><span class="token builtin class-name">:</span> <span class="token string">'http://localhost:11434/v1/'</span>, <span class="token string">'api_version'</span><span class="token builtin class-name">:</span> None, <span class="token string">'organization'</span><span class="token builtin class-name">:</span> None, <span class="token string">'proxy'</span><span class="token builtin class-name">:</span> None, <span class="token string">'cognitive_services_endpoint'</span><span class="token builtin class-name">:</span> None, <span class="token string">'deployment_name'</span><span class="token builtin class-name">:</span> None, <span class="token string">'model_supports_json'</span><span class="token builtin class-name">:</span> True, <span class="token string">'tokens_per_minute'</span><span class="token builtin class-name">:</span> <span class="token number">0</span>, <span class="token string">'requests_per_minute'</span><span class="token builtin class-name">:</span> <span class="token number">0</span>, <span class="token string">'max_retries'</span><span class="token builtin class-name">:</span> <span class="token number">10</span>, <span class="token string">'max_retry_wait'</span><span class="token builtin class-name">:</span> <span class="token number">10.0</span>, <span class="token string">'sleep_on_rate_limit_recommendation'</span><span class="token builtin class-name">:</span> True, <span class="token string">'concurrent_requests'</span><span class="token builtin class-name">:</span> <span class="token number">25</span><span class="token punctuation">}</span>
creating embedding llm client with <span class="token punctuation">{<!-- --></span><span class="token string">'api_key'</span><span class="token builtin class-name">:</span> <span class="token string">'REDACTED,len=9'</span>, <span class="token string">'type'</span><span class="token builtin class-name">:</span> <span class="token string">"openai_embedding"</span>, <span class="token string">'model'</span><span class="token builtin class-name">:</span> <span class="token string">'nomic-ai/nomic-embed-text-v1.5/nomic-embed-text-v1.5.Q8_0.gguf'</span>, <span class="token string">'max_tokens'</span><span class="token builtin class-name">:</span> <span class="token number">4000</span>, <span class="token string">'temperature'</span><span class="token builtin class-name">:</span> <span class="token number">0</span>, <span class="token string">'top_p'</span><span class="token builtin class-name">:</span> <span class="token number">1</span>, <span class="token string">'n'</span><span class="token builtin class-name">:</span> <span class="token number">1</span>, <span class="token string">'request_timeout'</span><span class="token builtin class-name">:</span> <span class="token number">180.0</span>, <span class="token string">'api_base'</span><span class="token builtin class-name">:</span> <span class="token string">'http://localhost:1234/v1'</span>, <span class="token string">'api_version'</span><span class="token builtin class-name">:</span> None, <span class="token string">'organization'</span><span class="token builtin class-name">:</span> None, <span class="token string">'proxy'</span><span class="token builtin class-name">:</span> None, <span class="token string">'cognitive_services_endpoint'</span><span class="token builtin class-name">:</span> None, <span class="token string">'deployment_name'</span><span class="token builtin class-name">:</span> None, <span class="token string">'model_supports_json'</span><span class="token builtin class-name">:</span> None, <span class="token string">'tokens_per_minute'</span><span class="token builtin class-name">:</span> <span class="token number">0</span>, <span class="token string">'requests_per_minute'</span><span class="token builtin class-name">:</span> <span class="token number">0</span>, <span class="token string">'max_retries'</span><span class="token builtin class-name">:</span> <span class="token number">10</span>, <span class="token string">'max_retry_wait'</span><span class="token builtin class-name">:</span> <span class="token number">10.0</span>, <span class="token string">'sleep_on_rate_limit_recommendation'</span><span class="token builtin class-name">:</span> True, <span class="token string">'concurrent_requests'</span><span class="token builtin class-name">:</span> <span class="token number">1</span><span class="token punctuation">}</span>
Error embedding chunk <span class="token punctuation">{<!-- --></span><span class="token string">'OpenAIEmbedding'</span><span class="token builtin class-name">:</span> <span class="token string">'Error code: 400 - {\'</span>error<span class="token punctuation">\</span>': <span class="token string">"\'input\' field must be a string or an array of strings"</span><span class="token punctuation">}</span><span class="token string">'}
Traceback (most recent call last):
  File "D:\ProgramData\miniconda3\envs\graphrag\lib\runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "D:\ProgramData\miniconda3\envs\graphrag\lib\runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "D:\ProgramData\miniconda3\envs\graphrag\lib\site-packages\graphrag\query\__main__.py", line 76, in &lt;module&gt;
    run_local_search(
  File "D:\ProgramData\miniconda3\envs\graphrag\lib\site-packages\graphrag\query\cli.py", line 153, in run_local_search
    result = search_engine.search(query=query)
  File "D:\ProgramData\miniconda3\envs\graphrag\lib\site-packages\graphrag\query\structured_search\local_search\search.py", line 118, in search
    context_text, context_records = self.context_builder.build_context(
  File "D:\ProgramData\miniconda3\envs\graphrag\lib\site-packages\graphrag\query\structured_search\local_search\mixed_context.py", line 139, in build_context
    selected_entities = map_query_to_entities(
  File "D:\ProgramData\miniconda3\envs\graphrag\lib\site-packages\graphrag\query\context_builder\entity_extraction.py", line 55, in map_query_to_entities
    search_results = text_embedding_vectorstore.similarity_search_by_text(
  File "D:\ProgramData\miniconda3\envs\graphrag\lib\site-packages\graphrag\vector_stores\lancedb.py", line 118, in similarity_search_by_text
    query_embedding = text_embedder(text)
  File "D:\ProgramData\miniconda3\envs\graphrag\lib\site-packages\graphrag\query\context_builder\entity_extraction.py", line 57, in &lt;lambda&gt;
    text_embedder=lambda t: text_embedder.embed(t),
  File "D:\ProgramData\miniconda3\envs\graphrag\lib\site-packages\graphrag\query\llm\oai\embedding.py", line 96, in embed
    chunk_embeddings = np.average(chunk_embeddings, axis=0, weights=chunk_lens)
  File "D:\ProgramData\miniconda3\envs\graphrag\lib\site-packages\numpy\lib\function_base.py", line 550, in average
    raise ZeroDivisionError(
ZeroDivisionError: Weights sum to zero, can'</span>t be normalized
</code></pre> 
<ol start="11"><li>开始Indexing处理:</li></ol> 
<pre><code class="prism language-shell">python <span class="token parameter variable">-m</span> graphrag.index <span class="token parameter variable">--root</span> ./ragtest
</code></pre> 
<p>运行效果:</p> 
<pre><code class="prism language-shell"><span class="token punctuation">(</span>graphrag<span class="token punctuation">)</span> D:<span class="token punctuation">\</span>Learn<span class="token punctuation">\</span>GraphRAG<span class="token operator">&gt;</span>python <span class="token parameter variable">-m</span> graphrag.index <span class="token parameter variable">--root</span> ./newTest12
🚀 Reading settings from newTest12<span class="token punctuation">\</span>settings.yaml
D:<span class="token punctuation">\</span>ProgramData<span class="token punctuation">\</span>miniconda3<span class="token punctuation">\</span>envs<span class="token punctuation">\</span>graphrag<span class="token punctuation">\</span>lib<span class="token punctuation">\</span>site-packages<span class="token punctuation">\</span>numpy<span class="token punctuation">\</span>core<span class="token punctuation">\</span>fromnumeric.py:59: FutureWarning:
<span class="token string">'DataFrame.swapaxes'</span> is deprecated and will be removed <span class="token keyword">in</span> a future version. Please use <span class="token string">'DataFrame.transpose'</span> instead.
  <span class="token builtin class-name">return</span> bound<span class="token punctuation">(</span>*args, **kwds<span class="token punctuation">)</span>
🚀 create_base_text_units
                                  <span class="token function">id</span>  <span class="token punctuation">..</span>. n_tokens
<span class="token number">0</span>   eb94998b0499b6271136701074a1d890  <span class="token punctuation">..</span>.      <span class="token number">300</span>
<span class="token number">1</span>   ae83a5ece6993bb8441110c128374267  <span class="token punctuation">..</span>.      <span class="token number">300</span>
<span class="token number">2</span>   8debc287482f854d941a17262b4fe9b4  <span class="token punctuation">..</span>.      <span class="token number">300</span>
<span class="token number">3</span>   0afae36282bd8db18b85ed0ff5c6bfcf  <span class="token punctuation">..</span>.      <span class="token number">300</span>
<span class="token number">4</span>   6029ac47ac05acb22ae6b625c2e726e5  <span class="token punctuation">..</span>.      <span class="token number">300</span>
<span class="token number">5</span>   18a2202cc4756368e833007edc118b83  <span class="token punctuation">..</span>.      <span class="token number">300</span>
<span class="token number">6</span>   0f1ca0e967c49c0eccb0641e4dca1d07  <span class="token punctuation">..</span>.      <span class="token number">300</span>
<span class="token number">7</span>   0f2c27b592f5ed732eb5dbf041475950  <span class="token punctuation">..</span>.      <span class="token number">300</span>
<span class="token number">8</span>   319702df76e338acb4ad3d0e02dd3d6f  <span class="token punctuation">..</span>.      <span class="token number">300</span>
<span class="token number">9</span>   919746c8d00d55401129a3eb6eb335d9  <span class="token punctuation">..</span>.      <span class="token number">300</span>
<span class="token number">10</span>  4cf72e5c48316b181b279c62ada7ee6d  <span class="token punctuation">..</span>.      <span class="token number">300</span>
<span class="token number">11</span>  6a7c6d9db387332aa7d9178d22014fa6  <span class="token punctuation">..</span>.      <span class="token number">300</span>
<span class="token number">12</span>  bd7e44fb9063cf8e02da39443f4c67eb  <span class="token punctuation">..</span>.      <span class="token number">300</span>
<span class="token number">13</span>  3239241f8fba889b9ebd1851c4f68aa5  <span class="token punctuation">..</span>.      <span class="token number">300</span>
<span class="token number">14</span>  c9d05edb3d1a58711f42639e18cdcea2  <span class="token punctuation">..</span>.      <span class="token number">300</span>
<span class="token number">15</span>  a4c53469e9283bad549f1d10568bba4b  <span class="token punctuation">..</span>.      <span class="token number">300</span>
<span class="token number">16</span>  01e50959b91fc167df1bd0fe83f2928b  <span class="token punctuation">..</span>.      <span class="token number">300</span>
<span class="token number">17</span>  91d7b0359c7417bd8c4ff0931c6ba236  <span class="token punctuation">..</span>.      <span class="token number">300</span>
<span class="token number">18</span>  0c2f21e8f141de2a2e03f17a875de54a  <span class="token punctuation">..</span>.      <span class="token number">300</span>
<span class="token number">19</span>  7716c29d83922f69e228eca2c99128ce  <span class="token punctuation">..</span>.      <span class="token number">300</span>
<span class="token number">20</span>  af2ef2f39176a565b509d48ef91f5ca6  <span class="token punctuation">..</span>.      <span class="token number">300</span>
<span class="token number">21</span>  38a919532f499e6c873162a050619f31  <span class="token punctuation">..</span>.      <span class="token number">300</span>
<span class="token number">22</span>  587fbda555a7a3a371ae35b16084f555  <span class="token punctuation">..</span>.      <span class="token number">300</span>
<span class="token number">23</span>  4dbcb435fc91cdbe2bbd4ca075e7df4d  <span class="token punctuation">..</span>.      <span class="token number">300</span>
<span class="token number">24</span>  a08a77fbbf1ea343ef915b776beb4fad  <span class="token punctuation">..</span>.      <span class="token number">300</span>
<span class="token number">25</span>  5d57d8d015e8d98ef355f0f42e114bb0  <span class="token punctuation">..</span>.      <span class="token number">300</span>
<span class="token number">26</span>  cba7a1ca9b4099be67035d5263d3cbab  <span class="token punctuation">..</span>.      <span class="token number">300</span>
<span class="token number">27</span>  403ee5e0425c850acea5f66494ab5590  <span class="token punctuation">..</span>.      <span class="token number">300</span>
<span class="token number">28</span>  f19574bd0b5f9db26188fbe7ce063035  <span class="token punctuation">..</span>.      <span class="token number">300</span>
<span class="token number">29</span>  f0577fe53579d7da7f4bded3cc209220  <span class="token punctuation">..</span>.      <span class="token number">300</span>
<span class="token number">30</span>  01ba18a8dc1159200e6e5418392b2de1  <span class="token punctuation">..</span>.      <span class="token number">300</span>
<span class="token number">31</span>  3bec09f620a572b869885b19b82c520e  <span class="token punctuation">..</span>.      <span class="token number">300</span>
<span class="token number">32</span>  8081e9512c0bd1163378659ea18fa589  <span class="token punctuation">..</span>.      <span class="token number">300</span>
<span class="token number">33</span>  78fb8731a8b51236488c07546bb39ab0  <span class="token punctuation">..</span>.      <span class="token number">300</span>
<span class="token number">34</span>  949ee97d8a055ea639b65db190326580  <span class="token punctuation">..</span>.      <span class="token number">300</span>
<span class="token number">35</span>  d7c149cd8df10e29d99c0a257cbab60f  <span class="token punctuation">..</span>.      <span class="token number">300</span>
<span class="token number">36</span>  42241043af1a3ae708fe06d4644b79fe  <span class="token punctuation">..</span>.      <span class="token number">300</span>
<span class="token number">37</span>  824ff7fe74b00fa6af083d9c42bfe0ef  <span class="token punctuation">..</span>.      <span class="token number">300</span>
<span class="token number">38</span>  43adb8cbfbfb7f8631ff19988d27f8f0  <span class="token punctuation">..</span>.      <span class="token number">300</span>
<span class="token number">39</span>  a621a38808af24546ac397393e8bc6be  <span class="token punctuation">..</span>.      <span class="token number">300</span>
<span class="token number">40</span>  5ee1a053b42c395db7c0abdc55e88af7  <span class="token punctuation">..</span>.      <span class="token number">300</span>
<span class="token number">41</span>  364150258ec05bb31b80141b75d7a5ca  <span class="token punctuation">..</span>.      <span class="token number">300</span>
<span class="token number">42</span>  d760b8e30ecd977add71ba4274b0c9dd  <span class="token punctuation">..</span>.      <span class="token number">300</span>
<span class="token number">43</span>  ebf935b232b056a6973cb6763a532a43  <span class="token punctuation">..</span>.      <span class="token number">300</span>
<span class="token number">44</span>  299966570cf5d14d7d46a4a81555907b  <span class="token punctuation">..</span>.      <span class="token number">300</span>
<span class="token number">45</span>  d6e4272bf5306dd8d1054e9a56ad7114  <span class="token punctuation">..</span>.      <span class="token number">200</span>

<span class="token punctuation">[</span><span class="token number">46</span> rows x <span class="token number">5</span> columns<span class="token punctuation">]</span>
🚀 create_base_extracted_entities
                                        entity_graph
<span class="token number">0</span>  <span class="token operator">&lt;</span>graphml <span class="token assign-left variable">xmlns</span><span class="token operator">=</span><span class="token string">"http://graphml.graphdrawing.or...
D:\ProgramData\miniconda3<span class="token entity" title="\e">\e</span>nvs\graphrag\lib\site-packages\datashaper<span class="token entity" title="\e">\e</span>ngine<span class="token entity" title="\v">\v</span>erbs<span class="token entity" title="\c">\c</span>onvert.py:65: FutureWarning:
errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing <span class="token variable"><span class="token variable">`</span>errors<span class="token variable">`</span></span> and catch
exceptions explicitly instead
  column_numeric = cast(pd.Series, pd.to_numeric(column, errors="</span>ignore<span class="token string">"))
🚀 create_final_covariates
                                      id human_readable_id  ...                        document_ids n_tokens
0   fa863911-f68e-4f11-bf1f-5c074ce528c8                 1  ...  [9907241b0721ab0f48fbbc9d784175eb]      300
1   6245da46-086e-476c-b4b7-b3efc1bd82bb                 2  ...  [9907241b0721ab0f48fbbc9d784175eb]      300
2   7f4ee402-0065-4b2e-a5d8-3eef944b18f3                 3  ...  [9907241b0721ab0f48fbbc9d784175eb]      300
3   1927e65b-3a8c-4c3a-bda8-4bbc1804737f                 4  ...  [9907241b0721ab0f48fbbc9d784175eb]      300
4   ebb53a51-9f03-4ede-924b-93f6f74320da                 5  ...  [9907241b0721ab0f48fbbc9d784175eb]      300
..                                   ...               ...  ...                                 ...      ...
56  81dc46bc-1c00-46a8-b745-aae710bfd949                57  ...  [9907241b0721ab0f48fbbc9d784175eb]      300
57  c96c929d-80be-4fc5-a865-ced074fe2f01                58  ...  [9907241b0721ab0f48fbbc9d784175eb]      300
58  785b12a8-3669-48fc-a017-f8fa1b60348e                59  ...  [9907241b0721ab0f48fbbc9d784175eb]      300
59  47cb429c-c402-4eb9-bcab-4c427cea6176                60  ...  [9907241b0721ab0f48fbbc9d784175eb]      300
60  701529fc-1499-4efe-bdac-0bc3a49a942c                61  ...  [9907241b0721ab0f48fbbc9d784175eb]      200

[61 rows x 16 columns]
🚀 create_summarized_entities
                                        entity_graph
0  &lt;graphml xmlns="</span>http://graphml.graphdrawing.or<span class="token punctuation">..</span>.
🚀 join_text_units_to_covariate_ids
                        text_unit_id  <span class="token punctuation">..</span>.                                <span class="token function">id</span>
<span class="token number">0</span>   eb94998b0499b6271136701074a1d890  <span class="token punctuation">..</span>.  eb94998b0499b6271136701074a1d890
<span class="token number">1</span>   ae83a5ece6993bb8441110c128374267  <span class="token punctuation">..</span>.  ae83a5ece6993bb8441110c128374267
<span class="token number">2</span>   8debc287482f854d941a17262b4fe9b4  <span class="token punctuation">..</span>.  8debc287482f854d941a17262b4fe9b4
<span class="token number">3</span>   0afae36282bd8db18b85ed0ff5c6bfcf  <span class="token punctuation">..</span>.  0afae36282bd8db18b85ed0ff5c6bfcf
<span class="token number">4</span>   6029ac47ac05acb22ae6b625c2e726e5  <span class="token punctuation">..</span>.  6029ac47ac05acb22ae6b625c2e726e5
<span class="token number">5</span>   18a2202cc4756368e833007edc118b83  <span class="token punctuation">..</span>.  18a2202cc4756368e833007edc118b83
<span class="token number">6</span>   0f1ca0e967c49c0eccb0641e4dca1d07  <span class="token punctuation">..</span>.  0f1ca0e967c49c0eccb0641e4dca1d07
<span class="token number">7</span>   0f2c27b592f5ed732eb5dbf041475950  <span class="token punctuation">..</span>.  0f2c27b592f5ed732eb5dbf041475950
<span class="token number">8</span>   319702df76e338acb4ad3d0e02dd3d6f  <span class="token punctuation">..</span>.  319702df76e338acb4ad3d0e02dd3d6f
<span class="token number">9</span>   919746c8d00d55401129a3eb6eb335d9  <span class="token punctuation">..</span>.  919746c8d00d55401129a3eb6eb335d9
<span class="token number">10</span>  4cf72e5c48316b181b279c62ada7ee6d  <span class="token punctuation">..</span>.  4cf72e5c48316b181b279c62ada7ee6d
<span class="token number">11</span>  6a7c6d9db387332aa7d9178d22014fa6  <span class="token punctuation">..</span>.  6a7c6d9db387332aa7d9178d22014fa6
<span class="token number">12</span>  bd7e44fb9063cf8e02da39443f4c67eb  <span class="token punctuation">..</span>.  bd7e44fb9063cf8e02da39443f4c67eb
<span class="token number">13</span>  3239241f8fba889b9ebd1851c4f68aa5  <span class="token punctuation">..</span>.  3239241f8fba889b9ebd1851c4f68aa5
<span class="token number">14</span>  c9d05edb3d1a58711f42639e18cdcea2  <span class="token punctuation">..</span>.  c9d05edb3d1a58711f42639e18cdcea2
<span class="token number">15</span>  a4c53469e9283bad549f1d10568bba4b  <span class="token punctuation">..</span>.  a4c53469e9283bad549f1d10568bba4b
<span class="token number">16</span>  01e50959b91fc167df1bd0fe83f2928b  <span class="token punctuation">..</span>.  01e50959b91fc167df1bd0fe83f2928b
<span class="token number">17</span>  91d7b0359c7417bd8c4ff0931c6ba236  <span class="token punctuation">..</span>.  91d7b0359c7417bd8c4ff0931c6ba236
<span class="token number">18</span>  0c2f21e8f141de2a2e03f17a875de54a  <span class="token punctuation">..</span>.  0c2f21e8f141de2a2e03f17a875de54a
<span class="token number">19</span>  7716c29d83922f69e228eca2c99128ce  <span class="token punctuation">..</span>.  7716c29d83922f69e228eca2c99128ce
<span class="token number">20</span>  af2ef2f39176a565b509d48ef91f5ca6  <span class="token punctuation">..</span>.  af2ef2f39176a565b509d48ef91f5ca6
<span class="token number">21</span>  38a919532f499e6c873162a050619f31  <span class="token punctuation">..</span>.  38a919532f499e6c873162a050619f31
<span class="token number">22</span>  587fbda555a7a3a371ae35b16084f555  <span class="token punctuation">..</span>.  587fbda555a7a3a371ae35b16084f555
<span class="token number">23</span>  4dbcb435fc91cdbe2bbd4ca075e7df4d  <span class="token punctuation">..</span>.  4dbcb435fc91cdbe2bbd4ca075e7df4d
<span class="token number">24</span>  a08a77fbbf1ea343ef915b776beb4fad  <span class="token punctuation">..</span>.  a08a77fbbf1ea343ef915b776beb4fad
<span class="token number">25</span>  5d57d8d015e8d98ef355f0f42e114bb0  <span class="token punctuation">..</span>.  5d57d8d015e8d98ef355f0f42e114bb0
<span class="token number">26</span>  f0577fe53579d7da7f4bded3cc209220  <span class="token punctuation">..</span>.  f0577fe53579d7da7f4bded3cc209220
<span class="token number">27</span>  8081e9512c0bd1163378659ea18fa589  <span class="token punctuation">..</span>.  8081e9512c0bd1163378659ea18fa589
<span class="token number">28</span>  78fb8731a8b51236488c07546bb39ab0  <span class="token punctuation">..</span>.  78fb8731a8b51236488c07546bb39ab0
<span class="token number">29</span>  949ee97d8a055ea639b65db190326580  <span class="token punctuation">..</span>.  949ee97d8a055ea639b65db190326580
<span class="token number">30</span>  d7c149cd8df10e29d99c0a257cbab60f  <span class="token punctuation">..</span>.  d7c149cd8df10e29d99c0a257cbab60f
<span class="token number">31</span>  42241043af1a3ae708fe06d4644b79fe  <span class="token punctuation">..</span>.  42241043af1a3ae708fe06d4644b79fe
<span class="token number">32</span>  824ff7fe74b00fa6af083d9c42bfe0ef  <span class="token punctuation">..</span>.  824ff7fe74b00fa6af083d9c42bfe0ef
<span class="token number">33</span>  a621a38808af24546ac397393e8bc6be  <span class="token punctuation">..</span>.  a621a38808af24546ac397393e8bc6be
<span class="token number">34</span>  ebf935b232b056a6973cb6763a532a43  <span class="token punctuation">..</span>.  ebf935b232b056a6973cb6763a532a43
<span class="token number">35</span>  299966570cf5d14d7d46a4a81555907b  <span class="token punctuation">..</span>.  299966570cf5d14d7d46a4a81555907b
<span class="token number">36</span>  d6e4272bf5306dd8d1054e9a56ad7114  <span class="token punctuation">..</span>.  d6e4272bf5306dd8d1054e9a56ad7114

<span class="token punctuation">[</span><span class="token number">37</span> rows x <span class="token number">3</span> columns<span class="token punctuation">]</span>
🚀 create_base_entity_graph
   level                                    clustered_graph
<span class="token number">0</span>      <span class="token number">0</span>  <span class="token operator">&lt;</span>graphml <span class="token assign-left variable">xmlns</span><span class="token operator">=</span><span class="token string">"http://graphml.graphdrawing.or...
D:\ProgramData\miniconda3<span class="token entity" title="\e">\e</span>nvs\graphrag\lib\site-packages<span class="token entity" title="\n">\n</span>umpy<span class="token entity" title="\c">\c</span>ore<span class="token entity" title="\f">\f</span>romnumeric.py:59: FutureWarning:
'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.
  return bound(*args, **kwds)
D:\ProgramData\miniconda3<span class="token entity" title="\e">\e</span>nvs\graphrag\lib\site-packages<span class="token entity" title="\n">\n</span>umpy<span class="token entity" title="\c">\c</span>ore<span class="token entity" title="\f">\f</span>romnumeric.py:59: FutureWarning:
'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.
  return bound(*args, **kwds)
🚀 create_final_entities
                                  id  ...                              description_embedding
0   b45241d70f0e43fca764df95b2b81f77  ...  [-0.037392858415842056, 0.06525952368974686, -...
1   4119fd06010c494caa07f439b333f4c5  ...  [0.010907179675996304, 0.026875361800193787, -...
2   d3835bf3dda84ead99deadbeac5d0d7d  ...  [0.054428134113550186, -9.018656419357285e-05,...
3   077d2820ae1845bcbb1803379a3d1eae  ...  [0.020732643082737923, 0.0034371891524642706, ...
4   3671ea0dd4e84c1a9b02c5ab2c8f4bac  ...  [-0.0012893152888864279, 0.037432845681905746,...
..                               ...  ...                                                ...
59  958beecdb5bb4060948415ffd75d2b03  ...  [0.01642344333231449, 0.021773478016257286, -0...
60  b999ed77e19e4f85b7f1ae79af5c002a  ...  [0.002400514902547002, 0.047308988869190216, -...
61  48c0c4d72da74ff5bb926fa0c856d1a7  ...  [-0.01692129857838154, 0.0539858303964138, -0....
62  4f3c97517f794ebfb49c4c6315f9cf23  ...  [0.0010956701589748263, 0.04648151248693466, -...
63  1745a2485a9443bab76587ad650e9be0  ...  [-0.007561820093542337, 0.045520562678575516, ...

[64 rows x 8 columns]
D:\ProgramData\miniconda3<span class="token entity" title="\e">\e</span>nvs\graphrag\lib\site-packages<span class="token entity" title="\n">\n</span>umpy<span class="token entity" title="\c">\c</span>ore<span class="token entity" title="\f">\f</span>romnumeric.py:59: FutureWarning:
'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.
  return bound(*args, **kwds)
D:\ProgramData\miniconda3<span class="token entity" title="\e">\e</span>nvs\graphrag\lib\site-packages\datashaper<span class="token entity" title="\e">\e</span>ngine<span class="token entity" title="\v">\v</span>erbs<span class="token entity" title="\c">\c</span>onvert.py:72: FutureWarning:
errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing <span class="token variable"><span class="token variable">`</span>errors<span class="token variable">`</span></span> and catch
exceptions explicitly instead
  datetime_column = pd.to_datetime(column, errors="</span>ignore<span class="token string">")
D:\ProgramData\miniconda3<span class="token entity" title="\e">\e</span>nvs\graphrag\lib\site-packages\datashaper<span class="token entity" title="\e">\e</span>ngine<span class="token entity" title="\v">\v</span>erbs<span class="token entity" title="\c">\c</span>onvert.py:72: UserWarning: Could not
infer format, so each element will be parsed individually, falling back to <span class="token variable"><span class="token variable">`</span>dateutil<span class="token variable">`</span></span>. To ensure parsing is consistent
and as-expected, please specify a format.
  datetime_column = pd.to_datetime(column, errors="</span>ignore<span class="token string">")
🚀 create_final_nodes
    level     title            type  ...                 top_level_node_id  x  y
0       0    "</span>红色联合<span class="token string">"  "</span>ORGANIZATION<span class="token string">"  ...  b45241d70f0e43fca764df95b2b81f77  0  0
1       0  "</span>四·二八兵团<span class="token string">"  "</span>ORGANIZATION<span class="token string">"  ...  4119fd06010c494caa07f439b333f4c5  0  0
2       0   "</span><span class="token number">1967</span>年<span class="token string">"         "</span>EVENT<span class="token string">"  ...  d3835bf3dda84ead99deadbeac5d0d7d  0  0
3       0    "</span>安眠药瓶<span class="token string">"        "</span>OBJECT<span class="token string">"  ...  077d2820ae1845bcbb1803379a3d1eae  0  0
4       0     "</span>铁炉子<span class="token string">"           "</span>GEO<span class="token string">"  ...  3671ea0dd4e84c1a9b02c5ab2c8f4bac  0  0
..    ...       ...             ...  ...                               ... .. ..
59      0     "</span>老校工<span class="token string">"  "</span>ORGANIZATION<span class="token string">"  ...  958beecdb5bb4060948415ffd75d2b03  0  0
60      0   "</span>教工宿舍楼<span class="token string">"           "</span>GEO<span class="token string">"  ...  b999ed77e19e4f85b7f1ae79af5c002a  0  0
61      0     "</span>阮老师<span class="token string">"        "</span>PERSON<span class="token string">"  ...  48c0c4d72da74ff5bb926fa0c856d1a7  0  0
62      0      "</span>阮雯<span class="token string">"        "</span>PERSON<span class="token string">"  ...  4f3c97517f794ebfb49c4c6315f9cf23  0  0
63      0      "</span>文洁<span class="token string">"        "</span>PERSON<span class="token string">"  ...  1745a2485a9443bab76587ad650e9be0  0  0

[64 rows x 14 columns]
D:\ProgramData\miniconda3<span class="token entity" title="\e">\e</span>nvs\graphrag\lib\site-packages<span class="token entity" title="\n">\n</span>umpy<span class="token entity" title="\c">\c</span>ore<span class="token entity" title="\f">\f</span>romnumeric.py:59: FutureWarning:
'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.
  return bound(*args, **kwds)
D:\ProgramData\miniconda3<span class="token entity" title="\e">\e</span>nvs\graphrag\lib\site-packages<span class="token entity" title="\n">\n</span>umpy<span class="token entity" title="\c">\c</span>ore<span class="token entity" title="\f">\f</span>romnumeric.py:59: FutureWarning:
'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.
  return bound(*args, **kwds)
🚀 create_final_communities
  id        title  ...                                   relationship_ids
text_unit_ids
0  0  Community 0  ...  [32e6ccab20d94029811127dbbe424c64, 94a964c6992...
[0f2c27b592f5ed732eb5dbf041475950,a621a38808af...

[1 rows x 6 columns]
🚀 join_text_units_to_entity_ids
                       text_unit_ids  ...                                id
0   0f1ca0e967c49c0eccb0641e4dca1d07  ...  0f1ca0e967c49c0eccb0641e4dca1d07
1   18a2202cc4756368e833007edc118b83  ...  18a2202cc4756368e833007edc118b83
2   6029ac47ac05acb22ae6b625c2e726e5  ...  6029ac47ac05acb22ae6b625c2e726e5
3   eb94998b0499b6271136701074a1d890  ...  eb94998b0499b6271136701074a1d890
4   0c2f21e8f141de2a2e03f17a875de54a  ...  0c2f21e8f141de2a2e03f17a875de54a
5   0f2c27b592f5ed732eb5dbf041475950  ...  0f2c27b592f5ed732eb5dbf041475950
6   319702df76e338acb4ad3d0e02dd3d6f  ...  319702df76e338acb4ad3d0e02dd3d6f
7   3bec09f620a572b869885b19b82c520e  ...  3bec09f620a572b869885b19b82c520e
8   403ee5e0425c850acea5f66494ab5590  ...  403ee5e0425c850acea5f66494ab5590
9   5d57d8d015e8d98ef355f0f42e114bb0  ...  5d57d8d015e8d98ef355f0f42e114bb0
10  5ee1a053b42c395db7c0abdc55e88af7  ...  5ee1a053b42c395db7c0abdc55e88af7
11  949ee97d8a055ea639b65db190326580  ...  949ee97d8a055ea639b65db190326580
12  af2ef2f39176a565b509d48ef91f5ca6  ...  af2ef2f39176a565b509d48ef91f5ca6
13  f19574bd0b5f9db26188fbe7ce063035  ...  f19574bd0b5f9db26188fbe7ce063035
14  ae83a5ece6993bb8441110c128374267  ...  ae83a5ece6993bb8441110c128374267
15  8debc287482f854d941a17262b4fe9b4  ...  8debc287482f854d941a17262b4fe9b4
16  0afae36282bd8db18b85ed0ff5c6bfcf  ...  0afae36282bd8db18b85ed0ff5c6bfcf
17  3239241f8fba889b9ebd1851c4f68aa5  ...  3239241f8fba889b9ebd1851c4f68aa5
18  c9d05edb3d1a58711f42639e18cdcea2  ...  c9d05edb3d1a58711f42639e18cdcea2
19  a621a38808af24546ac397393e8bc6be  ...  a621a38808af24546ac397393e8bc6be
20  919746c8d00d55401129a3eb6eb335d9  ...  919746c8d00d55401129a3eb6eb335d9
21  4cf72e5c48316b181b279c62ada7ee6d  ...  4cf72e5c48316b181b279c62ada7ee6d
22  6a7c6d9db387332aa7d9178d22014fa6  ...  6a7c6d9db387332aa7d9178d22014fa6
23  8081e9512c0bd1163378659ea18fa589  ...  8081e9512c0bd1163378659ea18fa589
24  91d7b0359c7417bd8c4ff0931c6ba236  ...  91d7b0359c7417bd8c4ff0931c6ba236
25  a4c53469e9283bad549f1d10568bba4b  ...  a4c53469e9283bad549f1d10568bba4b
26  bd7e44fb9063cf8e02da39443f4c67eb  ...  bd7e44fb9063cf8e02da39443f4c67eb
27  d7c149cd8df10e29d99c0a257cbab60f  ...  d7c149cd8df10e29d99c0a257cbab60f
28  f0577fe53579d7da7f4bded3cc209220  ...  f0577fe53579d7da7f4bded3cc209220
29  01e50959b91fc167df1bd0fe83f2928b  ...  01e50959b91fc167df1bd0fe83f2928b
30  7716c29d83922f69e228eca2c99128ce  ...  7716c29d83922f69e228eca2c99128ce
31  38a919532f499e6c873162a050619f31  ...  38a919532f499e6c873162a050619f31
32  587fbda555a7a3a371ae35b16084f555  ...  587fbda555a7a3a371ae35b16084f555
33  4dbcb435fc91cdbe2bbd4ca075e7df4d  ...  4dbcb435fc91cdbe2bbd4ca075e7df4d
34  a08a77fbbf1ea343ef915b776beb4fad  ...  a08a77fbbf1ea343ef915b776beb4fad
35  cba7a1ca9b4099be67035d5263d3cbab  ...  cba7a1ca9b4099be67035d5263d3cbab
36  01ba18a8dc1159200e6e5418392b2de1  ...  01ba18a8dc1159200e6e5418392b2de1
37  78fb8731a8b51236488c07546bb39ab0  ...  78fb8731a8b51236488c07546bb39ab0
38  42241043af1a3ae708fe06d4644b79fe  ...  42241043af1a3ae708fe06d4644b79fe
39  824ff7fe74b00fa6af083d9c42bfe0ef  ...  824ff7fe74b00fa6af083d9c42bfe0ef
40  43adb8cbfbfb7f8631ff19988d27f8f0  ...  43adb8cbfbfb7f8631ff19988d27f8f0
41  299966570cf5d14d7d46a4a81555907b  ...  299966570cf5d14d7d46a4a81555907b
42  364150258ec05bb31b80141b75d7a5ca  ...  364150258ec05bb31b80141b75d7a5ca
43  d760b8e30ecd977add71ba4274b0c9dd  ...  d760b8e30ecd977add71ba4274b0c9dd
44  ebf935b232b056a6973cb6763a532a43  ...  ebf935b232b056a6973cb6763a532a43
45  d6e4272bf5306dd8d1054e9a56ad7114  ...  d6e4272bf5306dd8d1054e9a56ad7114

[46 rows x 3 columns]
D:\ProgramData\miniconda3<span class="token entity" title="\e">\e</span>nvs\graphrag\lib\site-packages<span class="token entity" title="\n">\n</span>umpy<span class="token entity" title="\c">\c</span>ore<span class="token entity" title="\f">\f</span>romnumeric.py:59: FutureWarning:
'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.
  return bound(*args, **kwds)
D:\ProgramData\miniconda3<span class="token entity" title="\e">\e</span>nvs\graphrag\lib\site-packages<span class="token entity" title="\n">\n</span>umpy<span class="token entity" title="\c">\c</span>ore<span class="token entity" title="\f">\f</span>romnumeric.py:59: FutureWarning:
'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.
  return bound(*args, **kwds)
D:\ProgramData\miniconda3<span class="token entity" title="\e">\e</span>nvs\graphrag\lib\site-packages\datashaper<span class="token entity" title="\e">\e</span>ngine<span class="token entity" title="\v">\v</span>erbs<span class="token entity" title="\c">\c</span>onvert.py:65: FutureWarning:
errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing <span class="token variable"><span class="token variable">`</span>errors<span class="token variable">`</span></span> and catch
exceptions explicitly instead
  column_numeric = cast(pd.Series, pd.to_numeric(column, errors="</span>ignore<span class="token string">"))
🚀 create_final_relationships
         source                 target  weight  ... source_degree target_degree rank
0         "</span>SHE<span class="token string">"  "</span>CULTURAL REVOLUTION<span class="token string">"     1.0  ...             1             2    3
1    "</span>THE CITY<span class="token string">"  "</span>CULTURAL REVOLUTION<span class="token string">"     1.0  ...             1             2    3
2  "</span>RED GUARDS<span class="token string">"     "</span>FEMALE RED GUARD<span class="token string">"     1.0  ...             2             1    3
3  "</span>RED GUARDS<span class="token string">"       "</span>MALE RED GUARD<span class="token string">"     1.0  ...             2             1    3
4        "</span>小红卫兵<span class="token string">"          "</span>QUESTIONING<span class="token string">"     1.0  ...             1             1    2

[5 rows x 10 columns]
🚀 join_text_units_to_relationship_ids
                                 id                                   relationship_ids
0  0f2c27b592f5ed732eb5dbf041475950  [32e6ccab20d94029811127dbbe424c64, 94a964c6992...
1  cba7a1ca9b4099be67035d5263d3cbab  [1eb829d0ace042089f0746f78729696c, 015e7b58d1a...
2  8081e9512c0bd1163378659ea18fa589                 [26f88ab3e2e04c33a459ad6270ade565]
🚀 create_final_community_reports
  community  ...                                    id
0         0  ...  a1ceb1f1-c824-420b-a93f-2a76e83a4398

[1 rows x 10 columns]
🚀 create_final_text_units
                                  id  ...                                      covariate_ids
0   0f2c27b592f5ed732eb5dbf041475950  ...  [2c940a06-373b-402e-9203-b7b43b5ff0a4, d5dcbf1...
1   8081e9512c0bd1163378659ea18fa589  ...  [4a8f80d6-6509-4470-a6f2-788fbe81f52e, cbc8bf5...
2   eb94998b0499b6271136701074a1d890  ...  [fa863911-f68e-4f11-bf1f-5c074ce528c8, 6245da4...
3   ae83a5ece6993bb8441110c128374267  ...             [1927e65b-3a8c-4c3a-bda8-4bbc1804737f]
4   8debc287482f854d941a17262b4fe9b4  ...
5   0afae36282bd8db18b85ed0ff5c6bfcf  ...  [5e0d4564-20f6-4d9e-b562-7ffe3f44278d, 2069b5d...
6   6029ac47ac05acb22ae6b625c2e726e5  ...  [f3a2ef27-fb45-473a-bbc9-e43cb9d34d1c, 63dd709...
7   18a2202cc4756368e833007edc118b83  ...             [0eb5023a-8012-4881-8593-2de54301c8bb]
8   0f1ca0e967c49c0eccb0641e4dca1d07  ...
9   319702df76e338acb4ad3d0e02dd3d6f  ...             [423c8608-0d59-41f2-9197-ae612f1239e0]
10  919746c8d00d55401129a3eb6eb335d9  ...             [3d7ecd82-20ac-438e-ac86-997f6ad58cc5]
11  4cf72e5c48316b181b279c62ada7ee6d  ...  [82df9600-0bb7-4d0b-950c-067740692784, f89ecbc...
12  6a7c6d9db387332aa7d9178d22014fa6  ...             [1d4aff9a-f347-4aea-b255-8b9c092421c4]
13  bd7e44fb9063cf8e02da39443f4c67eb  ...
14  3239241f8fba889b9ebd1851c4f68aa5  ...  [87efcce8-fbfb-4806-b2ce-834b2a7327c9, aecb7f3...
15  c9d05edb3d1a58711f42639e18cdcea2  ...             [467b2889-ad04-4d39-b84f-d0567fe220ce]
16  a4c53469e9283bad549f1d10568bba4b  ...
17  01e50959b91fc167df1bd0fe83f2928b  ...             [8afcb698-9fb9-4ee9-bb38-49c854f1f9b6]
18  91d7b0359c7417bd8c4ff0931c6ba236  ...
19  0c2f21e8f141de2a2e03f17a875de54a  ...             [68e16f47-8b94-4f3f-bf8f-30042b0d797e]
20  7716c29d83922f69e228eca2c99128ce  ...  [bf2f48b8-3f39-453c-a020-b8e3c4937f43, f2593f9...
21  af2ef2f39176a565b509d48ef91f5ca6  ...             [9f6423b6-3168-4650-bc27-e7f7d3b4eee1]
22  38a919532f499e6c873162a050619f31  ...             [5a98452e-b66f-4ba8-995a-384a9907424a]
23  587fbda555a7a3a371ae35b16084f555  ...  [628e6f7c-b9ef-494f-a2b6-c5e9ffe58fab, 9943f75...
24  4dbcb435fc91cdbe2bbd4ca075e7df4d  ...             [141cdefd-3e39-41d3-9a05-7b4d3a0e3cda]
25  a08a77fbbf1ea343ef915b776beb4fad  ...             [11d29b8f-f528-455a-af29-0af3dd9c1f69]
26  5d57d8d015e8d98ef355f0f42e114bb0  ...  [b26c0619-4051-4b31-80bb-ba064c7153bd, c12d27f...
27  f0577fe53579d7da7f4bded3cc209220  ...             [1b5269e5-7cdd-4485-ae8d-ed7dffaadda4]
28  78fb8731a8b51236488c07546bb39ab0  ...
29  949ee97d8a055ea639b65db190326580  ...             [97e3724c-eca5-43ed-a308-f23296458464]
30  d7c149cd8df10e29d99c0a257cbab60f  ...             [94eb196e-5a69-4dd4-87dd-92746a88215c]
31  42241043af1a3ae708fe06d4644b79fe  ...             [56c81b53-0bfd-44e3-98dd-3b69d4997b68]
32  824ff7fe74b00fa6af083d9c42bfe0ef  ...             [81dc46bc-1c00-46a8-b745-aae710bfd949]
33  a621a38808af24546ac397393e8bc6be  ...
34  ebf935b232b056a6973cb6763a532a43  ...             [785b12a8-3669-48fc-a017-f8fa1b60348e]
35  299966570cf5d14d7d46a4a81555907b  ...             [47cb429c-c402-4eb9-bcab-4c427cea6176]
36  d6e4272bf5306dd8d1054e9a56ad7114  ...             [701529fc-1499-4efe-bdac-0bc3a49a942c]
37  cba7a1ca9b4099be67035d5263d3cbab  ...                                               None
38  403ee5e0425c850acea5f66494ab5590  ...                                               None
39  f19574bd0b5f9db26188fbe7ce063035  ...                                               None
40  01ba18a8dc1159200e6e5418392b2de1  ...                                               None
41  3bec09f620a572b869885b19b82c520e  ...                                               None
42  43adb8cbfbfb7f8631ff19988d27f8f0  ...                                               None
43  5ee1a053b42c395db7c0abdc55e88af7  ...                                               None
44  364150258ec05bb31b80141b75d7a5ca  ...                                               None
45  d760b8e30ecd977add71ba4274b0c9dd  ...                                               None

[46 rows x 7 columns]
D:\ProgramData\miniconda3<span class="token entity" title="\e">\e</span>nvs\graphrag\lib\site-packages\datashaper<span class="token entity" title="\e">\e</span>ngine<span class="token entity" title="\v">\v</span>erbs<span class="token entity" title="\c">\c</span>onvert.py:72: FutureWarning:
errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing <span class="token variable"><span class="token variable">`</span>errors<span class="token variable">`</span></span> and catch
exceptions explicitly instead
  datetime_column = pd.to_datetime(column, errors="</span>ignore"<span class="token punctuation">)</span>
🚀 create_base_documents
                                 <span class="token function">id</span>  <span class="token punctuation">..</span>.   title
<span class="token number">0</span>  9907241b0721ab0f48fbbc9d784175eb  <span class="token punctuation">..</span>.  01.txt

<span class="token punctuation">[</span><span class="token number">1</span> rows x <span class="token number">4</span> columns<span class="token punctuation">]</span>
🚀 create_final_documents
                                 <span class="token function">id</span>  <span class="token punctuation">..</span>.   title
<span class="token number">0</span>  9907241b0721ab0f48fbbc9d784175eb  <span class="token punctuation">..</span>.  01.txt

<span class="token punctuation">[</span><span class="token number">1</span> rows x <span class="token number">4</span> columns<span class="token punctuation">]</span>
⠏ GraphRAG Indexer
├── Loading Input <span class="token punctuation">(</span>text<span class="token punctuation">)</span> - <span class="token number">1</span> files loaded <span class="token punctuation">(</span><span class="token number">0</span> filtered<span class="token punctuation">)</span> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ <span class="token number">100</span>% <span class="token number">0</span>:00:00 <span class="token number">0</span>:00:00
├── create_base_text_units
├── create_base_extracted_entities
├── create_final_covariates
├── create_summarized_entities
├── join_text_units_to_covariate_ids
├── create_base_entity_graph
├── create_final_entities
├── create_final_nodes
├── create_final_communities
├── join_text_units_to_entity_ids
├── create_final_relationships
├── join_text_units_to_relationship_ids
├── create_final_community_reports
├── create_final_text_units
├── create_base_documents
└── create_final_documents
🚀 All workflows completed successfully.
</code></pre> 
<p>12 . 执行全局查询<code>global Search</code>:</p> 
<pre><code class="prism language-shell">python <span class="token parameter variable">-m</span> graphrag.query <span class="token parameter variable">--root</span> ./newTest12 <span class="token parameter variable">--method</span> global <span class="token string">"谁是叶文洁"</span>
</code></pre> 
<p>运行效果:</p> 
<pre><code class="prism language-shell"><span class="token punctuation">(</span>graphrag<span class="token punctuation">)</span> D:<span class="token punctuation">\</span>Learn<span class="token punctuation">\</span>GraphRAG<span class="token operator">&gt;</span>python <span class="token parameter variable">-m</span> graphrag.query <span class="token parameter variable">--root</span> ./newTest12 <span class="token parameter variable">--method</span> global <span class="token string">"谁是叶文洁"</span>


INFO: Reading settings from newTest12<span class="token punctuation">\</span>settings.yaml
creating llm client with <span class="token punctuation">{<!-- --></span><span class="token string">'api_key'</span><span class="token builtin class-name">:</span> <span class="token string">'REDACTED,len=6'</span>, <span class="token string">'type'</span><span class="token builtin class-name">:</span> <span class="token string">"openai_chat"</span>, <span class="token string">'model'</span><span class="token builtin class-name">:</span> <span class="token string">'qwen2'</span>, <span class="token string">'max_tokens'</span><span class="token builtin class-name">:</span> <span class="token number">4000</span>, <span class="token string">'temperature'</span><span class="token builtin class-name">:</span> <span class="token number">0.0</span>, <span class="token string">'top_p'</span><span class="token builtin class-name">:</span> <span class="token number">1.0</span>, <span class="token string">'n'</span><span class="token builtin class-name">:</span> <span class="token number">1</span>, <span class="token string">'request_timeout'</span><span class="token builtin class-name">:</span> <span class="token number">180.0</span>, <span class="token string">'api_base'</span><span class="token builtin class-name">:</span> <span class="token string">'http://localhost:11434/v1/'</span>, <span class="token string">'api_version'</span><span class="token builtin class-name">:</span> None, <span class="token string">'organization'</span><span class="token builtin class-name">:</span> None, <span class="token string">'proxy'</span><span class="token builtin class-name">:</span> None, <span class="token string">'cognitive_services_endpoint'</span><span class="token builtin class-name">:</span> None, <span class="token string">'deployment_name'</span><span class="token builtin class-name">:</span> None, <span class="token string">'model_supports_json'</span><span class="token builtin class-name">:</span> True, <span class="token string">'tokens_per_minute'</span><span class="token builtin class-name">:</span> <span class="token number">0</span>, <span class="token string">'requests_per_minute'</span><span class="token builtin class-name">:</span> <span class="token number">0</span>, <span class="token string">'max_retries'</span><span class="token builtin class-name">:</span> <span class="token number">10</span>, <span class="token string">'max_retry_wait'</span><span class="token builtin class-name">:</span> <span class="token number">10.0</span>, <span class="token string">'sleep_on_rate_limit_recommendation'</span><span class="token builtin class-name">:</span> True, <span class="token string">'concurrent_requests'</span><span class="token builtin class-name">:</span> <span class="token number">25</span><span class="token punctuation">}</span>

SUCCESS: Global Search Response: 叶文洁是一位在《三体》系列小说中扮演重要角色的科学家。她是中国第一位天线物理学家，在故事早期阶段对研究三体文明做出了贡献。

根据分析师1的报告，叶文洁的身份和背景在《三体》系列中被详细描绘。她是该系列中的关键人物之一，通过她的科学工作和对三体文明的研究，为整个故事的发展提供了重要的推动力。因此，我们可以得出结论：叶文洁是一位在科幻小说《三体》系列中具有重要地位的科学家角色。

请注意，分析师报告中提到的具体数据记录（如编号2、7、34、46、64等）用于支持上述信息，但为了简洁起见，在此未详细列出。这些数据记录提供了关于叶文洁在小说中的具体描述和背景信息。
</code></pre> 
<ol start="13"><li>执行局部查询<code>Local search</code>:</li></ol> 
<pre><code class="prism language-shell">python <span class="token parameter variable">-m</span> graphrag.query <span class="token parameter variable">--root</span> ./newTest12 <span class="token parameter variable">--method</span> <span class="token builtin class-name">local</span> <span class="token string">"谁是叶文洁"</span>
</code></pre> 
<p>运行效果:</p> 
<pre><code class="prism language-shell">SUCCESS: Local Search Response: 叶文洁是中国科幻小说《三体》系列中的一个主要角色，由刘慈欣所创造。在故事中，她是一位天体物理学家和工程师，在中国科学院工作，并参与了“红岸工程”，这是中国的一个外星文明探测项目。 叶文洁因为对人类社会的失望以及对宇宙探索的热情，而选择与外星文明接触，这一行为导致了她的职业生涯遭受重创。

在《三体》系列中，叶文洁的故事线贯穿整个故事，她经历了从科学家到被追捕者、再到成为抵抗组织核心成员的角色转变。她对于人类社会的失望和对未知宇宙的好奇心，使得她在面对外星文明时有着独特的视角和行动方式。叶文洁的 形象在科幻文学中具有一定的代表性，展现了人性中的复杂性和对未知世界探索的渴望。

《三体》系列是中国科幻文学的重要作品之一，获得了包括“雨果奖”在内的多个奖项，深受读者喜爱，并在全球范围内产生了广泛影响。
</code></pre> 
<ol start="14"><li>查看大模型回答问题所依赖的上下文，这时需要使用GraphRAG 的python调用方式:</li></ol> 
<pre><code class="prism language-python"><span class="token keyword">import</span> os

<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> tiktoken <span class="token comment"># Tiktoken 是一种文本处理工具，它能够将文本分解成更小的单元，通常用于自然语言处理（NLP）任务中的文本编码。</span>

<span class="token keyword">from</span> graphrag<span class="token punctuation">.</span>query<span class="token punctuation">.</span>context_builder<span class="token punctuation">.</span>entity_extraction <span class="token keyword">import</span> EntityVectorStoreKey
<span class="token keyword">from</span> graphrag<span class="token punctuation">.</span>query<span class="token punctuation">.</span>indexer_adapters <span class="token keyword">import</span> <span class="token punctuation">(</span>
    read_indexer_covariates<span class="token punctuation">,</span>
    read_indexer_entities<span class="token punctuation">,</span>
    read_indexer_relationships<span class="token punctuation">,</span>
    read_indexer_reports<span class="token punctuation">,</span>
    read_indexer_text_units<span class="token punctuation">,</span>
<span class="token punctuation">)</span>
<span class="token keyword">from</span> graphrag<span class="token punctuation">.</span>query<span class="token punctuation">.</span><span class="token builtin">input</span><span class="token punctuation">.</span>loaders<span class="token punctuation">.</span>dfs <span class="token keyword">import</span> <span class="token punctuation">(</span>
    store_entity_semantic_embeddings<span class="token punctuation">,</span>
<span class="token punctuation">)</span>
<span class="token keyword">from</span> graphrag<span class="token punctuation">.</span>query<span class="token punctuation">.</span>llm<span class="token punctuation">.</span>oai<span class="token punctuation">.</span>chat_openai <span class="token keyword">import</span> ChatOpenAI
<span class="token keyword">from</span> graphrag<span class="token punctuation">.</span>query<span class="token punctuation">.</span>llm<span class="token punctuation">.</span>oai<span class="token punctuation">.</span>embedding <span class="token keyword">import</span> OpenAIEmbedding
<span class="token keyword">from</span> graphrag<span class="token punctuation">.</span>query<span class="token punctuation">.</span>llm<span class="token punctuation">.</span>oai<span class="token punctuation">.</span>typing <span class="token keyword">import</span> OpenaiApiType
<span class="token keyword">from</span> graphrag<span class="token punctuation">.</span>query<span class="token punctuation">.</span>question_gen<span class="token punctuation">.</span>local_gen <span class="token keyword">import</span> LocalQuestionGen
<span class="token keyword">from</span> graphrag<span class="token punctuation">.</span>query<span class="token punctuation">.</span>structured_search<span class="token punctuation">.</span>local_search<span class="token punctuation">.</span>mixed_context <span class="token keyword">import</span> <span class="token punctuation">(</span>
    LocalSearchMixedContext<span class="token punctuation">,</span>
<span class="token punctuation">)</span>
<span class="token keyword">from</span> graphrag<span class="token punctuation">.</span>query<span class="token punctuation">.</span>structured_search<span class="token punctuation">.</span>local_search<span class="token punctuation">.</span>search <span class="token keyword">import</span> LocalSearch
<span class="token keyword">from</span> graphrag<span class="token punctuation">.</span>vector_stores<span class="token punctuation">.</span>lancedb <span class="token keyword">import</span> LanceDBVectorStore

<span class="token comment"># 配置参数</span>
INPUT_DIR <span class="token operator">=</span> <span class="token string">"../newTest12/output/20240802-103645/artifacts"</span> <span class="token comment"># 这里换成所在工程的输出路径</span>
LANCEDB_URI <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f"./lancedb"</span></span>

COMMUNITY_REPORT_TABLE <span class="token operator">=</span> <span class="token string">"create_final_community_reports"</span>
ENTITY_TABLE <span class="token operator">=</span> <span class="token string">"create_final_nodes"</span>
ENTITY_EMBEDDING_TABLE <span class="token operator">=</span> <span class="token string">"create_final_entities"</span>
RELATIONSHIP_TABLE <span class="token operator">=</span> <span class="token string">"create_final_relationships"</span>
COVARIATE_TABLE <span class="token operator">=</span> <span class="token string">"create_final_covariates"</span>
TEXT_UNIT_TABLE <span class="token operator">=</span> <span class="token string">"create_final_text_units"</span>
COMMUNITY_LEVEL <span class="token operator">=</span> <span class="token number">2</span>

<span class="token comment"># 读取实体entities</span>
<span class="token comment"># read nodes table to get community and degree data</span>
entity_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_parquet<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>INPUT_DIR<span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>ENTITY_TABLE<span class="token punctuation">}</span></span><span class="token string">.parquet"</span></span><span class="token punctuation">)</span>
entity_embedding_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_parquet<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>INPUT_DIR<span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>ENTITY_EMBEDDING_TABLE<span class="token punctuation">}</span></span><span class="token string">.parquet"</span></span><span class="token punctuation">)</span>

entities <span class="token operator">=</span> read_indexer_entities<span class="token punctuation">(</span>entity_df<span class="token punctuation">,</span> entity_embedding_df<span class="token punctuation">,</span> COMMUNITY_LEVEL<span class="token punctuation">)</span>

<span class="token comment"># load description embeddings to an in-memory lancedb vectorstore</span>
<span class="token comment"># to connect to a remote db, specify url and port values.</span>
description_embedding_store <span class="token operator">=</span> LanceDBVectorStore<span class="token punctuation">(</span>
    collection_name<span class="token operator">=</span><span class="token string">"entity_description_embeddings"</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
description_embedding_store<span class="token punctuation">.</span>connect<span class="token punctuation">(</span>db_uri<span class="token operator">=</span>LANCEDB_URI<span class="token punctuation">)</span>
entity_description_embeddings <span class="token operator">=</span> store_entity_semantic_embeddings<span class="token punctuation">(</span>
    entities<span class="token operator">=</span>entities<span class="token punctuation">,</span> vectorstore<span class="token operator">=</span>description_embedding_store
<span class="token punctuation">)</span>

<span class="token comment"># 读取关系relationships</span>
relationship_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_parquet<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>INPUT_DIR<span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>RELATIONSHIP_TABLE<span class="token punctuation">}</span></span><span class="token string">.parquet"</span></span><span class="token punctuation">)</span>
relationships <span class="token operator">=</span> read_indexer_relationships<span class="token punctuation">(</span>relationship_df<span class="token punctuation">)</span>

<span class="token comment"># 读取协变量covariates</span>
covariate_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_parquet<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>INPUT_DIR<span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>COVARIATE_TABLE<span class="token punctuation">}</span></span><span class="token string">.parquet"</span></span><span class="token punctuation">)</span>

claims <span class="token operator">=</span> read_indexer_covariates<span class="token punctuation">(</span>covariate_df<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Claim records: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span><span class="token builtin">len</span><span class="token punctuation">(</span>claims<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
covariates <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">"claims"</span><span class="token punctuation">:</span> claims<span class="token punctuation">}</span>

<span class="token comment"># 读取社区报告</span>
report_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_parquet<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>INPUT_DIR<span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>COMMUNITY_REPORT_TABLE<span class="token punctuation">}</span></span><span class="token string">.parquet"</span></span><span class="token punctuation">)</span>
reports <span class="token operator">=</span> read_indexer_reports<span class="token punctuation">(</span>report_df<span class="token punctuation">,</span> entity_df<span class="token punctuation">,</span> COMMUNITY_LEVEL<span class="token punctuation">)</span>

<span class="token comment"># 读取文本块</span>
text_unit_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_parquet<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>INPUT_DIR<span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>TEXT_UNIT_TABLE<span class="token punctuation">}</span></span><span class="token string">.parquet"</span></span><span class="token punctuation">)</span>
text_units <span class="token operator">=</span> read_indexer_text_units<span class="token punctuation">(</span>text_unit_df<span class="token punctuation">)</span>

<span class="token comment"># 配置模型参数</span>
llm <span class="token operator">=</span> ChatOpenAI<span class="token punctuation">(</span>
    api_key<span class="token operator">=</span><span class="token string">'ollama'</span><span class="token punctuation">,</span>
    model<span class="token operator">=</span><span class="token string">'qwen2'</span><span class="token punctuation">,</span>
    api_base<span class="token operator">=</span><span class="token string">'http://localhost:11434/v1/'</span><span class="token punctuation">,</span>
    api_type<span class="token operator">=</span>OpenaiApiType<span class="token punctuation">.</span>OpenAI<span class="token punctuation">,</span>  <span class="token comment"># OpenaiApiType.OpenAI or OpenaiApiType.AzureOpenAI</span>
    max_retries<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

token_encoder <span class="token operator">=</span> tiktoken<span class="token punctuation">.</span>get_encoding<span class="token punctuation">(</span><span class="token string">"cl100k_base"</span><span class="token punctuation">)</span>

text_embedder <span class="token operator">=</span> OpenAIEmbedding<span class="token punctuation">(</span>
    api_key<span class="token operator">=</span><span class="token string">'ollama'</span><span class="token punctuation">,</span>
    api_type<span class="token operator">=</span>OpenaiApiType<span class="token punctuation">.</span>OpenAI<span class="token punctuation">,</span>
    api_base<span class="token operator">=</span><span class="token string">'http://localhost:11434/api'</span><span class="token punctuation">,</span>
    model<span class="token operator">=</span><span class="token string">'qwen2'</span><span class="token punctuation">,</span>
    deployment_name<span class="token operator">=</span><span class="token string">'qwen2'</span><span class="token punctuation">,</span>
    max_retries<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

<span class="token comment"># 创建局部搜索上下文构建器context-builder</span>
context_builder <span class="token operator">=</span> LocalSearchMixedContext<span class="token punctuation">(</span>
    community_reports<span class="token operator">=</span>reports<span class="token punctuation">,</span>
    text_units<span class="token operator">=</span>text_units<span class="token punctuation">,</span>
    entities<span class="token operator">=</span>entities<span class="token punctuation">,</span>
    relationships<span class="token operator">=</span>relationships<span class="token punctuation">,</span>
    covariates<span class="token operator">=</span>covariates<span class="token punctuation">,</span>
    entity_text_embeddings<span class="token operator">=</span>description_embedding_store<span class="token punctuation">,</span>
    embedding_vectorstore_key<span class="token operator">=</span>EntityVectorStoreKey<span class="token punctuation">.</span>ID<span class="token punctuation">,</span>  <span class="token comment"># if the vectorstore uses entity title as ids, set this to EntityVectorStoreKey.TITLE</span>
    text_embedder<span class="token operator">=</span>text_embedder<span class="token punctuation">,</span>
    token_encoder<span class="token operator">=</span>token_encoder<span class="token punctuation">,</span>
<span class="token punctuation">)</span>

<span class="token comment"># 创建局部搜索引擎</span>
local_context_params <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token string">"text_unit_prop"</span><span class="token punctuation">:</span> <span class="token number">0.5</span><span class="token punctuation">,</span>
    <span class="token string">"community_prop"</span><span class="token punctuation">:</span> <span class="token number">0.1</span><span class="token punctuation">,</span>
    <span class="token string">"conversation_history_max_turns"</span><span class="token punctuation">:</span> <span class="token number">5</span><span class="token punctuation">,</span>
    <span class="token string">"conversation_history_user_turns_only"</span><span class="token punctuation">:</span> <span class="token boolean">True</span><span class="token punctuation">,</span>
    <span class="token string">"top_k_mapped_entities"</span><span class="token punctuation">:</span> <span class="token number">10</span><span class="token punctuation">,</span>
    <span class="token string">"top_k_relationships"</span><span class="token punctuation">:</span> <span class="token number">10</span><span class="token punctuation">,</span>
    <span class="token string">"include_entity_rank"</span><span class="token punctuation">:</span> <span class="token boolean">True</span><span class="token punctuation">,</span>
    <span class="token string">"include_relationship_weight"</span><span class="token punctuation">:</span> <span class="token boolean">True</span><span class="token punctuation">,</span>
    <span class="token string">"include_community_rank"</span><span class="token punctuation">:</span> <span class="token boolean">False</span><span class="token punctuation">,</span>
    <span class="token string">"return_candidate_context"</span><span class="token punctuation">:</span> <span class="token boolean">False</span><span class="token punctuation">,</span>
    <span class="token string">"embedding_vectorstore_key"</span><span class="token punctuation">:</span> EntityVectorStoreKey<span class="token punctuation">.</span>ID<span class="token punctuation">,</span>  <span class="token comment"># set this to EntityVectorStoreKey.TITLE if the vectorstore uses entity title as ids</span>
    <span class="token string">"max_tokens"</span><span class="token punctuation">:</span> <span class="token number">12_000</span><span class="token punctuation">,</span>  <span class="token comment"># change this based on the token limit you have on your model (if you are using a model with 8k limit, a good setting could be 5000)</span>
<span class="token punctuation">}</span>

llm_params <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token string">"max_tokens"</span><span class="token punctuation">:</span> <span class="token number">2_000</span><span class="token punctuation">,</span>  <span class="token comment"># change this based on the token limit you have on your model (if you are using a model with 8k limit, a good setting could be 1000=1500)</span>
    <span class="token string">"temperature"</span><span class="token punctuation">:</span> <span class="token number">0.0</span><span class="token punctuation">,</span>
<span class="token punctuation">}</span>

search_engine <span class="token operator">=</span> LocalSearch<span class="token punctuation">(</span>
    llm<span class="token operator">=</span>llm<span class="token punctuation">,</span>
    context_builder<span class="token operator">=</span>context_builder<span class="token punctuation">,</span>
    token_encoder<span class="token operator">=</span>token_encoder<span class="token punctuation">,</span>
    llm_params<span class="token operator">=</span>llm_params<span class="token punctuation">,</span>
    context_builder_params<span class="token operator">=</span>local_context_params<span class="token punctuation">,</span>
    response_type<span class="token operator">=</span><span class="token string">"multiple paragraphs"</span><span class="token punctuation">,</span>  <span class="token comment"># free form text describing the response type and format, can be anything, e.g. prioritized list, single paragraph, multiple paragraphs, multiple-page report</span>
<span class="token punctuation">)</span>

<span class="token comment"># 执行局部搜索</span>
result <span class="token operator">=</span> <span class="token keyword">await</span> search_engine<span class="token punctuation">.</span>asearch<span class="token punctuation">(</span><span class="token string">"叶文洁是谁"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">.</span>response<span class="token punctuation">)</span>

<span class="token comment"># 查看local Search依赖的上下文:</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>result<span class="token punctuation">.</span>context_data<span class="token punctuation">)</span>
</code></pre> 
<p>运行效果：</p> 
<pre><code class="prism language-shell">叶文洁是中国科幻作家刘慈欣的长篇科幻小说《三体》中的一个主要角色。在故事中，她是一位资深的天文学家和物理学家，在中国科学院从事研究工作。

叶文洁在年轻时因政治原因遭受迫害，后来成为“红卫兵”运动的积极参与者，并因此被下放到农村劳动改造。在小说中，她通过无线电波向宇宙发送了求救信号，结果意外地接收到三体文明的信息，从而引发了后续一系列惊心动魄的故事。

叶文洁的性格复杂多面，既有对科学和真理的执着追求，也有对人性和社会的深刻洞察。她在故事中的经历反映了人类在面对未知、恐惧与希望之间的挣扎，以及在极端环境下个人命运的脆弱性和坚韧性的交织。
</code></pre> 
<p>依赖的上下文:</p> 
<pre><code class="prism language-shell"><span class="token punctuation">{<!-- --></span><span class="token string">'relationships'</span><span class="token builtin class-name">:</span>   <span class="token function">id</span>  <span class="token builtin class-name">source</span>         target                                description weight  <span class="token punctuation">\</span>
 <span class="token number">0</span>  <span class="token number">4</span>  <span class="token string">"小红卫兵"</span>  <span class="token string">"QUESTIONING"</span>  <span class="token string">"小红卫兵对叶哲泰的回答提出疑问，试图理解是否有上帝的存在。"</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token string">"entity"</span>    <span class="token number">1.0</span>   
 
   rank  in_context  
 <span class="token number">0</span>    <span class="token number">2</span>        True  ,
 <span class="token string">'claims'</span><span class="token builtin class-name">:</span> Empty DataFrame
 Columns: <span class="token punctuation">[</span>in_context<span class="token punctuation">]</span>
 Index: <span class="token punctuation">[</span><span class="token punctuation">]</span>,
 <span class="token string">'entities'</span><span class="token builtin class-name">:</span>     <span class="token function">id</span>                    entity  <span class="token punctuation">\</span>
 <span class="token number">0</span>   <span class="token number">52</span>                      <span class="token string">"会场"</span>   
 <span class="token number">1</span>   <span class="token number">45</span>                    <span class="token string">"四位小将"</span>   
 <span class="token number">2</span>   <span class="token number">26</span>                       <span class="token string">"琳"</span>   
 <span class="token number">3</span>   <span class="token number">60</span>                   <span class="token string">"教工宿舍楼"</span>   
 <span class="token number">4</span>   <span class="token number">51</span>                       <span class="token string">"帝"</span>   
 <span class="token number">5</span>   <span class="token number">49</span>                    <span class="token string">"小红卫兵"</span>   
 <span class="token number">6</span>   <span class="token number">53</span>                      <span class="token string">"宗教"</span>   
 <span class="token number">7</span>   <span class="token number">41</span>                    <span class="token string">"实验结果"</span>   
 <span class="token number">8</span>   <span class="token number">21</span>                     <span class="token string">"基础课"</span>   
 <span class="token number">9</span>    <span class="token number">4</span>                     <span class="token string">"铁炉子"</span>   
 <span class="token number">10</span>   <span class="token number">6</span>                 <span class="token string">"全国范围的武斗"</span>   
 <span class="token number">11</span>  <span class="token number">15</span>                     <span class="token string">"批斗会"</span>   
 <span class="token number">12</span>  <span class="token number">62</span>                      <span class="token string">"阮雯"</span>   
 <span class="token number">13</span>  <span class="token number">61</span>                     <span class="token string">"阮老师"</span>   
 <span class="token number">14</span>  <span class="token number">58</span>                      <span class="token string">"父亲"</span>   
 <span class="token number">15</span>  <span class="token number">48</span>                     <span class="token string">"胡卫兵"</span>   
 <span class="token number">16</span>  <span class="token number">19</span>  <span class="token string">"批判"</span><span class="token punctuation">(</span><span class="token operator">&lt;</span>SPAN<span class="token operator">&gt;</span>EVENT<span class="token operator">&lt;</span>/SPAN<span class="token operator">&gt;</span><span class="token punctuation">)</span>   
 <span class="token number">17</span>  <span class="token number">28</span>                  <span class="token string">"生态宇宙模型"</span>   
 <span class="token number">18</span>  <span class="token number">56</span>                      <span class="token string">"组织"</span>   
 <span class="token number">19</span>  <span class="token number">25</span>                   <span class="token string">"革命小将们"</span>   
 
                                           description number of relationships  <span class="token punctuation">\</span>
 <span class="token number">0</span>                         <span class="token string">"会场是一个特定的地点，可能是某个会议或集会的地方。"</span>                       <span class="token number">0</span>   
 <span class="token number">1</span>   <span class="token string">"四位小将"</span>指的是来自附中的四位女性学生，她们以一种坚定的方式进行“革命”，通过实际行动表达<span class="token punctuation">..</span>.                       <span class="token number">0</span>   
 <span class="token number">2</span>           <span class="token string">"琳是叶哲泰的妻子或女儿，以其过人的天资和聪明才智著称，在学术上有着重要的地位。"</span>                       <span class="token number">0</span>   
 <span class="token number">3</span>                          <span class="token string">"教工宿舍楼是叶文洁生活和工作的地点，位于学校内。"</span>                       <span class="token number">0</span>   
 <span class="token number">4</span>            <span class="token string">"帝是一个象征性的存在，代表某种超自然或宇宙之外的力量。"</span><span class="token punctuation">)</span> <span class="token punctuation">(</span><span class="token string">"entity"</span>                       <span class="token number">0</span>   
 <span class="token number">5</span>                    <span class="token string">"小红卫兵对叶哲泰的回答感到困惑，并试图理解是否有上帝的存在。"</span>                       <span class="token number">1</span>   
 <span class="token number">6</span>             <span class="token string">"宗教在这里可能是指某种信仰体系，被描述为被统治阶级用来控制人民的精神工具。"</span>                       <span class="token number">0</span>   
 <span class="token number">7</span>                        <span class="token string">"实验结果指的是与量子波函数坍缩相关的科学实验的结果。"</span>                       <span class="token number">0</span>   
 <span class="token number">8</span>    <span class="token string">"基础课指的是教育体系中的一个课程或阶段，涉及到物理学的基础理论教学。"</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span><span class="token string">"entity"</span>                       <span class="token number">0</span>   
 <span class="token number">9</span>          <span class="token string">"铁炉子是一个充满烈性炸药的地方，暗示了潜在的危险或冲突。"</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span><span class="token string">"entity"</span>                       <span class="token number">0</span>   
 <span class="token number">10</span>        <span class="token string">"全国范围的武斗"</span>指的是在一个广泛区域内的武装冲突或斗争活动。<span class="token punctuation">)</span>  <span class="token punctuation">(</span><span class="token string">"entity"</span>                       <span class="token number">0</span>   
 <span class="token number">11</span>       <span class="token string">"批斗会是一个几千人参加的事件，在这个事件中，人们聚集起来对一个反动学术权威进行批判。"</span>                       <span class="token number">0</span>   
 <span class="token number">12</span>       <span class="token string">"阮雯是故事中的一个角色，她拥有自己的家，并且与叶文洁有关系。"</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span><span class="token string">"entity"</span>                       <span class="token number">0</span>   
 <span class="token number">13</span>      <span class="token string">"阮老师是阮雯除父亲外最亲近的人，在停课闹革命期间一直陪伴着她。"</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span><span class="token string">"entity"</span>                       <span class="token number">0</span>   
 <span class="token number">14</span>                         <span class="token string">"父亲是叶文洁的已故亲人，她将烟斗放在了他的手中。"</span>                       <span class="token number">0</span>   
 <span class="token number">15</span>                   <span class="token string">"胡卫兵可能是一个与红卫兵相关的组织或群体，但具体信息不明确。"</span>                       <span class="token number">0</span>   
 <span class="token number">16</span>  <span class="token string">"批判"</span>指的是长时间的批评活动，它在政治上产生了强烈的影响，摧毁了参与者的意识和思想体系。参<span class="token punctuation">..</span>.                       <span class="token number">0</span>   
 <span class="token number">17</span>    <span class="token string">"生态宇宙模型是一个被批判的概念，因为它否认物质运动的本质，被认为是反辩证法和反动唯心主义。"</span>                       <span class="token number">0</span>   
 <span class="token number">18</span>             <span class="token string">"叶文洁是故事中的一个人物，她与父亲叶哲泰有关联。"</span><span class="token punctuation">)</span>  <span class="token punctuation">(</span><span class="token string">"entity"</span>                       <span class="token number">0</span>   
 <span class="token number">19</span>   <span class="token string">"革命小将是帮助她醒悟并支持她的群体，表明了他们对社会变革的支持和参与."</span><span class="token punctuation">)</span> <span class="token punctuation">(</span><span class="token string">"entity"</span>                       <span class="token number">0</span>   
 
     in_context  
 <span class="token number">0</span>         True  
 <span class="token number">1</span>         True  
 <span class="token number">2</span>         True  
 <span class="token number">3</span>         True  
 <span class="token number">4</span>         True  
 <span class="token number">5</span>         True  
 <span class="token number">6</span>         True  
 <span class="token number">7</span>         True  
 <span class="token number">8</span>         True  
 <span class="token number">9</span>         True  
 <span class="token number">10</span>        True  
 <span class="token number">11</span>        True  
 <span class="token number">12</span>        True  
 <span class="token number">13</span>        True  
 <span class="token number">14</span>        True  
 <span class="token number">15</span>        True  
 <span class="token number">16</span>        True  
 <span class="token number">17</span>        True  
 <span class="token number">18</span>        True  
 <span class="token number">19</span>        True  ,
 <span class="token string">'sources'</span><span class="token builtin class-name">:</span>     <span class="token function">id</span>                                               text
 <span class="token number">0</span>   <span class="token number">29</span>  相信它不存在了。<span class="token punctuation">\</span>n<span class="token punctuation">\</span>n　　这句大逆不道的话在整个会场引起了骚动，在台上一名红卫兵的带领下，<span class="token punctuation">..</span>.
 <span class="token number">1</span>   <span class="token number">40</span>  不讲。但来自附中的四位小将自有她们“无坚不摧”的革命方式，刚才动手的那个女孩儿又狠抽了叶哲泰<span class="token punctuation">..</span>.
 <span class="token number">2</span>   <span class="token number">21</span>  �态宇宙模型，否定了物质的运动本性，是反辩证法的！它认为宇宙有限，更是彻头彻尾的反动唯心主义<span class="token punctuation">..</span>.
 <span class="token number">3</span>   <span class="token number">43</span>  四肢仍保持着老校工抓着她时的姿态，一动不动，像石化了一般。过了好久，她才将悬空的手臂放下来，<span class="token punctuation">..</span>.
 <span class="token number">4</span>   <span class="token number">28</span>  帝的存在留下了位置。”绍琳对女孩儿点点头提示说。<span class="token punctuation">\</span>n<span class="token punctuation">\</span>n　　小红卫兵那茫然的思路立刻找到了立<span class="token punctuation">..</span>.
 <span class="token number">5</span>    <span class="token number">1</span>  那一个，她不由自主地问道： “连时间都是从那个奇点开始的！？那奇点以前有什么？”<span class="token punctuation">\</span>n<span class="token punctuation">\</span>n　　<span class="token punctuation">..</span>.
 <span class="token number">6</span>   <span class="token number">39</span>  神免于彻底垮掉。“叶哲泰，这一点你是无法抵赖的！你多次向学生散布反动的哥本哈根解释！”<span class="token punctuation">\</span>n<span class="token punctuation">\</span><span class="token punctuation">..</span>.
 <span class="token number">7</span>   <span class="token number">17</span>  �二至六五届的基础课中，你是不是擅自加入了大量的相对论内容？！”<span class="token punctuation">\</span>n<span class="token punctuation">\</span>n　　“相对论已经成为<span class="token punctuation">..</span>.
 <span class="token number">8</span>    <span class="token number">3</span>  铁炉子，里面塞满了烈性炸药，用电雷管串联起来，他看不到它们，但能感觉到它们磁石般的存在，开关<span class="token punctuation">..</span>.
 <span class="token number">9</span>    <span class="token number">5</span>  �，全国范围的武斗也进入高潮。<span class="token punctuation">)</span>——连同那些梭标和大刀等冷兵器，构成了一部浓缩的近现代史……<span class="token punctuation">..</span>.
 <span class="token number">10</span>   <span class="token number">9</span>  ��场上，一场几千人参加的批斗会已经进行了近两个小时。在这个派别林立的年代，任何一处都有错综<span class="token punctuation">..</span>.
 <span class="token number">11</span>  <span class="token number">34</span>  们拿在手中和含在嘴里深思的那个男人的智慧，但阮雯从未提起过他。这个雅致温暖的小世界成为文洁逃<span class="token punctuation">..</span>.
 <span class="token number">12</span>  <span class="token number">45</span>  来停课闹革命至今，阮老师一直是她除父亲外最亲近的人。阮雯曾留学剑桥，她的家曾对叶文洁充满了吸<span class="token punctuation">..</span>.
 <span class="token number">13</span>  <span class="token number">41</span>  动的一个！”一名男红卫兵试图转移话题。<span class="token punctuation">\</span>n<span class="token punctuation">\</span>n　　“也许以后这个理论会被推翻，但本世纪的两大<span class="token punctuation">..</span>.
 <span class="token number">14</span>  <span class="token number">12</span>  阶段，旷日持久的批判将鲜明的政治图像如水银般：注入了他们的意识，将他们那由知识和理性构筑的思<span class="token punctuation">..</span>.
 <span class="token number">15</span>  <span class="token number">42</span>  �，这声音是精神已彻底崩溃的绍琳发出的，听起来十分恐怖。人们开始离去，最后发展成一场大溃逃，<span class="token punctuation">..</span>.
 <span class="token number">16</span>  <span class="token number">20</span>  �连其中的颤抖也放大了，“你没有想到我会站出来揭发你，批判你吧！？是的，我以前受你欺骗，你用<span class="token punctuation">..</span>.<span class="token punctuation">}</span>
</code></pre> 
<h2><a id="ollamallmlmstudioEmbeddingGraphRAG_827"></a>使用ollama提供llm服务，lm-studio提供Embedding服务，运行GraphRAG的方法</h2> 
<p><strong>注意</strong>：如果使用lm-studio提供Embedding服务，不需要修改这两个文件<code>D:\ProgramData\miniconda3\envs\graphRAG\Lib\site-packages\graphrag\llm\openai\openai_embeddings_llm.py</code>和<code>D:\ProgramData\miniconda3\envs\graphRAG\Lib\site-packages\graphrag\query\llm\oai\embedding.py</code>，维持官方提供原始的样子：</p> 
<ul><li>.env的修改同上：</li></ul> 
<pre><code class="prism language-shell">
<span class="token assign-left variable">GRAPHRAG_API_KEY</span><span class="token operator">=</span>ollama
<span class="token assign-left variable">GRAPHRAG_CLAIM_EXTRACTION_ENABLED</span><span class="token operator">=</span>True
</code></pre> 
<ul><li><code>setting.yaml</code>的配置如下:</li></ul> 
<pre><code class="prism language-yaml">
<span class="token key atrule">encoding_model</span><span class="token punctuation">:</span> cl100k_base
<span class="token key atrule">skip_workflows</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token key atrule">llm</span><span class="token punctuation">:</span>
  <span class="token key atrule">api_key</span><span class="token punctuation">:</span> ollama
  <span class="token key atrule">type</span><span class="token punctuation">:</span> openai_chat <span class="token comment"># or azure_openai_chat</span>
  <span class="token key atrule">model</span><span class="token punctuation">:</span> qwen2
  <span class="token key atrule">model_supports_json</span><span class="token punctuation">:</span> <span class="token boolean important">true</span> <span class="token comment"># recommended if this is available for your model.</span>
  <span class="token comment"># max_tokens: 4000</span>
  <span class="token comment"># request_timeout: 180.0</span>
  <span class="token key atrule">api_base</span><span class="token punctuation">:</span> http<span class="token punctuation">:</span>//localhost<span class="token punctuation">:</span>11434/v1/
  <span class="token comment"># api_version: 2024-02-15-preview</span>
  <span class="token comment"># organization: &lt;organization_id&gt;</span>
  <span class="token comment"># deployment_name: &lt;azure_model_deployment_name&gt;</span>
  <span class="token comment"># tokens_per_minute: 150_000 # set a leaky bucket throttle</span>
  <span class="token comment"># requests_per_minute: 10_000 # set a leaky bucket throttle</span>
  <span class="token comment"># max_retries: 10</span>
  <span class="token comment"># max_retry_wait: 10.0</span>
  <span class="token comment"># sleep_on_rate_limit_recommendation: true # whether to sleep when azure suggests wait-times</span>
  <span class="token comment"># concurrent_requests: 25 # the number of parallel inflight requests that may be made</span>

<span class="token key atrule">parallelization</span><span class="token punctuation">:</span>
  <span class="token key atrule">stagger</span><span class="token punctuation">:</span> <span class="token number">0.3</span>
  <span class="token comment"># num_threads: 50 # the number of threads to use for parallel processing</span>

<span class="token key atrule">async_mode</span><span class="token punctuation">:</span> threaded <span class="token comment"># or asyncio</span>

<span class="token key atrule">embeddings</span><span class="token punctuation">:</span>
  <span class="token comment">## parallelization: override the global parallelization settings for embeddings</span>
  <span class="token key atrule">async_mode</span><span class="token punctuation">:</span> threaded <span class="token comment"># or asyncio</span>
  <span class="token key atrule">llm</span><span class="token punctuation">:</span>
    <span class="token comment">#api_key: ${GRAPHRAG_API_KEY}</span>
    <span class="token key atrule">api_key</span><span class="token punctuation">:</span> lm<span class="token punctuation">-</span>studio
    <span class="token key atrule">type</span><span class="token punctuation">:</span> openai_embedding <span class="token comment"># or azure_openai_embedding</span>
    <span class="token key atrule">model</span><span class="token punctuation">:</span> nomic<span class="token punctuation">-</span>ai/nomic<span class="token punctuation">-</span>embed<span class="token punctuation">-</span>text<span class="token punctuation">-</span>v1.5/nomic<span class="token punctuation">-</span>embed<span class="token punctuation">-</span>text<span class="token punctuation">-</span>v1.5.Q8_0.gguf
    <span class="token key atrule">api_base</span><span class="token punctuation">:</span> http<span class="token punctuation">:</span>//localhost<span class="token punctuation">:</span>1234/v1
    <span class="token comment"># api_version: 2024-02-15-preview</span>
    <span class="token comment"># organization: &lt;organization_id&gt;</span>
    <span class="token comment"># deployment_name: &lt;azure_model_deployment_name&gt;</span>
    <span class="token comment"># tokens_per_minute: 150_000 # set a leaky bucket throttle</span>
    <span class="token comment"># requests_per_minute: 10_000 # set a leaky bucket throttle</span>
    <span class="token comment"># max_retries: 10</span>
    <span class="token comment"># max_retry_wait: 10.0</span>
    <span class="token comment"># sleep_on_rate_limit_recommendation: true # whether to sleep when azure suggests wait-times</span>
    <span class="token key atrule">concurrent_requests</span><span class="token punctuation">:</span> <span class="token number">1</span> <span class="token comment"># the number of parallel inflight requests that may be made</span>
    <span class="token comment"># batch_size: 16 # the number of documents to send in a single request</span>
    <span class="token comment"># batch_max_tokens: 8191 # the maximum number of tokens to send in a single request</span>
    <span class="token comment"># target: required # or optional</span>
  <span class="token punctuation">...</span>

</code></pre> 
<ul><li><code>chunk_text()</code>函数修改同上:</li></ul> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">chunk_text</span><span class="token punctuation">(</span>
    text<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span> max_tokens<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span> token_encoder<span class="token punctuation">:</span> tiktoken<span class="token punctuation">.</span>Encoding <span class="token operator">|</span> <span class="token boolean">None</span> <span class="token operator">=</span> <span class="token boolean">None</span>
<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Chunk text by token length."""</span>
    <span class="token keyword">if</span> token_encoder <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        token_encoder <span class="token operator">=</span> tiktoken<span class="token punctuation">.</span>get_encoding<span class="token punctuation">(</span><span class="token string">"cl100k_base"</span><span class="token punctuation">)</span>
    tokens <span class="token operator">=</span> token_encoder<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>text<span class="token punctuation">)</span>  <span class="token comment"># type: ignore</span>
    tokens <span class="token operator">=</span> token_encoder<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>tokens<span class="token punctuation">)</span> <span class="token comment"># 将tokens解码成字符串</span>

    chunk_iterator <span class="token operator">=</span> batched<span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">(</span>tokens<span class="token punctuation">)</span><span class="token punctuation">,</span> max_tokens<span class="token punctuation">)</span>
    <span class="token keyword">yield</span> <span class="token keyword">from</span> chunk_iterator

</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/5843ea509f6a874b54ef93ab079e90dd/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">node中如何定义中间件</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/dc565487353d8e788d0d4b485f081ea4/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">spring boot 根据实体类生成表</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>