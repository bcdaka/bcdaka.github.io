<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Computer Vision COMP90086 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/7eda28b59615a34b9cd436c28944a68f/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="Computer Vision COMP90086">
  <meta property="og:description" content="Introduction Finding correspondences between keypoints is a critical step in many computer vision applications. It can be used to align images when constructing a panorama from lots of separate photogtraps, and it is used to find point correspondences between keypoints detetected in multiple views of a scene. iuww520iuww520iuww520iuww520iuww520iuww520iuww520iuww520 This assignment uses a dataset generated from many views of the Trevi fountain in Rome. Finding correspondences between detected keypoints is a critical step in the pipeline for reconstructing a 3D representation of the fountain from individual photographs.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-09-04T10:08:18+08:00">
    <meta property="article:modified_time" content="2024-09-04T10:08:18+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Computer Vision COMP90086</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div> 
 <span style="color:#000000;"><strong>Introduction </strong></span> 
</div> 
<div> 
 <span style="color:#000000;">Finding correspondences between keypoints is a critical step in many computer vision applications. It can be used to align images when constructing a panorama from lots of separate photogtraps, and it is </span> 
</div> 
<div> 
 <span style="color:#000000;">used to find point correspondences between keypoints detetected in multiple views of a scene. </span> 
</div> 
<div>
  iuww520iuww520iuww520iuww520iuww520iuww520iuww520iuww520 
</div> 
<div> 
 <span style="color:#000000;">This assignment uses a dataset generated from many views of the Trevi fountain in Rome. Finding correspondences between detected keypoints is a critical step in the pipeline for reconstructing a 3D representation of the fountain from individual photographs. </span> 
</div> 
<div> 
 <span style="color:#000000;">The dataset in this assignment is generated as a set of pairs of image patches taken centred at detected keypoints. The image patches are 64x64 pixels each and each training sample is made of two patches placed side by side to make a 128x64 image. For half the training set (10,000 examples in the ’1good’ subdirectory) the two patches are from two separate views of the same keypoint. For the other half (10,000 examples in the ’0bad’ subdirectory) the two patches are from two different keypoints. Figure </span> 
</div> 
<div> 
 <span style="color:#ff0000;">1 </span> 
 <span style="color:#000000;">shows an example of each of these. The validation directory is similarly structured but contains four times as many non-matching pairs (2000 examples in ’0bad’) as matching pairs (500 examples in ’1good’). </span> 
</div> 
<div> 
 <span style="color:#000000;">Figure 1: Corresponding (left) and non-corresponding (right) pairs of image patches Your task is to create and train some neural networks that can tackle the problem of determining whether the two patches correspond or not.</span> 
</div> 
<div> 
 <div> 
  <span style="color:#000000;"><strong>1. Baseline Neural Network [2 pt] </strong></span> 
 </div> 
 <div> 
  <span style="color:#000000;">Run the baseline neural network implementation in the provided python notebook and in your report, </span> 
 </div> 
 <div> 
  <span style="color:#000000;">you should include the loss and accuracy curves for the training and validation sets in your report and </span> 
 </div> 
 <div> 
  <span style="color:#000000;">discuss what these imply about the baseline model. </span> 
 </div> 
 <div> 
  <span style="color:#000000;">The validation set contains more bad examples than good. Why might this be a sensible way of </span> 
 </div> 
 <div> 
  <span style="color:#000000;">testing for the task of finding feature correspondences? Should the training environment also reflect </span> 
 </div> 
 <div> 
  <span style="color:#000000;">this imbalance? </span> 
 </div> 
 <div> 
  <span style="color:#000000;"><strong>2. Regularizing your Neural Network [2pt] </strong></span> 
 </div> 
 <div> 
  <span style="color:#000000;">To regularize the network, your should try adding a regularization layer (see the Keras documenation  for these layers). Try adding a Dropout() layer after Flatten() and try different rate values to see what the effect of this parameter is. Include the loss and accuracy plots in your report for three different </span> 
 </div> 
 <div> 
  <span style="color:#000000;">choices of the rate parameter. Describe the changes you see in these loss and accuracy plots in your report and suggest what the best choice of rate value is from the three you have reported. </span> 
 </div> 
 <div> 
  <span style="color:#000000;"><strong>3. Convolutional Neural Network [3pt] </strong></span> 
 </div> 
 <div> 
  <span style="color:#000000;">Design a Convolutional Neural Network to solve this challenge. If you use Conv2D() layers imme diately after the LayerNormalization layer these convolutions will apply identically to both image  patches in each input sample. Try using one or two Conv2D() layers with relu activations. You should  explore the value of having different numbers of filters, kernel sizes, and strides before the Flatten() layer. </span> 
 </div> 
 <div> 
  <span style="color:#000000;">Briefly describe the set of settings you tried in your report in a table (this should be around 10 settings). </span> 
 </div> 
 <div> 
  <span style="color:#000000;">For each setting, report the final training loss and accuracy as well as the validation loss and accuracy. </span> 
 </div> 
 <div> 
  <span style="color:#000000;">Include a discussion of the results of these experiments in your report. Identify your best performing </span> 
 </div> 
 <div> 
  <span style="color:#000000;">design and discuss why you think this may have been best. </span> 
 </div> 
</div>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/18c4c66f351fe1d17551495ea3f38513/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">HTTPS访问是什么？</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/c0efa1cb22699da401345fa060650a2c/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">vue 踩坑记录</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>