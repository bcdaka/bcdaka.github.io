<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>开源模型应用落地-工具使用篇-Spring AI（七） - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/9d917dc4d4a371e65a23acbf2fe6d9a0/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="开源模型应用落地-工具使用篇-Spring AI（七）">
  <meta property="og:description" content="一、前言 在AI大模型百花齐放的时代，很多人都对新兴技术充满了热情，都想尝试一下。但是，实际上要入门AI技术的门槛非常高。除了需要高端设备，还需要面临复杂的部署和安装过程，这让很多人望而却步。不过，随着开源技术的不断进步，使得入门AI变得越来越容易。通过使用Ollama，您可以快速体验大语言模型的乐趣，不再需要担心繁琐的设置和安装过程。另外，通过集成Spring AI，让更多Java爱好者能便捷的将AI能力集成到项目中，接下来，跟随我的脚步，一起来体验一把。
二、术语 2.1、Spring AI 是 Spring 生态系统的一个新项目，它简化了 Java 中 AI 应用程序的创建。它提供以下功能：
支持所有主要模型提供商，例如 OpenAI、Microsoft、Amazon、Google 和 Huggingface。支持的模型类型包括“聊天”和“文本到图像”，还有更多模型类型正在开发中。跨 AI 提供商的可移植 API，用于聊天和嵌入模型。支持同步和流 API 选项。支持下拉访问模型特定功能。AI 模型输出到 POJO 的映射。 2.2、Ollama ​​​​​​​ 是一个强大的框架，用于在 Docker 容器中部署 LLM（大型语言模型）。它的主要功能是在 Docker 容器内部署和管理 LLM 的促进者，使该过程变得简单。它可以帮助用户快速在本地运行大模型，通过简单的安装指令，用户可以执行一条命令就在本地运行开源大型语言模型。
Ollama 支持 GPU/CPU 混合模式运行，允许用户根据自己的硬件条件（如 GPU、显存、CPU 和内存）选择不同量化版本的大模型。它提供了一种方式，使得即使在没有高性能 GPU 的设备上，也能够运行大型模型。
三、前置条件 3.1、JDK 17&#43; 下载地址：https://www.oracle.com/java/technologies/downloads/#jdk17-windows
类文件具有错误的版本 61.0, 应为 52.0
3.2、创建Maven项目 SpringBoot版本为3.2.3
&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;3.2.3&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; 3.3、导入Maven依赖包 &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-03-12T16:18:55+08:00">
    <meta property="article:modified_time" content="2024-03-12T16:18:55+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">开源模型应用落地-工具使用篇-Spring AI（七）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2><strong>一、前言</strong></h2> 
<p>    在AI大模型百花齐放的时代，很多人都对新兴技术充满了热情，都想尝试一下。但是，实际上要入门AI技术的门槛非常高。除了需要高端设备，还需要面临复杂的部署和安装过程，这让很多人望而却步。不过，随着开源技术的不断进步，使得入门AI变得越来越容易。通过使用<span style="color:#4da8ee;"><strong><a class="link-info" href="https://blog.csdn.net/qq839019311/article/details/136474207" title="Ollama">Ollama</a></strong></span>，您可以快速体验大语言模型的乐趣，不再需要担心繁琐的设置和安装过程。另外，通过集成Spring AI，让更多Java爱好者能便捷的将AI能力集成到项目中，接下来，跟随我的脚步，一起来体验一把。</p> 
<hr> 
<h2><strong>二、术语</strong></h2> 
<h3><strong>2.1、Spring AI</strong></h3> 
<p>    是 Spring 生态系统的一个新项目，它简化了 Java 中 AI 应用程序的创建。它提供以下功能：</p> 
<ul><li>支持所有主要模型提供商，例如 OpenAI、Microsoft、Amazon、Google 和 Huggingface。</li><li>支持的模型类型包括“聊天”和“文本到图像”，还有更多模型类型正在开发中。</li><li>跨 AI 提供商的可移植 API，用于聊天和嵌入模型。</li><li>支持同步和流 API 选项。</li><li>支持下拉访问模型特定功能。</li><li>AI 模型输出到 POJO 的映射。</li></ul> 
<h3><strong>2.2、Ollama</strong></h3> 
<p><strong>​​​​​​​    </strong>是一个强大的框架，用于在 Docker 容器中部署 LLM（大型语言模型）。它的主要功能是在 Docker 容器内部署和管理 LLM 的促进者，使该过程变得简单。它可以帮助用户快速在本地运行大模型，通过简单的安装指令，用户可以执行一条命令就在本地运行开源大型语言模型。</p> 
<p>    Ollama 支持 GPU/CPU 混合模式运行，允许用户根据自己的硬件条件（如 GPU、显存、CPU 和内存）选择不同量化版本的大模型。它提供了一种方式，使得即使在没有高性能 GPU 的设备上，也能够运行大型模型。<br>  </p> 
<hr> 
<h2><strong>三、前置条件</strong></h2> 
<h3><strong>3.1、JDK 17+</strong></h3> 
<p>    下载地址：<a href="https://www.oracle.com/java/technologies/downloads/#jdk17-windows" rel="nofollow" title="https://www.oracle.com/java/technologies/downloads/#jdk17-windows">https://www.oracle.com/java/technologies/downloads/#jdk17-windows</a></p> 
<p>    <img alt="" height="296" src="https://images2.imgbox.com/bc/b7/XxZKORdq_o.png" width="1200"></p> 
<p>    类文件具有错误的版本 61.0, 应为 52.0</p> 
<h3><strong>3.2、创建Maven项目</strong></h3> 
<p>    SpringBoot版本为3.2.3</p> 
<pre><code>&lt;parent&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;
    &lt;version&gt;3.2.3&lt;/version&gt;
    &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;
&lt;/parent&gt;</code></pre> 
<h3><strong>3.3、导入Maven依赖包</strong></h3> 
<pre><code>&lt;dependency&gt;
	&lt;groupId&gt;org.projectlombok&lt;/groupId&gt;
	&lt;artifactId&gt;lombok&lt;/artifactId&gt;
	&lt;optional&gt;true&lt;/optional&gt;
&lt;/dependency&gt;

&lt;dependency&gt;
	&lt;groupId&gt;ch.qos.logback&lt;/groupId&gt;
	&lt;artifactId&gt;logback-core&lt;/artifactId&gt;
&lt;/dependency&gt;

&lt;dependency&gt;
	&lt;groupId&gt;ch.qos.logback&lt;/groupId&gt;
	&lt;artifactId&gt;logback-classic&lt;/artifactId&gt;
&lt;/dependency&gt;

&lt;dependency&gt;
	&lt;groupId&gt;cn.hutool&lt;/groupId&gt;
	&lt;artifactId&gt;hutool-core&lt;/artifactId&gt;
	&lt;version&gt;5.8.24&lt;/version&gt;
&lt;/dependency&gt;

&lt;dependency&gt;
	&lt;groupId&gt;org.springframework.ai&lt;/groupId&gt;
	&lt;artifactId&gt;spring-ai-openai-spring-boot-starter&lt;/artifactId&gt;
	&lt;version&gt;0.8.0&lt;/version&gt;
&lt;/dependency&gt;

&lt;dependency&gt;
	&lt;groupId&gt;org.springframework.ai&lt;/groupId&gt;
	&lt;artifactId&gt;spring-ai-ollama-spring-boot-starter&lt;/artifactId&gt;
	&lt;version&gt;0.8.0&lt;/version&gt;
&lt;/dependency&gt;</code></pre> 
<h3><strong>3.4、 科学上网的软件</strong></h3> 
<h3><strong>3.5、 安装Ollama及部署Qwen模型</strong></h3> 
<p><strong>    参见：</strong><a href="https://blog.csdn.net/qq839019311/article/details/136474207?spm=1001.2014.3001.5502" title="开源模型应用落地-工具使用篇-Ollama（六）-CSDN博客">开源模型应用落地-工具使用篇-Ollama（六）-CSDN博客</a></p> 
<hr> 
<h2><strong>四、技术实现</strong></h2> 
<h3><strong>4.1、调用Open AI</strong></h3> 
<h4>4.1.1、非流式调用</h4> 
<pre><code class="language-java">@RequestMapping("/chat")
public String chat(){
	String systemPrompt = "{prompt}";
	SystemPromptTemplate systemPromptTemplate = new SystemPromptTemplate(systemPrompt);

	String userPrompt = "广州有什么特产？";
	Message userMessage = new UserMessage(userPrompt);

	Message systemMessage = systemPromptTemplate.createMessage(MapUtil.of("prompt", "you are a helpful AI assistant"));

	Prompt prompt = new Prompt(List.of(userMessage, systemMessage));

	List&lt;Generation&gt; response = openAiChatClient.call(prompt).getResults();

	String result = "";

	for (Generation generation : response){
		String content = generation.getOutput().getContent();
		result += content;
	}

	return result;
}</code></pre> 
<p>    调用结果：</p> 
<p>    <img alt="" height="119" src="https://images2.imgbox.com/1b/32/9jeSx21r_o.png" width="1200"></p> 
<h4>4.1.2、流式调用</h4> 
<pre><code class="language-java">@RequestMapping("/stream")
public SseEmitter stream(HttpServletResponse response){
	response.setContentType("text/event-stream");
	response.setCharacterEncoding("UTF-8");
	SseEmitter emitter = new SseEmitter();


	String systemPrompt = "{prompt}";
	SystemPromptTemplate systemPromptTemplate = new SystemPromptTemplate(systemPrompt);

	String userPrompt = "广州有什么特产？";
	Message userMessage = new UserMessage(userPrompt);

	Message systemMessage = systemPromptTemplate.createMessage(MapUtil.of("prompt", "you are a helpful AI assistant"));
	Prompt prompt = new Prompt(List.of(userMessage, systemMessage));

	openAiChatClient.stream(prompt).subscribe(x -&gt; {
		try {
			log.info("response: {}",x);
			List&lt;Generation&gt; generations = x.getResults();
			if(CollUtil.isNotEmpty(generations)){
				for(Generation generation:generations){
				   AssistantMessage assistantMessage =  generation.getOutput();
					String content = assistantMessage.getContent();
					if(StringUtils.isNotEmpty(content)){
						emitter.send(content);
					}else{
						if(StringUtils.equals(content,"null"))
						emitter.complete(); // Complete the SSE connection
					}
				}
			}


		} catch (Exception e) {
			emitter.complete();
			log.error("流式返回结果异常",e);
		}
	});

	return emitter;
}</code></pre> 
<p>流式输出返回的数据结构：</p> 
<p><img alt="" height="660" src="https://images2.imgbox.com/9c/12/BsfemsTl_o.png" width="1200"></p> 
<p>    调用结果：</p> 
<p><img alt="" height="706" src="https://images2.imgbox.com/24/db/wxNEot0h_o.png" width="1200"></p> 
<p> <img alt="" height="993" src="https://images2.imgbox.com/cf/28/MHolMKO4_o.png" width="527"></p> 
<h3><strong>4.2、调用Ollama API</strong></h3> 
<p><strong>Spring封装的很好，基本和调用OpenAI的代码一致</strong></p> 
<h4>4.2.1、非流式调用</h4> 
<pre><code class="language-java">@RequestMapping("/chat")
public String chat(){
	String systemPrompt = "{prompt}";
	SystemPromptTemplate systemPromptTemplate = new SystemPromptTemplate(systemPrompt);

	String userPrompt = "广州有什么特产？";
	Message userMessage = new UserMessage(userPrompt);

	Message systemMessage = systemPromptTemplate.createMessage(MapUtil.of("prompt", "you are a helpful AI assistant"));

	Prompt prompt = new Prompt(List.of(userMessage, systemMessage));

	List&lt;Generation&gt; response = ollamaChatClient.call(prompt).getResults();

	String result = "";

	for (Generation generation : response){
		String content = generation.getOutput().getContent();
		result += content;
	}

	return result;
}</code></pre> 
<p>调用结果：</p> 
<p>Ollam的server.log输出</p> 
<p><img alt="" height="231" src="https://images2.imgbox.com/9b/f5/ePq4s5bm_o.png" width="984"></p> 
<p></p> 
<p><img alt="" height="335" src="https://images2.imgbox.com/a5/86/KDC33XaT_o.png" width="1200"></p> 
<h4>4.2.2、流式调用</h4> 
<pre><code class="language-java">@RequestMapping("/stream")
public SseEmitter stream(HttpServletResponse response){
	response.setContentType("text/event-stream");
	response.setCharacterEncoding("UTF-8");
	SseEmitter emitter = new SseEmitter();


	String systemPrompt = "{prompt}";
	SystemPromptTemplate systemPromptTemplate = new SystemPromptTemplate(systemPrompt);

	String userPrompt = "广州有什么特产？";
	Message userMessage = new UserMessage(userPrompt);

	Message systemMessage = systemPromptTemplate.createMessage(MapUtil.of("prompt", "you are a helpful AI assistant"));
	Prompt prompt = new Prompt(List.of(userMessage, systemMessage));

	ollamaChatClient.stream(prompt).subscribe(x -&gt; {
		try {
			log.info("response: {}",x);
			List&lt;Generation&gt; generations = x.getResults();
			if(CollUtil.isNotEmpty(generations)){
				for(Generation generation:generations){
					AssistantMessage assistantMessage =  generation.getOutput();
					String content = assistantMessage.getContent();
					if(StringUtils.isNotEmpty(content)){
						emitter.send(content);
					}else{
						if(StringUtils.equals(content,"null"))
							emitter.complete(); // Complete the SSE connection
					}
				}
			}


		} catch (Exception e) {
			emitter.complete();
			log.error("流式返回结果异常",e);
		}
	});

	return emitter;
}</code></pre> 
<p>调用结果：</p> 
<p><img alt="" height="839" src="https://images2.imgbox.com/5d/75/CPVRsoiB_o.png" width="1200"></p> 
<p><img alt="" height="884" src="https://images2.imgbox.com/f3/5e/D0NyXdA3_o.png" width="851"></p> 
<p></p> 
<hr> 
<h2><strong>五、附带说明</strong></h2> 
<h3><strong>5.1、OpenAiChatClient默认使用gpt-3.5-turbo模型</strong></h3> 
<p><img alt="" height="351" src="https://images2.imgbox.com/c9/dd/PJBlC4cN_o.png" width="1138"></p> 
<h3><strong>5.2、流式输出如何关闭连接</strong></h3> 
<p>    不能判断是否为''（即空字符串），以下代码将提前关闭连接</p> 
<p><img alt="" height="137" src="https://images2.imgbox.com/26/51/Kcxd8Iwo_o.png" width="782"></p> 
<p>    流式输出会返回''的情况</p> 
<p><img alt="" height="413" src="https://images2.imgbox.com/af/ea/dOxEYACm_o.png" width="1200"></p> 
<p>      应该在返回内容为字符串null的时候关闭<img alt="" height="173" src="https://images2.imgbox.com/56/d5/N7ZtRi4r_o.png" width="734"></p> 
<p><img alt="" height="251" src="https://images2.imgbox.com/00/91/WaJ9AZDr_o.png" width="1200"></p> 
<h3 style="background-color:transparent;"><strong>5.3、配置文件中指定的Ollama的模型参数，要和运行的模型一致</strong></h3> 
<p><img alt="" height="174" src="https://images2.imgbox.com/0e/48/h5JdtX5t_o.png" width="572"></p> 
<p><img alt="" height="206" src="https://images2.imgbox.com/d3/f4/EItC9VHc_o.png" width="883"></p> 
<h3><strong>5.4、OpenAI调用完整代码</strong></h3> 
<pre><code class="language-java">import cn.hutool.core.collection.CollUtil;
import cn.hutool.core.map.MapUtil;
import jakarta.servlet.http.HttpServletResponse;
import lombok.extern.slf4j.Slf4j;
import org.apache.commons.lang3.StringUtils;
import org.springframework.ai.chat.Generation;
import org.springframework.ai.chat.messages.AssistantMessage;
import org.springframework.ai.chat.messages.Message;
import org.springframework.ai.chat.messages.UserMessage;
import org.springframework.ai.chat.prompt.Prompt;
import org.springframework.ai.chat.prompt.SystemPromptTemplate;
import org.springframework.ai.openai.OpenAiChatClient;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;
import org.springframework.web.servlet.mvc.method.annotation.SseEmitter;

import java.util.List;

@Slf4j
@RestController
@RequestMapping("/api")
public class OpenaiTestController {
    @Autowired
    private OpenAiChatClient openAiChatClient;

//    http://localhost:7777/api/chat
    @RequestMapping("/chat")
    public String chat(){
        String systemPrompt = "{prompt}";
        SystemPromptTemplate systemPromptTemplate = new SystemPromptTemplate(systemPrompt);

        String userPrompt = "广州有什么特产？";
        Message userMessage = new UserMessage(userPrompt);

        Message systemMessage = systemPromptTemplate.createMessage(MapUtil.of("prompt", "you are a helpful AI assistant"));

        Prompt prompt = new Prompt(List.of(userMessage, systemMessage));

        List&lt;Generation&gt; response = openAiChatClient.call(prompt).getResults();

        String result = "";

        for (Generation generation : response){
            String content = generation.getOutput().getContent();
            result += content;
        }

        return result;
    }

    @RequestMapping("/stream")
    public SseEmitter stream(HttpServletResponse response){
        response.setContentType("text/event-stream");
        response.setCharacterEncoding("UTF-8");
        SseEmitter emitter = new SseEmitter();


        String systemPrompt = "{prompt}";
        SystemPromptTemplate systemPromptTemplate = new SystemPromptTemplate(systemPrompt);

        String userPrompt = "广州有什么特产？";
        Message userMessage = new UserMessage(userPrompt);

        Message systemMessage = systemPromptTemplate.createMessage(MapUtil.of("prompt", "you are a helpful AI assistant"));
        Prompt prompt = new Prompt(List.of(userMessage, systemMessage));

        openAiChatClient.stream(prompt).subscribe(x -&gt; {
            try {
                log.info("response: {}",x);
                List&lt;Generation&gt; generations = x.getResults();
                if(CollUtil.isNotEmpty(generations)){
                    for(Generation generation:generations){
                       AssistantMessage assistantMessage =  generation.getOutput();
                        String content = assistantMessage.getContent();
                        if(StringUtils.isNotEmpty(content)){
                            emitter.send(content);
                        }else{
                            if(StringUtils.equals(content,"null"))
                            emitter.complete(); // Complete the SSE connection
                        }
                    }
                }


            } catch (Exception e) {
                emitter.complete();
                log.error("流式返回结果异常",e);
            }
        });

        return emitter;
    }
}
</code></pre> 
<h3><strong>5.5、Ollama调用完整代码</strong></h3> 
<pre><code class="language-java">import cn.hutool.core.collection.CollUtil;
import cn.hutool.core.map.MapUtil;
import jakarta.servlet.http.HttpServletResponse;
import lombok.extern.slf4j.Slf4j;
import org.apache.commons.lang3.StringUtils;
import org.springframework.ai.chat.Generation;
import org.springframework.ai.chat.messages.AssistantMessage;
import org.springframework.ai.chat.messages.Message;
import org.springframework.ai.chat.messages.UserMessage;
import org.springframework.ai.chat.prompt.Prompt;
import org.springframework.ai.chat.prompt.SystemPromptTemplate;
import org.springframework.ai.ollama.OllamaChatClient;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;
import org.springframework.web.servlet.mvc.method.annotation.SseEmitter;

import java.util.List;

@Slf4j
@RestController
@RequestMapping("/api")
public class OllamaTestController {
    @Autowired
    private OllamaChatClient ollamaChatClient;

    @RequestMapping("/chat")
    public String chat(){
        String systemPrompt = "{prompt}";
        SystemPromptTemplate systemPromptTemplate = new SystemPromptTemplate(systemPrompt);

        String userPrompt = "广州有什么特产？";
        Message userMessage = new UserMessage(userPrompt);

        Message systemMessage = systemPromptTemplate.createMessage(MapUtil.of("prompt", "you are a helpful AI assistant"));

        Prompt prompt = new Prompt(List.of(userMessage, systemMessage));

        List&lt;Generation&gt; response = ollamaChatClient.call(prompt).getResults();

        String result = "";

        for (Generation generation : response){
            String content = generation.getOutput().getContent();
            result += content;
        }

        return result;
    }


    @RequestMapping("/stream")
    public SseEmitter stream(HttpServletResponse response){
        response.setContentType("text/event-stream");
        response.setCharacterEncoding("UTF-8");
        SseEmitter emitter = new SseEmitter();


        String systemPrompt = "{prompt}";
        SystemPromptTemplate systemPromptTemplate = new SystemPromptTemplate(systemPrompt);

        String userPrompt = "广州有什么特产？";
        Message userMessage = new UserMessage(userPrompt);

        Message systemMessage = systemPromptTemplate.createMessage(MapUtil.of("prompt", "you are a helpful AI assistant"));
        Prompt prompt = new Prompt(List.of(userMessage, systemMessage));

        ollamaChatClient.stream(prompt).subscribe(x -&gt; {
            try {
                log.info("response: {}",x);
                List&lt;Generation&gt; generations = x.getResults();
                if(CollUtil.isNotEmpty(generations)){
                    for(Generation generation:generations){
                        AssistantMessage assistantMessage =  generation.getOutput();
                        String content = assistantMessage.getContent();
                        if(StringUtils.isNotEmpty(content)){
                            emitter.send(content);
                        }else{
                            if(StringUtils.equals(content,"null"))
                                emitter.complete(); // Complete the SSE connection
                        }
                    }
                }


            } catch (Exception e) {
                emitter.complete();
                log.error("流式返回结果异常",e);
            }
        });

        return emitter;
    }
}
</code></pre> 
<h3><strong>5.6、核心配置</strong></h3> 
<pre><code class="language-java">spring:
  ai:
    openai:
      api-key: sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
    ollama:
      base-url: http://localhost:11434
      chat:
        model: qwen:1.8b-chat</code></pre> 
<h3><strong>5.7、启动类</strong></h3> 
<pre><code class="language-java">import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;

@SpringBootApplication
public class AiApplication {

    public static void main(String[] args) {
        System.setProperty("http.proxyHost","127.0.0.1");
        System.setProperty("http.proxyPort","7078"); // 修改为你代理软件的端口
        System.setProperty("https.proxyHost","127.0.0.1");
        System.setProperty("https.proxyPort","7078"); // 同理

        SpringApplication.run(AiApplication.class, args);
    }

}</code></pre> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/306d3fad25b59393e7f9352827f668e0/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Unity2021.3.35f1配置安卓APK发布环境</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/d37bf442ff9ed2a8b3c66a9bb060aa50/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Java进程CPU高负载排查</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>