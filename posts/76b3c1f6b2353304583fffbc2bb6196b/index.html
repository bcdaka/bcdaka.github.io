<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>（教程）gpt-4o如何使用，怎么体验？gpt-4o和gpt-4-turbo的区别 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/76b3c1f6b2353304583fffbc2bb6196b/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="（教程）gpt-4o如何使用，怎么体验？gpt-4o和gpt-4-turbo的区别">
  <meta property="og:description" content="今天OpenAI发布了gpt-4o，我体验之后，gpt-4o简直逆天了。中文能力也挺别强。速度比现在的gpt4还要快。
早在 5 月 11 日，Sam 就在推文中表示：OpenAI 并没有推出 GPT-5，或搜索引擎，但团队一直在努力研发一些认为大家会喜欢的新东西（感觉就像是魔法一样）！
添加图片注释，不超过 140 字（可选）
现在来看应该说的就是 GPT-4o 了，它在免费和付费账户中均可使用（应该是目前最强的免费模型了）。除此之外，ChatGPT 页面也进行了许多细节方面的优化，并且推出了桌面应用，进一步提升用户体验。
一、什么是GPT-4o GPT-4o（“o”代表“omni”）是 OpenAI 在实现更自然人机交互方面的重要进展（Hello GPT-4o[1]）。它能够接受文本、音频和图像的任意组合输入，并生成相应的输出，包括文本、音频和图像。该模型在音频输入的响应时间非常短，最短可达 232 毫秒，平均为 320 毫秒，接近人类对话的反应时间。在文本（英语）和代码方面，GPT-4o 的表现与 GPT-4 Turbo 相当，但在处理非英语语言文本方面有显著提升，同时在 API 中的速度更快且成本降低 50%。此外，GPT-4o 在视觉和音频理解方面表现尤为出色。
在 GPT-4o 之前，使用语音模式与 ChatGPT 对话的平均延迟时间分别为 GPT-3.5 的 2.8 秒和 GPT-4 的 5.4 秒。实现这一功能的流水线涉及三个独立模型（音频 → 文本 → 音频）：一个用于将音频转录为文本，GPT-3.5 或 GPT-4 处理文本并生成文本，然后第三个模型将文本转换回音频。这种方式导致 GPT-4 无法直接感知语调、多位说话者或背景噪音，也无法生成笑声、歌唱或表达情感。
为了克服这些局限，OpenAI 训练了一个新的端到端跨文本、视觉和音频的单一模型（GPT-4o），这意味着所有输入和输出都由同一个神经网络处理。由于这是 OpenAI 第一个结合所有这些模态的模型，因此其功能和局限性仍在探索中。
它将首先在 ChatGPT 和 API 中作为文本和视觉模型提供（ChatGPT 将继续通过现有的语音模式功能支持语音）。具体来说，GPT-4o 将在 ChatGPT 免费版、Plus 版和团队版（企业版即将推出）以及 Chat Completions API、Assistants API 和 Batch API 中提供。">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-05-14T23:39:29+08:00">
    <meta property="article:modified_time" content="2024-05-14T23:39:29+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">（教程）gpt-4o如何使用，怎么体验？gpt-4o和gpt-4-turbo的区别</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>今天OpenAI发布了gpt-4o，我体验之后，gpt-4o简直逆天了。中文能力也挺别强。速度比现在的gpt4还要快。</p> 
<p>早在 5 月 11 日，Sam 就在推文中表示：OpenAI 并没有推出 GPT-5，或搜索引擎，但团队一直在努力研发一些认为大家会喜欢的新东西（感觉就像是魔法一样）！</p> 
<p></p> 
<p class="img-center"><img alt="" height="303" src="https://images2.imgbox.com/f5/d9/VMysIObR_o.png" width="628"></p> 
<p>添加图片注释，不超过 140 字（可选）</p> 
<p>现在来看应该说的就是 GPT-4o 了，它在免费和付费账户中均可使用（应该是目前最强的免费模型了）。除此之外，ChatGPT 页面也进行了许多细节方面的优化，并且推出了桌面应用，进一步提升用户体验。</p> 
<h4></h4> 
<h2>一、什么是GPT-4o</h2> 
<p>GPT-4o（“o”代表“omni”）是 OpenAI 在实现更自然人机交互方面的重要进展（Hello GPT-4o[1]）。它能够接受文本、音频和图像的任意组合输入，并生成相应的输出，包括文本、音频和图像。该模型在音频输入的响应时间非常短，最短可达 232 毫秒，平均为 320 毫秒，接近人类对话的反应时间。在文本（英语）和代码方面，GPT-4o 的表现与 GPT-4 Turbo 相当，但在处理非英语语言文本方面有显著提升，同时在 API 中的速度更快且成本降低 50%。此外，GPT-4o 在视觉和音频理解方面表现尤为出色。</p> 
<p>在 GPT-4o 之前，使用语音模式与 ChatGPT 对话的平均延迟时间分别为 GPT-3.5 的 2.8 秒和 GPT-4 的 5.4 秒。实现这一功能的流水线涉及三个独立模型（音频 → 文本 → 音频）：一个用于将音频转录为文本，GPT-3.5 或 GPT-4 处理文本并生成文本，然后第三个模型将文本转换回音频。这种方式导致 GPT-4 无法直接感知语调、多位说话者或背景噪音，也无法生成笑声、歌唱或表达情感。</p> 
<p>为了克服这些局限，OpenAI 训练了一个新的端到端跨文本、视觉和音频的单一模型（GPT-4o），这意味着所有输入和输出都由同一个神经网络处理。由于这是 OpenAI 第一个结合所有这些模态的模型，因此其功能和局限性仍在探索中。</p> 
<p>它将首先在 ChatGPT 和 API 中作为文本和视觉模型提供（ChatGPT 将继续通过现有的语音模式功能支持语音）。具体来说，GPT-4o 将在 ChatGPT 免费版、Plus 版和团队版（企业版即将推出）以及 Chat Completions API、Assistants API 和 Batch API 中提供。</p> 
<h4></h4> 
<h2>二、GPT-4o vs GPT-4 Turbo 的区别</h2> 
<p>GPT-4o 拥有相同的高智能性，但比 GPT-4 Turbo 更快、更便宜，且速率限制更高。具体来说：</p> 
<ul><li> <p>价格：GPT-4o 比 GPT-4 Turbo 便宜 50%，输入每百万 tokens 收费 $5，输出每百万 tokens 收费 $15。</p> </li><li> <p>速率限制：GPT-4o 的速率限制是 GPT-4 Turbo 的 5 倍——每分钟最多 1000 万 tokens。</p> </li><li> <p>速度：GPT-4o 是 GPT-4 Turbo 的两倍快。</p> </li><li> <p>视觉：在视觉能力相关评估中，GPT-4o 的表现优于 GPT-4 Turbo。</p> </li><li> <p>多语言：GPT-4o 对非英语语言的支持优于 GPT-4 Turbo。</p> </li></ul> 
<p>GPT-4o 目前有 128k 的上下文窗口，知识截止日期为 2023 年 10 月。</p> 
<p></p> 
<p class="img-center"><img alt="" height="731" src="https://images2.imgbox.com/81/72/J8NrIPrV_o.png" width="720"></p> 
<p>添加图片注释，不超过 140 字（可选）</p> 
<h4></h4> 
<h3>（1）ChatGPT 免费版</h3> 
<p>免费版用户将默认使用 GPT-4o，并限制使用 GPT-4o 发送消息的数量，这取决于当前的使用情况和需求。当不可用时，免费版用户将自动切换回 GPT-3.5。还可以有限地使用高级工具发送消息，例如：</p> 
<ul><li> <p>数据分析（Data analysis）</p> </li><li> <p>文件上传（File Uploads）</p> </li><li> <p>联网（Browse）</p> </li><li> <p>发现和使用 GPTs（Discovering and using GPTs）</p> </li><li> <p>视觉（Vision）</p> </li></ul> 
<p>GPT-4o 具有先进的视觉能力，能够更准确地理解你共享的图像，免费版用户随时可以点击 ChatGPT Plus 按钮来升级。</p> 
<p><strong>如果无法升级，或者不知道怎么升级Plus的用户，可以参考GPT4的升级方法：</strong><a class="link-info" href="https://openssora.com/chatgpt-upgrade-plus-gpt/" rel="nofollow" title="教程传送大门">教程传送大门</a></p> 
<p></p> 
<h4></h4> 
<h3>（2）LLM基准测试区别</h3> 
<p>可以到竞技场去测试GPT-4o 和 GPT-4 turbo两者到区别。另外竞技场是可以直接免费体验GPT-4o的地方。但是有次数限制。</p> 
<p></p> 
<p class="img-center"><img alt="" height="262" src="https://images2.imgbox.com/40/e2/GfCVwCUy_o.png" width="720"></p> 
<p>添加图片注释，不超过 140 字（可选）</p> 
<p></p> 
<p class="img-center"><img alt="" height="246" src="https://images2.imgbox.com/20/5d/WybAm4Jg_o.png" width="720"></p> 
<p>添加图片注释，不超过 140 字（可选）</p> 
<h4></h4> 
<h3>（3）通过申请Open API接口</h3> 
<p>通过Open API的接口，接入接口后，也可以快速的使用gpt-4o，前提你已经有了chatgpt账号。</p> 
<p></p> 
<p class="img-center"><img alt="" height="261" src="https://images2.imgbox.com/30/fc/D62fdFDp_o.png" width="720"></p> 
<p></p> 
<p></p> 
<p class="img-center"><img alt="" height="208" src="https://images2.imgbox.com/2d/88/xJA4hc1a_o.png" width="720"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/8463af6a29cc6893a9b366d621e322be/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【研发日记】Matlab/Simulink技能解锁(七)——两种复数移相算法</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/e48b6f66c11cb5e7c9487dcf145474b4/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Oracle JDK 与 OpenJDK：如何选择及其区别</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>