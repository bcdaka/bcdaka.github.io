<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Flink系列一：flink光速入门 (^_^) - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/fe020409b156bbcb621ae2168c5db36f/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="Flink系列一：flink光速入门 (^_^)">
  <meta property="og:description" content="引入 spark和flink的区别：在上一个spark专栏中我们了解了spark对数据的处理方式，在 Spark 生态体系中，对于批处理和流处理采用了不同的技术框架，批处理由 Spark-core,SparkSQL 实现，流处理由 Spark Streaming 实现，但是Flink 可以用同一套代码同时实现批处理和流处理。
虽然spark和flink都可以进行批处理和流处理，但是侧重点不同，spark侧重于批处理，flink侧重于流处理。而且Spark Streaming准确来说并不是严格意义上的实时，它本质上还是一种微批处理的结构，用近实时描述更准确，所以使用Spark Streaming来做实时计算会发现延时很高。这也是会出现flink去代替Spark Streaming完成实时计算的原因之一。
一、离线和实时的区别 首先要明确一个概念，离线计算也叫做批量处理，实时计算也叫做流式处理，都是同一种东西，只是叫法不同。
1、离线（批处理）和实时（流处理）的区别： 批处理的特点是有界、大量，批处理非常适合需要访问全套记录才能完成的计算工作，一般用于离线统计。流处理的特点是无界、实时，流处理方式无需针对整个数据集执行操作，而是对通过系统传输的每个数据项执行操作，一般用于实时统计。
二、主流实时计算框架对比 声明式：描述所需的数据转换和输出，而框架负责如何实现这些转换。它更加关注于“做什么”，而不是“如何做”。
组合式：开通过编写具体的指令来控制数据的流动和处理。
三、Spark Streaming微批处理 与Flink流式处理对比 从上图我们就可以看出Spark Streaming处理的方式是每隔一段时间，将该段时间产生的所有数据集中起来一起处理，而Flink流式处理是将数据产生一条就处理一条，这也是flink实时处理延迟低的原因。
四、Apache Flink简介 1、概述 Apache Flink 是一个实时计算框架和分布式处理引擎，用于在无边界和有边界数据流上进行有状态的计算。Flink 能在所有常见集群环境中运行，并能以内存速度和任意规模进行计算。
2、Flink特性 十大特性：
3、Apache Flink组件栈 4、Flink API 层级具体划分 ---------------------------------------------------------------------------------------------------------------------------------简要的介绍到这里结束，下一篇文章开始正式的学习。下面写一个简单的入门案例配上图解，便于对flink的理解。
五、入门案例（WordCount） 1、单词统计案例1（流处理/实时） import org.apache.flink.api.common.typeinfo.Types; import org.apache.flink.api.java.tuple.Tuple2; import org.apache.flink.streaming.api.datastream.DataStream; import org.apache.flink.streaming.api.datastream.KeyedStream; import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment; public class Demo1StreamWordCount { public static void main(String[] args) throws Exception { //1、获取flink执行环境 StreamExecutionEnvironment environment = StreamExecutionEnvironment.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-05-30T05:17:45+08:00">
    <meta property="article:modified_time" content="2024-05-30T05:17:45+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Flink系列一：flink光速入门 (^_^)</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2>引入</h2> 
<p><span style="color:#fe2c24;"><strong>spark和flink的区别：</strong></span>在上一个spark专栏中我们了解了spark对数据的处理方式，在 Spark 生态体系中，对于批处理和流处理采用了不同的技术框架，批处理由 Spark-core,SparkSQL 实现，流处理由 Spark Streaming 实现，但是<strong>Flink 可以用同一套代码同时实现批处理和流处理</strong>。</p> 
<p>虽然spark和flink都可以进行批处理和流处理，但是侧重点不同，<span style="color:#fe2c24;">spark侧重于批处理，flink侧重于流处理</span>。而且Spark Streaming准确来说并不是严格意义上的实时，它本质上还是一种<strong>微批处理</strong>的结构，用<span style="color:#0d0016;"><strong>近实时</strong></span>描述更准确，所以使用Spark Streaming来做实时计算会发现延时很高。这也是会出现flink去代替Spark Streaming完成实时计算的原因之一。</p> 
<p></p> 
<p></p> 
<h2>一、离线和实时的区别</h2> 
<p>首先要明确一个概念，离线计算也叫做批量处理，实时计算也叫做流式处理，都是同一种东西，只是叫法不同。</p> 
<h4>1、离线（批处理）和实时（流处理）的区别：</h4> 
<p><img alt="" height="463" src="https://images2.imgbox.com/de/9c/xZBfstIv_o.png" width="1200">       批处理的特点是有界、大量，批处理非常适合需要访问全套记录才能完成的计算工作，一般用于离线统计。流处理的特点是无界、实时，流处理方式无需针对整个数据集执行操作，而是对通过系统传输的每个数据项执行操作，一般用于实时统计。</p> 
<p></p> 
<h2>二、主流实时计算框架对比<img alt="" height="335" src="https://images2.imgbox.com/b3/af/upYG7cA8_o.png" width="1200"></h2> 
<p><strong>声明式：</strong>描述所需的数据转换和输出，而框架负责如何实现这些转换。它更加关注于“做什么”，而不是“如何做”。</p> 
<p><strong>组合式：</strong>开通过编写具体的指令来控制数据的流动和处理。</p> 
<p></p> 
<h2>三、Spark Streaming微批处理 与Flink流式处理对比</h2> 
<p><img alt="" height="595" src="https://images2.imgbox.com/3d/67/SW4NvrgB_o.png" width="1111"></p> 
<p>从上图我们就可以看出Spark Streaming处理的方式是每隔一段时间，将该段时间产生的所有数据集中起来一起处理，而Flink流式处理是将数据产生一条就处理一条，这也是flink实时处理延迟低的原因。</p> 
<p></p> 
<h2>四、Apache Flink简介</h2> 
<h3>1、概述</h3> 
<p>        Apache Flink 是一个<strong>实时计算</strong>框架和分布式处理引擎，<strong>用于在无边界和有边界数据流上进行有状态的计算</strong>。Flink 能在所有常见集群环境中运行，并能以内存速度和任意规模进行计算。</p> 
<p></p> 
<h3>2、Flink特性</h3> 
<p><img alt="" height="547" src="https://images2.imgbox.com/55/0c/utZDRKIG_o.png" width="1125"></p> 
<p><strong>十大特性：</strong></p> 
<p><img alt="" height="530" src="https://images2.imgbox.com/dd/9d/fUHvwV4R_o.png" width="1200"></p> 
<h2></h2> 
<h3>3、Apache Flink组件栈</h3> 
<p><img alt="" height="466" src="https://images2.imgbox.com/3b/b6/GCkmst2J_o.png" width="1188"></p> 
<h2></h2> 
<h3>4、Flink API 层级具体划分</h3> 
<p><img alt="" height="295" src="https://images2.imgbox.com/77/50/MlrVDFNa_o.png" width="758"></p> 
<h2></h2> 
<p></p> 
<p>---------------------------------------------------------------------------------------------------------------------------------简要的介绍到这里结束，下一篇文章开始正式的学习。下面写一个简单的入门案例配上图解，便于对flink的理解。</p> 
<h2></h2> 
<h2>五、入门案例（WordCount）</h2> 
<h4>1、单词统计案例1（流处理/实时）</h4> 
<pre><code class="language-java">import org.apache.flink.api.common.typeinfo.Types;
import org.apache.flink.api.java.tuple.Tuple2;
import org.apache.flink.streaming.api.datastream.DataStream;
import org.apache.flink.streaming.api.datastream.KeyedStream;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;

public class Demo1StreamWordCount {
    public static void main(String[] args) throws Exception {
        //1、获取flink执行环境
        StreamExecutionEnvironment environment = StreamExecutionEnvironment.getExecutionEnvironment();

        //设置任务的并行度,一个并行度相当于一个task
        environment.setParallelism(2);

        //设置数据从上游发送到下游的延迟时间，也可以不设置，默认延迟为200ms
        /*
             (1)一个正整数会根据该整数周期性地触发刷新
             (2)0在每条记录后触发刷新，从而最大限度地减少延迟
             (3)-1只在输出缓冲区已满时触发刷新，从而最大限度地提高吞吐量
         */
        environment.setBufferTimeout(200);

        //2、读取数据
        //在命令行执行nc -lk 8888来模拟实时数据生成
        DataStream&lt;String&gt; wordDS = environment.socketTextStream("master", 8888);

        //3、统计单词数量
        DataStream&lt;Tuple2&lt;String, Integer&gt;&gt; wordKVDS = wordDS.map(
                word-&gt;Tuple2.of(word,1), Types.TUPLE(Types.STRING,Types.INT)
                );

        //3、1分组统计单词的数量
        KeyedStream&lt;Tuple2&lt;String, Integer&gt;, String&gt; wordKeyBY = wordKVDS.keyBy(kv -&gt; kv.f0);

        //3.2对下标为1的列求和
        DataStream&lt;Tuple2&lt;String, Integer&gt;&gt; wordCounts = wordKeyBY.sum(1);

        //打印数据
        wordCounts.print();

        //启动flink
        environment.execute();
    }
}
</code></pre> 
<p><span style="color:#a2e043;">运行结果：</span></p> 
<p><img alt="" height="416" src="https://images2.imgbox.com/dc/e4/IA9MZKft_o.png" width="1200"></p> 
<p></p> 
<p><span style="color:#a2e043;">代码流程图解：</span></p> 
<p><img alt="" height="794" src="https://images2.imgbox.com/05/e4/efbEcANl_o.png" width="1200"></p> 
<p></p> 
<h4>2、单词统计案例2（批处理/离线）</h4> 
<pre><code class="language-java">import org.apache.flink.api.common.RuntimeExecutionMode;
import org.apache.flink.api.common.typeinfo.Types;
import org.apache.flink.api.java.tuple.Tuple2;
import org.apache.flink.streaming.api.datastream.DataStream;
import org.apache.flink.streaming.api.datastream.KeyedStream;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;

public class Demo2BatchWorldCounr {
    public static void main(String[] args) throws Exception {
        //1、创建Flink运行环境
        StreamExecutionEnvironment environment = StreamExecutionEnvironment.getExecutionEnvironment();

        /*
         *处理模式：
         * RuntimeExecutionMode.BATCH：批处理模式(MapReduce模型)
         * 1、输出最终结果
         * 2、批处理模式只能用于处理有界流
         *
         * RuntimeExecutionMode.STREAMING:流处理模式(持续型模型)
         * 1、输出连续结果（换句话说就是会不断输出中间结果）
         * 2、流处理模式，有界流和无界流都可以处理
         */

        //设置处理模式,如果不设置，默认是流处理模式
        environment.setRuntimeMode(RuntimeExecutionMode.BATCH);

        //2、读取文件（有向流）
        DataStream&lt;String&gt; wordDs = environment.readTextFile("flink/data/words.txt");

        //3、统计单词数量
        DataStream&lt;Tuple2&lt;String, Integer&gt;&gt; kvDS = wordDs.map(word -&gt; Tuple2.of(word, 1), Types.TUPLE(Types.STRING, Types.INT));

        //3.1分组统计单词数量
        KeyedStream&lt;Tuple2&lt;String, Integer&gt;, String&gt; keyBy = kvDS.keyBy(kv -&gt; kv.f0);

        //3.2对下标为1的列求和
        DataStream&lt;Tuple2&lt;String, Integer&gt;&gt; wordCounts = keyBy.sum(1);

        //打印数据
        wordCounts.print();

        //启动flink
        environment.execute();
    }
}
</code></pre> 
<p><span style="color:#a2e043;">运行结果：</span></p> 
<p><img alt="" height="320" src="https://images2.imgbox.com/b8/c7/LRSXwmic_o.png" width="1073"></p> 
<p><span style="color:#fe2c24;">注意：</span><span style="color:#0d0016;">在引入便提到过，</span>上述两个案例用的都是同一套代码，flink能够使用同一套代码执行流处理和批处理，完成了流批统一（批流一体）。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/ea5b4f529271b5129a6007da7f20b961/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Golang | Leetcode Golang题解之第119题杨辉三角II</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/e3c08c8126b643efc134f9beebb2e407/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【初阶数据结构】栈和队列（附题目）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>