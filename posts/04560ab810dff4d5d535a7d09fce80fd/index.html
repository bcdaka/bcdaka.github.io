<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>三问AI手机：什么意图？怎么识别？何种框架？ - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/04560ab810dff4d5d535a7d09fce80fd/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="三问AI手机：什么意图？怎么识别？何种框架？">
  <meta property="og:description" content="早在几个月前，就有媒体同行问我：AI手机到底是什么？跟智能手机有什么本质的不同？
试想一下，如果经常跟科技企业、技术趋势打交道的媒体人、分析师都对何谓AI手机云里雾里，更别提门店销售和消费者了。
2024被认为是AI手机元年，但今天走进线下门店，会发现店员和用户都对手机里的AI有啥不一样，感知并不明显。
移动互联网时代，我们常说手机是人“肢体”的延伸，可以让我们的“手”触及更远的地方，“看”到更广阔的事物。到了AI时代，手机是“大脑”的延伸，心念一动、言出法随，手机会根据我们的使用习惯和意图，主动提供有价值的服务。
所以，AI手机区别于智能机的一个更高阶、更本质的能力，就是“意图识别”。
目前，苹果阵营、华为鸿蒙阵营、荣耀OV安卓阵营，都将意图识别作为重点。
苹果CEO库克在AI系统“Apple Intelligence”的发布会上重点强调，在“苹果智能（Apple Intelligence）”的支持下，Siri具备了精准识别用户真正意图的能力。
而安卓和鸿蒙用户，恐怕对此并不陌生。
华荣OV等国产手机厂商早就上线了相应能力。荣耀在2023开发者大会上带来了行业首个基于AI意图识别的人机交互（IUI）操作系统——MagicOS 8.0；华为在HDC 2024上提出Harmony Intelligence，使得小艺能力大幅提升，能够理解并预测用户需求，并通过意图框架与合作伙伴应用场景整合。
OV虽然没有明确推出意图框架等平台，但也用行动参与其中。将大模型融入系统的底层设计中，升级OriginOS、BlueOS，来实现复杂的意图识别和推理决策。
那么用户又该迷惑了，各家都在说“意图识别”，到底有啥不一样呢？
“意图”是人心中所想，带有模糊和不确定性，“识别”结果也就有了很大的自由阐释空间，厂商如何避免自说自话，把“手机懂你”这件事落在实处？
就要依靠一个操作系统级的全局意图感知、理解、决策技术体系。
我们不妨把“意图识别框架”这一新概念详细拆分开，看看每一个环节的准入门槛是什么。
意图识别的第一步，当然是搞清楚什么是用户的“意图”，也就是手机厂商所说的“懂你”。
但“意图”并不是什么新概念。
早在互联网时代，意图识别就被应用于搜索引擎、广告推荐等场景。比如用户在搜索框输入“抓娃娃”，底层的检索策略要识别到这是电影需求，再去电影的数据库里检索，如果电影意图识别失败，返回的搜索结果中，根本没有《抓娃娃》电影相关内容，或者要翻好几页才显示，都会导致很糟糕的用户体验。所以，意图识别很早是科技企业研究的对象。
那么，AI手机所谓的“意图识别”，有啥特殊呢？
特殊在于，要游过深海。
今天手机所承载的“意图”，有两个特点：
一是范围广。一个动作或词语可能对应多个意图。现代消费电子设备的激增，带来了丰富多样的功能和服务，几乎涵盖了我们生活的方方面面，终端设备的多元、服务的多样，经常会出现多种意图，比如输入“长城”，可能是景点、电影或者汽车，这就使手机的意图识别更难做。
二是隐蔽性。传统意图识别可以根据用户给出的query词来进行判断，属于相对明确的“显性意图”，但日常使用手机时，还有大量隐性意图，比如眼睛注视手机屏幕，可能是想看时间、看新消息通知或日程计划；遗忘了出行计划，可实际上航班时间应该重点关注……这些是用户真实需要，但自己很少意识到或清晰表达出来的“隐性意图”，由于无法被清晰表达，难以转译成计算机语言，自然也就难以满足。
这些多且隐蔽的意图，构成了一片“意识深海”，需要手机厂商跋涉而过，找到一条最短路径。
由此，我们不难明确，AI手机意图识别的意义：
首先是化繁为简。通过洞察用户真正的需求，简化获取服务的步骤。
比如荣耀的“任意门”功能，带来了行业首个基于意图识别的人机交互，只需一拖不到1秒即可完成以往8步10秒的操作流程。当用户收到一条信息，复制之后，系统会自动分析语义并提炼关键内容，预判接下来的需求和操作，自动一步直达备忘录、地图等应用。华为智慧搜索支持“一键场景直达”、OPPO的ColorOS 14系统中的“流体云”功能，能预测用户行为，自动接入相应的使用场景……这些都简化了操作步骤。
其次，多想一步。通过隐性意图的识别和满足，带来超出用户期望的惊喜体验，构建差异化优势。
华为曾在一次分享会中提到，HarmonyOS意图框架可以通过长时间的学习训练，把人们自己都感觉不到的规律串联起来，并通过端侧的本地学习完成本地学习推荐，从而完成“超预期”的智慧搜索服务体验。
接下来，可以主动服务。比用户多想一步，就能将服务化被动为主动，更快更恰当地送到用户的眼前指尖。
目前，鸿蒙系统的场景化入口，就可以根据意图判断，将不同服务融入实际场景中，比如搭乘飞机，航班信息会优先显示在实时状态栏，荣耀Magic Live也有类似的主动服务，在观影、听歌、走进地铁站等场景中，提前将取票、听歌偏好、地铁码等原子化服务进行推送。
基于意图识别的人机交互，让你最需要的服务，涉过意识的深海。
洞察到了用户的意图，就能将服务精准送达吗？其实还要穿过一片AI的丛林。
有一个职场段子，老板让秘书定一个航班，最低段位的秘书，就只会看那一班，而最高段位的，还会提供多个航班选择，还考虑到出差需求，也把当地的住宿、餐饮等都提前查好备选。
如果让手机AI来应聘做你的助理，你希望是哪一个段位呢？
最高段位的AI助理，要真正理解你说的话背后的真实意图，并真正完成你想要的任务，其实要拆分为几个步骤。
步骤一：充分感知。一个优秀的助理，并非“胡子眉毛一把抓”，什么事情都要提前安排，而是结合上下文背景和情境，来对用户的潜在意图进行判断。所以，充分感知场景和情境，就非常必要了。
苹果高级副总裁Craig曾表示，Apple Intelligence的真正独特之处是能理解个人情境。能够根据你的个人数据，你现在打开的页面等背景，来理解需求。
比苹果更早一些，荣耀在2016年第一代Magic上首发Magic Live智慧系统，就能够自动感知判断。
步骤二：分析判断。
有了上下文背景，怎么推断多个意图的重要性和优先级呢？这就涉及语义理解了。目前，检索、问答等任务，由于用户有明确的检索词，利用大模型的自然语言理解能力，已经可以很好地推断用户到底想干什么。
其中比较具有代表性的是Apple Intelligence苹果智能&#43; GPT-4o大模型的方案。基于Apple Intelligence，苹果为Siri引入了多模态交互能力，可以从输入的自然语言中精准地进行用户意图识别，将任务拆分为多个任务，作为生成回答的基石。
步骤三：精准执行。
我们可以把每一个服务和功能，想象成一个个智能体，每个智能体只有孤立的识别和输出能力，要完成用户需要的复杂任务，需要对这些智能体进行精巧地、自动化地调取和编排，才能在意图判断之后，做出最恰当的执行反馈。
OPPO与IDC联合发布的《AI手机白皮书》中提到，成熟的AI手机系统要内嵌用户定义的专属智能体，不断理解用户习惯，自学习、直觉化。
在VDC开发者大会的一场技术论坛中，vivo的技术人员也透露，作为业内首个推出手机大模型（蓝心大模型）的厂商，他们很早就开始研究agent，对手机原生化服务组件的拆分很细、编排恰当。
这样看，从意图到服务之间，还要经过数据（感知）、算法（分析）、智能体（执行）的一片AI森林，只有具备完整AI技术体系的厂商，才能顺利跑通。
从上述意图识别的拆解中不难感受到，AI手机想做的“以人为中心”的主动服务，跨设备的数据流转（全场景感知），跨应用的服务触达，以及全局安全，是必不可少的。
如何将各层级、各终端、各系统、各应用都整合在一起？
意图框架，就是关键纽带，具备操作系统平台级的能力，可以让AI贯穿从数据到服务的完整链路，带来意图识别的能力飞跃。
目前，荣耀、华为、苹果都推出了自己的框架或平台。
其中，Magic Live智慧引擎是基于场景感知、用户理解和意图决策三大核心能力的平台型AI解决方案，形成了一个能够衔接各种轨迹和能力的“大脑”，实现了从单意图到多意图关联的精准意图判断。
苹果也采用了“荣耀模式”，App Intent意图框架包含了自学习引擎，实时学习用户行为，并根据时间和空间信息，提供个性化服务。
华为HarmonyOS的意图框架，则构建全局意图范式，基于鸿蒙系统的跨端互联协作优势，实现多维系统感知，结合AI大模型、AI推理框架、端云协同等计算处理能力，将需求传递给服务方，拉起/执行更恰当的服务。
总结一下荣耀、华为、苹果的意图框架，就是具备“地基”的能力。
为了更好的意图理解，三家都进行了深度的技术搭建，实现了操作系统级别、跨终端的意图感知、理解，只有深入到系统层面，才能真正重构手机AI体验。">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-08-20T21:36:44+08:00">
    <meta property="article:modified_time" content="2024-08-20T21:36:44+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">三问AI手机：什么意图？怎么识别？何种框架？</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div id="js_content"> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/63/42/ZnLJonst_o.gif" alt="d7fe07148e289382bc85fa2e1a88954a.gif"></p> 
 <p><img src="https://images2.imgbox.com/53/8f/ZV6k28yG_o.png" alt="569eab0db685cb64631390dc5e1f77d3.png"></p> 
 <p>早在几个月前，就有媒体同行问我：AI手机到底是什么？跟智能手机有什么本质的不同？</p> 
 <p>试想一下，如果经常跟科技企业、技术趋势打交道的媒体人、分析师都对何谓AI手机云里雾里，更别提门店销售和消费者了。</p> 
 <p>2024被认为是AI手机元年，但今天走进线下门店，会发现店员和用户都对手机里的AI有啥不一样，感知并不明显。</p> 
 <p>移动互联网时代，我们常说手机是人“肢体”的延伸，可以让我们的“手”触及更远的地方，“看”到更广阔的事物。到了AI时代，手机是“大脑”的延伸，心念一动、言出法随，手机会根据我们的使用习惯和意图，主动提供有价值的服务。</p> 
 <p>所以，<strong>AI手机区别于智能机的一个更高阶、更本质的能力，就是“意图识别”。</strong></p> 
 <p>目前，苹果阵营、华为鸿蒙阵营、荣耀OV安卓阵营，都将意图识别作为重点。</p> 
 <p>苹果CEO库克在AI系统“Apple Intelligence”的发布会上重点强调，在“苹果智能（Apple Intelligence）”的支持下，Siri具备了精准识别用户真正意图的能力。</p> 
 <p><img src="https://images2.imgbox.com/72/b5/yPR6KrQ8_o.png" alt="131e11426564f7f5aabae88343d9522a.png"></p> 
 <p>而安卓和鸿蒙用户，恐怕对此并不陌生。</p> 
 <p>华荣OV等国产手机厂商早就上线了相应能力。荣耀在2023开发者大会上带来了行业首个基于AI意图识别的人机交互（IUI）操作系统——MagicOS 8.0；华为在HDC 2024上提出Harmony Intelligence，使得小艺能力大幅提升，能够理解并预测用户需求，并通过意图框架与合作伙伴应用场景整合。</p> 
 <p>OV虽然没有明确推出意图框架等平台，但也用行动参与其中。将大模型融入系统的底层设计中，升级OriginOS、BlueOS，来实现复杂的意图识别和推理决策。</p> 
 <p>那么用户又该迷惑了，各家都在说“意图识别”，到底有啥不一样呢？</p> 
 <p>“意图”是人心中所想，带有模糊和不确定性，“识别”结果也就有了很大的自由阐释空间，厂商如何避免自说自话，把“手机懂你”这件事落在实处？</p> 
 <p>就要依靠一个操作系统级的全局意图感知、理解、决策技术体系。</p> 
 <p>我们不妨把“意图识别框架”这一新概念详细拆分开，看看每一个环节的准入门槛是什么。</p> 
 <p><img src="https://images2.imgbox.com/e6/31/LK8XjTjX_o.png" alt="5904369aed433cc8b6a287eb6d5f0049.png"></p> 
 <p>意图识别的第一步，当然是搞清楚什么是用户的“意图”，也就是手机厂商所说的“懂你”。</p> 
 <p>但“意图”并不是什么新概念。</p> 
 <p>早在互联网时代，意图识别就被应用于搜索引擎、广告推荐等场景。比如用户在搜索框输入“抓娃娃”，底层的检索策略要识别到这是电影需求，再去电影的数据库里检索，如果电影意图识别失败，返回的搜索结果中，根本没有《抓娃娃》电影相关内容，或者要翻好几页才显示，都会导致很糟糕的用户体验。所以，意图识别很早是科技企业研究的对象。</p> 
 <p>那么，AI手机所谓的“意图识别”，有啥特殊呢？</p> 
 <p>特殊在于，要游过深海。</p> 
 <p><strong>今天手机所承载的“意图”，有两个特点：</strong></p> 
 <p><strong>一是范围广。</strong>一个动作或词语可能对应多个意图。现代消费电子设备的激增，带来了丰富多样的功能和服务，几乎涵盖了我们生活的方方面面，终端设备的多元、服务的多样，经常会出现多种意图，比如输入“长城”，可能是景点、电影或者汽车，这就使手机的意图识别更难做。</p> 
 <p><strong>二是隐蔽性。</strong>传统意图识别可以根据用户给出的query词来进行判断，属于相对明确的“显性意图”，但日常使用手机时，还有大量隐性意图，比如眼睛注视手机屏幕，可能是想看时间、看新消息通知或日程计划；遗忘了出行计划，可实际上航班时间应该重点关注……这些是用户真实需要，但自己很少意识到或清晰表达出来的“隐性意图”，由于无法被清晰表达，难以转译成计算机语言，自然也就难以满足。</p> 
 <p><img src="https://images2.imgbox.com/ed/b8/IWxRq4g2_o.png" alt="6781f9cbe02a636895f75f086b935203.png"></p> 
 <p>这些多且隐蔽的意图，构成了一片“意识深海”，需要手机厂商跋涉而过，找到一条最短路径。</p> 
 <p><strong>由此，我们不难明确，AI手机意图识别的意义：</strong></p> 
 <p><strong>首先是化繁为简。通过洞察用户真正的需求，简化获取服务的步骤。</strong></p> 
 <p>比如荣耀的“任意门”功能，带来了行业首个基于意图识别的人机交互，只需一拖不到1秒即可完成以往8步10秒的操作流程。当用户收到一条信息，复制之后，系统会自动分析语义并提炼关键内容，预判接下来的需求和操作，自动一步直达备忘录、地图等应用。华为智慧搜索支持“一键场景直达”、OPPO的ColorOS 14系统中的“流体云”功能，能预测用户行为，自动接入相应的使用场景……这些都简化了操作步骤。</p> 
 <p><strong>其次，多想一步。通过隐性意图的识别和满足，带来超出用户期望的惊喜体验，构建差异化优势。</strong></p> 
 <p><img src="https://images2.imgbox.com/2b/57/UBmxlkpb_o.png" alt="35e713390a8ad634e8ddbc2c210e48a6.png"></p> 
 <p>华为曾在一次分享会中提到，HarmonyOS意图框架可以通过长时间的学习训练，把人们自己都感觉不到的规律串联起来，并通过端侧的本地学习完成本地学习推荐，从而完成“超预期”的智慧搜索服务体验。</p> 
 <p><strong>接下来，可以主动服务。比用户多想一步，就能将服务化被动为主动，更快更恰当地送到用户的眼前指尖。</strong></p> 
 <p>目前，鸿蒙系统的场景化入口，就可以根据意图判断，将不同服务融入实际场景中，比如搭乘飞机，航班信息会优先显示在实时状态栏，荣耀Magic Live也有类似的主动服务，在观影、听歌、走进地铁站等场景中，提前将取票、听歌偏好、地铁码等原子化服务进行推送。</p> 
 <p>基于意图识别的人机交互，让你最需要的服务，涉过意识的深海。</p> 
 <p><img src="https://images2.imgbox.com/c6/7f/WgDJMCzR_o.png" alt="658c22f7b3b696bd23db8c4c8ba740ec.png"></p> 
 <p>洞察到了用户的意图，就能将服务精准送达吗？其实还要穿过一片AI的丛林。</p> 
 <p>有一个职场段子，老板让秘书定一个航班，最低段位的秘书，就只会看那一班，而最高段位的，还会提供多个航班选择，还考虑到出差需求，也把当地的住宿、餐饮等都提前查好备选。</p> 
 <p>如果让手机AI来应聘做你的助理，你希望是哪一个段位呢？</p> 
 <p>最高段位的AI助理，要真正理解你说的话背后的真实意图，并真正完成你想要的任务，其实要拆分为几个步骤。</p> 
 <p><strong>步骤一：充分感知。</strong>一个优秀的助理，并非“胡子眉毛一把抓”，什么事情都要提前安排，<strong>而是结合上下文背景和情境，来对用户的潜在意图进行判断</strong>。所以，充分感知场景和情境，就非常必要了。</p> 
 <p>苹果高级副总裁Craig曾表示，Apple Intelligence的真正独特之处是能理解个人情境。能够根据你的个人数据，你现在打开的页面等背景，来理解需求。</p> 
 <p>比苹果更早一些，荣耀在2016年第一代Magic上首发Magic Live智慧系统，就能够自动感知判断。</p> 
 <p><img src="https://images2.imgbox.com/74/9c/k0v9XD8S_o.png" alt="f9cd0470ed452ae8351da2e01faa2f4e.png"></p> 
 <p><strong>步骤二：分析判断。</strong></p> 
 <p>有了上下文背景，怎么推断多个意图的重要性和优先级呢？这就涉及语义理解了。<strong>目前，检索、问答等任务，由于用户有明确的检索词，利用大模型的自然语言理解能力，已经可以很好地推断用户到底想干什么。</strong></p> 
 <p>其中比较具有代表性的是Apple Intelligence苹果智能+ GPT-4o大模型的方案。基于Apple Intelligence，苹果为Siri引入了多模态交互能力，可以从输入的自然语言中精准地进行用户意图识别，将任务拆分为多个任务，作为生成回答的基石。</p> 
 <p><img src="https://images2.imgbox.com/0f/63/0cHncNdw_o.png" alt="c39f220ade704dd74de90b34fe988efb.png"></p> 
 <p><strong>步骤三：精准执行。</strong></p> 
 <p>我们可以把每一个服务和功能，想象成一个个智能体，<strong>每个智能体只有孤立的识别和输出能力，要完成用户需要的复杂任务，需要对这些智能体进行精巧地、自动化地调取和编排</strong>，才能在意图判断之后，做出最恰当的执行反馈。</p> 
 <p>OPPO与IDC联合发布的《AI手机白皮书》中提到，成熟的AI手机系统要内嵌用户定义的专属智能体，不断理解用户习惯，自学习、直觉化。</p> 
 <p>在VDC开发者大会的一场技术论坛中，vivo的技术人员也透露，作为业内首个推出手机大模型（蓝心大模型）的厂商，他们很早就开始研究agent，对手机原生化服务组件的拆分很细、编排恰当。</p> 
 <p>这样看，从意图到服务之间，还要经过数据（感知）、算法（分析）、智能体（执行）的一片AI森林，只有具备完整AI技术体系的厂商，才能顺利跑通。</p> 
 <p><img src="https://images2.imgbox.com/c7/ab/g0QsWmHe_o.png" alt="19ac04dd09d59c3e6f61dfe120c4609e.png"></p> 
 <p>从上述意图识别的拆解中不难感受到，AI手机想做的“以人为中心”的主动服务，跨设备的数据流转（全场景感知），跨应用的服务触达，以及全局安全，是必不可少的。</p> 
 <p>如何将各层级、各终端、各系统、各应用都整合在一起？</p> 
 <p><strong>意图框架，就是关键纽带，具备操作系统平台级的能力，可以让AI贯穿从数据到服务的完整链路，带来意图识别的能力飞跃。</strong></p> 
 <p>目前，荣耀、华为、苹果都推出了自己的框架或平台。</p> 
 <p>其中，Magic Live智慧引擎是基于场景感知、用户理解和意图决策三大核心能力的平台型AI解决方案，形成了一个能够衔接各种轨迹和能力的“大脑”，实现了从单意图到多意图关联的精准意图判断。</p> 
 <p>苹果也采用了“荣耀模式”，App Intent意图框架包含了自学习引擎，实时学习用户行为，并根据时间和空间信息，提供个性化服务。</p> 
 <p>华为HarmonyOS的意图框架，则构建全局意图范式，基于鸿蒙系统的跨端互联协作优势，实现多维系统感知，结合AI大模型、AI推理框架、端云协同等计算处理能力，将需求传递给服务方，拉起/执行更恰当的服务。</p> 
 <p><strong>总结一下荣耀、华为、苹果的意图框架，就是具备“地基”的能力。</strong></p> 
 <p>为了更好的意图理解，三家都进行了深度的技术搭建，实现了操作系统级别、跨终端的意图感知、理解，只有深入到系统层面，才能真正重构手机AI体验。</p> 
 <p>同时，意图识别会涉及敏感数据的采集、共享和流动，在隐私安全方面，无论是一贯以隐私保护著称的苹果，还是荣耀的MagicGuard和MagicRing信任环，华为HarmonyOS NEXT的原生安全，都说明唯有平台级的AI能力，能在释放智慧的同时，守住安全的防线。</p> 
 <p><img src="https://images2.imgbox.com/0d/b4/MGxxHMbl_o.png" alt="c5960b91309199d395710a33df043ac6.png"></p> 
 <p>说到这里，你是不是有点疑惑，既然意图识别这么难、需要改造和创新的地方这么多，效果也不是一时半会儿能体现出来的，主打一个“谁用谁知道”，要不还是先躺平算了。</p> 
 <p>确实，意图识别的每一关都不好过，但这正是竞争白热化、同质化的手机市场，厂商突围的关键。</p> 
 <p>更何况，AI手机应该是消费电子市场最大的一个新蛋糕，华荣OV等一批国内厂商又早已“上桌”，只要攻克一些技术难关，就能成功分到大蛋糕，何乐而不为呢？</p> 
 <p>意图识别框架上，正在酝酿一场从“以手机为中心”到“以人为中心”的交互之变，AI手机才刚刚萌芽。</p> 
 <p><img src="https://images2.imgbox.com/27/5c/eE0tETP9_o.png" alt="69f3c489dd5a033835b82f2eb9a75bdd.png"></p> 
 <p>·</p> 
 <p>·</p> 
</div>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/5f41cadb89d60827b3adadfb7d2f9431/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【Linux学习】Linux开发工具——vim</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/90634d545d576c15696c58829ae5b3ab/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">STM32自制手持小风扇实验</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>