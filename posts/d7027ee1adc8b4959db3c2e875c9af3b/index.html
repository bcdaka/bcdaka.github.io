<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>过拟合与欠拟合 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/d7027ee1adc8b4959db3c2e875c9af3b/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="过拟合与欠拟合">
  <meta property="og:description" content="一，什么是过拟合和欠拟合 打个比方，一个小学生学习数学，刚开始可能什么也不会，慢慢开始学。对于学习较慢的同学，练习题都还没学懂就考试了，结果当然没考好。对于学习能力非常强的同学，才刚开始，所有的题都做会了，之后没事干，天天重复看以前做过的题，最后导致看到原题不用算就能背出答案，由于天天看原来的题，导致思维固化，原题稍微一改就想不出解决方法了。
上面这个例子就深度阐述了过拟合和欠拟合的关系，即
欠拟合：该学的没学会，要做的没做对。(训练集和测试集表现都不好)
过拟合：学的太猛，思维固化，只会做过的。（训练集表现很好，测试集表现不好）
两者的共同点是： 要做的做不对，即在测试集上表现不佳(如果表现好就不是问题了，就变成方法了)
二，过拟合出现的原因以及解决方法 1. 训练时间太久 -&gt; 减少训练时间
2. 数据质量很差。
一个是数据噪声大，一个有错误数据，一个是数据类型单一。 需要进行数据清洗或增加数据。
可能会过度捕捉数据的细节，导致过拟合。
3. 模型太大太复杂。
比如用GPT-3.5来学习论语，那就太小题大作了。数据集的大小应该与模型的大小相匹配。
方法：
4. Dropout。
随机丢弃一些参数不用去训练，这可以理解成一种特殊的集成学习，即每批数据都对应不同的一组参数，这组参数可以认为是一个子网络，每批数据都有一个子网络来进行学习，这样可以让不同的神经元不是很依赖其他的神经元，能够去学到更加鲁棒的特征表示。
5. 集成学习方法bagging。
通过用多个模型去学习数据，从而学习到不同方面的特征，来提高泛化能力，减小方差，降低过拟合的风险。
6. 交叉验证，如K折交叉验证。
通过循环学习，能够防止对特定的数据集过度拟合。
三，欠拟合出现的原因及解决方法 1. 训练时间太短 -&gt; 加长训练时间
2. 模型太简单学不会 -&gt; 模型变大，变深
3. 数据质量。
数据噪声过多，有错误。
可能会因噪声多无法捕捉数据的潜在特征，包括被噪声覆盖的特征。
4. 集成学习方法boosting。
通过顺序学习，能够尽可能的降低偏差，从而降低欠拟合的风险。
四，误差的推导，方差，偏差 其中消去的交叉项, 交叉项三项之间认为是独立的，那么E[XY] = E[X]E[Y], 其中
可得到最后三个交叉项消除
参考链接
欠拟合的原因以及解决办法（深度学习）_欠拟合的原因及解决办法-CSDN博客
dwnlpinterview/BasicAlgorithm/过拟合和欠拟合.md at main · hrwleo/dwnlpinterview (github.com)">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-08-06T20:27:41+08:00">
    <meta property="article:modified_time" content="2024-08-06T20:27:41+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">过拟合与欠拟合</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h3>一，什么是过拟合和欠拟合</h3> 
<p>打个比方，一个小学生学习数学，刚开始可能什么也不会，慢慢开始学。对于学习较慢的同学，练习题都还没学懂就考试了，结果当然没考好。对于学习能力非常强的同学，才刚开始，所有的题都做会了，之后没事干，天天重复看以前做过的题，最后导致看到原题不用算就能背出答案，由于天天看原来的题，导致思维固化，原题稍微一改就想不出解决方法了。</p> 
<p>上面这个例子就深度阐述了过拟合和欠拟合的关系，即</p> 
<p>欠拟合：该学的没学会，要做的没做对。(训练集和测试集表现都不好)</p> 
<p>过拟合：学的太猛，思维固化，只会做过的。（训练集表现很好，测试集表现不好）</p> 
<p>两者的共同点是： 要做的做不对，即在测试集上表现不佳(如果表现好就不是问题了，就变成方法了)</p> 
<h3>二，过拟合出现的原因以及解决方法</h3> 
<p>1. 训练时间太久 -&gt; 减少训练时间</p> 
<p>2. 数据质量很差。</p> 
<p>一个是数据噪声大，一个有错误数据，一个是数据类型单一。 需要进行数据清洗或增加数据。</p> 
<p>可能会过度捕捉数据的细节，导致过拟合。</p> 
<p>3. 模型太大太复杂。</p> 
<p>比如用GPT-3.5来学习论语，那就太小题大作了。数据集的大小应该与模型的大小相匹配。</p> 
<p>方法：</p> 
<p>4. Dropout。</p> 
<p>随机丢弃一些参数不用去训练，这可以理解成一种特殊的集成学习，即每批数据都对应不同的一组参数，这组参数可以认为是一个子网络，每批数据都有一个子网络来进行学习，这样可以让不同的神经元不是很依赖其他的神经元，能够去学到更加鲁棒的特征表示。</p> 
<p>5. 集成学习方法bagging。</p> 
<p>通过用多个模型去学习数据，从而学习到不同方面的特征，来提高泛化能力，减小方差，降低过拟合的风险。</p> 
<p>6. 交叉验证，如K折交叉验证。</p> 
<p>通过循环学习，能够防止对特定的数据集过度拟合。</p> 
<h3>三，欠拟合出现的原因及解决方法</h3> 
<p>1. 训练时间太短 -&gt; 加长训练时间</p> 
<p>2. 模型太简单学不会 -&gt; 模型变大，变深<img alt="E[f] = f\\ E[\varepsilon ] = 0 \ \ \ \ \ \ Var[\varepsilon ] = \sigma ^2" class="mathcode" src="https://images2.imgbox.com/e3/50/q7D89hxi_o.png"></p> 
<p>3. 数据质量。</p> 
<p>数据噪声过多，有错误。</p> 
<p>可能会因噪声多无法捕捉数据的潜在特征，包括被噪声覆盖的特征。</p> 
<p>4. 集成学习方法boosting。</p> 
<p>通过顺序学习，能够尽可能的降低偏差，从而降低欠拟合的风险。</p> 
<h3>四，误差的推导，方差，偏差</h3> 
<p><img alt="Sample\ data: D = \{(x_1,y_1),...,(x_n,y_n)\} \ from \ y = f(x) + \varepsilon \\ E_D[(y- \hat f(x))] = E[((f-E[\hat f]) + \varepsilon - (\hat f - E[\hat f))^2]\\ \hspace*{2.65cm} = E[(f-E[\hat f])^2 + \varepsilon ^2 + (\hat f -E[\hat f])^2]\\ \hspace*{2.65cm} = (f-E[\hat f])^2 + E[\varepsilon ^2 ] + E[(\hat f - E[\hat f])^2]\\ \hspace*{2.65cm} = Bias[\hat f]^2 + Var[\hat f] + \sigma ^2" class="mathcode" src="https://images2.imgbox.com/9a/6e/9BRoaVzO_o.png"></p> 
<p>其中消去的交叉项, 交叉项三项之间认为是独立的，那么E[XY] = E[X]E[Y], 其中</p> 
<p><img alt="E[f] = f\\ E[\varepsilon ] = 0 \ \ \ \ \ \ \ \ Var[\varepsilon ] = \sigma ^2\\ Var[\varepsilon ] = \frac{1}{n-1}\sum (\varepsilon_i - E[\varepsilon ])^2 = \frac{1}{n-1}\sum \varepsilon _i ^2 = \sigma ^2 = E[\varepsilon ^2]\\ E[\hat f - E[\hat f]] = 0" class="mathcode" src="https://images2.imgbox.com/c1/d8/LyzMXUs7_o.png"></p> 
<p>可得到最后三个交叉项消除</p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p>参考链接</p> 
<p><a href="https://blog.csdn.net/sinat_38079265/article/details/121786977" title="欠拟合的原因以及解决办法（深度学习）_欠拟合的原因及解决办法-CSDN博客">欠拟合的原因以及解决办法（深度学习）_欠拟合的原因及解决办法-CSDN博客</a></p> 
<p><a href="https://github.com/hrwleo/dwnlpinterview/blob/main/BasicAlgorithm/%E8%BF%87%E6%8B%9F%E5%90%88%E5%92%8C%E6%AC%A0%E6%8B%9F%E5%90%88.md" title="dwnlpinterview/BasicAlgorithm/过拟合和欠拟合.md at main · hrwleo/dwnlpinterview (github.com)">dwnlpinterview/BasicAlgorithm/过拟合和欠拟合.md at main · hrwleo/dwnlpinterview (github.com)</a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/23546629ddafcd64268bce58579634c1/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">人工智能深度学习系列—深入解析：均方误差损失（MSE Loss）在深度学习中的应用与实践</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/2f2a38942a64659d0b79fe1dbbc1d100/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">c＋＋STL中list介绍，模拟实现和list与vector对比</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>