<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Stable Diffusion AI绘画：绘画参数与原理全攻略参上！千万别错过！ - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/09d5a989bb3e7be0dc5710bcf93483c3/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="Stable Diffusion AI绘画：绘画参数与原理全攻略参上！千万别错过！">
  <meta property="og:description" content="一、基础模型和外挂VAE模型
Ⅰ. 基本术语讲解 基础模型（大模型/底模型）：属于预调模型，它决定了AI图片的主要风格。
VAE模型：全称Variational auto enconder变分自编码器，它类似于图片生成后的滤镜。
“基础模型”和“外挂VAE模型”之间的区别：首先正常情况下，每个模型都是自带了一个VAE的，VAE虽然不是滤镜但可以把它们看做是一种类似于滤镜的效果。而在大模型内的VAE出现问题、损坏或者是我们不满意的情况下，才需要使用外部手动去进行VAE选择VAE权重。
下载方式：大模型和VAE的下载我们可以从下面这些网站进行下载，而在模型下载的时候需要留意其哈希值。因为有些模型可能名字不一样，但哈希值一样，这就意味着两者几乎没有区别。
【网站①】：https://huggingface.co/
【网站②】：https://civitai.com/
Ⅱ. 不同基础模型的区别： 如下图显示，左边的图是二次元风格，右边的图是写实风格，模型的不同决定了基础的图像样子。
不同基础模型的区别
Ⅲ. 不同外挂VAE模型的区别： 如下图显示，该张图片展示了是否外挂VAE的差别，可以看到在加载新的一个VAE模型后，图片变得清晰起来。
是否加载VAE模型的区别
我们往下看，下面的图片展示了不同VAE模型下的图片差别，可以清晰看见图片的展现效果都不一样，“滤镜”效果完全不同。
不同VAE之间的区别
【总结】：所以，选用不同的VAE模型在制图的过程中很有必要，具体选用哪个模型，小编建议是用XYZ Plot（做出如图1-3的效果）选出你最喜欢的那一个。
二、clip终止层数
（clip skip）
【参考文章】：
https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/5674
大家想要深入理解 clip终止层数 需从Stable diffusion的原理入手，具体原理可以参考这两篇文章：
【SD原理性】：
https://openaccess.thecvf.com/content/CVPR2022/papers/Rombach_High-Resolution_Image_Synthesis_With_Latent_Diffusion_Models_CVPR_2022_paper.pdf
【SD解释性】：
https://stable-diffusion-art.com/how-stable-diffusion-work/
简单来说，我们可以将Stable diffusion理解为一个扩散模型（Stable：稳定的；diffusion：扩散），通过你所给的prompt词扩散出你想要的东西。
例如，当我们尝试生成一个人的插图时，会是这样的一个情况（当然，实际情况可能远比这个更复杂）：
Clip的原理图解
为什么是到12层呢？可能会有同学有所疑问，原因是因为在该版本的模型中，深度为12层。
而你想处理到那一层就是：
clip的终止层数（clipskip）
ClipSkip为1：处理到最后一层（即所有层）
ClipSkip为2：处理到倒数第二层（忽略最后一层）
ClipSkip为3：处理到倒数第三层（忽略最后和倒数第二层）
简而言之，随着剪辑跳过的增加，要处理的层数逐渐减少。结果就是详细信息被按顺序丢弃，没有反映的提示数量增加了。（一个词含有的意思很少，需要扩散来丰富）
再举一个比较具体的例子：
Prompt：masterpiece, best quality, 1girl, white hair, black skirt, purple eyes, full body, black dress.
不同clip skip的表现
可见ClipSkip值较小，生成含有丰富提示词的插图；ClipSkip的值较大，生成忽略提示词的插图。
三、提示词与预设样式存储
提示词与预设样式存储在网上都有很多资料，小编这里就不再赘述了，大家感兴趣可以去B站或者百度搜索一下。总之，提示词需要具有一定的指向性和有效性，同时注意权重的搭配，以及英文输入。
【权重改变格式】：
（）：一个括号的权重提升1.1倍。">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-04-29T11:21:46+08:00">
    <meta property="article:modified_time" content="2024-04-29T11:21:46+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Stable Diffusion AI绘画：绘画参数与原理全攻略参上！千万别错过！</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p><strong>一、基础模型和外挂VAE模型</strong></p> 
<h4><a id="__5"></a><strong>Ⅰ. 基本术语讲解</strong></h4> 
<p>基础模型（大模型/底模型）：属于预调模型，它决定了AI图片的主要风格。</p> 
<p>VAE模型：全称Variational auto enconder变分自编码器，它类似于图片生成后的滤镜。</p> 
<p>“基础模型”和“外挂VAE模型”之间的区别：首先正常情况下，每个模型都是自带了一个VAE的，VAE虽然不是滤镜但可以把它们看做是一种类似于滤镜的效果。而在大模型内的VAE出现问题、损坏或者是我们不满意的情况下，才需要使用外部手动去进行VAE选择VAE权重。</p> 
<p>下载方式：大模型和VAE的下载我们可以从下面这些网站进行下载，而在模型下载的时候需要留意其哈希值。因为有些模型可能名字不一样，但哈希值一样，这就意味着两者几乎没有区别。</p> 
<p>【网站①】：https://huggingface.co/</p> 
<p>【网站②】：https://civitai.com/</p> 
<h4><a id="__29"></a><strong>Ⅱ. 不同基础模型的区别：</strong></h4> 
<p>如下图显示，左边的图是二次元风格，右边的图是写实风格，模型的不同决定了基础的图像样子。</p> 
<p><img src="https://images2.imgbox.com/2d/95/jtHAKXr4_o.jpg" alt=""></p> 
<p>不同基础模型的区别</p> 
<h4><a id="_VAE_43"></a><strong>Ⅲ. 不同外挂VAE模型的区别：</strong></h4> 
<p>如下图显示，该张图片展示了是否外挂VAE的差别，可以看到在加载新的一个VAE模型后，图片变得清晰起来。</p> 
<p><img src="https://images2.imgbox.com/8c/51/5ISc52tC_o.jpg" alt=""></p> 
<p>是否加载VAE模型的区别</p> 
<p>我们往下看，下面的图片展示了不同VAE模型下的图片差别，可以清晰看见图片的展现效果都不一样，“滤镜”效果完全不同。</p> 
<p><img src="https://images2.imgbox.com/7a/0d/X3HSqPI8_o.jpg" alt=""></p> 
<p>不同VAE之间的区别</p> 
<p>【总结】：所以，选用不同的VAE模型在制图的过程中很有必要，具体选用哪个模型，小编建议是用XYZ Plot（做出如图1-3的效果）选出你最喜欢的那一个。</p> 
<hr> 
<p><strong>二、clip终止层数</strong></p> 
<p><strong>（clip skip）</strong></p> 
<p>【参考文章】：</p> 
<p>https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/5674</p> 
<p>大家想要深入理解 clip终止层数 需从Stable diffusion的原理入手，具体原理可以参考这两篇文章：</p> 
<p>【SD原理性】：</p> 
<p>https://openaccess.thecvf.com/content/CVPR2022/papers/Rombach_High-Resolution_Image_Synthesis_With_Latent_Diffusion_Models_CVPR_2022_paper.pdf</p> 
<p>【SD解释性】：</p> 
<p>https://stable-diffusion-art.com/how-stable-diffusion-work/</p> 
<p>简单来说，我们可以将Stable diffusion理解为一个扩散模型（Stable：稳定的；diffusion：扩散），通过你所给的prompt词扩散出你想要的东西。</p> 
<p>例如，当我们尝试生成一个人的插图时，会是这样的一个情况（当然，实际情况可能远比这个更复杂）：</p> 
<p><img src="https://images2.imgbox.com/95/8b/JkrNGaoK_o.jpg" alt=""></p> 
<p>Clip的原理图解</p> 
<p>为什么是到12层呢？可能会有同学有所疑问，原因是因为在该版本的模型中，深度为12层。</p> 
<p>而你想处理到那一层就是：</p> 
<p>clip的终止层数（clipskip）</p> 
<ul><li> <p>ClipSkip为1：处理到最后一层（即所有层）</p> </li><li> <p>ClipSkip为2：处理到倒数第二层（忽略最后一层）</p> </li><li> <p>ClipSkip为3：处理到倒数第三层（忽略最后和倒数第二层）</p> </li></ul> 
<p>简而言之，随着剪辑跳过的增加，要处理的层数逐渐减少。结果就是详细信息被按顺序丢弃，没有反映的提示数量增加了。（一个词含有的意思很少，需要扩散来丰富）</p> 
<p>再举一个比较具体的例子：</p> 
<p>Prompt：masterpiece, best quality, 1girl, white hair, black skirt, purple eyes, full body, black dress.</p> 
<p><img src="https://images2.imgbox.com/95/8a/Mo2BD4Lv_o.jpg" alt=""></p> 
<p>不同clip skip的表现</p> 
<p>可见ClipSkip值较小，生成含有丰富提示词的插图；ClipSkip的值较大，生成忽略提示词的插图。</p> 
<hr> 
<p><strong>三、提示词与预设样式存储</strong></p> 
<p>提示词与预设样式存储在网上都有很多资料，小编这里就不再赘述了，大家感兴趣可以去B站或者百度搜索一下。总之，提示词需要具有一定的指向性和有效性，同时注意权重的搭配，以及英文输入。</p> 
<p>【权重改变格式】：</p> 
<p>（）：一个括号的权重提升1.1倍。</p> 
<p>（（））：两个括号的权重提升1.1^2倍。</p> 
<p>（prompt词：1.8）：该词权重提升1.8倍。</p> 
<p>接下来小编给大家介绍一下本地SD的快捷键：</p> 
<p><img src="https://images2.imgbox.com/03/db/OACvZNhD_o.jpg" alt=""></p> 
<p>快捷键一览</p> 
<p>这些键从左到右依次为：</p> 
<p>从提示词或上次生成的图片中读取生成参数、清空提示词内容、显示和隐藏扩展模型、将所选预选样式插入到当前提示词之后、将当前提示词存储为预设样式。</p> 
<p>通过这些可以快速帮我们念咒语，做到无吟唱施法。</p> 
<hr> 
<p><strong>四、迭代步数（采样步数）</strong></p> 
<p>首先，我们简单介绍一下Stable diffusion的相关原理。小编前天发布的SD文章也有详细介绍，这里再简单地提一下。</p> 
<p>我们可以把模型理解为一个迭代过程——从文本输入生成随机噪声开始的重复循环，每一步都会消除一些噪声，并随着迭代步数的增加会产生更高质量的图像。而当完成所需的步骤数时，重复就会停止（可以结合第五节采样方式来看）。</p> 
<p>一般来说，大约25个采样步骤（20个也可以）通常足以获得高质量图像，使用更多的步骤可能会产生略有不同的图片，但不一定有更好的质量。此外，当我们使用的步骤越多，生成图像所需的时间就会越多。不过在大多数情况下，额外的等待时间是不值得的。</p> 
<p>例如，一个“太空中的小狗”的展示（迭代步数从1-100，gif图片较大可能需要一定的等待时间）：</p> 
<p><img src="https://images2.imgbox.com/f7/c5/KPTHzYVw_o.jpg" alt=""></p> 
<p>不同迭代步数的区别</p> 
<p>迭代步数为4-7时，小狗会从斑点中显现，然后在生成大约20-25个步骤后，它就达到了较高质量。</p> 
<p>超过25个步骤后不会造成质量的显着差异，只是小狗的形状将会反复变化，但没有产生更多细节。</p> 
<hr> 
<p><strong>五、不同采样方法的区别</strong></p> 
<p><img src="https://images2.imgbox.com/74/5a/mpH8UyzL_o.jpg" alt=""></p> 
<p>采样方法一览</p> 
<p>为了生成图像，Stable diffusion首先在潜在空间中生成完全随机的图像，然后噪声预测器估计图像的噪声，再从图像中减去预测的噪声。这个过程重复十几次，最后便会得到一个干净的图像。</p> 
<p>这个去噪过程称为采样，因为稳定扩散在每个步骤中都会生成一个新的样本图像。抽样所采用的方法称为抽样器或抽样方法。</p> 
<h4><a id="__267"></a><strong>Ⅰ. 采样方式介绍</strong></h4> 
<p>从目前这些采样方法来看，主要分为几个类型：Euler、LMS、Heun、DPM、DDIM、PLMS、UniPC，下面我们来详细解释一下！</p> 
<p><strong>①：《Euler》</strong></p> 
<p>其是最简单的采样器。它在数学上与求解常微分方程的欧拉方法相同。它是完全确定性的，这意味着采样期间不会添加随机噪声。</p> 
<p>它的一般步骤为：</p> 
<ul><li> <p>步骤1：噪声预测器根据潜在图像估计噪声图像。</p> </li><li> <p>步骤2：根据噪声表计算需要减去的噪声量。这就是当前步骤和下一步之间的噪声差异。</p> </li><li> <p>步骤3：将潜像减去归一化噪声图像（来自步骤1）乘以要减少的噪声量（来自步骤2）。</p> </li><li> <p>重复步骤1至3，直到噪声计划结束。</p> </li></ul> 
<p><strong>②：《LMS》</strong></p> 
<p>其与欧拉方法非常相似，线性多步法(LMS)是求解常微分方程的标准方法。它的目的是通过巧妙地使用先前时间步骤的值来提高准确性。</p> 
<p><strong>③：《Heun》</strong></p> 
<p>是对Euler方法更精确的改进。但它每一步需要预测噪声两次，因此比欧拉慢两倍。</p> 
<p><strong>④：《DPM》</strong></p> 
<p>DPM（扩散概率模型求解器）和DPM++（对DPM的改进）是为2022年发布的扩散模型设计的新采样器，它们代表了一系列具有相似架构的求解器。DPM自适应可能会很慢，因为它不能保证在采样步骤数内完成。</p> 
<p><strong>⑤：《DPM2》</strong></p> 
<p>DPM和DPM2类似，只不过DPM2的DPM-Solver-2算法，求解器精确到二阶，其更加准确但速度更慢。</p> 
<p><strong>⑥：《DDIM和PLMS》</strong></p> 
<p>DDIM（去噪扩散隐式模型）和PLMS（伪线性多步方法）是原始稳定扩散v1附带的采样器。DDIM是最早为扩散模型设计的采样器之一。PLMS是DDIM更新、更快的替代方案。它们通常被认为已经过时并且不再广泛使用。</p> 
<p><strong>⑦：《UniPC》</strong></p> 
<p>（Unified Predictor Corrector方法）这个是2023年新开发的扩散采样器，其由两部分组成：统一预测器(UniP)、统一校正器(UniC)它支持任何求解器和噪声预测器。</p> 
<h4><a id="_352"></a><strong>Ⅳ.总结与建议</strong></h4> 
<p>就收敛行为而言（选择收敛=选择稳定、可重复的图像）：</p> 
<ul><li> <p>不收敛：Euler_a、DPM2a、DPMFast、DDIM、PLMS、DPMAdaptive、DPM2aKarras</p> </li><li> <p>收敛：Euler、LMS、Heun、DPM2、DPM++2M、LMSKarras、DPM2Karras、DPM++2MKarras</p> </li></ul> 
<p>按所需步骤时间：</p> 
<p>Euler_a=Euler=DPM++2M=LMSKarras（图像在高步长时退化）＞LMS=DPM++2MKarras=Heun（较慢）=DPM++2S a（较慢）=DPM++2S a Karras&gt;DDIM=PLMS=DPM2（较慢）=DPM2 Karras&gt;DPM快速=DPM2a（较慢）</p> 
<ul><li> <p>如果你想使用快速且质量不错的东西，那么最好的选择是DPM++2M Karras，UniPC</p> </li><li> <p>如果你想要高质量的图像并且不关心收敛，那么不错的选择是DPM++SDE Karras</p> </li><li> <p>如果你喜欢稳定、可重复的图像，请避免使用任何ancestral samplers（加a的东西）。</p> </li><li> <p>如果你喜欢简单的东西，Euler和Heun是不错的选择。</p> </li></ul> 
<hr> 
<p><strong>六、面部修复</strong></p> 
<p>其实SD内置的面部修复目前的用处并不大，我简单跑了两组对比图，大家可以简单看一下效果：</p> 
<p><img src="https://images2.imgbox.com/b1/a6/bHEdpGed_o.jpg" alt=""></p> 
<p>动漫风格的面部修复（自制）</p> 
<p><img src="https://images2.imgbox.com/cd/ee/NLZcXKXg_o.jpg" alt=""></p> 
<p>真人风格的面部修复（自制）</p> 
<p>这两组图中，左边是没有开面部修复，右边是开了面部修复的。其中真人的要变得稍微自然一点（也没有过于改进），但是动漫风格的反而变得模糊了，所以面部修复一般是不建议用在非写实的图片生成上。</p> 
<p>不过相比于SD内置的面部修复，这里更推荐使用after detailer。</p> 
<h3><a id="_422"></a>写在最后</h3> 
<p><font face="幼圆" size="4" color="red">感兴趣的小伙伴，赠送全套AIGC学习资料，包含AI绘画、AI人工智能等前沿科技教程和软件工具，具体看这里。<br> </font><br> <img src="https://images2.imgbox.com/18/7d/WL9DcQAo_o.png"></p> 
<p>AIGC技术的未来发展前景广阔，随着人工智能技术的不断发展，AIGC技术也将不断提高。未来，AIGC技术将在游戏和计算领域得到更广泛的应用，使游戏和计算系统具有更高效、更智能、更灵活的特性。同时，AIGC技术也将与人工智能技术紧密结合，在更多的领域得到广泛应用，对程序员来说影响至关重要。未来，AIGC技术将继续得到提高，同时也将与人工智能技术紧密结合，在更多的领域得到广泛应用。<br>  <br> <img src="https://images2.imgbox.com/87/a6/1IpUEzMA_o.png" alt="在这里插入图片描述"></p> 
<p><strong>一、AIGC所有方向的学习路线</strong></p> 
<p>AIGC所有方向的技术点做的整理，形成各个领域的知识点汇总，它的用处就在于，你可以按照下面的知识点去找对应的学习资源，保证自己学得较为全面。</p> 
<p><img src="https://images2.imgbox.com/67/bc/oz0YkeS7_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/6f/a3/oc4v6fLm_o.png" alt="在这里插入图片描述"></p> 
<p><strong>二、AIGC必备工具</strong></p> 
<p>工具都帮大家整理好了，安装就可直接上手！<br> <img src="https://images2.imgbox.com/04/04/UG5l4jiR_o.png" alt="在这里插入图片描述"></p> 
<p><strong>三、最新AIGC学习笔记</strong></p> 
<p>当我学到一定基础，有自己的理解能力的时候，会去阅读一些前辈整理的书籍或者手写的笔记资料，这些笔记详细记载了他们对一些技术点的理解，这些理解是比较独到，可以学到不一样的思路。<br> <img src="https://images2.imgbox.com/91/ad/cXRr3Uqa_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/9b/e4/XDECj2P8_o.png" alt="在这里插入图片描述"></p> 
<p><strong>四、AIGC视频教程合集</strong></p> 
<p>观看全面零基础学习视频，看视频学习是最快捷也是最有效果的方式，跟着视频中老师的思路，从基础到深入，还是很容易入门的。</p> 
<p><img src="https://images2.imgbox.com/97/d7/jD0Ix1fc_o.png" alt="在这里插入图片描述"></p> 
<p><strong>五、实战案例</strong></p> 
<p>纸上得来终觉浅，要学会跟着视频一起敲，要动手实操，才能将自己的所学运用到实际当中去，这时候可以搞点实战案例来学习。<br> <img src="https://images2.imgbox.com/66/f6/8XKXGC69_o.png" alt="在这里插入图片描述"></p> 
<img src="https://images2.imgbox.com/ee/06/oy0Ze4xq_o.png"> 若有侵权，请联系删除
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/81e2dc6a615c19e88e98cf4f813ad8ff/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【Spring AI】05. 向量数据库-Redis</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/ae1b47be47e6fc82baa036f7b2c28a95/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">vue3面试题：2024 最新前端 Vue 3</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>