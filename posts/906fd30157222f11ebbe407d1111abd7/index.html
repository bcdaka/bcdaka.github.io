<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>基于协同注意力的视觉-语言嵌入用于机器人手术视觉问题定位回答 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/906fd30157222f11ebbe407d1111abd7/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="基于协同注意力的视觉-语言嵌入用于机器人手术视觉问题定位回答">
  <meta property="og:description" content=" 文章目录 CAT-ViL: Co-attention Gated Vision-Language Embedding for Visual Question Localized-Answering in Robotic Surgery摘要方法实验结果 CAT-ViL: Co-attention Gated Vision-Language Embedding for Visual Question Localized-Answering in Robotic Surgery 摘要 医学生和初级外科医生经常依赖于资深外科医生和专家来回答他们在学习手术过程中的问题,但专家通常忙于临床和学术工作,很难提供指导。现有基于深度学习的外科视觉问题回答(VQA)系统只能提供简单的答案,而无法给出答案的位置信息。同时,视觉-语言(ViL)嵌入在这类任务中也鲜有研究。因此,一个能够提供视觉问题定位回答(VQLA)的系统对于医学生和初级外科医生学习和理解手术视频会很有帮助。
论文提出了一种基于端到端Transformer的CAT-ViL (Co-Attention gaTed Vision-Language)嵌入模型用于外科VQLA任务,不需要通过检测模型进行特征提取。
代码地址 方法 实验结果 ">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-06-05T08:51:30+08:00">
    <meta property="article:modified_time" content="2024-06-05T08:51:30+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">基于协同注意力的视觉-语言嵌入用于机器人手术视觉问题定位回答</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#CATViL_Coattention_Gated_VisionLanguage_Embedding_for_Visual_Question_LocalizedAnswering_in_Robotic_Surgery_1" rel="nofollow">CAT-ViL: Co-attention Gated Vision-Language Embedding for Visual Question Localized-Answering in Robotic Surgery</a></li><li><ul><li><a href="#_2" rel="nofollow">摘要</a></li><li><a href="#_8" rel="nofollow">方法</a></li><li><a href="#_10" rel="nofollow">实验结果</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h2><a id="CATViL_Coattention_Gated_VisionLanguage_Embedding_for_Visual_Question_LocalizedAnswering_in_Robotic_Surgery_1"></a>CAT-ViL: Co-attention Gated Vision-Language Embedding for Visual Question Localized-Answering in Robotic Surgery</h2> 
<h3><a id="_2"></a>摘要</h3> 
<ol><li>医学生和初级外科医生经常依赖于资深外科医生和专家来回答他们在学习手术过程中的问题,但专家通常忙于临床和学术工作,很难提供指导。</li><li>现有基于深度学习的外科视觉问题回答(VQA)系统只能提供简单的答案,而无法给出答案的位置信息。同时,视觉-语言(ViL)嵌入在这类任务中也鲜有研究。</li><li>因此,一个能够提供视觉问题定位回答(VQLA)的系统对于医学生和初级外科医生学习和理解手术视频会很有帮助。<br> 论文提出了一种基于端到端Transformer的CAT-ViL (Co-Attention gaTed Vision-Language)嵌入模型用于外科VQLA任务,不需要通过检测模型进行特征提取。<br> <a href="https://github.com/longbai1006/CAT-ViL">代码地址</a></li></ol> 
<h3><a id="_8"></a>方法</h3> 
<p><img src="https://images2.imgbox.com/b7/1e/F5mz2AU3_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="_10"></a>实验结果</h3> 
<p><img src="https://images2.imgbox.com/97/3d/jKxK6x8n_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/27/54/HcuHlKSI_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/11/e9/SwJTGWc5_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/bb/cb/PKZuxDl0_o.png" alt="在这里插入图片描述"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/938329c8b42b09554daf3d3d7adc2e90/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">前端蜗牛排序实现和具体应用场景</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/4766f131bfb8be1dbbcb7ba02a4fd7ed/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">香港 Web3 的分岔路口：to 创新 or to 监管，这并不是一个问题</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>