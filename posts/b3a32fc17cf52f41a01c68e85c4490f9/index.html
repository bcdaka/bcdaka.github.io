<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>[深度学习入门案例2]基于卷积神经网络与Keras构建人脸识别模型 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/b3a32fc17cf52f41a01c68e85c4490f9/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="[深度学习入门案例2]基于卷积神经网络与Keras构建人脸识别模型">
  <meta property="og:description" content="文章目录 一、工具与环境
二、深度学习环境的搭建
三、基于卷积神经网络人脸识别模型的构建与测试
1.核心代码
第一步：采集自己和他人的人脸特征数据，分别对应数据标签0和1
第二步：训练识别人脸特征的模型，并将模型保存为.h5格式的文件
第三步：读取.h5文件格式的人脸识别模型，对摄像头录入的人脸图像进行识别
2.识别的基本原理
3.运行与测试
第一步：采集本人与他人的人脸特征数据（注意需要打开电脑摄像头，否则会报错！）
第二步：进行10轮次的人脸数据模型的训练
第三步：人脸识别与比对测试
四、分析与小结
参考文章
一、工具与环境 Pycharm 2022.1.4conda version : 4.5.4python version : 3.6.5.final.0platform : win-64 二、深度学习环境的搭建 详情见我写的这篇文章的第二部分，这里不再赘述
[深度学习入门案例1]基于Keras的手写数字图像识别https://blog.csdn.net/qq_52487066/article/details/131048466?spm=1001.2014.3001.5501环境搭建好之后，还需要额外下载下面的工具包，依次在Anaconda Prompt 中执行以下命令
conda install py-opencv -i https://pypi.tuna.tsinghua.edu.cn/simple pip install dlib==19.7.0 -i https://pypi.tuna.tsinghua.edu.cn/simple pip install face_recognition -i https://pypi.tuna.tsinghua.edu.cn/simple pip install Pillow -i https://pypi.tuna.tsinghua.edu.cn/simple 工具包下载导入完成，下面进行项目的构建与运行 三、基于卷积神经网络人脸识别模型的构建与测试 1.核心代码 第一步：采集自己和他人的人脸特征数据，分别对应数据标签0和1 get_my_face.py import cv2 import dlib import os import random output_dir = &#39;./my_crop_faces&#39; size = 160 if not os.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2023-06-06T09:38:26+08:00">
    <meta property="article:modified_time" content="2023-06-06T09:38:26+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">[深度学习入门案例2]基于卷积神经网络与Keras构建人脸识别模型</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/43/20/yDqjrZCF_o.png"></p> 
<h3 id="main-toc"><strong>文章目录</strong></h3> 
<p id="%E4%B8%80%E3%80%81%E5%B7%A5%E5%85%B7%E4%B8%8E%E7%8E%AF%E5%A2%83-toc" style="margin-left:0px;"><a href="#%E4%B8%80%E3%80%81%E5%B7%A5%E5%85%B7%E4%B8%8E%E7%8E%AF%E5%A2%83" rel="nofollow">一、工具与环境</a></p> 
<p id="%E4%BA%8C%E3%80%81%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E7%9A%84%E6%90%AD%E5%BB%BA-toc" style="margin-left:0px;"><a href="#%E4%BA%8C%E3%80%81%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E7%9A%84%E6%90%AD%E5%BB%BA" rel="nofollow">二、深度学习环境的搭建</a></p> 
<p id="%E4%B8%89%E3%80%81%E5%9F%BA%E4%BA%8E%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%9E%84%E5%BB%BA%E4%B8%8E%E6%B5%8B%E8%AF%95-toc" style="margin-left:0px;"><a href="#%E4%B8%89%E3%80%81%E5%9F%BA%E4%BA%8E%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%9E%84%E5%BB%BA%E4%B8%8E%E6%B5%8B%E8%AF%95" rel="nofollow">三、基于卷积神经网络人脸识别模型的构建与测试</a></p> 
<p id="1.%E6%A0%B8%E5%BF%83%E4%BB%A3%E7%A0%81-toc" style="margin-left:40px;"><a href="#1.%E6%A0%B8%E5%BF%83%E4%BB%A3%E7%A0%81" rel="nofollow">1.核心代码</a></p> 
<p id="%E7%AC%AC%E4%B8%80%E6%AD%A5%EF%BC%9A%E9%87%87%E9%9B%86%E8%87%AA%E5%B7%B1%E5%92%8C%E4%BB%96%E4%BA%BA%E7%9A%84%E4%BA%BA%E8%84%B8%E7%89%B9%E5%BE%81%E6%95%B0%E6%8D%AE%EF%BC%8C%E5%88%86%E5%88%AB%E5%AF%B9%E5%BA%94%E6%95%B0%E6%8D%AE%E6%A0%87%E7%AD%BE0%E5%92%8C1-toc" style="margin-left:80px;"><a href="#%E7%AC%AC%E4%B8%80%E6%AD%A5%EF%BC%9A%E9%87%87%E9%9B%86%E8%87%AA%E5%B7%B1%E5%92%8C%E4%BB%96%E4%BA%BA%E7%9A%84%E4%BA%BA%E8%84%B8%E7%89%B9%E5%BE%81%E6%95%B0%E6%8D%AE%EF%BC%8C%E5%88%86%E5%88%AB%E5%AF%B9%E5%BA%94%E6%95%B0%E6%8D%AE%E6%A0%87%E7%AD%BE0%E5%92%8C1" rel="nofollow">第一步：采集自己和他人的人脸特征数据，分别对应数据标签0和1</a></p> 
<p id="%C2%A0%E7%AC%AC%E4%BA%8C%E6%AD%A5%EF%BC%9A%E8%AE%AD%E7%BB%83%E8%AF%86%E5%88%AB%E4%BA%BA%E8%84%B8%E7%89%B9%E5%BE%81%E7%9A%84%E6%A8%A1%E5%9E%8B%EF%BC%8C%E5%B9%B6%E5%B0%86%E6%A8%A1%E5%9E%8B%E4%BF%9D%E5%AD%98%E4%B8%BA.h5%E6%A0%BC%E5%BC%8F%E7%9A%84%E6%96%87%E4%BB%B6-toc" style="margin-left:80px;"><a href="#%C2%A0%E7%AC%AC%E4%BA%8C%E6%AD%A5%EF%BC%9A%E8%AE%AD%E7%BB%83%E8%AF%86%E5%88%AB%E4%BA%BA%E8%84%B8%E7%89%B9%E5%BE%81%E7%9A%84%E6%A8%A1%E5%9E%8B%EF%BC%8C%E5%B9%B6%E5%B0%86%E6%A8%A1%E5%9E%8B%E4%BF%9D%E5%AD%98%E4%B8%BA.h5%E6%A0%BC%E5%BC%8F%E7%9A%84%E6%96%87%E4%BB%B6" rel="nofollow"> 第二步：训练识别人脸特征的模型，并将模型保存为.h5格式的文件</a></p> 
<p id="%C2%A0%E7%AC%AC%E4%B8%89%E6%AD%A5%EF%BC%9A%E8%AF%BB%E5%8F%96.h5%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F%E7%9A%84%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B%EF%BC%8C%E5%AF%B9%E6%91%84%E5%83%8F%E5%A4%B4%E5%BD%95%E5%85%A5%E7%9A%84%E4%BA%BA%E8%84%B8%E5%9B%BE%E5%83%8F%E8%BF%9B%E8%A1%8C%E8%AF%86%E5%88%AB-toc" style="margin-left:80px;"><a href="#%C2%A0%E7%AC%AC%E4%B8%89%E6%AD%A5%EF%BC%9A%E8%AF%BB%E5%8F%96.h5%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F%E7%9A%84%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B%EF%BC%8C%E5%AF%B9%E6%91%84%E5%83%8F%E5%A4%B4%E5%BD%95%E5%85%A5%E7%9A%84%E4%BA%BA%E8%84%B8%E5%9B%BE%E5%83%8F%E8%BF%9B%E8%A1%8C%E8%AF%86%E5%88%AB" rel="nofollow"> 第三步：读取.h5文件格式的人脸识别模型，对摄像头录入的人脸图像进行识别</a></p> 
<p id="2.%E8%AF%86%E5%88%AB%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86-toc" style="margin-left:40px;"><a href="#2.%E8%AF%86%E5%88%AB%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86" rel="nofollow">2.识别的基本原理</a></p> 
<p id="3.%E8%BF%90%E8%A1%8C%E4%B8%8E%E6%B5%8B%E8%AF%95-toc" style="margin-left:40px;"><a href="#3.%E8%BF%90%E8%A1%8C%E4%B8%8E%E6%B5%8B%E8%AF%95" rel="nofollow">3.运行与测试</a></p> 
<p id="%E7%AC%AC%E4%B8%80%E6%AD%A5%EF%BC%9A%E9%87%87%E9%9B%86%E6%9C%AC%E4%BA%BA%E4%B8%8E%E4%BB%96%E4%BA%BA%E7%9A%84%E4%BA%BA%E8%84%B8%E7%89%B9%E5%BE%81%E6%95%B0%E6%8D%AE%EF%BC%88%E6%B3%A8%E6%84%8F%E9%9C%80%E8%A6%81%E6%89%93%E5%BC%80%E7%94%B5%E8%84%91%E6%91%84%E5%83%8F%E5%A4%B4%EF%BC%8C%E5%90%A6%E5%88%99%E4%BC%9A%E6%8A%A5%E9%94%99%EF%BC%81%EF%BC%89-toc" style="margin-left:80px;"><a href="#%E7%AC%AC%E4%B8%80%E6%AD%A5%EF%BC%9A%E9%87%87%E9%9B%86%E6%9C%AC%E4%BA%BA%E4%B8%8E%E4%BB%96%E4%BA%BA%E7%9A%84%E4%BA%BA%E8%84%B8%E7%89%B9%E5%BE%81%E6%95%B0%E6%8D%AE%EF%BC%88%E6%B3%A8%E6%84%8F%E9%9C%80%E8%A6%81%E6%89%93%E5%BC%80%E7%94%B5%E8%84%91%E6%91%84%E5%83%8F%E5%A4%B4%EF%BC%8C%E5%90%A6%E5%88%99%E4%BC%9A%E6%8A%A5%E9%94%99%EF%BC%81%EF%BC%89" rel="nofollow">第一步：采集本人与他人的人脸特征数据（注意需要打开电脑摄像头，否则会报错！）</a></p> 
<p id="%E7%AC%AC%E4%BA%8C%E6%AD%A5%EF%BC%9A%E8%BF%9B%E8%A1%8C10%E8%BD%AE%E6%AC%A1%E7%9A%84%E4%BA%BA%E8%84%B8%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AE%AD%E7%BB%83-toc" style="margin-left:80px;"><a href="#%E7%AC%AC%E4%BA%8C%E6%AD%A5%EF%BC%9A%E8%BF%9B%E8%A1%8C10%E8%BD%AE%E6%AC%A1%E7%9A%84%E4%BA%BA%E8%84%B8%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AE%AD%E7%BB%83" rel="nofollow">第二步：进行10轮次的人脸数据模型的训练</a></p> 
<p id="%E7%AC%AC%E4%B8%89%E6%AD%A5%EF%BC%9A%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E4%B8%8E%E6%AF%94%E5%AF%B9%E6%B5%8B%E8%AF%95-toc" style="margin-left:80px;"><a href="#%E7%AC%AC%E4%B8%89%E6%AD%A5%EF%BC%9A%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E4%B8%8E%E6%AF%94%E5%AF%B9%E6%B5%8B%E8%AF%95" rel="nofollow">第三步：人脸识别与比对测试</a></p> 
<p id="%E5%9B%9B%E3%80%81%E5%88%86%E6%9E%90%E4%B8%8E%E5%B0%8F%E7%BB%93-toc" style="margin-left:0px;"><a href="#%E5%9B%9B%E3%80%81%E5%88%86%E6%9E%90%E4%B8%8E%E5%B0%8F%E7%BB%93" rel="nofollow">四、分析与小结</a></p> 
<p id="%E5%8F%82%E8%80%83%E6%96%87%E7%AB%A0-toc" style="margin-left:0px;"><a href="#%E5%8F%82%E8%80%83%E6%96%87%E7%AB%A0" rel="nofollow">参考文章</a></p> 
<hr id="hr-toc"> 
<h2 id="%E4%B8%80%E3%80%81%E5%B7%A5%E5%85%B7%E4%B8%8E%E7%8E%AF%E5%A2%83">一、工具与环境</h2> 
<blockquote> 
 <ul><li>Pycharm 2022.1.4</li><li>conda version : 4.5.4</li><li>python version : 3.6.5.final.0</li><li>platform : win-64</li></ul> 
</blockquote> 
<hr> 
<h2 id="%E4%BA%8C%E3%80%81%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E7%9A%84%E6%90%AD%E5%BB%BA">二、深度学习环境的搭建</h2> 
<p><em>详情见我写的这篇文章的第二部分，这里不再赘述</em></p> 
<p><a class="link-info has-card" href="https://blog.csdn.net/qq_52487066/article/details/131048466?spm=1001.2014.3001.5501" title="[深度学习入门案例1]基于Keras的手写数字图像识别"><span class="link-card-box"><span class="link-title">[深度学习入门案例1]基于Keras的手写数字图像识别</span><span class="link-link"><img class="link-link-icon" src="https://images2.imgbox.com/f2/ad/Kwk5nisR_o.png" alt="icon-default.png?t=N4P3">https://blog.csdn.net/qq_52487066/article/details/131048466?spm=1001.2014.3001.5501</span></span></a>环境搭建好<em>之后，还需要额外下载下面的工具包，依次在Anaconda Prompt 中执行以下命令</em></p> 
<pre><code class="language-python">conda install py-opencv -i https://pypi.tuna.tsinghua.edu.cn/simple
pip install dlib==19.7.0 -i https://pypi.tuna.tsinghua.edu.cn/simple
pip install face_recognition -i https://pypi.tuna.tsinghua.edu.cn/simple
pip install Pillow -i https://pypi.tuna.tsinghua.edu.cn/simple</code></pre> 
<p><em>工具包下载导入完成，下面进行项目的构建与运行 </em></p> 
<hr> 
<h2 id="%E4%B8%89%E3%80%81%E5%9F%BA%E4%BA%8E%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%9E%84%E5%BB%BA%E4%B8%8E%E6%B5%8B%E8%AF%95">三、基于卷积神经网络人脸识别模型的构建与测试</h2> 
<h3 id="1.%E6%A0%B8%E5%BF%83%E4%BB%A3%E7%A0%81">1.核心代码</h3> 
<h4 id="%E7%AC%AC%E4%B8%80%E6%AD%A5%EF%BC%9A%E9%87%87%E9%9B%86%E8%87%AA%E5%B7%B1%E5%92%8C%E4%BB%96%E4%BA%BA%E7%9A%84%E4%BA%BA%E8%84%B8%E7%89%B9%E5%BE%81%E6%95%B0%E6%8D%AE%EF%BC%8C%E5%88%86%E5%88%AB%E5%AF%B9%E5%BA%94%E6%95%B0%E6%8D%AE%E6%A0%87%E7%AD%BE0%E5%92%8C1">第一步：采集自己和他人的人脸特征数据，分别对应<span style="color:#fe2c24;">数据标签0和1</span></h4> 
<p><span style="color:#fe2c24;"><strong>get_my_face.py </strong></span></p> 
<pre><code class="language-python">import cv2
import dlib
import os
import random

output_dir = './my_crop_faces'
size = 160
if not os.path.exists(output_dir):
    os.makedirs(output_dir)

# 改变图片的亮度与对比度
def relight(img, light=1, bias=0):
    w = img.shape[1]
    h = img.shape[0]
    #image = []
    for i in range(0,w):
        for j in range(0,h):
            for c in range(3):
                tmp = int(img[j,i,c]*light + bias)
                if tmp &gt; 255:
                    tmp = 255
                elif tmp &lt; 0:
                    tmp = 0
                img[j,i,c] = tmp
    return img

#使用dlib自带的frontal_face_detector作为我们的特征提取器
detector = dlib.get_frontal_face_detector()
# 打开摄像头 参数为输入流，可以为摄像头或视频文件
camera = cv2.VideoCapture(0)

index = 0
while True:
    if (index &lt;= 1000):
        print('Being processed picture %s' % index)
        # 从摄像头读取照片
        success, img = camera.read()
        # 转为灰度图片
        gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        # 使用detector进行人脸检测
        dets = detector(gray_img, 1)

        for i, d in enumerate(dets):
            x1 = d.top() if d.top() &gt; 0 else 0
            y1 = d.bottom() if d.bottom() &gt; 0 else 0
            x2 = d.left() if d.left() &gt; 0 else 0
            y2 = d.right() if d.right() &gt; 0 else 0

            face = img[x1:y1,x2:y2]
            # 调整图片的对比度与亮度， 对比度与亮度值都取随机数，这样能增加样本的多样性
            face = relight(face, random.uniform(0.5, 1.5), random.randint(-50, 50))
            face = cv2.resize(face, (size,size))
            cv2.imshow('image', face)
            cv2.imwrite(output_dir+'/'+str(index)+'.jpg', face)
            index += 1
        key = cv2.waitKey(30) &amp; 0xff
        if key == 27:
            break
    else:
        print('Finished!')
        break
</code></pre> 
<h4 id="%C2%A0%E7%AC%AC%E4%BA%8C%E6%AD%A5%EF%BC%9A%E8%AE%AD%E7%BB%83%E8%AF%86%E5%88%AB%E4%BA%BA%E8%84%B8%E7%89%B9%E5%BE%81%E7%9A%84%E6%A8%A1%E5%9E%8B%EF%BC%8C%E5%B9%B6%E5%B0%86%E6%A8%A1%E5%9E%8B%E4%BF%9D%E5%AD%98%E4%B8%BA.h5%E6%A0%BC%E5%BC%8F%E7%9A%84%E6%96%87%E4%BB%B6"> 第二步：训练识别人脸特征的模型，并将模型保存为<span style="color:#fe2c24;">.h5格式</span>的文件</h4> 
<p><span style="color:#fe2c24;"><strong>model_train.py</strong></span></p> 
<pre><code class="language-python">#-*- coding: utf-8 -*-
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.layers import Convolution2D, MaxPooling2D
from keras.optimizers import SGD
from keras.utils import np_utils
import os
import cv2
import numpy as np
from sklearn.model_selection import train_test_split
import random

def get_files(input_dir):
    file_list = []
    for (path, dirnames, filenames) in os.walk(input_dir):
        # print(path) #输出对应顶层文件夹
        # print(dirnames)#在当前文件夹下的文件夹
        # print(filenames)#在当前文件夹下的文件夹
        for filename in filenames:
            if filename.endswith('.jpg') or filename.endswith('.bmp'):
                # print(filename)
                full_path = os.path.join(path, filename)
                # print(full_path)
                file_list.append(full_path)
    return file_list

#设置hujianhua文件夹的对应标签为0
def getPaddingSize(img):
    h, w, _ = img.shape
    top, bottom, left, right = (0,0,0,0)
    longest = max(h, w)

    if w &lt; longest:
        tmp = longest - w
        # //表示整除符号
        left = tmp // 2
        right = tmp - left
    elif h &lt; longest:
        tmp = longest - h
        top = tmp // 2
        bottom = tmp - top
    else:
        pass
    return top, bottom, left, right

def read_img_label(file_list, label):
    size = 64
    imgs = []
    labs = []
    #01
    num = 0
    for filename in file_list:
        # print(filename)
        img = cv2.imread(filename)
        # print(img.shape)
        top, bottom, left, right = getPaddingSize(img)
        # 将图片放大， 扩充图片边缘部分
        img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=[0, 0, 0])
        img = cv2.resize(img, (size, size))
        imgs.append(img)
        labs.append(label)
        num = num + 1

    # print(len(imgs))
    # print(len(labs))
    return imgs, labs


def read_dataset():
    input_dir = "./data_collection/my_crop_faces"


    all_imgs_list = []
    all_label_list = []
    my_file_list = get_files(input_dir)
    # 0-&gt;[0,1] 1-&gt;[1,0]
    label = 0 #[0, 1]
    my_imgs_list, my_labs_list = read_img_label(my_file_list, label)

    input_dir = "./data_collection/others_img_crop"

    others_file_list = get_files(input_dir)
    label = 1 #[1, 0] #-&gt;0
    others_imgs_list, others_labs_list = read_img_label(others_file_list, label)

    for img in my_imgs_list:
        all_imgs_list.append(img)
    for img in others_imgs_list:
        all_imgs_list.append(img)

    for label in my_labs_list:
        all_label_list.append(label)
    for label in others_labs_list:
        all_label_list.append(label)

    imgs_array = np.array(all_imgs_list)
    # print(imgs_array.shape)

    labs_array = np.array(all_label_list)
    # print(labs_array.shape)

    return imgs_array,labs_array


#加载数据集并按照交叉验证的原则划分数据集并进行相关预处理工作
def load_data(img_rows = 64, img_cols = 64,
         img_channels = 3, nb_classes = 2):
    #加载数据集到内存
    images, labels = read_dataset()
    print(images.shape)
    print(labels.shape)

    train_images, valid_images, train_labels, valid_labels = train_test_split(images, labels, test_size = 0.3, random_state = random.randint(0, 100))
    _, test_images, _, test_labels = train_test_split(images, labels, test_size = 0.5, random_state = random.randint(0, 100))

    train_images = train_images.reshape(train_images.shape[0], img_rows, img_cols, img_channels)
    valid_images = valid_images.reshape(valid_images.shape[0], img_rows, img_cols, img_channels)
    test_images = test_images.reshape(test_images.shape[0], img_rows, img_cols, img_channels)
    input_shape = (img_rows, img_cols, img_channels)

    #输出训练集、验证集、测试集的数量
    print(train_images.shape[0], 'train samples')
    print(valid_images.shape[0], 'valid samples')
    print(test_images.shape[0], 'test samples')

    #我们的模型使用categorical_crossentropy作为损失函数，因此需要根据类别数量nb_classes将
    #类别标签进行one-hot编码使其向量化，在这里我们的类别只有两种，经过转化后标签数据变为二维
    train_labels = np_utils.to_categorical(train_labels, nb_classes)
    valid_labels = np_utils.to_categorical(valid_labels, nb_classes)
    test_labels = np_utils.to_categorical(test_labels, nb_classes)
    print(train_labels.shape)
    print(valid_labels.shape)
    print(test_labels.shape)
    #像素数据浮点化以便归一化
    train_images = train_images.astype('float32')
    valid_images = valid_images.astype('float32')
    test_images = test_images.astype('float32')

    #将其归一化,图像的各像素值归一化到0~1区间
    train_images /= 255
    valid_images /= 255
    test_images /= 255

    return train_images, train_labels, valid_images, valid_labels, test_images, test_labels

#建立模型
def build_model(nb_classes = 2):
    #构建一个空的网络模型，它是一个线性堆叠模型，各神经网络层会被顺序添加，专业名称为序贯模型或线性堆叠模型
    model = Sequential()

    #以下代码将顺序添加CNN网络需要的各层，一个add就是一个网络层
    model.add(Convolution2D(32, 3, 3, border_mode='same',
                                 input_shape =  (64, 64, 3)))    #1 2维卷积层
    model.add(Activation('relu'))                                  #2 激活函数层

    model.add(Convolution2D(32, 3, 3))                             #3 2维卷积层
    model.add(Activation('relu'))                                  #4 激活函数层

    model.add(MaxPooling2D(pool_size=(2, 2)))                      #5 池化层
    model.add(Dropout(0.25))                                       #6 Dropout层

    model.add(Convolution2D(64, 3, 3, border_mode='same'))         #7  2维卷积层
    model.add(Activation('relu'))                                  #8  激活函数层

    model.add(Convolution2D(64, 3, 3))                             #9  2维卷积层
    model.add(Activation('relu'))                                  #10 激活函数层

    model.add(MaxPooling2D(pool_size=(2, 2)))                      #11 池化层
    model.add(Dropout(0.25))                                       #12 Dropout层

    model.add(Flatten())                                           #13 Flatten层
    model.add(Dense(512))                                          #14 Dense层,又被称作全连接层
    model.add(Activation('relu'))                                  #15 激活函数层
    model.add(Dropout(0.5))                                        #16 Dropout层
    model.add(Dense(nb_classes))                                   #17 Dense层
    model.add(Activation('softmax'))                               #18 分类层，输出最终结果
    #输出模型概况
    print(model.summary())
    return model

model = build_model()

sgd = SGD(lr=0.01, decay=1e-6,
          momentum=0.9, nesterov=True)  # 采用SGD+momentum的优化器进行训练，首先生成一个优化器对象
model.compile(loss='categorical_crossentropy',
                   optimizer=sgd,
                   metrics=['accuracy'])  # 完成实际的模型配置工作

train_images, train_labels, valid_images, valid_labels, test_images, test_labels = load_data()

batch_size = 20
nb_epoch = 10
train_history = model.fit(train_images,
               train_labels,
               batch_size=batch_size,
               nb_epoch=nb_epoch,
               validation_data=(valid_images, valid_labels),
               shuffle=True)

scores = model.evaluate(test_images, test_labels)
print('accuracy=', scores[1])
prediction = model.predict_classes(test_images)
# print(prediction)
model.save('./me.face.model.h5')</code></pre> 
<h4 id="%C2%A0%E7%AC%AC%E4%B8%89%E6%AD%A5%EF%BC%9A%E8%AF%BB%E5%8F%96.h5%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F%E7%9A%84%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B%EF%BC%8C%E5%AF%B9%E6%91%84%E5%83%8F%E5%A4%B4%E5%BD%95%E5%85%A5%E7%9A%84%E4%BA%BA%E8%84%B8%E5%9B%BE%E5%83%8F%E8%BF%9B%E8%A1%8C%E8%AF%86%E5%88%AB"> 第三步：读取.h5文件格式的人脸识别模型，对摄像头录入的人脸图像进行识别</h4> 
<p><span style="color:#fe2c24;"><strong>video_predict.py</strong></span></p> 
<pre><code class="language-python">import cv2
import dlib
from keras.models import load_model
import sys

size = 64

# 使用dlib自带的frontal_face_detector作为我们的特征提取器
detector = dlib.get_frontal_face_detector()

cam = cv2.VideoCapture(0)

model = load_model('./me.face.model.h5')

while True:
    _, img = cam.read()
    gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    dets = detector(gray_image, 1)
    for i, d in enumerate(dets):
        x1 = d.top() if d.top() &gt; 0 else 0
        y1 = d.bottom() if d.bottom() &gt; 0 else 0
        x2 = d.left() if d.left() &gt; 0 else 0
        y2 = d.right() if d.right() &gt; 0 else 0
        face = img[x1:y1, x2:y2]
        # 调整图片的尺寸
        face = cv2.resize(face, (size, size))
        shape_img = (face.reshape(1, size, size, 3)).astype('float32') / 255

        prediction = model.predict_classes(shape_img)
        print(prediction[0])
        name = "unknown"
        if prediction[0] == 0:
            print("识别出本人")
            name = "Aricl."
        else:
            print("不是本人")
            name = "unknown"
        cv2.rectangle(img, (x2, x1), (y2, y1), (255, 0, 0), 3)
        font = cv2.FONT_HERSHEY_SIMPLEX
        cv2.putText(img, name, (x2, x1), font, 0.8, (255, 255, 255), 1)

    cv2.imshow('image', img)
    key = cv2.waitKey(30) &amp; 0xff
    if key == 27:
        sys.exit(0)</code></pre> 
<h3 id="2.%E8%AF%86%E5%88%AB%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86">2.识别的基本原理</h3> 
<blockquote> 
 <p>        核心之一是使用<span style="color:#fe2c24;">OpenCV（Open source Computer Vision Library）</span>，即开放源代码计算机视觉库进行图像的处理。</p> 
 <p>        它是一套关于计算机视觉的开放源代码的<span style="color:#fe2c24;">API函数库</span>。这也就意味着，(1)不管是科学研究，还是商业应用，都可以利用它来作开发;(2)所有API函数的源代码都是<span style="color:#fe2c24;">公开的</span>，你可以看到其内部实现的程序步骤；(3)你可以修改OpenCV的源代码，编译生成你需要的特定API函数。但是，作为一个库，它所提供的，仅仅是一些常用、经典、大众化算法的API。</p> 
 <p>        一个典型的计算机视觉算法，一般包含以下步骤：</p> 
 <ol><li>数据获取</li><li>预处理</li><li>特征提取</li><li>特征选择</li><li>分类器设计与训练</li><li>分类判别</li></ol> 
 <p>而OpenCV对这六个部分，都分别提供了API以供开发者调用。</p> 
 <p>        核心之二是使用<span style="color:#fe2c24;">Keras搭建卷积神经网络</span>。</p> 
 <p>        Keras对人工智能来说，是一款比较好的入门框架。它是一个高级的<span style="color:#fe2c24;">Python神经网络框架</span>，已经被添加到TensorFlow中，成为其默认的框架，为TensorFlow提供更高级的API。</p> 
 <p>        如果将TensorFlow比喻为编程界的Java或者C++，那么Keras就是编程界的Python，它作为TensorFlow的<span style="color:#fe2c24;">高层封装</span>，可以与TensorFlow联合使用，用它可以快速搭建模型。</p> 
 <p>        并且Keras是TensorFlow官方支持的。当机器上有可用的GPU时，代码会自动调用GPU进行并行计算，功能十分强大！</p> 
</blockquote> 
<h3 id="3.%E8%BF%90%E8%A1%8C%E4%B8%8E%E6%B5%8B%E8%AF%95">3.运行与测试</h3> 
<h4 id="%E7%AC%AC%E4%B8%80%E6%AD%A5%EF%BC%9A%E9%87%87%E9%9B%86%E6%9C%AC%E4%BA%BA%E4%B8%8E%E4%BB%96%E4%BA%BA%E7%9A%84%E4%BA%BA%E8%84%B8%E7%89%B9%E5%BE%81%E6%95%B0%E6%8D%AE%EF%BC%88%E6%B3%A8%E6%84%8F%E9%9C%80%E8%A6%81%E6%89%93%E5%BC%80%E7%94%B5%E8%84%91%E6%91%84%E5%83%8F%E5%A4%B4%EF%BC%8C%E5%90%A6%E5%88%99%E4%BC%9A%E6%8A%A5%E9%94%99%EF%BC%81%EF%BC%89">第一步：采集本人与他人的人脸特征数据（注意需要打开电脑摄像头，否则会报错！）</h4> 
<p><img alt="" src="https://images2.imgbox.com/d9/d3/MtHyW93v_o.png"></p> 
<p style="text-align:center;"> <img alt="" src="https://images2.imgbox.com/47/90/Kb6qSUKz_o.png"></p> 
<h4 id="%E7%AC%AC%E4%BA%8C%E6%AD%A5%EF%BC%9A%E8%BF%9B%E8%A1%8C10%E8%BD%AE%E6%AC%A1%E7%9A%84%E4%BA%BA%E8%84%B8%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AE%AD%E7%BB%83">第二步：进行10轮次的人脸数据模型的训练</h4> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/2c/ef/fMnsrT6M_o.png"></p> 
<h4 id="%E7%AC%AC%E4%B8%89%E6%AD%A5%EF%BC%9A%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E4%B8%8E%E6%AF%94%E5%AF%B9%E6%B5%8B%E8%AF%95">第三步：人脸识别与比对测试</h4> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/d4/86/TA39Pyho_o.png"></p> 
<p><em>上图是本人（博主Aricl.），下图是我室友（未知人脸），可见人脸识别的准确率还是不错的！ </em></p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/e1/49/u8JxUQVa_o.png"></p> 
<hr> 
<h2 id="%E5%9B%9B%E3%80%81%E5%88%86%E6%9E%90%E4%B8%8E%E5%B0%8F%E7%BB%93">四、分析与小结</h2> 
<p style="margin-left:.0001pt;text-align:justify;">        本次通过构建<span style="color:#fe2c24;">基于卷积神经网络与Keras的人脸识别模型</span>，实现的基本原理是：引用Python中的<span style="color:#fe2c24;">OpenCV</span>库，调用其中的<span style="color:#fe2c24;">人脸分类器</span>，然后调用电脑的摄像头循环读取<span style="color:#fe2c24;">单帧数据</span>，进行实时人脸检测，并框出人脸，标注信息。</p> 
<p style="margin-left:.0001pt;text-align:justify;">        首先我们需要进行人脸数据的采集，总共采集了<span style="color:#fe2c24;">1000张</span>本人与他人的人脸特征数据，采集完毕后，进行数据模型的训练，共训练了<span style="color:#fe2c24;">10轮次，每轮次六千多</span>，将训练好的模型保存为<span style="color:#fe2c24;">.h5格式</span>的文件。然后调用摄像头读取每一帧的人脸照片，对图片进行灰度化处理，检测出人脸并框出对应的区域，读取.h5人脸识别模型文件进行人脸识别与比对，并在上方标注出是本人或者未知等信息。</p> 
<p style="margin-left:.0001pt;text-align:justify;">        另外，采集时对被采集人和环境有一定要求，<span style="color:#fe2c24;">光线应该明亮</span>使得摄像头能看清楚人脸，并且人脸应该<span style="color:#fe2c24;">正对着摄像头</span>，这样采集得到的人脸特征数据才较为<span style="color:#fe2c24;">准确</span>，识别的效果就<span style="color:#fe2c24;">越好</span>。</p> 
<p style="margin-left:.0001pt;text-align:justify;">        本次仅仅是人脸识别的一次初步入门，我对此也产生了浓厚的学习兴趣，但博主正在备战考研，只能初步了解，后续有机会再继续学习与研究该领域相关技术，加油！！</p> 
<p style="margin-left:.0001pt;text-align:center;"><img alt="" src="https://images2.imgbox.com/fd/a2/Bcp2Usiv_o.png"></p> 
<h2 id="%E5%8F%82%E8%80%83%E6%96%87%E7%AB%A0">参考文章</h2> 
<p><a class="link-info has-card" href="https://blog.csdn.net/gf19960103/article/details/91038858?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=%E4%BD%BF%E7%94%A8Keras%E6%9E%84%E5%BB%BA%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-3-91038858.nonecase&amp;spm=1018.2226.3001.4187" title="Python+Keras+opencv实现人脸识别"><span class="link-card-box"><span class="link-title">Python+Keras+opencv实现人脸识别</span><span class="link-link"><img class="link-link-icon" src="https://images2.imgbox.com/ef/86/DAl4YWUA_o.png" alt="icon-default.png?t=N4P3">https://blog.csdn.net/gf19960103/article/details/91038858?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=%E4%BD%BF%E7%94%A8Keras%E6%9E%84%E5%BB%BA%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-3-91038858.nonecase&amp;spm=1018.2226.3001.4187</span></span></a><a class="link-info has-card" href="https://blog.csdn.net/weixin_44491431/article/details/113839543?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522168601107216800185824691%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=168601107216800185824691&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-113839543-null-null.142%5Ev88%5Econtrol_2,239%5Ev2%5Einsert_chatgpt&amp;utm_term=%E4%BD%BF%E7%94%A8Keras%E6%9E%84%E5%BB%BA%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B&amp;spm=1018.2226.3001.4187" title="人脸检测及识别python实现系列（5）——利用keras库训练人脸识别模型"><span class="link-card-box"><span class="link-title">人脸检测及识别python实现系列（5）——利用keras库训练人脸识别模型</span><span class="link-link"><img class="link-link-icon" src="https://images2.imgbox.com/06/64/MjwOqwHE_o.png" alt="icon-default.png?t=N4P3">https://blog.csdn.net/weixin_44491431/article/details/113839543?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522168601107216800185824691%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=168601107216800185824691&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-1-113839543-null-null.142^v88^control_2,239^v2^insert_chatgpt&amp;utm_term=%E4%BD%BF%E7%94%A8Keras%E6%9E%84%E5%BB%BA%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B&amp;spm=1018.2226.3001.4187</span></span></a><a class="link-info has-card" href="https://blog.csdn.net/m0_55479420/article/details/115268470?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522168601107216800185824691%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=168601107216800185824691&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-2-115268470-null-null.142%5Ev88%5Econtrol_2,239%5Ev2%5Einsert_chatgpt&amp;utm_term=%E4%BD%BF%E7%94%A8Keras%E6%9E%84%E5%BB%BA%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B&amp;spm=1018.2226.3001.4187" title="手把手教你使用Keras进行人脸检测和识别"><span class="link-card-box"><span class="link-title">手把手教你使用Keras进行人脸检测和识别</span><span class="link-link"><img class="link-link-icon" src="https://images2.imgbox.com/23/cb/IA3InjmY_o.png" alt="icon-default.png?t=N4P3">https://blog.csdn.net/m0_55479420/article/details/115268470?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522168601107216800185824691%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=168601107216800185824691&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-2-115268470-null-null.142^v88^control_2,239^v2^insert_chatgpt&amp;utm_term=%E4%BD%BF%E7%94%A8Keras%E6%9E%84%E5%BB%BA%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E6%A8%A1%E5%9E%8B&amp;spm=1018.2226.3001.4187</span></span></a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/c267c69f8f5b9d3ce2c035489802f934/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">JDK 8的下载、安装、配置【保姆级教程】</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/10ddc158d1a2e397f3ec635c964e6792/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【Java基础】I/O流 —— Java中的流都需要关闭吗？</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>