<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Llamaæ¨¡å‹ç»“æ„è§£æï¼ˆæºç é˜…è¯»ï¼‰ - ç¼–ç¨‹å¤§å’–</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/4b79fbcc9f3d4a52015108f0c91fd676/">
  <meta property="og:site_name" content="ç¼–ç¨‹å¤§å’–">
  <meta property="og:title" content="Llamaæ¨¡å‹ç»“æ„è§£æï¼ˆæºç é˜…è¯»ï¼‰">
  <meta property="og:description" content="ç›®å½• 1. LlamaModelæ•´ä½“ç»“æ„æµç¨‹å›¾2. LlamaRMSNorm3. LlamaMLP4. LlamaRotaryEmbedding å‚è€ƒèµ„æ–™ï¼š
https://zhuanlan.zhihu.com/p/636784644
https://spaces.ac.cn/archives/8265 â€”â€”ã€ŠTransformerå‡çº§ä¹‹è·¯ï¼š2ã€åšé‡‡ä¼—é•¿çš„æ—‹è½¬å¼ä½ç½®ç¼–ç ã€‹ å‰è¨€ï¼šæœ¬æ¬¡é˜…è¯»ä»£ç ä½ç½®ï¼Œåœ¨transformersåº“åº•ä¸‹çš„modeling_llama.pyï¼Œå…·ä½“ä½ç½®åœ¨ï¼štransformers/models/llama/modeling_llama.pyï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š
1. LlamaModelæ•´ä½“ç»“æ„æµç¨‹å›¾ 2. LlamaRMSNorm ä»£ç å¦‚ä¸‹ class LlamaRMSNorm(nn.Module): def __init__(self, hidden_size, eps=1e-6): &#34;&#34;&#34; LlamaRMSNorm is equivalent to T5LayerNorm &#34;&#34;&#34; super().__init__() self.weight = nn.Parameter(torch.ones(hidden_size)) self.variance_epsilon = eps def forward(self, hidden_states): input_dtype = hidden_states.dtype variance = hidden_states.to(torch.float32).pow(2).mean(-1, keepdim=True) hidden_states = hidden_states * torch.rsqrt(variance &#43; self.variance_epsilon) return (self.weight * hidden_states).to(input_dtype) RMSNormçš„å…¬å¼å¦‚ä¸‹æ‰€ç¤ºï¼š
x i 1 n âˆ‘ i = 1 n x i 2 &#43; e p s âˆ— w e i g h t i \frac{x_i}{\sqrt{\frac{1}{n}\sum\limits_{i=1}^{n}{x_i}^2 &#43; eps}} * weight_i n1â€‹i=1âˆ‘nâ€‹xiâ€‹2&#43;eps â€‹xiâ€‹â€‹âˆ—weightiâ€‹">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2023-08-29T10:10:12+08:00">
    <meta property="article:modified_time" content="2023-08-29T10:10:12+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="ç¼–ç¨‹å¤§å’–" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">ç¼–ç¨‹å¤§å’–</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Llamaæ¨¡å‹ç»“æ„è§£æï¼ˆæºç é˜…è¯»ï¼‰</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-dracula">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>ç›®å½•</h4> 
 <ul><li><a href="#1_LlamaModel_10" rel="nofollow">1. LlamaModelæ•´ä½“ç»“æ„æµç¨‹å›¾</a></li><li><a href="#2_LlamaRMSNorm_13" rel="nofollow">2. LlamaRMSNorm</a></li><li><a href="#3_LlamaMLP_41" rel="nofollow">3. LlamaMLP</a></li><li><a href="#4_LlamaRotaryEmbedding_68" rel="nofollow">4. LlamaRotaryEmbedding</a></li></ul> 
</div> 
<p></p> 
<ul><li>å‚è€ƒèµ„æ–™ï¼š<br> https://zhuanlan.zhihu.com/p/636784644<br> https://spaces.ac.cn/archives/8265 â€”â€”ã€ŠTransformerå‡çº§ä¹‹è·¯ï¼š2ã€åšé‡‡ä¼—é•¿çš„æ—‹è½¬å¼ä½ç½®ç¼–ç ã€‹</li></ul> 
<p><strong>å‰è¨€</strong>ï¼šæœ¬æ¬¡é˜…è¯»ä»£ç ä½ç½®ï¼Œåœ¨transformersåº“åº•ä¸‹çš„modeling_llama.pyï¼Œå…·ä½“ä½ç½®åœ¨ï¼štransformers/models/llama/modeling_llama.pyï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š<img src="https://images2.imgbox.com/49/84/A7xIvYbh_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<h2><a id="1_LlamaModel_10"></a>1. LlamaModelæ•´ä½“ç»“æ„æµç¨‹å›¾</h2> 
<p><img src="https://images2.imgbox.com/d1/b0/SAJOGWTn_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<h2><a id="2_LlamaRMSNorm_13"></a>2. LlamaRMSNorm</h2> 
<ul><li>ä»£ç å¦‚ä¸‹</li></ul> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">LlamaRMSNorm</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-6</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        LlamaRMSNorm is equivalent to T5LayerNorm
        """</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>weight <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>hidden_size<span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>variance_epsilon <span class="token operator">=</span> eps

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> hidden_states<span class="token punctuation">)</span><span class="token punctuation">:</span>
        input_dtype <span class="token operator">=</span> hidden_states<span class="token punctuation">.</span>dtype
        variance <span class="token operator">=</span> hidden_states<span class="token punctuation">.</span>to<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        hidden_states <span class="token operator">=</span> hidden_states <span class="token operator">*</span> torch<span class="token punctuation">.</span>rsqrt<span class="token punctuation">(</span>variance <span class="token operator">+</span> self<span class="token punctuation">.</span>variance_epsilon<span class="token punctuation">)</span>

        <span class="token keyword">return</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>weight <span class="token operator">*</span> hidden_states<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>input_dtype<span class="token punctuation">)</span>
</code></pre> 
<ul><li> <p>RMSNormçš„å…¬å¼å¦‚ä¸‹æ‰€ç¤ºï¼š<br> <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
       
        
         
          
           
           
             x 
            
           
             i 
            
           
           
            
             
             
               1 
              
             
               n 
              
             
             
             
               âˆ‘ 
              
              
              
                i 
               
              
                = 
               
              
                1 
               
              
             
               n 
              
             
             
              
              
                x 
               
              
                i 
               
              
             
               2 
              
             
            
              + 
             
            
              e 
             
            
              p 
             
            
              s 
             
            
           
          
         
           âˆ— 
          
         
           w 
          
         
           e 
          
         
           i 
          
         
           g 
          
         
           h 
          
          
          
            t 
           
          
            i 
           
          
         
        
          \frac{x_i}{\sqrt{\frac{1}{n}\sum\limits_{i=1}^{n}{x_i}^2 + eps}} * weight_i 
         
        
      </span><span class="katex-html"><span class="base"><span class="strut" style="height: 2.3411em; vertical-align: -1.6296em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.7115em;"><span class="" style="top: -2.19em;"><span class="pstrut" style="height: 3.0805em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord sqrt mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.5436em;"><span class="svg-align" style="top: -4.5714em;"><span class="pstrut" style="height: 4.5714em;"></span><span class="mord mtight" style="padding-left: 1.4286em;"><span class="mord mtight"><span class="mopen nulldelimiter sizing reset-size3 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.8443em;"><span class="" style="top: -2.656em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="" style="top: -3.2255em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line mtight" style="border-bottom-width: 0.049em;"></span></span><span class="" style="top: -3.384em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height: 0.344em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size3 size6"></span></span><span class="mspace mtight" style="margin-right: 0.1952em;"></span><span class="mop op-limits mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.4005em;"><span class="" style="top: -1.8629em; margin-left: 0em;"><span class="pstrut" style="height: 2.75em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span class="" style="top: -2.75em;"><span class="pstrut" style="height: 2.75em;"></span><span class=""><span class="mop op-symbol small-op mtight">âˆ‘</span></span></span><span class="" style="top: -3.7em; margin-left: 0em;"><span class="pstrut" style="height: 2.75em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height: 1.0301em;"><span class=""></span></span></span></span></span><span class="mspace mtight" style="margin-right: 0.1952em;"></span><span class="mord mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3281em;"><span class="" style="top: -2.357em; margin-left: 0em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height: 0.143em;"><span class=""></span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.7463em;"><span class="" style="top: -2.786em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mbin mtight">+</span><span class="mord mathnormal mtight">e</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">s</span></span></span><span class="" style="top: -3.5156em;"><span class="pstrut" style="height: 4.5714em;"></span><span class="hide-tail mtight" style="min-width: 1.02em; height: 2.6857em;"> 
                     <svg width="400em" height="2.6857em" viewbox="0 0 400000 1944" preserveaspectratio="xMinYMin slice"> 
                      <path d="M983 90
l0 -0
c4,-6.7,10,-10,18,-10 H400000v40
H1013.1s-83.4,268,-264.1,840c-180.7,572,-277,876.3,-289,913c-4.7,4.7,-12.7,7,-24,7
s-12,0,-12,0c-1.3,-3.3,-3.7,-11.7,-7,-25c-35.3,-125.3,-106.7,-373.3,-214,-744
c-10,12,-21,25,-33,39s-32,39,-32,39c-6,-5.3,-15,-14,-27,-26s25,-30,25,-30
c26.7,-32.7,52,-63,76,-91s52,-60,52,-60s208,722,208,722
c56,-175.3,126.3,-397.3,211,-666c84.7,-268.7,153.8,-488.2,207.5,-658.5
c53.7,-170.3,84.5,-266.8,92.5,-289.5z
M1001 80h400000v40h-400000z"></path> 
                     </svg></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height: 1.0559em;"><span class=""></span></span></span></span></span></span></span></span><span class="" style="top: -3.3105em;"><span class="pstrut" style="height: 3.0805em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.4906em;"><span class="pstrut" style="height: 3.0805em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3281em;"><span class="" style="top: -2.357em; margin-left: 0em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height: 0.143em;"><span class=""></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height: 1.6296em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">âˆ—</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.8889em; vertical-align: -0.1944em;"></span><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="mord mathnormal">e</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="mord mathnormal">h</span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span></p> 
  <ul><li>å…¶ä¸­ï¼Œå…¬å¼ä¸ä»£ç çš„å¯¹åº”å…³ç³»å¦‚ä¸‹ï¼š<br> <img src="https://images2.imgbox.com/4f/97/xw8RuHSl_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></li></ul> </li></ul> 
<h2><a id="3_LlamaMLP_41"></a>3. LlamaMLP</h2> 
<ul><li>ä»£ç å¦‚ä¸‹ï¼š</li></ul> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">LlamaMLP</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>
        self<span class="token punctuation">,</span>
        hidden_size<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span>
        intermediate_size<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span>
        hidden_act<span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>gate_proj <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span> intermediate_size<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>down_proj <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>intermediate_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>up_proj <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span> intermediate_size<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>act_fn <span class="token operator">=</span> ACT2FN<span class="token punctuation">[</span>hidden_act<span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>down_proj<span class="token punctuation">(</span>self<span class="token punctuation">.</span>act_fn<span class="token punctuation">(</span>self<span class="token punctuation">.</span>gate_proj<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>up_proj<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<ul><li> <p>æµç¨‹å›¾ï¼š<br> <img src="https://images2.imgbox.com/bc/12/JgKaLSkS_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> </li><li> <p>å…¶ä¸­è¾“å…¥ä¸ºxï¼Œè¾“å‡ºä¸ºy</p> </li><li> <p>ä»£ç ä¸­intermediate_sizeä¸€èˆ¬æ¯”hidden_sizeå¤§ï¼Œæˆ‘ä»¬é€šè¿‡åœ¨jupyter notebookä¸­æ‰“å°Llama-13Bçš„æ¨¡å‹ï¼Œå¯ä»¥çœ‹åˆ°å¦‚ä¸‹æ‰€ç¤ºï¼š<br> <img src="https://images2.imgbox.com/65/46/dvpG3KHh_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> </li><li> <p>æ€»ç»“ï¼šMLPæ¨¡å—å°±æ˜¯å‡ ä¸ªnn.Linearçš„ç»„åˆ</p> </li></ul> 
<h2><a id="4_LlamaRotaryEmbedding_68"></a>4. LlamaRotaryEmbedding</h2> 
<ul><li>ä»£ç å¦‚ä¸‹</li></ul> 
<pre><code class="prism language-python">
<span class="token keyword">class</span> <span class="token class-name">LlamaRotaryEmbedding</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dim<span class="token punctuation">,</span> max_position_embeddings<span class="token operator">=</span><span class="token number">2048</span><span class="token punctuation">,</span> base<span class="token operator">=</span><span class="token number">10000</span><span class="token punctuation">,</span> device<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        inv_freq <span class="token operator">=</span> <span class="token number">1.0</span> <span class="token operator">/</span> <span class="token punctuation">(</span>base <span class="token operator">**</span> <span class="token punctuation">(</span>torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> dim<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span> <span class="token operator">/</span> dim<span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>register_buffer<span class="token punctuation">(</span><span class="token string">"inv_freq"</span><span class="token punctuation">,</span> inv_freq<span class="token punctuation">)</span>

        <span class="token comment"># Build here to make `torch.jit.trace` work.</span>
        self<span class="token punctuation">.</span>max_seq_len_cached <span class="token operator">=</span> max_position_embeddings
        t <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>self<span class="token punctuation">.</span>max_seq_len_cached<span class="token punctuation">,</span> device<span class="token operator">=</span>self<span class="token punctuation">.</span>inv_freq<span class="token punctuation">.</span>device<span class="token punctuation">,</span> dtype<span class="token operator">=</span>self<span class="token punctuation">.</span>inv_freq<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span>
        freqs <span class="token operator">=</span> torch<span class="token punctuation">.</span>einsum<span class="token punctuation">(</span><span class="token string">"i,j-&gt;ij"</span><span class="token punctuation">,</span> t<span class="token punctuation">,</span> self<span class="token punctuation">.</span>inv_freq<span class="token punctuation">)</span>
        <span class="token comment"># Different from paper, but it uses a different permutation in order to obtain the same calculation</span>
        emb <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>freqs<span class="token punctuation">,</span> freqs<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>register_buffer<span class="token punctuation">(</span><span class="token string">"cos_cached"</span><span class="token punctuation">,</span> emb<span class="token punctuation">.</span>cos<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> persistent<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>register_buffer<span class="token punctuation">(</span><span class="token string">"sin_cached"</span><span class="token punctuation">,</span> emb<span class="token punctuation">.</span>sin<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> persistent<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> seq_len<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># x: [bs, num_attention_heads, seq_len, head_size]</span>
        <span class="token comment"># This `if` block is unlikely to be run after we build sin/cos in `__init__`. Keep the logic here just in case.</span>
        <span class="token keyword">if</span> seq_len <span class="token operator">&gt;</span> self<span class="token punctuation">.</span>max_seq_len_cached<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>max_seq_len_cached <span class="token operator">=</span> seq_len
            t <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>self<span class="token punctuation">.</span>max_seq_len_cached<span class="token punctuation">,</span> device<span class="token operator">=</span>x<span class="token punctuation">.</span>device<span class="token punctuation">,</span> dtype<span class="token operator">=</span>self<span class="token punctuation">.</span>inv_freq<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span>
            freqs <span class="token operator">=</span> torch<span class="token punctuation">.</span>einsum<span class="token punctuation">(</span><span class="token string">"i,j-&gt;ij"</span><span class="token punctuation">,</span> t<span class="token punctuation">,</span> self<span class="token punctuation">.</span>inv_freq<span class="token punctuation">)</span>
            <span class="token comment"># Different from paper, but it uses a different permutation in order to obtain the same calculation</span>
            emb <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>freqs<span class="token punctuation">,</span> freqs<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>x<span class="token punctuation">.</span>device<span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>register_buffer<span class="token punctuation">(</span><span class="token string">"cos_cached"</span><span class="token punctuation">,</span> emb<span class="token punctuation">.</span>cos<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> persistent<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>register_buffer<span class="token punctuation">(</span><span class="token string">"sin_cached"</span><span class="token punctuation">,</span> emb<span class="token punctuation">.</span>sin<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> persistent<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token punctuation">(</span>
            self<span class="token punctuation">.</span>cos_cached<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span>seq_len<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>dtype<span class="token operator">=</span>x<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span><span class="token punctuation">,</span>
            self<span class="token punctuation">.</span>sin_cached<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span>seq_len<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>dtype<span class="token operator">=</span>x<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
</code></pre> 
<ul><li>å…·ä½“çš„ä½¿ç”¨ï¼Œè¿˜è°ƒç”¨äº†å¦å¤–ä¸¤ä¸ªå‡½æ•°ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š</li></ul> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">rotate_half</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Rotates half the hidden dims of the input."""</span>
    x1 <span class="token operator">=</span> x<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token punctuation">:</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">]</span>
    x2 <span class="token operator">=</span> x<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">//</span> <span class="token number">2</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
    <span class="token keyword">return</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span>x2<span class="token punctuation">,</span> x1<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">apply_rotary_pos_emb</span><span class="token punctuation">(</span>q<span class="token punctuation">,</span> k<span class="token punctuation">,</span> cos<span class="token punctuation">,</span> sin<span class="token punctuation">,</span> position_ids<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># The first two dimensions of cos and sin are always 1, so we can `squeeze` them.</span>
    cos <span class="token operator">=</span> cos<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>  <span class="token comment"># [seq_len, dim]</span>
    sin <span class="token operator">=</span> sin<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>  <span class="token comment"># [seq_len, dim]</span>
    cos <span class="token operator">=</span> cos<span class="token punctuation">[</span>position_ids<span class="token punctuation">]</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># [bs, 1, seq_len, dim]</span>
    sin <span class="token operator">=</span> sin<span class="token punctuation">[</span>position_ids<span class="token punctuation">]</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># [bs, 1, seq_len, dim]</span>
    q_embed <span class="token operator">=</span> <span class="token punctuation">(</span>q <span class="token operator">*</span> cos<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">(</span>rotate_half<span class="token punctuation">(</span>q<span class="token punctuation">)</span> <span class="token operator">*</span> sin<span class="token punctuation">)</span>
    k_embed <span class="token operator">=</span> <span class="token punctuation">(</span>k <span class="token operator">*</span> cos<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">(</span>rotate_half<span class="token punctuation">(</span>k<span class="token punctuation">)</span> <span class="token operator">*</span> sin<span class="token punctuation">)</span>
    <span class="token keyword">return</span> q_embed<span class="token punctuation">,</span> k_embed
    
</code></pre> 
<ul><li> <p>æ³¨æ„è¿™é‡Œçš„å®ç°è·ŸåŸå§‹æ¨å¯¼æœ‰ç‚¹åŒºåˆ«ï¼Œè¿™é‡Œå®ç°çš„æ–¹å¼å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š<br> <img src="https://images2.imgbox.com/66/0b/X81cSCeC_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> </li><li> <p>åŸå§‹æ¨å¯¼å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š<br> <img src="https://images2.imgbox.com/f8/14/RlVQbOKN_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"><br> å…·ä½“å¯ä»¥æŸ¥çœ‹ä½œè€…çš„åšå®¢ï¼šğŸ‘‰<a href="https://spaces.ac.cn/archives/8265" rel="nofollow">æˆ³æˆ‘</a>ğŸ‘ˆ</p> </li><li> <p>æ€»ç»“ï¼šRoPEå°±æ˜¯åœ¨attentionè®¡ç®—æ—¶ï¼ŒKè·ŸQåšå†…ç§¯ä¹‹å‰ï¼Œå…ˆç»™å„è‡ªæ³¨å…¥ä½ç½®ä¿¡æ¯ã€‚</p> </li></ul> 
<p><strong>ç»“æŸã€‚</strong></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/310021add1c7ca187d72fa14a403a197/" rel="prev">
			<span class="pager__subtitle">Â«&thinsp;Previous</span>
			<p class="pager__title">99ä¸ªåŸºäºJAVAçš„ç®¡ç†ç³»ç»Ÿï¼ˆæºç &#43;è®ºæ–‡ï¼‰</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/bd3e9d492826bd97998d263e743cc82f/" rel="next">
			<span class="pager__subtitle">Next&thinsp;Â»</span>
			<p class="pager__title">JDKä¸‹è½½å®‰è£…</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 ç¼–ç¨‹å¤§å’–.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>