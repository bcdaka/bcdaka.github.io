<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>即插即用的涨点模块之注意力机制（CBAMAttention）详解及代码，可应用于检测、分割、分类等各种算法领域 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/05d34668280b1129931f6dfe7ea458cb/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="即插即用的涨点模块之注意力机制（CBAMAttention）详解及代码，可应用于检测、分割、分类等各种算法领域">
  <meta property="og:description" content="目录
前言
一、CBAM结构
二、CBAM计算流程
三、CBAM参数
四、代码详解
前言 CE模块通常只注意了通道特征，但在视觉任务中，空间任务通常更为重要，是不可忽略的，因此CBAM将通道注意力机制与空间注意力机制进行串联，充分关注特征信息。
什么是空间特征？在深度学习中，空间特征是指描述输入数据在空间维度上的特征信息。对于图像数据而言，空间特征可以涵盖多种信息，包括边缘、角点、纹理、颜色等。这些特征信息可以帮助模型理解图像中不同区域的内容和结构，从而实现诸如目标检测、图像分割、图像分类等任务。在深度学习模型中，通常通过卷积神经网络（CNN）等结构来提取和学习空间特征，这些特征对于模型的表现和性能具有重要的影响。
什么是空间注意力机制？空间注意力机制是一种注意力机制，用于在深度学习模型中对输入数据的不同空间位置进行加权，以便模型能够更加关注重要的空间位置，从而提高模型的性能和泛化能力。空间注意力机制通常应用在图像处理或自然语言处理等任务中，能够有效地捕捉输入数据在空间维度上的相关性。
在空间注意力机制中，模型会学习到针对输入数据中不同空间位置的权重，以确定哪些位置对于任务是最重要的。这些权重可以根据输入数据的内容和上下文来自适应地调整，从而实现对不同空间位置的加权组合。通过引入空间注意力机制，模型可以更好地捕捉数据的局部特征和全局结构，从而提高模型的性能和泛化能力。
通道注意力机制
空间注意力机制
关注对象
关注于不同特征通道的重要性
关注于输入数据中不同位置的重要性
操作对象
输入数据的通道维度
输入数据的空间维度
应用范围
处理具有多个特征通道的数据
处理具有空间结构的数据
一、CBAM结构 CBAM 是由Channel Attention Moduel和Spatial Attention Module构成，结构如图1所示。Channel Attention Moduel，结构如图2所示。对输入的特征图分别同时进行最大池化和平均池化，通过对输入形状为(B,C,H,W)的特征图进行最大池化或平均池化操作，将每个通道(C)在空间维度上的信息进行压缩，最终得到形状为(B,C,1,1)的输出，在这个过程中，对于每个通道而言，它的空间信息被最大池化或者平均池化操作压缩为一个单独的值，从而实现了对全局空间信息的压缩和提取。这一步旨在将特征图上的信息集中在通道上，从而更好的在通道上捕捉到输入的特征图的特征信息，利用这两个特征可以大大提高网络的表示能力。共享网络由两个卷积和一个Relu激活函数构成，先降维再升维，这一步旨在减少参数开销，其中MLP中的权重是共享的，所用的输入都用相同的W0和W1权重矩阵进行计算处理，将共享网络应用于每个特征描述子后，使用元素求和（&#43;）来合并输出特征向量，再将输出的特征向量通过sigmoid函数生成权重向量，确保它们的总和为1。Spatial Attention Module，结构如图3所示。对输入的特征图沿通道轴应用平均池化和最大池化，通过平均池化和最大池化操作，可以将输入张量的通道维度（C）压缩为1，从而将全局通道信息整合为一个单一的通道特征图，形状为(B,1,H,W)。在这个过程中，对于每个样本(B)，模型会对该样本在通道上的特征进行平均池化，从而实现对全局通道信息的压缩合并。这种操作有助于减少参数数量、减小计算复杂度，同时保留重要的通道特征信息。将获得的两个矩阵在通道上拼接起来（torch.cat），并通过一个卷积层，将通道数再次变成1，使获得的特征信息全部分布在一个通道上，再将通过卷积层的输出通过sigmoid函数生成权重向量。CBAM则是将在Channel Attention Module得到的通道注意力权重乘以输入的原始特征图。这一步用于调整每个通道的特征值，强调重要通道的信息，抑制不重要通道的信息。再将之前在Spatial Attention Module得到的空间注意力权重乘以通过通道注意力机制得到的特征图，最终即得到最终输出结果。（通道和空间注意力机制可以并行或者顺序放置，发现顺序排列比平行排列产生更好结果，我们实验结果表明，通道优先顺序略优于空间优先顺序）
图1 CBAM结构
图2 通道注意力机制
图3 空间注意力机制
精读：CBAM（Convolutional Block Attention Module）是一个集成在卷积神经网络中的注意力模块，目的是增强模型的特征表达能力，通过强调重要的特征并抑制不重要的特征。CBAM 通过两个主要部分工作：Channel Attention Module 和 Spatial Attention Module。下面详细解释这两部分的工作原理及其互动方式。
Channel Attention Module (CAM)的核心目的是强调那些对当前任务更重要的特征通道。它通过以下步骤实现：
1.特征压缩：对输入的特征图X，形状为(B,C,H,W)，进行最大池化和平均池化。这两种池化操作都在空间维度H×W 上进行，输出的结果是两个形状为(B,C,1,1)的特征图，即每个通道压缩成一个单独的值，分别代表了该通道的最大值和平均值。通过以下步骤实现：
2.维度转换：通过一个小型神经网络（通常是两层MLP），首先将通道数降维以减少参数量，然后再升维恢复到原始通道数。这个小网络包括两个全连接层和一个ReLU激活函数。
3.特征融合与激活：将最大池化和平均池化得到的两个特征图通过共享的MLP处理后，结果相加并通过sigmoid函数，得到每个通道的权重系数。
Spatial Attention Module (SAM) 的目的是在空间上强调更为关键的区域。它的步骤包括：
1.通道压缩：将处理后的特征图X 进行最大池化和平均池化，但这次是沿着通道轴 C，从而压缩所有通道信息到一个单通道图像中。操作结果是两个形状为(B,1,H,W)的特征图。">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-04-19T16:00:15+08:00">
    <meta property="article:modified_time" content="2024-04-19T16:00:15+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">即插即用的涨点模块之注意力机制（CBAMAttention）详解及代码，可应用于检测、分割、分类等各种算法领域</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p><strong>目录</strong></p> 
<p id="%E5%89%8D%E8%A8%80-toc" style="margin-left:0px;"><a href="#%E5%89%8D%E8%A8%80" rel="nofollow">前言</a></p> 
<p id="%E4%B8%80%E3%80%81CBAM%E7%BB%93%E6%9E%84-toc" style="margin-left:0px;"><a href="#%E4%B8%80%E3%80%81CBAM%E7%BB%93%E6%9E%84" rel="nofollow">一、CBAM结构</a></p> 
<p id="%E4%BA%8C%E3%80%81CBAM%E8%AE%A1%E7%AE%97%E6%B5%81%E7%A8%8B-toc" style="margin-left:0px;"><a href="#%E4%BA%8C%E3%80%81CBAM%E8%AE%A1%E7%AE%97%E6%B5%81%E7%A8%8B" rel="nofollow">二、CBAM计算流程</a></p> 
<p id="%E4%B8%89%E3%80%81CBAM%E5%8F%82%E6%95%B0-toc" style="margin-left:0px;"><a href="#%E4%B8%89%E3%80%81CBAM%E5%8F%82%E6%95%B0" rel="nofollow">三、CBAM参数</a></p> 
<p id="%E5%9B%9B%E3%80%81%E4%BB%A3%E7%A0%81%E8%AF%A6%E8%A7%A3-toc" style="margin-left:0px;"><a href="#%E5%9B%9B%E3%80%81%E4%BB%A3%E7%A0%81%E8%AF%A6%E8%A7%A3" rel="nofollow">四、代码详解</a></p> 
<hr> 
<h2 id="%E5%89%8D%E8%A8%80"><a id="_7"></a>前言</h2> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#FFFFFF;"><span style="color:#353740;">        CE模块通常只注意了通道特征，但在视觉任务中，空间任务通常更为重要，是不可忽略的，因此CBAM将通道注意力机制与空间注意力机制进行串联，充分关注特征信息。</span></span></p> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#FFFFFF;"><span style="color:#353740;">        什么是空间特征？在深度学习中，空间特征是指描述输入数据在空间维度上的特征信息。对于图像数据而言，空间特征可以涵盖多种信息，包括边缘、角点、纹理、颜色等。这些特征信息可以帮助模型理解图像中不同区域的内容和结构，从而实现诸如目标检测、图像分割、图像分类等任务。在深度学习模型中，通常通过卷积神经网络（CNN）等结构来提取和学习空间特征，这些特征对于模型的表现和性能具有重要的影响。</span></span></p> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#FFFFFF;"><span style="color:#353740;">        什么是空间注意力机制？空间注意力机制是一种注意力机制，用于在深度学习模型中对输入数据的不同空间位置进行加权，以便模型能够更加关注重要的空间位置，从而提高模型的性能和泛化能力。空间注意力机制通常应用在图像处理或自然语言处理等任务中，能够有效地捕捉输入数据在空间维度上的相关性。</span></span></p> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#FFFFFF;"><span style="color:#353740;">        在空间注意力机制中，模型会学习到针对输入数据中不同空间位置的权重，以确定哪些位置对于任务是最重要的。这些权重可以根据输入数据的内容和上下文来自适应地调整，从而实现对不同空间位置的加权组合。通过引入空间注意力机制，模型可以更好地捕捉数据的局部特征和全局结构，从而提高模型的性能和泛化能力。</span></span></p> 
<table border="1" cellspacing="0"><tbody><tr><td style="border-color:#000000;vertical-align:top;width:142pt;"> <p style="margin-left:0;text-align:left;"></p> </td><td style="border-color:#000000;vertical-align:top;width:142.05pt;"> <p style="margin-left:0;text-align:left;"><span style="background-color:#FFFFFF;"><span style="color:#353740;">通道注意力机制</span></span></p> </td><td style="border-color:#000000;vertical-align:top;width:142.05pt;"> <p style="margin-left:0;text-align:left;"><span style="background-color:#FFFFFF;"><span style="color:#353740;">空间注意力机制</span></span></p> </td></tr><tr><td style="border-color:#000000;vertical-align:top;width:142pt;"> <p style="margin-left:0;text-align:left;"><span style="background-color:#FFFFFF;"><span style="color:#353740;">关注对象</span></span></p> </td><td style="vertical-align:top;width:142.05pt;"> <p style="margin-left:0;text-align:left;"><span style="background-color:#FFFFFF;"><span style="color:#353740;">关注于不同特征通道的重要性</span></span></p> </td><td style="vertical-align:top;width:142.05pt;"> <p style="margin-left:0;text-align:left;"><span style="background-color:#FFFFFF;"><span style="color:#353740;">关注于输入数据中不同位置的重要性</span></span></p> </td></tr><tr><td style="border-color:#000000;vertical-align:top;width:142pt;"> <p style="margin-left:0;text-align:left;"><span style="background-color:#FFFFFF;"><span style="color:#353740;">操作对象</span></span></p> </td><td style="vertical-align:top;width:142.05pt;"> <p style="margin-left:0;text-align:left;"><span style="background-color:#FFFFFF;"><span style="color:#353740;">输入数据的通道维度</span></span></p> </td><td style="vertical-align:top;width:142.05pt;"> <p style="margin-left:0;text-align:left;"><span style="background-color:#FFFFFF;"><span style="color:#353740;">输入数据的空间维度</span></span></p> </td></tr><tr><td style="border-color:#000000;vertical-align:top;width:142pt;"> <p style="margin-left:0;text-align:left;"><span style="background-color:#FFFFFF;"><span style="color:#353740;">应用范围</span></span></p> </td><td style="vertical-align:top;width:142.05pt;"> <p style="margin-left:0;text-align:left;"><span style="background-color:#FFFFFF;"><span style="color:#353740;">处理具有多个特征通道的数据</span></span></p> </td><td style="vertical-align:top;width:142.05pt;"> <p style="margin-left:0;text-align:left;"><span style="background-color:#FFFFFF;"><span style="color:#353740;">处理具有空间结构的数据</span></span></p> </td></tr></tbody></table> 
<hr> 
<h2 id="%E4%B8%80%E3%80%81CBAM%E7%BB%93%E6%9E%84"><a id="pandas_16"></a>一、CBAM结构</h2> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#FFFFFF;"><span style="color:#353740;">        CBAM 是由</span></span><span style="background-color:#FFFFFF;"><span style="color:#FF0000;">Channel Attention Moduel</span></span><span style="background-color:#FFFFFF;"><span style="color:#353740;">和</span></span><span style="background-color:#FFFFFF;"><span style="color:#4472c4;">Spatial Attention Module</span></span><span style="background-color:#FFFFFF;"><span style="color:#353740;">构成，结构如图1所示。</span></span><span style="background-color:#FFFFFF;"><span style="color:#FF0000;">Channel Attention Moduel</span></span><span style="background-color:#FFFFFF;"><span style="color:#353740;">，结构如图2所示。对输入的特征图分别同时进行最大池化和平均池化，通过对</span></span><span style="background-color:#FFFFFF;"><span style="color:#FF0000;">输入形状为(B,C,H,W)</span></span><span style="background-color:#FFFFFF;"><span style="color:#353740;">的特征图进行</span></span><span style="background-color:#FFFFFF;"><span style="color:#FF0000;">最大池化或平均池化操作</span></span><span style="background-color:#FFFFFF;"><span style="color:#353740;">，将每个通道(C)在空间维度上的信息进行压缩，最终得到形状为</span></span><span style="background-color:#FFFFFF;"><span style="color:#FF0000;">(B,C,1,1)</span></span><span style="background-color:#FFFFFF;"><span style="color:#FF0000;">的输出</span></span><span style="background-color:#FFFFFF;"><span style="color:#353740;">，在这个过程中，对于每个通道而言，它的空间信息被最大池化或者平均池化操作压缩为一个单独的值，从而实现了对全局空间信息的压缩和提取。这一步旨在将特征图上的信息集中在通道上，从而更好的在通道上捕捉到输入的特征图的特征信息，利用这两个特征可以大大提高网络的表示能力。共享网络由两个卷积和一个Relu激活函数构成，先降维再升维，这一步旨在减少参数开销，其中MLP中的权重是共享的，所用的输入都用相同的W0和W1权重矩阵进行计算处理，将共享网络应用于每个特征描述子后，使用元素求和（+）来合并输出特征向量，再将输出的特征向量通过sigmoid函数生成权重向量，确保它们的总和为1。</span></span><span style="background-color:#FFFFFF;"><span style="color:#4472c4;">Spatial Attention Module</span></span><span style="background-color:#FFFFFF;"><span style="color:#353740;">，结构如图3所示。对输入的特征图沿通道轴应用平均池化和最大池化，通过</span></span><span style="background-color:#FFFFFF;"><span style="color:#4472c4;">平均池化和最大池化</span></span><span style="background-color:#FFFFFF;"><span style="color:#353740;">操作，可以将输入张量的通道维度（C）压缩为1，从而将全局通道信息整合为一个单一的通道特征图，形状为</span></span><span style="background-color:#FFFFFF;"><span style="color:#4472c4;">(B,1,H,W)</span></span><span style="background-color:#FFFFFF;"><span style="color:#353740;">。在这个过程中，对于每个样本(B)，模型会对该样本在通道上的特征进行平均池化，从而实现对全局通道信息的压缩合并。这种操作有助于减少参数数量、减小计算复杂度，同时保留重要的通道特征信息。将获得的两个矩阵在通道上拼接起来（torch.cat），并通过一个卷积层，将通道数再次变成1，使获得的特征信息全部分布在一个通道上，再将通过卷积层的输出通过sigmoid函数生成权重向量。</span></span><span style="background-color:#FFFFFF;"><span style="color:#ffc000;">CBAM</span></span><span style="background-color:#FFFFFF;"><span style="color:#ffc000;">则是将在Channel Attention Module得到的通道注意力权重乘以输入的原始特征图。这一步用于调整每个通道的特征值，强调重要通道的信息，抑制不</span></span><span style="color:#ffc000;">重要通道的信息。再将之前在</span><span style="background-color:#FFFFFF;"><span style="color:#ffc000;">Spatial Attention Module</span></span><span style="color:#ffc000;">得到的空间注意力权重乘以通过通道注意力机制得到的特征图，最终即得到最终输出结果。</span>（通道和空间注意力机制可以并行或者顺序放置，发现顺序排列比平行排列产生更好结果，我们实验结果表明，通道优先顺序略优于空间优先顺序）</p> 
<p style="margin-left:0;text-align:left;"></p> 
<p style="margin-left:0;text-align:left;"></p> 
<p style="margin-left:0;text-align:left;"><img alt="" height="244" src="https://images2.imgbox.com/69/55/D8D2pqen_o.png" width="859"></p> 
<p style="margin-left:0;text-align:center;">图1 CBAM结构</p> 
<p style="margin-left:0;text-align:center;"></p> 
<p style="margin-left:0;text-align:left;"><img alt="" height="216" src="https://images2.imgbox.com/76/b5/jI0keWZX_o.png" width="904"></p> 
<p style="margin-left:0;text-align:center;">图2 通道注意力机制</p> 
<p style="margin-left:0;text-align:center;"></p> 
<p style="margin-left:0;text-align:justify;">         <img alt="" height="230" src="https://images2.imgbox.com/c2/d3/WyDrywrz_o.png" width="688"></p> 
<p style="margin-left:0;text-align:center;">图3 空间注意力机制</p> 
<p style="margin-left:0;text-align:justify;"><span style="color:#0070c0;">精读：</span>CBAM（Convolutional Block Attention Module）是一个集成在卷积神经网络中的注意力模块，目的是增强模型的特征表达能力，通过强调重要的特征并抑制不重要的特征。CBAM 通过两个主要部分工作：Channel Attention Module 和 Spatial Attention Module。下面详细解释这两部分的工作原理及其互动方式。</p> 
<p style="margin-left:0;text-align:justify;"><span style="color:#70ad47;">Channel Attention Module (CAM)</span>的核心目的是强调那些对当前任务更重要的特征通道。它通过以下步骤实现：</p> 
<p style="margin-left:0;text-align:justify;"><strong>1.</strong><strong>特征压缩：</strong>对输入的特征图X，形状为(B,C,H,W)，进行最大池化和平均池化。这两种池化操作都在空间维度H×W 上进行，输出的结果是两个形状为(B,C,1,1)的特征图，即每个通道压缩成一个单独的值，分别代表了该通道的最大值和平均值。通过以下步骤实现：</p> 
<p style="margin-left:0;text-align:justify;"><strong>2.</strong><strong>维度转换：</strong>通过一个小型神经网络（通常是两层MLP），首先将通道数降维以减少参数量，然后再升维恢复到原始通道数。这个小网络包括两个全连接层和一个ReLU激活函数。</p> 
<p style="margin-left:0;text-align:justify;"><strong>3.</strong><strong>特征融合与激活：</strong>将最大池化和平均池化得到的两个特征图通过共享的MLP处理后，结果相加并通过sigmoid函数，得到每个通道的权重系数。</p> 
<p style="margin-left:0;text-align:justify;"><span style="color:#70ad47;">Spatial Attention Module (SAM)</span> 的目的是在空间上强调更为关键的区域。它的步骤包括：</p> 
<p style="margin-left:0;text-align:justify;"><strong>1.</strong><strong>通道压缩：</strong>将处理后的特征图X 进行最大池化和平均池化，但这次是沿着通道轴 C，从而压缩所有通道信息到一个单通道图像中。操作结果是两个形状为(B,1,H,W)的特征图。</p> 
<p style="margin-left:0;text-align:justify;"><strong>2. </strong><strong>特征拼接与卷积</strong>：将上述两个特征图在通道维度上拼接，然后通过一个卷积层将通道数变为1，最终通过sigmoid函数得到每个空间位置的权重系数。</p> 
<p style="margin-left:0;text-align:justify;"><span style="color:#70ad47;">整合与顺序</span></p> 
<p style="margin-left:0;text-align:justify;"><strong>1.特征图</strong><strong>权重调整：</strong>首先，通过Channel Attention Module得到的通道权重乘以原始的特征图X，调整每个通道的重要性。然后，将这个调整后的特征图输入到Spatial Attention Module，进一步调整每个位置的重要性。</p> 
<p style="margin-left:0;text-align:justify;"><strong>2. </strong><strong>顺序优化：</strong>实验显示，首先应用Channel Attention（通道注意力）后再应用Spatial Attention（空间注意力）通常效果更好。这是因为，一旦我们确定了最重要的特征通道，再去调整这些通道中各个位置的重要性，能够更精确地强化有用的信息，抑制不必要的信息。</p> 
<h2 id="%E4%BA%8C%E3%80%81CBAM%E8%AE%A1%E7%AE%97%E6%B5%81%E7%A8%8B"><a id="_19"></a>二、CBAM计算流程</h2> 
<p style="margin-left:0;text-align:justify;"><span style="background-color:#FFFFFF;"><span style="color:#353740;"> 如图 1所示，给定一个输入</span></span><img alt="" height="29" src="https://images2.imgbox.com/40/e1/aDE0Ay8K_o.png" width="128"><span style="background-color:#FFFFFF;"><span style="color:#353740;">，</span></span><img alt="" height="29" src="https://images2.imgbox.com/b4/15/c87gRYpD_o.png" width="131"><span style="background-color:#FFFFFF;"><span style="color:#353740;">为CBAM通过 Channel Attention Moduel获得，在Channel Attention Moduel中，先通过全局平均池化和全局最大池化分别获得</span></span><img alt="" height="31" src="https://images2.imgbox.com/d3/00/clBO3xJl_o.png" width="43"><span style="background-color:#FFFFFF;"><span style="color:#353740;">和</span></span><img alt="" height="28" src="https://images2.imgbox.com/a7/16/2wpNJuIw_o.png" width="48"><span style="background-color:#FFFFFF;"><span style="color:#353740;">，其中</span></span><img alt="" height="28" src="https://images2.imgbox.com/cb/58/RAlcjY5Y_o.png" width="15"><span style="background-color:#FFFFFF;"><span style="color:#353740;">为Sigmoid函数，MLP结构为Conv-ReLU-Conv，</span></span><img alt="" height="30" src="https://images2.imgbox.com/e9/01/085OPpAz_o.png" width="133"><span style="background-color:#FFFFFF;"><span style="color:#353740;">，</span></span><img alt="" height="30" src="https://images2.imgbox.com/94/5e/HJhRpkBH_o.png" width="130"><span style="background-color:#FFFFFF;"><span style="color:#353740;">，</span></span><img alt="" height="28" src="https://images2.imgbox.com/a7/91/LH4Xmibj_o.png" width="35"><span style="background-color:#FFFFFF;"><span style="color:#353740;">，</span></span><img alt="" height="28" src="https://images2.imgbox.com/24/b2/JrZwDzLc_o.png" width="30"><span style="background-color:#FFFFFF;"><span style="color:#353740;">为MLP的权重。</span></span></p> 
<p class="img-center"><img alt="" height="31" src="https://images2.imgbox.com/f4/28/hpMWGUBs_o.png" width="201"></p> 
<p style="margin-left:0px;text-align:center;"><img alt="" height="28" src="https://images2.imgbox.com/cd/21/H8CuVK49_o.png" width="210"></p> 
<p class="img-center"><img alt="" height="33" src="https://images2.imgbox.com/3f/1e/BcNDYT3P_o.png" width="570"></p> 
<p style="margin-left:0;text-align:left;"><em>             <span style="color:#353740;"><span style="background-color:#ffffff;">               </span></span></em><img alt="" height="43" src="https://images2.imgbox.com/7e/87/Ew7fDkGj_o.png" width="387"></p> 
<p style="margin-left:0;text-align:left;"><img alt="" height="28" src="https://images2.imgbox.com/91/2f/i7IVlVlK_o.png" width="140"><span style="background-color:#FFFFFF;"><span style="color:#353740;">为CBAM通过Spatial Attention Module获得，在Spatial Attention Module中，先通过全局平均池化和全局最大池化分别获得</span></span><img alt="" height="31" src="https://images2.imgbox.com/c4/7f/q8lSNZTh_o.png" width="154"><span style="background-color:#FFFFFF;"><span style="color:#353740;">和</span></span><img alt="" height="28" src="https://images2.imgbox.com/7b/90/851Qs3bt_o.png" width="159"><span style="background-color:#FFFFFF;"><span style="color:#353740;">，其中</span></span><img alt="" height="28" src="https://images2.imgbox.com/67/09/7rqJocJV_o.png" width="15"><span style="background-color:#FFFFFF;"><span style="color:#353740;">为Sigmoid函数，</span></span><img alt="" height="28" src="https://images2.imgbox.com/54/cf/Tl6M9A8c_o.png" width="47"><span style="background-color:#FFFFFF;"><span style="color:#353740;">表示滤波器为7*7的卷积运算。</span></span></p> 
<p style="margin-left:0px;text-align:center;"><img alt="" height="31" src="https://images2.imgbox.com/f3/62/nzNZbDI0_o.png" width="207"></p> 
<p style="margin-left:0px;text-align:center;"><img alt="" height="28" src="https://images2.imgbox.com/16/9b/KWHeoEaP_o.png" width="210"></p> 
<p style="margin-left:0px;text-align:center;"><img alt="" height="28" src="https://images2.imgbox.com/29/91/WowCDxNB_o.png" width="557"></p> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#FFFFFF;"><span style="color:#353740;">将F通过Channel Attention Moduel得到的通道注意力权重</span></span><img alt="" height="28" src="https://images2.imgbox.com/0e/61/UdHVAvSP_o.png" width="67"><span style="background-color:#FFFFFF;"><span style="color:#353740;">乘以输入的原始特征图F，以获得</span></span><img alt="" height="28" src="https://images2.imgbox.com/8c/10/vfkfRpOD_o.png" width="23"><span style="background-color:#FFFFFF;"><span style="color:#353740;">，再将</span></span><img alt="" height="28" src="https://images2.imgbox.com/a0/d7/StP6mo9b_o.png" width="23"><span style="background-color:#FFFFFF;"><span style="color:#353740;">通过Spatial Attention Module</span></span>得到的空间注意力权重<img alt="" height="28" src="https://images2.imgbox.com/09/e0/Iieb24Wz_o.png" width="71">乘以通过通道注意力机制得到的特征图<img alt="" height="28" src="https://images2.imgbox.com/c3/6e/0G2zDkXV_o.png" width="23"><span style="background-color:#FFFFFF;"><span style="color:#353740;">，其中</span></span><img alt="" height="28" src="https://images2.imgbox.com/bc/46/BCAJeJRY_o.png" width="24"><span style="background-color:#FFFFFF;"><span style="color:#353740;">为元素乘法，</span></span><img alt="" height="28" src="https://images2.imgbox.com/7d/66/Pvp4h2Om_o.png" width="29"><em><span style="background-color:#FFFFFF;"><span style="color:#353740;">为最终输出</span></span></em></p> 
<p class="img-center"><img alt="" height="28" src="https://images2.imgbox.com/aa/33/PvzxKdM3_o.png" width="171"></p> 
<p class="img-center"><img alt="" height="28" src="https://images2.imgbox.com/31/d2/NEHBCZmM_o.png" width="188"></p> 
<h2 id="%E4%B8%89%E3%80%81CBAM%E5%8F%82%E6%95%B0">三、CBAM参数</h2> 
<p>利用thop库的profile函数计算FLOPs和Param。Input:(512,7,7)。</p> 
<table border="1" cellspacing="0"><tbody><tr><td style="border-color:#000000;vertical-align:top;width:142pt;"> <p style="margin-left:0;text-align:justify;">Module</p> </td><td style="border-color:#000000;vertical-align:top;width:142.05pt;"> <p style="margin-left:0;text-align:justify;">FLOPs</p> </td><td style="border-color:#000000;vertical-align:top;width:142.05pt;"> <p style="margin-left:0;text-align:justify;">Param</p> </td></tr><tr><td style="border-color:#000000;vertical-align:top;width:142pt;"> <p style="margin-left:0;text-align:justify;">CBAM</p> </td><td style="vertical-align:top;width:142.05pt;"> <p style="margin-left:0;text-align:justify;">95938.0</p> </td><td style="vertical-align:top;width:142.05pt;"> <p style="margin-left:0;text-align:justify;">32866.0</p> </td></tr></tbody></table> 
<h2 id="%E5%9B%9B%E3%80%81%E4%BB%A3%E7%A0%81%E8%AF%A6%E8%A7%A3">四、代码详解</h2> 
<p> </p> 
<pre><code class="language-python">import torch
from torch import nn
from torch.nn import init

class ChannelAttention(nn.Module):
    def __init__(self, in_planes, ratio=16):
        super(ChannelAttention, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.max_pool = nn.AdaptiveMaxPool2d(1)
        self.mlp=nn.Sequential(
            nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False),
            nn.ReLU(),
            nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False)
        )
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):

        avg_out = self.mlp(self.avg_pool(x))  # 通过平均池化压缩全局空间信息: (B,C,H,W)--&gt; (B,C,1,1) ,然后通过MLP降维升维:(B,C,1,1)
        max_out = self.mlp(self.max_pool(x))  # 通过最大池化压缩全局空间信息: (B,C,H,W)--&gt; (B,C,1,1) ,然后通过MLP降维升维:(B,C,1,1)
        out = avg_out + max_out
        return self.sigmoid(out)


class SpatialAttention(nn.Module):
    def __init__(self, kernel_size=7):
        super(SpatialAttention, self).__init__()

        assert kernel_size in (3, 7), 'kernel size must be 3 or 7'
        padding = 3 if kernel_size == 7 else 1
        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        avg_out = torch.mean(x, dim=1, keepdim=True)    # 通过平均池化压缩全局通道信息:(B,C,H,W)--&gt;(B,1,H,W)
        max_out, _ = torch.max(x, dim=1, keepdim=True)  # 通过最大池化压缩全局通道信息:(B,C,H,W)--&gt;(B,1,H,W)
        x = torch.cat([avg_out, max_out], dim=1)     # 在通道上拼接两个矩阵:(B,2,H,W)
        x = self.conv1(x)                                   # 通过卷积层得到注意力权重:(B,2,H,W)--&gt;(B,1,H,W)
        return self.sigmoid(x)


class CBAM(nn.Module):
    def __init__(self, in_planes, ratio=16, kernel_size=7):
        super(CBAM, self).__init__()
        self.ca = ChannelAttention(in_planes, ratio)
        self.sa = SpatialAttention(kernel_size)

    def init_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                init.kaiming_normal_(m.weight, mode='fan_out')
                if m.bias is not None:
                    init.constant_(m.bias, 0)
            elif isinstance(m, nn.BatchNorm2d):
                init.constant_(m.weight, 1)
                init.constant_(m.bias, 0)
            elif isinstance(m, nn.Linear):
                init.normal_(m.weight, std=0.001)
                if m.bias is not None:
                    init.constant_(m.bias, 0)

    def forward(self, x):
        out = x * self.ca(x)                # 通过通道注意力机制得到的特征图,x:(B,C,H,W),ca(x):(B,C,1,1),out:(B,C,H,W)
        result = out * self.sa(out)           # 通过空间注意力机制得到的特征图,out:(B,C,H,W),sa(out):(B,1,H,W),result:(B,C,H,W)
        return result


if __name__ == '__main__':
    from  torchsummary import summary
    from thop import profile
    model = CBAM(in_planes=512)
    # summary(model, (512, 7, 7), device='cpu', batch_size=1)
    flops, params = profile(model, inputs=(torch.randn(1, 512, 7, 7),))
    print(f"FLOPs: {flops}, Params: {params}")</code></pre> 
<h3><a id="1_20"></a></h3> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/2865837e95fec7a35087f44a477af6ac/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">初学者必看：AI绘画电脑配置指南</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/d838c735ad4983cf10a30a8647a3f52f/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Java中如何实现minio文件上传</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>