<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>基于llama-index对embedding模型进行微调 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/c9b14e9c1e55a6e4fcccec75f088c515/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="基于llama-index对embedding模型进行微调">
  <meta property="og:description" content="QA对话目前是大语言模型的一大应用场景，在QA对话中，由于大语言模型信息的滞后性以及不包含业务知识的特点，我们经常需要外挂知识库来协助大模型解决一些问题。在外挂知识库的过程中，embedding模型的召回效果直接影响到大模型的回答效果，因此，在许多场景下，我们都需要微调我们的embedding模型来提高我们的召回效果。下面，我们就基于llama-index对BAAI/bge-base-zh-v1.5模型进行微调，关于该模型的介绍，可以参考https://huggingface.co/BAAI/bge-base-zh-v1.5。
平台介绍 对embedding模型进行微调的过程中需要使用GPU加速训练，由于家境贫寒，我这里就使用了Google colab提供的免费T4GPU进行微调测试。如果大家没办法使用这个，可以使用国内一些公司的GPU云平台，租便宜的GPU就行，微调这个模型所耗费的GPU资源不多。以下所有训练代码皆是在Jupter-notebook上编写并执行的。
依赖安装 安装一些依赖库，有些依赖需要制定版本，否则存在不兼容的问题。
!pip install langchain==0.0.300 llmx==0.0.15a0 openai==0.28.1 llama_index==0.8.23.post1 pypdf sentence-transformers 训练样本准备 我们当前的使用场景是QA问答场景，因此训练数据的格式最好也是问答的格式。我这里由于没有现成的问答样本（人工整理比较耗时），因此我就摘取了《明朝那些事儿》这个小说里面的部分章节，然后让GPT-3.5针对文章内容进行提问，从而形成问答对。代码如下
import json import openai import os from llama_index import SimpleDirectoryReader from llama_index.node_parser import SimpleNodeParser from llama_index.schema import MetadataMode from llama_index import ( VectorStoreIndex, SimpleDirectoryReader, ServiceContext, Response ) def load_corpus(docs, for_training=False, verbose=False): parser = SimpleNodeParser.from_defaults() if for_training: nodes = parser.get_nodes_from_documents(docs[:5], show_progress=verbose) else: nodes = parser.get_nodes_from_documents(docs[6:], show_progress=verbose) if verbose: print(f&#39;Parsed {len(nodes)} nodes&#39;) return nodes SEC_FILE = [&#39;embedding_test.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2023-12-24T16:47:50+08:00">
    <meta property="article:modified_time" content="2023-12-24T16:47:50+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">基于llama-index对embedding模型进行微调</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>QA对话目前是大语言模型的一大应用场景，在QA对话中，由于大语言模型信息的滞后性以及不包含业务知识的特点，我们经常需要外挂知识库来协助大模型解决一些问题。在外挂知识库的过程中，embedding模型的召回效果直接影响到大模型的回答效果，因此，在许多场景下，我们都需要微调我们的embedding模型来提高我们的召回效果。下面，我们就基于llama-index对<strong>BAAI/bge-base-zh-v1.5</strong>模型进行微调，关于该模型的介绍，可以参考https://huggingface.co/BAAI/bge-base-zh-v1.5。</p> 
<h2><a id="_3"></a>平台介绍</h2> 
<p>对embedding模型进行微调的过程中需要使用GPU加速训练，由于家境贫寒，我这里就使用了Google colab提供的免费T4GPU进行微调测试。如果大家没办法使用这个，可以使用国内一些公司的GPU云平台，租便宜的GPU就行，微调这个模型所耗费的GPU资源不多。以下所有训练代码皆是在Jupter-notebook上编写并执行的。</p> 
<h2><a id="_7"></a>依赖安装</h2> 
<p>安装一些依赖库，有些依赖需要制定版本，否则存在不兼容的问题。</p> 
<pre><code class="prism language-bash"><span class="token operator">!</span>pip <span class="token function">install</span> <span class="token assign-left variable">langchain</span><span class="token operator">==</span><span class="token number">0.0</span>.300 <span class="token assign-left variable">llmx</span><span class="token operator">==</span><span class="token number">0.0</span>.15a0 <span class="token assign-left variable">openai</span><span class="token operator">==</span><span class="token number">0.28</span>.1 <span class="token assign-left variable">llama_index</span><span class="token operator">==</span><span class="token number">0.8</span>.23.post1 pypdf sentence-transformers
</code></pre> 
<h2><a id="_15"></a>训练样本准备</h2> 
<p>我们当前的使用场景是QA问答场景，因此训练数据的格式最好也是问答的格式。我这里由于没有现成的问答样本（人工整理比较耗时），因此我就摘取了《明朝那些事儿》这个小说里面的部分章节，然后让GPT-3.5针对文章内容进行提问，从而形成问答对。代码如下</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> json
<span class="token keyword">import</span> openai
<span class="token keyword">import</span> os

<span class="token keyword">from</span> llama_index <span class="token keyword">import</span> SimpleDirectoryReader
<span class="token keyword">from</span> llama_index<span class="token punctuation">.</span>node_parser <span class="token keyword">import</span> SimpleNodeParser
<span class="token keyword">from</span> llama_index<span class="token punctuation">.</span>schema <span class="token keyword">import</span> MetadataMode
<span class="token keyword">from</span> llama_index <span class="token keyword">import</span> <span class="token punctuation">(</span>
    VectorStoreIndex<span class="token punctuation">,</span>
    SimpleDirectoryReader<span class="token punctuation">,</span>
    ServiceContext<span class="token punctuation">,</span>
    Response
<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">load_corpus</span><span class="token punctuation">(</span>docs<span class="token punctuation">,</span> for_training<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    parser <span class="token operator">=</span> SimpleNodeParser<span class="token punctuation">.</span>from_defaults<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> for_training<span class="token punctuation">:</span>
        nodes <span class="token operator">=</span> parser<span class="token punctuation">.</span>get_nodes_from_documents<span class="token punctuation">(</span>docs<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> show_progress<span class="token operator">=</span>verbose<span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        nodes <span class="token operator">=</span> parser<span class="token punctuation">.</span>get_nodes_from_documents<span class="token punctuation">(</span>docs<span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> show_progress<span class="token operator">=</span>verbose<span class="token punctuation">)</span>

    <span class="token keyword">if</span> verbose<span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Parsed </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span><span class="token builtin">len</span><span class="token punctuation">(</span>nodes<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string"> nodes'</span></span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> nodes

SEC_FILE <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'embedding_test.txt'</span><span class="token punctuation">]</span> <span class="token comment"># embedding_test.txt是我训练样本的文件名，即我摘取了部分小说章节并直接保存为了txt文件。</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Loading files </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>SEC_FILE<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>

reader <span class="token operator">=</span> SimpleDirectoryReader<span class="token punctuation">(</span>input_files<span class="token operator">=</span>SEC_FILE<span class="token punctuation">)</span>
docs <span class="token operator">=</span> reader<span class="token punctuation">.</span>load_data<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Loaded </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span><span class="token builtin">len</span><span class="token punctuation">(</span>docs<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string"> docs'</span></span><span class="token punctuation">)</span>

docs_nodes <span class="token operator">=</span> load_corpus<span class="token punctuation">(</span>docs<span class="token punctuation">,</span> for_training<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token builtin">len</span><span class="token punctuation">(</span>docs_nodes<span class="token punctuation">)</span>

train_nodes <span class="token operator">=</span> docs_nodes<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">75</span><span class="token punctuation">]</span>  <span class="token comment"># 人工选择3分之2作为训练集</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Loaded </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span><span class="token builtin">len</span><span class="token punctuation">(</span>train_nodes<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string"> train docs'</span></span><span class="token punctuation">)</span>
val_nodes <span class="token operator">=</span> docs_nodes<span class="token punctuation">[</span><span class="token number">76</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token comment"># 剩下三分之一作为验证集</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Loaded </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span><span class="token builtin">len</span><span class="token punctuation">(</span>val_nodes<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string"> val docs'</span></span><span class="token punctuation">)</span>
</code></pre> 
<h2><a id="_64"></a>构造训练集和测试集</h2> 
<p>使用GPT3.5基于小说内容生成对应的问题，最后生成train_dataset.json作为训练集，val_dataset.json作为验证集。</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> llama_index<span class="token punctuation">.</span>finetuning <span class="token keyword">import</span> <span class="token punctuation">(</span>
    generate_qa_embedding_pairs<span class="token punctuation">,</span>
    EmbeddingQAFinetuneDataset<span class="token punctuation">,</span>
<span class="token punctuation">)</span>
<span class="token keyword">from</span> llama_index<span class="token punctuation">.</span>llms <span class="token keyword">import</span> OpenAI

os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">"OPENAI_API_KEY"</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">"sk-************"</span>
openai<span class="token punctuation">.</span>api_key <span class="token operator">=</span> os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">"OPENAI_API_KEY"</span><span class="token punctuation">]</span>
openai<span class="token punctuation">.</span>api_base <span class="token operator">=</span> <span class="token string">"https://************"</span>

prompt<span class="token operator">=</span><span class="token triple-quoted-string string">"""下方是上下文信息。

---------------------
{context_str}
---------------------

根据提供的上下文信息和没有先验知识的原则，仅基于以下查询生成问题。

你是一名教师/教授。你的任务是为即将到来的测验/考试设置{num_questions_per_chunk}个问题。这些问题应在文档中多样化，且仅限于所提供的上下文信息。
"""</span>

train_dataset <span class="token operator">=</span> generate_qa_embedding_pairs<span class="token punctuation">(</span>train_nodes<span class="token punctuation">,</span> qa_generate_prompt_tmpl<span class="token operator">=</span>prompt<span class="token punctuation">)</span>
val_dataset <span class="token operator">=</span> generate_qa_embedding_pairs<span class="token punctuation">(</span>val_nodes<span class="token punctuation">,</span> qa_generate_prompt_tmpl<span class="token operator">=</span>prompt<span class="token punctuation">)</span>

train_dataset<span class="token punctuation">.</span>save_json<span class="token punctuation">(</span><span class="token string">"train_dataset.json"</span><span class="token punctuation">)</span>
val_dataset<span class="token punctuation">.</span>save_json<span class="token punctuation">(</span><span class="token string">"val_dataset.json"</span><span class="token punctuation">)</span>
</code></pre> 
<h2><a id="Embedding_97"></a>微调Embedding模型</h2> 
<p>这里的微调都是使用的默认参数，在实际微调过程中，可根据实际情况进行调整。</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> llama_index<span class="token punctuation">.</span>finetuning <span class="token keyword">import</span> SentenceTransformersFinetuneEngine
</code></pre> 
<pre><code class="prism language-python">train_dataset <span class="token operator">=</span> EmbeddingQAFinetuneDataset<span class="token punctuation">.</span>from_json<span class="token punctuation">(</span><span class="token string">"train_dataset.json"</span><span class="token punctuation">)</span>
val_dataset <span class="token operator">=</span> EmbeddingQAFinetuneDataset<span class="token punctuation">.</span>from_json<span class="token punctuation">(</span><span class="token string">"val_dataset.json"</span><span class="token punctuation">)</span>
finetune_engine <span class="token operator">=</span> SentenceTransformersFinetuneEngine<span class="token punctuation">(</span>
    train_dataset<span class="token punctuation">,</span>
    model_id<span class="token operator">=</span><span class="token string">"BAAI/bge-base-zh-v1.5"</span><span class="token punctuation">,</span>
    model_output_path<span class="token operator">=</span><span class="token string">"test_model"</span><span class="token punctuation">,</span>
    val_dataset<span class="token operator">=</span>val_dataset<span class="token punctuation">,</span>
<span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python">finetune_engine<span class="token punctuation">.</span>finetune<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#由于模型较小，且训练样本较少，微调过程非常快</span>
</code></pre> 
<pre><code class="prism language-python">embed_model <span class="token operator">=</span> finetune_engine<span class="token punctuation">.</span>get_finetuned_model<span class="token punctuation">(</span><span class="token punctuation">)</span>
embed_model
</code></pre> 
<h2><a id="_125"></a>评估微调后的模型</h2> 
<p>在评估阶段，我们对比了微调前、后的BAAI/bge-base-zh-v1.5模型以及OPENAI的ada002的Embedding模型的召回效果，代码如下：</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> llama_index<span class="token punctuation">.</span>embeddings <span class="token keyword">import</span> OpenAIEmbedding
<span class="token keyword">from</span> llama_index <span class="token keyword">import</span> ServiceContext<span class="token punctuation">,</span> VectorStoreIndex
<span class="token keyword">from</span> llama_index<span class="token punctuation">.</span>schema <span class="token keyword">import</span> TextNode
<span class="token keyword">from</span> tqdm<span class="token punctuation">.</span>notebook <span class="token keyword">import</span> tqdm
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
</code></pre> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">evaluate</span><span class="token punctuation">(</span>
    dataset<span class="token punctuation">,</span>
    embed_model<span class="token punctuation">,</span>
    top_k<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span>
    verbose<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span><span class="token punctuation">:</span>
    corpus <span class="token operator">=</span> dataset<span class="token punctuation">.</span>corpus
    queries <span class="token operator">=</span> dataset<span class="token punctuation">.</span>queries
    relevant_docs <span class="token operator">=</span> dataset<span class="token punctuation">.</span>relevant_docs

    service_context <span class="token operator">=</span> ServiceContext<span class="token punctuation">.</span>from_defaults<span class="token punctuation">(</span>embed_model<span class="token operator">=</span>embed_model<span class="token punctuation">)</span>
    nodes <span class="token operator">=</span> <span class="token punctuation">[</span>TextNode<span class="token punctuation">(</span>id_<span class="token operator">=</span>id_<span class="token punctuation">,</span> text<span class="token operator">=</span>text<span class="token punctuation">)</span> <span class="token keyword">for</span> id_<span class="token punctuation">,</span> text <span class="token keyword">in</span> corpus<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
    index <span class="token operator">=</span> VectorStoreIndex<span class="token punctuation">(</span>nodes<span class="token punctuation">,</span> service_context<span class="token operator">=</span>service_context<span class="token punctuation">,</span> show_progress<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    retriever <span class="token operator">=</span> index<span class="token punctuation">.</span>as_retriever<span class="token punctuation">(</span>similarity_top_k<span class="token operator">=</span>top_k<span class="token punctuation">)</span>

    eval_results <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> query_id<span class="token punctuation">,</span> query <span class="token keyword">in</span> tqdm<span class="token punctuation">(</span>queries<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        retrieved_nodes <span class="token operator">=</span> retriever<span class="token punctuation">.</span>retrieve<span class="token punctuation">(</span>query<span class="token punctuation">)</span>
        retrieved_ids <span class="token operator">=</span> <span class="token punctuation">[</span>node<span class="token punctuation">.</span>node<span class="token punctuation">.</span>node_id <span class="token keyword">for</span> node <span class="token keyword">in</span> retrieved_nodes<span class="token punctuation">]</span>
        expected_id <span class="token operator">=</span> relevant_docs<span class="token punctuation">[</span>query_id<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        is_hit <span class="token operator">=</span> expected_id <span class="token keyword">in</span> retrieved_ids  <span class="token comment"># assume 1 relevant doc</span>

        eval_result <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
            <span class="token string">"is_hit"</span><span class="token punctuation">:</span> is_hit<span class="token punctuation">,</span>
            <span class="token string">"retrieved"</span><span class="token punctuation">:</span> retrieved_ids<span class="token punctuation">,</span>
            <span class="token string">"expected"</span><span class="token punctuation">:</span> expected_id<span class="token punctuation">,</span>
            <span class="token string">"query"</span><span class="token punctuation">:</span> query_id<span class="token punctuation">,</span>
        <span class="token punctuation">}</span>
        eval_results<span class="token punctuation">.</span>append<span class="token punctuation">(</span>eval_result<span class="token punctuation">)</span>
    <span class="token keyword">return</span> eval_results
</code></pre> 
<p>注意，在执行下面的代码前，需要先在当前项目的目录下创建results文件夹，否则会导致程序执行失败。</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> sentence_transformers<span class="token punctuation">.</span>evaluation <span class="token keyword">import</span> InformationRetrievalEvaluator
<span class="token keyword">from</span> sentence_transformers <span class="token keyword">import</span> SentenceTransformer

<span class="token keyword">def</span> <span class="token function">evaluate_st</span><span class="token punctuation">(</span>
    dataset<span class="token punctuation">,</span>
    model_id<span class="token punctuation">,</span>
    name<span class="token punctuation">,</span>
<span class="token punctuation">)</span><span class="token punctuation">:</span>
    corpus <span class="token operator">=</span> dataset<span class="token punctuation">.</span>corpus
    queries <span class="token operator">=</span> dataset<span class="token punctuation">.</span>queries
    relevant_docs <span class="token operator">=</span> dataset<span class="token punctuation">.</span>relevant_docs

    evaluator <span class="token operator">=</span> InformationRetrievalEvaluator<span class="token punctuation">(</span>queries<span class="token punctuation">,</span> corpus<span class="token punctuation">,</span> relevant_docs<span class="token punctuation">,</span> name<span class="token operator">=</span>name<span class="token punctuation">)</span>
    model <span class="token operator">=</span> SentenceTransformer<span class="token punctuation">(</span>model_id<span class="token punctuation">)</span>
    <span class="token keyword">return</span> evaluator<span class="token punctuation">(</span>model<span class="token punctuation">,</span> output_path<span class="token operator">=</span><span class="token string">"results/"</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="OPENAIada002_190"></a>OPENAI-ada002</h3> 
<pre><code class="prism language-python">ada <span class="token operator">=</span> OpenAIEmbedding<span class="token punctuation">(</span><span class="token punctuation">)</span>
ada_val_results <span class="token operator">=</span> evaluate<span class="token punctuation">(</span>val_dataset<span class="token punctuation">,</span> ada<span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python">df_ada <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>ada_val_results<span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python">hit_rate_ada <span class="token operator">=</span> df_ada<span class="token punctuation">[</span><span class="token string">'is_hit'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>
hit_rate_ada
</code></pre> 
<p>ada002模型的最终评测结果为<code>0.9285714285714286</code></p> 
<h3><a id="BAAIbgebasezhv15_208"></a>原始BAAI/bge-base-zh-v1.5</h3> 
<pre><code class="prism language-python">bge <span class="token operator">=</span> <span class="token string">"local:BAAI/bge-base-zh-v1.5"</span>
bge_val_results <span class="token operator">=</span> evaluate<span class="token punctuation">(</span>val_dataset<span class="token punctuation">,</span> bge<span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python">df_bge <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>bge_val_results<span class="token punctuation">)</span>
hit_rate_bge <span class="token operator">=</span> df_bge<span class="token punctuation">[</span><span class="token string">'is_hit'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>
hit_rate_bge
</code></pre> 
<p>原始的bge-base-zh-v1.5模型的评测结果为<code>0.7663744588744589</code></p> 
<h3><a id="BAAIbgebasezhv15_223"></a>微调后的BAAI/bge-base-zh-v1.5</h3> 
<pre><code class="prism language-python">finetuned <span class="token operator">=</span> <span class="token string">"local:test_model"</span>
val_results_finetuned <span class="token operator">=</span> evaluate<span class="token punctuation">(</span>val_dataset<span class="token punctuation">,</span> finetuned<span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python">df_finetuned <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>val_results_finetuned<span class="token punctuation">)</span>
hit_rate_finetuned <span class="token operator">=</span> df_finetuned<span class="token punctuation">[</span><span class="token string">'is_hit'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>
hit_rate_finetuned
</code></pre> 
<p>微调后模型的最终评测结果为<code>0.975</code>。即微调后，我们的embedding模型在当前数据集的召回效果由<code>0.766</code>上升到<code>0.975</code>。<strong>注意，得分并不是越高越好，需考虑是否过拟合，可以在其他数据集上再评测下。</strong></p> 
<p>以上，即是一次简单的微调过程。感谢技术的发展和开源大佬们的贡献，使得人工智能的应用门槛越来越低。</p> 
<p><strong>参考资料</strong>：</p> 
<ol><li>https://colab.research.google.com/github/wenqiglantz/nvidia-sec-finetuning/blob/main/embedding-finetuning/finetune_embedding_nvidia_sec.ipynb</li></ol>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/476fbf464637e04d6f7dd9c8ac7a4df8/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">人工智能课程设计毕业设计——基于机器学习的贷款违约预测</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/e34f5dd8150b9ee6f76dbff510169b27/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">本地搭建【文档助手】大模型版（LangChain&#43;llama&#43;Streamlit）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>