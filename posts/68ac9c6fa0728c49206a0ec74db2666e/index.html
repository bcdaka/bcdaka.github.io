<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Flink 内容分享(一)：Fink原理、实战与性能优化(一) - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/68ac9c6fa0728c49206a0ec74db2666e/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="Flink 内容分享(一)：Fink原理、实战与性能优化(一)">
  <meta property="og:description" content="目录
前言
什么是Flink
Flink 部署
Flink快速应用
Flink分布式架构与核心组件
前言 Flink是一个分布式流处理引擎，可以处理实时数据流和批处理数据。它支持多种数据源和数据目的地，并且提供了丰富的流处理操作，如窗口化、聚合、过滤、连接和转换等。Flink还支持多种语言编写的应用程序，如Java、Scala和Python等。
Flink的核心特性包括：
高吞吐量和低延迟：Flink采用了基于内存的流处理方式，可以实现毫秒级别的低延迟和高吞吐量处理。
精确一次性处理（Exactly-once processing）：Flink的流式处理引擎可以确保每条数据仅被处理一次，从而避免数据重复和丢失等问题。
支持多种数据源和数据目的地：Flink能够从多种数据源中读取数据，并将处理结果输出到多种数据目的地中，如Kafka、Hadoop、Cassandra、ElasticSearch等。
灵活的数据分析方式：Flink支持多种数据分析方式，包括流式处理、窗口化聚合、流式SQL查询和机器学习等。
Flink的架构由JobManager和TaskManager两个组件组成。JobManager负责接收和调度应用程序，并协调TaskManager的执行。TaskManager负责执行具体的任务，如数据处理、窗口化、聚合等。
Flink的优化包括优化数据倾斜、调整并行度、合并算子、使用状态后端、调整内存管理等。这些优化手段可以提高Flink的性能和稳定性，保证Flink的高吞吐量和低延迟处理。
什么是Flink 大数据 大数据（Big Data）是指规模庞大、结构多样且速度快速增长的数据集合。这些数据集合通常包含传统数据库管理系统无法有效处理的数据，具有高度的复杂性和挑战性。大数据的主要特点包括三个维度：三V，即Volume（数据量大）、Variety（数据多样性）、Velocity（数据速度）。
数据量大（Volume）：大数据的最明显特征之一是其庞大的数据量。传统的数据处理方法和工具在处理这种规模的数据时可能会变得低效或不可行。
数据多样性（Variety）：大数据不仅包括结构化数据（如表格数据），还包括半结构化数据（如JSON、XML）和非结构化数据（如文本、图像、音频、视频等）。这些数据可能来自不同的源头和不同的格式。
数据速度快（Velocity）：大数据往往以高速率产生、流动和累积。这要求数据处理系统能够实时或近实时地处理数据，以便从中获取有价值的信息。
分布式计算 随着计算机技术的发展和数据规模的增大，单台计算机的处理能力和存储容量逐渐变得有限，无法满足大数据处理的要求。为了应对这一挑战，分布式计算应运而生，它利用多台计算机组成集群，将计算任务分割成多个子任务并在不同的计算节点上并行执行，从而提高计算效率和处理能力。
分布式计算的核心思想是将大问题划分为小问题，将任务分发给多个计算节点并行执行，最后将结果合并得到最终的解。这种方式有效地解决了单台计算机无法处理大规模数据和高并发计算的问题。同时，分布式计算还具有良好的可扩展性，可以根据数据量的增加灵活地扩展集群规模，以应对不断增长的数据挑战。
分布式计算的概念听起来很高深，其背后的思想却十分朴素，即分而治之，又称为分治法（Divide and Conquer）。分治法是一种解决问题的算法设计策略，它将一个问题分解成多个相同或相似的子问题，然后分别解决这些子问题，最后将子问题的解合并起来得到原问题的解。分治法常用于解决复杂问题，尤其是在大数据处理中，可以将大规模的数据集合分割成更小的部分，然后分别处理这些部分，最后合并结果。
在处理大数据问题时，可以使用分治法的思想来提高效率和可扩展性，以下是一些应用分治法处理大数据问题的示例：
MapReduce 模式：分治法的经典应用是 MapReduce 模式，它将大规模的数据集合分为多个小块，每个小块由不同的计算节点进行处理，然后将结果合并。这种方法适用于批处理任务，如数据清洗、转换、聚合等。
并行计算：将大规模的计算任务分解成多个小任务，分配给不同的计算节点并行处理，最后合并结果。这适用于需要大量计算的问题，如数值模拟、图算法等。
分布式排序：将大规模数据集合分割成多个部分，每个部分在不同的计算节点上进行排序，然后使用合并排序算法将这些有序部分合并为整体有序的数据集合。
分区和分片：在分布式存储系统中，可以将数据分区和分片存储在不同的节点上，通过分区键或哈希函数将数据分配到不同的存储节点上，从而实现数据的分布式存储和管理。
分布式机器学习：将大规模的机器学习任务分解成多个子任务，在分布式计算环境中分别进行训练，然后合并模型参数，如分布式随机梯度下降算法。
数据分割和合并：对于需要频繁访问的大数据集合，可以将数据分割成多个小块，每个小块存储在不同的存储节点上，然后根据需要进行合并，以减少数据访问的开销。
分治法在大数据处理中的应用不仅有助于提高处理效率，还可以充分利用分布式计算和存储资源，从而更好地应对大数据量和复杂性。然而，在应用分治法时需要考虑合适的数据分割策略、任务调度、结果合并等问题，以确保分治法的正确性和性能。
然而，分布式计算也带来了一些挑战，如数据一致性、通信开销、任务调度等问题，需要综合考虑各种因素来设计和优化分布式系统。同时，分布式计算也需要开发者具备分布式系统设计和调优的知识和技能，以确保系统的性能和稳定性。
分布式存储 当数据量巨大且单机存储已无法满足需求时，分布式存储和分布式文件系统成为处理大数据的关键技术。下面我会详细介绍分布式存储和分布式文件系统的概念、特点和常见的实现。
分布式存储： 分布式存储是将数据分散存储在多个节点上，以提供高容量、高性能、高可靠性和可扩展性的数据存储解决方案。每个节点都可以通过网络访问数据，并且多个节点协同工作来处理数据请求。分布式存储的核心目标是解决单机存储的瓶颈，同时提供高可靠性和可用性。
分布式存储的特点包括：
横向扩展性： 可以通过增加节点来扩展存储容量和性能，适应不断增长的数据量和负载。
高可靠性和容错性： 数据在多个节点上冗余存储，当某个节点出现故障时，数据依然可用，不会丢失。
数据分布和复制： 数据按照一定策略分布在不同节点上，数据的复制确保了数据的可用性和容错性。
并发访问和高性能： 支持多个客户端同时访问数据，实现高并发和更好的性能。
灵活的数据模型： 支持多种数据类型和访问方式，如文件系统、对象存储、键值存储等。
分布式文件系统： 分布式文件系统是一种特殊类型的分布式存储，主要用于存储和管理文件数据。它提供了类似于传统单机文件系统的接口，但是在底层实现上，数据被分散存储在多个节点上。分布式文件系统能够自动处理数据的分布、复制、一致性和故障恢复等问题。
常见的分布式文件系统特点包括：
命名空间和路径： 分布式文件系统通过路径来访问文件，类似于传统文件系统的目录结构。
数据分布和复制： 文件被切分成块并分散存储在多个节点上，同时进行数据复制以实现冗余和高可用性。
一致性和数据一致性模型： 分布式文件系统需要保证数据的一致性，不同节点上的数据副本需要保持同步。
访问控制和权限管理： 提供用户和应用程序访问控制和权限管理功能，确保数据安全性。
高性能： 分布式文件系统通常优化了数据的读写性能，以满足大数据场景的需求。">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2023-12-30T09:51:06+08:00">
    <meta property="article:modified_time" content="2023-12-30T09:51:06+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Flink 内容分享(一)：Fink原理、实战与性能优化(一)</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/e2/70/tKtQzFx0_o.jpg"></p> 
<p id="main-toc"><strong>目录</strong></p> 
<p id="%E5%89%8D%E8%A8%80-toc" style="margin-left:40px;"><a href="#%E5%89%8D%E8%A8%80" rel="nofollow">前言</a></p> 
<p id="1.%20%E4%BB%80%E4%B9%88%E6%98%AFFlink-toc" style="margin-left:40px;"><a href="#1.%20%E4%BB%80%E4%B9%88%E6%98%AFFlink" rel="nofollow">什么是Flink</a></p> 
<p id="2.%20Flink%20%E9%83%A8%E7%BD%B2-toc" style="margin-left:40px;"><a href="#2.%20Flink%20%E9%83%A8%E7%BD%B2" rel="nofollow">Flink 部署</a></p> 
<p id="3.%20Flink%E5%BF%AB%E9%80%9F%E5%BA%94%E7%94%A8-toc" style="margin-left:40px;"><a href="#3.%20Flink%E5%BF%AB%E9%80%9F%E5%BA%94%E7%94%A8" rel="nofollow">Flink快速应用</a></p> 
<p id="4.%20Flink%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E4%B8%8E%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6-toc" style="margin-left:40px;"><a href="#4.%20Flink%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E4%B8%8E%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6" rel="nofollow">Flink分布式架构与核心组件</a></p> 
<hr id="hr-toc"> 
<h3 id="%E5%89%8D%E8%A8%80" style="background-color:transparent;">前言</h3> 
<p>Flink是一个分布式流处理引擎，可以处理实时数据流和批处理数据。它支持多种数据源和数据目的地，并且提供了丰富的流处理操作，如窗口化、聚合、过滤、连接和转换等。Flink还支持多种语言编写的应用程序，如Java、Scala和Python等。</p> 
<p>Flink的核心特性包括：</p> 
<ol><li> <p>高吞吐量和低延迟：Flink采用了基于内存的流处理方式，可以实现毫秒级别的低延迟和高吞吐量处理。</p> </li><li> <p>精确一次性处理（Exactly-once processing）：Flink的流式处理引擎可以确保每条数据仅被处理一次，从而避免数据重复和丢失等问题。</p> </li><li> <p>支持多种数据源和数据目的地：Flink能够从多种数据源中读取数据，并将处理结果输出到多种数据目的地中，如Kafka、Hadoop、Cassandra、ElasticSearch等。</p> </li><li> <p>灵活的数据分析方式：Flink支持多种数据分析方式，包括流式处理、窗口化聚合、流式SQL查询和机器学习等。</p> </li></ol> 
<p>Flink的架构由JobManager和TaskManager两个组件组成。JobManager负责接收和调度应用程序，并协调TaskManager的执行。TaskManager负责执行具体的任务，如数据处理、窗口化、聚合等。</p> 
<p>Flink的优化包括优化数据倾斜、调整并行度、合并算子、使用状态后端、调整内存管理等。这些优化手段可以提高Flink的性能和稳定性，保证Flink的高吞吐量和低延迟处理。</p> 
<h3 id="1.%20%E4%BB%80%E4%B9%88%E6%98%AFFlink" style="background-color:transparent;"> 什么是Flink</h3> 
<h4 id="%E5%A4%A7%E6%95%B0%E6%8D%AE">大数据</h4> 
<p>大数据（Big Data）是指规模庞大、结构多样且速度快速增长的数据集合。这些数据集合通常包含传统数据库管理系统无法有效处理的数据，具有高度的复杂性和挑战性。大数据的主要特点包括三个维度：<strong>三V</strong>，即<strong>Volume</strong>（数据量大）、<strong>Variety</strong>（数据多样性）、<strong>Velocity</strong>（数据速度）。</p> 
<ol><li> <p><strong>数据量大（Volume）</strong>：大数据的最明显特征之一是其庞大的数据量。传统的数据处理方法和工具在处理这种规模的数据时可能会变得低效或不可行。</p> </li><li> <p><strong>数据多样性（Variety）</strong>：大数据不仅包括结构化数据（如表格数据），还包括半结构化数据（如JSON、XML）和非结构化数据（如文本、图像、音频、视频等）。这些数据可能来自不同的源头和不同的格式。</p> </li><li> <p><strong>数据速度快（Velocity）</strong>：大数据往往以高速率产生、流动和累积。这要求数据处理系统能够实时或近实时地处理数据，以便从中获取有价值的信息。</p> </li></ol> 
<h4 id="%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97">分布式计算</h4> 
<p>随着计算机技术的发展和数据规模的增大，单台计算机的处理能力和存储容量逐渐变得有限，无法满足大数据处理的要求。为了应对这一挑战，分布式计算应运而生，它利用多台计算机组成集群，将计算任务分割成多个子任务并在不同的计算节点上并行执行，从而提高计算效率和处理能力。</p> 
<p>分布式计算的核心思想是将大问题划分为小问题，将任务分发给多个计算节点并行执行，最后将结果合并得到最终的解。这种方式有效地解决了单台计算机无法处理大规模数据和高并发计算的问题。同时，分布式计算还具有良好的可扩展性，可以根据数据量的增加灵活地扩展集群规模，以应对不断增长的数据挑战。</p> 
<p>分布式计算的概念听起来很高深，其背后的思想却十分朴素，即分而治之，又称为分治法（Divide and Conquer）。分治法是一种解决问题的算法设计策略，它将一个问题分解成多个相同或相似的子问题，然后分别解决这些子问题，最后将子问题的解合并起来得到原问题的解。分治法常用于解决复杂问题，尤其是在大数据处理中，可以将大规模的数据集合分割成更小的部分，然后分别处理这些部分，最后合并结果。</p> 
<p>在处理大数据问题时，可以使用分治法的思想来提高效率和可扩展性，以下是一些应用分治法处理大数据问题的示例：</p> 
<ol><li> <p><strong>MapReduce 模式</strong>：分治法的经典应用是 MapReduce 模式，它将大规模的数据集合分为多个小块，每个小块由不同的计算节点进行处理，然后将结果合并。这种方法适用于批处理任务，如数据清洗、转换、聚合等。</p> </li><li> <p><strong>并行计算</strong>：将大规模的计算任务分解成多个小任务，分配给不同的计算节点并行处理，最后合并结果。这适用于需要大量计算的问题，如数值模拟、图算法等。</p> </li><li> <p><strong>分布式排序</strong>：将大规模数据集合分割成多个部分，每个部分在不同的计算节点上进行排序，然后使用合并排序算法将这些有序部分合并为整体有序的数据集合。</p> </li><li> <p><strong>分区和分片</strong>：在分布式存储系统中，可以将数据分区和分片存储在不同的节点上，通过分区键或哈希函数将数据分配到不同的存储节点上，从而实现数据的分布式存储和管理。</p> </li><li> <p><strong>分布式机器学习</strong>：将大规模的机器学习任务分解成多个子任务，在分布式计算环境中分别进行训练，然后合并模型参数，如分布式随机梯度下降算法。</p> </li><li> <p><strong>数据分割和合并</strong>：对于需要频繁访问的大数据集合，可以将数据分割成多个小块，每个小块存储在不同的存储节点上，然后根据需要进行合并，以减少数据访问的开销。</p> </li></ol> 
<p><img alt="" height="1138" src="https://images2.imgbox.com/33/95/KgHVaxsT_o.png" width="1200"></p> 
<p></p> 
<p>分治法在大数据处理中的应用不仅有助于提高处理效率，还可以充分利用分布式计算和存储资源，从而更好地应对大数据量和复杂性。然而，在应用分治法时需要考虑合适的数据分割策略、任务调度、结果合并等问题，以确保分治法的正确性和性能。</p> 
<p>然而，分布式计算也带来了一些挑战，如数据一致性、通信开销、任务调度等问题，需要综合考虑各种因素来设计和优化分布式系统。同时，分布式计算也需要开发者具备分布式系统设计和调优的知识和技能，以确保系统的性能和稳定性。</p> 
<h4 id="%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8">分布式存储</h4> 
<p>当数据量巨大且单机存储已无法满足需求时，分布式存储和分布式文件系统成为处理大数据的关键技术。下面我会详细介绍分布式存储和分布式文件系统的概念、特点和常见的实现。</p> 
<h5 id="%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8%EF%BC%9A">分布式存储：</h5> 
<p>分布式存储是将数据分散存储在多个节点上，以提供高容量、高性能、高可靠性和可扩展性的数据存储解决方案。每个节点都可以通过网络访问数据，并且多个节点协同工作来处理数据请求。分布式存储的核心目标是解决单机存储的瓶颈，同时提供高可靠性和可用性。</p> 
<p>分布式存储的特点包括：</p> 
<ul><li> <p><strong>横向扩展性：</strong> 可以通过增加节点来扩展存储容量和性能，适应不断增长的数据量和负载。</p> </li><li> <p><strong>高可靠性和容错性：</strong> 数据在多个节点上冗余存储，当某个节点出现故障时，数据依然可用，不会丢失。</p> </li><li> <p><strong>数据分布和复制：</strong> 数据按照一定策略分布在不同节点上，数据的复制确保了数据的可用性和容错性。</p> </li><li> <p><strong>并发访问和高性能：</strong> 支持多个客户端同时访问数据，实现高并发和更好的性能。</p> </li><li> <p><strong>灵活的数据模型：</strong> 支持多种数据类型和访问方式，如文件系统、对象存储、键值存储等。</p> </li></ul> 
<h5 id="%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%EF%BC%9A">分布式文件系统：</h5> 
<p>分布式文件系统是一种特殊类型的分布式存储，主要用于存储和管理文件数据。它提供了类似于传统单机文件系统的接口，但是在底层实现上，数据被分散存储在多个节点上。分布式文件系统能够自动处理数据的分布、复制、一致性和故障恢复等问题。</p> 
<p>常见的分布式文件系统特点包括：</p> 
<ul><li> <p><strong>命名空间和路径：</strong> 分布式文件系统通过路径来访问文件，类似于传统文件系统的目录结构。</p> </li><li> <p><strong>数据分布和复制：</strong> 文件被切分成块并分散存储在多个节点上，同时进行数据复制以实现冗余和高可用性。</p> </li><li> <p><strong>一致性和数据一致性模型：</strong> 分布式文件系统需要保证数据的一致性，不同节点上的数据副本需要保持同步。</p> </li><li> <p><strong>访问控制和权限管理：</strong> 提供用户和应用程序访问控制和权限管理功能，确保数据安全性。</p> </li><li> <p><strong>高性能：</strong> 分布式文件系统通常优化了数据的读写性能，以满足大数据场景的需求。</p> </li><li> <p><strong>扩展性：</strong> 可以通过增加节点来扩展存储容量和性能。</p> </li></ul> 
<p>常见的分布式文件系统包括：</p> 
<ul><li> <p><strong>Hadoop HDFS（Hadoop Distributed File System）：</strong> Hadoop生态系统中的分布式文件系统，适用于大数据存储。</p> </li><li> <p><strong>Ceph：</strong> 开源的分布式存储系统，提供块存储、文件系统和对象存储。</p> </li><li> <p><strong>GlusterFS：</strong> 开源的分布式文件系统，可以线性扩展存储容量和性能。</p> </li></ul> 
<p>总之，分布式存储和分布式文件系统在大数据时代扮演着重要角色，帮助我们存储、管理和访问海量的数据，解决了传统单机存储无法应对的挑战。</p> 
<h4 id="%E6%89%B9%E5%A4%84%E7%90%86%E5%92%8C%E6%B5%81%E5%A4%84%E7%90%86">批处理和流处理</h4> 
<p>批处理和流处理是大数据处理领域中常见的两种数据处理模式，用于不同类型的数据处理需求。下面将详细介绍这两种模式，并给出相关的应用场景示例。</p> 
<h5 id="%E6%89%B9%E5%A4%84%E7%90%86%EF%BC%88Batch%20Processing%EF%BC%89%EF%BC%9A">批处理（Batch Processing）：</h5> 
<p>批处理是指将一批数据集合在一起，在一个固定的时间间隔内对这批数据进行处理和分析。批处理通常适用于数据量较大、处理周期较长、要求高一致性的场景。</p> 
<p>特点：</p> 
<ul><li> <p>数据被集中处理，适合周期性分析和报告生成。</p> </li><li> <p>数据被切分成小块，每个小块在一个作业中被处理。</p> </li><li> <p>数据处理时间较长，不适合实时性要求高的场景。</p> </li></ul> 
<p>应用场景示例：</p> 
<ol><li> <p><strong>离线数据分析：</strong> 对历史数据进行分析，从中发现趋势、模式和规律，用于业务决策。例如，销售数据分析、用户行为分析。</p> </li><li> <p><strong>批量推荐系统：</strong> 基于用户历史行为数据，定期生成推荐结果。例如，电影推荐、商品推荐。</p> </li><li> <p><strong>数据清洗和预处理：</strong> 对大规模数据进行清洗、过滤和预处理，提高数据质量和可用性。例如，清理无效数据、填充缺失值。</p> </li><li> <p><strong>大规模ETL（Extract, Transform, Load）：</strong> 将数据从源系统中抽取出来，经过转换和加工后加载到目标系统。例如，数据仓库的构建。</p> </li></ol> 
<h5 id="%E6%B5%81%E5%A4%84%E7%90%86%EF%BC%88Stream%20Processing%EF%BC%89%EF%BC%9A">流处理（Stream Processing）：</h5> 
<p>流处理是指在数据生成的时候立即进行处理，实现数据的实时处理和分析。流处理通常适用于数据实时性要求高、需要快速响应的场景。</p> 
<p>特点：</p> 
<ul><li> <p>数据是实时流动的，需要快速处理和响应。</p> </li><li> <p>数据是持续不断地到达，需要实时计算和分析。</p> </li><li> <p>可能会遇到延迟和数据乱序等问题。</p> </li></ul> 
<p>应用场景示例：</p> 
<ol><li> <p><strong>实时监控和告警：</strong> 对实时数据进行监控和分析，及时发现异常并触发告警。例如，网络流量监控、系统性能监控。</p> </li><li> <p><strong>实时数据分析：</strong> 对流式数据进行实时分析，从中提取有价值的信息。例如，实时点击流分析、实时市场行情分析。</p> </li><li> <p><strong>实时推荐系统：</strong> 基于用户实时行为数据，实时生成推荐结果。例如，新闻推荐、广告推荐。</p> </li><li> <p><strong>实时数据仓库：</strong> 构建实时数据仓库，将实时数据集成、加工和分析。例如，实时销售数据分析、实时用户行为分析。</p> </li></ol> 
<p>总之，批处理和流处理分别适用于不同类型的数据处理需求，根据业务需求和实时性要求选择合适的处理模式。</p> 
<h4 id="%E5%BC%80%E6%BA%90%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF">开源大数据技术</h4> 
<p><img alt="" height="756" src="https://images2.imgbox.com/b1/96/z1zpeWMU_o.png" width="1200"></p> 
<p></p> 
<p>当谈论大数据处理时，Hadoop、YARN、Spark和Flink都是重要的技术。它们都属于大数据领域的分布式计算框架，但在功能和使用方式上有所不同。</p> 
<h5 id="Hadoop%EF%BC%9A">Hadoop：</h5> 
<p>Hadoop是一个开源的分布式存储和计算框架，最初由Apache开发，用于处理大规模数据集。Hadoop的核心组件包括：</p> 
<ol><li> <p><strong>Hadoop Distributed File System（HDFS）：</strong> HDFS是一种分布式文件系统，用于存储大规模数据。它将数据分成多个块，并将这些块分散存储在集群中的不同节点上。HDFS支持高可靠性、冗余存储和数据复制。</p> </li><li> <p><strong>MapReduce：</strong> MapReduce是Hadoop的计算模型，用于处理分布式数据。它将计算任务分成Map和Reduce两个阶段，分布在集群中的节点上并行执行。Map阶段负责数据的拆分和处理，Reduce阶段负责数据的汇总和计算。</p> </li></ol> 
<h5 id="YARN%20(Yet%20Another%20Resource%20Negotiator)">YARN (Yet Another Resource Negotiator)</h5> 
<p>YARN是Hadoop的资源管理器，它负责集群资源的管理和分配。YARN将集群资源划分为容器（Containers），并分配给不同的应用程序。这种资源的隔离和管理允许多个应用程序同时在同一个Hadoop集群上运行，从而提高了资源利用率和集群的多租户能力。</p> 
<h5 id="Spark%EF%BC%9A">Spark：</h5> 
<p>Apache Spark是一个通用的分布式计算引擎，旨在提供高性能、易用性和多功能性。与传统的Hadoop MapReduce相比，Spark具有更快的执行速度，因为它将数据加载到内存中并进行内存计算。Spark支持多种计算模式，包括批处理、交互式查询、流处理和机器学习。</p> 
<p>Spark的主要特点和组件包括：</p> 
<ol><li> <p><strong>RDD（Resilient Distributed Dataset）：</strong> RDD是Spark的核心数据抽象，表示分布式的数据集。RDD支持并行操作和容错性，可以在计算过程中重新计算丢失的分区。</p> </li><li> <p><strong>Spark SQL：</strong> Spark SQL是用于处理结构化数据的组件，支持SQL查询和操作。它能够将RDD和传统的数据源（如Hive）无缝集成。</p> </li><li> <p><strong>Spark Streaming：</strong> Spark Streaming是用于处理实时流数据的模块，支持微批处理模式。它能够将实时数据流分割成小批次并进行处理。</p> </li><li> <p><strong>MLlib：</strong> MLlib是Spark的机器学习库，提供了常见的机器学习算法和工具，用于训练和评估模型。</p> </li><li> <p><strong>GraphX：</strong> GraphX是Spark的图计算库，用于处理图数据和图算法。</p> </li></ol> 
<h5 id="Flink%EF%BC%9A">Flink：</h5> 
<p>Apache Flink是一个流式处理引擎和分布式批处理框架，具有低延迟、高吞吐量和容错性。Flink支持流批一体化，能够实现实时流处理和批处理作业的无缝切换。它的核心特点包括：</p> 
<ol><li> <p><strong>DataStream API：</strong> Flink的DataStream API用于处理实时流数据，支持事件时间处理、窗口操作和状态管理。它能够处理高吞吐量的实时数据流。</p> </li><li> <p><strong>DataSet API：</strong> Flink的DataSet API用于批处理作业，类似于Hadoop的MapReduce。它支持丰富的操作符和优化技术。</p> </li><li> <p><strong>Stateful Stream Processing：</strong> Flink支持有状态的流式处理，可以在处理过程中保存和管理状态。这对于实现复杂的数据处理逻辑很有用。</p> </li><li> <p><strong>Event Time Processing：</strong> Flink支持事件时间处理，能够处理乱序事件并准确计算窗口操作的结果。</p> </li><li> <p><strong>Table API和SQL：</strong> Flink提供了Table API和SQL查询，使开发人员可以使用类似SQL的语法来查询和分析数据。</p> </li><li> <p>可以连接大数据生态圈各类组件，包括Kafka、Elasticsearch、JDBC、HDFS和Amazon S3</p> </li><li> <p>可以运行在Kubernetes、YARN、Mesos和独立（Standalone）集群上。</p> </li></ol> 
<p>Flink在流处理上的几个主要优势如下:</p> 
<ol><li> <p>真正的流计算引擎:Flink具有更好的streaming计算模型,可以进行非常高效的状态运算和窗口操作。Spark Streaming仍然是微批处理引擎。</p> </li><li> <p>更低延迟:Flink可以实现毫秒级的低延迟处理,而Spark Streaming延迟较高。</p> </li><li> <p>更好的容错机制:Flink支持更细粒度的状态管理和检查点机制,可以实现精确一次的状态一致性语义。Spark较难做到确保exactly once。</p> </li><li> <p>支持有限数据流和无限数据流:Flink可处理有开始和结束的有限数据流,也能处理无限不断增长的数据流。Spark Streaming更适合有限数据集。</p> </li><li> <p>更易统一批处理和流处理:Flink提供了DataStream和DataSet API,可以轻松统一批处理和流处理。Spark需要联合Spark SQL使用。</p> </li><li> <p>更优秀的内存管理:Flink具有自己的内存管理,可以根据不同查询优化内存使用。Spark依赖Hadoop YARN进行资源调度。</p> </li><li> <p>更高性能:在部分场景下,Flink拥有比Spark Streaming更高的吞吐和低的延迟。</p> </li></ol> 
<p>总体来说,Flink作为新一代流处理引擎,在延迟、容错、易用性方面优于Spark Streaming。但Spark生态更加完善,也在努力减小与Flink的差距。需要根据具体场景选择最优的框架。</p> 
<p>总的来说，Flink在流处理领域的优势主要体现在事件时间处理、低延迟、精确一次语义和状态管理等方面。这些特性使得Flink在处理实时流数据时能够更好地满足复杂的业务需求，特别是对于需要高准确性和可靠性的应用场景。</p> 
<h3 id="2.%20Flink%20%E9%83%A8%E7%BD%B2" style="background-color:transparent;">Flink 部署</h3> 
<p>Apache Flink在1.7版本中进行了重大的架构重构，引入了Master-Worker架构，这使得Flink能够更好地适应不同的集群基础设施，包括Standalone、Hadoop YARN和Kubernetes等。下面会详细介绍一下Flink 1.7版本引入的Master-Worker架构以及其在不同集群基础设施中的适应性。</p> 
<h4 id="Master-Worker%E6%9E%B6%E6%9E%84%EF%BC%9A">Master-Worker架构：</h4> 
<p>Flink 1.7版本中引入的Master-Worker架构是为了解决之前版本中存在的一些问题，如资源管理、高可用性等。在这个架构中，Flink将任务管理和资源管理分离，引入了JobManager和ResourceManager两个主要角色。</p> 
<ul><li> <p><strong>JobManager：</strong> 负责接受和调度任务，维护任务的状态和元数据信息，还负责处理容错机制。JobManager分为两种：JobManager（高可用模式）和StandaloneJobManager（非高可用模式）。</p> </li><li> <p><strong>ResourceManager：</strong> 负责管理集群中的资源，包括分配任务的资源、维护资源池等。</p> </li></ul> 
<p>这种架构的优势在于解耦任务的管理和资源的管理，使得Flink能够更好地适应不同的集群环境和基础设施。</p> 
<h5 id="%E5%85%BC%E5%AE%B9%E6%80%A7%EF%BC%9A">兼容性：</h5> 
<p>Flink的Master-Worker架构设计使其能够兼容几乎所有主流信息系统的基础设施，包括：</p> 
<ul><li> <p><strong>Standalone集群：</strong> 在Standalone模式下，Flink的JobManager和ResourceManager都运行在同一个进程中，适用于简单的开发和测试场景。</p> </li><li> <p><strong>Hadoop YARN集群：</strong> Flink可以部署在现有的Hadoop YARN集群上，通过ResourceManager与YARN ResourceManager进行交互，实现资源管理。</p> </li><li> <p><strong>Kubernetes集群：</strong> Flink还支持在Kubernetes集群中部署，通过Kubernetes提供的资源管理能力来管理任务和资源。</p> </li></ul> 
<p>这种兼容性使得Flink可以灵活地在不同的集群环境中运行，满足不同场景下的需求。</p> 
<p>总之，Flink在1.7版本中引入的Master-Worker架构使其在资源管理、高可用性等方面有了更好的表现，同时也使得Flink能够更好地适应各种不同的集群基础设施，包括Standalone、Hadoop YARN和Kubernetes等。这为Flink的部署和使用带来了更多的灵活性和选择性。</p> 
<p>Standalone集群是Apache Flink中一种简单的部署模式，适用于开发、测试和小规模应用场景。下面我将详细介绍Standalone集群的特点以及部署方式。</p> 
<h4 id="Standalone%E9%9B%86%E7%BE%A4%E7%9A%84%E7%89%B9%E7%82%B9%EF%BC%9A">Standalone集群的特点：</h4> 
<p><img alt="" height="970" src="https://images2.imgbox.com/a1/f4/4zUQvXPg_o.png" width="1200"></p> 
<p></p> 
<ol><li> <p><strong>简单部署：</strong> Standalone集群是Flink的最简单部署模式之一，不需要依赖其他集群管理工具，可以在单个机器上部署。</p> </li><li> <p><strong>资源共享：</strong> Standalone集群中的JobManager和TaskManager共享同一份资源，例如内存和CPU。这使得资源管理相对简单，但也可能在资源竞争时影响任务的性能。</p> </li><li> <p><strong>适用于开发和测试：</strong> Standalone集群适用于开发和测试阶段，可以在本地机器上模拟Flink集群环境，方便开发人员进行调试和测试。</p> </li><li> <p><strong>不支持高可用性：</strong> Standalone集群默认情况下不支持高可用性，即不具备故障恢复和任务迁移的能力。如果需要高可用性，可以通过运行多个JobManager实例来实现。</p> </li></ol> 
<h4 id="Standalone%E9%9B%86%E7%BE%A4%E7%9A%84%E9%83%A8%E7%BD%B2%E6%96%B9%E5%BC%8F%EF%BC%9A">Standalone集群的部署方式：</h4> 
<ol><li> <p><strong>安装Flink：</strong> 首先，需要下载并安装Flink。可以从官方网站下载预编译的二进制文件，解压到指定目录。也可以从以下网站下载：</p> <p>apache-flink安装包下载_开源镜像站-阿里云 (aliyun.com)(<code>https://mirrors.aliyun.com/apache/flink/</code>)</p> </li></ol> 
<p></p> 
<p class="img-center"><img alt="图片" height="493" src="https://images2.imgbox.com/8f/e3/I5ard156_o.jpg" width="960"></p> 
<ol><li> <p><strong>配置Flink：</strong> 进入Flink的安装目录，修改<code>conf/flink-conf.yaml</code>配置文件。主要配置项包括<code>jobmanager.rpc.address</code>和<code>taskmanager.numberOfTaskSlots</code>等。</p> </li><li> <p><strong>启动JobManager：</strong> 打开终端，进入Flink安装目录，执行以下命令启动JobManager：</p> </li></ol> 
<pre><code>./bin/start-cluster.sh
</code></pre> 
<ol><li> <p><strong>启动TaskManager：</strong> 打开终端，进入Flink安装目录，执行以下命令启动TaskManager：</p> </li></ol> 
<pre><code>./bin/taskmanager.sh start
</code></pre> 
<ol><li> <p><strong>提交作业：</strong> 使用Flink客户端工具提交作业。可以使用以下命令提交JAR文件中的作业：</p> </li></ol> 
<pre><code>./bin/flink run -c your.main.Class ./path/to/your.jar
</code></pre> 
<ol><li> <p><strong>停止集群：</strong> 可以使用以下命令停止整个Standalone集群：</p> </li></ol> 
<pre><code>./bin/stop-cluster.sh
</code></pre> 
<p>总之，Standalone集群是一个简单且易于部署的Flink集群模式，适用于开发、测试和小规模应用场景。然而，由于其资源共享和不支持高可用性的特点，不适合部署在生产环境中。</p> 
<p>下面提供利用Docker部署flink standalone简单集群。</p> 
<h4 id="Docker%E9%83%A8%E7%BD%B2flink%E7%AE%80%E5%8D%95%E9%9B%86%E7%BE%A4">Docker部署flink简单集群</h4> 
<p>Flink程序可以作为集群内的分布式系统运行，也可以以独立模式或在YARN、Mesos、基于Docker的环境和其他资源管理框架下进行部署。</p> 
<h5 id="1%E3%80%81%E5%9C%A8%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%88%9B%E5%BB%BAflink%E7%9B%AE%E5%BD%95">1、在服务器创建flink目录</h5> 
<pre><code>mkdir flink
</code></pre> 
<p>目录的结构如下：</p> 
<p><img alt="" height="682" src="https://images2.imgbox.com/51/24/YQa5bhcJ_o.png" width="1200"></p> 
<p></p> 
<h5 id="2%E3%80%81docker-compose.yml%E8%84%9A%E6%9C%AC%E5%88%9B%E5%BB%BA">2、docker-compose.yml脚本创建</h5> 
<p>docker 容器的编排文件，具体如下</p> 
<p><img alt="" height="1194" src="https://images2.imgbox.com/84/bc/66U5tVSN_o.png" width="1200"></p> 
<p></p> 
<h5 id="3%E3%80%81%E5%90%AF%E5%8A%A8flink">3、启动flink</h5> 
<p>（1）后台运行</p> 
<p>一般推荐生产环境下使用该选项。</p> 
<pre><code>docker-compose up -d
</code></pre> 
<p>（2）前台运行</p> 
<p>控制台将会同时打印所有容器的输出信息，可以很方便进行调试。</p> 
<pre><code>docker-compose up
</code></pre> 
<p></p> 
<h5 id="4%E3%80%81%E6%B5%8F%E8%A7%88%E5%99%A8%E4%B8%8A%E6%9F%A5%E7%9C%8B%E9%A1%B5%E9%9D%A2dashboard">4、浏览器上查看页面dashboard</h5> 
<p>访问web界面</p> 
<pre><code>http://cdh1:8081/
</code></pre> 
<p></p> 
<h3 id="%E2%80%8B%E7%BC%96%E8%BE%91"><img alt="" height="644" src="https://images2.imgbox.com/38/69/qfwCw1ZH_o.png" width="1200"></h3> 
<h3 id="3.%20Flink%E5%BF%AB%E9%80%9F%E5%BA%94%E7%94%A8" style="background-color:transparent;">Flink快速应用</h3> 
<p>通过一个单词统计的案例，快速上手应用Flink，进行流处理（Streaming）和批处理（Batch）</p> 
<h4 id="%E5%AE%9E%E6%93%8D1%EF%BC%9A%E5%8D%95%E8%AF%8D%E7%BB%9F%E8%AE%A1%E6%A1%88%E4%BE%8B%EF%BC%88%E6%89%B9%E6%95%B0%E6%8D%AE%EF%BC%89">实操1：单词统计案例（批数据）</h4> 
<h5 id="1.1%20%E9%9C%80%E6%B1%82">1.1 需求</h5> 
<p>统计一个文件中各个单词出现的次数，把统计结果输出到文件</p> 
<p>步骤：1、读取数据源 2、处理数据源</p> 
<p>a、将读到的数据源文件中的每一行根据空格切分</p> 
<p>b、将切分好的每个单词拼接1</p> 
<p>c、根据单词聚合（将相同的单词放在一起）</p> 
<p>d、累加相同的单词（单词后面的1进行累加）</p> 
<p>3、保存处理结果</p> 
<h5 id="1.2%20%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0">1.2 代码实现</h5> 
<ul><li> <p>引入依赖</p> </li></ul> 
<pre><code class="language-bash">&lt;!--flink核心包--&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
    &lt;artifactId&gt;flink-java&lt;/artifactId&gt;
    &lt;version&gt;1.7.2&lt;/version&gt;
&lt;/dependency&gt;
&lt;!--flink流处理包--&gt;
&lt;dependency&gt;
    &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;
    &lt;artifactId&gt;flink-streaming-java_2.12&lt;/artifactId&gt;
    &lt;version&gt;1.7.2&lt;/version&gt;
    &lt;scope&gt;provided&lt;/scope&gt;
&lt;/dependency&gt; 
</code></pre> 
<ul><li> <p>Java程序</p> </li></ul> 
<pre><code class="language-java">package com.crazymaker.bigdata.wordcount.batch;

import org.apache.flink.api.common.functions.FlatMapFunction;
import org.apache.flink.api.java.DataSet;
import org.apache.flink.api.java.ExecutionEnvironment;
import org.apache.flink.api.java.operators.AggregateOperator;
import org.apache.flink.api.java.operators.FlatMapOperator;
import org.apache.flink.api.java.operators.UnsortedGrouping;
import org.apache.flink.api.java.tuple.Tuple2;
import org.apache.flink.util.Collector;

/**
   * 1、读取数据源
   * 2、处理数据源
   *  a、将读到的数据源文件中的每一行根据空格切分
   *  b、将切分好的每个单词拼接1
   *  c、根据单词聚合（将相同的单词放在一起）
   *  d、累加相同的单词（单词后面的1进行累加）
   * 3、保存处理结果
   */
public class WordCountJavaBatch {
    public static void main(String[] args) throws Exception {
        String inputPath="D:\\data\\input\\hello.txt";
        String outputPath="D:\\data\\output\\hello.txt";

        //获取flink的运行环境
        ExecutionEnvironment executionEnvironment = ExecutionEnvironment.getExecutionEnvironment();
        DataSet&lt;String&gt; text = executionEnvironment.readTextFile(inputPath);
        FlatMapOperator&lt;String, Tuple2&lt;String, Integer&gt;&gt; wordOndOnes = text.flatMap(new SplitClz());

        //0代表第1个元素
        UnsortedGrouping&lt;Tuple2&lt;String, Integer&gt;&gt; groupedWordAndOne = wordOndOnes.groupBy(0);
        //1代表第1个元素
        AggregateOperator&lt;Tuple2&lt;String, Integer&gt;&gt; out = groupedWordAndOne.sum(1);

        out.writeAsCsv(outputPath, "\n", " ").setParallelism(1);//设置并行度
        executionEnvironment.execute();//人为调用执行方法

    }

    static class SplitClz implements FlatMapFunction&lt;String,Tuple2&lt;String,Integer&gt;&gt;{

        public void flatMap(String s, Collector&lt;Tuple2&lt;String, Integer&gt;&gt; collector) throws Exception {
            String[] s1 = s.split(" ");
            for (String word:s1) {
                collector.collect(new Tuple2&lt;String,Integer&gt;(word,1));//发送到下游

            }

        }
    }
}
</code></pre> 
<p>源文件的内容</p> 
<p><img alt="" height="648" src="https://images2.imgbox.com/3b/c2/jvhoi7qd_o.png" width="1200"></p> 
<p></p> 
<p>统计的结果</p> 
<p></p> 
<p class="img-center"><img alt="图片" height="315" src="https://images2.imgbox.com/62/3b/qO1sLo93_o.png" width="621"></p> 
<h4 id="%E5%AE%9E%E6%93%8D2%EF%BC%9A%E5%8D%95%E8%AF%8D%E7%BB%9F%E8%AE%A1%E6%A1%88%E4%BE%8B%EF%BC%88%E6%B5%81%E6%95%B0%E6%8D%AE%EF%BC%89">实操2：单词统计案例（流数据）</h4> 
<p>nc</p> 
<p>netcat:</p> 
<p>flink开发时候，经常用socket作为source；使用linux/mac环境开发，可以在终端中开启 nc -l 9000(开启netcat程序，作为服务端，发送数据)；</p> 
<p>nc是netcat的缩写，有着网络界的瑞士军刀美誉。因为它短小精悍、功能实用，被设计为一个简单、可靠的网络工具。</p> 
<p>nc作用</p> 
<ul><li> <p>数据传输</p> </li><li> <p>文件传输</p> </li><li> <p>机器之间网络测速</p> </li></ul> 
<p></p> 
<h5 id="2.1%20%E9%9C%80%E6%B1%82">2.1 需求</h5> 
<p>Socket模拟实时发送单词，</p> 
<p>使用Flink实时接收数据，对指定时间窗口内（如5s）的数据进行聚合统计，每隔1s汇总计算一次，并且把时间窗口内计算结果打印出来。</p> 
<h5 id="2.2%20%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0">2.2 代码实现</h5> 
<pre><code class="language-java">package com.crazymaker.bigdata.wordcount.stream;

import org.apache.flink.api.common.functions.FlatMapFunction;
import org.apache.flink.api.java.tuple.Tuple2;
import org.apache.flink.streaming.api.datastream.DataStreamSource;
import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.streaming.api.windowing.time.Time;
import org.apache.flink.util.Collector;

/**
 *  Socket模拟实时发送单词，使用Flink实时接收数据
 */
public class WordCountStream {

    public static void main(String[] args) throws Exception {
        // 监听的ip和端口号，以main参数形式传入，约定第一个参数为ip，第二个参数为端口
//        String ip = args[0];
        String ip = "127.0.0.1";
//        int port = Integer.parseInt(args[1]);
        int port = 9000;
        // 获取Flink流执行环境
        StreamExecutionEnvironment streamExecutionEnvironment = StreamExecutionEnvironment.getExecutionEnvironment();
        // 获取socket输入数据
        DataStreamSource&lt;String&gt; textStream = streamExecutionEnvironment.socketTextStream(ip, port, "\n");

        SingleOutputStreamOperator&lt;Tuple2&lt;String, Long&gt;&gt; tuple2SingleOutputStreamOperator = textStream.flatMap(new FlatMapFunction&lt;String, Tuple2&lt;String, Long&gt;&gt;() {
            public void flatMap(String s, Collector&lt;Tuple2&lt;String, Long&gt;&gt; collector) throws Exception {
                String[] splits = s.split("\\s");
                for (String word : splits) {
                    collector.collect(Tuple2.of(word, 1l));
                }
            }
        });

        SingleOutputStreamOperator&lt;Tuple2&lt;String, Long&gt;&gt; word = tuple2SingleOutputStreamOperator.keyBy(0)
                .sum(1);
        // 打印数据
        word.print();
        // 触发任务执行
        streamExecutionEnvironment.execute("wordcount stream process");

    }
}
</code></pre> 
<p></p> 
<h4 id="Flink%E7%A8%8B%E5%BA%8F%E5%BC%80%E5%8F%91%E7%9A%84%E6%B5%81%E7%A8%8B%E6%80%BB%E7%BB%93">Flink程序开发的流程总结</h4> 
<p>Flink程序开发的流程总结如下：</p> 
<p>1）获得一个执行环境</p> 
<p>2）加载/创建初始化数据</p> 
<p>3）指定数据操作的算子</p> 
<p>4）指定结果数据存放位置</p> 
<p>5）调用execute()触发执行程序</p> 
<p><strong>注意：Flink程序是延迟计算的，只有最后调用execute()方法的时候才会真正触发执行程序</strong></p> 
<h3 id="4.%20Flink%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84%E4%B8%8E%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6" style="background-color:transparent;">Flink分布式架构与核心组件</h3> 
<h4 id="Flink%E4%BD%9C%E4%B8%9A%E6%8F%90%E4%BA%A4%E8%BF%87%E7%A8%8B">Flink作业提交过程</h4> 
<p>standalone模式下的作业提交过程如下：</p> 
<p><img alt="" height="720" src="https://images2.imgbox.com/ab/f3/muLfmvuy_o.png" width="1200"></p> 
<p></p> 
<p>在一个作业提交前，Master和TaskManager等进程需要先被启动。</p> 
<p>我们可以在Flink主目录中执行脚本来启动这些进程：</p> 
<p>bin/start-cluster.sh。</p> 
<p>Master和TaskManager被启动后，TaskManager需要将自己注册给Master中的ResourceManager。</p> 
<p>这个初始化和资源注册过程发生在单个作业提交前，我们称之为第0步。</p> 
<p>接下来，我们将逐步解析Flink作业的提交过程，具体步骤如下：</p> 
<p>① 用户编写应用程序代码，并使用Flink客户端（Client）提交该作业。通常，这些程序会使用Java或Scala语言编写，并调用Flink API 构建出逻辑视图。这些代码以及相关配置文件被编译并打包，然后被提交至Master节点的Dispatcher，形成一个应用作业（Application）。</p> 
<p>② Dispatcher接收到提交的作业后，会启动一个JobManager，该JobManager负责协调这个作业的各项任务。</p> 
<p>③ JobManager向ResourceManager申请所需的作业资源，这些资源可能包括CPU、内存等。</p> 
<p>④ 由于在前面的步骤中，TaskManager已经向ResourceManager注册了可供使用的资源，这时处于空闲状态的TaskManager将被分配给JobManager。</p> 
<p>⑤ JobManager将用户作业中的逻辑视图转化为物理执行图，如图3-3所示，该图显示了作业被并行化后的执行过程。JobManager将计算任务分配并部署到多个TaskManager上。此时，一个Flink作业正式开始执行。</p> 
<p>在计算任务执行过程中，TaskManager可能会与其他TaskManager交换数据，使用特定的数据交换策略。同时，TaskManager还会将任务的状态信息传递给JobManager，这些状态信息包括任务的启动、执行和终止状态，以及快照的元数据等。</p> 
<h4 id="Flink%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6">Flink核心组件</h4> 
<p>在这个作业提交流程的基础上，我们可以更详细地介绍涉及的各个组件的功能和角色：</p> 
<ol><li> <p><strong>Client（客户端）：</strong> 用户通常使用Flink提供的客户端工具（如位于Flink主目录下的bin目录中的命令行工具）来提交作业。客户端会对用户提交的Flink作业进行预处理，并将作业提交到Flink集群中。在提交作业时，客户端需要配置一些必要的参数，例如使用Standalone集群还是YARN集群等。整个作业会被打包成一个JAR文件，DataStream API会被转换成一个JobGraph，该图类似于逻辑视图（如图3-2所示）。</p> </li><li> <p><strong>Dispatcher（调度器）：</strong> Dispatcher可以接收多个作业，每次接收作业时，会为该作业分配一个JobManager。Dispatcher通过提供表述性状态转移（REST）式的接口，使用超文本传输协议（HTTP）来对外提供服务。</p> </li><li> <p><strong>JobManager（作业管理器）：</strong> JobManager是单个Flink作业的协调者。每个作业都有一个对应的JobManager负责管理。JobManager将客户端提交的JobGraph转化为ExecutionGraph，该图类似于并行物理执行图（如图3-3所示）。JobManager会向ResourceManager申请所需的资源。一旦获取足够的资源，JobManager会将ExecutionGraph及其计算任务分发到多个TaskManager上。此外，JobManager还管理多个TaskManager，包括收集作业状态信息、生成检查点、必要时进行故障恢复等。</p> </li><li> <p><strong>ResourceManager（资源管理器）：</strong> Flink可以在Standalone、YARN、Kubernetes等环境中部署，而不同环境对计算资源的管理模式有所不同。为了解决资源分配问题，Flink引入了ResourceManager模块。在Flink中，计算资源的基本单位是TaskManager上的任务槽位（Slot）。ResourceManager的主要职责是从资源提供方（如YARN）获取计算资源。当JobManager需要计算资源时，ResourceManager会将空闲的Slot分配给JobManager。在计算任务结束后，ResourceManager会回收这些空闲Slot。</p> </li><li> <p><strong>TaskManager（任务管理器）：</strong> TaskManager是实际执行计算任务的节点。一般来说，一个Flink作业会分布在多个TaskManager上执行，每个TaskManager提供一定数量的Slot。当一个TaskManager启动后，相关的Slot信息会被注册到ResourceManager中。当Flink作业提交后，ResourceManager会将空闲的Slot分配给JobManager。一旦JobManager获取了空闲Slot，它会将具体的计算任务部署到这些Slot上，并在这些Slot上执行。在执行过程中，TaskManager可能需要与其他TaskManager进行数据交换，因此需要进行必要的数据通信。总之，TaskManager负责具体计算任务的执行，它会在启动时将Slot资源向ResourceManager注册。</p> </li></ol> 
<h4 id="Flink%E7%BB%84%E4%BB%B6%E6%A0%88">Flink组件栈</h4> 
<p><img alt="" height="914" src="https://images2.imgbox.com/7d/f4/8en0B5vd_o.png" width="1200"></p> 
<p></p> 
<h5 id="1.%C2%A0%E9%83%A8%E7%BD%B2%E5%B1%82%EF%BC%9A">1. <strong>部署层：</strong></h5> 
<ul><li> <p><strong>Local模式：</strong> Flink支持本地模式，包括单节点（SingleNode）和单虚拟机（SingleJVM）模式。在SingleNode模式中，JobManager和TaskManager运行在同一个节点上；在SingleJVM模式中，所有角色都在同一个JVM中运行。</p> </li><li> <p><strong>Cluster模式：</strong> Flink可以部署在Standalone、YARN、Mesos和Kubernetes集群上。Standalone集群需要配置JobManager和TaskManager的节点，然后通过Flink提供的脚本启动。YARN、Mesos和Kubernetes集群提供了更强大的资源管理和集群扩展能力。</p> </li><li> <p><strong>Cloud模式：</strong> Flink还可以部署在各大云平台上，如AWS、谷歌云和阿里云，使用户能够在云环境中灵活地部署和运行作业。</p> </li></ul> 
<h5 id="2.%C2%A0%E8%BF%90%E8%A1%8C%E6%97%B6%E5%B1%82%EF%BC%9A">2. <strong>运行时层：</strong></h5> 
<ul><li> <p>运行时层是Flink的核心组件，支持分布式执行和处理。该层负责将用户提交的作业转化为任务，并分发到相应的JobManager和TaskManager上执行。运行时层还涵盖了检查点和故障恢复机制，确保作业的容错性和稳定性。</p> </li></ul> 
<h5 id="3.%C2%A0API%E5%B1%82%EF%BC%9A">3. <strong>API层：</strong></h5> 
<ul><li> <p>Flink的API层提供了DataStream API和DataSet API，分别用于流式处理和批处理。这两个API允许开发者使用各种操作符和转换来处理数据，包括转换、连接、聚合、窗口等计算任务。</p> </li></ul> 
<h5 id="4.%C2%A0%E4%B8%8A%E5%B1%82%E5%B7%A5%E5%85%B7%EF%BC%9A">4. <strong>上层工具：</strong></h5> 
<ul><li> <p>在API层之上，Flink提供了一些工具来扩展其功能：</p> 
  <ul><li> <p><strong>复杂事件处理（CEP）：</strong> 面向流处理的库，用于检测和处理复杂的事件模式。</p> </li><li> <p><strong>图计算库（Gelly）：</strong> 面向批处理的图计算库，用于执行图算法。</p> </li><li> <p><strong>Table API和SQL：</strong> 针对SQL用户和关系型数据处理场景的接口，允许使用SQL语法和表操作处理流和批数据。</p> </li><li> <p><strong>PyFlink：</strong> 针对Python用户的接口，使其能够使用Flink进行数据处理，目前主要基于Table API。</p> </li></ul></li></ul> 
<p>综上所述，Flink在不同层次上提供了丰富的组件和工具，支持流式处理和批处理，以及与不同环境（本地、集群、云）的无缝集成，使开发者能够灵活地构建和部署大规模数据处理应用程序。</p> 
<h4 id="%E4%BD%9C%E4%B8%9A%E6%89%A7%E8%A1%8C%E9%98%B6%E6%AE%B5">作业执行阶段</h4> 
<p><img alt="" height="1200" src="https://images2.imgbox.com/25/c5/nRF6DUxE_o.png" width="1200"></p> 
<p></p> 
<p>在Apache Flink中，数据流作业的执行过程可以划分为多个阶段，从逻辑视图到物理执行图的转换。这个过程包括从StreamGraph到JobGraph，再到ExecutionGraph，最终映射到实际的物理执行图。下面详细说明这个过程：</p> 
<ol><li> <p><strong>StreamGraph（逻辑视图）：</strong> StreamGraph是用户编写的流处理应用程序的逻辑表示。它包含了数据流的转换操作、算子之间的关系、事件时间处理策略、容错配置等。StreamGraph是用户定义的数据流拓扑，是一种高级抽象，用户可以通过DataStream API构建StreamGraph。</p> </li><li> <p><strong>JobGraph（作业图）：</strong> JobGraph是从StreamGraph派生而来的，表示一个具体的作业执行计划。在JobGraph中，StreamGraph中的逻辑算子被映射为具体的物理算子，且有明确的执行顺序和任务间的依赖关系。JobGraph还包含了资源配置、任务并行度、优化选项等信息。JobGraph是从逻辑视图转向物理执行的关键步骤。</p> </li><li> <p><strong>ExecutionGraph（执行图）：</strong> ExecutionGraph是JobGraph的执行时表示，它是实际执行计划的核心。在ExecutionGraph中，JobGraph中的每个任务都会被映射到一个具体的执行任务，每个任务可以包含一个或多个子任务，这些子任务被映射到不同的TaskManager上。ExecutionGraph还负责维护作业的执行状态，以及任务之间的调度和通信。</p> </li><li> <p><strong>物理执行图：</strong> ExecutionGraph被映射到实际的物理执行图，即在TaskManager集群上真正执行的任务拓扑。物理执行图包括了任务的并行执行、数据交换、任务状态管理等细节，它是作业在分布式环境中实际运行的体现。</p> </li></ol> 
<p>总结起来，StreamGraph到JobGraph到ExecutionGraph的转换是Flink作业执行计划的关键步骤。从逻辑视图到物理执行图的转换过程考虑了作业的拓扑结构、资源分配、任务调度等方面的问题，确保了作业可以在分布式环境中高效执行。这一系列转换过程使得用户可以通过高层次的抽象来描述作业逻辑，而Flink框架会负责将其转化为可执行的任务图，实现数据流的处理和计算。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/fbfd7677d1b020c41e25f1f972ae03f7/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">AIGC时代下，结合ChatGPT谈谈儿童教育</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/771fae7c585ef29f6d2ada925b8cbe44/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Spark编程实验四：Spark Streaming编程</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>