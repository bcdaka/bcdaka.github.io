<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>面试专区|【70道Hive高频题整理(附答案背诵版)】 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/e9d08da0b189527ffd0a3b673b575627/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="面试专区|【70道Hive高频题整理(附答案背诵版)】">
  <meta property="og:description" content="简述什么是Hive？ Hive是一个基于Hadoop的数据仓库工具，它可以将结构化的数据文件映射为一张数据库表，并提供简单的SQL查询功能，可以将SQL语句转换为MapReduce任务进行运行。Hive定义了简单的SQL查询语言称为HiveQL，该语言允许熟悉SQL的用户查询数据。同时，Hive提供了一个元数据存储，存储了所有表的元数据信息。
应用场景举例：假设我们有一个电商网站，每天都会产生大量的交易数据，我们需要分析这些数据以了解销售情况、用户行为等信息。我们可以用Hive来建立这些数据的仓库，使用HiveQL查询这些数据，比如统计每天的销售总额、每个商品的销售额等。这样我们可以快速地获取到需要的信息，并基于这些信息做出决策。
第二题：Hive的数据类型有哪些？
Hive支持的数据类型包括：
基本类型：如int、float、double、string、boolean等；集合类型：如array、map、struct等；复杂类型：如uniontype、array&lt; struct&gt;、map&lt;string,struct&gt;等；用户自定义类型。 应用场景举例：假设我们有一个用户信息表，表中有一个字段叫做“地址”，该地址由省、市、区、街道等多个部分组成。我们可以使用Hive的复杂类型来定义这个字段，比如定义一个map类型，其中key为地址的组成部分，value为对应的值，这样我们就可以在一个字段中存储整个地址信息。
简述Hive的优缺点 ？ Hive的优点：
易于使用：Hive提供了一个类似于SQL的查询语言，称为HiveQL，这使得数据分析变得非常简单。处理大数据：Hive是基于Hadoop的数据仓库工具，能够处理大规模数据。可扩展性：Hive可以扩展到多个节点，以处理更多数据。数据整合：Hive可以轻松地将来自不同源的数据整合到一个数据仓库中。数据安全：Hive支持数据加密和用户权限管理，确保数据的安全性。 Hive的缺点：
性能问题：对于实时查询或低延迟查询，Hive可能不是最佳选择，因为它的查询性能可能不如其他一些工具。不支持所有SQL功能：虽然HiveQL提供了很多SQL功能，但它并不支持所有的SQL特性。数据同步问题：在多节点环境中，数据的同步可能是一个问题。不支持联接类型：Hive在处理表之间的联接时可能不如其他数据库系统高效。不支持索引：为了提高查询性能，许多数据库系统使用索引，但Hive并不支持这一特性。 以上就是对Hive优缺点的简要概述，如果你需要更详细的解释或者有其他问题，欢迎随时提问。
简述Hive的作用 ？ Hive是一个基于Hadoop的数据仓库工具，它可以用来处理和分析大规模数据。Hive提供了类似于SQL的查询语言HiveQL，用户可以使用HiveQL编写查询来分析数据。Hive的作用包括：
数据仓库：Hive可以用来存储和管理大规模数据，并提供数据查询和分析功能。数据处理：Hive支持各种数据处理操作，如数据过滤、连接、聚合等，可以帮助用户快速处理和分析数据。数据转换：Hive可以用来转换数据格式，将数据从一种格式转换为另一种格式，方便用户进行数据分析和利用。数据报表：Hive可以用来生成各种报表，帮助用户了解数据的分布和趋势，为决策提供支持。 应用场景举例：
电商网站：电商网站可以使用Hive来分析用户购买行为、商品销售情况等，从而制定营销策略和优化产品。金融行业：银行、证券等金融机构可以使用Hive来分析客户交易行为、风险评估等，从而提高风控水平和业务效益。社交媒体：社交媒体可以使用Hive来分析用户行为、舆情热点等，从而优化产品功能和提高用户体验。 简述Hive 架构原理 ？ Hive是基于Hadoop的数据仓库工具，用于处理和分析大数据。Hive通过构建元数据、查询语言、编译器、执行程序和驱动程序等组件，提供了一种类似SQL的查询语言HiveQL，用于查询和管理大数据。
Hive的架构原理可以分为以下几个部分：
元数据存储：Hive使用关系型数据库存储元数据，例如MySQL或PostgreSQL。元数据包括数据库、表、列和分区等的信息。查询语言：HiveQL是一种类似SQL的查询语言，用于编写查询和数据分析语句。HiveQL可以将复杂的查询分解为多个简单的子任务，这些子任务可以在Hadoop集群上并行执行。编译器：Hive的编译器负责将HiveQL查询语句转化为MapReduce、Tez或Spark等执行计划的中间表示形式。编译器还会对查询语句进行语义分析和优化，以提高查询性能。执行程序：Hive的执行程序根据编译器生成的执行计划，在Hadoop集群上并行执行查询任务。执行程序可以与不同的计算框架（如MapReduce、Tez或Spark）集成，以提高数据处理效率。驱动程序：Hive的驱动程序负责与用户交互，接收用户的查询请求并返回结果。驱动程序还负责监控查询的执行状态，并在必要时重新调整执行计划以提高性能。 在应用场景方面，Hive可以用于处理和分析大规模数据集，例如数据仓库、商业智能和机器学习等领域。通过使用Hive，用户可以快速地编写和分析数据，而无需了解底层的数据处理细节。
简述Hive和关系数据库比较 ？ Hive和关系数据库（如MySQL、Oracle等）在数据存储和处理上有一些不同之处。以下是它们之间的一些比较：
数据存储：关系数据库将数据存储在关系型表格中，每个表格由行和列组成，并使用主键和外键约束来维护数据完整性。而Hive是基于Hadoop的数据仓库工具，它将数据存储在HDFS中，以表的形式组织数据，但Hive的表是映射到HDFS的文件和目录结构上。数据处理：关系数据库使用SQL语言进行数据的查询和处理，可以进行复杂的数据操作和计算。而Hive使用HiveQL语言，它是基于SQL的查询语言，但与传统的SQL略有不同，HiveQL支持更多的数据操作和计算功能。扩展性：关系数据库在扩展性方面可能受到限制，特别是在处理大量数据时，可能会遇到性能瓶颈。而Hive基于Hadoop，可以利用Hadoop集群进行分布式处理，因此在处理大规模数据时具有更好的扩展性。数据格式：关系数据库可以支持多种数据格式，如CSV、JSON、XML等。而Hive默认使用CSV格式，但也可以使用其他格式，如Parquet和ORC等列式存储格式。ACID属性：关系数据库支持ACID属性，即原子性、一致性、隔离性和持久性，这使得关系数据库在处理事务时具有更高的可靠性和一致性。而Hive不支持ACID属性，因此在处理事务时可能存在一些限制和问题。 总之，Hive和关系数据库各有优缺点，选择使用哪种工具取决于具体的应用场景和需求。如果需要处理大规模数据并利用分布式计算资源，Hive是一个很好的选择。如果需要维护数据的完整性和一致性，并执行复杂的事务操作，关系数据库可能更加适合。
简述什么是Hive 管理表和外部表 ？ Hive中的管理表和外部表是两种不同类型的表，它们在数据存储、管理和访问方式上有一些区别。
管理表（也称为内部表）是Hive中默认的表类型。当你在Hive中创建一个表，并指定一个存储位置时，Hive会为这个表创建一个管理表。管理表的数据存储在Hive默认的文件系统（通常是HDFS）中的指定目录下，元数据存储在Hive自己的元数据存储库中。管理表由Hive完全管理，这意味着当你删除一个管理表时，Hive会同时删除该表的元数据和存储的数据。管理表适合存储大量的数据，并且可以通过HiveQL进行查询和管理。
外部表是指向HDFS中现有数据的表。当你创建一个外部表时，你只需要指定HDFS中数据的路径，而不是创建新的数据文件。与内部表不同，外部表的元数据也存储在Hive的元数据存储库中，但数据存储在HDFS中的指定位置，由Hadoop而不是Hive进行管理。这意味着，当你删除一个外部表时，只会删除该表的元数据，而不会删除实际的数据。外部表适合用于访问已经在HDFS中存在的数据，并且可以通过HiveQL进行查询和管理。
总之，管理表和外部表的主要区别在于数据的存储和管理方式。管理表由Hive完全管理，适合存储大量数据，而外部表则指向现有数据，由Hadoop而不是Hive进行管理。
简述Hive内部表和外部表的区别 ？ Hive内部表和外部表的区别主要表现在以下几个方面：
存储位置：内部表的数据和元数据都存储在Hive的存储路径下，即位于HDFS上。而外部表的数据则可以存放在HDFS、HBase、本地文件系统等位置，不在Hive管理的路径下，而是在指定的路径下。数据管理：内部表的数据由Hive进行管理、维护、删除和新建。对于数据的删除操作是彻底删除数据，包括在HDFS上的数据和Hive中的元数据。而外部表只管理数据的元数据信息，对于数据删除时并不会删除实际数据，只会删除元数据。数据访问权限：由于内部表的数据和元数据都存储在Hive中，因此Hive对于内部表有完全的访问权限，可以实现对表的一系列操作。而外部表只是对外部存储系统中数据的元数据进行管理，因此不能对数据进行全部的操作。数据导入导出：内部表和外部表在导入和导出数据方面具有不同的特点。对于内部表，导入数据通常是将数据从外部存储系统中导入到Hive管理的路径下，使用LOAD DATA语句来实现。导出数据则是将Hive中的数据导出成文件，使用INSERT OVERWRITE语句来实现。而对于外部表，导入数据通常是将数据直接存储到外部存储系统中，使用命令行工具或其他数据导入工具来实现。导出数据则是将外部存储系统中的数据导出到其他地方。 总的来说，Hive的内部表和外部表在存储位置、数据管理、访问权限和数据导入导出等方面都有较大的差异。用户可以根据实际需求选择适合的表类型来处理和分析大规模数据。
为什么内部表的删除，就会将数据全部删除，而外部表只删除表结构? 为什么用外部表更好 ？ Hive中的内部表和外部表在删除时表现出不同的行为，主要是因为它们的数据存储和管理方式不同。
内部表的数据存储在Hive自身的文件系统（通常是HDFS）中，而外部表的数据则存储在外部文件系统（如HDFS或其他存储系统）中。当删除内部表时，Hive会删除与该表相关的元数据信息以及存储在自身文件系统中的数据。这是因为内部表和其数据都是由Hive自身管理的。
相比之下，外部表仅删除表结构，而不删除实际数据。这是因为外部表的数据存储在外部文件系统中，并不由Hive管理。仅当删除外部表时，与该表相关的元数据信息会被删除，但存储在外部文件系统中的实际数据不会被影响。
使用外部表的好处在于它提供了更高的灵活性和安全性。由于数据存储在外部文件系统中，用户可以随时对外部表进行删除、创建或修改操作，而不用担心影响底层数据。此外，由于数据不直接由Hive管理，因此用户可以更加自由地管理和控制数据的访问和修改，提高了数据的安全性。
综上所述，Hive中内部表的删除会同时删除数据和元数据信息，而外部表仅删除元数据信息，实际数据不受影响。使用外部表可以提供更高的灵活性和安全性，因为用户可以更加自由地管理和控制数据的访问和修改，同时避免了直接操作底层数据可能带来的风险。
简述Hive建表语句？创建表时使用什么分隔符 ？ Hive建表语句的基本语法如下：
CREATE TABLE table_name ( column1 data_type, column2 data_type, ... ) ROWFORMAT DELIMITED FIELDS TERMINATED BY &#39;field_delimiter&#39;; 其中，table_name是表的名称，column1、column2等是表的列名，data_type是列的数据类型。ROWFORMAT DELIMITED指定了行格式和分隔符，FIELDS TERMINATED BY &#39;field_delimiter&#39;指定了字段的分隔符。">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-06-20T10:30:00+08:00">
    <meta property="article:modified_time" content="2024-06-20T10:30:00+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">面试专区|【70道Hive高频题整理(附答案背诵版)】</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h4><a id="Hive_0"></a>简述什么是Hive？</h4> 
<p>Hive是一个基于Hadoop的数据仓库工具，它可以将结构化的数据文件映射为一张数据库表，并提供简单的SQL查询功能，可以将SQL语句转换为MapReduce任务进行运行。Hive定义了简单的SQL查询语言称为HiveQL，该语言允许熟悉SQL的用户查询数据。同时，Hive提供了一个元数据存储，存储了所有表的元数据信息。</p> 
<p>应用场景举例：假设我们有一个电商网站，每天都会产生大量的交易数据，我们需要分析这些数据以了解销售情况、用户行为等信息。我们可以用Hive来建立这些数据的仓库，使用HiveQL查询这些数据，比如统计每天的销售总额、每个商品的销售额等。这样我们可以快速地获取到需要的信息，并基于这些信息做出决策。</p> 
<p>第二题：Hive的数据类型有哪些？</p> 
<p>Hive支持的数据类型包括：</p> 
<ol><li>基本类型：如int、float、double、string、boolean等；</li><li>集合类型：如array、map、struct等；</li><li>复杂类型：如uniontype、array&lt; struct&gt;、map&lt;string,struct&gt;等；</li><li>用户自定义类型。</li></ol> 
<p>应用场景举例：假设我们有一个用户信息表，表中有一个字段叫做“地址”，该地址由省、市、区、街道等多个部分组成。我们可以使用Hive的复杂类型来定义这个字段，比如定义一个map类型，其中key为地址的组成部分，value为对应的值，这样我们就可以在一个字段中存储整个地址信息。</p> 
<h4><a id="Hive__17"></a>简述Hive的优缺点 ？</h4> 
<p>Hive的优点：</p> 
<ol><li><strong>易于使用</strong>：Hive提供了一个类似于SQL的查询语言，称为HiveQL，这使得数据分析变得非常简单。</li><li><strong>处理大数据</strong>：Hive是基于Hadoop的数据仓库工具，能够处理大规模数据。</li><li><strong>可扩展性</strong>：Hive可以扩展到多个节点，以处理更多数据。</li><li><strong>数据整合</strong>：Hive可以轻松地将来自不同源的数据整合到一个数据仓库中。</li><li><strong>数据安全</strong>：Hive支持数据加密和用户权限管理，确保数据的安全性。</li></ol> 
<p>Hive的缺点：</p> 
<ol><li><strong>性能问题</strong>：对于实时查询或低延迟查询，Hive可能不是最佳选择，因为它的查询性能可能不如其他一些工具。</li><li><strong>不支持所有SQL功能</strong>：虽然HiveQL提供了很多SQL功能，但它并不支持所有的SQL特性。</li><li><strong>数据同步问题</strong>：在多节点环境中，数据的同步可能是一个问题。</li><li><strong>不支持联接类型</strong>：Hive在处理表之间的联接时可能不如其他数据库系统高效。</li><li><strong>不支持索引</strong>：为了提高查询性能，许多数据库系统使用索引，但Hive并不支持这一特性。</li></ol> 
<p>以上就是对Hive优缺点的简要概述，如果你需要更详细的解释或者有其他问题，欢迎随时提问。</p> 
<h4><a id="Hive__37"></a>简述Hive的作用 ？</h4> 
<p>Hive是一个基于Hadoop的数据仓库工具，它可以用来处理和分析大规模数据。Hive提供了类似于SQL的查询语言HiveQL，用户可以使用HiveQL编写查询来分析数据。Hive的作用包括：</p> 
<ol><li>数据仓库：Hive可以用来存储和管理大规模数据，并提供数据查询和分析功能。</li><li>数据处理：Hive支持各种数据处理操作，如数据过滤、连接、聚合等，可以帮助用户快速处理和分析数据。</li><li>数据转换：Hive可以用来转换数据格式，将数据从一种格式转换为另一种格式，方便用户进行数据分析和利用。</li><li>数据报表：Hive可以用来生成各种报表，帮助用户了解数据的分布和趋势，为决策提供支持。</li></ol> 
<p>应用场景举例：</p> 
<ol><li>电商网站：电商网站可以使用Hive来分析用户购买行为、商品销售情况等，从而制定营销策略和优化产品。</li><li>金融行业：银行、证券等金融机构可以使用Hive来分析客户交易行为、风险评估等，从而提高风控水平和业务效益。</li><li>社交媒体：社交媒体可以使用Hive来分析用户行为、舆情热点等，从而优化产品功能和提高用户体验。</li></ol> 
<h4><a id="Hive___52"></a>简述Hive 架构原理 ？</h4> 
<p>Hive是基于Hadoop的数据仓库工具，用于处理和分析大数据。Hive通过构建元数据、查询语言、编译器、执行程序和驱动程序等组件，提供了一种类似SQL的查询语言HiveQL，用于查询和管理大数据。</p> 
<p>Hive的架构原理可以分为以下几个部分：</p> 
<ol><li>元数据存储：Hive使用关系型数据库存储元数据，例如MySQL或PostgreSQL。元数据包括数据库、表、列和分区等的信息。</li><li>查询语言：HiveQL是一种类似SQL的查询语言，用于编写查询和数据分析语句。HiveQL可以将复杂的查询分解为多个简单的子任务，这些子任务可以在Hadoop集群上并行执行。</li><li>编译器：Hive的编译器负责将HiveQL查询语句转化为MapReduce、Tez或Spark等执行计划的中间表示形式。编译器还会对查询语句进行语义分析和优化，以提高查询性能。</li><li>执行程序：Hive的执行程序根据编译器生成的执行计划，在Hadoop集群上并行执行查询任务。执行程序可以与不同的计算框架（如MapReduce、Tez或Spark）集成，以提高数据处理效率。</li><li>驱动程序：Hive的驱动程序负责与用户交互，接收用户的查询请求并返回结果。驱动程序还负责监控查询的执行状态，并在必要时重新调整执行计划以提高性能。</li></ol> 
<p>在应用场景方面，Hive可以用于处理和分析大规模数据集，例如数据仓库、商业智能和机器学习等领域。通过使用Hive，用户可以快速地编写和分析数据，而无需了解底层的数据处理细节。</p> 
<h4><a id="Hive__66"></a>简述Hive和关系数据库比较 ？</h4> 
<p>Hive和关系数据库（如MySQL、Oracle等）在数据存储和处理上有一些不同之处。以下是它们之间的一些比较：</p> 
<ol><li>数据存储：关系数据库将数据存储在关系型表格中，每个表格由行和列组成，并使用主键和外键约束来维护数据完整性。而Hive是基于Hadoop的数据仓库工具，它将数据存储在HDFS中，以表的形式组织数据，但Hive的表是映射到HDFS的文件和目录结构上。</li><li>数据处理：关系数据库使用SQL语言进行数据的查询和处理，可以进行复杂的数据操作和计算。而Hive使用HiveQL语言，它是基于SQL的查询语言，但与传统的SQL略有不同，HiveQL支持更多的数据操作和计算功能。</li><li>扩展性：关系数据库在扩展性方面可能受到限制，特别是在处理大量数据时，可能会遇到性能瓶颈。而Hive基于Hadoop，可以利用Hadoop集群进行分布式处理，因此在处理大规模数据时具有更好的扩展性。</li><li>数据格式：关系数据库可以支持多种数据格式，如CSV、JSON、XML等。而Hive默认使用CSV格式，但也可以使用其他格式，如Parquet和ORC等列式存储格式。</li><li>ACID属性：关系数据库支持ACID属性，即原子性、一致性、隔离性和持久性，这使得关系数据库在处理事务时具有更高的可靠性和一致性。而Hive不支持ACID属性，因此在处理事务时可能存在一些限制和问题。</li></ol> 
<p>总之，Hive和关系数据库各有优缺点，选择使用哪种工具取决于具体的应用场景和需求。如果需要处理大规模数据并利用分布式计算资源，Hive是一个很好的选择。如果需要维护数据的完整性和一致性，并执行复杂的事务操作，关系数据库可能更加适合。</p> 
<h4><a id="Hive___78"></a>简述什么是Hive 管理表和外部表 ？</h4> 
<p>Hive中的管理表和外部表是两种不同类型的表，它们在数据存储、管理和访问方式上有一些区别。</p> 
<p>管理表（也称为内部表）是Hive中默认的表类型。当你在Hive中创建一个表，并指定一个存储位置时，Hive会为这个表创建一个管理表。管理表的数据存储在Hive默认的文件系统（通常是HDFS）中的指定目录下，元数据存储在Hive自己的元数据存储库中。管理表由Hive完全管理，这意味着当你删除一个管理表时，Hive会同时删除该表的元数据和存储的数据。管理表适合存储大量的数据，并且可以通过HiveQL进行查询和管理。</p> 
<p>外部表是指向HDFS中现有数据的表。当你创建一个外部表时，你只需要指定HDFS中数据的路径，而不是创建新的数据文件。与内部表不同，外部表的元数据也存储在Hive的元数据存储库中，但数据存储在HDFS中的指定位置，由Hadoop而不是Hive进行管理。这意味着，当你删除一个外部表时，只会删除该表的元数据，而不会删除实际的数据。外部表适合用于访问已经在HDFS中存在的数据，并且可以通过HiveQL进行查询和管理。</p> 
<p>总之，管理表和外部表的主要区别在于数据的存储和管理方式。管理表由Hive完全管理，适合存储大量数据，而外部表则指向现有数据，由Hadoop而不是Hive进行管理。</p> 
<h4><a id="Hive__88"></a>简述Hive内部表和外部表的区别 ？</h4> 
<p>Hive内部表和外部表的区别主要表现在以下几个方面：</p> 
<ol><li>存储位置：内部表的数据和元数据都存储在Hive的存储路径下，即位于HDFS上。而外部表的数据则可以存放在HDFS、HBase、本地文件系统等位置，不在Hive管理的路径下，而是在指定的路径下。</li><li>数据管理：内部表的数据由Hive进行管理、维护、删除和新建。对于数据的删除操作是彻底删除数据，包括在HDFS上的数据和Hive中的元数据。而外部表只管理数据的元数据信息，对于数据删除时并不会删除实际数据，只会删除元数据。</li><li>数据访问权限：由于内部表的数据和元数据都存储在Hive中，因此Hive对于内部表有完全的访问权限，可以实现对表的一系列操作。而外部表只是对外部存储系统中数据的元数据进行管理，因此不能对数据进行全部的操作。</li><li>数据导入导出：内部表和外部表在导入和导出数据方面具有不同的特点。对于内部表，导入数据通常是将数据从外部存储系统中导入到Hive管理的路径下，使用LOAD DATA语句来实现。导出数据则是将Hive中的数据导出成文件，使用INSERT OVERWRITE语句来实现。而对于外部表，导入数据通常是将数据直接存储到外部存储系统中，使用命令行工具或其他数据导入工具来实现。导出数据则是将外部存储系统中的数据导出到其他地方。</li></ol> 
<p>总的来说，Hive的内部表和外部表在存储位置、数据管理、访问权限和数据导入导出等方面都有较大的差异。用户可以根据实际需求选择适合的表类型来处理和分析大规模数据。</p> 
<h4><a id="___99"></a>为什么内部表的删除，就会将数据全部删除，而外部表只删除表结构? 为什么用外部表更好 ？</h4> 
<p>Hive中的内部表和外部表在删除时表现出不同的行为，主要是因为它们的数据存储和管理方式不同。</p> 
<p>内部表的数据存储在Hive自身的文件系统（通常是HDFS）中，而外部表的数据则存储在外部文件系统（如HDFS或其他存储系统）中。当删除内部表时，Hive会删除与该表相关的元数据信息以及存储在自身文件系统中的数据。这是因为内部表和其数据都是由Hive自身管理的。</p> 
<p>相比之下，外部表仅删除表结构，而不删除实际数据。这是因为外部表的数据存储在外部文件系统中，并不由Hive管理。仅当删除外部表时，与该表相关的元数据信息会被删除，但存储在外部文件系统中的实际数据不会被影响。</p> 
<p>使用外部表的好处在于它提供了更高的灵活性和安全性。由于数据存储在外部文件系统中，用户可以随时对外部表进行删除、创建或修改操作，而不用担心影响底层数据。此外，由于数据不直接由Hive管理，因此用户可以更加自由地管理和控制数据的访问和修改，提高了数据的安全性。</p> 
<p>综上所述，Hive中内部表的删除会同时删除数据和元数据信息，而外部表仅删除元数据信息，实际数据不受影响。使用外部表可以提供更高的灵活性和安全性，因为用户可以更加自由地管理和控制数据的访问和修改，同时避免了直接操作底层数据可能带来的风险。</p> 
<h4><a id="Hive__111"></a>简述Hive建表语句？创建表时使用什么分隔符 ？</h4> 
<p>Hive建表语句的基本语法如下：</p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> table_name <span class="token punctuation">(</span>
   column1 data_type<span class="token punctuation">,</span>
   column2 data_type<span class="token punctuation">,</span>
   <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token punctuation">)</span>
ROWFORMAT DELIMITED
<span class="token keyword">FIELDS</span> <span class="token keyword">TERMINATED</span> <span class="token keyword">BY</span> <span class="token string">'field_delimiter'</span><span class="token punctuation">;</span>
</code></pre> 
<p>其中，<code>table_name</code>是表的名称，<code>column1</code>、<code>column2</code>等是表的列名，<code>data_type</code>是列的数据类型。<code>ROWFORMAT DELIMITED</code>指定了行格式和分隔符，<code>FIELDS TERMINATED BY 'field_delimiter'</code>指定了字段的分隔符。</p> 
<p>创建表时使用的分隔符通常是特定的字符或字符串，用于将每行数据分割成不同的字段。Hive默认使用单字节分隔符来加载文本数据，例如逗号、制表符、空格等等。在创建表的时候，可以通过指定<code>FIELDS TERMINATED BY</code>子句来指定字段的分隔符。例如，如果使用制表符作为分隔符，可以将其指定为<code>FIELDS TERMINATED BY '\t'</code>。</p> 
<p>除了默认的文本文件格式，Hive还支持其他文件格式，如Parquet和ORC等列式存储格式。这些格式通常使用特定的分隔符来表示不同字段的值。例如，Parquet使用二进制格式存储数据，并通过特定的字段描述符来表示不同字段的类型和值。在创建表的时候，可以选择不同的文件格式来优化数据的存储和查询性能。</p> 
<h4><a id="Hive__132"></a>简述Hive删除语句外部表删除的是什么 ？</h4> 
<p>在Hive中，当你删除一个外部表时，实际上只会删除该表的元数据，而不会删除实际的数据。这是因为外部表的数据存储在Hive外部的HDFS中，由Hadoop而不是Hive进行管理。因此，当你执行删除外部表的命令时，只会从Hive的元数据存储库中移除表的定义和相关元数据，而不会影响到实际存储在HDFS中的数据。这样可以确保数据的完整性和安全性，因为原始数据不会被误删除或受到影响。</p> 
<h4><a id="Hive__136"></a>简述Hive导入数据的五种方式是什么?举例说明 ？</h4> 
<p>Hive导入数据的五种方式包括：</p> 
<ol><li>向表中装载数据（Load）：使用LOAD DATA语句将数据加载到Hive表中。例如，从本地文件系统加载数据到Hive表：</li></ol> 
<pre><code class="prism language-sql"><span class="token keyword">LOAD</span> <span class="token keyword">DATA</span> <span class="token keyword">LOCAL</span> INPATH <span class="token string">'/home/hdfs/data/test.txt'</span> <span class="token keyword">INTO</span> <span class="token keyword">TABLE</span> test<span class="token punctuation">;</span>
</code></pre> 
<p>从HDFS文件系统加载数据覆盖Hive表：</p> 
<pre><code class="prism language-sql"><span class="token keyword">LOAD</span> <span class="token keyword">DATA</span> INPATH <span class="token string">'/wcinput/test.txt'</span> OVERWRITE <span class="token keyword">INTO</span> <span class="token keyword">TABLE</span> test<span class="token punctuation">;</span>
</code></pre> 
<ol start="2"><li>通过查询语句向表中插入数据（Insert）：使用INSERT INTO语句将数据插入到Hive表中。例如，以追加数据的方式插入到表或分区，原有数据不会删除：</li></ol> 
<pre><code class="prism language-sql"><span class="token keyword">INSERT</span> <span class="token keyword">INTO</span> <span class="token keyword">TABLE</span> tablename1 <span class="token punctuation">[</span><span class="token keyword">PARTITION</span> <span class="token punctuation">(</span>partcol1<span class="token operator">=</span>val1<span class="token punctuation">,</span> partcol2<span class="token operator">=</span>val2…<span class="token punctuation">)</span><span class="token punctuation">]</span> SELECT_STATEMENT1 <span class="token keyword">FROM</span> from_statement<span class="token punctuation">;</span>
</code></pre> 
<ol start="3"><li>创建表时加载数据：在创建表的时候，可以直接指定数据的加载路径。例如：</li></ol> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> EXTERNAL <span class="token keyword">TABLE</span> <span class="token keyword">if</span> <span class="token operator">not</span> <span class="token keyword">exists</span> tablename <span class="token punctuation">(</span>id <span class="token keyword">int</span><span class="token punctuation">,</span> name string<span class="token punctuation">)</span> <span class="token keyword">ROW</span> FORMAT DELIMITED <span class="token keyword">FIELDS</span> <span class="token keyword">TERMINATED</span> <span class="token keyword">BY</span> <span class="token string">'\t'</span> LOCATION <span class="token string">'/data/test/'</span><span class="token punctuation">;</span>
</code></pre> 
<ol start="4"><li>增量导入：表中原有数据不变，新插入的数据增加在后面。这种方式主要用于数据增量导入。</li><li>Import数据到指定Hive表：先用export导出后，再将数据导入（export和import主要用于两个Hadoop平台集群之间Hive表迁移）。例如：从a集群中导出hive表数据，然后再将其导入到另一个集群的指定Hive表中。</li></ol> 
<p>以上是Hive导入数据的五种方式，用户可以根据实际需求选择适合的方式来进行数据导入。</p> 
<h4><a id="row_numberrankdense_rank__173"></a>简述row_number()，rank()和dense_rank()的区别 ？</h4> 
<p>在Hive中，row_number()、rank()和dense_rank()是用于窗口函数（Window Function）的三个常见函数，它们可以用来对数据集中的行进行排序和编号。以下是这三个函数的区别：</p> 
<ol><li>row_number()：为每一行分配一个唯一的序号，序号从1开始递增。如果两行或多行具有相同的排序值，它们将获得相同的序号。row_number()不会在值之间留下任何“空隙”，即如果某一行的排序值比前一行大，下一行的序号将增加1。</li><li>rank()：为每一行分配一个排名值，排名值从1开始递增。如果两行或多行具有相同的排序值，它们将获得相同的排名值。与row_number()不同，rank()会在值之间留下空隙。例如，如果有两行并列排名第一，下一行的排名将为3而不是2。</li><li>dense_rank()：与rank()类似，为每一行分配一个排名值。但是，与rank()不同的是，dense_rank()不会在值之间留下空隙。如果两行或多行具有相同的排序值，它们将获得相同的排名值，并且下一行的排名将增加1。</li></ol> 
<p>应用场景示例：</p> 
<p>假设有一个包含以下数据的表格，按照分数进行升序排序：</p> 
<pre><code class="prism language-markdown">| id | score |
|----|-------|
| 1  | 80    |
| 2  | 85    |
| 3  | 85    |
| 4  | 90    |
</code></pre> 
<p>使用row_number()函数：</p> 
<pre><code class="prism language-markdown">| id | score | row_number() |
|----|-------|--------------|
| 1  | 80    | 1            |
| 2  | 85    | 2            |
| 3  | 85    | 2            |
| 4  | 90    | 3            |
</code></pre> 
<p>使用rank()函数：</p> 
<pre><code class="prism language-markdown">| id | score | rank() |
|----|-------|--------|
| 1  | 80    | 1      |
| 2  | 85    | 2      |
| 3  | 85    | 2      |
| 4  | 90    | 4      |
</code></pre> 
<p>使用dense_rank()函数：</p> 
<pre><code class="prism language-markdown">| id | score | dense_rank() |
|----|-------|--------------|
| 1  | 80    | 1            |
| 2  | 85    | 2            |
| 3  | 85    | 2            |
| 4  | 90    | 3            |
</code></pre> 
<h4><a id="hive_Sort_ByOrder_ByCluster_ByDistrbute_By_231"></a>简述请说明hive中 Sort By，Order By，Cluster By，Distrbute By各代表什么意思？</h4> 
<p>Hive是基于Hadoop的数据仓库工具，它提供了多种用于数据查询和处理的SQL-like语言，其中Sort By、Order By、Cluster By和Distrbute By是Hive中用于数据分发的关键字。</p> 
<ol><li>Sort By：Sort By用于对数据进行排序，它将数据按照指定的列进行排序，并将结果输出到相应的输出目录中。Sort By可以根据一列或多列进行排序，默认情况下按照升序排序。</li><li>Order By：Order By与Sort By类似，也是用于对数据进行排序。但是，Order By会强制全局排序，即在整个数据集上进行排序，而不仅仅是每个分区的内部排序。因此，Order By可能会消耗更多的计算资源和时间。</li><li>Cluster By：Cluster By是Hive中的一个特殊关键字，它结合了Sort By和Distrbute By的功能。Cluster By将数据按照指定的列进行排序和分发，以确保相同的值被分发到同一个节点上。这样可以提高数据的局部性，并减少节点之间的数据传输量。</li><li>Distrbute By：Distrbute By用于控制数据的分发方式，即如何将数据分布到不同的任务节点上进行计算。默认情况下，Hive会根据每行数据的哈希值将数据分发到不同的节点上，这样可以实现数据的均匀分布。但是，在某些情况下，我们可能希望将具有相同键值的数据分发到同一个节点上，以便进行更高效的处理。这时可以使用Distrbute By关键字来实现。</li></ol> 
<p>综上所述，Sort By、Order By、Cluster By和Distrbute By是Hive中用于控制数据分发和处理的四种关键字，它们各自具有不同的用途和特点，可以在查询中根据需要进行选择和使用。</p> 
<h4><a id="Hivesplitcoalescecollect_list__242"></a>写出Hive中split、coalesce及collect_list函数的用法 ？</h4> 
<p>好的，我会为你解释这三个函数在Hive中的用法。</p> 
<ol><li><strong>split函数</strong></li></ol> 
<p><code>split</code> 函数用于将字符串按照指定的分隔符拆分成数组。它的语法如下：</p> 
<pre><code class="prism language-sql">split<span class="token punctuation">(</span>string str<span class="token punctuation">,</span> string pattern<span class="token punctuation">)</span>
</code></pre> 
<p>其中，<code>str</code> 是要拆分的字符串，<code>pattern</code> 是分隔符的模式。</p> 
<p><strong>例子</strong>：<br> 假设有一个名为 <code>users</code> 的表，其中有一个名为 <code>email</code> 的列，包含用户的电子邮件地址。如果我们想将每个电子邮件地址拆分成单独的地址，可以使用 <code>split</code> 函数：</p> 
<pre><code class="prism language-sql"><span class="token keyword">SELECT</span> split<span class="token punctuation">(</span>email<span class="token punctuation">,</span> <span class="token string">'@'</span><span class="token punctuation">)</span> <span class="token keyword">AS</span> email_parts <span class="token keyword">FROM</span> users<span class="token punctuation">;</span>
</code></pre> 
<p>这将返回一个包含两个元素的数组：电子邮件地址的前缀和后缀。</p> 
<ol start="2"><li><strong>coalesce函数</strong></li></ol> 
<p><code>coalesce</code> 函数用于返回参数列表中的第一个非空值。它的语法如下：</p> 
<pre><code class="prism language-sql"><span class="token keyword">coalesce</span><span class="token punctuation">(</span>expression1<span class="token punctuation">,</span> expression2<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> expressionN<span class="token punctuation">)</span>
</code></pre> 
<p>当参数列表中的某个表达式为 NULL 时，<code>coalesce</code> 函数将返回下一个表达式的值，直到找到第一个非空值为止。如果没有非空值，则返回 NULL。</p> 
<p><strong>例子</strong>：<br> 假设有一个名为 <code>products</code> 的表，其中有一个名为 <code>price</code> 的列和一个名为 <code>discounted_price</code> 的列。如果某个产品没有折扣价格（即 <code>discounted_price</code> 为 NULL），我们想使用正常的价格，可以使用 <code>coalesce</code> 函数：</p> 
<pre><code class="prism language-sql"><span class="token keyword">SELECT</span> <span class="token keyword">coalesce</span><span class="token punctuation">(</span>discounted_price<span class="token punctuation">,</span> price<span class="token punctuation">)</span> <span class="token keyword">AS</span> final_price <span class="token keyword">FROM</span> products<span class="token punctuation">;</span>
</code></pre> 
<p>这将返回 <code>discounted_price</code> 或 <code>price</code> 中的非空值作为最终价格。</p> 
<ol start="3"><li><strong>collect_list函数</strong></li></ol> 
<p><code>collect_list</code> 函数用于将多行数据中的某一列值聚合在一起形成一个数组。它的语法如下：</p> 
<pre><code class="prism language-sql">collect_list<span class="token punctuation">(</span>col<span class="token punctuation">)</span>
</code></pre> 
<p>其中，<code>col</code> 是要聚合的列名。</p> 
<p><strong>例子</strong>：<br> 假设有一个名为 <code>orders</code> 的表，其中有一个名为 <code>product_id</code> 的列，表示订单中的产品。我们想将所有订单中的产品 ID 聚合到一个数组中，可以使用 <code>collect_list</code> 函数：</p> 
<pre><code class="prism language-sql"><span class="token keyword">SELECT</span> collect_list<span class="token punctuation">(</span>product_id<span class="token punctuation">)</span> <span class="token keyword">AS</span> product_ids <span class="token keyword">FROM</span> orders<span class="token punctuation">;</span>
</code></pre> 
<p>这将返回一个包含所有产品 ID 的数组。</p> 
<h4><a id="Hive__309"></a>简述Hive如何实现分区 ？</h4> 
<p>Hive的分区是通过在创建表的时候指定分区字段来实现的。分区字段是在表结构中定义的，相当于为表数据按照分区字段进行了分类。每个分区以文件夹的形式单独存在表文件夹的目录下，分区字段的值就作为文件夹的名字。</p> 
<p>创建分区的方式是在CREATE TABLE语句后面加上PARTITIONED BY子句，指定分区字段和类型。例如：</p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> partitioned_table <span class="token punctuation">(</span>id <span class="token keyword">INT</span><span class="token punctuation">,</span> name STRING<span class="token punctuation">,</span> <span class="token keyword">date</span> <span class="token keyword">DATE</span><span class="token punctuation">)</span>
PARTITIONED <span class="token keyword">BY</span> <span class="token punctuation">(</span><span class="token keyword">year</span> <span class="token keyword">INT</span><span class="token punctuation">,</span> <span class="token keyword">month</span> <span class="token keyword">INT</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>上述语句创建了一个分区表，按照year和month两个字段进行分区。</p> 
<p>在插入数据时，可以指定分区字段的值，将数据插入到相应的分区中。例如：</p> 
<pre><code class="prism language-sql"><span class="token keyword">INSERT</span> <span class="token keyword">INTO</span> <span class="token keyword">TABLE</span> partitioned_table <span class="token keyword">PARTITION</span> <span class="token punctuation">(</span><span class="token keyword">year</span><span class="token operator">=</span><span class="token number">2020</span><span class="token punctuation">,</span> <span class="token keyword">month</span><span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span> <span class="token keyword">VALUES</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">'John'</span><span class="token punctuation">,</span> <span class="token string">'2020-10-01'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>上述语句将数据插入到year=2020和month=10的分区中。</p> 
<p>Hive还支持动态分区和静态分区。动态分区可以动态加载数据，静态分区则需要手动指定分区值。在创建静态分区时，可以使用单值分区或范围分区的建表方式。单值分区的建表方式比较简单，只需要指定分区键和类型即可；范围分区的建表方式则需要在直接定义列的方式下创建。</p> 
<p>总的来说，Hive的分区是一种将数据按照业务需求进行分类的方式，可以提高查询性能和数据管理效率。用户可以根据实际需求选择适合的分区方式来进行数据管理。</p> 
<p>由于内容太多，更多内容以链接形势给大家，点击进去就是答案了</p> 
<p><a href="https://www.iamshuaidi.com/?p=27758" rel="nofollow">16. 简述Hive的两张表关联，使用MapReduce怎么实现 ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27760" rel="nofollow">17. 简述Hive有哪些方式保存元数据，各有哪些特点？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27762" rel="nofollow">18. 简述Hive 的 join 有几种方式，怎么实现 join 的？ ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27764" rel="nofollow">19. 简述Hive 中的压缩格式 RCFile、 TextFile、 SequenceFile 各有什么区别？ ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27766" rel="nofollow">20. 简述Hive 的 sort by 和 order by 的区别？ ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27768" rel="nofollow">21. 简述Hive的函数：UDF、UDAF、UDTF的区别？ ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27770" rel="nofollow">22. 简述所有的Hive任务都会有MapReduce的执行吗 ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27772" rel="nofollow">23. 简述Hive有索引吗 ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27774" rel="nofollow">24. 简述对Hive桶表的理解 ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27776" rel="nofollow">25. 简述Hive本地模式 ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27778" rel="nofollow">26. 简述Hive表关联查询，如何解决数据倾斜的问题 ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27780" rel="nofollow">27. 简述什么是Hive HQL之Fetch抓取 ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27782" rel="nofollow">28. 简述Hive并行模式 ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27784" rel="nofollow">29. 简述Hive中的优化分类 ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27786" rel="nofollow">30. 简述什么是笛卡尔乘积与小表join大表 ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27788" rel="nofollow">31. 简述Hive数据去重的两种方式 (distinct和group by) ？</a></p> 
<p>[32. 简述优化调优<a href="https://www.iamshuaidi.com/?p=27790" rel="nofollow">(Count(Distinct)去重统计] ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27792" rel="nofollow">33. 简述Hive的介绍一下有哪些常用函数 ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27794" rel="nofollow">34. 简述Hive的数据组织 ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27796" rel="nofollow">35. 简述内部表和外部表的使用选择原则 ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27798" rel="nofollow">36. 简述分区表和分桶表的区别 ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27800" rel="nofollow">37. 简述Hive优化相关措施 ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27802" rel="nofollow">38. 简述Hive的数据类型 ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27804" rel="nofollow">39. 简述Hive的DDL操作 ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27806" rel="nofollow">40. 简述Hive的HSQL转换为MapReduce的过程 ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27808" rel="nofollow">41. 简述Hive底层与数据库交互原理 ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27810" rel="nofollow">42. 简述ORC、Parquet等列式存储的优点 ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27812" rel="nofollow">43. 简述使用过Hive解析JSON串吗 ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27814" rel="nofollow">44. 简述Hive导出数据有几种方式？如何导出数据 ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27816" rel="nofollow">45. 简述为什么要对数据仓库分层 ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27818" rel="nofollow">46. 简述数据建模用的哪些模型 ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27820" rel="nofollow">47. 简述Hive和HBase的对比区别 ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27822" rel="nofollow">48. 简述Hive 小文件问题及解决 ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27824" rel="nofollow">49. 简述 Hive的几种存储方式 ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27826" rel="nofollow">50. 简述Hive 动态分区和静态分区的区别 + 使用场景 ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27828" rel="nofollow">51. 简述Hive 语句执行顺序 ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27830" rel="nofollow">52. 简述Hive中MR(map reduce)、Tez和Spark执行引擎对比 ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27832" rel="nofollow">53. 简述为什么任务执行的时候只有一个reduce ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27834" rel="nofollow">54. 简述Hive为什么要分桶 ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27836" rel="nofollow">55. 简述如何使用分桶 ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27838" rel="nofollow">56. 简述Hive如果不用参数调优，在map和reduce端应该做什么 ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27840" rel="nofollow">57. 简述Hive的三种自定义函数是什么？实现步骤与流程？它们之间的区别？作用是什么 ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27842" rel="nofollow">58. 简述Hive的存储引擎和计算引擎 ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27844" rel="nofollow">59. 简述Hive的count的用法 ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27846" rel="nofollow">60. 简述Hive的union和union all的区别 ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27848" rel="nofollow">61. 简述Hive Join 的原理与机制 ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27850" rel="nofollow">62. 简述Hive如何优化join操作 ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27852" rel="nofollow">63. 简述什么是Hive的map join ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27854" rel="nofollow">64. 简述Hive的开窗函数有哪些 ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27856" rel="nofollow">65. 简述Hive存储数据吗 ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27858" rel="nofollow">66. 简述row_number，rank，dense_rank的区别 ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27860" rel="nofollow">67. 简述Hive count(distinct)有几个reduce，海量数据会有什么问题 ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27862" rel="nofollow">68. 简述一条HQL从代码到执行的过程 ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27864" rel="nofollow">69. 简述前后函数 lag(expr,n,defval)、lead(expr,n,defval) ？</a></p> 
<p><a href="https://www.iamshuaidi.com/?p=27866" rel="nofollow">70. 简述头尾函数：FIRST_VALUE(expr),LAST_VALUE(expr) ？</a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/caa522adbe363fc086ef70ec745380fb/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">RabbitMQ详解-06RabbitMQ高级</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/df5895da0865559b8629f03d0efad508/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【AI大模型】在运动项目的深度融合和在穿戴设备的实践及未来运动健康技术发展</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>