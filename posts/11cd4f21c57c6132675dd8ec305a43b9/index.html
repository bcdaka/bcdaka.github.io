<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>让AI听话的一种办法（Stable Diffusion进阶篇：SVD 3） - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/11cd4f21c57c6132675dd8ec305a43b9/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="让AI听话的一种办法（Stable Diffusion进阶篇：SVD 3）">
  <meta property="og:description" content="动态内容在上一篇笔记里学会了参数以及文生图生视频的操作，可能还是会有小伙伴觉得进行一些参数的改动或者就目前的产出结果还不到自己的预期。
例如像是动作幅度太小，眼睛不够有神等，而也是SVD的一个缺点，它所产出的动态内容某种程度上是不可控的。
就现阶段而言，要控制SVD去动某个部分或者那个部位不要动都是比较难控制的，而目前想要AI画出符合自己预期的结果则又需要反复的“抽卡”。
当然ComfyUI的开发者们早就想到了这些，于是就有了一些节点可以动态控制画面的一部分区域，从而提高视频的可塑性。
所以今天的内容就是要让AI学会怎么“听话”
**蒙版
**
蒙版这个东西之前学习Stable Diffusion的小伙伴们应该就很熟悉了，为了防止有小伙伴忘记了：
正是因为有了蒙版的存在，在用AI绘制时可以用蒙版来控制AI只重绘画面里的一小部分，而这样的方法也可以运用在视频生成部分。
可能有些小伙伴知道Runway有一个运动笔刷功能可以做到这样的效果，ComfyUI也可以做到只让画面的一小部分动起来。在ComfyUI中有一个工作流：运动笔刷（下载链接在文末），直接将其拖拽进ComfyUI界面。
在工作流的最左边导入初始图片：
然后鼠标右键点击图像，选择在**遮罩编辑器（MaskEditor）**中打开
然后就可以在编辑器里面对想要更改的部分进行涂鸦画黑：
记得完成之后点击最右下角的Save to Node
然后就进行一些常规的参数设置后（也可以直接先默认试试）就可以点击添加提示词队列进行生成啦！
这个工作流里面还有其他的辅助功能选项：
这里的两个选项：蒙版反转和蒙版边缘羽化。
蒙版反转是会把蒙版控制的绘制区域倒转过来，像是我们刚刚涂鸦的是非人物的部分，反转就会变成涂鸦人物的部分。这个选项默认是关闭的，如果开启了那么所涂鸦的区域就会变成“固定不变的区域”。
蒙版边缘羽化是默认开启的选项，目的是为了让固定区域和动态区域之间的过渡变得更加自然，如果感觉涂鸦部分和非涂鸦部分的边缘比较生硬，那么可以增大一些边缘羽化的数值。
上述两个操作可以帮助我们出图的效果更符合预期，但是这种用手涂鸦蒙版的方式显然还是会有点瑕疵，毕竟没法完美贴合自己想要绘制的范围。
所以需要用到智能抠图工具：Segment Anything组件（忽略红色部分）
这个组件里面有两个功能强大的节点可以帮助我们只能识别并选定图像中的区域：
这里面的Grounding DINO是一个强大的零样本检测器，能够根据文本描述来检测图像中的任意物体并且生成一个大致的范围。
另一个SAM（Segment Anything Model）节点可以在这个已经生成的区域中再去进行更仔细地切割。这个东西也是WebUI里面的Segment Anything扩展，用的是同样的技术。
这个节点的用法也很简单，在导入图片之后在右侧的Prompt里面输入想要画面动起来的元素的提示词。
然后其他的参数也可以维持不动或者看了上一篇文章的小伙伴自行进行调节，之后点击添加提示词队列进行生成即可。
当然，如果这个元素在画面中占据的比例太小的话是不会有动态效果的，而生成区域太过固定的情况下可能会造成出框的违和感，这样的情况下需要降低几个控制动态水平的参数会比较好。
**放大补帧
**
之前所生成的视频只有个位数帧以及1024*576，但是现在的视频往往都是1024*1024以及30帧的视频，而接下来的这个工作流可以帮生成的视频补帧。
可以在最左边导入SVD生成的视频，然后在这里设置放大宽度、帧数等的信息，这样一来就可以调用R-ESRGAN模型进行放大以及FILM模型进行补帧。
不过最终生成的格式可能是webp，不太适合一些剪辑软件的导入，这个时候需要安装一个Video Helper Suite.
**https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite
**
下载完后使用这里面的Video Combione节点替换为默认的Webp保存节点，然后在下方的输出格式改为mp4等常见的视频格式即可。
问题汇总：
这里不说废话，我这篇文花费最多时间的就是解决那些无法正常下载插件的问题。
可能有小伙伴在导入上述工作流的时候会遇到一些情况：
例如这样的红色节点或者提示报错出现问题，接下来我就来提供一下我自己尝试有用以及可能可以帮助到其他小伙伴的方法。
第一个管理界面进行丢失节点安装：
在遇到丢失节点的时候，可以先去右侧工具栏的Manager管理界面进行丢失节点下载：
在最右侧有个Install进行下载，需要等待一段时间因为是链接GitHub的，在下载完毕之后关闭ComfyUI以及后台命令行，然后重启ComfyUI。
第二种方法：下载到本地
如果第一种方式提示下载失败了则可以点击页面中的链接
然后网页会跳转到该插件的官方GitHub页面，点击最右侧的绿色Code，选择DownloadZIP
在下载完后解压到ComfyUI的这个位置：
然后重启ComfyUI和后台命令行。
第三种：通过更改环境进行下载
这个比较简单但是得一步一步跟着学，万不得已走到这一步的小伙伴可以看下这个视频进行参考（我就不占用太多篇幅了）
https://www.youtube.com/watch?v=yjCa9WALzAs
**第四种：确认一下自己的ComfyUI以及插件版本是否是最新版本
**
这一点我为什么不放在最上面说呢？这里因为有些情况是ComfyUI比较老但是插件版本太新了不兼容，如果上述方法都不好用的话可以检查更新一下ComfyUI的版本和插件的版本。
当然还可能有其他情况，例如一些命令行里面的问题，如果遇到这类问题可以去这个网址进行询问，直接复制粘贴问GPT就行，这是一个B站up做出来专门回答ComfyUI问题的bot。
**https://www.coze.com/store/bot/7332400218706690056?bid=MDQEECxYhmZ78fEPKTe4HJ69ZZwEHgi1ufmaBNV46fM1nkSRCzBTu6WcQmHyAPsY5c1ijwQA&amp;from=bots_card&amp;panel=1
**
今天的内容就到这里啦！
希望大伙都不要遇到我踩到的坑，也希望我的解决方案可以帮助到大家。">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-04-16T21:38:22+08:00">
    <meta property="article:modified_time" content="2024-04-16T21:38:22+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">让AI听话的一种办法（Stable Diffusion进阶篇：SVD 3）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>动态内容在上一篇笔记里学会了参数以及文生图生视频的操作，可能还是会有小伙伴觉得进行一些参数的改动或者就目前的产出结果还不到自己的预期。</p> 
<p><img src="https://images2.imgbox.com/08/1f/ubQdbPHn_o.gif" alt=""></p> 
<p>例如像是动作幅度太小，眼睛不够有神等，而也是SVD的一个缺点，它所产出的动态内容某种程度上是不可控的。</p> 
<p>就现阶段而言，要控制SVD去动某个部分或者那个部位不要动都是比较难控制的，而目前想要AI画出符合自己预期的结果则又需要反复的“抽卡”。</p> 
<p>当然ComfyUI的开发者们早就想到了这些，于是就有了一些节点可以动态控制画面的一部分区域，从而提高视频的可塑性。</p> 
<p>所以今天的内容就是要让AI学会怎么“听话”</p> 
<p><img src="https://images2.imgbox.com/0b/be/8c51CtIO_o.jpg" alt=""></p> 
<p>**蒙版<br> **</p> 
<p>蒙版这个东西之前学习Stable Diffusion的小伙伴们应该就很熟悉了，为了防止有小伙伴忘记了：</p> 
<p><img src="https://images2.imgbox.com/b5/f2/RNotsIXp_o.png" alt=""></p> 
<p>正是因为有了蒙版的存在，在用AI绘制时可以用蒙版来控制AI只重绘画面里的一小部分，而这样的方法也可以运用在视频生成部分。</p> 
<p>可能有些小伙伴知道Runway有一个运动笔刷功能可以做到这样的效果，ComfyUI也可以做到只让画面的一小部分动起来。在ComfyUI中有一个工作流：运动笔刷（下载链接在文末），直接将其拖拽进ComfyUI界面。</p> 
<p><img src="https://images2.imgbox.com/4c/04/dGMp8S2t_o.png" alt=""></p> 
<p>在工作流的最左边导入初始图片：</p> 
<p><img src="https://images2.imgbox.com/6a/e5/U8rjOGZv_o.png" alt=""></p> 
<p>然后鼠标右键点击图像，选择在**遮罩编辑器（MaskEditor）**中打开</p> 
<p><img src="https://images2.imgbox.com/ae/dd/kgX5hCOr_o.png" alt=""></p> 
<p>然后就可以在编辑器里面对想要更改的部分进行涂鸦画黑：</p> 
<p><img src="https://images2.imgbox.com/fa/53/6WkaCNmF_o.gif" alt=""></p> 
<p>记得完成之后点击最右下角的Save to Node</p> 
<p><img src="https://images2.imgbox.com/f7/48/8n8DVVSU_o.png" alt=""></p> 
<p>然后就进行一些常规的参数设置后（也可以直接先默认试试）就可以点击<strong>添加提示词队列</strong>进行生成啦！</p> 
<p>这个工作流里面还有其他的辅助功能选项：</p> 
<p><img src="https://images2.imgbox.com/96/86/rfCQLKoF_o.png" alt=""></p> 
<p>这里的两个选项：蒙版反转和蒙版边缘羽化。</p> 
<p>蒙版反转是会把蒙版控制的绘制区域倒转过来，像是我们刚刚涂鸦的是非人物的部分，反转就会变成涂鸦人物的部分。这个选项默认是关闭的，如果开启了那么所涂鸦的区域就会变成“固定不变的区域”。</p> 
<p>蒙版边缘羽化是默认开启的选项，目的是为了让固定区域和动态区域之间的过渡变得更加自然，如果感觉涂鸦部分和非涂鸦部分的边缘比较生硬，那么可以增大一些边缘羽化的数值。</p> 
<p>上述两个操作可以帮助我们出图的效果更符合预期，但是这种用手涂鸦蒙版的方式显然还是会有点瑕疵，毕竟没法完美贴合自己想要绘制的范围。</p> 
<p>所以需要用到智能抠图工具：Segment Anything组件（忽略红色部分）</p> 
<p><img src="https://images2.imgbox.com/8f/4e/0DdE3ZbF_o.png" alt=""></p> 
<p>这个组件里面有两个功能强大的节点可以帮助我们只能识别并选定图像中的区域：</p> 
<p><img src="https://images2.imgbox.com/0b/4b/GY99py13_o.png" alt=""></p> 
<p>这里面的Grounding DINO是一个强大的零样本检测器，能够根据文本描述来检测图像中的任意物体并且生成一个大致的范围。</p> 
<p>另一个SAM（Segment Anything Model）节点可以在这个已经生成的区域中再去进行更仔细地切割。这个东西也是WebUI里面的Segment Anything扩展，用的是同样的技术。</p> 
<p>这个节点的用法也很简单，在导入图片之后在右侧的Prompt里面输入想要画面动起来的元素的提示词。</p> 
<p><img src="https://images2.imgbox.com/af/f9/vHqxyDRo_o.png" alt=""></p> 
<p>然后其他的参数也可以维持不动或者看了上一篇文章的小伙伴自行进行调节，之后点击<strong>添加提示词队列</strong>进行生成即可。</p> 
<p>当然，如果这个元素在画面中占据的比例太小的话是不会有动态效果的，而生成区域太过固定的情况下可能会造成出框的违和感，这样的情况下需要降低几个控制动态水平的参数会比较好。</p> 
<p>**放大补帧<br> **</p> 
<p>之前所生成的视频只有个位数帧以及1024*576，但是现在的视频往往都是1024*1024以及30帧的视频，而接下来的这个工作流可以帮生成的视频补帧。</p> 
<p><img src="https://images2.imgbox.com/d7/6c/pLQLpJ4R_o.png" alt=""></p> 
<p>可以在最左边导入SVD生成的视频，然后在这里设置放大宽度、帧数等的信息，这样一来就可以调用R-ESRGAN模型进行放大以及FILM模型进行补帧。</p> 
<p>不过最终生成的格式可能是webp，不太适合一些剪辑软件的导入，这个时候需要安装一个Video Helper Suite.</p> 
<p><img src="https://images2.imgbox.com/4b/ae/6rUxEkTM_o.png" alt=""></p> 
<p>**https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite<br> **</p> 
<p>下载完后使用这里面的Video Combione节点替换为默认的Webp保存节点，然后在下方的输出格式改为mp4等常见的视频格式即可。</p> 
<p><strong>问题汇总：</strong></p> 
<p>这里不说废话，我这篇文花费最多时间的就是解决那些无法正常下载插件的问题。</p> 
<p>可能有小伙伴在导入上述工作流的时候会遇到一些情况：</p> 
<p><img src="https://images2.imgbox.com/db/85/MxTUnI5v_o.png" alt=""></p> 
<p><img src="https://images2.imgbox.com/5c/7f/vxiaY5NS_o.png" alt=""></p> 
<p>例如这样的红色节点或者提示报错出现问题，接下来我就来提供一下我自己尝试有用以及可能可以帮助到其他小伙伴的方法。</p> 
<p><strong>第一个管理界面进行丢失节点安装：</strong></p> 
<p>在遇到丢失节点的时候，可以先去右侧工具栏的Manager管理界面进行丢失节点下载：</p> 
<p><img src="https://images2.imgbox.com/f5/07/73n2DAte_o.jpg" alt=""></p> 
<p><img src="https://images2.imgbox.com/99/9f/bBV4atqO_o.png" alt=""></p> 
<p><img src="https://images2.imgbox.com/50/70/W6ZhfNuJ_o.png" alt=""></p> 
<p>在最右侧有个Install进行下载，需要等待一段时间因为是链接GitHub的，在下载完毕之后关闭ComfyUI以及后台命令行，然后重启ComfyUI。</p> 
<p><strong>第二种方法：下载到本地</strong></p> 
<p>如果第一种方式提示下载失败了则可以点击页面中的链接</p> 
<p><img src="https://images2.imgbox.com/e6/4d/HUo0f7w7_o.png" alt=""></p> 
<p>然后网页会跳转到该插件的官方GitHub页面，点击最右侧的绿色Code，选择DownloadZIP</p> 
<p><img src="https://images2.imgbox.com/3f/0c/nv1aXet7_o.png" alt=""></p> 
<p>在下载完后解压到ComfyUI的这个位置：</p> 
<p><img src="https://images2.imgbox.com/2e/cc/a0fP6IOo_o.png" alt=""></p> 
<p><img src="https://images2.imgbox.com/d8/ea/yGo1Pb3c_o.gif" alt=""></p> 
<p>然后重启ComfyUI和后台命令行。</p> 
<p><strong>第三种：通过更改环境进行下载</strong></p> 
<p>这个比较简单但是得一步一步跟着学，万不得已走到这一步的小伙伴可以看下这个视频进行参考（我就不占用太多篇幅了）</p> 
<p><img src="https://images2.imgbox.com/6b/7d/D8BsjePC_o.png" alt=""></p> 
<p><strong>https://www.youtube.com/watch?v=yjCa9WALzAs</strong></p> 
<p>**第四种：确认一下自己的ComfyUI以及插件版本是否是最新版本<br> **</p> 
<p><img src="https://images2.imgbox.com/2f/3c/RQ4AHKA3_o.png" alt=""></p> 
<p>这一点我为什么不放在最上面说呢？这里因为有些情况是ComfyUI比较老但是插件版本太新了不兼容，如果上述方法都不好用的话可以检查更新一下ComfyUI的版本和插件的版本。</p> 
<p>当然还可能有其他情况，例如一些命令行里面的问题，如果遇到这类问题可以去这个网址进行询问，直接复制粘贴问GPT就行，这是一个B站up做出来专门回答ComfyUI问题的bot。</p> 
<p><img src="https://images2.imgbox.com/20/77/wQFw7moE_o.png" alt=""></p> 
<p>**https://www.coze.com/store/bot/7332400218706690056?bid=MDQEECxYhmZ78fEPKTe4HJ69ZZwEHgi1ufmaBNV46fM1nkSRCzBTu6WcQmHyAPsY5c1ijwQA&amp;from=bots_card&amp;panel=1<br> **</p> 
<p>今天的内容就到这里啦！</p> 
<p>希望大伙都不要遇到我踩到的坑，也希望我的解决方案可以帮助到大家。</p> 
<p>大伙下篇笔记见，拜了个拜！</p> 
<p><img src="https://images2.imgbox.com/88/8e/YwI8L474_o.png" alt=""></p> 
<p><strong>1girl, necklace, jewelry, solo, long_hair, gem, blue_eyes, red_lips, lips, tiara, pendant, pearl_necklace, bubble, beautiful girl</strong></p> 
<p><strong>Negative prompt:</strong> <strong>(worst quality, low quality:1.4),deformed, bad anatomy, disfigured, poorly drawn face, mutation, mutated, extra limb, ugly, disgusting, poorly drawn hands, missing limb, floating limbs, disconnected limbs, malformed hands, blurry, ((((mutated hands and fingers)))), watermark, watermarked, oversaturated, censored, distorted hands, amputation, missing hands, obese, doubled face, double hands,(((missing arms))),(((missing legs))), (((extra arms))),(((extra legs))), badhandsv5, badhandv4, deepnegative</strong></p> 
<ul><li> <p><strong>Steps: 30</strong></p> </li><li> <p><strong>Sampler: DPM++ 2M Karras</strong></p> </li><li> <p><strong>CFG scale: 7</strong></p> </li><li> <p><strong>Seed: 4068954081</strong></p> </li><li> <p><strong>Size: 512x512</strong></p> </li><li> <p><strong>Model hash: 7c819b6d13</strong></p> </li><li> <p><strong>Model: majicmixRealistic_v7</strong></p> </li><li> <p><strong>Denoising strength: 0.7</strong></p> </li><li> <p><strong>Clip skip: 2</strong></p> </li><li> <p><strong>Hires upscale: 3</strong></p> </li><li> <p><strong>Hires upscaler: R-ESRGAN 4x+</strong></p> </li><li> <p><strong>Pad conds: True</strong></p> </li><li> <p><strong>Version: v1.8.0</strong></p> </li></ul> 
<p>**部分文章素材来源<br> **</p> 
<p>原教程链接（下载链接在原视频简介中）：</p> 
<p><strong>https://www.bilibili.com/video/BV1iZ421t7Ax/?spm_id_from=333.337.search-card.all.click&amp;vd_source=24f33eddf5587fb40e947798abce6715</strong></p> 
<p>100%解决问题！ComfyUI-安装报错问题的一系列终极解决办法_哔哩哔哩_bilibili</p> 
<p>Aihelper帮助解决ComfyUI报错问题解决+怎么查看报错信息只需要这个3个工具基本能解决ComfyUI85%的问题_哔哩哔哩_bilibili</p> 
<h3><a id="_235"></a>写在最后</h3> 
<p><font face="幼圆" size="4" color="red">感兴趣的小伙伴，赠送全套AIGC学习资料，包含AI绘画、AI人工智能等前沿科技教程和软件工具，具体看这里。<br> </font><br> <img src="https://images2.imgbox.com/fd/c9/dBDDvlDp_o.png" alt="在这里插入图片描述"></p> 
<p>AIGC技术的未来发展前景广阔，随着人工智能技术的不断发展，AIGC技术也将不断提高。未来，AIGC技术将在游戏和计算领域得到更广泛的应用，使游戏和计算系统具有更高效、更智能、更灵活的特性。同时，AIGC技术也将与人工智能技术紧密结合，在更多的领域得到广泛应用，对程序员来说影响至关重要。未来，AIGC技术将继续得到提高，同时也将与人工智能技术紧密结合，在更多的领域得到广泛应用。<br>  <br> <img src="https://images2.imgbox.com/9b/cb/b8AsCLyH_o.png" alt="在这里插入图片描述"></p> 
<p><strong>一、AIGC所有方向的学习路线</strong></p> 
<p>AIGC所有方向的技术点做的整理，形成各个领域的知识点汇总，它的用处就在于，你可以按照下面的知识点去找对应的学习资源，保证自己学得较为全面。</p> 
<p><img src="https://images2.imgbox.com/72/fb/8i519MhW_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/9b/45/cWDgObDM_o.png" alt="在这里插入图片描述"></p> 
<p><strong>二、AIGC必备工具</strong></p> 
<p>工具都帮大家整理好了，安装就可直接上手！<br> <img src="https://images2.imgbox.com/94/06/uz1jRWiK_o.png" alt="在这里插入图片描述"></p> 
<p><strong>三、最新AIGC学习笔记</strong></p> 
<p>当我学到一定基础，有自己的理解能力的时候，会去阅读一些前辈整理的书籍或者手写的笔记资料，这些笔记详细记载了他们对一些技术点的理解，这些理解是比较独到，可以学到不一样的思路。<br> <img src="https://images2.imgbox.com/51/ed/RYVMLAHL_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/bb/bf/BT69jBsZ_o.png" alt="在这里插入图片描述"></p> 
<p><strong>四、AIGC视频教程合集</strong></p> 
<p>观看全面零基础学习视频，看视频学习是最快捷也是最有效果的方式，跟着视频中老师的思路，从基础到深入，还是很容易入门的。</p> 
<p><img src="https://images2.imgbox.com/a0/a1/avziIHRU_o.png" alt="在这里插入图片描述"></p> 
<p><strong>五、实战案例</strong></p> 
<p>纸上得来终觉浅，要学会跟着视频一起敲，要动手实操，才能将自己的所学运用到实际当中去，这时候可以搞点实战案例来学习。<br> <img src="https://images2.imgbox.com/1a/d1/AuEPzH87_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/c6/cb/oUHLUDv9_o.png" alt="在这里插入图片描述"></p> 
<p>若有侵权，请联系删除</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/48c5f7d2c3cd7a203df64bc0d3a92279/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">大数据快速搭建环境 CDH QuickStart VM虚拟机版本安装</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/60d365281da5e5497db964c6174b8520/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">SQL2000在win10上安装的方法</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>