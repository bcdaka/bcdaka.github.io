<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【自然语言处理】0821学习记录 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/561cf29cc9c601a031ee186eb43a12c9/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="【自然语言处理】0821学习记录">
  <meta property="og:description" content="1.对于自然语言来讲，在自然语言处理的第一步，我们要面对的是各种各样以不同形式表现的文本数据，比如，有的是纯 txt 文档，有的是存储在 Excel 中的表格数据，还有的是无法直接打开的 pkl 文件等。
2.整体框架如下：
2.1 txt 文本的读写
(1) write()
(2) open()
(3) 参数mode
(4) readline() read read()不同点
2.2 CSV以及Excel的文本读写
2.3 data Frame的操作
获取某行某列
根据条件获取部分数据
进行数据可视化
2.4 数据规模太大怎么处理
（1）压缩文件
（2）使用精确度更低的数据类型
（3）拆分数据分成块
open() 函数用于打开一个文件，创建一个 file 对象，之后，相关的方法才可以调用它进行更多的操作。 对于 open() 函数，我们主要关注三个传入的参数：
file: 文件路径（相对或者绝对路径）。
mode: 文件打开模式。
encoding: 编码格式，一般使用 utf-8。
其中，mode 决定了打开文件的模式，也就是限定了可以对文件做什么样的操作，比如只读，写入，追加等，这个参数是非强制的，默认文件访问模式为只读 ®，以下是常用的模式：
r : 读取文件，若文件不存在则会报错。
w: 写入文件，若文件不存在则会先创建再写入，若存在则会覆盖原文件。
a : 写入文件，若文件不存在则会先创建再写入，若存在不会覆盖原文件，而是在文件中继续写入内容。
rb, wb：分别与 r, w 类似，但用于读写二进制文件。
r&#43; : 可读、可写，若文件不存在会报错，在写操作时会覆盖原文件。
w&#43; : 可读，可写，文件不存在先创建，若存在会覆盖。">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-08-21T14:44:32+08:00">
    <meta property="article:modified_time" content="2024-08-21T14:44:32+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【自然语言处理】0821学习记录</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>1.对于自然语言来讲，在自然语言处理的第一步，我们要面对的是各种各样以不同形式表现的文本数据，比如，有的是纯 txt 文档，有的是存储在 Excel 中的表格数据，还有的是无法直接打开的 pkl 文件等。</p> 
<p>2.整体框架如下：<br> 2.1 txt 文本的读写<br> (1) write()<br> (2) open()<br> (3) 参数mode<br> (4) readline() read read()不同点</p> 
<p>2.2 CSV以及Excel的文本读写</p> 
<p>2.3 data Frame的操作<br> 获取某行某列<br> 根据条件获取部分数据<br> 进行数据可视化</p> 
<p>2.4 数据规模太大怎么处理<br> （1）压缩文件<br> （2）使用精确度更低的数据类型<br> （3）拆分数据分成块</p> 
<hr> 
<p>open() 函数用于打开一个文件，创建一个 file 对象，之后，相关的方法才可以调用它进行更多的操作。 对于 open() 函数，我们主要关注三个传入的参数：</p> 
<p>file: 文件路径（相对或者绝对路径）。<br> mode: 文件打开模式。<br> encoding: 编码格式，一般使用 utf-8。<br> 其中，mode 决定了打开文件的模式，也就是限定了可以对文件做什么样的操作，比如只读，写入，追加等，这个参数是非强制的，默认文件访问模式为只读 ®，以下是常用的模式：</p> 
<p>r : 读取文件，若文件不存在则会报错。<br> w: 写入文件，若文件不存在则会先创建再写入，若存在则会覆盖原文件。<br> a : 写入文件，若文件不存在则会先创建再写入，若存在不会覆盖原文件，而是在文件中继续写入内容。<br> rb, wb：分别与 r, w 类似，但用于读写二进制文件。<br> r+ : 可读、可写，若文件不存在会报错，在写操作时会覆盖原文件。<br> w+ : 可读，可写，文件不存在先创建，若存在会覆盖。<br> a+ ：可读、可写，文件不存在先创建，若不存在不会覆盖，在文件中继续写入内容。<br> 注：utf-8（8 位元，Universal Character Set/Unicode Transformation Format）是针对 Unicode 的一种可变长度字符编码。它可以用来表示 Unicode 标准中的任何字符，而且其编码中的第一个字节仍与 ASCII 相容，使得原来处理 ASCII 字符的软件无须或只进行少部份修改后，便可继续使用。因此，它逐渐成为电子邮件、网页及其他存储或传送文字的应用中，优先采用的编码。</p> 
<pre><code class="prism language-python">!wget <span class="token operator">-</span>nc <span class="token string">"https://labfile.oss.aliyuncs.com/courses/3205/idiom.txt"</span>
</code></pre> 
<p>读取文件 “idiom.txt” 中的内容并打印出来：<br> f = open(“idiom.txt”,“r”, encoding=“utf-8”)<br> poem = f.readlines()<br> print(type(poem), poem) # 从结果可见，readlines() 方法会返回一个 list，包含所有的行，每一行为 list 中的一个元素</p> 
<hr> 
<p>通过以上的小练习，我们知道了 readlines() 方法的特点是，每次按行读取整个文件内容，将读取到的内容放到一个列表中，返回 list 类型。事实上，还存在另外两种读取方法：</p> 
<p>read()：读取整个文件，将文件内容放到一个 str 类型的变量中，但是，如果文件非常大，尤其是大于内存时，无法使用 read() 方法。<br> readline()：每次只读取文件的一行，即读取到的一行内容放到一个字符串变量中，返回 str 类型。可以在文件过大，内存不够时使用。</p> 
<hr> 
<p>read() 方法：</p> 
<pre><code class="prism language-python">f <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"poem.txt"</span><span class="token punctuation">,</span><span class="token string">"r"</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">"utf-8"</span><span class="token punctuation">)</span>
poem <span class="token operator">=</span> f<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token punctuation">(</span>poem<span class="token punctuation">)</span><span class="token punctuation">,</span> poem<span class="token punctuation">)</span>  <span class="token comment"># 返回的是一个包含所有内容的 str 类型的变量</span>
</code></pre> 
<hr> 
<p>readline() 方法：</p> 
<pre><code class="prism language-python">f <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"poem.txt"</span><span class="token punctuation">,</span><span class="token string">"r"</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">"utf-8"</span><span class="token punctuation">)</span>
<span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>
    poem_line <span class="token operator">=</span> f<span class="token punctuation">.</span>readline<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> poem_line<span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token punctuation">(</span>poem_line<span class="token punctuation">)</span><span class="token punctuation">,</span> poem_line<span class="token punctuation">)</span>  <span class="token comment"># 分次返回每一行</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token keyword">break</span>
</code></pre> 
<hr> 
<p>以上利用 open() 函数实现了 txt 文件的读取，接下来，我们希望应用 write() 函数，实现写入一个 txt 文件。</p> 
<pre><code class="prism language-python"><span class="token comment"># 将一些俗语写入至文件 idiom.txt 中</span>
idiom <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"路遥知马力，日久见人心。"</span><span class="token punctuation">,</span> <span class="token string">"千学不如一看，千看不如一练。"</span><span class="token punctuation">,</span> <span class="token string">"岁寒知松柏，患难见交情。"</span><span class="token punctuation">]</span>
f <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'idiom.txt'</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> text <span class="token keyword">in</span> idiom<span class="token punctuation">:</span>
    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"\n"</span><span class="token punctuation">)</span>  <span class="token comment"># 注意每写一句要换行一次，否则所有文字会粘在一行中</span>
</code></pre> 
<hr> 
<p>写入文件之后，我们可以通过 Linux 命令查看当前目录下是否存在相应文件。</p> 
<pre><code class="prism language-python">!ls
<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
有时候，我们希望在一个已存在的 txt 文件中，继续写入东西，这时候 mode 要选择 “a”，如果选择 “w”，新写入的内容会覆盖原来的内容。

```python
f <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'idiom.txt'</span><span class="token punctuation">,</span> <span class="token string">'a'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>
f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">"好好学习，天天向上。"</span><span class="token punctuation">)</span>
</code></pre> 
<hr> 
<p>CSV 及 Excel 文本数据的读写<br> 首先，在这里给大家介绍 Pandas，这是一个功能强大且灵活的 Python 软件包，具有读写 Excel，CSV 以及更多其他类型文件的能力，另外，它还提供统计方法，绘图等功能。在接下来的教程中，我们基于 Pandas 对不同类型的文件数据进行操作。</p> 
<p>对于 CSV 类型的文件，可调用 Pandas 中的 to_csv() 以及 read_csv() 函数，轻松实现写入或者读取。<br> ``</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token comment"># 这是我们的数据</span>
data <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token string">'CHN'</span><span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">'COUNTRY'</span><span class="token punctuation">:</span> <span class="token string">'China'</span><span class="token punctuation">,</span> <span class="token string">'POP'</span><span class="token punctuation">:</span> <span class="token number">1_398.72</span><span class="token punctuation">,</span> <span class="token string">'AREA'</span><span class="token punctuation">:</span> <span class="token number">9_596.96</span><span class="token punctuation">,</span>
            <span class="token string">'GDP'</span><span class="token punctuation">:</span> <span class="token number">12_234.78</span><span class="token punctuation">,</span> <span class="token string">'CONT'</span><span class="token punctuation">:</span> <span class="token string">'Asia'</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token string">'IND'</span><span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">'COUNTRY'</span><span class="token punctuation">:</span> <span class="token string">'India'</span><span class="token punctuation">,</span> <span class="token string">'POP'</span><span class="token punctuation">:</span> <span class="token number">1_351.16</span><span class="token punctuation">,</span> <span class="token string">'AREA'</span><span class="token punctuation">:</span> <span class="token number">3_287.26</span><span class="token punctuation">,</span>
            <span class="token string">'GDP'</span><span class="token punctuation">:</span> <span class="token number">2_575.67</span><span class="token punctuation">,</span> <span class="token string">'CONT'</span><span class="token punctuation">:</span> <span class="token string">'Asia'</span><span class="token punctuation">,</span> <span class="token string">'IND_DAY'</span><span class="token punctuation">:</span> <span class="token string">'1947-08-15'</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token string">'USA'</span><span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">'COUNTRY'</span><span class="token punctuation">:</span> <span class="token string">'US'</span><span class="token punctuation">,</span> <span class="token string">'POP'</span><span class="token punctuation">:</span> <span class="token number">329.74</span><span class="token punctuation">,</span> <span class="token string">'AREA'</span><span class="token punctuation">:</span> <span class="token number">9_833.52</span><span class="token punctuation">,</span>
            <span class="token string">'GDP'</span><span class="token punctuation">:</span> <span class="token number">19_485.39</span><span class="token punctuation">,</span> <span class="token string">'CONT'</span><span class="token punctuation">:</span> <span class="token string">'N.America'</span><span class="token punctuation">,</span>
            <span class="token string">'IND_DAY'</span><span class="token punctuation">:</span> <span class="token string">'1776-07-04'</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token string">'IDN'</span><span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">'COUNTRY'</span><span class="token punctuation">:</span> <span class="token string">'Indonesia'</span><span class="token punctuation">,</span> <span class="token string">'POP'</span><span class="token punctuation">:</span> <span class="token number">268.07</span><span class="token punctuation">,</span> <span class="token string">'AREA'</span><span class="token punctuation">:</span> <span class="token number">1_910.93</span><span class="token punctuation">,</span>
            <span class="token string">'GDP'</span><span class="token punctuation">:</span> <span class="token number">1_015.54</span><span class="token punctuation">,</span> <span class="token string">'CONT'</span><span class="token punctuation">:</span> <span class="token string">'Asia'</span><span class="token punctuation">,</span> <span class="token string">'IND_DAY'</span><span class="token punctuation">:</span> <span class="token string">'1945-08-17'</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token string">'BRA'</span><span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">'COUNTRY'</span><span class="token punctuation">:</span> <span class="token string">'Brazil'</span><span class="token punctuation">,</span> <span class="token string">'POP'</span><span class="token punctuation">:</span> <span class="token number">210.32</span><span class="token punctuation">,</span> <span class="token string">'AREA'</span><span class="token punctuation">:</span> <span class="token number">8_515.77</span><span class="token punctuation">,</span>
            <span class="token string">'GDP'</span><span class="token punctuation">:</span> <span class="token number">2_055.51</span><span class="token punctuation">,</span> <span class="token string">'CONT'</span><span class="token punctuation">:</span> <span class="token string">'S.America'</span><span class="token punctuation">,</span> <span class="token string">'IND_DAY'</span><span class="token punctuation">:</span> <span class="token string">'1822-09-07'</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token string">'PAK'</span><span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">'COUNTRY'</span><span class="token punctuation">:</span> <span class="token string">'Pakistan'</span><span class="token punctuation">,</span> <span class="token string">'POP'</span><span class="token punctuation">:</span> <span class="token number">205.71</span><span class="token punctuation">,</span> <span class="token string">'AREA'</span><span class="token punctuation">:</span> <span class="token number">881.91</span><span class="token punctuation">,</span>
            <span class="token string">'GDP'</span><span class="token punctuation">:</span> <span class="token number">302.14</span><span class="token punctuation">,</span> <span class="token string">'CONT'</span><span class="token punctuation">:</span> <span class="token string">'Asia'</span><span class="token punctuation">,</span> <span class="token string">'IND_DAY'</span><span class="token punctuation">:</span> <span class="token string">'1947-08-14'</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token string">'NGA'</span><span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">'COUNTRY'</span><span class="token punctuation">:</span> <span class="token string">'Nigeria'</span><span class="token punctuation">,</span> <span class="token string">'POP'</span><span class="token punctuation">:</span> <span class="token number">200.96</span><span class="token punctuation">,</span> <span class="token string">'AREA'</span><span class="token punctuation">:</span> <span class="token number">923.77</span><span class="token punctuation">,</span>
            <span class="token string">'GDP'</span><span class="token punctuation">:</span> <span class="token number">375.77</span><span class="token punctuation">,</span> <span class="token string">'CONT'</span><span class="token punctuation">:</span> <span class="token string">'Africa'</span><span class="token punctuation">,</span> <span class="token string">'IND_DAY'</span><span class="token punctuation">:</span> <span class="token string">'1960-10-01'</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token string">'BGD'</span><span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">'COUNTRY'</span><span class="token punctuation">:</span> <span class="token string">'Bangladesh'</span><span class="token punctuation">,</span> <span class="token string">'POP'</span><span class="token punctuation">:</span> <span class="token number">167.09</span><span class="token punctuation">,</span> <span class="token string">'AREA'</span><span class="token punctuation">:</span> <span class="token number">147.57</span><span class="token punctuation">,</span>
            <span class="token string">'GDP'</span><span class="token punctuation">:</span> <span class="token number">245.63</span><span class="token punctuation">,</span> <span class="token string">'CONT'</span><span class="token punctuation">:</span> <span class="token string">'Asia'</span><span class="token punctuation">,</span> <span class="token string">'IND_DAY'</span><span class="token punctuation">:</span> <span class="token string">'1971-03-26'</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token string">'RUS'</span><span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">'COUNTRY'</span><span class="token punctuation">:</span> <span class="token string">'Russia'</span><span class="token punctuation">,</span> <span class="token string">'POP'</span><span class="token punctuation">:</span> <span class="token number">146.79</span><span class="token punctuation">,</span> <span class="token string">'AREA'</span><span class="token punctuation">:</span> <span class="token number">17_098.25</span><span class="token punctuation">,</span>
            <span class="token string">'GDP'</span><span class="token punctuation">:</span> <span class="token number">1_530.75</span><span class="token punctuation">,</span> <span class="token string">'IND_DAY'</span><span class="token punctuation">:</span> <span class="token string">'1992-06-12'</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token string">'MEX'</span><span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">'COUNTRY'</span><span class="token punctuation">:</span> <span class="token string">'Mexico'</span><span class="token punctuation">,</span> <span class="token string">'POP'</span><span class="token punctuation">:</span> <span class="token number">126.58</span><span class="token punctuation">,</span> <span class="token string">'AREA'</span><span class="token punctuation">:</span> <span class="token number">1_964.38</span><span class="token punctuation">,</span>
            <span class="token string">'GDP'</span><span class="token punctuation">:</span> <span class="token number">1_158.23</span><span class="token punctuation">,</span> <span class="token string">'CONT'</span><span class="token punctuation">:</span> <span class="token string">'N.America'</span><span class="token punctuation">,</span> <span class="token string">'IND_DAY'</span><span class="token punctuation">:</span> <span class="token string">'1810-09-16'</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token string">'JPN'</span><span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">'COUNTRY'</span><span class="token punctuation">:</span> <span class="token string">'Japan'</span><span class="token punctuation">,</span> <span class="token string">'POP'</span><span class="token punctuation">:</span> <span class="token number">126.22</span><span class="token punctuation">,</span> <span class="token string">'AREA'</span><span class="token punctuation">:</span> <span class="token number">377.97</span><span class="token punctuation">,</span>
            <span class="token string">'GDP'</span><span class="token punctuation">:</span> <span class="token number">4_872.42</span><span class="token punctuation">,</span> <span class="token string">'CONT'</span><span class="token punctuation">:</span> <span class="token string">'Asia'</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token string">'DEU'</span><span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">'COUNTRY'</span><span class="token punctuation">:</span> <span class="token string">'Germany'</span><span class="token punctuation">,</span> <span class="token string">'POP'</span><span class="token punctuation">:</span> <span class="token number">83.02</span><span class="token punctuation">,</span> <span class="token string">'AREA'</span><span class="token punctuation">:</span> <span class="token number">357.11</span><span class="token punctuation">,</span>
            <span class="token string">'GDP'</span><span class="token punctuation">:</span> <span class="token number">3_693.20</span><span class="token punctuation">,</span> <span class="token string">'CONT'</span><span class="token punctuation">:</span> <span class="token string">'Europe'</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token string">'FRA'</span><span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">'COUNTRY'</span><span class="token punctuation">:</span> <span class="token string">'France'</span><span class="token punctuation">,</span> <span class="token string">'POP'</span><span class="token punctuation">:</span> <span class="token number">67.02</span><span class="token punctuation">,</span> <span class="token string">'AREA'</span><span class="token punctuation">:</span> <span class="token number">640.68</span><span class="token punctuation">,</span>
            <span class="token string">'GDP'</span><span class="token punctuation">:</span> <span class="token number">2_582.49</span><span class="token punctuation">,</span> <span class="token string">'CONT'</span><span class="token punctuation">:</span> <span class="token string">'Europe'</span><span class="token punctuation">,</span> <span class="token string">'IND_DAY'</span><span class="token punctuation">:</span> <span class="token string">'1789-07-14'</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token string">'GBR'</span><span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">'COUNTRY'</span><span class="token punctuation">:</span> <span class="token string">'UK'</span><span class="token punctuation">,</span> <span class="token string">'POP'</span><span class="token punctuation">:</span> <span class="token number">66.44</span><span class="token punctuation">,</span> <span class="token string">'AREA'</span><span class="token punctuation">:</span> <span class="token number">242.50</span><span class="token punctuation">,</span>
            <span class="token string">'GDP'</span><span class="token punctuation">:</span> <span class="token number">2_631.23</span><span class="token punctuation">,</span> <span class="token string">'CONT'</span><span class="token punctuation">:</span> <span class="token string">'Europe'</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token string">'ITA'</span><span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">'COUNTRY'</span><span class="token punctuation">:</span> <span class="token string">'Italy'</span><span class="token punctuation">,</span> <span class="token string">'POP'</span><span class="token punctuation">:</span> <span class="token number">60.36</span><span class="token punctuation">,</span> <span class="token string">'AREA'</span><span class="token punctuation">:</span> <span class="token number">301.34</span><span class="token punctuation">,</span>
            <span class="token string">'GDP'</span><span class="token punctuation">:</span> <span class="token number">1_943.84</span><span class="token punctuation">,</span> <span class="token string">'CONT'</span><span class="token punctuation">:</span> <span class="token string">'Europe'</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token string">'ARG'</span><span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">'COUNTRY'</span><span class="token punctuation">:</span> <span class="token string">'Argentina'</span><span class="token punctuation">,</span> <span class="token string">'POP'</span><span class="token punctuation">:</span> <span class="token number">44.94</span><span class="token punctuation">,</span> <span class="token string">'AREA'</span><span class="token punctuation">:</span> <span class="token number">2_780.40</span><span class="token punctuation">,</span>
            <span class="token string">'GDP'</span><span class="token punctuation">:</span> <span class="token number">637.49</span><span class="token punctuation">,</span> <span class="token string">'CONT'</span><span class="token punctuation">:</span> <span class="token string">'S.America'</span><span class="token punctuation">,</span> <span class="token string">'IND_DAY'</span><span class="token punctuation">:</span> <span class="token string">'1816-07-09'</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token string">'DZA'</span><span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">'COUNTRY'</span><span class="token punctuation">:</span> <span class="token string">'Algeria'</span><span class="token punctuation">,</span> <span class="token string">'POP'</span><span class="token punctuation">:</span> <span class="token number">43.38</span><span class="token punctuation">,</span> <span class="token string">'AREA'</span><span class="token punctuation">:</span> <span class="token number">2_381.74</span><span class="token punctuation">,</span>
            <span class="token string">'GDP'</span><span class="token punctuation">:</span> <span class="token number">167.56</span><span class="token punctuation">,</span> <span class="token string">'CONT'</span><span class="token punctuation">:</span> <span class="token string">'Africa'</span><span class="token punctuation">,</span> <span class="token string">'IND_DAY'</span><span class="token punctuation">:</span> <span class="token string">'1962-07-05'</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token string">'CAN'</span><span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">'COUNTRY'</span><span class="token punctuation">:</span> <span class="token string">'Canada'</span><span class="token punctuation">,</span> <span class="token string">'POP'</span><span class="token punctuation">:</span> <span class="token number">37.59</span><span class="token punctuation">,</span> <span class="token string">'AREA'</span><span class="token punctuation">:</span> <span class="token number">9_984.67</span><span class="token punctuation">,</span>
            <span class="token string">'GDP'</span><span class="token punctuation">:</span> <span class="token number">1_647.12</span><span class="token punctuation">,</span> <span class="token string">'CONT'</span><span class="token punctuation">:</span> <span class="token string">'N.America'</span><span class="token punctuation">,</span> <span class="token string">'IND_DAY'</span><span class="token punctuation">:</span> <span class="token string">'1867-07-01'</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token string">'AUS'</span><span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">'COUNTRY'</span><span class="token punctuation">:</span> <span class="token string">'Australia'</span><span class="token punctuation">,</span> <span class="token string">'POP'</span><span class="token punctuation">:</span> <span class="token number">25.47</span><span class="token punctuation">,</span> <span class="token string">'AREA'</span><span class="token punctuation">:</span> <span class="token number">7_692.02</span><span class="token punctuation">,</span>
            <span class="token string">'GDP'</span><span class="token punctuation">:</span> <span class="token number">1_408.68</span><span class="token punctuation">,</span> <span class="token string">'CONT'</span><span class="token punctuation">:</span> <span class="token string">'Oceania'</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token string">'KAZ'</span><span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span><span class="token string">'COUNTRY'</span><span class="token punctuation">:</span> <span class="token string">'Kazakhstan'</span><span class="token punctuation">,</span> <span class="token string">'POP'</span><span class="token punctuation">:</span> <span class="token number">18.53</span><span class="token punctuation">,</span> <span class="token string">'AREA'</span><span class="token punctuation">:</span> <span class="token number">2_724.90</span><span class="token punctuation">,</span>
            <span class="token string">'GDP'</span><span class="token punctuation">:</span> <span class="token number">159.41</span><span class="token punctuation">,</span> <span class="token string">'CONT'</span><span class="token punctuation">:</span> <span class="token string">'Asia'</span><span class="token punctuation">,</span> <span class="token string">'IND_DAY'</span><span class="token punctuation">:</span> <span class="token string">'1991-12-16'</span><span class="token punctuation">}</span>
<span class="token punctuation">}</span>

columns <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">'COUNTRY'</span><span class="token punctuation">,</span> <span class="token string">'POP'</span><span class="token punctuation">,</span> <span class="token string">'AREA'</span><span class="token punctuation">,</span> <span class="token string">'GDP'</span><span class="token punctuation">,</span> <span class="token string">'CONT'</span><span class="token punctuation">,</span> <span class="token string">'IND_DAY'</span><span class="token punctuation">)</span>
<span class="token comment"># 需要应用 DataFrame 构造函数将 data 创建一个 DataFrame 对象，才能写入文件</span>
df <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>data<span class="token operator">=</span>data<span class="token punctuation">)</span>
</code></pre> 
<hr> 
<pre><code class="prism language-python">df  <span class="token comment"># 查看数据</span>
</code></pre> 
<hr> 
<h2><a id="_162"></a>将数据进行转置</h2> 
<pre><code class="prism language-python">df <span class="token operator">=</span> df<span class="token punctuation">.</span>T
df
</code></pre> 
<p>接下来，应用 to_csv() 将以上内容写入一个 CSV 文件中。</p> 
<pre><code class="prism language-python">df<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span><span class="token string">'20_country.csv'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">"utf-8"</span><span class="token punctuation">)</span>  <span class="token comment"># 写入 CSV 文件</span>
</code></pre> 
<p>应用 read_csv() 则可以读取刚刚生成的 CSV 文件。</p> 
<pre><code class="prism language-python"><span class="token comment"># 读取 CSV 文件</span>
<span class="token comment"># 使用 index_col = 0，表示直接将第一列作为索引</span>
df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'20_country.csv'</span><span class="token punctuation">,</span> index_col<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
df
<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>

对于 Excel 文件，如法炮制，调用 Pandas 中的 to_excel<span class="token punctuation">(</span><span class="token punctuation">)</span> 以及 read_excel<span class="token punctuation">(</span><span class="token punctuation">)</span> 函数，轻松实现写入或者读取。如果我们操作的对象是以 <span class="token punctuation">.</span>xlsx 为后缀的 Excel 文件，还需要安装库 openpyxl，线上环境已经预装了 openpyxl。

```python
df<span class="token punctuation">.</span>to_excel<span class="token punctuation">(</span><span class="token string">'20_country.xlsx'</span><span class="token punctuation">)</span>  <span class="token comment"># 写入 .xlsx 文件</span>
<span class="token comment"># read_excel() 则可以读取 csv 文件</span>
df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_excel<span class="token punctuation">(</span><span class="token string">'20_country.xlsx'</span><span class="token punctuation">,</span> index_col<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
df
</code></pre> 
<p>通过以上的例子，相信大家都已经发现，如果想将 DataFrame 对象写入某一格式的文件，应用 Pandas 库中 to_() 形式的函数就可以了，比如上述的 to_csv() 和 to_excel()，当然，还包括更多其它的文件形式：</p> 
<p>to_json()<br> to_html()<br> to_sql()<br> to_pickle()<br> 对于不同类型文件的读取，同理可得：</p> 
<p>read_json()<br> read_html()<br> read_sql()<br> read_pickle()<br> 更多的 DataFrame 操作<br> 很多时候，我们完成了文件中的数据读取，转换为 DataFrame 形式之后，需要进行一系列的数据处理操作，比如获取某行某列，根据条件获取部分数据，进行数据可视化等等。接下来的部分将为大家介绍一些常见的基于 DataFrame 的操作。</p> 
<p>使用 loc[] 可以获取具有指定行和列名称的数据。</p> 
<pre><code class="prism language-python">df<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token string">"CHN"</span><span class="token punctuation">,</span> <span class="token string">"POP"</span><span class="token punctuation">]</span>
</code></pre> 
<p>直接根据列名来获取某列</p> 
<pre><code class="prism language-python">df<span class="token punctuation">[</span><span class="token string">"POP"</span><span class="token punctuation">]</span>
</code></pre> 
<p>也可以根据列名来获取多列。</p> 
<pre><code class="prism language-python">df<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">"POP"</span><span class="token punctuation">,</span> <span class="token string">"GDP"</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
</code></pre> 
<p>根据 iloc[] 获取某一行。</p> 
<pre><code class="prism language-python">df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">]</span>
</code></pre> 
<p>获取某几行</p> 
<pre><code class="prism language-python">df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">]</span>
</code></pre> 
<p>取某几行，某几列。</p> 
<pre><code class="prism language-python">df<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
</code></pre> 
<p>根据条件获取数据，如获取亚洲国家对应的数据。</p> 
<pre><code class="prism language-python">df<span class="token punctuation">.</span>loc<span class="token punctuation">[</span>df<span class="token punctuation">[</span><span class="token string">"CONT"</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">"Asia"</span><span class="token punctuation">]</span>
</code></pre> 
<p>若需要满足多个条件，用 &amp; 连接即可。</p> 
<pre><code class="prism language-python">df<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">(</span>df<span class="token punctuation">[</span><span class="token string">"CONT"</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">"Asia"</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span> <span class="token punctuation">(</span>df<span class="token punctuation">[</span><span class="token string">"GDP"</span><span class="token punctuation">]</span> <span class="token operator">&gt;</span> <span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">]</span>  <span class="token comment"># 注意 &amp; 左右两边的条件要加上（），否则报错</span>
直接应用 DataFrame 中的 plot<span class="token punctuation">(</span><span class="token punctuation">)</span> 函数可以对数值类型的列进行画图。
df<span class="token punctuation">.</span>plot<span class="token punctuation">.</span>bar<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p>也可以只选取其中的某部分感兴趣的数据进行画图</p> 
<pre><code class="prism language-python">df<span class="token punctuation">[</span><span class="token string">"POP"</span><span class="token punctuation">]</span><span class="token punctuation">.</span>plot<span class="token punctuation">.</span>bar<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 各国家的人口对比</span>
</code></pre> 
<p>有时候在数据预处理过程中，我们会遇到大型文件，比如某部长篇小说都存放在一个 txt 文件中，如果文件太大，无法直接保存或处理，则可以采用以下几种方法来减少所需的磁盘空间：</p> 
<p>压缩文件。<br> 使用精确更低的数据类型。<br> 拆分数据分成块。<br> 压缩文件：在保存文件时，添加一个与所需压缩类型相对应的后缀，比如：</p> 
<p>‘.gz’<br> ‘.bz2’<br> ‘.zip’<br> ‘.xz’<br> 压缩为以 “.zip” 为后缀的文件。</p> 
<pre><code class="prism language-python">df<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span><span class="token string">"20_country.csv.zip"</span><span class="token punctuation">)</span>
</code></pre> 
<p>使用精确更低的数据类型：在可以接受不太精确的数据类型的情况下，转换数据类型可以节省大量内存。</p> 
<pre><code class="prism language-python">df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_excel<span class="token punctuation">(</span><span class="token string">"20_country.xlsx"</span><span class="token punctuation">,</span> index_col<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
df<span class="token punctuation">.</span>dtypes
</code></pre> 
<p>具有浮点数的列是 64 位浮点数。此类型的每个数字 float64 消耗 64 位或 8 个字节。每列有 20 个数字，需要 160 个字节。</p> 
<pre><code class="prism language-python">df<span class="token punctuation">.</span>memory_usage<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p>通过将将 float64 浮点数存为 float32 浮点数，以节省内存。</p> 
<pre><code class="prism language-python">dtypes <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">'POP'</span><span class="token punctuation">:</span> <span class="token string">'float32'</span><span class="token punctuation">,</span> <span class="token string">'AREA'</span><span class="token punctuation">:</span> <span class="token string">'float32'</span><span class="token punctuation">,</span> <span class="token string">'GDP'</span><span class="token punctuation">:</span> <span class="token string">'float32'</span><span class="token punctuation">}</span>
df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_excel<span class="token punctuation">(</span><span class="token string">"20_country.xlsx"</span><span class="token punctuation">,</span> index_col<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>dtypes<span class="token punctuation">)</span>
df<span class="token punctuation">.</span>dtypes
</code></pre> 
<p>转换后的数值部分可以节省内存，从 160 个字节变为 80 个字节。</p> 
<pre><code class="prism language-python">df<span class="token punctuation">.</span>memory_usage<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p>拆分数据分成块：处理超大型数据集的另一种方法是将数据分成较小的块，然后一次处理一个块，参数 chunksize，默认为 None，可以传入一个整数值指明块的数量。</p> 
<pre><code class="prism language-python">data_chunk <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"20_country.csv"</span><span class="token punctuation">,</span> index_col<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> chunksize<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">type</span><span class="token punctuation">(</span>data_chunk<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">hasattr</span><span class="token punctuation">(</span>data_chunk<span class="token punctuation">,</span> <span class="token string">'__iter__'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">hasattr</span><span class="token punctuation">(</span>data_chunk<span class="token punctuation">,</span> <span class="token string">'__next__'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p>当 chunksize 为整数时，read_csv() 返回一个可迭代的变量，可以在 for 循环中使用该可迭代的变量，以在每次迭代中仅获取和处理数据集的一部分，这样就能够控制处理一次数据所需的内存量，并将其保持在合理的程度。</p> 
<pre><code class="prism language-python"><span class="token keyword">for</span> df_chunk <span class="token keyword">in</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'20_country.csv'</span><span class="token punctuation">,</span> index_col<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> chunksize<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>df_chunk<span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token string">'\n\n'</span><span class="token punctuation">)</span>  <span class="token comment"># 每次迭代一部分</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'memory:'</span><span class="token punctuation">,</span> df_chunk<span class="token punctuation">.</span>memory_usage<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
          <span class="token string">'bytes'</span><span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token string">'\n\n\n'</span><span class="token punctuation">)</span>  <span class="token comment"># 查看所占内存</span>
</code></pre> 
<p>在上述例子中，chunksize 是 8，因此 for 循环的第一次迭代仅返回 DataFrame 数据集的前 8 行，第二次迭代将返回接下来的 8 行，第三次也是最后一次迭代将返回其余 4 行。在每次迭代中，获得 DataFrame 行数等于 chunksize。当前，在最后一次迭代中，行数可能少于 chunksize，因为 DataFrame 的总行数不一定能够被 chunksize 整除。</p> 
<p>在本实验中，我们主要介绍了对于不同类型文件的读写以及后续的操作处理，包括以下知识点：</p> 
<p>txt 文本数据的读写<br> CSV 及 Excel 文本数据的读写<br> 更多的 DataFrame 操作<br> 数据规模太大怎么办<br> 相信通过本次实验的学习，同学们可以游刃有余地面对各种数据文件了。在接下来的实验中，我们将开始真正地开启自然语言处理之旅，开始认识并熟悉一些常见的针对文本本身的预处理操作。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/65263635dcdfda02c224fed9c14c873f/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Python知识点：如何使用SQLite，在Python开发中进行轻量级数据库操作</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/17c705a468df66cb2ca4462d0b759acf/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">云原生系列 - Nginx(高级篇)</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>