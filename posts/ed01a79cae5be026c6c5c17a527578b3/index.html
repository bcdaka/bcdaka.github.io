<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>YOLO目标检测项目--YOLOv4算法对交通标志的识别 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/ed01a79cae5be026c6c5c17a527578b3/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="YOLO目标检测项目--YOLOv4算法对交通标志的识别">
  <meta property="og:description" content="交通安全的重要性 交通安全是指在道路上保障交通参与者的生命安全和财产安全，预防交通事故发生的和减少事故造成的伤亡和损失。交通安全是社会发展和人民生活的重要组成部分，其与人们的生命财产安全和社会稳定密切相关。为此，通过深度学习技术对交通标志进行识别和检测，包括交通指示牌、交通信号灯和交通标线导向箭头等，提高导航设备对交通标志识别的准确性和效率，为驾驶员提供更好的交通信息服务，降低驾驶风险。
YOLOv4算法简介 YOLOv4是You Only Look Once版本4的缩写，是一种先进的目标检测算法，是基于YOLOv3的基础上进行进一步优化和完善，其旨在解决yolo之前版本和其他检测模型的局限性-- 不仅适用于推荐系统，还适用于独立的流程管理和减少人工输入，并且可以使用传统的GPU进行训练和测试，并能够获得实时的、高精度的检测结果。
YOLOv4算法属于单阶段目标检测算法，其具有检测速度快、综合性能强的优点，可以实现一次性得到检测对象的位置信息和类别信息。其主要组成部分如下：
骨干网络Backbone--用于从输入数据中提取特征；颈部Neck--将提取到的各种尺寸特征进行融合；检测头部Head--用来完成目标分类以及回归操作。 数据准备及标注 首先，通过代码将模型训练所需标注和检测的图像（交通指示牌、交通信号灯和交通标线导向箭头）进行采集，采集过程中需注意以下几点要求：
数据集应包含以上提到的交通指示牌、交通信号灯和交通标线导向箭头等种类，确保模型在任何情况下都能准确识别；数据的质量--数据集中的图像优先采取分辨率高的且易识别的，切不可包含太多的噪声和干扰；数据集需要有准确的标注信息，包括每张图像中交通标志的位置和类别。 数据预处理的步骤如下：
数据格式转换：采集到的图像通常是.jpg、.webp、.png等格式，使用格式工厂将采集到图像进行格式转换，统一转换成.jpg格式；数据标注：使用labelling对每张图像进行标注，标明需要识别的交通标志的位置以及其类别；标注完成后以.xml的格式进行保存到相应的文件夹；数据加载：将预处理后的图像加载到相应的文件夹，用于下一步模型的训练；数据压缩：对图像进行适当的有损压缩，图像太大也会影响模型的正常训练。 本模型共采集图片150张，对150张图片进行数据预处理，最终筛选到100张质量较高的图片用于模型训练，目标检测算法--自动划分训练集和测试集。
附（如何使用labelling进行图片标注）：
首先，解压labelling压缩包，运行labelling.exe;设置需要标注图像的文件夹路径以及标注成功的图像存放路径；加载图片后，点击create\nRectBox进行标注--使用矩形框对其所需要识别的类型标注；标注完成，点击保存图片。 YOLOv4模型的训练 将下载好的YOLOv4的代码框架解压，并使用pycharm打开；将模型需要标注的图像保存到yolov4-pytorch-master/VOCdevkit/VOC2007/JEPGImages目录（保存之前，清空该目录下的所有图像）；同理，将已使用labelling标注过的.xml文件保存到yolov4-pytorch-master/VOCdevkit/VOC2007/Annotations（保存之前，清空该目录下的所有.xml文件）。(注意：JEPGImage中的图像名称必须与Annotations中的.xml文件对应且数量相同)修改yolov4-pytorch-master/model_data/coco_classes.txt和yolov4-pytorch-master/model_data/voc_classes.txt，将上述文件修改成所需要标注和识别图像的类型。修改train.py中的‘optimizer_type’=&#34;adam&#34;（原代码框架使用的优化器为SGD），同时相应的修改&#34;weight_decay&#34;=0（adam会导致weight_decay错误，使用adam时建议设置为0）。完成上述步骤后，对模型开始进行训练--先运行voc_annotation.py，再运行train.py（完成一次训练大概3.5小时）。模型训练完成后，将模型训练得到的last_epoch_weights.pth存放到yolov4-pytorch-master/model_data，同时修改yolo.py的“model_path”路径（即model_path:&#39;model_data/last_epoch_weights.pth&#39;），修改结束后，需要再次运行yolo.py。将需要进行预测的图像保存到yolov4-pytorch-master/img文件夹中，运行predict.py对图像进行预测：完成上述步骤后，对训练好的模型进行保存。 模型预测结果 经过训练后的模型能够较为准确的识别不同图像的交通指示牌、交通信号灯和交通标线导向箭头这三类并对其进行位置标注以及精确率的展示。这些识别结果证明了本模型在交通标志识别任务上的性能和效果，为交通管理部门和驾驶员提供了重要的辅助信息，有助于提高交通安全水平。
以下是模型预测结果的展示：
结论 通过展示经过训练的YOLOv4模型在测试集上的交通标志识别结果，可以得出以下结论：
YOLOv4模型在交通标志识别任务上表现不错，能够准确地识别不同类型的交通标志，并且标注出它们的位置和类别。模型对于各种复杂场景下的交通标志都能够有效地进行识别，包括停车标志、限速标志、交通信号灯和路口标线导向箭头等。YOLOv4模型在交通标志识别任务上具有高准确性和鲁棒性，能够为驾驶员和交通管理部门提供重要的交通信息，有助于提高交通安全水平。 综上所述，经过训练的YOLOv4模型在交通标志识别方面表现不错，为改善交通管理和提升交通安全提供了有效的技术支持。随着深度学习技术的不断发展和模型的进一步优化，相信这种技术将在未来更多领域发挥更加重要的作用，为建设更便捷、美好的社会做出贡献。
参考文献 [1]张鐘月.基于改进Yolo5s的人脸口罩检测[D].东华大学,2021.DOI:10.27012/d.cnki.gdhuu.2021.001527.
[2]江屾,殷时蓉,罗天洪,等.基于改进YOLOv4的多目标车辆检测算法[J].计算机工程与设计,2024,45(04):1181-1188.DOI:10.16208/j.issn1000-7024.2024.04.030.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-04-28T19:34:19+08:00">
    <meta property="article:modified_time" content="2024-04-28T19:34:19+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">YOLO目标检测项目--YOLOv4算法对交通标志的识别</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h3>交通安全的重要性</h3> 
<p>交通安全是指在道路上保障交通参与者的生命安全和财产安全，预防交通事故发生的和减少事故造成的伤亡和损失。交通安全是社会发展和人民生活的重要组成部分，其与人们的生命财产安全和社会稳定密切相关。为此，通过深度学习技术对交通标志进行识别和检测，包括交通指示牌、交通信号灯和交通标线导向箭头等，提高导航设备对交通标志识别的准确性和效率，为驾驶员提供更好的交通信息服务，降低驾驶风险。</p> 
<h3>YOLOv4算法简介</h3> 
<p>YOLOv4是You Only Look Once版本4的缩写，是一种先进的目标检测算法，是基于YOLOv3的基础上进行进一步优化和完善，其旨在解决yolo之前版本和其他检测模型的局限性-- 不仅适用于推荐系统，还适用于独立的流程管理和减少人工输入，并且可以使用传统的GPU进行训练和测试，并能够获得实时的、高精度的检测结果。</p> 
<p>YOLOv4算法属于单阶段目标检测算法，其具有检测速度快、综合性能强的优点，可以实现一次性得到检测对象的位置信息和类别信息。其主要组成部分如下：</p> 
<ol><li>骨干网络Backbone--用于从输入数据中提取特征；</li><li>颈部Neck--将提取到的各种尺寸特征进行融合；</li><li>检测头部Head--用来完成目标分类以及回归操作。</li></ol> 
<h3>数据准备及标注</h3> 
<p>首先，通过代码将模型训练所需标注和检测的图像（交通指示牌、交通信号灯和交通标线导向箭头）进行采集，采集过程中需注意以下几点要求：</p> 
<ol><li>数据集应包含以上提到的交通指示牌、交通信号灯和交通标线导向箭头等种类，确保模型在任何情况下都能准确识别；</li><li>数据的质量--数据集中的图像优先采取分辨率高的且易识别的，切不可包含太多的噪声和干扰；</li><li>数据集需要有准确的标注信息，包括每张图像中交通标志的位置和类别。</li></ol> 
<p>数据预处理的步骤如下：</p> 
<ol><li>数据格式转换：采集到的图像通常是.jpg、.webp、.png等格式，使用<a class="link-info" href="http://www.pcgeshi.com/" rel="nofollow" title="格式工厂">格式工厂</a>将采集到图像进行格式转换，统一转换成.jpg格式；</li><li>数据标注：使用labelling对每张图像进行标注，标明需要识别的交通标志的位置以及其类别；标注完成后以.xml的格式进行保存到相应的文件夹；</li><li>数据加载：将预处理后的图像加载到相应的文件夹，用于下一步模型的训练；</li><li>数据压缩：对图像进行适当的有损压缩，图像太大也会影响模型的正常训练。</li></ol> 
<p>本模型共采集图片150张，对150张图片进行数据预处理，最终筛选到100张质量较高的图片用于模型训练，目标检测算法--自动划分训练集和测试集。</p> 
<p>附（如何使用labelling进行图片标注）：</p> 
<ol><li>首先，解压<a class="link-info" href="https://musetransfer.com/s/guglt6euc" rel="nofollow" title="labelling压缩包">labelling压缩包</a>，运行labelling.exe;<img alt="" src="https://images2.imgbox.com/b7/65/NEYeHpbm_o.png"></li><li>设置需要标注图像的文件夹路径以及标注成功的图像存放路径；<img alt="" src="https://images2.imgbox.com/bb/ff/UcPGMS0S_o.png"></li><li>加载图片后，点击create\nRectBox进行标注--使用矩形框对其所需要识别的类型标注；<img alt="" src="https://images2.imgbox.com/0f/e0/mXrH9sA8_o.png"></li><li>标注完成，点击保存图片。<img alt="" src="https://images2.imgbox.com/d6/00/Pe01cQlg_o.png"></li></ol> 
<h3>YOLOv4模型的训练</h3> 
<ol><li>将下载好的<a class="link-info" href="http://www.file.yiyuen.com/file/download/656554" rel="nofollow" title="YOLOv4的代码框架">YOLOv4的代码框架</a>解压，并使用pycharm打开；<img alt="" src="https://images2.imgbox.com/f8/af/RDC2XzXZ_o.png"></li><li>将模型需要标注的图像保存到yolov4-pytorch-master/VOCdevkit/VOC2007/JEPGImages目录（保存之前，清空该目录下的所有图像）；同理，将已使用labelling标注过的.xml文件保存到yolov4-pytorch-master/VOCdevkit/VOC2007/Annotations（保存之前，清空该目录下的所有.xml文件）。<span style="color:#fe2c24;">(注意：JEPGImage中的图像名称必须与Annotations中的.xml文件对应且数量相同)</span><img alt="" src="https://images2.imgbox.com/2a/05/VAjhv2WL_o.png"><img alt="" src="https://images2.imgbox.com/cf/9c/LCZIoY4z_o.png"></li><li>修改yolov4-pytorch-master/model_data/coco_classes.txt和yolov4-pytorch-master/model_data/voc_classes.txt，将上述文件修改成所需要标注和识别图像的类型。<img alt="" src="https://images2.imgbox.com/c4/34/JQ4mgwgp_o.png"><img alt="" src="https://images2.imgbox.com/31/9b/N8AOFitZ_o.png"></li><li>修改train.py中的‘optimizer_type’="adam"（原代码框架使用的优化器为SGD），同时相应的修改"weight_decay"=0（adam会导致weight_decay错误，使用adam时建议设置为0）。完成上述步骤后，对模型开始进行训练--先运行voc_annotation.py，再运行train.py（完成一次训练大概3.5小时）。<img alt="" src="https://images2.imgbox.com/76/38/wRDpRDUz_o.png"><img alt="" src="https://images2.imgbox.com/97/d2/TkQLY0PK_o.png"><img alt="" src="https://images2.imgbox.com/70/c4/vT9AWMaW_o.jpg"></li><li>模型训练完成后，将模型训练得到的last_epoch_weights.pth存放到yolov4-pytorch-master/model_data，同时修改yolo.py的“model_path”路径（即model_path:'model_data/last_epoch_weights.pth'），修改结束后，需要再次运行yolo.py。<img alt="" src="https://images2.imgbox.com/99/5b/vKuMBH8A_o.png"></li><li>将需要进行预测的图像保存到yolov4-pytorch-master/img文件夹中，运行predict.py对图像进行预测：<img alt="" src="https://images2.imgbox.com/a4/fa/YV3lHq0q_o.png"><img alt="" src="https://images2.imgbox.com/35/90/XEk5Od4E_o.png"></li><li>完成上述步骤后，对训练好的模型进行保存。</li></ol> 
<h3>模型预测结果</h3> 
<p>经过训练后的模型能够较为准确的识别不同图像的交通指示牌、交通信号灯和交通标线导向箭头这三类并对其进行位置标注以及精确率的展示。这些识别结果证明了本模型在交通标志识别任务上的性能和效果，为交通管理部门和驾驶员提供了重要的辅助信息，有助于提高交通安全水平。</p> 
<p>以下是模型预测结果的展示：</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/a8/ec/4s4gS38P_o.png"></p> 
<h3>结论</h3> 
<p>通过展示经过训练的YOLOv4模型在测试集上的交通标志识别结果，可以得出以下结论：</p> 
<ol><li>YOLOv4模型在交通标志识别任务上表现不错，能够准确地识别不同类型的交通标志，并且标注出它们的位置和类别。</li><li>模型对于各种复杂场景下的交通标志都能够有效地进行识别，包括停车标志、限速标志、交通信号灯和路口标线导向箭头等。</li><li>YOLOv4模型在交通标志识别任务上具有高准确性和鲁棒性，能够为驾驶员和交通管理部门提供重要的交通信息，有助于提高交通安全水平。</li></ol> 
<p>综上所述，经过训练的YOLOv4模型在交通标志识别方面表现不错，为改善交通管理和提升交通安全提供了有效的技术支持。随着深度学习技术的不断发展和模型的进一步优化，相信这种技术将在未来更多领域发挥更加重要的作用，为建设更便捷、美好的社会做出贡献。</p> 
<h3>参考文献</h3> 
<p>[1]张鐘月.基于改进Yolo5s的人脸口罩检测[D].东华大学,2021.DOI:10.27012/d.cnki.gdhuu.2021.001527.</p> 
<p>[2]江屾,殷时蓉,罗天洪,等.基于改进YOLOv4的多目标车辆检测算法[J].计算机工程与设计,2024,45(04):1181-1188.DOI:10.16208/j.issn1000-7024.2024.04.030.</p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<h2></h2>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/a28e8d1fa2c4c1272d9dddd37143dddf/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【Python】全面掌握 Collections Deque：队列与栈的高效实现及动态内存管理指南</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/d3f3680278fa91c3fc4edba45651e172/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">通俗易懂的Stable Diffusion模型结构介绍</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>