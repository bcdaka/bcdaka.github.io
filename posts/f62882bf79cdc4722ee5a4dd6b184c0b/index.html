<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>大数据实训（三）——MapReduce编程实例：词频统计 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/f62882bf79cdc4722ee5a4dd6b184c0b/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="大数据实训（三）——MapReduce编程实例：词频统计">
  <meta property="og:description" content="#MapReduce#YARN#hdfs#IDEA#JDK1.8
实验三：Mapreduce词频统计
3.1启动hadoop服务，输入命令：
start-all.sh 3.2在export目录下，创建wordcount目录，在里面创建words.txt文件，向words.txt输入下面内容。
[root@bogon~]# mkdir -p /export/wordcount [root@bogon~]# cd /export/wordcount/ [root@bogon~]# vi words.txt [root@bogon~]# cat words.txt 3.3编辑结束，上传文件到HDFS指定目录
创建/wordcount/input目录，执行命令：
hdfs dfs -mkdir -p /wordcount/input 3.4将在本地/export/wordcount/目录下的words.txt文件，上传到HDFS的/wordcount/input目录，输入命令：
hdfs dfs -put /export/wordcount/words.txt /wordcount/input 在Hadoop WebUI界面查看目录是否创建成功
3.5使用IDEA创建Maven项目MRWordCount
在pom.xml文件里添加hadoop和junit依赖，内容为：
&lt;dependencies&gt; &lt;!--hadoop客户端--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt; &lt;artifactId&gt;hadoop-client&lt;/artifactId&gt; &lt;version&gt;3.3.4&lt;/version&gt; &lt;/dependency&gt; &lt;!--单元测试框架--&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.13.2&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 3.6创建日志文件：在resources目录里创建log4j.properties文件
log4j.rootLogger=ERROR, stdout, logfile log4j.appender.stdout=org.apache.log4j.ConsoleAppender log4j.appender.stdout.layout=org.apache.log4j.PatternLayout log4j.appender.stdout.layout.ConversionPattern=%d %p [%c] - %m%n log4j.appender.logfile=org.apache.log4j.FileAppender log4j.appender.logfile.File=target/wordcount.log log4j.appender.logfile.layout=org.apache.log4j.PatternLayout log4j.appender.logfile.layout.ConversionPattern=%d %p [%c] - %m%n 3.7创建词频统计映射器类">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-05-24T09:45:00+08:00">
    <meta property="article:modified_time" content="2024-05-24T09:45:00+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">大数据实训（三）——MapReduce编程实例：词频统计</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>#MapReduce#YARN#hdfs#IDEA#JDK1.8</p> 
<p style="text-align:justify;"><strong><strong>实验三：M</strong></strong><strong><strong>apreduce</strong></strong><strong><strong>词频统计</strong></strong></p> 
<p><strong><strong>3</strong></strong><strong><strong>.1启动hadoop服务，输入命令：</strong></strong></p> 
<pre><code class="hljs">start-all.sh
</code></pre> 
<p><strong><strong>3</strong></strong><strong><strong>.2在export目录下，创建wordcount目录，在里面创建words.txt文件，向words.txt输入下面内容。</strong></strong></p> 
<pre><code class="hljs">[root@bogon~]# mkdir -p /export/wordcount
[root@bogon~]# cd /export/wordcount/
[root@bogon~]# vi words.txt
[root@bogon~]# cat words.txt</code></pre> 
<p><strong><strong>3</strong></strong><strong><strong>.3编辑结束，</strong></strong><strong><strong>上传文件到HDFS指定目录</strong></strong></p> 
<p><strong><strong>创建/wordcount/input目录，执行命令：</strong></strong></p> 
<pre><code class="hljs">hdfs dfs -mkdir -p /wordcount/input</code></pre> 
<p><strong><strong>3</strong></strong><strong><strong>.4将在本地/export/wordcount/目录下的words.txt文件，上传到HDFS的/wordcount/input目录，输入命令：</strong></strong></p> 
<pre><code class="hljs">hdfs dfs -put /export/wordcount/words.txt /wordcount/input</code></pre> 
<p> 在Hadoop WebUI界面查看目录是否创建成功</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/ea/d8/ppQVfBEV_o.png"></p> 
<p><strong><strong>3</strong></strong><strong><strong>.5</strong></strong><strong><strong>使用IDEA创建Maven项目M</strong></strong><strong><strong>RWordCount</strong></strong></p> 
<p>在pom.xml文件里添加hadoop和junit依赖，内容为：</p> 
<pre><code class="hljs">&lt;dependencies&gt;                                   
    &lt;!--hadoop客户端--&gt;                             
    &lt;dependency&gt;                                 
        &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;     
        &lt;artifactId&gt;hadoop-client&lt;/artifactId&gt;   
        &lt;version&gt;3.3.4&lt;/version&gt;                 
    &lt;/dependency&gt;                                
    &lt;!--单元测试框架--&gt;                                
    &lt;dependency&gt;                                 
        &lt;groupId&gt;junit&lt;/groupId&gt;                 
        &lt;artifactId&gt;junit&lt;/artifactId&gt;           
        &lt;version&gt;4.13.2&lt;/version&gt;                
    &lt;/dependency&gt;                                
&lt;/dependencies&gt;                   </code></pre> 
<p style="text-align:center;"> <img alt="" src="https://images2.imgbox.com/96/0c/QqV1wz7K_o.png"></p> 
<p><strong><strong>3</strong></strong><strong><strong>.6</strong></strong><strong><strong>创建日志文件：在resources目录里创建log4j.properties文件</strong></strong></p> 
<pre><code class="hljs">log4j.rootLogger=ERROR, stdout, logfile
log4j.appender.stdout=org.apache.log4j.ConsoleAppender
log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
log4j.appender.stdout.layout.ConversionPattern=%d %p [%c] - %m%n
log4j.appender.logfile=org.apache.log4j.FileAppender
log4j.appender.logfile.File=target/wordcount.log
log4j.appender.logfile.layout=org.apache.log4j.PatternLayout
log4j.appender.logfile.layout.ConversionPattern=%d %p [%c] - %m%n</code></pre> 
<p><strong><strong>3</strong></strong><strong><strong>.7</strong></strong><strong><strong>创建词频统计映射器类</strong></strong></p> 
<p style="margin-left:.0001pt;text-align:justify;">（1）创建net.army.mr包，在弹出的new package对话框中输入net.army.mr</p> 
<p style="margin-left:.0001pt;text-align:justify;">（2）在net.army.mr包下创建WordCountMapper类</p> 
<pre><code class="hljs">package net.army.mr;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.io.Text;
import java.io.IOException;
/**
 * 功能：词频统计映射器类
 */
public class WordCountMapper extends Mapper&lt;LongWritable, Text, Text, IntWritable&gt; {
    @Override
    protected void map(LongWritable key, Text value, Context context)
            throws IOException, InterruptedException {
        // 获取行内容
        String line = value.toString();
        // 按空格拆分成单词数组
        String[] words = line.split(" ");
        // 遍历单词数组，生成输出键值对
        for (String word : words) {
            context.write(new Text(word), new IntWritable(1));
        }
    }
}
</code></pre> 
<p> <strong><strong>3.8创建WordCountReducer类</strong></strong></p> 
<pre><code class="hljs">package net.army.mr;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.NullWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;
import java.io.IOException;
/**
 * 功能：词频统计归并类
 */
public class WordCountReducer extends Reducer&lt;Text, IntWritable, Text, NullWritable&gt; {
    @Override
    protected void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context)
            throws IOException, InterruptedException {
        // 定义键（单词）出现次数
        int count = 0;
        // 遍历输入值迭代器
        for (IntWritable value : values) {
            count = count + value.get(); // 针对此案例，可以写为count++;
        }
        // 生成新的键，格式为(word,count)
        String newKey = "(" + key.toString() + "," + count + ")";
        // 输出新的键值对
        context.write(new Text(newKey), NullWritable.get());
    }
}</code></pre> 
<p> <strong><strong>3.9创建WordCountDriver类</strong></strong></p> 
<pre><code class="hljs">package net.army.mr;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FSDataInputStream;
import org.apache.hadoop.fs.FileStatus;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IOUtils;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.NullWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import java.net.URI;
/**
 * 功能：词频统计驱动器类
 */
public class WordCountDriver {
    public static void main(String[] args) throws Exception {
        // 创建配置对象
        Configuration conf = new Configuration();
        // 设置客户端使用数据节点主机名属性
        conf.set("dfs.client.use.datanode.hostname", "true");

        // 获取作业实例
        Job job = Job.getInstance(conf);
        // 设置作业启动类
        job.setJarByClass(WordCountDriver.class);

        // 设置Mapper类
        job.setMapperClass(WordCountMapper.class);
        // 设置map任务输出键类型
        job.setMapOutputKeyClass(Text.class);
        // 设置map任务输出值类型
        job.setMapOutputValueClass(IntWritable.class);

        // 设置Reducer类
        job.setReducerClass(WordCountReducer.class);
        // 设置reduce任务输出键类型
        job.setOutputKeyClass(Text.class);
        // 设置reduce任务输出值类型
        job.setOutputValueClass(NullWritable.class);

        // 定义uri字符串
        String uri = "hdfs://bogon:9000";

        // 创建输入目录
        Path inputPath = new Path(uri + "/wordcount/input");
        // 创建输出目录
        Path outputPath = new Path(uri + "/wordcount/output");

        // 获取文件系统
        FileSystem fs = FileSystem.get(new URI(uri), conf);
        // 删除输出目录（第二个参数设置是否递归）
        fs.delete(outputPath, true);

        // 给作业添加输入目录（允许多个）
        FileInputFormat.addInputPath(job, inputPath);
        // 给作业设置输出目录（只能一个）
        FileOutputFormat.setOutputPath(job, outputPath);

        // 等待作业完成
        job.waitForCompletion(true);

        // 输出统计结果
        System.out.println("======统计结果======");
        FileStatus[] fileStatuses = fs.listStatus(outputPath);
        for (int i = 1; i &lt; fileStatuses.length; i++) {
            // 输出结果文件路径
            System.out.println(fileStatuses[i].getPath());
            // 获取文件系统数据字节输入流
            FSDataInputStream in = fs.open(fileStatuses[i].getPath());
            // 将结果文件显示在控制台
            IOUtils.copyBytes(in, System.out, 4096, false);
        }
    }
}</code></pre> 
<p><strong><strong>3</strong></strong><strong><strong>.</strong></strong><strong><strong>10</strong></strong><strong><strong>运行词频统计驱动器类</strong></strong><strong><strong>WordCountDriver</strong></strong><strong><strong>，查看结果</strong></strong></p> 
<p style="text-align:center;"><strong><strong><img alt="" src="https://images2.imgbox.com/e0/35/sbfKG9qe_o.png"></strong></strong></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/2e268a0c9d21e73feaef93670ae82d64/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">数据库-MySQL 实战项目——学生选课系统数据库设计与实现（附源码）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/aab66ec4d64aa63df5bee82309e60bda/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Midjourney &#43; InsightFaceSwap Al 换脸轻松实现</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>