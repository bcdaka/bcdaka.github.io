<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Kafka之集群搭建 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/01cf1555031e43645ca5c5632724b4be/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="Kafka之集群搭建">
  <meta property="og:description" content="1. 为什么要使用kafka集群 单机服务下，Kafka已经具备了非常高的性能。TPS能够达到百万级别。但是，在实际工作中使用时，单机搭建的Kafka会有很大的局限性。
​ 消息太多，需要分开保存。Kafka是面向海量消息设计的，一个Topic下的消息会非常多，单机服务很难存得下来。这些消息就需要分成不同的Partition，分布到多个不同的Broker上。这样每个Broker就只需要保存一部分数据。这些分区的个数就称为分区数。​ 服务不稳定，数据容易丢失。单机服务下，如果服务崩溃，数据就丢失了。为了保证数据安全，就需要给每个Partition配置一个或多个备份，保证数据不丢失。Kafka的集群模式下，每个Partition都有一个或多个备份。Kafka会通过一个统一的Zookeeper集群作为选举中心，给每个Partition选举出一个主节点Leader，其他节点就是从节点Follower。主节点负责响应客户端的具体业务请求，并保存消息。而从节点则负责同步主节点的数据。当主节点发生故障时，Kafka会选举出一个从节点成为新的主节点。 Kafka集群中的这些Broker信息，包括Partition的选举信息，都会保存在额外部署的Zookeeper集群当中，这样，kafka集群就不会因为某一些Broker服务崩溃而中断。 2. kafka的集群架构 由章节1中对kafka集群特点的描述，我们可以大致画出kafka的集群架构图大致如下：
3. kafka集群搭建 ​ 接下来我们就动手部署一个Kafka集群，来体验一下Kafka是如何面向海量数据进行横向扩展的。
3.1 搭建kafka集群 搭建环境：
1. 准备3台虚拟机
2. 安装jdk
jdk安装可参考Linux环境下安装JDK-CSDN博客
3. 关闭防火墙（实验版本关闭防火墙，生产环境开启对应端口即可）
firewall-cmd --state 查看防火墙状态 systemctl stop firewalld.service 关闭防火墙 第一步： zookeeper 集群搭建
kafka依赖于zookeeper,虽然kafka内部自带了一个zookeeper,为了保证服务之间的独立性，不建议使用其内部的zookeeper，所以我们先搭建一个独立的zookeeper集群。Zookeeper是一种多数同意的选举机制，允许集群中少数节点出现故障。因此，在搭建集群时，通常都是采用3，5，7这样的奇数节点，这样可以最大化集群的高可用特性。
zk集群搭建参考：zookeeper之集群搭建-CSDN博客
根据上述文章搭建完成之后，启动zookeeper集群
第二步： 部署kafka集群
kafka服务并不需要进行选举，因此也没有奇数台服务的建议。 首先，三台机器都根据 初识Kafka-CSDN博客 中的单机服务体验，上传、解压kafka到 解压到 /app/kafka 目录下。 接下来，进入config目录，修改server.properties。这个配置文件里面的配置项非常多，下面列出几个要重点关注的配置 #broker 的全局唯一编号，不能重复，只能是数字。 broker.id=0 #数据文件地址。同样默认是给的/tmp目录。 log.dirs=/app/kafka/logs #默认的每个Topic的分区数 num.partitions=1 #zookeeper的服务地址 zookeeper.connect=192.168.31.5:2181,192.168.31.176:2181,192.168.31.232:2181 broker.id需要每个服务器上不一样，分发到其他服务器上时，要注意修改一下,比如第一台是0，第二台就是1，第三台的配置就是2。
当多个Kafka服务注册到同一个zookeeper集群上的节点，会自动组成集群。
server.properties文件中比较重要的核心配置 第三步： 启动kafka集群
bin/kafka-server-start.sh -daemon config/server.properties -daemon表示后台启动kafka服务，这样就不会占用当前命令窗口。
jps看一下启动情况：
3.2 搭建中遇到的问题 3.2.1 启动时报错 问题1描述： 启动kafka时，报没有与主机关联的地址">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-01-12T22:17:42+08:00">
    <meta property="article:modified_time" content="2024-01-12T22:17:42+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Kafka之集群搭建</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2>1. 为什么要使用kafka集群</h2> 
<p>        单机服务下，Kafka已经具备了非常高的性能。TPS能够达到百万级别。但是，在实际工作中使用时，单机搭建的Kafka会有很大的局限性。</p> 
<ol><li>        ​ <strong>消息太多，需要分开保存。</strong>Kafka是面向海量消息设计的，一个Topic下的消息会非常多，单机服务很难存得下来。这些消息就需要分成不同的Partition，分布到多个不同的Broker上。这样每个Broker就只需要保存一部分数据。这些分区的个数就称为分区数。</li><li>​       <strong>服务不稳定，数据容易丢失。</strong>单机服务下，如果服务崩溃，数据就丢失了。为了保证数据安全，就需要给每个Partition配置一个或多个备份，保证数据不丢失。Kafka的集群模式下，每个Partition都有一个或多个备份。Kafka会通过一个统一的Zookeeper集群作为选举中心，给每个Partition选举出一个主节点Leader，其他节点就是从节点Follower。主节点负责响应客户端的具体业务请求，并保存消息。而从节点则负责同步主节点的数据。当主节点发生故障时，Kafka会选举出一个从节点成为新的主节点。</li><li><strong>        Kafka集群中的这些Broker信息，包括Partition的选举信息，都会保存在额外部署的Zookeeper集群当中</strong>，这样，kafka集群就不会因为某一些Broker服务崩溃而中断。</li></ol> 
<h2>2. kafka的集群架构</h2> 
<p>        由章节1中对kafka集群特点的描述，我们可以大致画出kafka的集群架构图大致如下：</p> 
<p><img alt="" height="947" src="https://images2.imgbox.com/66/ce/4waOuzEW_o.png" width="1200"></p> 
<h2 style="background-color:transparent;">3. kafka集群搭建</h2> 
<p>    ​ 接下来我们就动手部署一个Kafka集群，来体验一下Kafka是如何面向海量数据进行横向扩展的。</p> 
<h3>3.1 搭建kafka集群</h3> 
<blockquote> 
 <p>搭建环境：</p> 
 <p>1. 准备3台虚拟机</p> 
 <p>2.  安装jdk</p> 
 <p>        jdk安装可参考<a href="https://blog.csdn.net/weixin_43134177/article/details/135025744?spm=1001.2014.3001.5502" title="Linux环境下安装JDK-CSDN博客">Linux环境下安装JDK-CSDN博客</a></p> 
 <p>3. 关闭防火墙（实验版本关闭防火墙，生产环境开启对应端口即可）</p> 
 <pre><code>firewall-cmd --state 查看防火墙状态 
systemctl stop firewalld.service 关闭防火墙</code></pre> 
</blockquote> 
<blockquote> 
 <p><strong> 第一步： zookeeper 集群搭建</strong></p> 
 <p>        kafka依赖于zookeeper,虽然kafka内部自带了一个zookeeper,为了保证服务之间的独立性，不建议使用其内部的zookeeper，所以我们先搭建一个独立的zookeeper集群。Zookeeper是一种多数同意的选举机制，允许集群中少数节点出现故障。因此，在搭建集群时，通常都是<strong>采用3，5，7这样的奇数节点</strong>，这样可以最大化集群的高可用特性。</p> 
 <p>        zk集群搭建参考：<a href="https://blog.csdn.net/weixin_43134177/article/details/135306485?spm=1001.2014.3001.5502" title="zookeeper之集群搭建-CSDN博客">zookeeper之集群搭建-CSDN博客</a></p> 
 <p>根据上述文章搭建完成之后，启动zookeeper集群</p> 
 <p></p> 
</blockquote> 
<blockquote> 
 <p><strong>第二步： 部署kafka集群</strong></p> 
 <div> 
  <strong><span style="color:#333333;">        kafka服务并不需要进行选举，因此也没有奇数台服务的建议。 </span></strong> 
 </div> 
 <div> 
  <strong><span style="color:#333333;">首先，三台机器都根据 </span></strong> 
  <a href="https://blog.csdn.net/weixin_43134177/article/details/135467946?spm=1001.2014.3001.5502" title="初识Kafka-CSDN博客">初识Kafka-CSDN博客</a> 中的单机服务体验，上传、解压kafka到 
  <span style="color:#333333;">解压到</span> 
  <span style="color:#333333;">/app/kafka</span> 
  <span style="color:#333333;">目录下</span>。 
 </div> 
 <div>
           接下来，进入config目录，修改server.properties。这个配置文件里面的配置项非常多，下面列出几个要重点关注的配置 
 </div> 
 <div> 
  <pre><code class="language-bash">#broker 的全局唯一编号，不能重复，只能是数字。
broker.id=0
#数据文件地址。同样默认是给的/tmp目录。
log.dirs=/app/kafka/logs
#默认的每个Topic的分区数
num.partitions=1
#zookeeper的服务地址
zookeeper.connect=192.168.31.5:2181,192.168.31.176:2181,192.168.31.232:2181
</code></pre> 
  <p><strong>broker.id需要每个服务器上不一样</strong>，分发到其他服务器上时，要注意修改一下,比如第一台是0，第二台就是1，第三台的配置就是2。<br><strong>当多个Kafka服务注册到同一个zookeeper集群上的节点，会自动组成集群。</strong></p> 
 </div> 
</blockquote> 
<blockquote> 
 <p><strong>server.properties文件中比较重要的核心配置 </strong></p> 
 <p><img alt="" height="816" src="https://images2.imgbox.com/b7/09/MPN6DgMd_o.png" width="1200"></p> 
</blockquote> 
<blockquote> 
 <p><strong> 第三步： 启动kafka集群</strong></p> 
 <pre><code class="language-bash">bin/kafka-server-start.sh -daemon config/server.properties</code></pre> 
 <p><strong>-daemon表示后台启动</strong>kafka服务，这样就不会占用当前命令窗口。</p> 
 <p>jps看一下启动情况：</p> 
 <p><img alt="" height="281" src="https://images2.imgbox.com/8a/9f/AQN5oPTO_o.png" width="1200"></p> 
 <p><img alt="" height="284" src="https://images2.imgbox.com/95/46/VYtzJUjd_o.png" width="1200"></p> 
 <p><img alt="" height="254" src="https://images2.imgbox.com/f4/f2/FCHGBjH3_o.png" width="1200"></p> 
</blockquote> 
<h3>3.2 搭建中遇到的问题 </h3> 
<h4>3.2.1 启动时报错</h4> 
<blockquote> 
 <p><strong>问题1描述：</strong> 启动kafka时，报没有与主机关联的地址</p> 
 <p><img alt="" height="267" src="https://images2.imgbox.com/fb/f3/95NKi8bY_o.png" width="830"></p> 
</blockquote> 
<blockquote> 
 <p><strong> 问题解决</strong>：在hosts文件中追加 127.0.0.1 主机名 localhost </p> 
 <p>示例如下：</p> 
 <p>        </p> 
 <p><img alt="" height="100" src="https://images2.imgbox.com/57/99/Y0DaRzJS_o.png" width="700"></p> 
</blockquote> 
<blockquote> 
 <p><strong>问题2描述： node already exists</strong></p> 
 <p><img alt="" height="310" src="https://images2.imgbox.com/85/01/Jpj9FRpu_o.png" width="830"></p> 
</blockquote> 
<blockquote> 
 <p><strong>问题解决：</strong> 检查kafka集群各个节点的<span style="color:#333333;">server.properties，看broker.id有没有一样的，各个节点的broker.id不能重复。</span></p> 
</blockquote> 
<h4 style="background-color:transparent;"> 3.2.1 启动成功后创建topic报错</h4> 
<blockquote> 
 <p><strong>问题描述</strong>：执行以下命令报连接超时</p> 
 <pre><code class="hljs">bin/kafka-topics.sh --bootstrap-server localhost:9092 --create --replication-factor 2 --partitions 4 --topic disTopic</code></pre> 
 <p><img alt="" height="220" src="https://images2.imgbox.com/d9/f1/mGBFbJo2_o.png" width="1200"></p> 
 <p></p> 
</blockquote> 
<blockquote> 
 <p><strong> 问题解决：</strong>命令中的localhost修改为本机ip,还是报超时；</p> 
 <p>最终解决,修改每个节点的<span style="color:#333333;">server.properties，配置监听</span></p> 
 <p><img alt="" height="924" src="https://images2.imgbox.com/14/ff/wcObLzSD_o.png" width="1200"></p> 
 <p>然后执行命令时使用主机ip</p> 
 <pre><code class="language-bash">bin/kafka-topics.sh --bootstrap-server 192.168.31.232:9092 --create --replication-factor 2 --partitions 4 --topic disTopic</code></pre> 
 <p>创建成功</p> 
 <p><img alt="" height="173" src="https://images2.imgbox.com/40/14/ZgRmZIWE_o.png" width="1200"></p> 
</blockquote> 
<h2 style="background-color:transparent;">4. 理解Kafka集群当中核心的Topic、Partition、Broker</h2> 
<p>        接下来，我们创建几个topic,对比单机服务下，理解以下topic、partition和broker。</p> 
<blockquote> 
 <p><strong>创建几个topic：</strong></p> 
 <pre><code class="language-bash">bin/kafka-topics.sh --bootstrap-server 192.168.31.5:9092 --create --replication-factor 2 --partitions 4 --topic disTopic</code></pre> 
 <p><img alt="" height="298" src="https://images2.imgbox.com/72/b1/stLX2WEH_o.png" width="831"></p> 
</blockquote> 
<blockquote> 
 <p><strong>列出所有topic：</strong></p> 
 <pre><code class="language-bash">bin/kafka-topics.sh --bootstrap-server 192.168.31.5:9092 --list __consumer_offsets</code></pre> 
 <p><img alt="" height="103" src="https://images2.imgbox.com/3d/db/k5W6yhNk_o.png" width="831"></p> 
 <p></p> 
</blockquote> 
<blockquote> 
 <p><strong>查看topic列表情况：</strong></p> 
 <pre><code class="language-bash">bin/kafka-topics.sh --bootstrap-server 192.168.31.5:9092 --describe -- topic disTopic</code></pre> 
 <p><img alt="" height="367" src="https://images2.imgbox.com/ba/2f/F8F52lDI_o.png" width="830"></p> 
</blockquote> 
<p>1、--create创建，可以指定一些补充的参数。大部分的参数都可以在配置文件中指定默认值。</p> 
<ul><li>partitons参数表示分区数，这个Topic下的消息会分别存入这些不同的分区中。示例中创建的disTopic，指定了四个分区，也就是说这个Topic下的消息会划分为四个部分。</li><li>replication-factor表示每个分区有几个备份。示例中创建的disTopic，指定了每个partition有两个备份。</li></ul> 
<p>2、--describe查看Topic信息。</p> 
<ul><li>partiton参数列出了四个partition，后面带有分区编号，用来标识这些分区。</li><li>Leader表示这一组partiton中的Leader节点是哪一个。这个Leader节点就是负责响应客户端请求的主节点。从这里可以看到，Kafka中的每一个Partition都会分配Leader，也就是说每个Partition都有不同的节点来负责响应客户端的请求。这样就可以将客户端的请求做到尽量的分散。</li><li>Replicas参数表示这个partition的多个备份是分配在哪些Broker上的。也称为AR。这里的0,1,<a href="http://xn--2broker-1k6mr1a8p83ss0o6ijjp4d561ayya490ttuua.id/" rel="nofollow" title="2就对应配置集群时指定的broker.id">2就对应配置集群时指定的broker.id</a>。但是，Replicas列出的只是一个逻辑上的分配情况，并不关心数据实际是不是按照这个分配。甚至有些节点服务挂了之后，Replicas中也依然会列出节点的ID。</li><li>ISR参数表示partition的实际分配情况。他是AR的一个子集，只列出那些当前还存活，能够正常同步数据的那些Broker节点。</li></ul> 
<p>         接下来，我们还可以查看<strong>Topic下的Partition分布情况</strong>。在Broker上，与消息，联系最为紧密的，其实就是Partition了。之前在配置Kafka集群时，指定了一个log.dirs属性，指向了一个服务器上的日志目录。进入这个目录，就能看到每个Broker的实际数据承载情况。</p> 
<p><img alt="" height="206" src="https://images2.imgbox.com/94/a1/9NtWR78m_o.png" width="1200"></p> 
<p>​ 从这里可以看到<strong>，Broker上的一个Partition对应了日志目录中的一个目录</strong>。<strong>而这个Partition上的所有消息，就保存在这个对应的目录当中</strong>。</p> 
<p>        从整个过程可以看到，Kafka当中，<strong>Topic是一个数据集合的逻辑单元</strong>。同一个Topic下的数据，实际上是存储在Partition分区中的，<strong>Partition就是数据存储的物理单元</strong>。而<strong>Broker是Partition的物理载体</strong>，这些Partition分区会尽量均匀的分配到不同的Broker机器上。而之前接触到的offset，就是每个消息在partition上的偏移量。</p> 
<p><img alt="" height="628" src="https://images2.imgbox.com/11/44/lTJBLQo2_o.png" width="1200"></p> 
<blockquote> 
 <p><strong>Kafka为何要这样来设计Topic、Partition和Broker的关系呢？</strong></p> 
 <p>1、Kafka设计需要支持海量的数据，而这样庞大的数据量，一个Broker是存不下的。那就拆分成多个Partition，每个Broker只存一部分数据。这样<strong>极大的扩展了集群的吞吐量</strong>。</p> 
 <p>2、每个Partition保留了一部分的消息副本，如果放到一个Broker上，就容易出现单点故障。所以就给每个Partition设计Follower节点，进行数据备份，从而保证数据安全。另外，多备份的Partition设计也<strong>提高了读取消息时的并发度</strong>。</p> 
 <p>3、在同一个Topic的多个Partition中，会产生一个Partition作为Leader。这个Leader Partition会负责响应客户端的请求，并将数据往其他Partition分发。</p> 
 <p> </p> 
</blockquote> 
<h2>5.总结</h2> 
<p>        ​ 经过上面的实验，我们接触到了很多Kafka中的概念。将这些基础概念整合起来，就形成了Kafka集群的整体结构。这次我们先把这个整体结构梳理清楚，后续再一点点去了解其中的细节。</p> 
<p>        <img alt="" height="794" src="https://images2.imgbox.com/b1/e5/gzxZsAkx_o.png" width="1200"></p> 
<p>​ 1、Topic是一个逻辑概念，Producer和Consumer通过Topic进行业务沟通。</p> 
<p>​ 2、Topic并不存储数据，Topic下的数据分为多组Partition，尽量平均的分散到各个Broker上。每组Partition包含Topic下一部分的消息。每组Partition包含一个Leader Partition以及若干个Follower Partition进行备份，每组Partition的个数称为备份因子 replica factor。</p> 
<p>​ 3、Producer将消息发送到对应的Partition上，然后Consumer通过Partition上的Offset偏移量，记录自己所属消费者组Group在当前Partition上消费消息的进度。</p> 
<p>​ 4、Producer发送给一个Topic的消息，会由Kafka推送给所有订阅了这个Topic的消费者组进行处理。但是在每个消费者组内部，只会有一个消费者实例处理这一条消息。</p> 
<p>​ 5、最后，Kafka的Broker通过Zookeeper组成集群。然后在这些Broker中，需要选举产生一个担任Controller角色的Broker。这个Controller的主要任务就是负责Topic的分配以及后续管理工作。在我们实验的集群中，这个Controller实际上是通过ZooKeeper产生的。</p> 
<p> </p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/2954c4dec2bde901af5025b8b160d7ec/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Python-动态烟花【附完整源码】</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/992499c15d444c9320d33b89e86aac3c/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">[MySQL]:详细MySQL8.0完整的下载安装教程</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>