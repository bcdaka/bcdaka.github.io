<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>大数据开发之Hive（详细版，最后有实战训练） - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/f84fd5f547117abfdac0abe909e9fac5/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="大数据开发之Hive（详细版，最后有实战训练）">
  <meta property="og:description" content="第 1 章：Hive基本概念 1.1 Hive 1.1.1 Hive产生背景 HDFS来存储海量的数据、MapReduce来对海量数据进行分布式并行计算、Yarn来实现资源管理和作业调度。但是面对海量的数据和负责的业务逻辑，开发人员要编写MR对数据进行统计分析难度极大，所以就产生了Hive这个数仓工具。Hive可以帮助开发人员将SQL语句转化为MapReduce在yarn上跑。
1.1.2 hive简介 Hive是基于hadoop的一个数据仓库工具，将结构化的数据文件映射成一张表，并提供类SQL（HQL）查询功能。
1.1.3 Hive本质：将HQL（hiveSQL）转化成MapReduce程序 1、Hive处理的数据存储在HDFS
2、Hive分析数据底层的实现是MapReduce
3、执行程序运行在Yarn上
4、结构化文件如何映射成一张表呢？借助存储在元数据数据库中的元数据来解析结构化文件。
1.2 Hive架构原理 1.2.1 Hive架构介绍 1）用户结构：ClientCLI（command-line interface）、JDBC/ODBC（jdbc访问hive）2）元数据：Metastore元数据包括：表名、表所属的数据库（默认是default）、表的拥有者、列/分区字段、表的类型（是否是外部表）、表的数据所在目录等；默认存储在自带的derby数据库中，推荐使用MySQL存储Metastore3) Hadoop使用HDFS进行存储，使用MapReduce进行计算4) 驱动器：Driver解析器（SQL Parser）将SQL字符串转换成抽象语法树AST，这一步一般都用第三方工具库完成，比如antlr；对AST进行语法分析，比如表是否存在、字段是否存在、SQL语义是否有误编译器（Physical Plan）将AST编译生成逻辑执行计划优化器（Query Optimizer）对逻辑执行计划进行优化执行器（Execution）把逻辑执行计划转换成可以运行的物理计划。对于Hive来说，就是MR/Spark 1.2.2 Hive的运行机制 hive通过给用户提供的一系列交互接口，接受到的用户指令（SQL），使用自己Driver，结合元数据（metaStore），将这些指令翻译成MapReduce，提交到Hadoop中执行，最后，将执行返回的结果输出到用户交互接口中。
1.3 Hive和数据库比较 Hivemysql语言类sqlsql语言规模大数据pd及以上数据量小一般在百万左右到达单表极限数据插入能增加insert，不能update，delete能insert，update，delete数据存储Hdfs拥有自己的存储空间计算引擎MapReduce/Spark/tez自己的引擎innodb 第 2 章：Hive安装 2.1 修改hadoop相关参数 1）修改core-site.xml
1、配置该superUser允许通过代理访问的主机节点
2、配置该superUser允许通过代理用户所属组
3、配置该superUser允许通过代理的用户
2）配置yarn-site.xml
1、NodeManager使用内存数，默认是8G，修改成4G内存
2、容器最小内存，默认512M
3、容器最大内存，默认是8G，修改成4G
4、关闭虚拟内存检查（默认开启）
3）分发修改后的配置文件
2.2 Hive解压安装 1）上传压缩包到linux的/opt/softsware目录下
2）将/opt/softsware目录下的压缩包解压到/opt/module目录下
3）将解压后的文件修改成hive
4）修改/etc/profile.d/my_env.sh文件，将hive的/bin目录添加到环境变量
2.3 Hive元数据的三种部署方式 2.3.1 元数据库之Derby 这种方式适用于轻量级或者单机模式的部署，通常用于测试或开发环境。配置相对简单，但不适合高可用性和大规模部署。
1、内嵌模式示意图：
2、Derby数据库：
Derby数据库是Java编写的内存数据库，在内嵌模式中与应用程序共享一个JVM，应用程序负责启动和停止。
3、初始化Derby数据库：
1）在hive根目录下，使用/bin目录下的schematool命令初始化hive自带的Derby元数据库
2）执行上述初始化元数据库时，会发生存在jar包冲突问题
3）解决jar包冲突问题，只需要把hive的/lib目录下的log4j~.jar重命名即可
4、启动Hive
1）执行/bin目录下的hive命令，就可以启动hive，并通过cli方式连接到hive">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-01-14T11:28:18+08:00">
    <meta property="article:modified_time" content="2024-01-14T11:28:18+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">大数据开发之Hive（详细版，最后有实战训练）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_1_Hive_0"></a>第 1 章：Hive基本概念</h2> 
<h3><a id="11_Hive_1"></a>1.1 Hive</h3> 
<h4><a id="111_Hive_2"></a>1.1.1 Hive产生背景</h4> 
<p>HDFS来存储海量的数据、MapReduce来对海量数据进行分布式并行计算、Yarn来实现资源管理和作业调度。但是面对海量的数据和负责的业务逻辑，开发人员要编写MR对数据进行统计分析难度极大，所以就产生了Hive这个数仓工具。Hive可以帮助开发人员将SQL语句转化为MapReduce在yarn上跑。</p> 
<h4><a id="112_hive_4"></a>1.1.2 hive简介</h4> 
<p>Hive是基于hadoop的一个数据仓库工具，将结构化的数据文件映射成一张表，并提供类SQL（HQL）查询功能。</p> 
<h4><a id="113_HiveHQLhiveSQLMapReduce_6"></a>1.1.3 Hive本质：将HQL（hiveSQL）转化成MapReduce程序</h4> 
<p><img src="https://images2.imgbox.com/83/9b/RxAOR95R_o.png" alt="在这里插入图片描述"><br> 1、Hive处理的数据存储在HDFS<br> 2、Hive分析数据底层的实现是MapReduce<br> 3、执行程序运行在Yarn上<br> 4、结构化文件如何映射成一张表呢？借助存储在元数据数据库中的元数据来解析结构化文件。</p> 
<h3><a id="12_Hive_12"></a>1.2 Hive架构原理</h3> 
<p><img src="https://images2.imgbox.com/08/b0/q2Lx4hUO_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="121_Hive_14"></a>1.2.1 Hive架构介绍</h4> 
<table><thead><tr><th>1）用户结构：Client</th><th>CLI（command-line interface）、JDBC/ODBC（jdbc访问hive）</th><th></th></tr></thead><tbody><tr><td>2）元数据：Metastore</td><td>元数据包括：表名、表所属的数据库（默认是default）、表的拥有者、列/分区字段、表的类型（是否是外部表）、表的数据所在目录等；默认存储在自带的derby数据库中，推荐使用MySQL存储Metastore</td><td></td></tr><tr><td>3) Hadoop</td><td>使用HDFS进行存储，使用MapReduce进行计算</td><td></td></tr><tr><td>4) 驱动器：Driver</td><td>解析器（SQL Parser）</td><td>将SQL字符串转换成抽象语法树AST，这一步一般都用第三方工具库完成，比如antlr；对AST进行语法分析，比如表是否存在、字段是否存在、SQL语义是否有误</td></tr><tr><td></td><td>编译器（Physical Plan）</td><td>将AST编译生成逻辑执行计划</td></tr><tr><td></td><td>优化器（Query Optimizer）</td><td>对逻辑执行计划进行优化</td></tr><tr><td></td><td>执行器（Execution）</td><td>把逻辑执行计划转换成可以运行的物理计划。对于Hive来说，就是MR/Spark</td></tr></tbody></table> 
<h4><a id="122_Hive_23"></a>1.2.2 Hive的运行机制</h4> 
<p><img src="https://images2.imgbox.com/d1/d8/o6rIqXqB_o.png" alt="在这里插入图片描述"><br> hive通过给用户提供的一系列交互接口，接受到的用户指令（SQL），使用自己Driver，结合元数据（metaStore），将这些指令翻译成MapReduce，提交到Hadoop中执行，最后，将执行返回的结果输出到用户交互接口中。</p> 
<h3><a id="13_Hive_26"></a>1.3 Hive和数据库比较</h3> 
<table><thead><tr><th></th><th>Hive</th><th>mysql</th></tr></thead><tbody><tr><td>语言</td><td>类sql</td><td>sql</td></tr><tr><td>语言规模</td><td>大数据pd及以上</td><td>数据量小一般在百万左右到达单表极限</td></tr><tr><td>数据插入</td><td>能增加insert，不能update，delete</td><td>能insert，update，delete</td></tr><tr><td>数据存储</td><td>Hdfs</td><td>拥有自己的存储空间</td></tr><tr><td>计算引擎</td><td>MapReduce/Spark/tez</td><td>自己的引擎innodb</td></tr></tbody></table> 
<h2><a id="_2_Hive_34"></a>第 2 章：Hive安装</h2> 
<h3><a id="21_hadoop_35"></a>2.1 修改hadoop相关参数</h3> 
<p>1）修改core-site.xml<br> 1、配置该superUser允许通过代理访问的主机节点<br> 2、配置该superUser允许通过代理用户所属组<br> 3、配置该superUser允许通过代理的用户</p> 
<p>2）配置yarn-site.xml<br> 1、NodeManager使用内存数，默认是8G，修改成4G内存<br> 2、容器最小内存，默认512M<br> 3、容器最大内存，默认是8G，修改成4G<br> 4、关闭虚拟内存检查（默认开启）</p> 
<p>3）分发修改后的配置文件</p> 
<h3><a id="22_Hive_48"></a>2.2 Hive解压安装</h3> 
<p>1）上传压缩包到linux的/opt/softsware目录下<br> 2）将/opt/softsware目录下的压缩包解压到/opt/module目录下<br> 3）将解压后的文件修改成hive<br> 4）修改/etc/profile.d/my_env.sh文件，将hive的/bin目录添加到环境变量</p> 
<h3><a id="23_Hive_53"></a>2.3 Hive元数据的三种部署方式</h3> 
<h4><a id="231_Derby_54"></a>2.3.1 元数据库之Derby</h4> 
<p>这种方式适用于轻量级或者单机模式的部署，通常用于测试或开发环境。配置相对简单，但不适合高可用性和大规模部署。<br> 1、内嵌模式示意图：<br> <img src="https://images2.imgbox.com/a7/a0/5r5FezjU_o.png" alt="在这里插入图片描述"><br> 2、Derby数据库：<br> Derby数据库是Java编写的内存数据库，在内嵌模式中与应用程序共享一个JVM，应用程序负责启动和停止。</p> 
<p>3、初始化Derby数据库：<br> 1）在hive根目录下，使用/bin目录下的schematool命令初始化hive自带的Derby元数据库<br> 2）执行上述初始化元数据库时，会发生存在jar包冲突问题<br> 3）解决jar包冲突问题，只需要把hive的/lib目录下的log4j~.jar重命名即可</p> 
<p>4、启动Hive<br> 1）执行/bin目录下的hive命令，就可以启动hive，并通过cli方式连接到hive<br> 2）使用hive</p> 
<ul><li>show databases; 查看当前所有的数据库</li><li>show tables; 查看当前所有的表</li><li>create table test_derby(id int); 创建表</li><li>insert into test_derby values(1001); 插入数据</li><li>select * from test_derby; 查看数据</li></ul> 
<p>5、内嵌模式只有一个JVM进程<br> 在内嵌模式下，命令行执行jps -ml命令，只能看到一个CliDriver进程。</p> 
<h4><a id="232_Mysql_78"></a>2.3.2 元数据库之Mysql</h4> 
<p>这种方式更加适合生产环境，因为它支持多用户并发访问和更好的可伸延性。需要额外的配置和管理数据库服务。<br> 1、直连模式示意图：<br> <img src="https://images2.imgbox.com/72/a9/vx4v0esz_o.png" alt="在这里插入图片描述"><br> 2、Mysql安装部署<br> 1）检测当前系统是否安装过Mysql，如果安装过删除掉<br> 2）将Mysql安装包上传至/opt/software目录下<br> 3）解压到/opt/software下新建的mysql_jars目录<br> 4）查看mysql_jars目录下文件<br> 5）在/opt/software/mysql_jars目录下执行rpm安装，按顺序<br> 6）如果在mysql的数据存储路径下有文件存在，需要将其全部删除，存储路径地址在/etc/my.cnf文件下datadir参数所对应的值<br> 7）初始化数据库，查看临时的root用户的密码<br> 8）启动mysql服务<br> 9）登录mysql，修改root用户的密码<br> 10）修改mysql库下的user表中的root用户允许任意ip连接<br> 11）刷新，使得修改生效</p> 
<p>3、配置Hive元数据库为MySQL<br> 1）拷贝驱动<br> Hive需要将元数据信息存储到元数据库mysql中，需要使用JDBC的方式连接到Mysql，所以，将Mysql的JDBC驱动拷贝到Hive的lib目录下，供hive调用。<br> 2）配置Metastore到Mysql<br> 在/opt/module/hive/conf目录下新建hive-site.xml文件<br> （1）jdbc连接的URL<br> （2）jdbc连接的Driver<br> （3）jdbc连接的username<br> （4）jdbc连接的password<br> （5）Hive默认在HDFS的工作目录<br> （6）Hive元数据存储的验证设置false<br> （7）元数据存储授权设置false</p> 
<p>4、Hive初始化元数据库<br> 在mysql中创建hive存储元数据的数据库metastore，再通过hive的初始化元数据库操作创建表<br> 1）登录mysql<br> 2）新建Hive元数据库<br> 3）初始化Hive元数据库</p> 
<p>5、启动Hive<br> 1）启动Hive<br> 2）使用hive</p> 
<ul><li>show databases; 查看当前所有的数据库</li><li>show tables; 查看当前所有的表</li><li>create table test_mysql(id int); 创建表</li><li>insert into test_mysql values(1002); 插入数据</li><li>select * from test_mysql; 查看数据</li></ul> 
<p>3）开启另一个窗口测试，是否支持客户端并发操作</p> 
<p>6、在公司生产环境中，网络环境非常的复杂，mysql的所在环境可能存在网络隔离，无法直接访问；另外，mysql的root账户和密码在此模式下会存在泄露风险，存在数据安全隐患。</p> 
<h4><a id="233_MetaStore_Server_127"></a>2.3.3 元数据之MetaStore Server</h4> 
<p>在这种模式下，Hive与Hadoop生态系统中的其他组件共享元数据，这种方式可以实现元数据的高度集成和优化。<br> 1、元数据服务模式示意图：<br> <img src="https://images2.imgbox.com/33/c2/alupreeI_o.png" alt="在这里插入图片描述"><br> 2、元数据服务模式<br> 在服务器端访问MetaStore服务，客户端利用Thrift协议通过MetaStore服务访问元数据库。相比于内嵌式，这种更适合在生产环境中部署使用。</p> 
<p>3、将Mysql作为元数据库，配置元数据服务<br> 1）首先，将hive的元数据库配置为Mysql，编写hive-site.xml文件。在配置完后，启动hive之前必须先启动元数据服务，否则，hive启动后无法连接到元数据服务。<br> 2）启动元数据服务<br> 注意：启动后窗口不能再操作，需打开一个新的shell窗口做别的操作。<br> （1）启动hive，查看表和表中的数据，是否是Mysql数据库中的表。<br> （2）再另一个窗口启动hive，测试多客户端能否同时连接操作。</p> 
<h3><a id="24_hive_141"></a>2.4 hive的两种访问方式</h3> 
<h4><a id="241__142"></a>2.4.1 命令行方式</h4> 
<p>1、cli太过笨重，需要hive的jar支持。</p> 
<h4><a id="242_HiveServe2__144"></a>2.4.2 HiveServe2 模式</h4> 
<p>1、JDBC访问Hive示意图：<br> <img src="https://images2.imgbox.com/0d/26/ZXHBTdKC_o.png" alt="在这里插入图片描述"><br> 2、JDBC方式访问Hive<br> 将hive包装为服务发布出去，开发者使用JDBC的方式连接到服务，从而操作hive，减少对hive环境的依赖。</p> 
<p>3、开启Hiveserver2<br> 1）在hive-site.xml文件中添加如下配置信息<br> （1）指定hiveserver2连接的host<br> （2）指定hiveserver2连接的端口号<br> 2）重启MetaStore服务<br> 3）启动hive服务（如果是使用元数据服务的模式，需要提前开启元数据服务）<br> 4）启动beeline服务</p> 
<h3><a id="25_Hive_157"></a>2.5 Hive常用交互命令</h3> 
<h4><a id="251_binhive_158"></a>2.5.1 查看bin/hive命令帮助</h4> 
<ul><li>bin/hive -help</li></ul> 
<h4><a id="252_e_161"></a>2.5.2 命令中参数-e的使用</h4> 
<p>使用-e参数，可以不进入hive的交互窗口执行sql语句</p> 
<h4><a id="253_f_163"></a>2.5.3 命令中参数-f的使用</h4> 
<p>使用-f参数，可以不进入hive交互窗口，执行脚本中sql语句<br> 1）在/opt/module/hive/下创建datas目录并在目录下创建hive-f.sql文件<br> 2）文件中写入正确的sql语句<br> 3）执行文件中的sql语句，还可以将结果写入指定文件中</p> 
<h2><a id="_3__Hive_168"></a>第 3 章 Hive数据类型</h2> 
<h3><a id="31__169"></a>3.1 基本数据类型</h3> 
<table><thead><tr><th>Hive数据类型</th><th>Java数据类型</th><th>长度</th></tr></thead><tbody><tr><td>TINYINT</td><td>byte</td><td>1byte有符号整数</td></tr><tr><td>SWALINT</td><td>short</td><td>2byte有符号整数</td></tr><tr><td>INT</td><td>int</td><td>4byte有符号整数</td></tr><tr><td>BIGINT</td><td>long</td><td>8byte有符号整数</td></tr><tr><td>BOOLEAN</td><td>boolean</td><td>布尔类型，true或者false</td></tr><tr><td>FLOAT</td><td>float</td><td>单精度浮点数</td></tr><tr><td>DOUBLE</td><td>double</td><td>双精度浮点数</td></tr><tr><td>STRING</td><td>string</td><td>字符系列。可以使用单引号或者双引号</td></tr><tr><td>TIMESTAMP</td><td></td><td>时间类型</td></tr><tr><td>BINARY</td><td></td><td>字节数组</td></tr></tbody></table> 
<p>Hive的String类型不用声明其中最多能存储多少个字符，理论上它可以存储2GB的字符数。</p> 
<h3><a id="32__184"></a>3.2 集合数据类型</h3> 
<table><thead><tr><th>数据类型</th><th>描述</th><th>语法示例</th></tr></thead><tbody><tr><td>STRUCT</td><td>和c语言中的struct类似，都可以通过“点”符号访问元素内容。例如：如果某个列的数据类型是STRUCT{first STRING, last String}，那么第1个元素可以通过字段.first来引用。</td><td>struct() 例如： struct&lt;street:string,city:string&gt;</td></tr><tr><td>MAP</td><td>MAP是一组键-值对元组集合，使用数组表示法可以访问数据。例如：如果某个列的数据类型是MAP，其中键-&gt;值对是’first’-&gt;'john’和‘last’-&gt;‘doe’，那么可以通过字段名[‘last’]获取最后一个元素</td><td>map() 例如：map&lt;string,int&gt;</td></tr><tr><td>ARRAY</td><td>数组是一组具有相同类型和名称的变量的集合。这些变量称为数组的元素，每个数组元素都有一个编号，编号从零开始。例如：数组值为[‘john’,‘doe’] ，那么第2个元素可以通过数组名[1]进行引用</td><td>Array() 例如：array</td></tr></tbody></table> 
<h3><a id="33__191"></a>3.3 案例操作</h3> 
<h4><a id="331__192"></a>3.3.1 简单了解前后端的数据传输</h4> 
<p><img src="https://images2.imgbox.com/f2/24/PS5FXZb2_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="332__194"></a>3.3.2 数据结构映射</h4> 
<p>1）假设某表有如下一行，我们用JSON格式来表示其数据结构。在Hive下访问的格式为</p> 
<pre><code class="prism language-bash"><span class="token punctuation">{<!-- --></span>
    <span class="token string">"name"</span><span class="token builtin class-name">:</span> <span class="token string">"songsong"</span>,
    <span class="token string">"friends"</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span><span class="token string">"bingbing"</span> , <span class="token string">"lili"</span><span class="token punctuation">]</span> ,       //列表Array, 
    <span class="token string">"children"</span><span class="token builtin class-name">:</span> <span class="token punctuation">{<!-- --></span>                      //键值Map,
        <span class="token string">"xiao song"</span><span class="token builtin class-name">:</span> <span class="token number">19</span> ,
        <span class="token string">"xiaoxiao song"</span><span class="token builtin class-name">:</span> <span class="token number">18</span>
    <span class="token punctuation">}</span>
    <span class="token string">"address"</span><span class="token builtin class-name">:</span> <span class="token punctuation">{<!-- --></span>                      //结构Struct,
        <span class="token string">"street"</span><span class="token builtin class-name">:</span> <span class="token string">"hui long guan"</span> ,
        <span class="token string">"city"</span><span class="token builtin class-name">:</span> <span class="token string">"beijing"</span> 
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>2）基于上述数据结构，我们在Hive里创建对应的表，并导入数据。<br> 在目录/opt/module/hive/datas下创建本地测试文件personInfo.txt</p> 
<ul><li>vim personInfo.txt</li></ul> 
<pre><code class="prism language-bash">songsong,bingbing_lili,xiao song:18_xiaoxiao song:19,hui long guan_beijing
yangyang,caicai_susu,xiao yang:18_xiaoxiao yang:19,chao yang_beijing
</code></pre> 
<h4><a id="333__220"></a>3.3.3 测试案例</h4> 
<p>1）Hive上创建测试表personInfo</p> 
<pre><code class="prism language-bash">hive<span class="token punctuation">(</span>default<span class="token punctuation">)</span><span class="token operator">&gt;</span>create table personInfo <span class="token punctuation">(</span>
name string,
friends array<span class="token operator">&lt;</span>string<span class="token operator">&gt;</span>,
children map<span class="token operator">&lt;</span>string, int<span class="token operator">&gt;</span>,
address struct<span class="token operator">&lt;</span>street:string, city:string<span class="token operator">&gt;</span>
<span class="token punctuation">)</span>

row <span class="token function">format</span> delimited
fields terminated by <span class="token string">','</span>
collection items terminated by <span class="token string">'_'</span>
map keys terminated by <span class="token string">':'</span>
lines terminated by <span class="token string">'\n'</span><span class="token punctuation">;</span>

指定数据文件中行格式的分隔符
指定字段之间用’,’进行分割
指定集合类型的元素之间用’_’进行分割
指定map类型中key和value用’:’进行分割
指定行之间的分隔符为’<span class="token punctuation">\</span>n’
</code></pre> 
<p>2）上传数据到hdfs中上述表的对应路径</p> 
<pre><code class="prism language-bash">hadoop fs  <span class="token parameter variable">-put</span> /opt/module/hive/datas/personInfo.txt /user/hive/warehouse/personInfo<span class="token punctuation">;</span> 
</code></pre> 
<p>3）访问三种集合列里的数据，以下分别是ARRAY，MAP，STRUCT的访问方式</p> 
<pre><code class="prism language-bash"><span class="token keyword">select</span>
friends<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>,
children<span class="token punctuation">[</span><span class="token string">'xiao song'</span><span class="token punctuation">]</span>,
address.city
from personInfo
where <span class="token assign-left variable">name</span><span class="token operator">=</span><span class="token string">"songsong"</span><span class="token punctuation">;</span>
结果：
_c0     _c1     city
lili    <span class="token number">18</span>      beijing
</code></pre> 
<h3><a id="34__261"></a>3.4 类型转换</h3> 
<p>1）Hive的基本数据类型进行隐性转换类似Java<br> 2）隐式类型转换规则如下<br> （1）所有整数类型都可以隐式的转换为一个范围更广的类型，如INT可以转换成BIGINT。<br> （2）所有整数类型、FLOAT和STRING类型都可以隐式地转换成DOUBLE。<br> （3）TINYINT、SMALLINT、INT都可以转换为FLOAT。<br> （4）BOOLEAN类型不可以转换为任何其它的类型。<br> 3）可以使用CAST操作显示进行数据类型转换<br> 例如：CAST(‘1’ AS INT)将把字符串‘1’转换成整数1；</p> 
<h2><a id="4DDL__270"></a>第4章：DDL 数据定义</h2> 
<h3><a id="41__271"></a>4.1 创建数据库</h3> 
<p>1）创建数据库，数据库在HDFS上的默认存储路径是/usr/hive/warehouse/*.db。</p> 
<pre><code class="prism language-bash">create database bigdata<span class="token punctuation">;</span>
</code></pre> 
<p>2）避免要创建的数据库已经存在，增加if not exists判断。</p> 
<pre><code class="prism language-bash">create database <span class="token keyword">if</span> not exists bigdata<span class="token punctuation">;</span>
</code></pre> 
<p>3）创建一个数据库，指定数据库在HDFS上存放的位置</p> 
<pre><code class="prism language-bash">create database bigdata2 location <span class="token string">'/bigdata2.db'</span><span class="token punctuation">;</span>
</code></pre> 
<h3><a id="42__287"></a>4.2 查询数据库</h3> 
<h4><a id="421__288"></a>4.2.1 显示数据库</h4> 
<p>1）显示数据库</p> 
<pre><code class="prism language-bash">show databases<span class="token punctuation">;</span>
</code></pre> 
<p>2）过滤显示查询的数据库</p> 
<pre><code class="prism language-bash">show databases like <span class="token string">'bigdata*'</span><span class="token punctuation">;</span>
</code></pre> 
<h4><a id="422__299"></a>4.2.2 查看数据库详情</h4> 
<p>1）显示数据库信息</p> 
<pre><code class="prism language-bash">desc database bigdata<span class="token punctuation">;</span>
bigdata		hdfs://hadoop102:9000/user/hive/warehouse/bigdata.db	atguigu <span class="token environment constant">USER</span>	
</code></pre> 
<p>2）显示数据库详细信息，extended</p> 
<pre><code class="prism language-bash">desc database extended bigdata<span class="token punctuation">;</span>
bigdata		hdfs://hadoop102:9000/user/hive/warehouse/bigdata.db	atguigu <span class="token environment constant">USER</span>
</code></pre> 
<p>3）创建数据库bigdata3，并设置其createtime属性</p> 
<pre><code class="prism language-bash">create database bigdata3 with dbproperties<span class="token punctuation">(</span><span class="token string">'createtime'</span><span class="token operator">=</span><span class="token string">'20211022'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>4）再次查询</p> 
<pre><code class="prism language-bash">desc database bigdata3
OK
bigdata3                hdfs://hadoop102:8020/user/hive/warehouse/bigdata3.db   atguigu <span class="token environment constant">USER</span>

desc database extended bigdata3
OK
bigdata3                hdfs://hadoop102:8020/user/hive/warehouse/bigdata3.db   atguigu <span class="token environment constant">USER</span>    <span class="token punctuation">{<!-- --></span>createtime<span class="token operator">=</span><span class="token number">20211022</span><span class="token punctuation">}</span>
</code></pre> 
<h4><a id="423__328"></a>4.2.3 切换当前数据库</h4> 
<pre><code class="prism language-bash">use bigdata<span class="token punctuation">;</span>
</code></pre> 
<h3><a id="43__333"></a>4.3 修改数据库</h3> 
<p>用户可以使用ALTER DATABASE命令为某个数据库的DBPROPERTIES设置键-值对属性值，来描述这个数据库的属性信息。</p> 
<pre><code class="prism language-sql"><span class="token keyword">alter</span> <span class="token keyword">database</span> bigdata <span class="token keyword">set</span> dbproperties<span class="token punctuation">(</span><span class="token string">'createtime'</span><span class="token operator">=</span><span class="token string">'20211022'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<h3><a id="44__339"></a>4.4 删除数据库</h3> 
<p>1）删除空数据库</p> 
<pre><code class="prism language-sql"><span class="token keyword">drop</span> <span class="token keyword">database</span> <span class="token keyword">if</span> <span class="token keyword">exists</span> bigdata2
</code></pre> 
<p>2）如果数据库不为空，可以采用cascade命令，强制删除</p> 
<pre><code class="prism language-sql"><span class="token keyword">drop</span> <span class="token keyword">database</span> bigdata <span class="token keyword">cascade</span><span class="token punctuation">;</span>
</code></pre> 
<h3><a id="45__350"></a>4.5 创建表</h3> 
<p>1）建表语句</p> 
<pre><code class="prism language-sql"><span class="token keyword">CREATE</span> <span class="token punctuation">[</span>EXTERNAL<span class="token punctuation">]</span> <span class="token keyword">TABLE</span> <span class="token punctuation">[</span><span class="token keyword">IF</span> <span class="token operator">NOT</span> <span class="token keyword">EXISTS</span><span class="token punctuation">]</span> table_name 
<span class="token punctuation">[</span><span class="token punctuation">(</span>col_name data_type <span class="token punctuation">[</span><span class="token keyword">COMMENT</span> col_comment<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">]</span> 
<span class="token punctuation">[</span><span class="token keyword">COMMENT</span> table_comment<span class="token punctuation">]</span> 
<span class="token punctuation">[</span>PARTITIONED <span class="token keyword">BY</span> <span class="token punctuation">(</span>col_name data_type <span class="token punctuation">[</span><span class="token keyword">COMMENT</span> col_comment<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">]</span> 
<span class="token punctuation">[</span><span class="token keyword">CLUSTERED</span> <span class="token keyword">BY</span> <span class="token punctuation">(</span>col_name<span class="token punctuation">,</span> col_name<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span> 
<span class="token punctuation">[</span>SORTED <span class="token keyword">BY</span> <span class="token punctuation">(</span>col_name <span class="token punctuation">[</span><span class="token keyword">ASC</span><span class="token operator">|</span><span class="token keyword">DESC</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token keyword">INTO</span> num_buckets BUCKETS<span class="token punctuation">]</span> 
<span class="token punctuation">[</span><span class="token keyword">ROW</span> FORMAT row_format<span class="token punctuation">]</span> 
<span class="token punctuation">[</span>STORED <span class="token keyword">AS</span> file_format<span class="token punctuation">]</span> 
<span class="token punctuation">[</span>LOCATION hdfs_path<span class="token punctuation">]</span>
<span class="token punctuation">[</span>TBLPROPERTIES <span class="token punctuation">(</span>property_name<span class="token operator">=</span>property_value<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
<span class="token punctuation">[</span><span class="token keyword">AS</span> select_statement<span class="token punctuation">]</span>
<span class="token punctuation">[</span>LIKES existing_table_or_view_name<span class="token punctuation">]</span>
</code></pre> 
<p>2）字段解释说明</p> 
<table><thead><tr><th>CREATE TABLE</th><th>创建一个指定名称的表。如果相同名称的表已经存在，则抛出异常；用户可以用 IF NOT EXISTS 选项忽略这个异常</th></tr></thead><tbody><tr><td>EXTERNAL</td><td>1）关键字可以让用户创建一个外部表，在建表的同时可以指定一个指向实际数据的路径（LOCATION）2）在删除表的适合，内部表的元数据和数据都被一起删除，外部表只删除元数据，不删除数据。</td></tr><tr><td>COMMENT</td><td>为表和列添加注释</td></tr><tr><td>PARTITIONED BY</td><td>创建分区表</td></tr><tr><td>CLUSTERED BY</td><td>创建分桶表</td></tr><tr><td>SORTED BY</td><td>不常用，对桶中的一个或多个列另外排序</td></tr><tr><td>ROW FROMAT</td><td>Fields 指定字段之间的分隔符；Collection 用于指定集合中元素的分隔符等</td></tr><tr><td>STORE AS</td><td>指定存储文件类型：如SEQUENCEFILE（二进制序列文件）、TEXTFILE（文本）、RCFILE（列式存储格式文件）</td></tr><tr><td>LOCATION</td><td>指定表在HDFS上的存储位置</td></tr><tr><td>AS</td><td>后跟查询语句，根据查询语句结果创建表</td></tr><tr><td>LIKE</td><td>允许用户复制现有的表结构，但是不复制数据</td></tr></tbody></table> 
<h4><a id="451__380"></a>4.5.1 管理表（内部表）</h4> 
<p>1）理论</p> 
<ul><li>默认创建的表都是所谓的管理表，有时也被称为内部表。</li><li>管理表，Hive会控制着元数据和真实数据的生命周期。</li><li>Hive默认会将这些表的数据存储在hive.metastore.warehouse.dir定义目录的子目录下。</li><li>当我们删除一个管理表时，Hive也会删除这个表中数据。</li><li>管理表不适合和其他工具共享数据。</li></ul> 
<p>2）案例实操<br> 创建数据文件，在/opt/module/hive/datas目录下创建文件student.txt，编辑如下内容：</p> 
<pre><code class="prism language-sql">vim student<span class="token punctuation">.</span>txt
<span class="token number">1001</span>	ss1
<span class="token number">1002</span>	ss2
<span class="token number">1003</span>	ss3
<span class="token number">1004</span>	ss4
<span class="token number">1005</span>	ss5
<span class="token number">1006</span>	ss6
<span class="token number">1007</span>	ss7
<span class="token number">1008</span>	ss8
<span class="token number">1009</span>	ss9
</code></pre> 
<p>（1）创建内部表student</p> 
<pre><code class="prism language-sql"><span class="token keyword">create</span> <span class="token keyword">table</span> <span class="token keyword">if</span> <span class="token operator">not</span> <span class="token keyword">exists</span> student<span class="token punctuation">(</span>
id <span class="token keyword">int</span><span class="token punctuation">,</span>
name string
<span class="token punctuation">)</span>
<span class="token keyword">row</span> format delimited
<span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'\t'</span>
stored <span class="token keyword">as</span> textfile
location <span class="token string">'/user/hive/warehouse/student'</span><span class="token punctuation">;</span> 
</code></pre> 
<p>（2）查询表的类型</p> 
<pre><code class="prism language-sql"><span class="token keyword">desc</span> formatted student<span class="token punctuation">;</span>
<span class="token keyword">Table</span> <span class="token keyword">Type</span>:             MANAGED_TABLE 
</code></pre> 
<p>（3）根据查询结果创建表（查询的结果会添加到新创建的表中）</p> 
<pre><code class="prism language-sql"><span class="token keyword">create</span> <span class="token keyword">table</span> <span class="token keyword">if</span> <span class="token operator">not</span> <span class="token keyword">exists</span> student2 <span class="token keyword">as</span> <span class="token keyword">select</span> id<span class="token punctuation">,</span> name <span class="token keyword">from</span> student<span class="token punctuation">;</span>
</code></pre> 
<p>（4）根据已经存在的表结构创建表</p> 
<pre><code class="prism language-sql"><span class="token keyword">create</span> <span class="token keyword">table</span> <span class="token keyword">if</span> <span class="token operator">not</span> <span class="token keyword">exists</span> student3 <span class="token operator">like</span> student<span class="token punctuation">;</span>
</code></pre> 
<p>（5）查询表的类型</p> 
<pre><code class="prism language-sql"><span class="token keyword">desc</span> formatted student2<span class="token punctuation">;</span>
<span class="token keyword">Table</span> <span class="token keyword">Type</span>:             MANAGED_TABLE  
</code></pre> 
<p>（6）删除表student2后，观察表的元数据和数据文件是否还存在</p> 
<pre><code class="prism language-sql"><span class="token keyword">drop</span> <span class="token keyword">table</span> student2<span class="token punctuation">;</span>
</code></pre> 
<h4><a id="452__443"></a>4.5.2 外部表</h4> 
<p>1、理论<br> 因为表是外部表，所以Hive并非认为其完全拥有这份数据。删除该表并不会删除掉这份数据，不过描述表的元数据信息会被删除掉。<br> 元数据信息：指存储在Hive元数据仓库中的关于表的信息，例如表名、表结构（列名和数据类型）、表的物理位置（文件路径）等。这些信息帮助Hive了解如何访问和解释存储在外部位置的数据。<br> 2、管理表和外部表的使用场景<br> 外部表多用来存储原始数据，采用外部表交易共享数据。在原始数据基础上做大量的统计分析，中间用到的中间表、结果表多存于内部表。<br> 3、案例实操<br> 1）创建teacher.txt</p> 
<pre><code class="prism language-sql"><span class="token number">1001</span>	teacher1
<span class="token number">1002</span>	teacher2
<span class="token number">1003</span>	teacher3		
<span class="token number">1004</span>	teacher4
<span class="token number">1005</span>	teacher5
</code></pre> 
<p>2）上传数据到HDFS</p> 
<pre><code class="prism language-sql">hadoop fs <span class="token operator">-</span>mkdir <span class="token operator">-</span>p <span class="token operator">/</span>school<span class="token operator">/</span>teacher
hadoop fs <span class="token operator">-</span>put teacher<span class="token punctuation">.</span>txt <span class="token operator">/</span>school<span class="token operator">/</span>teacher
</code></pre> 
<p>3）在hive中创建外部表teacher</p> 
<pre><code class="prism language-sql"><span class="token keyword">create</span> external <span class="token keyword">table</span> <span class="token keyword">if</span> <span class="token operator">not</span> <span class="token keyword">exists</span> teacher<span class="token punctuation">(</span>
    id <span class="token keyword">int</span><span class="token punctuation">,</span> 
    name string
<span class="token punctuation">)</span>
<span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'\t'</span>
location <span class="token string">'/school/teacher'</span><span class="token punctuation">;</span>
</code></pre> 
<p>4）查看创建的表</p> 
<pre><code class="prism language-sql"><span class="token keyword">show</span> <span class="token keyword">tables</span><span class="token punctuation">;</span>
</code></pre> 
<p>5）查看表格式化信息</p> 
<pre><code class="prism language-sql"><span class="token keyword">desc</span> formatted dept<span class="token punctuation">;</span>
<span class="token keyword">Table</span> <span class="token keyword">Type</span>:             EXTERNAL_TABLE
</code></pre> 
<p>6）删除外部表，观察表的元数据和相应hdfs中的数据</p> 
<pre><code class="prism language-sql"><span class="token keyword">drop</span> <span class="token keyword">table</span> dept<span class="token punctuation">;</span>
</code></pre> 
<p>外部表删除后，hdfs中的数据还在，但是metadata中dept的元数据已被删除</p> 
<h4><a id="453__492"></a>4.5.3 管理表与外部表的互相转换</h4> 
<p>1）查询表的类型</p> 
<pre><code class="prism language-sql"><span class="token keyword">desc</span> formatted student2<span class="token punctuation">;</span>
<span class="token keyword">Table</span> <span class="token keyword">Type</span>:             MANAGED_TABLE
</code></pre> 
<p>2）修改内部表student2为外部表</p> 
<pre><code class="prism language-sql"><span class="token keyword">alter</span> <span class="token keyword">table</span> student2 <span class="token keyword">set</span> tblproperties<span class="token punctuation">(</span><span class="token string">'EXTERNAL'</span><span class="token operator">=</span><span class="token string">'TRUE'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>3）查询表的类型</p> 
<pre><code class="prism language-sql"><span class="token keyword">desc</span> formatted student2<span class="token punctuation">;</span>
<span class="token keyword">Table</span> <span class="token keyword">Type</span>:             EXTERNAL_TABLE
</code></pre> 
<p>4）修改外部表student2为内部表</p> 
<pre><code class="prism language-sql"><span class="token keyword">alter</span> <span class="token keyword">table</span> student2 <span class="token keyword">set</span> tblproperties<span class="token punctuation">(</span><span class="token string">'EXTERNAL'</span><span class="token operator">=</span><span class="token string">'FALSE'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<h3><a id="46__515"></a>4.6 修改表</h3> 
<h4><a id="461__516"></a>4.6.1 重命名表</h4> 
<p>1、语法</p> 
<pre><code class="prism language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> table_name <span class="token keyword">RENAME</span> <span class="token keyword">TO</span> new_table_name
</code></pre> 
<p>2、实操案例</p> 
<pre><code class="prism language-sql"><span class="token keyword">alter</span> <span class="token keyword">table</span> student3 <span class="token keyword">rename</span> <span class="token keyword">to</span> student4<span class="token punctuation">;</span>
</code></pre> 
<h4><a id="462__527"></a>4.6.2 增加/修改/替换列信息</h4> 
<p>1、语法<br> 1）更新列</p> 
<pre><code class="prism language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> table_name CHANGE <span class="token punctuation">[</span><span class="token keyword">COLUMN</span><span class="token punctuation">]</span> col_old_name col_new_name column_type <span class="token punctuation">[</span><span class="token keyword">COMMENT</span> col_comment<span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token keyword">FIRST</span><span class="token operator">|</span><span class="token keyword">AFTER</span> column_name<span class="token punctuation">]</span>
</code></pre> 
<p>2）增加和替换列</p> 
<pre><code class="prism language-sql"><span class="token keyword">ALTER</span> <span class="token keyword">TABLE</span> table_name <span class="token keyword">ADD</span><span class="token operator">|</span><span class="token keyword">REPLACE</span> <span class="token keyword">COLUMNS</span> <span class="token punctuation">(</span>col_name data_type <span class="token punctuation">[</span><span class="token keyword">COMMENT</span> col_comment<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span> 
</code></pre> 
<p>2、实操案例<br> 1）查询表结构</p> 
<pre><code class="prism language-sql"><span class="token keyword">desc</span> test2<span class="token punctuation">;</span>
OK
col_name        data_type       <span class="token keyword">comment</span>
id                      <span class="token keyword">int</span>         
</code></pre> 
<p>2）更新列：将列名id修改为student_id，类型不变</p> 
<pre><code class="prism language-sql"> <span class="token keyword">alter</span> <span class="token keyword">table</span> test2 change <span class="token keyword">column</span> id student_id <span class="token keyword">int</span><span class="token punctuation">;</span>
OK
<span class="token keyword">Time</span> taken: <span class="token number">0.083</span> seconds
<span class="token keyword">desc</span> test2<span class="token punctuation">;</span>
OK
col_name        data_type       <span class="token keyword">comment</span>
student_id              <span class="token keyword">int</span>        
</code></pre> 
<p>3）更新列：不修改列名，仅修改列的类型为string</p> 
<pre><code class="prism language-sql"><span class="token keyword">alter</span> <span class="token keyword">table</span> test2 change <span class="token keyword">column</span> student_id student_id string<span class="token punctuation">;</span>
OK
<span class="token keyword">Time</span> taken: <span class="token number">0.083</span> seconds
<span class="token keyword">desc</span> test2<span class="token punctuation">;</span>
OK
col_name        data_type       <span class="token keyword">comment</span>
student_id              string  
</code></pre> 
<p>4）新增列：向test2表中新增一列，列名为name，类型为string</p> 
<pre><code class="prism language-sql"><span class="token keyword">alter</span> <span class="token keyword">table</span> test2 <span class="token keyword">add</span> <span class="token keyword">columns</span><span class="token punctuation">(</span>name string<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">desc</span> test2<span class="token punctuation">;</span>
OK
col_name        data_type       <span class="token keyword">comment</span>
student_id              string                                      
name                    string
</code></pre> 
<p>5）调整列的位置：现在想让name的列在最前面，做如下操作</p> 
<pre><code class="prism language-sql"><span class="token keyword">alter</span> <span class="token keyword">table</span> test2 change name name string <span class="token keyword">first</span><span class="token punctuation">;</span>
OK
<span class="token keyword">Time</span> taken: <span class="token number">0.139</span> seconds
<span class="token keyword">desc</span> test2<span class="token punctuation">;</span>
OK
col_name        data_type       <span class="token keyword">comment</span>
name                    string                                      
student_id              string                                      
<span class="token keyword">Time</span> taken: <span class="token number">0.036</span> seconds<span class="token punctuation">,</span> Fetched: <span class="token number">2</span> <span class="token keyword">row</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span>
</code></pre> 
<p>6）调整列的位置：将name更新到指定列的后面，操作如下</p> 
<pre><code class="prism language-sql"><span class="token keyword">alter</span> <span class="token keyword">table</span> test2 change name name string <span class="token keyword">after</span> student_id<span class="token punctuation">;</span>
OK
<span class="token keyword">Time</span> taken: <span class="token number">0.069</span> seconds
<span class="token keyword">desc</span> test2<span class="token punctuation">;</span>
OK
col_name        data_type       <span class="token keyword">comment</span>
student_id              string                                      
name                    string                                      
<span class="token keyword">Time</span> taken: <span class="token number">0.033</span> seconds<span class="token punctuation">,</span> Fetched: <span class="token number">2</span> <span class="token keyword">row</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span>
</code></pre> 
<p>7）替换列（替换所有的列）</p> 
<pre><code class="prism language-sql"><span class="token keyword">alter</span> <span class="token keyword">table</span> test2 <span class="token keyword">replace</span> <span class="token keyword">columns</span><span class="token punctuation">(</span>id <span class="token keyword">double</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
OK
<span class="token keyword">Time</span> taken: <span class="token number">0.058</span> seconds
<span class="token keyword">desc</span> test2<span class="token punctuation">;</span>
OK
col_name        data_type       <span class="token keyword">comment</span>
id                      <span class="token keyword">double</span>                                      
<span class="token keyword">Time</span> taken: <span class="token number">0.032</span> seconds<span class="token punctuation">,</span> Fetched: <span class="token number">1</span> <span class="token keyword">row</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span>
</code></pre> 
<h3><a id="47__618"></a>4.7 删除表</h3> 
<pre><code class="prism language-sql"><span class="token keyword">drop</span> <span class="token keyword">table</span> test2<span class="token punctuation">;</span>
</code></pre> 
<h3><a id="48_Truncate_623"></a>4.8 清除表中数据（Truncate）</h3> 
<pre><code class="prism language-sql"><span class="token keyword">truncate</span> <span class="token keyword">table</span> student<span class="token punctuation">;</span>
</code></pre> 
<p>注意：truncate 只能删除管理表，不能删除外部表中数据</p> 
<h2><a id="5_DML__630"></a>第5章 DML 数据操作</h2> 
<h3><a id="51__631"></a>5.1 数据导入</h3> 
<h4><a id="511_Load_632"></a>5.1.1 向表中状态数据（Load）</h4> 
<p>1、基本语法</p> 
<pre><code class="prism language-sql"><span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token punctuation">[</span><span class="token keyword">local</span><span class="token punctuation">]</span> inpath <span class="token string">'数据的path'</span> <span class="token punctuation">[</span>overwrite<span class="token punctuation">]</span> <span class="token keyword">into</span> <span class="token keyword">table</span> table_name <span class="token punctuation">[</span><span class="token keyword">partition</span> <span class="token punctuation">(</span>partcol1<span class="token operator">=</span>val1<span class="token punctuation">,</span>…<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
</code></pre> 
<table><thead><tr><th>Load data</th><th>加载数据</th></tr></thead><tbody><tr><td>Local</td><td>表示从本地加载数据到hive表，否则是从HDFS加载数据到Hive表</td></tr><tr><td>Inpath</td><td>表是加载数据的路径</td></tr><tr><td>Overwrite</td><td>表示覆盖表中已有数据，否则表示追加</td></tr><tr><td>Into table</td><td>表示加载数据到哪张表中</td></tr><tr><td>Partition</td><td>表示加载数据到指定分区 。通过分区，可以将表中的数据分散存储在不同的部分，通常基于某些列的值。例如，可以根据日期、地区等属性来分区。</td></tr></tbody></table> 
<p>2、实例操作<br> 1）创建一张表student</p> 
<pre><code class="prism language-sql"><span class="token keyword">create</span> <span class="token keyword">table</span> student<span class="token punctuation">(</span>
              id string<span class="token punctuation">,</span> 
              name string
<span class="token punctuation">)</span>
<span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'\t'</span><span class="token punctuation">;</span>
</code></pre> 
<p>2）加载本地文件到hive</p> 
<pre><code class="prism language-sql"><span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/opt/module/hive/datas/student.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> <span class="token keyword">default</span><span class="token punctuation">.</span>student<span class="token punctuation">;</span>
</code></pre> 
<p>3）加载HDFS文件到hive中<br> （1）上传文件到HDFS</p> 
<pre><code class="prism language-sql">dfs <span class="token operator">-</span>put <span class="token operator">/</span>opt<span class="token operator">/</span>module<span class="token operator">/</span>hive<span class="token operator">/</span>datas<span class="token operator">/</span>student<span class="token punctuation">.</span>txt <span class="token operator">/</span>input<span class="token punctuation">;</span>
</code></pre> 
<p>（2）加载HDFS上数据</p> 
<pre><code class="prism language-sql"><span class="token keyword">load</span> <span class="token keyword">data</span> inpath <span class="token string">'/input/student.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> <span class="token keyword">default</span><span class="token punctuation">.</span>student<span class="token punctuation">;</span>
</code></pre> 
<p>4）加载数据覆盖表中已有的数据</p> 
<pre><code class="prism language-sql"><span class="token keyword">load</span> <span class="token keyword">data</span> inpath <span class="token string">'/input/student.txt'</span> overwrite <span class="token keyword">into</span> <span class="token keyword">table</span> <span class="token keyword">default</span><span class="token punctuation">.</span>student<span class="token punctuation">;</span>
FAILED: SemanticException Line <span class="token number">1</span>:<span class="token number">17</span> Invalid path <span class="token string">''</span><span class="token operator">/</span>input<span class="token operator">/</span>student<span class="token punctuation">.</span>txt<span class="token string">''</span>: <span class="token keyword">No</span> files matching path hdfs:<span class="token comment">//hadoop102:8020/input/student.txt</span>

竟然报错了，信息显示文件不存在？
显然，加载HDFS上的文件到hive表中，采用的类似剪切的方式，将文件拷贝到表的映射目录下。
</code></pre> 
<p>上传文件到HDFS</p> 
<pre><code class="prism language-sql">dfs <span class="token operator">-</span>put <span class="token operator">/</span>opt<span class="token operator">/</span>module<span class="token operator">/</span>hive<span class="token operator">/</span>datas<span class="token operator">/</span>student<span class="token punctuation">.</span>txt <span class="token operator">/</span>input<span class="token punctuation">;</span>
</code></pre> 
<p>加载HDFS上数据</p> 
<pre><code class="prism language-sql"><span class="token keyword">load</span> <span class="token keyword">data</span> inpath <span class="token string">'/input/student.txt'</span> overwrite <span class="token keyword">into</span> <span class="token keyword">table</span> <span class="token keyword">default</span><span class="token punctuation">.</span>student<span class="token punctuation">;</span>
</code></pre> 
<h4><a id="512_Insert_691"></a>5.1.2 向表中插入数据（Insert）</h4> 
<p>1）创建一张表</p> 
<pre><code class="prism language-sql"> <span class="token keyword">create</span> <span class="token keyword">table</span> student2<span class="token punctuation">(</span>id <span class="token keyword">int</span><span class="token punctuation">,</span> name string<span class="token punctuation">)</span> <span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'\t'</span><span class="token punctuation">;</span>
</code></pre> 
<p>2）基本插入数据</p> 
<pre><code class="prism language-sql"><span class="token keyword">insert</span> <span class="token keyword">into</span> <span class="token keyword">table</span>  student2 <span class="token keyword">values</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token string">'wangwu'</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token string">'zhaoliu'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>3）将查询结果插入表中</p> 
<pre><code class="prism language-sql"><span class="token keyword">insert</span> overwrite <span class="token keyword">table</span> student2 <span class="token keyword">select</span> id<span class="token punctuation">,</span> name <span class="token keyword">from</span> student <span class="token punctuation">;</span>
</code></pre> 
<table><thead><tr><th>insert into</th><th>以追加数据的方式插入到表或分区，原有数据不会删除</th></tr></thead><tbody><tr><td>insert overwrite</td><td>会覆盖表中已存在的数据</td></tr></tbody></table> 
<p>注意：insert不支持只插入部分数据</p> 
<h4><a id="513_AS_Select_712"></a>5.1.3 查询语句中创建表并加载数据（AS Select）</h4> 
<p>根据查询结果创建表</p> 
<pre><code class="prism language-sql"><span class="token keyword">create</span> <span class="token keyword">table</span> <span class="token keyword">if</span> <span class="token operator">not</span> <span class="token keyword">exists</span> student4
<span class="token keyword">as</span> <span class="token keyword">select</span> id<span class="token punctuation">,</span> name <span class="token keyword">from</span> student<span class="token punctuation">;</span>
</code></pre> 
<h4><a id="514_Location_719"></a>5.1.4 创建表时通过Location指定加载数据路径</h4> 
<p>1、上传数据到hdfs上</p> 
<pre><code class="prism language-sql">dfs <span class="token operator">-</span>mkdir <span class="token operator">/</span>input<span class="token operator">/</span>student<span class="token punctuation">;</span>
dfs <span class="token operator">-</span>put <span class="token operator">/</span>opt<span class="token operator">/</span>module<span class="token operator">/</span>hive<span class="token operator">/</span>datas<span class="token operator">/</span>student<span class="token punctuation">.</span>txt <span class="token operator">/</span>input<span class="token operator">/</span>student<span class="token operator">/</span>student<span class="token punctuation">.</span>txt<span class="token punctuation">;</span>
</code></pre> 
<p>2、创建表，并指定在hdfs上的位置</p> 
<pre><code class="prism language-sql"><span class="token keyword">create</span> external <span class="token keyword">table</span> <span class="token keyword">if</span> <span class="token operator">not</span> <span class="token keyword">exists</span> student5<span class="token punctuation">(</span>
              id <span class="token keyword">int</span><span class="token punctuation">,</span>
              name string
<span class="token punctuation">)</span>
<span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'\t'</span>
location <span class="token string">'/input/student'</span><span class="token punctuation">;</span>
</code></pre> 
<p>3、查询数据</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> student5<span class="token punctuation">;</span>
OK
student5<span class="token punctuation">.</span>id     student5<span class="token punctuation">.</span>name
<span class="token number">1001</span>    ss1
<span class="token number">1002</span>    ss2
……
</code></pre> 
<p>注意：hive创建表时，默认将表的名称作为默认HDFS上表对应的存储路径的名称，但是，如果你通过location指定存储路径，就不会修改路径名称为表名了。如上边的表名为student5和其在HDFS上的存储路径student。</p> 
<h3><a id="52__747"></a>5.2 数据导入</h3> 
<h4><a id="521_Insert_748"></a>5.2.1 Insert导入</h4> 
<p>1、将查询的结果导出到本地</p> 
<pre><code class="prism language-sql"><span class="token keyword">insert</span> overwrite <span class="token keyword">local</span> directory <span class="token string">'/opt/module/hive/datas/export/student'</span>
            <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> student<span class="token punctuation">;</span>
</code></pre> 
<p>2、将查询的结果格式化导出到本地</p> 
<pre><code class="prism language-sql"><span class="token keyword">insert</span> overwrite <span class="token keyword">local</span> directory <span class="token string">'/opt/module/hive/datas/export/student'</span>
           <span class="token keyword">ROW</span> FORMAT DELIMITED <span class="token keyword">FIELDS</span> <span class="token keyword">TERMINATED</span> <span class="token keyword">BY</span> <span class="token string">'\t'</span>             <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> bigdata1<span class="token punctuation">.</span>student<span class="token punctuation">;</span>
</code></pre> 
<p>3、将查询的结果导出到HDFS上（没有local）</p> 
<pre><code class="prism language-sql"><span class="token keyword">insert</span> overwrite directory <span class="token string">'/output/student'</span>
             <span class="token keyword">ROW</span> FORMAT DELIMITED <span class="token keyword">FIELDS</span> <span class="token keyword">TERMINATED</span> <span class="token keyword">BY</span> <span class="token string">'\t'</span> 
             <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> student<span class="token punctuation">;</span>
</code></pre> 
<p>注意：insert导入时，hive会自动创建导出目录，但是由于是overwrite，所以导出路径一定要写准确，否则存在误删数据的可能。</p> 
<h3><a id="53__769"></a>5.3 数据迁移</h3> 
<p>export 和 import命令主要用于两个Hadoop平台集群之间Hive表迁移。（元数据源+真实数据）</p> 
<h4><a id="531_ExportHDFS_771"></a>5.3.1 Export导出到HDFS上</h4> 
<pre><code class="prism language-sql">export <span class="token keyword">table</span> <span class="token keyword">default</span><span class="token punctuation">.</span>student2 <span class="token keyword">to</span> <span class="token string">'/地址'</span><span class="token punctuation">;</span>	导出到哪里
</code></pre> 
<h4><a id="532_ImportHive_776"></a>5.3.2 Import数据到指定Hive表中</h4> 
<pre><code class="prism language-sql"><span class="token keyword">import</span> <span class="token keyword">table</span> student2  <span class="token keyword">from</span> <span class="token string">'/地址 '</span><span class="token punctuation">;</span>		从哪里导入
</code></pre> 
<p>注意：先用export导出后，再将数据导入。</p> 
<h2><a id="_6__782"></a>第 6 章：查询</h2> 
<h3><a id="61__783"></a>6.1 基本语法及执行顺序</h3> 
<p>1、查询语句语法</p> 
<pre><code class="prism language-sql">select_expr<span class="token punctuation">,</span> select_expr<span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token keyword">FROM</span> table_reference
<span class="token punctuation">[</span><span class="token keyword">WHERE</span> where_condition<span class="token punctuation">]</span>
<span class="token punctuation">[</span><span class="token keyword">GROUP</span> <span class="token keyword">BY</span> col_list<span class="token punctuation">]</span>
<span class="token punctuation">[</span><span class="token keyword">ORDER</span> <span class="token keyword">BY</span> col_list<span class="token punctuation">]</span>
<span class="token punctuation">[</span>CLUSTER <span class="token keyword">BY</span> col_list<span class="token operator">|</span> <span class="token punctuation">[</span>DISTRIBUTE <span class="token keyword">BY</span> col_list<span class="token punctuation">]</span> <span class="token punctuation">[</span>SORT <span class="token keyword">BY</span> col_list<span class="token punctuation">]</span><span class="token punctuation">]</span>
<span class="token punctuation">[</span><span class="token keyword">LIMIT</span> number<span class="token punctuation">]</span>
</code></pre> 
<p>2、书写次序和执行次序</p> 
<table><thead><tr><th>顺序</th><th>书写次序</th><th>书写次序说明</th><th>执行次序</th><th>执行次序说明</th></tr></thead><tbody><tr><td>1</td><td>select</td><td>查询</td><td>from</td><td>先执行表与表直接的关系</td></tr><tr><td>2</td><td>from</td><td>先执行表与表直接的关系</td><td>on</td><td>先执行表与表直接的关系</td></tr><tr><td>3</td><td>join on</td><td>先执行表与表直接的关系</td><td>join</td><td>先执行表与表直接的关系</td></tr><tr><td>4</td><td>where</td><td>先执行表与表直接的关系</td><td>where</td><td>过滤</td></tr><tr><td>5</td><td>group by</td><td>分组</td><td>group by</td><td>分组</td></tr><tr><td>6</td><td>having</td><td>分组后再过滤</td><td>having</td><td>分组后再过滤</td></tr><tr><td>7</td><td>distribute by cluster by</td><td>4个by</td><td>select</td><td>查询</td></tr><tr><td>8</td><td>sort by</td><td>4个by</td><td>distinct</td><td>去重</td></tr><tr><td>9</td><td>order by</td><td>4个by</td><td>distribute by cluster by</td><td>4个by</td></tr><tr><td>10</td><td>limit</td><td>限制输出的行数</td><td>sort by</td><td>4个by</td></tr><tr><td>11</td><td>union/union all</td><td>合并</td><td>order by</td><td>4个by</td></tr><tr><td>12</td><td></td><td></td><td>limit</td><td>限制输出的行数</td></tr><tr><td>13</td><td></td><td></td><td>union/union all</td><td>合并</td></tr></tbody></table> 
<h3><a id="62_SelectFrom_811"></a>6.2 基本查询（Select…From）</h3> 
<h4><a id="621__812"></a>6.2.1 全表和特定列查询</h4> 
<p>1、数据准备<br> 分别创建部门和员工外部表，并向表中导入数据。<br> 1）在/opt/module/hive/datas目录下编辑文件dept.txt，添加如下内容。</p> 
<pre><code class="prism language-sql"> vim dept<span class="token punctuation">.</span>txt
<span class="token number">10</span>	行政部	<span class="token number">1700</span>
<span class="token number">20</span>	财务部	<span class="token number">1800</span>
<span class="token number">30</span>	教学部	<span class="token number">1900</span>
<span class="token number">40</span>	销售部	<span class="token number">1700</span>
</code></pre> 
<p>2）在/opt/module/hive/datas目录下编辑文件emp.txt，添加如下内容。</p> 
<pre><code class="prism language-sql">vim emp<span class="token punctuation">.</span>txt
<span class="token number">7369</span>	张三	研发	<span class="token number">800.00</span>	<span class="token number">30</span>
<span class="token number">7499</span>	李四	财务	<span class="token number">1600.00</span>	<span class="token number">20</span>
<span class="token number">7521</span>	王五	行政	<span class="token number">1250.00</span>	<span class="token number">10</span>
<span class="token number">7566</span>	赵六	销售	<span class="token number">2975.00</span>	<span class="token number">40</span>
<span class="token number">7654</span>	侯七	研发	<span class="token number">1250.00</span>	<span class="token number">30</span>
<span class="token number">7698</span>	马八	研发	<span class="token number">2850.00</span>	<span class="token number">30</span>
<span class="token number">7782</span>	金九	\N	<span class="token number">2450.0</span>	<span class="token number">30</span>
<span class="token number">7788</span>	银十	行政	<span class="token number">3000.00</span>	<span class="token number">10</span>
<span class="token number">7839</span>	小芳	销售	<span class="token number">5000.00</span>	<span class="token number">40</span>
<span class="token number">7844</span>	小明	销售	<span class="token number">1500.00</span>	<span class="token number">40</span>
<span class="token number">7876</span>	小李	行政	<span class="token number">1100.00</span>	<span class="token number">10</span>
<span class="token number">7900</span>	小元	讲师	<span class="token number">950.00</span>	<span class="token number">30</span>
<span class="token number">7902</span>	小海	行政	<span class="token number">3000.00</span>	<span class="token number">10</span>
<span class="token number">7934</span>	小红明	讲师	<span class="token number">1300.00</span>	<span class="token number">30</span>
</code></pre> 
<p>3）上传数据到HDFS</p> 
<pre><code class="prism language-sql">dfs <span class="token operator">-</span>mkdir <span class="token operator">/</span><span class="token keyword">user</span><span class="token operator">/</span>hive<span class="token operator">/</span>warehouse<span class="token operator">/</span>dept<span class="token punctuation">;</span>
dfs <span class="token operator">-</span>mkdir <span class="token operator">/</span><span class="token keyword">user</span><span class="token operator">/</span>hive<span class="token operator">/</span>warehouse<span class="token operator">/</span>emp<span class="token punctuation">;</span>
dfs <span class="token operator">-</span>put <span class="token operator">/</span>opt<span class="token operator">/</span>module<span class="token operator">/</span>hive<span class="token operator">/</span>datas<span class="token operator">/</span>dept<span class="token punctuation">.</span>txt <span class="token operator">/</span><span class="token keyword">user</span><span class="token operator">/</span>hive<span class="token operator">/</span>warehouse<span class="token operator">/</span>dept<span class="token punctuation">;</span>
dfs <span class="token operator">-</span>put <span class="token operator">/</span>opt<span class="token operator">/</span>module<span class="token operator">/</span>hive<span class="token operator">/</span>datas<span class="token operator">/</span>emp<span class="token punctuation">.</span>txt <span class="token operator">/</span><span class="token keyword">user</span><span class="token operator">/</span>hive<span class="token operator">/</span>warehouse<span class="token operator">/</span>emp<span class="token punctuation">;</span>
</code></pre> 
<p>4）建表语句，创建外部表<br> 创建部门表dept</p> 
<pre><code class="prism language-sql"><span class="token keyword">create</span> external <span class="token keyword">table</span> <span class="token keyword">if</span> <span class="token operator">not</span> <span class="token keyword">exists</span> dept<span class="token punctuation">(</span>
deptno <span class="token keyword">int</span><span class="token punctuation">,</span><span class="token comment">--部门编号</span>
dname string<span class="token punctuation">,</span> <span class="token comment">--部门名称</span>
loc <span class="token keyword">int</span> <span class="token comment">--部门位置</span>
<span class="token punctuation">)</span>
<span class="token keyword">row</span> format delimited
<span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'\t'</span><span class="token punctuation">;</span>
</code></pre> 
<p>创建员工表</p> 
<pre><code class="prism language-sql"><span class="token keyword">create</span> external <span class="token keyword">table</span> <span class="token keyword">if</span> <span class="token operator">not</span> <span class="token keyword">exists</span> emp<span class="token punctuation">(</span>
empno <span class="token keyword">int</span><span class="token punctuation">,</span> <span class="token comment">--员工编号</span>
ename string<span class="token punctuation">,</span> <span class="token comment">--员工姓名</span>
job string<span class="token punctuation">,</span> <span class="token comment">--员工岗位（大数据工程师、前端工程师、java工程师）</span>
sal <span class="token keyword">double</span><span class="token punctuation">,</span><span class="token comment">--员工薪资</span>
deptno <span class="token keyword">int</span> <span class="token comment">--部门编号</span>
<span class="token punctuation">)</span>
<span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'\t'</span><span class="token punctuation">;</span>
</code></pre> 
<p>2、全表查询</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> EMP<span class="token punctuation">;</span>
<span class="token keyword">select</span> empno<span class="token punctuation">,</span>ename<span class="token punctuation">,</span>job<span class="token punctuation">,</span>mgr<span class="token punctuation">,</span>hiredate<span class="token punctuation">,</span>sal<span class="token punctuation">,</span>comm<span class="token punctuation">,</span>deptno <span class="token keyword">from</span> emp <span class="token punctuation">;</span>
</code></pre> 
<p>3、选定特定列查询</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> empno<span class="token punctuation">,</span> ename <span class="token keyword">from</span> emp<span class="token punctuation">;</span>
</code></pre> 
<p>注意：<br> 1、SQL语言大小写不敏感<br> 2、SQL可以写在一行或者多行<br> 3、关键字不能被缩写也不能分行<br> 4、各子句一般要分行写<br> 5、使用缩进提高语句的可读性</p> 
<h4><a id="622__892"></a>6.2.2 列别名</h4> 
<p>紧跟列名，也可以在列名和别名之间加入关键字‘AS’<br> 如：</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> 
          ename <span class="token keyword">AS</span> name<span class="token punctuation">,</span>
          deptno dn 
<span class="token keyword">from</span> emp<span class="token punctuation">;</span>

</code></pre> 
<h4><a id="623_set_hiveexecmodelocalautotrue_903"></a>6.2.3 常用函数（set hive.exec.mode.local.auto=true;本地模式）</h4> 
<p>1、求emp表的总行数（count）</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> <span class="token function">count</span><span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">)</span> cnt <span class="token keyword">from</span> emp<span class="token punctuation">;</span>
</code></pre> 
<p>2、求emp表中工资的最大值</p> 
<pre><code class="prism language-sql">elect <span class="token function">max</span><span class="token punctuation">(</span>sal<span class="token punctuation">)</span> max_sal <span class="token keyword">from</span> emp<span class="token punctuation">;</span>
</code></pre> 
<p>3、求emp表中工资的最小值</p> 
<pre><code class="prism language-sql">elect <span class="token function">min</span><span class="token punctuation">(</span>sal<span class="token punctuation">)</span> min_sal <span class="token keyword">from</span> emp<span class="token punctuation">;</span>
</code></pre> 
<p>4、求emp表中工资的总和</p> 
<pre><code class="prism language-sql">elect <span class="token function">sum</span><span class="token punctuation">(</span>sal<span class="token punctuation">)</span> sum_sal <span class="token keyword">from</span> emp<span class="token punctuation">;</span>
</code></pre> 
<p>5、求emp表中工资的平均值</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> <span class="token function">avg</span><span class="token punctuation">(</span>sal<span class="token punctuation">)</span> avg_sal <span class="token keyword">from</span> emp<span class="token punctuation">;</span>
</code></pre> 
<h4><a id="624_Limit_927"></a>6.2.4 Limit语句</h4> 
<p>一般的查询会返回多行数据，在生产环境中，通常使用LIMIT子句用于限制返回的行数</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> ename<span class="token punctuation">,</span> sal <span class="token keyword">from</span> emp <span class="token keyword">limit</span> <span class="token number">5</span><span class="token punctuation">;</span>
<span class="token keyword">select</span> ename<span class="token punctuation">,</span> sal <span class="token keyword">from</span> emp <span class="token keyword">limit</span> <span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">;</span>
</code></pre> 
<h4><a id="625_Where_934"></a>6.2.5 Where语句</h4> 
<p>1、实例：查询出薪水大于1000的所有员工</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> emp <span class="token keyword">where</span> sal <span class="token operator">&gt;</span> <span class="token number">1000</span><span class="token punctuation">;</span>
</code></pre> 
<h4><a id="626_BetweenInIs_Null_940"></a>6.2.6 比较运算符（Between/In/Is Null）</h4> 
<p>1、下面表中描述了谓词操作符，这些操作符同样可以用于JOIN…ON和HAVING语句中。</p> 
<table><thead><tr><th>操作符</th><th>支持的数据类型</th><th>描述</th></tr></thead><tbody><tr><td>A&lt;=&gt;B</td><td>基本数据类型</td><td>如果A和B都为NULL，则返回TRUE，如果以便为NULL，返回False</td></tr><tr><td>A RLIKE B</td><td>STRING类型</td><td>B是基于java的正则表达式，如果A与其匹配，则返回TRUE；反之返回FALSE。匹配使用的是</td></tr></tbody></table> 
<p>2、案例实操<br> 1）查询出薪水等于5000的所有员工</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> emp <span class="token keyword">where</span> sal <span class="token operator">=</span><span class="token number">5000</span><span class="token punctuation">;</span>
OK
emp<span class="token punctuation">.</span>empno       emp<span class="token punctuation">.</span>ename       emp<span class="token punctuation">.</span>job emp<span class="token punctuation">.</span>mgr emp<span class="token punctuation">.</span>hiredate    emp<span class="token punctuation">.</span>sal emp<span class="token punctuation">.</span>comm        emp<span class="token punctuation">.</span>deptno
<span class="token number">7839</span>    KING    PRESIDENT       <span class="token boolean">NULL</span>    <span class="token number">1981</span><span class="token operator">-</span><span class="token number">11</span><span class="token operator">-</span><span class="token number">17</span>      <span class="token number">5000.0</span>  <span class="token boolean">NULL</span>    <span class="token number">10</span>
</code></pre> 
<p>2）查询工资在500到1000的员工信息</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> emp <span class="token keyword">where</span> sal <span class="token operator">between</span> <span class="token number">800</span> <span class="token operator">and</span> <span class="token number">1100</span><span class="token punctuation">;</span>
OK
emp<span class="token punctuation">.</span>empno       emp<span class="token punctuation">.</span>ename       emp<span class="token punctuation">.</span>job emp<span class="token punctuation">.</span>mgr emp<span class="token punctuation">.</span>hiredate    emp<span class="token punctuation">.</span>sal emp<span class="token punctuation">.</span>comm        emp<span class="token punctuation">.</span>deptno
<span class="token number">7369</span>    SMITH   CLERK   <span class="token number">7902</span>    <span class="token number">1980</span><span class="token operator">-</span><span class="token number">12</span><span class="token operator">-</span><span class="token number">17</span>      <span class="token number">800.0</span>   <span class="token boolean">NULL</span>    <span class="token number">20</span>
<span class="token number">7876</span>    ADAMS   CLERK   <span class="token number">7788</span>    <span class="token number">1987</span><span class="token operator">-</span><span class="token number">5</span><span class="token operator">-</span><span class="token number">23</span>       <span class="token number">1100.0</span>  <span class="token boolean">NULL</span>    <span class="token number">20</span>
<span class="token number">7900</span>    JAMES   CLERK   <span class="token number">7698</span>    <span class="token number">1981</span><span class="token operator">-</span><span class="token number">12</span><span class="token operator">-</span><span class="token number">3</span>       <span class="token number">950.0</span>   <span class="token boolean">NULL</span>    <span class="token number">30</span>
</code></pre> 
<p>3）查询job为空的所有员工信息</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> emp <span class="token keyword">where</span> job <span class="token operator">is</span> <span class="token boolean">null</span><span class="token punctuation">;</span>
OK
emp<span class="token punctuation">.</span>empno       emp<span class="token punctuation">.</span>ename       emp<span class="token punctuation">.</span>job emp<span class="token punctuation">.</span>mgr emp<span class="token punctuation">.</span>hiredate    emp<span class="token punctuation">.</span>sal emp<span class="token punctuation">.</span>comm        emp<span class="token punctuation">.</span>deptno
<span class="token number">7369</span>    SMITH   CLERK   <span class="token number">7902</span>    <span class="token number">1980</span><span class="token operator">-</span><span class="token number">12</span><span class="token operator">-</span><span class="token number">17</span>      <span class="token number">800.0</span>   <span class="token boolean">NULL</span>    <span class="token number">20</span>
<span class="token number">7566</span>    JONES   MANAGER <span class="token number">7839</span>    <span class="token number">1981</span><span class="token operator">-</span><span class="token number">4</span><span class="token operator">-</span><span class="token number">2</span>        <span class="token number">2975.0</span>  <span class="token boolean">NULL</span>    <span class="token number">20</span>
<span class="token number">7698</span>    BLAKE   MANAGER <span class="token number">7839</span>    <span class="token number">1981</span><span class="token operator">-</span><span class="token number">5</span><span class="token operator">-</span><span class="token number">1</span>        <span class="token number">2850.0</span>  <span class="token boolean">NULL</span>    <span class="token number">30</span>
</code></pre> 
<p>4）查询工资是1500或5000的员工信息</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> emp <span class="token keyword">where</span> sal <span class="token operator">IN</span> <span class="token punctuation">(</span><span class="token number">1500</span><span class="token punctuation">,</span> <span class="token number">5000</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
OK
emp<span class="token punctuation">.</span>empno       emp<span class="token punctuation">.</span>ename       emp<span class="token punctuation">.</span>job emp<span class="token punctuation">.</span>mgr emp<span class="token punctuation">.</span>hiredate    emp<span class="token punctuation">.</span>sal emp<span class="token punctuation">.</span>comm        emp<span class="token punctuation">.</span>deptno
<span class="token number">7839</span>    KING    PRESIDENT       <span class="token boolean">NULL</span>    <span class="token number">1981</span><span class="token operator">-</span><span class="token number">11</span><span class="token operator">-</span><span class="token number">17</span>      <span class="token number">5000.0</span>  <span class="token boolean">NULL</span>    <span class="token number">10</span>
<span class="token number">7844</span>    TURNER  SALESMAN        <span class="token number">7698</span>    <span class="token number">1981</span><span class="token operator">-</span><span class="token number">9</span><span class="token operator">-</span><span class="token number">8</span>        <span class="token number">1500.0</span>  <span class="token number">0.0</span>     <span class="token number">30</span>
</code></pre> 
<h4><a id="627_Like__RLike_985"></a>6.2.7 Like 和 RLike</h4> 
<p>1、like关键字：使用LIKE运算选择类似的值<br> 2、选择条件可以包含字符或数字：<br> 1）% -&gt; 代表零个或多个字符<br> 2）_ -&gt; 代表一个字符<br> 3、RLIKE关键字：RLIKE子句是Hive中这个功能的一个扩展，其可以通过java的正则表达式这个更加强大的语言来指定匹配条件。<br> 1）$x -&gt; 代表以x结尾<br> 2）^x -&gt; 代表以x开头<br> 3）.* 任意数量字符<br> 4）. 一个任意字符<br> 5）*上一个字符可以无限次出现或者不出现<br> 4、实例操作<br> 1）查找名字以“小”开头的员工信息</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> emp <span class="token keyword">where</span> ename <span class="token operator">LIKE</span> <span class="token string">'小%'</span><span class="token punctuation">;</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> emp <span class="token keyword">where</span> ename <span class="token operator">RLIKE</span> <span class="token string">'^小'</span><span class="token punctuation">;</span>
</code></pre> 
<p>2）查找名字以“明”结尾的员工信息</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> emp <span class="token keyword">where</span> ename <span class="token operator">LIKE</span> <span class="token string">'%明'</span><span class="token punctuation">;</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> emp <span class="token keyword">where</span> ename <span class="token operator">RLIKE</span> <span class="token string">'明$'</span><span class="token punctuation">;</span>
</code></pre> 
<p>3）查找名字中带有“明”的员工信息</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> emp <span class="token keyword">where</span> ename  <span class="token operator">LIKE</span> <span class="token string">'%明%'</span><span class="token punctuation">;</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> emp <span class="token keyword">where</span> ename  <span class="token operator">RLIKE</span> <span class="token string">'[明]'</span><span class="token punctuation">;</span>
</code></pre> 
<h3><a id="63__1015"></a>6.3 排序</h3> 
<h4><a id="631_ReduceSort_By_1016"></a>6.3.1 每个Reduce内部排序（Sort By）</h4> 
<p>1、Sort by：在每个Reduce内部进行排序，对全局结果集来说不是有序。sort by为每个reducer产生一个排序文件，每个Reducer内部进行排序，对全局结果来说不是排序。<br> 2、通过命令设置reduce个数</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> mapreduce<span class="token punctuation">.</span>job<span class="token punctuation">.</span>reduces<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">;</span>
</code></pre> 
<p>3、案例实操：<br> 1）根据部门编号降序查看员工信息</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> emp sort <span class="token keyword">by</span> deptno <span class="token keyword">desc</span><span class="token punctuation">;</span>
</code></pre> 
<p>2）将查询结果导入到文件中</p> 
<pre><code class="prism language-sql"><span class="token keyword">insert</span> overwrite <span class="token keyword">local</span> directory <span class="token string">'/opt/module/hive/datas/sortby-result'</span>
<span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'\t '</span>
<span class="token keyword">select</span> <span class="token operator">*</span> 
<span class="token keyword">from</span> emp 
sort <span class="token keyword">by</span> deptno <span class="token keyword">desc</span><span class="token punctuation">;</span>
</code></pre> 
<h4><a id="632_Distribute_By_1038"></a>6.3.2 分区（Distribute By）</h4> 
<p>1、Distribute By<br> 在有些情况下，我们需要控制某个特定行应该在哪个reducer，通常时为了进行后续的聚集操作。distribute by可以实现。distribute by类似MR中的partition（自定义分区），进行分区，结合sort by 使用。<br> 2、案例分析<br> 1）先按照部门编号分区，再按照员工薪水降序排序</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> mapreduce<span class="token punctuation">.</span>job<span class="token punctuation">.</span>reduces<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">;</span>
<span class="token keyword">insert</span> overwrite <span class="token keyword">local</span> directory <span class="token string">'/opt/module/hive/datas/distribute-result'</span>
<span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'\t'</span>
<span class="token keyword">select</span>
       ename<span class="token punctuation">,</span>
       empno<span class="token punctuation">,</span>
       deptno<span class="token punctuation">,</span>
       sal 
<span class="token keyword">from</span> emp 
distribute <span class="token keyword">by</span> deptno
sort <span class="token keyword">by</span> sal <span class="token keyword">desc</span><span class="token punctuation">;</span>
</code></pre> 
<p>注意：</p> 
<ul><li>distribute by的分区规则是根据分区字段的hash码与reduce的个数进行模除后，余数相同的分到一起。</li><li>Hive要求DISTRIBUTE BY语句要写在SORT BY语句前面。</li></ul> 
<h4><a id="633_Cluster_By_1061"></a>6.3.3 Cluster By</h4> 
<p>1、cluster by：<br> 1）当distribute by和sort by字段相同时，可以使用cluster by方式。<br> 2）cluster by除了具有distribute by的功能外还兼具sort by的功能。<br> 2、案例：查询emp表中的员工信息，并按照部分编号分区排序。</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> ename<span class="token punctuation">,</span>empno<span class="token punctuation">,</span>deptno<span class="token punctuation">,</span>sal <span class="token keyword">from</span> emp cluster <span class="token keyword">by</span> deptno<span class="token punctuation">;</span>
<span class="token keyword">select</span> ename<span class="token punctuation">,</span>empno<span class="token punctuation">,</span>deptno<span class="token punctuation">,</span>sal <span class="token keyword">from</span> emp distribute <span class="token keyword">by</span> deptno sort <span class="token keyword">by</span> deptno<span class="token punctuation">;</span>
</code></pre> 
<h2><a id="_7___1071"></a>第 7 章 分区表和分桶表</h2> 
<p>我们创建一个hive表时，此时在hdfs上就在默认路径上创建了一个以表名字命名的文件夹。Hive表中的数据在hdfs上则是对应文件夹下的所有文件。在查询表中数据时，其实就是将文件下的所有文件进行读取，在海量数据的场景下，这无疑是非常耗时的，并且在实际生产环境中，往往会进行查询过滤。<br> 所以，如何在海量数据的场景下进行高效的查询过滤呢？</p> 
<h3><a id="71__1074"></a>7.1 分区表</h3> 
<p>1、分区表实际上就是对应一个HDFS文件系统上的独立的文件夹。<br> 2、该文件夹下是该分区所有的数据文件。<br> 3、Hive中的分区就是分目录，把一个大的数据集根据业务需求分割成小的数据集。<br> 4、在查询时通过WHERE子句中的表达式选择查询所需要的指定的分区，这样的查询效率会提高很多。</p> 
<h4><a id="711__1079"></a>7.1.1 分区表基本操作</h4> 
<p>1、需要根据日期对日志进行管理，通过部门信息模拟<br> 2、创建分区表语法</p> 
<pre><code class="prism language-sql"><span class="token keyword">create</span> <span class="token keyword">table</span> dept_partition<span class="token punctuation">(</span>
deptno <span class="token keyword">int</span><span class="token punctuation">,</span> <span class="token comment">--部门编号</span>
dname string<span class="token punctuation">,</span> <span class="token comment">--部门名称</span>
loc string <span class="token comment">--部门位置</span>
<span class="token punctuation">)</span>
partitioned <span class="token keyword">by</span> <span class="token punctuation">(</span><span class="token keyword">day</span> string<span class="token punctuation">)</span>
<span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'\t'</span><span class="token punctuation">;</span>
</code></pre> 
<p>注意：分区字段不能是表中已经存在的数据，可以将分区字段看作表的伪列。<br> 3、数据准备<br> 为每个分区准备数据，我们根据日期对日志进行管理，通过部门信息模拟</p> 
<pre><code class="prism language-sql">vim dept_20200401<span class="token punctuation">.</span>log
<span class="token number">10</span>	行政部	<span class="token number">1700</span>
<span class="token number">20</span>	财务部	<span class="token number">1800</span> 
vim dept_20200402<span class="token punctuation">.</span>log
<span class="token number">30</span>	教学部	<span class="token number">1900</span>
<span class="token number">40</span>	销售部	<span class="token number">1700</span>
vim dept_20200403<span class="token punctuation">.</span>log
<span class="token number">50</span>	运营部	<span class="token number">2000</span>
<span class="token number">60</span>	人事部	<span class="token number">1900</span>
</code></pre> 
<p>4、案例：<br> 1）向dept_partition表的分区加载数据</p> 
<pre><code class="prism language-sql"><span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/opt/module/hive/datas/dept_20200401.log'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> dept_partition <span class="token keyword">partition</span><span class="token punctuation">(</span><span class="token keyword">day</span><span class="token operator">=</span><span class="token string">'20200401'</span><span class="token punctuation">)</span><span class="token punctuation">;</span> 
<span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/opt/module/hive/datas/dept_20200402.log'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> dept_partition <span class="token keyword">partition</span><span class="token punctuation">(</span><span class="token keyword">day</span><span class="token operator">=</span><span class="token string">'20200402'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/opt/module/hive/datas/dept_20200403.log'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> dept_partition <span class="token keyword">partition</span><span class="token punctuation">(</span><span class="token keyword">day</span><span class="token operator">=</span><span class="token string">'20200403'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>注意：分区表加载数据时，必须指定分区<br> <img src="https://images2.imgbox.com/23/5e/l1Yhc5Fz_o.png" alt="在这里插入图片描述"><br> 2）查询分区表中数据<br> 单分区查询</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> dept_partition <span class="token keyword">where</span> <span class="token keyword">day</span><span class="token operator">=</span><span class="token string">'20200401'</span><span class="token punctuation">;</span>
</code></pre> 
<p>多分区联合查询（union必走mr效率较低）</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> dept_partition <span class="token keyword">where</span> <span class="token keyword">day</span><span class="token operator">=</span><span class="token string">'20200401'</span>
              <span class="token keyword">union</span>
              <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> dept_partition <span class="token keyword">where</span> <span class="token keyword">day</span><span class="token operator">=</span><span class="token string">'20200402'</span>
              <span class="token keyword">union</span>
              <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> dept_partition <span class="token keyword">where</span> <span class="token keyword">day</span><span class="token operator">=</span><span class="token string">'20200403'</span><span class="token punctuation">;</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> dept_partition <span class="token keyword">where</span> <span class="token keyword">day</span><span class="token operator">=</span><span class="token string">'20200401'</span> <span class="token operator">or</span>
                <span class="token keyword">day</span><span class="token operator">=</span><span class="token string">'20200402'</span> <span class="token operator">or</span> <span class="token keyword">day</span><span class="token operator">=</span><span class="token string">'20200403'</span> <span class="token punctuation">;</span>			
</code></pre> 
<p>5、增加分区<br> 1）添加单个分区</p> 
<pre><code class="prism language-sql"><span class="token keyword">alter</span> <span class="token keyword">table</span> dept_partition <span class="token keyword">add</span> <span class="token keyword">partition</span><span class="token punctuation">(</span><span class="token keyword">day</span><span class="token operator">=</span><span class="token string">'20200404'</span><span class="token punctuation">)</span> <span class="token punctuation">;</span>
</code></pre> 
<p>2）同时添加多个分区</p> 
<pre><code class="prism language-sql"><span class="token keyword">alter</span> <span class="token keyword">table</span> dept_partition <span class="token keyword">add</span> <span class="token keyword">partition</span><span class="token punctuation">(</span><span class="token keyword">day</span><span class="token operator">=</span><span class="token string">'20200405'</span><span class="token punctuation">)</span> <span class="token keyword">partition</span><span class="token punctuation">(</span><span class="token keyword">day</span><span class="token operator">=</span><span class="token string">'20200406'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>6、删除分区<br> 1）删除单个分区</p> 
<pre><code class="prism language-sql"><span class="token keyword">alter</span> <span class="token keyword">table</span> dept_partition <span class="token keyword">drop</span> <span class="token keyword">partition</span> <span class="token punctuation">(</span><span class="token keyword">day</span><span class="token operator">=</span><span class="token string">'20200406'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>2）同时删除多个分区</p> 
<pre><code class="prism language-sql"><span class="token keyword">alter</span> <span class="token keyword">table</span> dept_partition <span class="token keyword">drop</span> <span class="token keyword">partition</span> <span class="token punctuation">(</span><span class="token keyword">day</span><span class="token operator">=</span><span class="token string">'20200404'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">partition</span><span class="token punctuation">(</span><span class="token keyword">day</span><span class="token operator">=</span><span class="token string">'20200405'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>7、查看分区表结构</p> 
<pre><code class="prism language-sql"><span class="token keyword">desc</span> formatted dept_partition<span class="token punctuation">;</span>
<span class="token comment"># Partition Information          </span>
<span class="token comment"># col_name              data_type               comment             </span>
<span class="token keyword">day</span>                   string    
</code></pre> 
<h4><a id="712__1162"></a>7.1.2 二级分区</h4> 
<p>思考：在根据日期分区后，如果一天的日志数据量也很大，如何再将数据拆分？<br> 1、创建二级分区表</p> 
<pre><code class="prism language-sql"><span class="token keyword">create</span> <span class="token keyword">table</span> dept_partition2<span class="token punctuation">(</span>
       deptno <span class="token keyword">int</span><span class="token punctuation">,</span>
       dname string<span class="token punctuation">,</span>
       loc string
<span class="token punctuation">)</span>
partitioned <span class="token keyword">by</span> <span class="token punctuation">(</span><span class="token keyword">day</span> string<span class="token punctuation">,</span> <span class="token keyword">hour</span> string<span class="token punctuation">)</span>
<span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'\t'</span><span class="token punctuation">;</span>
</code></pre> 
<p>2、加载数据<br> 1）加载数据到二级分区表中</p> 
<pre><code class="prism language-sql"><span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/opt/module/hive/datas/dept_20200401.log'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> dept_partition2 <span class="token keyword">partition</span><span class="token punctuation">(</span><span class="token keyword">day</span><span class="token operator">=</span><span class="token string">'20200401'</span><span class="token punctuation">,</span> <span class="token keyword">hour</span><span class="token operator">=</span><span class="token string">'11'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>2）查找分区数据</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> dept_partition2 <span class="token keyword">where</span> <span class="token keyword">day</span><span class="token operator">=</span><span class="token string">'20200401'</span> <span class="token operator">and</span> <span class="token keyword">hour</span><span class="token operator">=</span><span class="token string">'11'</span><span class="token punctuation">;</span>
</code></pre> 
<p>3、让分区表和数据产生关联的三种方式<br> 1）、方式一：上传数据后修复<br> （1）上传数据</p> 
<pre><code class="prism language-sql"> dfs <span class="token operator">-</span>mkdir <span class="token operator">-</span>p <span class="token operator">/</span><span class="token keyword">user</span><span class="token operator">/</span>hive<span class="token operator">/</span>warehouse<span class="token operator">/</span>dept_partition2<span class="token operator">/</span><span class="token keyword">day</span><span class="token operator">=</span><span class="token number">20200401</span><span class="token operator">/</span><span class="token keyword">hour</span><span class="token operator">=</span><span class="token number">12</span><span class="token punctuation">;</span>
 dfs <span class="token operator">-</span>put <span class="token operator">/</span>opt<span class="token operator">/</span>module<span class="token operator">/</span>hive<span class="token operator">/</span>datas<span class="token operator">/</span>dept_20200402<span class="token punctuation">.</span>log <span class="token operator">/</span><span class="token keyword">user</span><span class="token operator">/</span>hive<span class="token operator">/</span>warehouse<span class="token operator">/</span>dept_partition2<span class="token operator">/</span><span class="token keyword">day</span><span class="token operator">=</span><span class="token number">20200401</span><span class="token operator">/</span><span class="token keyword">hour</span><span class="token operator">=</span><span class="token number">12</span><span class="token punctuation">;</span>
</code></pre> 
<p>（2）查询数据（查询不到刚上传的数据）</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> dept_partition2 <span class="token keyword">where</span> <span class="token keyword">day</span><span class="token operator">=</span><span class="token string">'20200401'</span> <span class="token operator">and</span> <span class="token keyword">hour</span><span class="token operator">=</span><span class="token string">'12'</span><span class="token punctuation">;</span>
</code></pre> 
<p>（3）执行修复命令</p> 
<pre><code class="prism language-sql">msck repair <span class="token keyword">table</span> dept_partition2<span class="token punctuation">;</span>
</code></pre> 
<p>（4）再次查询数据</p> 
<pre><code class="prism language-sql"> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> dept_partition2 <span class="token keyword">where</span> <span class="token keyword">day</span><span class="token operator">=</span><span class="token string">'20200401'</span> <span class="token operator">and</span> <span class="token keyword">hour</span><span class="token operator">=</span><span class="token string">'12'</span><span class="token punctuation">;</span>
</code></pre> 
<p>2）方式二：上传数据后添加分区<br> （1）上传数据</p> 
<pre><code class="prism language-sql">dfs <span class="token operator">-</span>mkdir <span class="token operator">-</span>p <span class="token operator">/</span><span class="token keyword">user</span><span class="token operator">/</span>hive<span class="token operator">/</span>warehouse<span class="token operator">/</span>dept_partition2<span class="token operator">/</span><span class="token keyword">day</span><span class="token operator">=</span><span class="token number">20200401</span><span class="token operator">/</span><span class="token keyword">hour</span><span class="token operator">=</span><span class="token number">13</span><span class="token punctuation">;</span>
dfs <span class="token operator">-</span>put <span class="token operator">/</span>opt<span class="token operator">/</span>module<span class="token operator">/</span>hive<span class="token operator">/</span>datas<span class="token operator">/</span>dept_20200403<span class="token punctuation">.</span>log <span class="token operator">/</span><span class="token keyword">user</span><span class="token operator">/</span>hive<span class="token operator">/</span>warehouse<span class="token operator">/</span>dept_partition2<span class="token operator">/</span><span class="token keyword">day</span><span class="token operator">=</span><span class="token number">20200401</span><span class="token operator">/</span><span class="token keyword">hour</span><span class="token operator">=</span><span class="token number">13</span><span class="token punctuation">;</span>
</code></pre> 
<p>（2）执行添加分区</p> 
<pre><code class="prism language-sql"><span class="token keyword">alter</span> <span class="token keyword">table</span> dept_partition2 <span class="token keyword">add</span> <span class="token keyword">partition</span><span class="token punctuation">(</span><span class="token keyword">day</span><span class="token operator">=</span><span class="token string">'20200401'</span><span class="token punctuation">,</span><span class="token keyword">hour</span><span class="token operator">=</span><span class="token string">'13'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>（3）查询数据</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> dept_partition2 <span class="token keyword">where</span> <span class="token keyword">day</span><span class="token operator">=</span><span class="token string">'20200401'</span> <span class="token operator">and</span> <span class="token keyword">hour</span><span class="token operator">=</span><span class="token string">'14'</span><span class="token punctuation">;</span>
</code></pre> 
<p>3）方式三：创建文件夹后load数据到分区<br> （1）创建目录</p> 
<pre><code class="prism language-sql">dfs <span class="token operator">-</span>mkdir <span class="token operator">-</span>p <span class="token operator">/</span><span class="token keyword">user</span><span class="token operator">/</span>hive<span class="token operator">/</span>warehouse<span class="token operator">/</span>mydb<span class="token punctuation">.</span>db<span class="token operator">/</span>dept_partition2<span class="token operator">/</span><span class="token keyword">day</span><span class="token operator">=</span><span class="token number">20200401</span><span class="token operator">/</span><span class="token keyword">hour</span><span class="token operator">=</span><span class="token number">14</span><span class="token punctuation">;</span>
</code></pre> 
<p>（2）上传数据</p> 
<pre><code class="prism language-sql"><span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/opt/module/hive/datas/dept_20200401.log'</span> <span class="token keyword">into</span> <span class="token keyword">table</span>
 dept_partition2 <span class="token keyword">partition</span><span class="token punctuation">(</span><span class="token keyword">day</span><span class="token operator">=</span><span class="token string">'20200401'</span><span class="token punctuation">,</span><span class="token keyword">hour</span><span class="token operator">=</span><span class="token string">'14'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>（3）查询数据</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> dept_partition2 <span class="token keyword">where</span> <span class="token keyword">day</span><span class="token operator">=</span><span class="token string">'20200401'</span> <span class="token operator">and</span> <span class="token keyword">hour</span><span class="token operator">=</span><span class="token string">'14'</span><span class="token punctuation">;</span>
</code></pre> 
<h4><a id="713__1243"></a>7.1.3 动态分区</h4> 
<p>引言：关系型数据库中，对分区表Insert数据时候，数据库自动会根据分区字段的值，将数据插入到相应的分区中。Hive中也提供类似的操作，即动态分区（Dynamic Partition），只不过，使用Hive的动态分区，需要进行相应的配置。<br> 1、开启动态分区参数设置<br> 1）开启动态分区功能</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>dynamic<span class="token punctuation">.</span><span class="token keyword">partition</span><span class="token operator">=</span><span class="token boolean">true</span><span class="token punctuation">;</span>
</code></pre> 
<p>2）设置非严格模式（动态分区的模式，默认strict，表示必须指定至少一个分区为静态分区，nonstrict模式表示允许所有的分区字段都可以使用动态分区）</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>dynamic<span class="token punctuation">.</span><span class="token keyword">partition</span><span class="token punctuation">.</span><span class="token keyword">mode</span><span class="token operator">=</span>nonstrict
</code></pre> 
<p>3）在所有执行MR的节点上，最大一共可以创建多少个动态分区。默认1000</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>max<span class="token punctuation">.</span>dynamic<span class="token punctuation">.</span>partitions<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">;</span>
</code></pre> 
<p>4）在每个执行MR的节点上，最大可以创建多少个动态分区<br> 该参数需要根据实际的数据来设定。比如，源数据中包含了一年的数据，即day字段有365个值，那么该参数就需要设置成大于365，如果使用默认100，则会报错。</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>max<span class="token punctuation">.</span>dynamic<span class="token punctuation">.</span>partitions<span class="token punctuation">.</span>pernode<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">;</span>
</code></pre> 
<p>5）整个MR Job中，最大可以创建多少个HDFS文件。默认100000</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>max<span class="token punctuation">.</span>created<span class="token punctuation">.</span>files<span class="token operator">=</span><span class="token number">100000</span><span class="token punctuation">;</span>
</code></pre> 
<p>6）当有空分区生成时，是否抛出异常。一般不需要设置。默认false</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span>error<span class="token punctuation">.</span><span class="token keyword">on</span><span class="token punctuation">.</span>empty<span class="token punctuation">.</span><span class="token keyword">partition</span><span class="token operator">=</span><span class="token boolean">false</span><span class="token punctuation">;</span>
</code></pre> 
<p>2、案例<br> 需求：将dept表中的数据按照地区（loc字段），插入到目标表dept_partition_loc的相应分区中<br> 1）创建部门地区分区表</p> 
<pre><code class="prism language-sql"><span class="token keyword">create</span> <span class="token keyword">table</span> dept_partition_dynamic<span class="token punctuation">(</span>
       id <span class="token keyword">int</span><span class="token punctuation">,</span>
       name string
<span class="token punctuation">)</span>
partitioned <span class="token keyword">by</span> <span class="token punctuation">(</span>loc <span class="token keyword">int</span><span class="token punctuation">)</span>
<span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'\t'</span><span class="token punctuation">;</span>
</code></pre> 
<p>2）以动态分区的方式向表中插入数据</p> 
<pre><code class="prism language-sql"><span class="token keyword">insert</span> <span class="token keyword">into</span> <span class="token keyword">table</span> dept_partition_loc <span class="token keyword">partition</span><span class="token punctuation">(</span>loc<span class="token punctuation">)</span> <span class="token keyword">select</span> deptno<span class="token punctuation">,</span> dname<span class="token punctuation">,</span> loc <span class="token keyword">from</span> dept<span class="token punctuation">;</span>
FAILED: SemanticException <span class="token punctuation">[</span>Error <span class="token number">10096</span><span class="token punctuation">]</span>: Dynamic <span class="token keyword">partition</span> strict <span class="token keyword">mode</span> requires at least one static <span class="token keyword">partition</span> <span class="token keyword">column</span><span class="token punctuation">.</span> <span class="token keyword">To</span> turn this <span class="token keyword">off</span> <span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>dynamic<span class="token punctuation">.</span><span class="token keyword">partition</span><span class="token punctuation">.</span><span class="token keyword">mode</span><span class="token operator">=</span>nonstrict

<span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>dynamic<span class="token punctuation">.</span><span class="token keyword">partition</span><span class="token punctuation">.</span><span class="token keyword">mode</span> <span class="token operator">=</span> nonstrict<span class="token punctuation">;</span>

<span class="token keyword">insert</span> <span class="token keyword">into</span> <span class="token keyword">table</span> dept_partition_dynamic <span class="token keyword">partition</span><span class="token punctuation">(</span>loc<span class="token punctuation">)</span> <span class="token keyword">select</span> deptno<span class="token punctuation">,</span> dname<span class="token punctuation">,</span> loc <span class="token keyword">from</span> dept<span class="token punctuation">;</span>
</code></pre> 
<p>3）查看目标分区表的分区情况</p> 
<pre><code class="prism language-sql"><span class="token keyword">show</span> partitions dept_partition<span class="token punctuation">;</span>
OK
<span class="token keyword">partition</span>
loc<span class="token operator">=</span><span class="token number">1700</span>
loc<span class="token operator">=</span><span class="token number">1800</span>
loc<span class="token operator">=</span><span class="token number">1900</span>
</code></pre> 
<h3><a id="72__1309"></a>7.2 分桶表</h3> 
<p>1、分桶表<br> 对于一张表或分区，Hive可以进一步组织成桶，也就是更为细粒度的数据范围划分。分区针对的是数据的存储路径（细分文件夹）；分桶针对的是数据文件（按规则多文件放在一起）。<br> 2、案例：创建分桶表<br> 1）创建分桶表</p> 
<pre><code class="prism language-sql"><span class="token keyword">create</span> <span class="token keyword">table</span> stu_bucket<span class="token punctuation">(</span>id <span class="token keyword">int</span><span class="token punctuation">,</span> name string<span class="token punctuation">)</span>
<span class="token keyword">clustered</span> <span class="token keyword">by</span><span class="token punctuation">(</span>id<span class="token punctuation">)</span> 
<span class="token keyword">into</span> <span class="token number">4</span> buckets
<span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'\t'</span><span class="token punctuation">;</span>
</code></pre> 
<p>2）查看表结构</p> 
<pre><code class="prism language-sql"><span class="token keyword">desc</span> formatted stu_bucket<span class="token punctuation">;</span>
Num Buckets:            <span class="token number">4</span>     
</code></pre> 
<p>注意：想要将表创建为4个桶，需要将hive中mapreduce.jog.reduces参数设置为&gt;=4或设置为-1<br> 3）导入数据到分桶表中</p> 
<pre><code class="prism language-sql"><span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath   <span class="token string">'/opt/module/hive/datas/student.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> stu_bucket<span class="token punctuation">;</span>
</code></pre> 
<p>4）查看创建的分桶表中是否分为4个桶<br> <img src="https://images2.imgbox.com/6e/9d/HGZPKFoR_o.png" alt="在这里插入图片描述"><br> 5）查询分桶的数据</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> stu_bucket<span class="token punctuation">;</span>
</code></pre> 
<p>6）分桶规则<br> Hive的分桶采取对分桶字段的值进行哈希，然后除以桶的个数求余<br> 7）分桶表操作需要注意的事项：<br> （1）mapreduce.job.reduces=-1，让Job自行决定需要用多少个reduce或者将reduce的个数设置为大于等于分桶表的数量。<br> （2）从hdfs中load数据到分桶表中，避免本地文件找不到问题<br> 8）insert方式将数据导入分桶表</p> 
<pre><code class="prism language-sql"><span class="token keyword">truncate</span> <span class="token keyword">table</span> stu_bucket<span class="token punctuation">;</span>（删除表内数据，不删表结构，因此只能删内表）
<span class="token keyword">insert</span> <span class="token keyword">into</span> <span class="token keyword">table</span> stu_bucket <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> student <span class="token punctuation">;</span>
</code></pre> 
<h2><a id="_8__1351"></a>第 8 章：函数</h2> 
<h3><a id="81__1352"></a>8.1 系统内置函数</h3> 
<p>1）查看系统自带的函数</p> 
<pre><code class="prism language-sql"><span class="token keyword">show</span> functions<span class="token punctuation">;</span>
</code></pre> 
<p>2）显示自带的函数的用法</p> 
<pre><code class="prism language-sql"><span class="token keyword">desc</span> <span class="token keyword">function</span> abs<span class="token punctuation">;</span>
</code></pre> 
<p>3）详细显示自带函数的用法</p> 
<pre><code class="prism language-sql"><span class="token keyword">desc</span> <span class="token keyword">function</span> <span class="token keyword">extended</span> abs<span class="token punctuation">;</span>
</code></pre> 
<h3><a id="82__1368"></a>8.2 常用内置函数</h3> 
<h4><a id="821_NVL_1369"></a>8.2.1 空字段赋值-NVL（防止空字段参与计算）</h4> 
<p>1、函数说明</p> 
<pre><code class="prism language-sql"><span class="token keyword">desc</span> <span class="token keyword">function</span> <span class="token keyword">extended</span> nvl<span class="token punctuation">;</span>
</code></pre> 
<p>2、解释</p> 
<table><thead><tr><th>NVL</th><th>给值为NULL的数据赋值，它的格式是NVL（value,default_value）</th></tr></thead><tbody><tr><td>功能</td><td>如果value为NULL，则NVL函数返回default_value的值，否则返回value的值。如果两个参数都为NULL，则返回NULL</td></tr></tbody></table> 
<p>3、案例<br> 1、数据准备<br> 采用员工表<br> 2、查询<br> 1）如果员工的comm为NULL，则用0代替</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> ename<span class="token punctuation">,</span>comm<span class="token punctuation">,</span>nvl<span class="token punctuation">(</span>comm<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span> comm_0 <span class="token keyword">from</span> emp<span class="token punctuation">;</span>
</code></pre> 
<p>2）如果员工的job为NULL，则用领导id代替</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> ename<span class="token punctuation">,</span> mgr<span class="token punctuation">,</span>comm<span class="token punctuation">,</span> nvl<span class="token punctuation">(</span>job<span class="token punctuation">,</span>mgr<span class="token punctuation">)</span> comm_mgr <span class="token keyword">from</span> emp<span class="token punctuation">;</span>
</code></pre> 
<h4><a id="822_CASE_WHEN_ELSE_END_1394"></a>8.2.2 CASE WHEN ELSE END</h4> 
<p>1、案例<br> 1）数据准备，在/opt/module/hive/datas目录下创建emp_sex.txt，添加如下内容</p> 
<pre><code class="prism language-sql">vim emp_sex<span class="token punctuation">.</span>txt
悟空<span class="token punctuation">,</span>A<span class="token punctuation">,</span>男
大海<span class="token punctuation">,</span>A<span class="token punctuation">,</span>男
宋宋<span class="token punctuation">,</span>B<span class="token punctuation">,</span>男
凤姐<span class="token punctuation">,</span>A<span class="token punctuation">,</span>女
婷姐<span class="token punctuation">,</span>B<span class="token punctuation">,</span>女
婷婷<span class="token punctuation">,</span>B<span class="token punctuation">,</span>女
</code></pre> 
<p>2）创建emp_sex表并导入数据</p> 
<pre><code class="prism language-sql"><span class="token keyword">create</span> <span class="token keyword">table</span> emp_sex<span class="token punctuation">(</span>
name string<span class="token punctuation">,</span> 
dept_id string<span class="token punctuation">,</span> 
sex string
<span class="token punctuation">)</span> 
<span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">","</span><span class="token punctuation">;</span>

<span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/opt/module/hive/datas/emp_sex.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> emp_sex<span class="token punctuation">;</span>
</code></pre> 
<p>3）需求：求出不同部门男女各多少人。结果如下</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> 
  dept_id<span class="token punctuation">,</span>
  <span class="token function">sum</span><span class="token punctuation">(</span><span class="token keyword">case</span> sex <span class="token keyword">when</span> <span class="token string">'男'</span> <span class="token keyword">then</span> <span class="token number">1</span> <span class="token keyword">else</span> <span class="token number">0</span> <span class="token keyword">end</span><span class="token punctuation">)</span> man_num<span class="token punctuation">,</span>
  <span class="token function">sum</span><span class="token punctuation">(</span><span class="token keyword">case</span> sex <span class="token keyword">when</span> <span class="token string">'女'</span> <span class="token keyword">then</span> <span class="token number">1</span> <span class="token keyword">else</span> <span class="token number">0</span> <span class="token keyword">end</span><span class="token punctuation">)</span> woman_num
<span class="token keyword">from</span> 
  emp_sex
<span class="token keyword">group</span> <span class="token keyword">by</span>  dept_id<span class="token punctuation">;</span>
</code></pre> 
<h4><a id="823__1430"></a>8.2.3 行转列</h4> 
<p><img src="https://images2.imgbox.com/6c/3d/v6tMELkn_o.png" alt="在这里插入图片描述"><br> 1、相关函数说明<br> 1）CONCAT(string A/col，string B/col…)</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> concat<span class="token punctuation">(</span><span class="token string">'abc'</span><span class="token punctuation">,</span><span class="token string">'def'</span><span class="token punctuation">)</span> <span class="token keyword">from</span> src <span class="token keyword">limit</span> <span class="token number">1</span><span class="token punctuation">;</span>
<span class="token string">'abcdef'</span>
</code></pre> 
<p>2）CONCAT_WS(separator,str1,str2,…)</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> concat_ws<span class="token punctuation">(</span><span class="token string">'.'</span><span class="token punctuation">,</span><span class="token string">'www'</span><span class="token punctuation">,</span>array<span class="token punctuation">(</span><span class="token string">'facebook'</span><span class="token punctuation">,</span><span class="token string">'com'</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">from</span> src <span class="token keyword">limit</span> <span class="token number">1</span><span class="token punctuation">;</span>
<span class="token string">'www.facebook.com'</span>
</code></pre> 
<p>3）COLLECT_SET(col)：去重汇总<br> 4）COLLECT_LIST(col)：汇总<br> 2、案例<br> 1）需求：把星座和血型一样的人归类到一起。结果如下：</p> 
<pre><code class="prism language-sql">射手座<span class="token punctuation">,</span>A            大海<span class="token operator">|</span>凤姐
白羊座<span class="token punctuation">,</span>A            孙悟空<span class="token operator">|</span>猪八戒
白羊座<span class="token punctuation">,</span>B            宋宋<span class="token operator">|</span>苍老师
</code></pre> 
<p>2）数据准备</p> 
<pre><code class="prism language-sql">vim person_info<span class="token punctuation">.</span>txt
孙悟空<span class="token punctuation">,</span>白羊座<span class="token punctuation">,</span>A
大海<span class="token punctuation">,</span>射手座<span class="token punctuation">,</span>A
宋宋<span class="token punctuation">,</span>白羊座<span class="token punctuation">,</span>B
猪八戒<span class="token punctuation">,</span>白羊座<span class="token punctuation">,</span>A
凤姐<span class="token punctuation">,</span>射手座<span class="token punctuation">,</span>A
苍老师<span class="token punctuation">,</span>白羊座<span class="token punctuation">,</span>B
</code></pre> 
<p>3）操作</p> 
<pre><code class="prism language-sql"><span class="token keyword">create</span> <span class="token keyword">table</span> person_info<span class="token punctuation">(</span>
name string<span class="token punctuation">,</span> 
constellation string<span class="token punctuation">,</span> 
blood_type string
<span class="token punctuation">)</span> 
<span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">","</span><span class="token punctuation">;</span>

<span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">"/opt/module/hive/datas/person_info.txt"</span> <span class="token keyword">into</span> <span class="token keyword">table</span> person_info<span class="token punctuation">;</span>
</code></pre> 
<p>按需求查询结果</p> 
<pre><code class="prism language-sql"><span class="token keyword">SELECT</span>
t1<span class="token punctuation">.</span>c_b<span class="token punctuation">,</span>
CONCAT_WS<span class="token punctuation">(</span><span class="token string">"|"</span><span class="token punctuation">,</span>collect_set<span class="token punctuation">(</span>t1<span class="token punctuation">.</span>name<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">FROM</span> <span class="token punctuation">(</span>
<span class="token keyword">SELECT</span>
NAME <span class="token punctuation">,</span>
CONCAT_WS<span class="token punctuation">(</span><span class="token string">','</span><span class="token punctuation">,</span>constellation<span class="token punctuation">,</span>blood_type<span class="token punctuation">)</span> c_b
<span class="token keyword">FROM</span> person_info
<span class="token punctuation">)</span>t1 
<span class="token keyword">GROUP</span> <span class="token keyword">BY</span> t1<span class="token punctuation">.</span>c_b
</code></pre> 
<h4><a id="824__1491"></a>8.2.4 列转行</h4> 
<p><img src="https://images2.imgbox.com/de/12/FpigjnFJ_o.png" alt="在这里插入图片描述"><br> 1、函数说明<br> 1）EXPLODE(col)：将hive表的一列中复杂的array或者map结构拆分成多行<br> 2）SPLIT(string str,string regex)：按照reget字符串分割str，会返回分割后的字符串数组</p> 
<pre><code class="prism language-sql"> <span class="token keyword">SELECT</span> split<span class="token punctuation">(</span><span class="token string">'oneAtwoBthreeC'</span><span class="token punctuation">,</span> <span class="token string">'[ABC]'</span><span class="token punctuation">)</span> <span class="token keyword">FROM</span> src <span class="token keyword">LIMIT</span> <span class="token number">1</span><span class="token punctuation">;</span>
  <span class="token punctuation">[</span><span class="token string">"one"</span><span class="token punctuation">,</span> <span class="token string">"two"</span><span class="token punctuation">,</span> <span class="token string">"three"</span><span class="token punctuation">]</span>
</code></pre> 
<p>3）LATERAL VIEW：对拆分后的数据进行聚合<br> 2、案例<br> 1）需求</p> 
<pre><code class="prism language-sql">《疑犯追踪》      悬疑
《疑犯追踪》      动作
《疑犯追踪》      科幻
《疑犯追踪》      剧情
《Lie <span class="token keyword">to</span> me》   悬疑
《Lie <span class="token keyword">to</span> me》   警匪
《Lie <span class="token keyword">to</span> me》   动作
《Lie <span class="token keyword">to</span> me》   心理
《Lie <span class="token keyword">to</span> me》   剧情
《战狼<span class="token number">2</span>》        战争
《战狼<span class="token number">2</span>》        动作
《战狼<span class="token number">2</span>》        灾难
</code></pre> 
<p>2）原始数据</p> 
<table><thead><tr><th>movie</th><th>category</th></tr></thead><tbody><tr><td>《疑犯追踪》</td><td>悬疑,动作,科幻,剧情</td></tr><tr><td>《Lie to me》</td><td>悬疑,警匪,动作,心理,剧情</td></tr><tr><td>《战狼2》</td><td>战争,动作,灾难</td></tr></tbody></table> 
<p>3）操作</p> 
<pre><code class="prism language-sql">vim movie_info<span class="token punctuation">.</span>txt
《疑犯追踪》	悬疑<span class="token punctuation">,</span>动作<span class="token punctuation">,</span>科幻<span class="token punctuation">,</span>剧情
《Lie <span class="token keyword">to</span> me》	悬疑<span class="token punctuation">,</span>警匪<span class="token punctuation">,</span>动作<span class="token punctuation">,</span>心理<span class="token punctuation">,</span>剧情
《战狼<span class="token number">2</span>》	战争<span class="token punctuation">,</span>动作<span class="token punctuation">,</span>灾难

<span class="token keyword">create</span> <span class="token keyword">table</span> movie_info<span class="token punctuation">(</span>
    movie string<span class="token punctuation">,</span> 
    category string<span class="token punctuation">)</span> 
<span class="token keyword">row</span> format delimited
<span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">"\t"</span><span class="token punctuation">;</span>

<span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">"/opt/module/hive/datas/movie_info.txt"</span> <span class="token keyword">into</span> <span class="token keyword">table</span> movie_info<span class="token punctuation">;</span>
</code></pre> 
<p>4）按需求查询数据</p> 
<pre><code class="prism language-sql"><span class="token keyword">SELECT</span> movie<span class="token punctuation">,</span>category_name 
<span class="token keyword">FROM</span> movie_info 
lateral <span class="token keyword">VIEW</span>
explode<span class="token punctuation">(</span>split<span class="token punctuation">(</span>category<span class="token punctuation">,</span><span class="token string">","</span><span class="token punctuation">)</span><span class="token punctuation">)</span> movie_info_tmp  <span class="token keyword">AS</span> category_name <span class="token punctuation">;</span>
</code></pre> 
<h4><a id="825__1549"></a>8.2.5 窗口函数（开窗函数）</h4> 
<p>1、介绍<br> 输入多行数据（一个窗口），为每行数据进行一次计算，返回一个值。灵活运用窗口函数可以解决如去重，排序等。<br> <img src="https://images2.imgbox.com/f8/bc/Mt1dKGCu_o.png" alt="在这里插入图片描述"><br> 2、语法</p> 
<pre><code class="prism language-sql"><span class="token keyword">Function</span> <span class="token punctuation">(</span>arg1 <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span> <span class="token keyword">over</span> <span class="token punctuation">(</span><span class="token punctuation">[</span>patition <span class="token keyword">by</span> arg1 <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token keyword">order</span> <span class="token keyword">by</span> arg1 <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token operator">&lt;</span>window_expression<span class="token operator">&gt;</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<table><thead><tr><th>Function</th><th>Over()</th><th>window_expression</th></tr></thead><tbody><tr><td>支持的函数</td><td>指定分析函数工作的数据窗口大小，窗口会随着行的变化而变化</td><td>窗口边界的设置</td></tr><tr><td>聚合函数：sum()、max()等</td><td>partition by：表示将数据先按字段进行分区</td><td>n preceding : 向前n行 n following：向后n行 current row：当前行</td></tr><tr><td>排序函数：rank()、row_number()等</td><td>Order by：表示将各个分区内的数据按字段进行排序</td><td>unbounded preceding：从前面的起点开始 unbounded following：到后面的终点结束</td></tr><tr><td>统计比较函数：lead()、lag()等</td><td></td><td></td></tr></tbody></table> 
<p>3、数据准备<br> 1）在/opt/module/hive/datas目录下创建business.txt，添加如下内容</p> 
<pre><code class="prism language-sql">vim business<span class="token punctuation">.</span>txt
jack<span class="token punctuation">,</span><span class="token number">2017</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">01</span><span class="token punctuation">,</span><span class="token number">10</span>
tony<span class="token punctuation">,</span><span class="token number">2017</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span><span class="token punctuation">,</span><span class="token number">15</span>
jack<span class="token punctuation">,</span><span class="token number">2017</span><span class="token operator">-</span><span class="token number">02</span><span class="token operator">-</span><span class="token number">03</span><span class="token punctuation">,</span><span class="token number">23</span>
tony<span class="token punctuation">,</span><span class="token number">2017</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">04</span><span class="token punctuation">,</span><span class="token number">29</span>
jack<span class="token punctuation">,</span><span class="token number">2017</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">05</span><span class="token punctuation">,</span><span class="token number">46</span>
jack<span class="token punctuation">,</span><span class="token number">2017</span><span class="token operator">-</span><span class="token number">04</span><span class="token operator">-</span><span class="token number">06</span><span class="token punctuation">,</span><span class="token number">42</span>
tony<span class="token punctuation">,</span><span class="token number">2017</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">07</span><span class="token punctuation">,</span><span class="token number">50</span>
jack<span class="token punctuation">,</span><span class="token number">2017</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">08</span><span class="token punctuation">,</span><span class="token number">55</span>
mart<span class="token punctuation">,</span><span class="token number">2017</span><span class="token operator">-</span><span class="token number">04</span><span class="token operator">-</span><span class="token number">08</span><span class="token punctuation">,</span><span class="token number">62</span>
mart<span class="token punctuation">,</span><span class="token number">2017</span><span class="token operator">-</span><span class="token number">04</span><span class="token operator">-</span><span class="token number">09</span><span class="token punctuation">,</span><span class="token number">68</span>
neil<span class="token punctuation">,</span><span class="token number">2017</span><span class="token operator">-</span><span class="token number">05</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">12</span>
mart<span class="token punctuation">,</span><span class="token number">2017</span><span class="token operator">-</span><span class="token number">04</span><span class="token operator">-</span><span class="token number">11</span><span class="token punctuation">,</span><span class="token number">75</span>
neil<span class="token punctuation">,</span><span class="token number">2017</span><span class="token operator">-</span><span class="token number">06</span><span class="token operator">-</span><span class="token number">12</span><span class="token punctuation">,</span><span class="token number">80</span>
mart<span class="token punctuation">,</span><span class="token number">2017</span><span class="token operator">-</span><span class="token number">04</span><span class="token operator">-</span><span class="token number">13</span><span class="token punctuation">,</span><span class="token number">94</span>
</code></pre> 
<p>2）创建hive表并导入数据</p> 
<pre><code class="prism language-sql"><span class="token keyword">create</span> <span class="token keyword">table</span> business<span class="token punctuation">(</span>
name string<span class="token punctuation">,</span> 
orderdate string<span class="token punctuation">,</span>
cost <span class="token keyword">int</span>
<span class="token punctuation">)</span>
<span class="token keyword">ROW</span> FORMAT DELIMITED
<span class="token keyword">FIELDS</span> <span class="token keyword">TERMINATED</span> <span class="token keyword">BY</span> <span class="token string">','</span><span class="token punctuation">;</span>

<span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">"/opt/module/hive/datas/business.txt"</span> <span class="token keyword">into</span> <span class="token keyword">table</span> business<span class="token punctuation">;</span>
</code></pre> 
<p>4、实例<br> 1）需求：查询在2017年4月份购买过的顾客，及总人数<br> （1）样例</p> 
<pre><code class="prism language-sql">name    consume_num
mart    <span class="token number">2</span>
jack    <span class="token number">2</span>
</code></pre> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> 
name<span class="token punctuation">,</span> 
<span class="token function">count</span><span class="token punctuation">(</span>name<span class="token punctuation">)</span> <span class="token keyword">over</span><span class="token punctuation">(</span><span class="token punctuation">)</span> 
<span class="token keyword">from</span> business 
<span class="token keyword">where</span> subString<span class="token punctuation">(</span>orderdate<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">)</span> <span class="token operator">=</span> <span class="token string">'2017-04'</span>
<span class="token keyword">group</span> <span class="token keyword">by</span> name<span class="token punctuation">;</span>
</code></pre> 
<p>2）需求：查询顾客的购买明细及月购买总额<br> （1）样例</p> 
<pre><code class="prism language-sql">name    orderdate       cost    month_sum
jack    <span class="token number">2017</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">05</span>      <span class="token number">46</span>      <span class="token number">111</span>
jack    <span class="token number">2017</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">08</span>      <span class="token number">55</span>      <span class="token number">111</span>
jack    <span class="token number">2017</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">01</span>      <span class="token number">10</span>      <span class="token number">111</span>
jack    <span class="token number">2017</span><span class="token operator">-</span><span class="token number">02</span><span class="token operator">-</span><span class="token number">03</span>      <span class="token number">23</span>      <span class="token number">23</span>
jack    <span class="token number">2017</span><span class="token operator">-</span><span class="token number">04</span><span class="token operator">-</span><span class="token number">06</span>      <span class="token number">42</span>      <span class="token number">42</span>
</code></pre> 
<p>（2）分析<br> 查询顾客的购买明细，即表中的所有的列，分别以name和orderdate分组，显然group by无法满足我们。这里我们用到over(partition by arg1)指定窗口函数的分区字段，在分区基础上进行窗口分析。<br> （3）案例</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> 
name<span class="token punctuation">,</span>
orderdate<span class="token punctuation">,</span>
cost<span class="token punctuation">,</span>
<span class="token function">sum</span><span class="token punctuation">(</span>cost<span class="token punctuation">)</span> <span class="token keyword">over</span><span class="token punctuation">(</span><span class="token keyword">partition</span> <span class="token keyword">by</span> name<span class="token punctuation">,</span><span class="token keyword">month</span><span class="token punctuation">(</span>orderdate<span class="token punctuation">)</span><span class="token punctuation">)</span> 
<span class="token keyword">from</span> business<span class="token punctuation">;</span>
OK
name    orderdate       cost    sum_window_0	
jack    <span class="token number">2017</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">05</span>      <span class="token number">46</span>      <span class="token number">111</span>
jack    <span class="token number">2017</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">08</span>      <span class="token number">55</span>      <span class="token number">111</span>
jack    <span class="token number">2017</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">01</span>      <span class="token number">10</span>      <span class="token number">111</span>
jack    <span class="token number">2017</span><span class="token operator">-</span><span class="token number">02</span><span class="token operator">-</span><span class="token number">03</span>      <span class="token number">23</span>      <span class="token number">23</span>
jack    <span class="token number">2017</span><span class="token operator">-</span><span class="token number">04</span><span class="token operator">-</span><span class="token number">06</span>      <span class="token number">42</span>      <span class="token number">42</span>
mart    <span class="token number">2017</span><span class="token operator">-</span><span class="token number">04</span><span class="token operator">-</span><span class="token number">13</span>      <span class="token number">94</span>      <span class="token number">299</span>
mart    <span class="token number">2017</span><span class="token operator">-</span><span class="token number">04</span><span class="token operator">-</span><span class="token number">11</span>      <span class="token number">75</span>      <span class="token number">299</span>
mart    <span class="token number">2017</span><span class="token operator">-</span><span class="token number">04</span><span class="token operator">-</span><span class="token number">09</span>      <span class="token number">68</span>      <span class="token number">299</span>
mart    <span class="token number">2017</span><span class="token operator">-</span><span class="token number">04</span><span class="token operator">-</span><span class="token number">08</span>      <span class="token number">62</span>      <span class="token number">299</span>
neil    <span class="token number">2017</span><span class="token operator">-</span><span class="token number">05</span><span class="token operator">-</span><span class="token number">10</span>      <span class="token number">12</span>      <span class="token number">12</span>
neil    <span class="token number">2017</span><span class="token operator">-</span><span class="token number">06</span><span class="token operator">-</span><span class="token number">12</span>      <span class="token number">80</span>      <span class="token number">80</span>
tony    <span class="token number">2017</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">04</span>      <span class="token number">29</span>      <span class="token number">94</span>
tony    <span class="token number">2017</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span>      <span class="token number">15</span>      <span class="token number">94</span>
tony    <span class="token number">2017</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">07</span>      <span class="token number">50</span>      <span class="token number">94</span>
</code></pre> 
<p>3）需求：将每个顾客的cost按照日期进行累加<br> 计算表business的消费总额</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> 
name<span class="token punctuation">,</span>
orderdate<span class="token punctuation">,</span>
cost<span class="token punctuation">,</span> 
<span class="token function">sum</span><span class="token punctuation">(</span>cost<span class="token punctuation">)</span> <span class="token keyword">over</span><span class="token punctuation">(</span><span class="token punctuation">)</span> sample1 
<span class="token keyword">from</span> business<span class="token punctuation">;</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/b3/a9/aUulAfNr_o.png" alt="在这里插入图片描述"><br> 计算每个人的销售总额<br> select<br> name,<br> orderdate,<br> cost,<br> sum(cost) over(partition by name) as sample2<br> from business;<img src="https://images2.imgbox.com/8b/d0/w25fmnvI_o.png" alt="在这里插入图片描述"><br> 计算每个人截至到当天的消费总额</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> 
name<span class="token punctuation">,</span>
orderdate<span class="token punctuation">,</span>
cost<span class="token punctuation">,</span>
<span class="token function">sum</span><span class="token punctuation">(</span>cost<span class="token punctuation">)</span> <span class="token keyword">over</span><span class="token punctuation">(</span><span class="token keyword">partition</span> <span class="token keyword">by</span> name <span class="token keyword">order</span> <span class="token keyword">by</span> orderdate<span class="token punctuation">)</span> <span class="token keyword">as</span> sample3 <span class="token keyword">from</span> business<span class="token punctuation">;</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/71/82/hJHBObD9_o.png" alt="在这里插入图片描述"><br> 计算每个人截至到今天的消费总额（另一种写法）</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> 
name<span class="token punctuation">,</span>
orderdate<span class="token punctuation">,</span>
cost<span class="token punctuation">,</span> 
<span class="token function">sum</span><span class="token punctuation">(</span>cost<span class="token punctuation">)</span> <span class="token keyword">over</span><span class="token punctuation">(</span><span class="token keyword">partition</span> <span class="token keyword">by</span> name <span class="token keyword">order</span> <span class="token keyword">by</span> orderdate <span class="token keyword">rows</span> <span class="token operator">between</span> <span class="token keyword">UNBOUNDED</span> <span class="token keyword">PRECEDING</span> <span class="token operator">and</span> <span class="token keyword">current</span> <span class="token keyword">row</span> <span class="token punctuation">)</span> <span class="token keyword">as</span> sample4
<span class="token keyword">from</span> business<span class="token punctuation">;</span>
</code></pre> 
<p>计算每个人连续两天的消费总额</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> 
name<span class="token punctuation">,</span>
orderdate<span class="token punctuation">,</span>
cost<span class="token punctuation">,</span> 
<span class="token function">sum</span><span class="token punctuation">(</span>cost<span class="token punctuation">)</span> <span class="token keyword">over</span><span class="token punctuation">(</span><span class="token keyword">partition</span> <span class="token keyword">by</span> name <span class="token keyword">order</span> <span class="token keyword">by</span> orderdate <span class="token keyword">rows</span> <span class="token operator">between</span> <span class="token number">1</span> <span class="token keyword">PRECEDING</span> <span class="token operator">and</span> <span class="token keyword">current</span> <span class="token keyword">row</span> <span class="token punctuation">)</span> <span class="token keyword">as</span> sample5
<span class="token keyword">from</span> business<span class="token punctuation">;</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/3d/1e/IF61gNS9_o.png" alt="在这里插入图片描述"><br> 计算每个人从当前天到最后一天的消费总额</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> 
name<span class="token punctuation">,</span>
orderdate<span class="token punctuation">,</span>
cost<span class="token punctuation">,</span>
<span class="token function">sum</span><span class="token punctuation">(</span>cost<span class="token punctuation">)</span> <span class="token keyword">over</span><span class="token punctuation">(</span><span class="token keyword">partition</span> <span class="token keyword">by</span> name <span class="token keyword">order</span> <span class="token keyword">by</span> orderdate <span class="token keyword">rows</span> <span class="token operator">between</span> <span class="token keyword">current</span> <span class="token keyword">row</span> <span class="token operator">and</span> <span class="token keyword">UNBOUNDED</span> <span class="token keyword">FOLLOWING</span> <span class="token punctuation">)</span> <span class="token keyword">as</span> sample6 <span class="token keyword">from</span> business<span class="token punctuation">;</span><span class="token punctuation">.</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/d9/fa/XqB8QY5C_o.png" alt="在这里插入图片描述"><br> rows必须跟在Order by子句之后，对排序的结果进行限制，使用固定的行数来限制分区中的数量行数量。<br> 4）需求：查看顾客上次的购买时间<br> （1）样例</p> 
<pre><code class="prism language-sql">name    orderdate       cost    last_time
jack    <span class="token number">2017</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">01</span>      <span class="token number">10</span>      <span class="token punctuation">(</span>…………………<span class="token punctuation">)</span>
jack    <span class="token number">2017</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">05</span>      <span class="token number">46</span>      <span class="token number">2017</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">01</span>
jack    <span class="token number">2017</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">08</span>      <span class="token number">55</span>      <span class="token number">2017</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">05</span>
</code></pre> 
<p>（2）函数介绍</p> 
<pre><code class="prism language-sql">LAG <span class="token punctuation">(</span>scalar_expression<span class="token punctuation">[</span><span class="token punctuation">,</span><span class="token keyword">offset</span><span class="token punctuation">]</span> <span class="token punctuation">[</span><span class="token punctuation">,</span><span class="token keyword">default</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">OVER</span> <span class="token punctuation">(</span><span class="token punctuation">[</span>query_partition_clause<span class="token punctuation">]</span> order_by_clause<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>解释：<br> Lag函数用于统计窗口内往上第n行值，参数scalar_pexpression为列名，参数offset为往上几行，参数default是设置的默认值（当往上第n行为NULL时，取默认值，否则就为NULL）<br> （3）案例代码</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span>
name<span class="token punctuation">,</span>
orderdate<span class="token punctuation">,</span>
cost<span class="token punctuation">,</span>
lag<span class="token punctuation">(</span>orderdate<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token string">'1900-01-01'</span><span class="token punctuation">)</span> <span class="token keyword">over</span><span class="token punctuation">(</span><span class="token keyword">partition</span> <span class="token keyword">by</span> name <span class="token keyword">order</span> <span class="token keyword">by</span> orderdate <span class="token punctuation">)</span> <span class="token keyword">as</span> last_time
<span class="token keyword">from</span> business<span class="token punctuation">;</span>
OK
name    orderdate       cost    last_time
jack    <span class="token number">2017</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">01</span>      <span class="token number">10</span>      <span class="token number">1900</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">01</span>
jack    <span class="token number">2017</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">05</span>      <span class="token number">46</span>      <span class="token number">2017</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">01</span>
jack    <span class="token number">2017</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">08</span>      <span class="token number">55</span>      <span class="token number">2017</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">05</span>
jack    <span class="token number">2017</span><span class="token operator">-</span><span class="token number">02</span><span class="token operator">-</span><span class="token number">03</span>      <span class="token number">23</span>      <span class="token number">2017</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">08</span>
jack    <span class="token number">2017</span><span class="token operator">-</span><span class="token number">04</span><span class="token operator">-</span><span class="token number">06</span>      <span class="token number">42</span>      <span class="token number">2017</span><span class="token operator">-</span><span class="token number">02</span><span class="token operator">-</span><span class="token number">03</span>
mart    <span class="token number">2017</span><span class="token operator">-</span><span class="token number">04</span><span class="token operator">-</span><span class="token number">08</span>      <span class="token number">62</span>      <span class="token number">1900</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">01</span>
</code></pre> 
<p>5）需求：查询前20%时间的订单信息<br> （1）分析<br> 当前表中总共有14行数据，前20%，就是大约前三行，你会觉得很简单，将数据orderdate字段排序取前三即可，但是表中数据量持续变化，前20%的数据是变化的，这里需要使用ntile函数。<br> （2）函数介绍<br> Ntile函数，为已排序的行，均分为指定数量的组，组号按顺序排列，返回组号，不支持rows between<br> （3）案例</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span>
t1<span class="token punctuation">.</span>name<span class="token punctuation">,</span>
t1<span class="token punctuation">.</span>orderdate<span class="token punctuation">,</span>
t1<span class="token punctuation">.</span>cost
<span class="token keyword">from</span> <span class="token punctuation">(</span>
<span class="token keyword">select</span>
name<span class="token punctuation">,</span>
orderdate<span class="token punctuation">,</span>
cost<span class="token punctuation">,</span>
ntile<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span> <span class="token keyword">over</span><span class="token punctuation">(</span><span class="token keyword">order</span> <span class="token keyword">by</span> orderdate<span class="token punctuation">)</span> sorted <span class="token keyword">from</span> business
<span class="token punctuation">)</span> t1
<span class="token keyword">where</span> t1<span class="token punctuation">.</span>sorted <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>
OK
t<span class="token punctuation">.</span>name  t<span class="token punctuation">.</span>orderdate     t<span class="token punctuation">.</span>cost
jack    <span class="token number">2017</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">01</span>      <span class="token number">10</span>
tony    <span class="token number">2017</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">02</span>      <span class="token number">15</span>
tony    <span class="token number">2017</span><span class="token operator">-</span><span class="token number">01</span><span class="token operator">-</span><span class="token number">04</span>      <span class="token number">29</span>
</code></pre> 
<h4><a id="826_Rank_1776"></a>8.2.6 Rank</h4> 
<p>1、函数说明<br> 1）RANK()：排序相同时会重复，总数不会变。重复的名次一样但是下一名名次会以前面人数+1来定<br> 2）DENSE_RANK()：排序相同时会重复，总数会减少。就是若有重复则最后一名的名词不会和总数相等 即并列<br> 3）ROW_NUMBER()：会根据顺序计算，字段相同就按排头字段继续排<br> 2、数据准备<br> 1）数据</p> 
<pre><code class="prism language-sql">vim score<span class="token punctuation">.</span>txt
孙悟空	语文	<span class="token number">87</span>
孙悟空	数学	<span class="token number">95</span>
孙悟空	英语	<span class="token number">68</span>
大海	语文	<span class="token number">94</span>
大海	数学	<span class="token number">56</span>
大海	英语	<span class="token number">84</span>
宋宋	语文	<span class="token number">64</span>
宋宋	数学	<span class="token number">86</span>
宋宋	英语	<span class="token number">84</span>
婷婷	语文	<span class="token number">65</span>
婷婷	数学	<span class="token number">85</span>
婷婷	英语	<span class="token number">78</span>
</code></pre> 
<p>2）导入数据</p> 
<pre><code class="prism language-sql"><span class="token keyword">create</span> <span class="token keyword">table</span> score<span class="token punctuation">(</span>
name string<span class="token punctuation">,</span>
subject string<span class="token punctuation">,</span> 
score <span class="token keyword">int</span><span class="token punctuation">)</span> 
<span class="token keyword">row</span> format delimited
<span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">"\t"</span><span class="token punctuation">;</span>

<span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/opt/module/hive/datas/score.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> score<span class="token punctuation">;</span>
</code></pre> 
<p>3、需求：计算每门学科成绩排名</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> name<span class="token punctuation">,</span>
subject<span class="token punctuation">,</span>
score<span class="token punctuation">,</span>
rank<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">over</span><span class="token punctuation">(</span><span class="token keyword">partition</span> <span class="token keyword">by</span> subject <span class="token keyword">order</span> <span class="token keyword">by</span> score <span class="token keyword">desc</span><span class="token punctuation">)</span> rp<span class="token punctuation">,</span>
dense_rank<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">over</span><span class="token punctuation">(</span><span class="token keyword">partition</span> <span class="token keyword">by</span> subject <span class="token keyword">order</span> <span class="token keyword">by</span> score <span class="token keyword">desc</span><span class="token punctuation">)</span> drp<span class="token punctuation">,</span>
row_number<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">over</span><span class="token punctuation">(</span><span class="token keyword">partition</span> <span class="token keyword">by</span> subject <span class="token keyword">order</span> <span class="token keyword">by</span> score <span class="token keyword">desc</span><span class="token punctuation">)</span> rmp
<span class="token keyword">from</span> score<span class="token punctuation">;</span>
OK
name    subject score   rp      drp     rmp
孙悟空  数学    <span class="token number">95</span>      <span class="token number">1</span>       <span class="token number">1</span>       <span class="token number">1</span>
宋宋    数学    <span class="token number">86</span>      <span class="token number">2</span>       <span class="token number">2</span>       <span class="token number">2</span>
婷婷    数学    <span class="token number">85</span>      <span class="token number">3</span>       <span class="token number">3</span>       <span class="token number">3</span>
大海    数学    <span class="token number">56</span>      <span class="token number">4</span>       <span class="token number">4</span>       <span class="token number">4</span>
宋宋    英语    <span class="token number">84</span>      <span class="token number">1</span>       <span class="token number">1</span>       <span class="token number">1</span>
大海    英语    <span class="token number">84</span>      <span class="token number">1</span>       <span class="token number">1</span>       <span class="token number">2</span>
婷婷    英语    <span class="token number">78</span>      <span class="token number">3</span>       <span class="token number">2</span>       <span class="token number">3</span>
孙悟空  英语    <span class="token number">68</span>      <span class="token number">4</span>       <span class="token number">3</span>       <span class="token number">4</span>
大海    语文    <span class="token number">94</span>      <span class="token number">1</span>       <span class="token number">1</span>       <span class="token number">1</span>
孙悟空  语文    <span class="token number">87</span>      <span class="token number">2</span>       <span class="token number">2</span>       <span class="token number">2</span>
婷婷    语文    <span class="token number">65</span>      <span class="token number">3</span>       <span class="token number">3</span>       <span class="token number">3</span>
宋宋    语文    <span class="token number">64</span>      <span class="token number">4</span>       <span class="token number">4</span>       <span class="token number">4</span>
</code></pre> 
<h3><a id="83__1836"></a>8.3 自定义函数</h3> 
<p>1、内置函数：比如max/min等<br> 2、根据用户自定义函数类别分为以下三种：<br> 1）UDF：一进一出<br> 2）UDAF：聚合函数，多进一出，类似：count/max/min<br> 3）UDTF：炸裂函数，一进多出，类似：explode()<br> 3、编程步骤<br> 1）继承Hive提供的类<br> 2）实现类中的抽象方法<br> 3）在hive的命令行窗口创建函数<br> 4、hive中引入自定义函数步骤<br> 1）添加jar</p> 
<pre><code class="prism language-sql"><span class="token keyword">add</span> jar linux_jar_path
</code></pre> 
<p>2）创建function</p> 
<pre><code class="prism language-sql"><span class="token keyword">create</span> <span class="token punctuation">[</span><span class="token keyword">temporary</span><span class="token punctuation">]</span> <span class="token keyword">function</span> <span class="token punctuation">[</span>dbname<span class="token punctuation">.</span><span class="token punctuation">]</span>function_name <span class="token keyword">AS</span> class_name<span class="token punctuation">;</span>
</code></pre> 
<p>3）在hive的命令行窗口删除函数</p> 
<pre><code class="prism language-sql"><span class="token keyword">drop</span> <span class="token punctuation">[</span><span class="token keyword">temporary</span><span class="token punctuation">]</span> <span class="token keyword">function</span> <span class="token punctuation">[</span><span class="token keyword">if</span> <span class="token keyword">exists</span><span class="token punctuation">]</span> <span class="token punctuation">[</span>dbname<span class="token punctuation">.</span><span class="token punctuation">]</span>function_name<span class="token punctuation">;</span>
</code></pre> 
<h3><a id="84_UDF_1862"></a>8.4 自定义UDF函数</h3> 
<p>1、需求：自定义一个UDF实现计算给定字符串的长度，例如：</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> my_len<span class="token punctuation">(</span><span class="token string">"abcd"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
ok
<span class="token number">4</span>
</code></pre> 
<p>2、案例 <br> 1）创建Maven工程Hive<br> 2）在工程项目的pom.xml文件中导入依赖<br> hive-exec<br> 3）创建一个类</p> 
<pre><code class="prism language-sql">package com<span class="token punctuation">.</span>atguigu<span class="token punctuation">.</span>hive<span class="token punctuation">;</span>

<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>ql<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>UDFArgumentException<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>ql<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>UDFArgumentLengthException<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>ql<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>UDFArgumentTypeException<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>ql<span class="token punctuation">.</span>metadata<span class="token punctuation">.</span>HiveException<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>ql<span class="token punctuation">.</span>udf<span class="token punctuation">.</span>generic<span class="token punctuation">.</span>GenericUDF<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>serde2<span class="token punctuation">.</span>objectinspector<span class="token punctuation">.</span>ObjectInspector<span class="token punctuation">;</span>
<span class="token keyword">import</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>serde2<span class="token punctuation">.</span>objectinspector<span class="token punctuation">.</span>primitive<span class="token punctuation">.</span>PrimitiveObjectInspectorFactory<span class="token punctuation">;</span>

<span class="token comment">/**
 * 自定义UDF函数，需要继承GenericUDF类
 * 需求: 计算指定字符串的长度
 */</span>
<span class="token keyword">public</span> class MyStringLength extends GenericUDF {
    <span class="token comment">/**
     *
     * @param arguments 输入参数类型的鉴别器对象
     * @return 返回值类型的鉴别器对象
     * @throws UDFArgumentException
     */</span>
    <span class="token variable">@Override</span>
    <span class="token keyword">public</span> ObjectInspector initialize<span class="token punctuation">(</span>ObjectInspector<span class="token punctuation">[</span><span class="token punctuation">]</span> arguments<span class="token punctuation">)</span> throws UDFArgumentException {
        <span class="token comment">// 判断输入参数的个数</span>
        <span class="token keyword">if</span><span class="token punctuation">(</span>arguments<span class="token punctuation">.</span>length <span class="token operator">!=</span><span class="token number">1</span><span class="token punctuation">)</span>{
            throw new UDFArgumentLengthException<span class="token punctuation">(</span><span class="token string">"Input Args Length Error!!!"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        }
        <span class="token comment">// 判断输入参数的类型</span>
        <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token operator">!</span>arguments<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>getCategory<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>equals<span class="token punctuation">(</span>ObjectInspector<span class="token punctuation">.</span>Category<span class="token punctuation">.</span>PRIMITIVE<span class="token punctuation">)</span><span class="token punctuation">)</span>{
            throw new UDFArgumentTypeException<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token string">"Input Args Type Error!!!"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        }
        <span class="token comment">//函数本身返回值为int，需要返回int类型的鉴别器对象</span>
        <span class="token keyword">return</span> PrimitiveObjectInspectorFactory<span class="token punctuation">.</span>javaIntObjectInspector<span class="token punctuation">;</span>
    }

    <span class="token comment">/**
     * 函数的逻辑处理
     * @param arguments 输入的参数
     * @return 返回值
     * @throws HiveException
     */</span>
    <span class="token variable">@Override</span>
    <span class="token keyword">public</span> Object evaluate<span class="token punctuation">(</span>DeferredObject<span class="token punctuation">[</span><span class="token punctuation">]</span> arguments<span class="token punctuation">)</span> throws HiveException {
       <span class="token keyword">if</span><span class="token punctuation">(</span>arguments<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">=</span><span class="token operator">=</span> <span class="token boolean">null</span><span class="token punctuation">)</span>{
           <span class="token keyword">return</span> <span class="token number">0</span> <span class="token punctuation">;</span>
       }
       <span class="token keyword">return</span> arguments<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>toString<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>length<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    }

    <span class="token variable">@Override</span>
    <span class="token keyword">public</span> String getDisplayString<span class="token punctuation">(</span>String<span class="token punctuation">[</span><span class="token punctuation">]</span> children<span class="token punctuation">)</span> {
        <span class="token keyword">return</span> <span class="token string">""</span><span class="token punctuation">;</span>
    }
}
</code></pre> 
<p>4）打包jar包上传到服务器/opt/module/hive/datas/myudf.jar<br> 5）将jar包添加到hive的classpath</p> 
<pre><code class="prism language-sql"><span class="token keyword">add</span> jar <span class="token operator">/</span>opt<span class="token operator">/</span>module<span class="token operator">/</span>hive<span class="token operator">/</span>datas<span class="token operator">/</span>myudf<span class="token punctuation">.</span>jar<span class="token punctuation">;</span>
</code></pre> 
<h3><a id="85__1938"></a>8.5 创建临时函数</h3> 
<p>1、创建临时函数与开发好的java class关联</p> 
<pre><code class="prism language-sql"><span class="token keyword">create</span> <span class="token keyword">temporary</span> <span class="token keyword">function</span> my_len <span class="token keyword">as</span> <span class="token string">"com.atguigu.hive. MyStringLength"</span><span class="token punctuation">;</span>
</code></pre> 
<p>2、在hql中使用自定义的函数</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> ename<span class="token punctuation">,</span>my_len<span class="token punctuation">(</span>ename<span class="token punctuation">)</span> ename_len <span class="token keyword">from</span> emp<span class="token punctuation">;</span>
OK
ename   _c1
fanfan  <span class="token number">6</span>
SMITH   <span class="token number">5</span>
ALLEN   <span class="token number">5</span>
WARD    <span class="token number">4</span>
JONES   <span class="token number">5</span>
MARTIN  <span class="token number">6</span>
BLAKE   <span class="token number">5</span>
CLARK   <span class="token number">5</span>
SCOTT   <span class="token number">5</span>
KING    <span class="token number">4</span>
TURNER  <span class="token number">6</span>
ADAMS   <span class="token number">5</span>
JAMES   <span class="token number">5</span>
FORD    <span class="token number">4</span>
MILLER  <span class="token number">6</span>
</code></pre> 
<p>注意：临时函数只跟会话有关系，跟库没有关系，只有创建临时函数的会话不断，在当前会话下，任意一个库都可以使用，其他会话全部不能使用。</p> 
<h3><a id="86__1967"></a>8.6 创建永久函数</h3> 
<p>注意：因为add jar 的方式本身也是临时生效，所以在创建永久函数的时候，需要执行路径</p> 
<pre><code class="prism language-sql"><span class="token keyword">create</span> <span class="token keyword">function</span> my_len2 
<span class="token keyword">as</span> <span class="token string">"com.atguigu.hive.udf.MyUDF"</span> 
<span class="token keyword">using</span> jar <span class="token string">"hdfs://hadoop102:8020/udf/myudf.jar"</span><span class="token punctuation">;</span>
</code></pre> 
<p>即可在hql中使用自定义的永久函数</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> 
    ename<span class="token punctuation">,</span>
    my_len2<span class="token punctuation">(</span>ename<span class="token punctuation">)</span> ename_len 
<span class="token keyword">from</span> emp<span class="token punctuation">;</span>
</code></pre> 
<p>删除永久函数</p> 
<pre><code class="prism language-sql"><span class="token keyword">drop</span> <span class="token keyword">function</span> my_len2<span class="token punctuation">;</span>
</code></pre> 
<p>注意：永久函数跟会话没有关系，创建函数的会话断了以后，其他会话也可以使用。</p> 
<h2><a id="_9__1989"></a>第 9 章：压缩和存储</h2> 
<p>Hive不会强制要求将数据转换成特定的格式才能使用。利用Hadoop的InputFormat API可以从不同数据源读取数据，使用OutputFormat API可以将数据写成不同的格式输出。<br> 对数据进行压缩虽然会增加额外的CPU开销，但是会节约客观的磁盘空间，并且通过减少内存的数据量而提高I/O吞吐量会更加提高网络传输性能。<br> 原则上Hadoop的job时I/O密集型的话就可以采用压缩可以提高性能，如果job是CPU密集型的话，那么使用压缩可能会降低执行性能。</p> 
<h3><a id="91_Hadoop_1993"></a>9.1 Hadoop压缩配置</h3> 
<h4><a id="911_MR_1994"></a>9.1.1 MR支持的压缩编码</h4> 
<table><thead><tr><th>压缩格式</th><th>算法</th><th>文件扩展名</th><th>是否可切分</th></tr></thead><tbody><tr><td>Deflate</td><td>Deflate</td><td>.deflate</td><td>否</td></tr><tr><td>Gzip</td><td>Deflate</td><td>.gz</td><td>否</td></tr><tr><td>Bzip2</td><td>Bzip2</td><td>.bz2</td><td>是</td></tr><tr><td>Lzo</td><td>Lzo</td><td>.lzo</td><td>是</td></tr><tr><td>Snappy</td><td>Snappy</td><td>.snappy</td><td>否</td></tr></tbody></table> 
<p>为了支持多种压缩/解压缩算法，Hadoop引入了编码/解码器，如下表所示：</p> 
<table><thead><tr><th>压缩格式</th><th>对应的编码/解码器</th></tr></thead><tbody><tr><td>Deflate</td><td>org.apache.hadoop.io.compress.DefaultCodec</td></tr><tr><td>Gzip</td><td>org.apache.hadoop.io.compress.GzipCodec</td></tr><tr><td>Bzip2</td><td>org.apache.hadoop.io.compress.BZip2Codec</td></tr><tr><td>Lzo</td><td>com.hadoop.compression.lzo.LzopCodec</td></tr><tr><td>Snappy</td><td>org.apache.hadoop.io.compress.SnappyCodec</td></tr></tbody></table> 
<p>为什么需要这么多的压缩方案呢？<br> 每一个压缩方案都在压缩和解压缩速度和压缩率间进行权衡。<br> 如下是压缩性能的比较</p> 
<table><thead><tr><th>压缩算法</th><th>原始文件大小</th><th>压缩文件大小</th><th>压缩速度</th><th>解压速度</th></tr></thead><tbody><tr><td>gzip</td><td>8.3GB</td><td>1.8GB</td><td>17.5MB/s</td><td>58MB/s</td></tr><tr><td>bzip2</td><td>8.3GB</td><td>1.1GB</td><td>2.4MB/s</td><td>9.5MB/s</td></tr><tr><td>LZO</td><td>8.3GB</td><td>2.9GB</td><td>49.3MB/s</td><td>74.6MB/s</td></tr></tbody></table> 
<h4><a id="912__2021"></a>9.1.2 压缩参数配置</h4> 
<p>要在Hadoop中启用压缩，可以配置如下参数（mapred-site.xml文件中）：</p> 
<table><thead><tr><th>参数</th><th>默认值</th><th>阶段</th><th>建议</th></tr></thead><tbody><tr><td>io.compression.codecs （在core-site.xml中配置）</td><td>org.apache.hadoop.io.compress.DefaultCodec, org.apache.hadoop.io.compress.GzipCodec, org.apache.hadoop.io.compress.BZip2Codec,org.apache.hadoop.io.compress.Lz4Codec</td><td>输出压缩</td><td>Hadoop使用文件扩展名判断是否支持某种编解码器</td></tr><tr><td>mapreduce.map.output.compress</td><td>false</td><td>mapper输出</td><td>这个参数为true启动压缩</td></tr><tr><td>mapreduce.map.output.compress.codec</td><td>org.apache.hadoop.io.compress.DefaultCodec</td><td>mapper输出</td><td>使用LZO、LZ4或snappy编解码器在此阶段压缩数据</td></tr><tr><td>mapreduce.output.fileoutputformat.compress</td><td>false</td><td>reducer输出</td><td>这个参数设为true启动压缩</td></tr><tr><td>mapreduce.output.fileoutputformat.compress.codec</td><td>org.apache.hadoop.io.compress. DefaultCodec</td><td>reducer输出</td><td>使用标准工具或者编码器，如gzip和bzip2</td></tr><tr><td>mapreduce.output.fileoutputformat.compress.type</td><td>RECORD</td><td>reducer输出</td><td>SequenceFile输出使用的压缩类型：NONE和BLOCK</td></tr></tbody></table> 
<h3><a id="92_Map_2031"></a>9.2 开启Map输出阶段压缩</h3> 
<p>开启map输出阶段压缩可以减少job中map和Reduce task间数据传输量。<br> 1、具体配置如下：<br> 1）开启hive中间传输数据压缩功能</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>compress<span class="token punctuation">.</span>intermediate <span class="token operator">=</span><span class="token boolean">true</span><span class="token punctuation">;</span>
</code></pre> 
<p>2）开启mapreduce中map输出压缩功能</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> mapreduce<span class="token punctuation">.</span>map<span class="token punctuation">.</span>output<span class="token punctuation">.</span>compress<span class="token operator">=</span><span class="token boolean">true</span><span class="token punctuation">;</span>
</code></pre> 
<p>3）设置mapreduce中map输出数据的压缩方式</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> mapreduce<span class="token punctuation">.</span>map<span class="token punctuation">.</span>output<span class="token punctuation">.</span>compress<span class="token punctuation">.</span>codec<span class="token operator">=</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>compress<span class="token punctuation">.</span>SnappyCodec<span class="token punctuation">;</span>
</code></pre> 
<p>4）执行查询语句</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> <span class="token function">count</span><span class="token punctuation">(</span>ename<span class="token punctuation">)</span> name <span class="token keyword">from</span> emp<span class="token punctuation">;</span>
</code></pre> 
<p>5）观察yarn执行的job的map阶段日志可看到如下内容<br> <img src="https://images2.imgbox.com/ef/9e/YXZaVzy7_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="93_Reduce_2056"></a>9.3 开启Reduce输出阶段压缩</h3> 
<p>当Hive将输出写入到表中时可以通过属性hive.exec.compress.output，对输出内容进行压缩。当hive.exec.compress.output=false，这样输出就是非压缩的纯文本文件了。将hive.exec.compress.output=true，来开启输出结果压缩功能。<br> 1、设置步骤如下：<br> 1）开启hive最终输出数据压缩功能</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>compress<span class="token punctuation">.</span>output<span class="token operator">=</span><span class="token boolean">true</span><span class="token punctuation">;</span>
</code></pre> 
<p>2）开启mapreduce最终输出数据压缩</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> mapreduce<span class="token punctuation">.</span>output<span class="token punctuation">.</span>fileoutputformat<span class="token punctuation">.</span>compress<span class="token operator">=</span><span class="token boolean">true</span><span class="token punctuation">;</span>
</code></pre> 
<p>3）设置mapreduce最终数据输出压缩方式</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> mapreduce<span class="token punctuation">.</span>output<span class="token punctuation">.</span>fileoutputformat<span class="token punctuation">.</span>compress<span class="token punctuation">.</span>codec <span class="token operator">=</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span>compress<span class="token punctuation">.</span>SnappyCodec<span class="token punctuation">;</span>
</code></pre> 
<p>4）设置mapreduce最终数据输出压缩为块压缩</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> mapreduce<span class="token punctuation">.</span>output<span class="token punctuation">.</span>fileoutputformat<span class="token punctuation">.</span>compress<span class="token punctuation">.</span><span class="token keyword">type</span><span class="token operator">=</span>BLOCK<span class="token punctuation">;</span>
</code></pre> 
<p>5）测试以下输出结果是否为压缩文件</p> 
<pre><code class="prism language-sql"> <span class="token keyword">insert</span> overwrite <span class="token keyword">local</span> directory
 <span class="token string">'/opt/module/hive/datas/distribute-result'</span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> emp distribute <span class="token keyword">by</span> deptno sort <span class="token keyword">by</span> empno <span class="token keyword">desc</span><span class="token punctuation">;</span>
</code></pre> 
<p>6）查看目录/opt/module/hive/datas/distribute-result下文件</p> 
<pre><code class="prism language-sql">distribute<span class="token operator">-</span>result<span class="token punctuation">]</span>$ ll
总用量 <span class="token number">4</span>
<span class="token operator">-</span>rw<span class="token operator">-</span>r<span class="token comment">--r--. 1 atguigu atguigu 493 10月 21 22:56 000000_0.snappy</span>
</code></pre> 
<h3><a id="94__2092"></a>9.4 文件存储格式</h3> 
<p>Hive支持的存储数据的格式主要有：TEXTFILE、SEQUENCEFILE、ORC、PARQUET。</p> 
<h4><a id="941__2094"></a>9.4.1 列式存储和行式存储</h4> 
<p><img src="https://images2.imgbox.com/62/4b/ViaKz7UB_o.png" alt="在这里插入图片描述"><br> 如图所示，左边为逻辑表，右边第一个是行式存储，第二个式列式存储。</p> 
<h4><a id="942_TextFile_2097"></a>9.4.2 TextFile格式</h4> 
<p>默认格式，数据不做压缩，磁盘开销大，数据解析开销大。<br> 可结合Gzip，Bzip2使用，但使用Gzip这种方式，hive不会对数据进行切分，从而无法对数据进行并行操作。</p> 
<h4><a id="943_Orc_2100"></a>9.4.3 Orc格式</h4> 
<p>Orc是Hive 0.11版里引入的新的存储格式。<br> 如下图所示可以看到每个Orc文件由1个或多个stripe组成，每个stripe一般为HDFS的块大小，每一个stripe包含多条记录，这些记录按照列进行独立存储，对应到Parquet中的row group的概念。每个Stripe里有三部分组成，分别是Index Data, Row Data,Stripe Footer；<br> <img src="https://images2.imgbox.com/33/ee/apVDU4wl_o.png" alt="在这里插入图片描述"><br> 1、Index Data：一个轻量级的index，默认是每隔1W行做一个索引。这里做的索引应该只是记录某行的各字段在Row Data中的offset。<br> 2、Row Data：存的是具体的数据，先取部分行，然后对这些行按列进行存储。对每个列进行了编码，分成多个Stream来存储。<br> 3、Stripe Footer：存的是各个Stream的类型，长度等信息。每个文件有一个File Footer，这里面存的是每个Stripe的行数，每个Column的数据类型信息等；每个文件的尾部是一个PostScript，这里面记录了整个文件的压缩类型以及FileFooter的长度信息等。在读取文件时，会seek到文件尾部读PostScript，从里面解析到File Footer长度，再读FileFooter，从里面解析到各个Stripe信息，再读各个Stripe，即从后往前读。</p> 
<h4><a id="944_Parquet_2107"></a>9.4.4 Parquet格式</h4> 
<p>Parquet文件是以二进制方式存储的，所以是不可以直接读取的。文件中包括该文件的数据和元数据，因此Parquet格式文件是自解析的。<br> 1、行组（Row Group）：每一个行组包含一定的行数，在一个HDFS文件中至少存储一个行组，类似于orc的stripe的概念。<br> 2、列块（Column Chunk）：在一个行组中每一列保持在一个列块中，行组中的所有列连续的存储在这个行组文件中。一个列块中的值都是相同类型的，不同列块可能使用不同的算法进行压缩。<br> 3、页（Page）：每一个列块划分为多个页，一个页是最小的编码的单位，在同一个列块的不同页可能使用不同的编码方式。<br> 通常情况下，在存储Parquet数据的时候会按照Block大小设置行组的大小，由于一般情况下每一个Mapper任务处理数据的最小单位是一个Block，这样可以把每一个行组由一个Mapper任务处理，增大任务执行并行度。<br> <img src="https://images2.imgbox.com/88/9a/WnWbc0wA_o.png" alt="在这里插入图片描述"><br> 上图展示了一个Parquet文件的内容，一个文件中可以存储多个行组，文件的首位都是该文件的Magic Code，用于校验它是否是一个Parquet文件，Footer length记录了文件元数据的大小，通过该值和文件长度可以计算出元数据的偏移量，文件的元数据中包括每一个行组的元数据信息和该文件存储数据的Schema信息。除了文件中每一个行组的元数据，每一页的开始都会存储该页的元数据，在Parquet中，有三中类型的页：数据页、字典页和索引页。数据页用于存储当前行组中该列的值，字典页存储该列值的编码字典，每一个列块中最多包含一个字典页，索引页用来存储当前行组下该列的索引，目前Parquet中还不支持索引页。</p> 
<h4><a id="945__2115"></a>9.4.5 主流存储文件格式对比</h4> 
<p>1、TextFile<br> 1)创建log_text，设置其存储数据格式为TEXTFILE</p> 
<pre><code class="prism language-sql"><span class="token keyword">create</span> <span class="token keyword">table</span> log_text <span class="token punctuation">(</span>
track_time string<span class="token punctuation">,</span>
url string<span class="token punctuation">,</span>
session_id string<span class="token punctuation">,</span>
referer string<span class="token punctuation">,</span>
ip string<span class="token punctuation">,</span>
end_user_id string<span class="token punctuation">,</span>
city_id string
<span class="token punctuation">)</span>
<span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'\t'</span>
stored <span class="token keyword">as</span> textfile<span class="token punctuation">;</span>
</code></pre> 
<p>2）向表中加载数据</p> 
<pre><code class="prism language-sql"><span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/opt/module/hive/datas/log.data'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> log_text <span class="token punctuation">;</span>
</code></pre> 
<p>3）查看表中数据大小</p> 
<pre><code class="prism language-sql">dfs <span class="token operator">-</span>du <span class="token operator">-</span>h <span class="token operator">/</span><span class="token keyword">user</span><span class="token operator">/</span>hive<span class="token operator">/</span>warehouse<span class="token operator">/</span>log_text<span class="token punctuation">;</span>
<span class="token number">18.1</span> M  <span class="token number">54.4</span> M  <span class="token operator">/</span><span class="token keyword">user</span><span class="token operator">/</span>hive<span class="token operator">/</span>warehouse<span class="token operator">/</span>log_text<span class="token operator">/</span>log<span class="token punctuation">.</span><span class="token keyword">data</span>
</code></pre> 
<p>4）采用TextFile格式存储，文件大小为18.1M<br> 2、ORC<br> 1）创建表loc_orc，存储数据格式是ORC</p> 
<pre><code class="prism language-sql"><span class="token keyword">create</span> <span class="token keyword">table</span> log_orc<span class="token punctuation">(</span>
track_time string<span class="token punctuation">,</span>
url string<span class="token punctuation">,</span>
session_id string<span class="token punctuation">,</span>
referer string<span class="token punctuation">,</span>
ip string<span class="token punctuation">,</span>
end_user_id string<span class="token punctuation">,</span>
city_id string
<span class="token punctuation">)</span>
<span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'\t'</span>
stored <span class="token keyword">as</span> orc
tblproperties<span class="token punctuation">(</span><span class="token string">"orc.compress"</span><span class="token operator">=</span><span class="token string">"NONE"</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 由于ORC格式时自带压缩的，这设置orc存储不使用压缩</span>
</code></pre> 
<p>2）向表中插入数据</p> 
<pre><code class="prism language-sql"><span class="token keyword">insert</span> <span class="token keyword">into</span> <span class="token keyword">table</span> log_orc <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> log_text <span class="token punctuation">;</span>
</code></pre> 
<p>3）查看表中数据大小</p> 
<pre><code class="prism language-sql">dfs <span class="token operator">-</span>du <span class="token operator">-</span>h <span class="token operator">/</span><span class="token keyword">user</span><span class="token operator">/</span>hive<span class="token operator">/</span>warehouse<span class="token operator">/</span>log_orc<span class="token operator">/</span> <span class="token punctuation">;</span>
<span class="token number">7.7</span> M  <span class="token number">23.1</span> M  <span class="token operator">/</span><span class="token keyword">user</span><span class="token operator">/</span>hive<span class="token operator">/</span>warehouse<span class="token operator">/</span>log_orc<span class="token operator">/</span><span class="token number">000000</span>_0
</code></pre> 
<p>4）采用ORC（非压缩）格式存储，文件大小为7.7M<br> 3、Parquet<br> 1）创建表log_parquet，设置其存储数据格式为parquet</p> 
<pre><code class="prism language-sql"><span class="token keyword">create</span> <span class="token keyword">table</span> log_parquet<span class="token punctuation">(</span>
track_time string<span class="token punctuation">,</span>
url string<span class="token punctuation">,</span>
session_id string<span class="token punctuation">,</span>
referer string<span class="token punctuation">,</span>
ip string<span class="token punctuation">,</span>
end_user_id string<span class="token punctuation">,</span>
city_id string
<span class="token punctuation">)</span>
<span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'\t'</span>
stored <span class="token keyword">as</span> parquet <span class="token punctuation">;</span>
</code></pre> 
<p>2）向表中插入数据</p> 
<pre><code class="prism language-sql"><span class="token keyword">insert</span> <span class="token keyword">into</span> <span class="token keyword">table</span> log_parquet <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> log_text <span class="token punctuation">;</span>
</code></pre> 
<p>3）查看表中数据大小</p> 
<pre><code class="prism language-sql">dfs <span class="token operator">-</span>du <span class="token operator">-</span>h <span class="token operator">/</span><span class="token keyword">user</span><span class="token operator">/</span>hive<span class="token operator">/</span>warehouse<span class="token operator">/</span>log_parquet<span class="token operator">/</span> <span class="token punctuation">;</span>
<span class="token number">13.1</span> M  <span class="token number">39.3</span> M  <span class="token operator">/</span><span class="token keyword">user</span><span class="token operator">/</span>hive<span class="token operator">/</span>warehouse<span class="token operator">/</span>log_parquet<span class="token operator">/</span><span class="token number">000000</span>_0
</code></pre> 
<p>4）采用Parquet格式存储，文件大小为13.1M<br> 4、存储文件的对比总结：<br> ORC&gt;Parquet&gt;textFile<br> 5、存储文件的查询速度测试：<br> 1）TextFile</p> 
<pre><code class="prism language-sql"><span class="token keyword">insert</span> overwrite <span class="token keyword">local</span> directory <span class="token string">'/opt/module/hive/data/log_text'</span> <span class="token keyword">select</span> substring<span class="token punctuation">(</span>url<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span> <span class="token keyword">from</span> log_text <span class="token punctuation">;</span>
<span class="token keyword">No</span> <span class="token keyword">rows</span> affected <span class="token punctuation">(</span><span class="token number">10.522</span> seconds<span class="token punctuation">)</span>
</code></pre> 
<p>2）ORC</p> 
<pre><code class="prism language-sql"><span class="token keyword">insert</span> overwrite <span class="token keyword">local</span> directory <span class="token string">'/opt/module/hive/data/log_orc'</span> <span class="token keyword">select</span> substring<span class="token punctuation">(</span>url<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span> <span class="token keyword">from</span> log_orc <span class="token punctuation">;</span>
<span class="token keyword">No</span> <span class="token keyword">rows</span> affected <span class="token punctuation">(</span><span class="token number">11.495</span> seconds<span class="token punctuation">)</span>
</code></pre> 
<p>3）Parquet</p> 
<pre><code class="prism language-sql"><span class="token keyword">insert</span> overwrite <span class="token keyword">local</span> directory <span class="token string">'/opt/module/hive/data/log_parquet'</span> <span class="token keyword">select</span> substring<span class="token punctuation">(</span>url<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span> <span class="token keyword">from</span> log_parquet <span class="token punctuation">;</span>
<span class="token keyword">No</span> <span class="token keyword">rows</span> affected <span class="token punctuation">(</span><span class="token number">11.445</span> seconds<span class="token punctuation">)</span>
</code></pre> 
<p>存储文件的查询速度总结：查询速度相近</p> 
<h3><a id="95__2223"></a>9.5 存储和压缩结合</h3> 
<h4><a id="951__2224"></a>9.5.1 测试存储和压缩</h4> 
<p>1、创建一个ZLIB压缩的ORC存储方式<br> 1）创建表log_orc_zlib表，设置其使用ORC文件格式，并使用ZLIB压缩</p> 
<pre><code class="prism language-sql"> <span class="token keyword">create</span> <span class="token keyword">table</span> log_orc_zlib<span class="token punctuation">(</span>
track_time string<span class="token punctuation">,</span>
url string<span class="token punctuation">,</span>
session_id string<span class="token punctuation">,</span>
referer string<span class="token punctuation">,</span>
ip string<span class="token punctuation">,</span>
end_user_id string<span class="token punctuation">,</span>
city_id string
<span class="token punctuation">)</span>
<span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'\t'</span>
stored <span class="token keyword">as</span> orc
tblproperties<span class="token punctuation">(</span><span class="token string">"orc.compress"</span><span class="token operator">=</span><span class="token string">"ZLIB"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>2）向表log_orc_zlib插入数据</p> 
<pre><code class="prism language-sql"><span class="token keyword">insert</span> <span class="token keyword">into</span> log_orc_zlib <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> log_text<span class="token punctuation">;</span>
</code></pre> 
<p>3）查看插入后数据文件大小</p> 
<pre><code class="prism language-sql">dfs <span class="token operator">-</span>du <span class="token operator">-</span>h <span class="token operator">/</span><span class="token keyword">user</span><span class="token operator">/</span>hive<span class="token operator">/</span>warehouse<span class="token operator">/</span>log_orc_zlib<span class="token operator">/</span> <span class="token punctuation">;</span>
<span class="token number">2.8</span> M  <span class="token number">8.3</span> M  <span class="token operator">/</span><span class="token keyword">user</span><span class="token operator">/</span>hive<span class="token operator">/</span>warehouse<span class="token operator">/</span>log_orc_zlib<span class="token operator">/</span><span class="token number">000000</span>_0
</code></pre> 
<p>4）采用ORC文件格式，并使用ZLIB压缩时，文件大小2.8M<br> 2、创建一个SNAPP压缩的ORC存储方式<br> 1）创建表log_orc_snappy表，设置其使用ORC文件格式，并使用snappy压缩</p> 
<pre><code class="prism language-sql"> <span class="token keyword">create</span> <span class="token keyword">table</span> log_orc_snappy<span class="token punctuation">(</span>
track_time string<span class="token punctuation">,</span>
url string<span class="token punctuation">,</span>
session_id string<span class="token punctuation">,</span>
referer string<span class="token punctuation">,</span>
ip string<span class="token punctuation">,</span>
end_user_id string<span class="token punctuation">,</span>
city_id string
<span class="token punctuation">)</span>
<span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'\t'</span>
stored <span class="token keyword">as</span> orc
tblproperties<span class="token punctuation">(</span><span class="token string">"orc.compress"</span><span class="token operator">=</span><span class="token string">"SNAPPY"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>2）插入数据</p> 
<pre><code class="prism language-sql"><span class="token keyword">insert</span> <span class="token keyword">into</span> log_orc_snappy <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> log_text<span class="token punctuation">;</span>
</code></pre> 
<p>3）查看插入后数据</p> 
<pre><code class="prism language-sql">dfs <span class="token operator">-</span>du <span class="token operator">-</span>h <span class="token operator">/</span><span class="token keyword">user</span><span class="token operator">/</span>hive<span class="token operator">/</span>warehouse<span class="token operator">/</span>log_orc_snappy<span class="token operator">/</span> <span class="token punctuation">;</span>
<span class="token number">3.7</span> M  <span class="token number">11.2</span> M  <span class="token operator">/</span><span class="token keyword">user</span><span class="token operator">/</span>hive<span class="token operator">/</span>warehouse<span class="token operator">/</span>log_orc_snappy<span class="token operator">/</span><span class="token number">000000</span>_1
</code></pre> 
<p>4）采用ORC文件格式，并使用SNAPPY压缩时，文件大小3.7M<br> ZLIB比Snappy压缩的还小。原因是ZLIB采用的是deflate压缩算法。比snappy压缩的压缩率高。<br> 3、创建一个SNAPPY压缩的parquet存储方式<br> 1）创建表log_parquet_snappy，设置其使用Parquet文件格式，并使用SNAPPY压缩</p> 
<pre><code class="prism language-sql"><span class="token keyword">create</span> <span class="token keyword">table</span> log_parquet_snappy<span class="token punctuation">(</span>
track_time string<span class="token punctuation">,</span>
url string<span class="token punctuation">,</span>
session_id string<span class="token punctuation">,</span>
referer string<span class="token punctuation">,</span>
ip string<span class="token punctuation">,</span>
end_user_id string<span class="token punctuation">,</span>
city_id string
<span class="token punctuation">)</span>
<span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'\t'</span>
stored <span class="token keyword">as</span> parquet
tblproperties<span class="token punctuation">(</span><span class="token string">"parquet.compression"</span><span class="token operator">=</span><span class="token string">"SNAPPY"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>2）向表log_parquet_snappy插入数据</p> 
<pre><code class="prism language-sql"><span class="token keyword">insert</span> <span class="token keyword">into</span> log_parquet_snappy <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> log_text<span class="token punctuation">;</span>
</code></pre> 
<p>3）查看插入后数据</p> 
<pre><code class="prism language-sql">dfs <span class="token operator">-</span>du <span class="token operator">-</span>h <span class="token operator">/</span><span class="token keyword">user</span><span class="token operator">/</span>hive<span class="token operator">/</span>warehouse<span class="token operator">/</span>log_parquet_snappy <span class="token operator">/</span> <span class="token punctuation">;</span>
<span class="token number">6.4</span> M  <span class="token number">19.2</span> M  <span class="token operator">/</span><span class="token keyword">user</span><span class="token operator">/</span>hive<span class="token operator">/</span>warehouse<span class="token operator">/</span>log_parquet_snappy<span class="token operator">/</span><span class="token number">000000</span>_0
</code></pre> 
<p>4）采用Parquet文件格式，并使用SNAPPY压缩时，文件大小6.4MB<br> 4、存储方式和压缩总结<br> 在实际的项目开发当中：<br> 1）hive表的数据存储格式一般选择：orc或parquet<br> 2）压缩方式一般选择snappy，lzo</p> 
<h2><a id="_10__2317"></a>第 10 章：企业级调优</h2> 
<p>创建测试用例<br> 1、建大表、小表和JOIN后表的语句</p> 
<pre><code class="prism language-sql"><span class="token comment">// 创建大表</span>
<span class="token keyword">create</span> <span class="token keyword">table</span> bigtable<span class="token punctuation">(</span>id <span class="token keyword">bigint</span><span class="token punctuation">,</span> t <span class="token keyword">bigint</span><span class="token punctuation">,</span> uid string<span class="token punctuation">,</span> keyword string<span class="token punctuation">,</span> url_rank <span class="token keyword">int</span><span class="token punctuation">,</span> click_num <span class="token keyword">int</span><span class="token punctuation">,</span> click_url string<span class="token punctuation">)</span> <span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'\t'</span><span class="token punctuation">;</span>
<span class="token comment">// 创建小表</span>
<span class="token keyword">create</span> <span class="token keyword">table</span> smalltable<span class="token punctuation">(</span>id <span class="token keyword">bigint</span><span class="token punctuation">,</span> t <span class="token keyword">bigint</span><span class="token punctuation">,</span> uid string<span class="token punctuation">,</span> keyword string<span class="token punctuation">,</span> url_rank <span class="token keyword">int</span><span class="token punctuation">,</span> click_num <span class="token keyword">int</span><span class="token punctuation">,</span> click_url string<span class="token punctuation">)</span> <span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'\t'</span><span class="token punctuation">;</span>
<span class="token comment">// 创建JOIN后表</span>
<span class="token keyword">create</span> <span class="token keyword">table</span> jointable<span class="token punctuation">(</span>id <span class="token keyword">bigint</span><span class="token punctuation">,</span> t <span class="token keyword">bigint</span><span class="token punctuation">,</span> uid string<span class="token punctuation">,</span> keyword string<span class="token punctuation">,</span> url_rank <span class="token keyword">int</span><span class="token punctuation">,</span> click_num <span class="token keyword">int</span><span class="token punctuation">,</span> click_url string<span class="token punctuation">)</span> <span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'\t'</span><span class="token punctuation">;</span>
</code></pre> 
<p>2、分别向大表和小表中导入数据</p> 
<pre><code class="prism language-sql"><span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/opt/module/hive/datas/bigtable'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> bigtable<span class="token punctuation">;</span>
<span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/opt/module/hive/datas/smalltable'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> smalltable<span class="token punctuation">;</span>
</code></pre> 
<h3><a id="101_Explain_2335"></a>10.1 执行计划（Explain）</h3> 
<p>1、基本语法</p> 
<pre><code class="prism language-sql"><span class="token keyword">EXPLAIN</span> <span class="token punctuation">[</span><span class="token keyword">EXTENDED</span> <span class="token operator">|</span> DEPENDENCY <span class="token operator">|</span> <span class="token keyword">AUTHORIZATION</span><span class="token punctuation">]</span> query
</code></pre> 
<p>2、实例操作<br> 1）查看下面这条语句的执行计划<br> （1）没有生成MR任务的</p> 
<pre><code class="prism language-sql"><span class="token keyword">explain</span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> emp<span class="token punctuation">;</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/75/af/TxhW7jHW_o.png" alt="在这里插入图片描述"><br> （2）有生成MR任务的</p> 
<pre><code class="prism language-sql"><span class="token keyword">explain</span> <span class="token keyword">select</span> deptno<span class="token punctuation">,</span> <span class="token function">avg</span><span class="token punctuation">(</span>sal<span class="token punctuation">)</span> avg_sal <span class="token keyword">from</span> emp <span class="token keyword">group</span> <span class="token keyword">by</span> deptno<span class="token punctuation">;</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/71/43/0HiYBDTT_o.png" alt="在这里插入图片描述"><br> 2）查看详细执行计划</p> 
<pre><code class="prism language-sql"><span class="token keyword">explain</span> <span class="token keyword">extended</span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> emp<span class="token punctuation">;</span>
<span class="token keyword">explain</span> <span class="token keyword">extended</span> <span class="token keyword">select</span> deptno<span class="token punctuation">,</span> <span class="token function">avg</span><span class="token punctuation">(</span>sal<span class="token punctuation">)</span> avg_sal <span class="token keyword">from</span> emp <span class="token keyword">group</span> <span class="token keyword">by</span> deptno<span class="token punctuation">;</span>
</code></pre> 
<h3><a id="102_HQL_2361"></a>10.2 HQL语法优化</h3> 
<h4><a id="1021__2362"></a>10.2.1 列裁剪和分区裁剪</h4> 
<p>在生产环境中，会面临列很多或者数据量很大时，如果使用select * 或者不指定分区进行全列或者全表扫描时效率很低。Hive在读取数据时，可以只读取查询中所需要的列，忽略其它的列，这样做可以节省读取开销（中间表存储开销和数据整合开销）<br> 1、列裁剪：在查询时只读取需要的列<br> 2、分区裁剪：在查询时只读取需要的分区</p> 
<h4><a id="1022_Group_By_2366"></a>10.2.2 Group By</h4> 
<p>1、介绍：默认情况下，Map阶段同一Key数据分发给一个reduce，当一个key数据过大时就倾斜了。<br> <img src="https://images2.imgbox.com/13/7a/ID5cUiRR_o.png" alt="在这里插入图片描述"><br> 并不是所有的聚合操作都需要在Reduce端完成，很多聚合操作都可以先在Map端进行部分聚合，最后在Reduce端得出最终结果。<br> 2、进行参数设置<br> 1）开始Map端聚合参数设置<br> （1）是否在Map端进行聚合，默认为True()</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span>map<span class="token punctuation">.</span>aggr <span class="token operator">=</span> <span class="token boolean">true</span>
</code></pre> 
<p>（2）在Map端进行聚合操作的条目数量</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span>groupby<span class="token punctuation">.</span>mapaggr<span class="token punctuation">.</span>checkinterval <span class="token operator">=</span> <span class="token number">100000</span>
</code></pre> 
<p>（3）在数据倾斜的时候进行负载均衡（默认是false）</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span>groupby<span class="token punctuation">.</span>skewindata <span class="token operator">=</span> <span class="token boolean">true</span>
</code></pre> 
<p>（4）当开启数据负载均衡时，生成的查询计划会有两个MRJob。<br> 第一个MRJob中，Map的输出结果会随机分布到Reduce中，每个Reduce做部分聚合操作，并输出结果，这样处理的结果是相同的Group By Key有可能被分发到不同的Reduce中，从而达到负载均衡的目的；<br> 第二个MRJob再根据预处理的数据结果按照Group By Key分布到Reduce中（这个过程可以保证相同的Group By Key被分布到同一个Reduce中），最后完成最终的聚合操作。<br> 3、案例<br> 1）优化前</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> deptno <span class="token keyword">from</span> emp <span class="token keyword">group</span> <span class="token keyword">by</span> deptno<span class="token punctuation">;</span>
Stage<span class="token operator">-</span>Stage<span class="token operator">-</span><span class="token number">1</span>: Map: <span class="token number">1</span>  Reduce: <span class="token number">5</span>   Cumulative CPU: <span class="token number">23.68</span> sec   HDFS <span class="token keyword">Read</span>: <span class="token number">19987</span> HDFS <span class="token keyword">Write</span>: <span class="token number">9</span> SUCCESS
Total MapReduce CPU <span class="token keyword">Time</span> Spent: <span class="token number">23</span> seconds <span class="token number">680</span> msec
OK
deptno
<span class="token number">10</span>
<span class="token number">20</span>
<span class="token number">30</span>

</code></pre> 
<p>2）优化以后</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span>groupby<span class="token punctuation">.</span>skewindata <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>
<span class="token keyword">explain</span> <span class="token keyword">select</span> deptno <span class="token keyword">from</span> emp <span class="token keyword">group</span> <span class="token keyword">by</span> deptno<span class="token punctuation">;</span>
Stage<span class="token operator">-</span>Stage<span class="token operator">-</span><span class="token number">1</span>: Map: <span class="token number">1</span>  Reduce: <span class="token number">5</span>   Cumulative CPU: <span class="token number">28.53</span> sec   HDFS <span class="token keyword">Read</span>: <span class="token number">18209</span> HDFS <span class="token keyword">Write</span>: <span class="token number">534</span> SUCCESS
Stage<span class="token operator">-</span>Stage<span class="token operator">-</span><span class="token number">2</span>: Map: <span class="token number">1</span>  Reduce: <span class="token number">5</span>   Cumulative CPU: <span class="token number">38.32</span> sec   HDFS <span class="token keyword">Read</span>: <span class="token number">15014</span> HDFS <span class="token keyword">Write</span>: <span class="token number">9</span> SUCCESS
Total MapReduce CPU <span class="token keyword">Time</span> Spent: <span class="token number">1</span> minutes <span class="token number">6</span> seconds <span class="token number">850</span> msec
OK
deptno
<span class="token number">10</span>
<span class="token number">20</span>
<span class="token number">30</span>
</code></pre> 
<h4><a id="1023_CBO_2420"></a>10.2.3 CBO优化</h4> 
<p>join的时候表的顺序的关系：前面的表会被加载到内存中。后面的表进行磁盘扫描</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> a<span class="token punctuation">.</span><span class="token operator">*</span><span class="token punctuation">,</span> b<span class="token punctuation">.</span><span class="token operator">*</span><span class="token punctuation">,</span> c<span class="token punctuation">.</span><span class="token operator">*</span> <span class="token keyword">from</span> a <span class="token keyword">join</span> b <span class="token keyword">on</span> a<span class="token punctuation">.</span>id <span class="token operator">=</span> b<span class="token punctuation">.</span>id <span class="token keyword">join</span> c <span class="token keyword">on</span> b<span class="token punctuation">.</span>tt <span class="token operator">=</span> c<span class="token punctuation">.</span>tt<span class="token punctuation">;</span>
</code></pre> 
<p>Hive自0.14.0开始，加入了一项“Cost based Optimizer”来对HQL执行计划进行优化，这个功能通过“hive.cbo.enable”来开启。在Hive1.1.0之后，这个属性是默认开启的，它可以自动优化HQL中多个Join的顺序，并选择合适的Join算法。<br> CBO，成本优化器，代价最小的执行计划就是最好的执行计划。传统的数据块，成本优化器做出最优化的执行计划是依据统计信息来计算的。<br> Hive的成本优化器也一样，Hive在提供最终执行前，优化每个查询的执行逻辑和物理执行计划。这些优化工作是交给底层来完成的。根据查询成本执行进一步的优化，从而产生潜在的不同决策：如何排序连接，执行哪种类型的连接，并行度等等。<br> 要使用基于成本的优化（也称为CBO）,请在查询开始设置一下参数：</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span>cbo<span class="token punctuation">.</span><span class="token keyword">enable</span><span class="token operator">=</span><span class="token boolean">true</span><span class="token punctuation">;</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">compute</span><span class="token punctuation">.</span>query<span class="token punctuation">.</span><span class="token keyword">using</span><span class="token punctuation">.</span>stats<span class="token operator">=</span><span class="token boolean">true</span><span class="token punctuation">;</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span>stats<span class="token punctuation">.</span><span class="token keyword">fetch</span><span class="token punctuation">.</span><span class="token keyword">column</span><span class="token punctuation">.</span>stats<span class="token operator">=</span><span class="token boolean">true</span><span class="token punctuation">;</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span>stats<span class="token punctuation">.</span><span class="token keyword">fetch</span><span class="token punctuation">.</span><span class="token keyword">partition</span><span class="token punctuation">.</span>stats<span class="token operator">=</span><span class="token boolean">true</span><span class="token punctuation">;</span>（Removed <span class="token operator">In</span>: Hive <span class="token number">3.0</span><span class="token number">.0</span> <span class="token keyword">with</span> HIVE<span class="token operator">-</span><span class="token number">17932</span>）
</code></pre> 
<h4><a id="1024__2437"></a>10.2.4 谓词下推</h4> 
<p>1、谓词下推：保证结果正确的前提下，将SQL语句中的where谓词逻辑都尽可能提前执行，减少下游处理的数据量。对应逻辑优化器是PredicatePushDown，配置项为hive.optimize.ppd，默认值为true。<br> 2、什么是谓词：where后面的条件<br> 3、优势：通过谓词下推，过滤条件将在map端提前执行，减少了map端的输出，降低了数据IO，节约资源，提升性能。<br> 4、实例：<br> 1）打开谓词下推优化属性</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">optimize</span><span class="token punctuation">.</span>ppd <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span> <span class="token comment">#谓词下推，默认是true</span>
</code></pre> 
<p>2）查看先关联两张表，再用where条件过滤的执行计划</p> 
<pre><code class="prism language-sql"><span class="token keyword">explain</span> <span class="token keyword">select</span> o<span class="token punctuation">.</span>id <span class="token keyword">from</span> bigtable b <span class="token keyword">join</span> bigtable o  <span class="token keyword">on</span> o<span class="token punctuation">.</span>id <span class="token operator">=</span> b<span class="token punctuation">.</span>id <span class="token keyword">where</span> o<span class="token punctuation">.</span>id <span class="token operator">&lt;=</span> <span class="token number">10</span><span class="token punctuation">;</span>
</code></pre> 
<p>3）查看子查询后，再关联表的执行计划</p> 
<pre><code class="prism language-sql"><span class="token keyword">explain</span> <span class="token keyword">select</span> b<span class="token punctuation">.</span>id <span class="token keyword">from</span> bigtable b
<span class="token keyword">join</span> <span class="token punctuation">(</span><span class="token keyword">select</span> id <span class="token keyword">from</span> bigtable <span class="token keyword">where</span> id <span class="token operator">&lt;=</span> <span class="token number">10</span><span class="token punctuation">)</span> o <span class="token keyword">on</span> b<span class="token punctuation">.</span>id <span class="token operator">=</span> o<span class="token punctuation">.</span>id<span class="token punctuation">;</span>
</code></pre> 
<p>（1）测试先关联两张表，再用where条件过滤</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> o<span class="token punctuation">.</span>id <span class="token keyword">from</span> bigtable b
<span class="token keyword">join</span> bigtable o <span class="token keyword">on</span>  o<span class="token punctuation">.</span>id <span class="token operator">=</span> b<span class="token punctuation">.</span>id
<span class="token keyword">where</span> o<span class="token punctuation">.</span>id <span class="token operator">&lt;=</span> <span class="token number">10</span><span class="token punctuation">;</span>
</code></pre> 
<p>Time taken: 34.406 seconds, Fetched: 100 row(s)<br> （2）通过子查询后，再关联表</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> b<span class="token punctuation">.</span>id <span class="token keyword">from</span> bigtable b
<span class="token keyword">join</span> <span class="token punctuation">(</span><span class="token keyword">select</span> id <span class="token keyword">from</span> bigtable <span class="token keyword">where</span> id <span class="token operator">&lt;=</span> <span class="token number">10</span> <span class="token punctuation">)</span> o <span class="token keyword">on</span> b<span class="token punctuation">.</span>id <span class="token operator">=</span> o<span class="token punctuation">.</span>id<span class="token punctuation">;</span>
</code></pre> 
<p>Time taken: 30.058 seconds, Fetched: 100 row(s)</p> 
<h4><a id="1025_MapJoin_2475"></a>10.2.5 MapJoin</h4> 
<p>MapJoin是将Join双方比较小的表直接分发给各个Map进程的内存中，在Map进程中进行Join操作，这样就不用进行Reduce步骤，从而提高了速度。如果不指定MapJoin或者不符合MapJoin的条件，那么Hive解析器会将Join操作转换成Common Join，即：在Reduce阶段完成Join。容易发生数据倾斜。可以用MapJoin把小表全部加载到内存在Map端进行Join，避免Reducer处理。<br> 1、开启MapJoin参数设置<br> 1）设置自动选择MapJoin</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span>auto<span class="token punctuation">.</span><span class="token keyword">convert</span><span class="token punctuation">.</span><span class="token keyword">join</span><span class="token operator">=</span><span class="token boolean">true</span><span class="token punctuation">;</span> <span class="token comment">#默认为true</span>
</code></pre> 
<p>2）大表小表的阈值设置（默认25M以下认为是小表）</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span>mapjoin<span class="token punctuation">.</span>smalltable<span class="token punctuation">.</span>filesize<span class="token operator">=</span><span class="token number">25000000</span><span class="token punctuation">;</span>
</code></pre> 
<p>2、MapJoin工作机制<br> MapJoin是将Join双方比较小的表直接分发到各个Map进程的内容中，在Map进程中进行Join操作，这样就不用进行Reduce步骤，从而提高了速度。<br> 3、实操：<br> 1）开启MapJoin功能</p> 
<pre><code class="prism language-sql">hive<span class="token punctuation">(</span><span class="token keyword">default</span><span class="token punctuation">)</span><span class="token operator">&gt;</span> <span class="token keyword">set</span> hive<span class="token punctuation">.</span>auto<span class="token punctuation">.</span><span class="token keyword">convert</span><span class="token punctuation">.</span><span class="token keyword">join</span> <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span> <span class="token comment">//默认为true</span>
</code></pre> 
<p>2）执行小表JOIN大表功能<br> 注意：此时小表（左连接）作为主表，所有数据都要写出去，因此此时会走reduce，mapjoin失效</p> 
<pre><code class="prism language-sql"><span class="token keyword">Explain</span>
<span class="token keyword">select</span> b<span class="token punctuation">.</span>id<span class="token punctuation">,</span> b<span class="token punctuation">.</span>t<span class="token punctuation">,</span> b<span class="token punctuation">.</span>uid<span class="token punctuation">,</span> b<span class="token punctuation">.</span>keyword<span class="token punctuation">,</span> b<span class="token punctuation">.</span>url_rank<span class="token punctuation">,</span> b<span class="token punctuation">.</span>click_num<span class="token punctuation">,</span> b<span class="token punctuation">.</span>click_url
<span class="token keyword">from</span> smalltable s
<span class="token keyword">left</span> <span class="token keyword">join</span> bigtable b
<span class="token keyword">on</span> s<span class="token punctuation">.</span>id <span class="token operator">=</span> b<span class="token punctuation">.</span>id<span class="token punctuation">;</span>
</code></pre> 
<p>3）执行大表JOIN小表语句</p> 
<pre><code class="prism language-sql"><span class="token keyword">Explain</span>
<span class="token keyword">select</span> b<span class="token punctuation">.</span>id<span class="token punctuation">,</span> b<span class="token punctuation">.</span>t<span class="token punctuation">,</span> b<span class="token punctuation">.</span>uid<span class="token punctuation">,</span> b<span class="token punctuation">.</span>keyword<span class="token punctuation">,</span> b<span class="token punctuation">.</span>url_rank<span class="token punctuation">,</span> b<span class="token punctuation">.</span>click_num<span class="token punctuation">,</span> b<span class="token punctuation">.</span>click_url
<span class="token keyword">from</span> bigtable b
<span class="token keyword">left</span> <span class="token keyword">join</span> smalltable s
<span class="token keyword">on</span> b<span class="token punctuation">.</span>id <span class="token operator">=</span> s<span class="token punctuation">.</span>id<span class="token punctuation">;</span>
</code></pre> 
<h4><a id="1026_SMB_JOIN_2519"></a>10.2.6 大表、大表SMB JOIN（重点）</h4> 
<p>1、SMB：sort merge bucket join<br> 2、实例<br> 1）对照案例，普通大表join<br> （1）创建第二张大表bigtable2，并加载数据</p> 
<pre><code class="prism language-sql"><span class="token keyword">create</span> <span class="token keyword">table</span> bigtable2<span class="token punctuation">(</span>
    id <span class="token keyword">bigint</span><span class="token punctuation">,</span>
    t <span class="token keyword">bigint</span><span class="token punctuation">,</span>
    uid string<span class="token punctuation">,</span>
    keyword string<span class="token punctuation">,</span>
    url_rank <span class="token keyword">int</span><span class="token punctuation">,</span>
    click_num <span class="token keyword">int</span><span class="token punctuation">,</span>
    click_url string<span class="token punctuation">)</span>
<span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'\t'</span><span class="token punctuation">;</span>
<span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/opt/module/hive/datas/bigtable'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> bigtable2<span class="token punctuation">;</span>
</code></pre> 
<p>（2）测试大表直接JOIN</p> 
<pre><code class="prism language-sql"><span class="token keyword">insert</span> overwrite <span class="token keyword">table</span> jointable
<span class="token keyword">select</span> b<span class="token punctuation">.</span>id<span class="token punctuation">,</span> b<span class="token punctuation">.</span>t<span class="token punctuation">,</span> b<span class="token punctuation">.</span>uid<span class="token punctuation">,</span> b<span class="token punctuation">.</span>keyword<span class="token punctuation">,</span> b<span class="token punctuation">.</span>url_rank<span class="token punctuation">,</span> b<span class="token punctuation">.</span>click_num<span class="token punctuation">,</span> b<span class="token punctuation">.</span>click_url
<span class="token keyword">from</span> bigtable s
<span class="token keyword">join</span> bigtable2 b
<span class="token keyword">on</span> b<span class="token punctuation">.</span>id <span class="token operator">=</span> s<span class="token punctuation">.</span>id<span class="token punctuation">;</span>
</code></pre> 
<p>2）SMB案例，分桶大表join<br> （1）创建分桶表1 -&gt; bigtable_buck1，桶的个数不要超过可用cpu的核数</p> 
<pre><code class="prism language-sql"><span class="token keyword">create</span> <span class="token keyword">table</span> bigtable_buck1<span class="token punctuation">(</span>
    id <span class="token keyword">bigint</span><span class="token punctuation">,</span>
    t <span class="token keyword">bigint</span><span class="token punctuation">,</span>
    uid string<span class="token punctuation">,</span>
    keyword string<span class="token punctuation">,</span>
    url_rank <span class="token keyword">int</span><span class="token punctuation">,</span>
    click_num <span class="token keyword">int</span><span class="token punctuation">,</span>
    click_url string<span class="token punctuation">)</span>
<span class="token keyword">clustered</span> <span class="token keyword">by</span><span class="token punctuation">(</span>id<span class="token punctuation">)</span> 
sorted <span class="token keyword">by</span><span class="token punctuation">(</span>id<span class="token punctuation">)</span>
<span class="token keyword">into</span> <span class="token number">6</span> buckets   <span class="token comment">-- 桶的个数和CPU核数和Reduce数需要一致</span>
<span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">'\t'</span><span class="token punctuation">;</span>
<span class="token keyword">insert</span> <span class="token keyword">into</span> bigtable_buck1 <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> bigtable<span class="token punctuation">;</span> 
</code></pre> 
<p>（2）创建分桶表2 -&gt; bigtable_buck2，桶的个数是bigtable_buck1的倍数关系，这里取一倍</p> 
<pre><code class="prism language-sql"><span class="token keyword">create</span> <span class="token keyword">table</span> bigtable_buck2 <span class="token operator">like</span> bigtable_buck1<span class="token punctuation">;</span>
<span class="token keyword">insert</span> <span class="token keyword">into</span> bigtable_buck2 <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> bigtable<span class="token punctuation">;</span> 
</code></pre> 
<p>（3）设置参数，开启SMB</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">optimize</span><span class="token punctuation">.</span>bucketmapjoin <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">optimize</span><span class="token punctuation">.</span>bucketmapjoin<span class="token punctuation">.</span>sortedmerge <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span>input<span class="token punctuation">.</span>format<span class="token operator">=</span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>ql<span class="token punctuation">.</span>io<span class="token punctuation">.</span>BucketizedHiveInputFormat<span class="token punctuation">;</span>
</code></pre> 
<p>（4）测试SMB join</p> 
<pre><code class="prism language-sql"><span class="token keyword">insert</span> overwrite <span class="token keyword">table</span> jointable
<span class="token keyword">select</span> b<span class="token punctuation">.</span>id<span class="token punctuation">,</span> b<span class="token punctuation">.</span>t<span class="token punctuation">,</span> b<span class="token punctuation">.</span>uid<span class="token punctuation">,</span> b<span class="token punctuation">.</span>keyword<span class="token punctuation">,</span> b<span class="token punctuation">.</span>url_rank<span class="token punctuation">,</span> b<span class="token punctuation">.</span>click_num<span class="token punctuation">,</span> b<span class="token punctuation">.</span>click_url
<span class="token keyword">from</span> bigtable_buck1 s
<span class="token keyword">join</span> bigtable_buck2 b
<span class="token keyword">on</span> b<span class="token punctuation">.</span>id <span class="token operator">=</span> s<span class="token punctuation">.</span>id<span class="token punctuation">;</span>
</code></pre> 
<h4><a id="1027__2589"></a>10.2.7 笛卡尔积</h4> 
<p>1、产生笛卡尔积的条件：<br> 1）两个表join时不写on条件<br> 2）两个表join时on条件无效<br> 2、问题：Hive中笛卡尔积的查询只能使用一个Reducer来完成，面对海量数据很容易出现问题。<br> Map阶段：在这个阶段，系统对输入数据进行初步处理，通常是分解和转换操作。例如，它可能对数据集进行排序或筛选。<br> Reduce阶段：在Map阶段之后进行的是Reduce阶段。在这个阶段，Reduce接收来自Mapper的输出数据，并对这些数据进行汇总、整合或其它形式的处理，并生成最终的输出结果。<br> 3、解决：不要写笛卡尔积，开启严格模式，不允许在HQL中出现笛卡尔积</p> 
<h3><a id="103__2597"></a>10.3 数据倾斜</h3> 
<p>1、数据倾斜现象：<br> 绝大多数任务都很快完成，只有一个或者少数几个任务执行的很慢甚至最终执行失败。<br> 2、数据过量现象：<br> 数据过量的表现为所有任务都执行的很慢，这个时候只有提高执行资源才可以优化HQL的执行效率。<br> 3、数据倾斜的原因：<br> 导致倾斜的原因在于按照key分组后，少量的任务负载着绝大部分数据的计算，也就是说，产生数据倾斜的HQL中一定存在分组的操作。所有从HQL的角度，我们可用将数据倾斜分为单表携带了Group by字段的查询和两表（多表）join的查询。</p> 
<h4><a id="1031__2604"></a>10.3.1 单表数据倾斜优化</h4> 
<p>1、使用参数优化<br> 当任务中存在group by操作同时聚合函数为count或者sum可用设置参数来处理数据倾斜的问题，就是上文的Group by处理方式。<br> 1）是否在Map端进行聚合，默认为True</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span>map<span class="token punctuation">.</span>aggr <span class="token operator">=</span> <span class="token boolean">true</span>
</code></pre> 
<p>2）在Map端进行聚合操作的条目数目</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span>groupby<span class="token punctuation">.</span>mapaggr<span class="token punctuation">.</span>checkinterval <span class="token operator">=</span> <span class="token number">100000</span>
</code></pre> 
<p>3）有数据倾斜的时候进行负载均衡（默认是false）</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span>groupby<span class="token punctuation">.</span>skewindata <span class="token operator">=</span> <span class="token boolean">true</span>
</code></pre> 
<p>2、增加Reduce数量<br> 当数据中的多个key同时导致数据倾斜，可用通过增加reduce的数量解决数据倾斜问题<br> 1）调整Reduce个数方法1：<br> （1）每个Reduce处理的数据量默认是256MB</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>reducers<span class="token punctuation">.</span>bytes<span class="token punctuation">.</span>per<span class="token punctuation">.</span>reducer<span class="token operator">=</span><span class="token number">256000000</span>
</code></pre> 
<p>（2）每个任务最大的reduce数，默认为1009</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>reducers<span class="token punctuation">.</span>max<span class="token operator">=</span><span class="token number">1009</span>
</code></pre> 
<p>（3）计算reducer数的公式</p> 
<pre><code class="prism language-sql">N<span class="token operator">=</span><span class="token function">min</span><span class="token punctuation">(</span>参数<span class="token number">2</span>，总输入数据量<span class="token operator">/</span>参数<span class="token number">1</span><span class="token punctuation">)</span>
</code></pre> 
<p>2）调整Reduce个数方法2：<br> 通过参数配置的方式（三种）直接指定reduce的个数，参数mapreduce.job.reduces。</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> mapreduce<span class="token punctuation">.</span>job<span class="token punctuation">.</span>reduces <span class="token operator">=</span> <span class="token number">15</span><span class="token punctuation">;</span>
</code></pre> 
<h4><a id="1031_join_2652"></a>10.3.1 join数据倾斜优化</h4> 
<p>1、使用参数<br> 在编写Join查询语句时，如果确定是由于join出现的数据倾斜，那么请坐如下设置。</p> 
<pre><code class="prism language-sql"><span class="token comment"># join的键对应的记录条数超过这个值则会进行分拆，值根据具体数据量设置</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span>skewjoin<span class="token punctuation">.</span><span class="token keyword">key</span><span class="token operator">=</span><span class="token number">100000</span><span class="token punctuation">;</span>
<span class="token comment"># 如果是join过程出现倾斜应该设置为true</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">optimize</span><span class="token punctuation">.</span>skewjoin<span class="token operator">=</span><span class="token boolean">false</span><span class="token punctuation">;</span>
</code></pre> 
<p>如果开启了，在Join过程中Hive会将计数超过阈值hive.skewjoin.key（默认100000）的倾斜key对应的行临时写入文件中，然后再启动另一个job左map join生成结果。通过hive.skewjoin.mapjoin.map.tasts参数还可以控制第二个job的mapper数量，默认10000。</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span>skewjoin<span class="token punctuation">.</span>mapjoin<span class="token punctuation">.</span>map<span class="token punctuation">.</span>tasks<span class="token operator">=</span><span class="token number">10000</span><span class="token punctuation">;</span>
</code></pre> 
<p>2、大小表join<br> 可用使用MapJoin，没有Reduce阶段就不会出现数据倾斜。<br> 3、大表大表join<br> 使用大散加扩容方式解决数据倾斜问题<br> 选择其中较大的表做打散处理：</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> <span class="token operator">*</span><span class="token punctuation">,</span>concat<span class="token punctuation">(</span>id<span class="token punctuation">,</span><span class="token string">'-'</span><span class="token punctuation">,</span><span class="token string">'0 or 1 or 2'</span><span class="token punctuation">)</span> <span class="token keyword">from</span> A<span class="token punctuation">;</span>t1
</code></pre> 
<p>选择其中较小的表做扩容处理</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> <span class="token operator">*</span><span class="token punctuation">,</span>concat<span class="token punctuation">(</span>id<span class="token punctuation">,</span><span class="token string">'-'</span><span class="token punctuation">,</span><span class="token string">'0'</span><span class="token punctuation">)</span> <span class="token keyword">from</span> B
<span class="token keyword">union</span> <span class="token keyword">all</span>
<span class="token keyword">select</span> <span class="token operator">*</span><span class="token punctuation">,</span>concat<span class="token punctuation">(</span>id<span class="token punctuation">,</span><span class="token string">'-'</span><span class="token punctuation">,</span><span class="token string">'1'</span><span class="token punctuation">)</span> <span class="token keyword">from</span> B
<span class="token keyword">union</span> <span class="token keyword">all</span>
<span class="token keyword">select</span> <span class="token operator">*</span><span class="token punctuation">,</span>concat<span class="token punctuation">(</span>id<span class="token punctuation">,</span><span class="token string">'-'</span><span class="token punctuation">,</span><span class="token string">'2'</span><span class="token punctuation">)</span> <span class="token keyword">from</span> B<span class="token punctuation">;</span>t2
</code></pre> 
<h3><a id="104_Hive_job_2685"></a>10.4 Hive job优化</h3> 
<h4><a id="1041_Hive_Map_2686"></a>10.4.1 Hive Map阶段优化</h4> 
<p>1、负载文件增加Map数量<br> 1）使用场景：当input的文件都很大，任务逻辑复杂，map执行非常慢的时候，可用考虑增加Map数，来使得每个map处理的数据量减少，从而提高任务的执行效率。<br> 2）增加map数据的方法：</p> 
<pre><code class="prism language-sql">computeSliteSize<span class="token punctuation">(</span>Math<span class="token punctuation">.</span><span class="token function">max</span><span class="token punctuation">(</span>minSize<span class="token punctuation">,</span>Math<span class="token punctuation">.</span><span class="token function">min</span><span class="token punctuation">(</span>maxSize<span class="token punctuation">,</span>blocksize<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">=</span>blocksize<span class="token operator">=</span><span class="token number">128</span>M
</code></pre> 
<p>公式调整maxSize最大值。让maxSize最大值低于blocksize就可以增加map的个数。<br> 3）案例：<br> （1）执行查询</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> <span class="token function">count</span><span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">)</span> <span class="token keyword">from</span> emp<span class="token punctuation">;</span>
Hadoop job information <span class="token keyword">for</span> Stage<span class="token operator">-</span><span class="token number">1</span>: number <span class="token keyword">of</span> mappers: <span class="token number">1</span><span class="token punctuation">;</span> number <span class="token keyword">of</span> reducers: <span class="token number">1</span>
</code></pre> 
<p>（2）设置最大切片值为100个字节</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> mapreduce<span class="token punctuation">.</span>input<span class="token punctuation">.</span>fileinputformat<span class="token punctuation">.</span>split<span class="token punctuation">.</span>maxsize<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">;</span>
<span class="token keyword">select</span> <span class="token function">count</span><span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">)</span> <span class="token keyword">from</span> emp<span class="token punctuation">;</span>
Hadoop job information <span class="token keyword">for</span> Stage<span class="token operator">-</span><span class="token number">1</span>: number <span class="token keyword">of</span> mappers: <span class="token number">6</span><span class="token punctuation">;</span> number <span class="token keyword">of</span> reducers: <span class="token number">1</span>
</code></pre> 
<p>2、小文件进行合并<br> 1）再map执行前合并小文件，减少map数：<br> CombineHiveInputFormat具有对小文件进行合并的功能（系统默认的格式）。<br> HiveInputFormat没有对小文件合并功能。</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span>input<span class="token punctuation">.</span>format<span class="token operator">=</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>ql<span class="token punctuation">.</span>io<span class="token punctuation">.</span>CombineHiveInputFormat<span class="token punctuation">;</span>
</code></pre> 
<p>2）再Map-Reduce的任务结束时合并小文件的设置<br> 在map-only任务结束时合并小文件，默认true</p> 
<pre><code class="prism language-sql"><span class="token keyword">SET</span> hive<span class="token punctuation">.</span><span class="token keyword">merge</span><span class="token punctuation">.</span>mapfiles <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>
</code></pre> 
<p>在map-reduce任务结束时合并小文件，默认false</p> 
<pre><code class="prism language-sql"><span class="token keyword">SET</span> hive<span class="token punctuation">.</span><span class="token keyword">merge</span><span class="token punctuation">.</span>mapredfiles <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>
</code></pre> 
<p>合并文件的大小，默认256M</p> 
<pre><code class="prism language-sql"><span class="token keyword">SET</span> hive<span class="token punctuation">.</span><span class="token keyword">merge</span><span class="token punctuation">.</span>size<span class="token punctuation">.</span>per<span class="token punctuation">.</span>task <span class="token operator">=</span> <span class="token number">268435456</span><span class="token punctuation">;</span>
</code></pre> 
<p>当输出文件的平均大小小于该值时，启动一个独立的map-reduce任务进行文件merge</p> 
<pre><code class="prism language-sql"><span class="token keyword">SET</span> hive<span class="token punctuation">.</span><span class="token keyword">merge</span><span class="token punctuation">.</span>smallfiles<span class="token punctuation">.</span>avgsize <span class="token operator">=</span> <span class="token number">16777216</span><span class="token punctuation">;</span>
</code></pre> 
<p>3、Map端聚合</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span>map<span class="token punctuation">.</span>aggr<span class="token operator">=</span><span class="token boolean">true</span><span class="token punctuation">;</span><span class="token comment">//相当于map端执行combiner</span>
</code></pre> 
<h4><a id="1042_Hive_Reduce_2751"></a>10.4.2 Hive Reduce优化</h4> 
<p>1、合理设置Reduce数<br> 1）调整reduce个数方法一<br> （1）每个Reduce处理的数据量默认是256MB</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>reducers<span class="token punctuation">.</span>bytes<span class="token punctuation">.</span>per<span class="token punctuation">.</span>reducer<span class="token operator">=</span><span class="token number">256000000</span>
</code></pre> 
<p>（2）每个任务最大的reduce数，默认为1009</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>reducers<span class="token punctuation">.</span>max<span class="token operator">=</span><span class="token number">1009</span>
</code></pre> 
<p>（3）计算reducer数的公式</p> 
<pre><code class="prism language-sql">N<span class="token operator">=</span><span class="token function">min</span><span class="token punctuation">(</span>参数<span class="token number">2</span>，总输入数据量<span class="token operator">/</span>参数<span class="token number">1</span><span class="token punctuation">)</span>
</code></pre> 
<p>2）调整reduce个数方法二<br> 通过参数配置的方式（三种）直接指定reduce的个二叔，参数mapreduce.job.reduces。</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> mapreduce<span class="token punctuation">.</span>job<span class="token punctuation">.</span>reduces <span class="token operator">=</span> <span class="token number">15</span><span class="token punctuation">;</span>
</code></pre> 
<p>3）reduce个数不是越多越好<br> （1）过多的启动和初始化reduce也会消耗时间和资源<br> （2）另外，有多少个reduce，就会有多少个输出文件，如果生成了很多个小文件，那么如果这些小文件作为下一个文件的输入，则会出现小文件过多的问题。<br> （3）在设置reduce个数的时候也需要考虑这两个问题：处理大数据量利用合适的redece数；使单个reduce任务处理数据量大小要合适。</p> 
<h4><a id="1043_Hive_2783"></a>10.4.3 Hive任务整体优化</h4> 
<p>1、Fetch抓取<br> Fetch抓取是指，Hive中对某些情况的查询可以不必使用MapReduce计算。例如：select * from emp;在这种情况下，Hive可以简单地读取emp对应地存储目录下的文件，然后输出查询结果到控制台。在hive-default.xml.template文件中hive.fetch.task.conversion默认是more，老版本hive默认minimal，该属性修改为more以后，在全局查询、字段查询、limit查询等都不走mapreduce。</p> 
<pre><code class="prism language-sql"><span class="token operator">&lt;</span>property<span class="token operator">&gt;</span>
    <span class="token operator">&lt;</span>name<span class="token operator">&gt;</span>hive<span class="token punctuation">.</span><span class="token keyword">fetch</span><span class="token punctuation">.</span>task<span class="token punctuation">.</span>conversion<span class="token operator">&lt;</span><span class="token operator">/</span>name<span class="token operator">&gt;</span>
    <span class="token operator">&lt;</span><span class="token keyword">value</span><span class="token operator">&gt;</span>more<span class="token operator">&lt;</span><span class="token operator">/</span><span class="token keyword">value</span><span class="token operator">&gt;</span>
    <span class="token operator">&lt;</span>description<span class="token operator">&gt;</span>
      Expects one <span class="token keyword">of</span> <span class="token punctuation">[</span>none<span class="token punctuation">,</span> minimal<span class="token punctuation">,</span> more<span class="token punctuation">]</span><span class="token punctuation">.</span>
      <span class="token keyword">Some</span> <span class="token keyword">select</span> queries can be converted <span class="token keyword">to</span> single <span class="token keyword">FETCH</span> task minimizing latency<span class="token punctuation">.</span>
      Currently the query should be single sourced <span class="token operator">not</span> <span class="token keyword">having</span> <span class="token keyword">any</span> subquery <span class="token operator">and</span> should <span class="token operator">not</span> have <span class="token keyword">any</span> aggregations <span class="token operator">or</span> distincts <span class="token punctuation">(</span>which incurs RS<span class="token punctuation">)</span><span class="token punctuation">,</span> lateral views <span class="token operator">and</span> joins<span class="token punctuation">.</span>
      <span class="token number">0.</span> none : <span class="token keyword">disable</span> hive<span class="token punctuation">.</span><span class="token keyword">fetch</span><span class="token punctuation">.</span>task<span class="token punctuation">.</span>conversion
      <span class="token number">1.</span> minimal : <span class="token keyword">SELECT</span> STAR<span class="token punctuation">,</span> FILTER <span class="token keyword">on</span> <span class="token keyword">partition</span> <span class="token keyword">columns</span><span class="token punctuation">,</span> <span class="token keyword">LIMIT</span> only
      <span class="token number">2.</span> more  : <span class="token keyword">SELECT</span><span class="token punctuation">,</span> FILTER<span class="token punctuation">,</span> <span class="token keyword">LIMIT</span> only <span class="token punctuation">(</span>support TABLESAMPLE <span class="token operator">and</span> virtual <span class="token keyword">columns</span><span class="token punctuation">)</span>
    <span class="token operator">&lt;</span><span class="token operator">/</span>description<span class="token operator">&gt;</span>
<span class="token operator">&lt;</span><span class="token operator">/</span>property<span class="token operator">&gt;</span>
</code></pre> 
<p>1）案例：<br> （1）把hive.fetch.task.conversion设置成none，然后执行查询语句，都会执行mapreduce程序。</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">fetch</span><span class="token punctuation">.</span>task<span class="token punctuation">.</span>conversion<span class="token operator">=</span>none<span class="token punctuation">;</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> emp<span class="token punctuation">;</span>
<span class="token keyword">select</span> ename <span class="token keyword">from</span> emp<span class="token punctuation">;</span>
<span class="token keyword">select</span> ename <span class="token keyword">from</span> emp <span class="token keyword">limit</span> <span class="token number">3</span><span class="token punctuation">;</span>
</code></pre> 
<p>（2）把hive.fetch.task.conversion设置成more，然后执行查询语句，如下查询语句都不会执行mapreduce程序。</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">fetch</span><span class="token punctuation">.</span>task<span class="token punctuation">.</span>conversion<span class="token operator">=</span>more<span class="token punctuation">;</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> emp<span class="token punctuation">;</span>
<span class="token keyword">select</span> ename <span class="token keyword">from</span> emp<span class="token punctuation">;</span>
<span class="token keyword">select</span> ename <span class="token keyword">from</span> emp <span class="token keyword">limit</span> <span class="token number">3</span><span class="token punctuation">;</span>
</code></pre> 
<p>2、本地模式<br> 1）本地模式介绍<br> （1）大多数的Hadoop Job是需要Hadoop提供的完整的可扩展性来处理大数据集的。<br> （2）不过，有时Hive的输入数据量是非常小的。在这种情况下，为查询触发执行任务消耗的时间可能会比实际job的执行时间要多的多。<br> （3）对于大多数这种情况，Hive可以通过本地模式在单台机器上处理所有的任务。对于小数据集，执行时间可以明显被缩短。<br> （4）用户可以通过设置hive.exec.mode.local.auto=true，来让Hive在适当的时候自动启动这个优化。</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span><span class="token keyword">mode</span><span class="token punctuation">.</span><span class="token keyword">local</span><span class="token punctuation">.</span>auto<span class="token operator">=</span><span class="token boolean">true</span><span class="token punctuation">;</span>   <span class="token comment">//开启本地mr</span>
<span class="token comment">// 设置local mr的最大输入数据量，当输入数据量小于这个值时采用local mr的方式，默认为134217728，即128M</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span><span class="token keyword">mode</span><span class="token punctuation">.</span><span class="token keyword">local</span><span class="token punctuation">.</span>auto<span class="token punctuation">.</span>inputbytes<span class="token punctuation">.</span>max<span class="token operator">=</span><span class="token number">50000000</span><span class="token punctuation">;</span>
<span class="token comment">// 设置local mr的最大输入文件个数，当输入文件个数小于这个值时采用local mr的方式，默认为4</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span><span class="token keyword">mode</span><span class="token punctuation">.</span><span class="token keyword">local</span><span class="token punctuation">.</span>auto<span class="token punctuation">.</span>input<span class="token punctuation">.</span>files<span class="token punctuation">.</span>max<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">;</span>
</code></pre> 
<p>2）案例：<br> （1）开启本地模式，并执行查询语句</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span><span class="token keyword">mode</span><span class="token punctuation">.</span><span class="token keyword">local</span><span class="token punctuation">.</span>auto<span class="token operator">=</span><span class="token boolean">true</span><span class="token punctuation">;</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> emp cluster <span class="token keyword">by</span> deptno<span class="token punctuation">;</span>
……
Ended Job <span class="token operator">=</span> job_local177532144_0001
……
<span class="token keyword">Time</span> taken: <span class="token number">1.328</span> seconds<span class="token punctuation">,</span> Fetched: <span class="token number">14</span> <span class="token keyword">row</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span>
</code></pre> 
<p>（2）关闭本地模式，并执行查询语句</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span><span class="token keyword">mode</span><span class="token punctuation">.</span><span class="token keyword">local</span><span class="token punctuation">.</span>auto<span class="token operator">=</span><span class="token boolean">false</span><span class="token punctuation">;</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> emp cluster <span class="token keyword">by</span> deptno<span class="token punctuation">;</span>
……
<span class="token keyword">Starting</span> Job <span class="token operator">=</span> job_1634825444943_0018<span class="token punctuation">,</span> Tracking URL <span class="token operator">=</span> http:<span class="token comment">//hadoop103:8088/proxy/application_1634825444943_0018/</span>
……
<span class="token keyword">Time</span> taken: <span class="token number">20.09</span> seconds<span class="token punctuation">,</span> Fetched: <span class="token number">14</span> <span class="token keyword">row</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span>
</code></pre> 
<p>3、并行执行<br> Hive会将一个查询转化成一个或者多个阶段。这样的阶段可以是MapReduce阶段、抽样阶段、合并阶段、limit阶段。或者Hive执行过程中可能需要的其它阶段。默认情况下，Hive依次只会执行一个阶段。不过，某个特定的job可能包含众多的阶段，而这些阶段可能并非完全互相依赖的，也就是说有些阶段是可以并行执行的，这样可能使得整个job的执行时间缩短。不过，如果有更多的阶段可以并行执行，那么job可能就越快完成。通过设置参数hive.exec.parallel=true，就可以开启并发执行。不过，在共享集群中，需要注意下，如果job中并行阶段增多，那么集群利用率就会增加。</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>parallel<span class="token operator">=</span><span class="token boolean">true</span><span class="token punctuation">;</span>            <span class="token comment">//打开任务并行执行</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>parallel<span class="token punctuation">.</span>thread<span class="token punctuation">.</span>number<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">;</span>  <span class="token comment">//同一个sql允许最大并行度，默认为8。</span>
</code></pre> 
<p>当然，的在系统资源比较空闲的时候才有优势，否则，没资源，并行不起来。<br> 4、严格模式<br> 1）介绍：Hive可以通过设置防止一些危险操作<br> 2）分区表不适用分区过滤<br> 将hive.strict.checks.no.partition.filter=true时，对于分区表，除非where语句中含有分区字段过滤条件来限制范围，否则不允许执行。换句话说，就是用户不允许扫描所有分区。进行这个限制的原因是，通常分区表都拥有非常大的数据集，而且数据增加迅速。没有进行分区限制的查询可能会消耗令人不可接受的巨大资源来处理这个表。</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span>strict<span class="token punctuation">.</span>checks<span class="token punctuation">.</span><span class="token keyword">no</span><span class="token punctuation">.</span><span class="token keyword">partition</span><span class="token punctuation">.</span>filter<span class="token operator">=</span><span class="token boolean">true</span><span class="token punctuation">;</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> dept_partition<span class="token punctuation">;</span>
FAILED: SemanticException <span class="token punctuation">[</span>Error <span class="token number">10056</span><span class="token punctuation">]</span>: Queries against partitioned <span class="token keyword">tables</span> without a <span class="token keyword">partition</span> filter are disabled <span class="token keyword">for</span> safety reasons<span class="token punctuation">.</span> <span class="token keyword">If</span> you know what you are doing<span class="token punctuation">,</span> please <span class="token keyword">set</span> hive<span class="token punctuation">.</span>strict<span class="token punctuation">.</span>checks<span class="token punctuation">.</span><span class="token keyword">no</span><span class="token punctuation">.</span><span class="token keyword">partition</span><span class="token punctuation">.</span>filter <span class="token keyword">to</span> <span class="token boolean">false</span> <span class="token operator">and</span> make sure that hive<span class="token punctuation">.</span>mapred<span class="token punctuation">.</span><span class="token keyword">mode</span> <span class="token operator">is</span> <span class="token operator">not</span> <span class="token keyword">set</span> <span class="token keyword">to</span> <span class="token string">'strict'</span> <span class="token keyword">to</span> proceed<span class="token punctuation">.</span> Note that you may get <span class="token keyword">errors</span> <span class="token operator">or</span> incorrect results <span class="token keyword">if</span> you make a mistake <span class="token keyword">while</span> <span class="token keyword">using</span> <span class="token keyword">some</span> <span class="token keyword">of</span> the unsafe features<span class="token punctuation">.</span> <span class="token keyword">No</span> <span class="token keyword">partition</span> predicate <span class="token keyword">for</span> Alias <span class="token string">"dept_partition"</span> <span class="token keyword">Table</span> <span class="token string">"dept_partition"</span>
</code></pre> 
<p>3）使用order by 没有limit过滤<br> 将hive.strict.checks.orderby.no.limit=true时，对于使用了order by语句的查询，要求必须使用limit语句。应为order by为了执行排序过程中会将所有的结果数据分发到同一个Reducer中进行处理，强制要求用户增加这个LIMIT语句可以防止Reducer额外执行很长一段时间。</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span>strict<span class="token punctuation">.</span>checks<span class="token punctuation">.</span>orderby<span class="token punctuation">.</span><span class="token keyword">no</span><span class="token punctuation">.</span><span class="token keyword">limit</span><span class="token operator">=</span><span class="token boolean">true</span><span class="token punctuation">;</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> emp <span class="token keyword">order</span> <span class="token keyword">by</span> sal<span class="token punctuation">;</span>
FAILED: SemanticException <span class="token number">1</span>:<span class="token number">27</span> <span class="token keyword">Order</span> <span class="token keyword">by</span><span class="token operator">-</span>s without <span class="token keyword">limit</span> are disabled <span class="token keyword">for</span> safety reasons<span class="token punctuation">.</span> <span class="token keyword">If</span> you know what you are doing<span class="token punctuation">,</span> please <span class="token keyword">set</span> hive<span class="token punctuation">.</span>strict<span class="token punctuation">.</span>checks<span class="token punctuation">.</span>orderby<span class="token punctuation">.</span><span class="token keyword">no</span><span class="token punctuation">.</span><span class="token keyword">limit</span> <span class="token keyword">to</span> <span class="token boolean">false</span> <span class="token operator">and</span> make sure that hive<span class="token punctuation">.</span>mapred<span class="token punctuation">.</span><span class="token keyword">mode</span> <span class="token operator">is</span> <span class="token operator">not</span> <span class="token keyword">set</span> <span class="token keyword">to</span> <span class="token string">'strict'</span> <span class="token keyword">to</span> proceed<span class="token punctuation">.</span> Note that you may get <span class="token keyword">errors</span> <span class="token operator">or</span> incorrect results <span class="token keyword">if</span> you make a mistake <span class="token keyword">while</span> <span class="token keyword">using</span> <span class="token keyword">some</span> <span class="token keyword">of</span> the unsafe features<span class="token punctuation">.</span><span class="token punctuation">.</span> Error encountered near token <span class="token string">'sal'</span>
</code></pre> 
<p>4）笛卡尔积<br> 将hive.strict.checks.cartesian.product=true时，会限制笛卡尔积的查询。对关系型数据块非常了解的用户可能期望在执行JOIN查询的时候不使用ON语句而是使用where语句，这样关系数据库的执行优化器就可以高效地将WHERE语句转化成那个ON语句。不幸的是,Hive并不会执行这种优化，因此，如果表足够大，那么这个查询就会出现不可控的情况。</p> 
<pre><code class="prism language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span>strict<span class="token punctuation">.</span>checks<span class="token punctuation">.</span>orderby<span class="token punctuation">.</span><span class="token keyword">no</span><span class="token punctuation">.</span><span class="token keyword">limit</span><span class="token operator">=</span><span class="token boolean">true</span><span class="token punctuation">;</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> emp <span class="token keyword">order</span> <span class="token keyword">by</span> sal<span class="token punctuation">;</span>
FAILED: SemanticException <span class="token number">1</span>:<span class="token number">27</span> <span class="token keyword">Order</span> <span class="token keyword">by</span><span class="token operator">-</span>s without <span class="token keyword">limit</span> are disabled <span class="token keyword">for</span> safety reasons<span class="token punctuation">.</span> <span class="token keyword">If</span> you know what you are doing<span class="token punctuation">,</span> please <span class="token keyword">set</span> hive<span class="token punctuation">.</span>strict<span class="token punctuation">.</span>checks<span class="token punctuation">.</span>orderby<span class="token punctuation">.</span><span class="token keyword">no</span><span class="token punctuation">.</span><span class="token keyword">limit</span> <span class="token keyword">to</span> <span class="token boolean">false</span> <span class="token operator">and</span> make sure that hive<span class="token punctuation">.</span>mapred<span class="token punctuation">.</span><span class="token keyword">mode</span> <span class="token operator">is</span> <span class="token operator">not</span> <span class="token keyword">set</span> <span class="token keyword">to</span> <span class="token string">'strict'</span> <span class="token keyword">to</span> proceed<span class="token punctuation">.</span> Note that you may get <span class="token keyword">errors</span> <span class="token operator">or</span> incorrect results <span class="token keyword">if</span> you make a mistake <span class="token keyword">while</span> <span class="token keyword">using</span> <span class="token keyword">some</span> <span class="token keyword">of</span> the unsafe features<span class="token punctuation">.</span><span class="token punctuation">.</span> Error encountered near token <span class="token string">'sal'</span>
</code></pre> 
<h2><a id="_11_Hive_2893"></a>第 11 章：Hive实战</h2> 
<h3><a id="111__2894"></a>11.1 数据结构</h3> 
<p>1、视频表</p> 
<table><thead><tr><th>字段</th><th>备注</th><th>详细描述</th></tr></thead><tbody><tr><td>videoId</td><td>视频唯一id(String)</td><td>11位字符串</td></tr><tr><td>uploader</td><td>视频上传者(String)</td><td>上传视频的用户名String</td></tr><tr><td>age</td><td>视频年龄(int)</td><td>视频在平台上的整天数</td></tr><tr><td>category</td><td>视频类别(Array)</td><td>上传视频指定的视频分类</td></tr><tr><td>length</td><td>视频长度(Int)</td><td>整形数字标识的视频长度</td></tr><tr><td>views</td><td>观看次数(Int)</td><td>视频被浏览的次数</td></tr><tr><td>rate</td><td>视频评分(Double)</td><td>满分5分</td></tr><tr><td>Ratings</td><td>流量(Int)</td><td>视频的流量，整形数字</td></tr><tr><td>comments</td><td>评论数(Int)</td><td>一个视频的整数评论数</td></tr><tr><td>relatedId</td><td>相关视频id(Array)</td><td>相关视频的id，最多20个</td></tr></tbody></table> 
<p>2、用户表</p> 
<table><thead><tr><th>字段</th><th>备注</th><th>字段类型</th></tr></thead><tbody><tr><td>uploader</td><td>上传者用户名</td><td>string</td></tr><tr><td>videos</td><td>上传视频数</td><td>int</td></tr><tr><td>friends</td><td>朋友数量</td><td>int</td></tr></tbody></table> 
<h3><a id="112__2915"></a>11.2 准备工作</h3> 
<p>1、需要准备的表<br> 1）创建原始数据表：gulivideo_ori，gulivideo_user_ori，<br> 2）创建最终表：gulivideo_orc，gulivideo_user_orc<br> 2、创建原始数据表<br> 1）创建原始数据表gulivideo_ori</p> 
<pre><code class="prism language-sql"><span class="token keyword">create</span> external <span class="token keyword">table</span> gulivideo_ori<span class="token punctuation">(</span>
    videoId string<span class="token punctuation">,</span> 
    uploader string<span class="token punctuation">,</span> 
    age <span class="token keyword">int</span><span class="token punctuation">,</span> 
    category array<span class="token operator">&lt;</span>string<span class="token operator">&gt;</span><span class="token punctuation">,</span> 
    length <span class="token keyword">int</span><span class="token punctuation">,</span> 
    views <span class="token keyword">int</span><span class="token punctuation">,</span> 
    rate <span class="token keyword">float</span><span class="token punctuation">,</span> 
    ratings <span class="token keyword">int</span><span class="token punctuation">,</span> 
    comments <span class="token keyword">int</span><span class="token punctuation">,</span>
    relatedId array<span class="token operator">&lt;</span>string<span class="token operator">&gt;</span>
<span class="token punctuation">)</span>
<span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">"\t"</span>
collection items <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">"&amp;"</span>
stored <span class="token keyword">as</span> textfile
location <span class="token string">'/gulivideo/video'</span><span class="token punctuation">;</span>
</code></pre> 
<p>2）创建原始数据表：gulivideo_user_ori</p> 
<pre><code class="prism language-sql"><span class="token keyword">create</span> external <span class="token keyword">table</span> gulivideo_user_ori<span class="token punctuation">(</span>
    uploader string<span class="token punctuation">,</span>
    videos <span class="token keyword">int</span><span class="token punctuation">,</span>
    friends <span class="token keyword">int</span>
<span class="token punctuation">)</span>
<span class="token keyword">row</span> format delimited 
<span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">"\t"</span> 
stored <span class="token keyword">as</span> textfile
location <span class="token string">'/gulivideo/user'</span><span class="token punctuation">;</span>
</code></pre> 
<p>3）创建orc存储格式带snappy压缩的表gulivideo_orc</p> 
<pre><code class="prism language-sql"><span class="token keyword">create</span> <span class="token keyword">table</span> gulivideo_orc<span class="token punctuation">(</span>
    videoId string<span class="token punctuation">,</span> 
    uploader string<span class="token punctuation">,</span> 
    age <span class="token keyword">int</span><span class="token punctuation">,</span> 
    category array<span class="token operator">&lt;</span>string<span class="token operator">&gt;</span><span class="token punctuation">,</span> 
    length <span class="token keyword">int</span><span class="token punctuation">,</span> 
    views <span class="token keyword">int</span><span class="token punctuation">,</span> 
    rate <span class="token keyword">float</span><span class="token punctuation">,</span> 
    ratings <span class="token keyword">int</span><span class="token punctuation">,</span> 
    comments <span class="token keyword">int</span><span class="token punctuation">,</span>
    relatedId array<span class="token operator">&lt;</span>string<span class="token operator">&gt;</span>
<span class="token punctuation">)</span>
stored <span class="token keyword">as</span> orc
tblproperties<span class="token punctuation">(</span><span class="token string">"orc.compress"</span><span class="token operator">=</span><span class="token string">"SNAPPY"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>4）创建orc存储格式带snappy压缩的表gulivideo_user_orc</p> 
<pre><code class="prism language-sql"><span class="token keyword">create</span> <span class="token keyword">table</span> gulivideo_user_orc<span class="token punctuation">(</span>
    uploader string<span class="token punctuation">,</span>
    videos <span class="token keyword">int</span><span class="token punctuation">,</span>
    friends <span class="token keyword">int</span>
<span class="token punctuation">)</span>
<span class="token keyword">row</span> format delimited 
<span class="token keyword">fields</span> <span class="token keyword">terminated</span> <span class="token keyword">by</span> <span class="token string">"\t"</span> 
stored <span class="token keyword">as</span> orc
tblproperties<span class="token punctuation">(</span><span class="token string">"orc.compress"</span><span class="token operator">=</span><span class="token string">"SNAPPY"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<p>5）向ori表插入数据</p> 
<pre><code class="prism language-sql"><span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">"/opt/module/hive/datas/video"</span> <span class="token keyword">into</span> <span class="token keyword">table</span> gulivideo_ori<span class="token punctuation">;</span>
<span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">"/opt/module/hive/datas/user.txt"</span> <span class="token keyword">into</span> <span class="token keyword">table</span> gulivideo_user_ori<span class="token punctuation">;</span>
</code></pre> 
<p>6）向orc表插入数据</p> 
<pre><code class="prism language-sql"><span class="token keyword">insert</span> <span class="token keyword">into</span> <span class="token keyword">table</span> gulivideo_orc <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> gulivideo_ori<span class="token punctuation">;</span>
<span class="token keyword">insert</span> <span class="token keyword">into</span> <span class="token keyword">table</span> gulivideo_user_orc <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> gulivideo_user_ori<span class="token punctuation">;</span>
</code></pre> 
<h3><a id="113__3000"></a>11.3 业务分析</h3> 
<h4><a id="1131_Top10_3001"></a>11.3.1 统计视频观看数Top10</h4> 
<p>1、思路：<br> 使用order by按照views字段做一个全局排序即可，同时我们设置只显示前10条。<br> 2、代码</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span>
    videoId<span class="token punctuation">,</span>
    <span class="token identifier"><span class="token punctuation">`</span>views<span class="token punctuation">`</span></span>
<span class="token keyword">from</span> gulivideo_orc
<span class="token keyword">order</span> <span class="token keyword">by</span> <span class="token identifier"><span class="token punctuation">`</span>views<span class="token punctuation">`</span></span> <span class="token keyword">desc</span> 
<span class="token keyword">limit</span> <span class="token number">10</span><span class="token punctuation">;</span>
OK
videoid          views
dMH0bHeiRNg     <span class="token number">42513417</span>
<span class="token number">0</span>XxI<span class="token operator">-</span>hvPRRA     <span class="token number">20282464</span>
<span class="token number">1</span>dmVU08zVpA     <span class="token number">16087899</span>
RB<span class="token operator">-</span>wUgnyGv0     <span class="token number">15712924</span>
QjA5faZF1A8     <span class="token number">15256922</span>
<span class="token operator">-</span>_CSo1gOd48     <span class="token number">13199833</span>
<span class="token number">49</span>IDp76kjPw     <span class="token number">11970018</span>
tYnn51C3X_w     <span class="token number">11823701</span>
pv5zWaTEVkI     <span class="token number">11672017</span>
D2kJZOfq7zk     <span class="token number">11184051</span>
</code></pre> 
<h4><a id="1132_Top10_3026"></a>11.3.2 统计视频类别热度Top10（类别热度：类别下的总视频数）</h4> 
<p>1、思路：<br> 1）统计每个类别有多少个视频，显示出包含视频最多的前10个类别。<br> 2）我们需要按照类别group by聚合，然后count组内的videoId个数即可。<br> 3）因为当前表结构为：一个视频对应一个或多个类别。所以如果要group by类别，需要先将类别进行行列转化（展开），然后再进行count即可。<br> 4）最后按照热度排序，显示前10条。<br> 2、代码</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span>
    tmp01<span class="token punctuation">.</span>category_col<span class="token punctuation">,</span>
    <span class="token function">count</span><span class="token punctuation">(</span>tmp01<span class="token punctuation">.</span>videoId<span class="token punctuation">)</span> num
<span class="token keyword">from</span> <span class="token punctuation">(</span>
     <span class="token keyword">select</span>
         videoId<span class="token punctuation">,</span>
         category_col
     <span class="token keyword">from</span> gulivideo_orc
              lateral <span class="token keyword">view</span>
                  explode<span class="token punctuation">(</span>category<span class="token punctuation">)</span> t <span class="token keyword">as</span> category_col
<span class="token punctuation">)</span> tmp01
<span class="token keyword">group</span> <span class="token keyword">by</span> tmp01<span class="token punctuation">.</span>category_col
<span class="token keyword">order</span> <span class="token keyword">by</span> num <span class="token keyword">desc</span>
<span class="token keyword">limit</span> <span class="token number">10</span><span class="token punctuation">;</span>
<span class="token comment">// 结果显示</span>
OK
tmp01<span class="token punctuation">.</span>category_col        num
Music                      <span class="token number">179049</span>
Entertainment             <span class="token number">127674</span>
Comedy                     <span class="token number">87818</span>
Animation                 <span class="token number">73293</span>
Film                       <span class="token number">73293</span>
Sports                     <span class="token number">67329</span>
Gadgets                    <span class="token number">59817</span>
Games                      <span class="token number">59817</span>
Blogs                      <span class="token number">48890</span>
People                     <span class="token number">48890</span>
</code></pre> 
<h4><a id="1133_20Top20_3063"></a>11.3.3 统计出视频观看数最高的20个视频的所属类别以及类别包含Top20视频的个数</h4> 
<p>1、思路<br> 1）先找到观看书最高的20个视频所属条目的所有信息（主要是类目），降序排列<br> 2）先把20条信息中的category分裂出来（列转行），形成新的字段category_name<br> 3）在第二步的结果下，按照炸开的视频类别category_name分组，然后统计组内的个数category_count<br> 2、最终代码</p> 
<pre><code class="prism language-sql"> <span class="token keyword">select</span>
    table02<span class="token punctuation">.</span>categroy_name<span class="token punctuation">,</span>
    <span class="token function">count</span><span class="token punctuation">(</span>table02<span class="token punctuation">.</span>videoId<span class="token punctuation">)</span> num
<span class="token keyword">from</span> <span class="token punctuation">(</span>
     <span class="token keyword">select</span>
         videoId<span class="token punctuation">,</span>
         categroy_name
     <span class="token keyword">from</span> <span class="token punctuation">(</span>
              <span class="token keyword">select</span>
                  videoId<span class="token punctuation">,</span>
                  <span class="token identifier"><span class="token punctuation">`</span>views<span class="token punctuation">`</span></span><span class="token punctuation">,</span>
                  category
              <span class="token keyword">from</span> gulivideo_orc
              <span class="token keyword">order</span> <span class="token keyword">by</span> <span class="token identifier"><span class="token punctuation">`</span>views<span class="token punctuation">`</span></span> <span class="token keyword">desc</span>
              <span class="token keyword">limit</span> <span class="token number">20</span>
          <span class="token punctuation">)</span> table01
              lateral <span class="token keyword">view</span>
                  explode<span class="token punctuation">(</span>category<span class="token punctuation">)</span> tmp <span class="token keyword">as</span> categroy_name
<span class="token punctuation">)</span> table02
<span class="token keyword">group</span> <span class="token keyword">by</span> table02<span class="token punctuation">.</span>categroy_nam<span class="token punctuation">;</span>
<span class="token comment">// 结果显示</span>
OK
table02<span class="token punctuation">.</span>categroy_name   num
 Blogs                     <span class="token number">2</span>
 UNA                        <span class="token number">1</span>
Comedy                     <span class="token number">6</span>
Entertainment             <span class="token number">6</span>
Music                      <span class="token number">5</span>
People                     <span class="token number">2</span>
</code></pre> 
<h4><a id="1134_Top50_3101"></a>11.3.4 统计视频观看数Top50所关联视频的所属类别排序</h4> 
<p>1、思路<br> 1）先找到观看数前50的视频信息（主要是求出关联视频）<br> 2）炸开第一步求出的关联视频array，形成一个新字段new_relatedid<br> 3）用new_relatedid和gulivideo_orc表进行join，求出new_relatedid的类别<br> 4）炸开第三步结果的category，形成新字段category_name<br> 5）按照catedory_name分组，然后求出每个分组的个数category_count<br> 6）对category_count进行排序，利用开窗函数<br> 2、代码</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span> 
    t5<span class="token punctuation">.</span>category_name<span class="token punctuation">,</span>
    t5<span class="token punctuation">.</span>num<span class="token punctuation">,</span>
    rank<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">over</span><span class="token punctuation">(</span><span class="token keyword">order</span> <span class="token keyword">by</span> t5<span class="token punctuation">.</span>num <span class="token keyword">desc</span> <span class="token punctuation">)</span> rk
<span class="token keyword">from</span> <span class="token punctuation">(</span>
     <span class="token keyword">select</span>
         t4<span class="token punctuation">.</span>category_name<span class="token punctuation">,</span>
         <span class="token function">count</span><span class="token punctuation">(</span>t4<span class="token punctuation">.</span>realte_id<span class="token punctuation">)</span> num
     <span class="token keyword">from</span> <span class="token punctuation">(</span>
              <span class="token keyword">select</span>
                  t3<span class="token punctuation">.</span>realte_id<span class="token punctuation">,</span>
                  category_name
              <span class="token keyword">from</span> <span class="token punctuation">(</span>
                       <span class="token keyword">select</span>
                           t2<span class="token punctuation">.</span>realte_id<span class="token punctuation">,</span>
                           g<span class="token punctuation">.</span>category
                       <span class="token keyword">from</span> <span class="token punctuation">(</span>
                                <span class="token keyword">select</span>
                                    realte_id
                                <span class="token keyword">from</span> <span class="token punctuation">(</span>
                                         <span class="token keyword">select</span>
                                             videoId<span class="token punctuation">,</span>
                                             relatedId<span class="token punctuation">,</span>
                                             <span class="token identifier"><span class="token punctuation">`</span>views<span class="token punctuation">`</span></span>
                                         <span class="token keyword">from</span> gulivideo_orc
                                         <span class="token keyword">order</span> <span class="token keyword">by</span> <span class="token identifier"><span class="token punctuation">`</span>views<span class="token punctuation">`</span></span> <span class="token keyword">desc</span>
                                         <span class="token keyword">limit</span> <span class="token number">50</span>
                                     <span class="token punctuation">)</span> t1
                                         lateral <span class="token keyword">view</span>
                                             explode<span class="token punctuation">(</span>t1<span class="token punctuation">.</span>relatedId<span class="token punctuation">)</span> tmp <span class="token keyword">as</span> realte_id
                            <span class="token punctuation">)</span> t2 <span class="token keyword">join</span> gulivideo_orc g <span class="token keyword">on</span> t2<span class="token punctuation">.</span>realte_id <span class="token operator">=</span> g<span class="token punctuation">.</span>videoId
                   <span class="token punctuation">)</span> t3
                       lateral <span class="token keyword">view</span>
                           explode<span class="token punctuation">(</span>t3<span class="token punctuation">.</span>category<span class="token punctuation">)</span> tmp <span class="token keyword">as</span> category_name
          <span class="token punctuation">)</span> t4
     <span class="token keyword">group</span> <span class="token keyword">by</span> t4<span class="token punctuation">.</span>category_name        
<span class="token punctuation">)</span> t5 <span class="token punctuation">;</span>
<span class="token comment">// 结果显示OK</span>
t5<span class="token punctuation">.</span>category_name        t5<span class="token punctuation">.</span>num  rk
Comedy  <span class="token number">237</span>     <span class="token number">1</span>
Entertainment   <span class="token number">216</span>     <span class="token number">2</span>
Music   <span class="token number">195</span>     <span class="token number">3</span>
People  <span class="token number">51</span>      <span class="token number">4</span>
Blogs   <span class="token number">51</span>      <span class="token number">4</span>
Animation       <span class="token number">47</span>      <span class="token number">6</span>
Film    <span class="token number">47</span>      <span class="token number">6</span>
News    <span class="token number">24</span>      <span class="token number">8</span>
Politics        <span class="token number">24</span>      <span class="token number">8</span>
Games   <span class="token number">22</span>      <span class="token number">10</span>
Gadgets <span class="token number">22</span>      <span class="token number">10</span>
Sports  <span class="token number">19</span>      <span class="token number">12</span>
Howto   <span class="token number">14</span>      <span class="token number">13</span>
DIY     <span class="token number">14</span>      <span class="token number">13</span>
UNA     <span class="token number">13</span>      <span class="token number">15</span>
Travel  <span class="token number">12</span>      <span class="token number">16</span>
Places  <span class="token number">12</span>      <span class="token number">16</span>
Animals <span class="token number">11</span>      <span class="token number">18</span>
Pets    <span class="token number">11</span>      <span class="token number">18</span>
Autos   <span class="token number">4</span>       <span class="token number">20</span>
Vehicles        <span class="token number">4</span>       <span class="token number">20</span>
</code></pre> 
<h4><a id="1135Top10Music_3173"></a>11.3.5统计每个类别中的视频热度Top10，以Music为例</h4> 
<p>1、思路<br> 1）要想统计Music类别中的视频热度Top10，需要先找到Music类别，那么就需要将category展开成新的字段categary_name。<br> 2）然后通过category_name过滤“Music”分类的所有视频信息，按照视频观看数倒序排序，取前10<br> 3）统计对应类别(Music)中的视频热度<br> 2、代码</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span>
    videoId<span class="token punctuation">,</span>
    <span class="token identifier"><span class="token punctuation">`</span>views<span class="token punctuation">`</span></span> hot
<span class="token keyword">from</span> <span class="token punctuation">(</span>
     <span class="token keyword">select</span>
         videoId<span class="token punctuation">,</span>
         category_name<span class="token punctuation">,</span>
         <span class="token identifier"><span class="token punctuation">`</span>views<span class="token punctuation">`</span></span>
     <span class="token keyword">from</span> gulivideo_orc
              lateral <span class="token keyword">view</span>
                  explode<span class="token punctuation">(</span>category<span class="token punctuation">)</span> tmp <span class="token keyword">as</span> category_name        
<span class="token punctuation">)</span> t1
<span class="token keyword">where</span> category_name <span class="token operator">=</span> <span class="token string">"Music"</span>
<span class="token keyword">order</span> <span class="token keyword">by</span> hot <span class="token keyword">desc</span> 
<span class="token keyword">limit</span> <span class="token number">10</span><span class="token punctuation">;</span>
<span class="token comment">// 结果显示</span>
OK
videoid          hot
QjA5faZF1A8     <span class="token number">15256922</span>
tYnn51C3X_w     <span class="token number">11823701</span>
pv5zWaTEVkI     <span class="token number">11672017</span>
<span class="token number">8</span>bbTtPL1jRs     <span class="token number">9579911</span>
UMf40daefsI     <span class="token number">7533070</span>
<span class="token operator">-</span>xEzGIuY7kw     <span class="token number">6946033</span>
d6C0bNDqf3Y     <span class="token number">6935578</span>
HSoVKUVOnfQ     <span class="token number">6193057</span>
<span class="token number">3</span>URfWTEPmtE     <span class="token number">5581171</span>
thtmaZnxk_0     <span class="token number">5142238</span>
</code></pre> 
<h4><a id="1136_Top10_3210"></a>11.3.6 统计每个类别视频观看数Top10</h4> 
<p>1、思路<br> 1）把每个原始表的类别炸开，形成新的字段category_name<br> 2）按照炸裂开的类别字段category_name分区，按照视频观看数views倒叙排序进行开窗，求出每个类别下的所有视频的观看次数排序rk<br> 3）按照rk字段对全表进行where过滤，求出每个类别观看书Top10<br> 2、代码</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span>
    t2<span class="token punctuation">.</span>category_name<span class="token punctuation">,</span>
    t2<span class="token punctuation">.</span>views<span class="token punctuation">,</span>
    t2<span class="token punctuation">.</span>rk
<span class="token keyword">from</span> <span class="token punctuation">(</span>
     <span class="token keyword">select</span>
         t1<span class="token punctuation">.</span>category_name<span class="token punctuation">,</span>
         t1<span class="token punctuation">.</span>views<span class="token punctuation">,</span>
         rank<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">over</span><span class="token punctuation">(</span><span class="token keyword">partition</span> <span class="token keyword">by</span> t1<span class="token punctuation">.</span>category_name <span class="token keyword">order</span> <span class="token keyword">by</span> t1<span class="token punctuation">.</span>views <span class="token keyword">desc</span> <span class="token punctuation">)</span> rk
     <span class="token keyword">from</span> <span class="token punctuation">(</span>   
           <span class="token keyword">select</span>
               category_name<span class="token punctuation">,</span>
               <span class="token identifier"><span class="token punctuation">`</span>views<span class="token punctuation">`</span></span>
           <span class="token keyword">from</span> gulivideo_orc
                    lateral <span class="token keyword">view</span>
                        explode<span class="token punctuation">(</span>category<span class="token punctuation">)</span> tmp <span class="token keyword">as</span> category_name
       <span class="token punctuation">)</span> t1
<span class="token punctuation">)</span> t2
<span class="token keyword">where</span> rk <span class="token operator">&lt;=</span> <span class="token number">10</span>；
<span class="token comment">// 结果显示</span>
OK
t2<span class="token punctuation">.</span>category_name        t2<span class="token punctuation">.</span>views        t2<span class="token punctuation">.</span>rk
Comedy  <span class="token number">42513417</span>        <span class="token number">1</span>
Comedy  <span class="token number">20282464</span>        <span class="token number">2</span>
Comedy  <span class="token number">11970018</span>        <span class="token number">3</span>
Comedy  <span class="token number">10107491</span>        <span class="token number">4</span>
Comedy  <span class="token number">9566609</span> <span class="token number">5</span>
Comedy  <span class="token number">7066676</span> <span class="token number">6</span>
Comedy  <span class="token number">6322117</span> <span class="token number">7</span>
Comedy  <span class="token number">5826923</span> <span class="token number">8</span>
Comedy  <span class="token number">5587299</span> <span class="token number">9</span>
Comedy  <span class="token number">5508079</span> <span class="token number">10</span>
News    <span class="token number">4706030</span> <span class="token number">1</span>
News    <span class="token number">2899397</span> <span class="token number">2</span>
News    <span class="token number">2817078</span> <span class="token number">3</span>
News    <span class="token number">2803520</span> <span class="token number">4</span>
News    <span class="token number">2348709</span> <span class="token number">5</span>
News    <span class="token number">2335060</span> <span class="token number">6</span>
News    <span class="token number">2326680</span> <span class="token number">7</span>
News    <span class="token number">2318782</span> <span class="token number">8</span>
News    <span class="token number">2310583</span> <span class="token number">9</span>
News    <span class="token number">2291369</span> <span class="token number">10</span>
……
<span class="token keyword">Time</span> taken: <span class="token number">11.376</span> seconds<span class="token punctuation">,</span> Fetched: <span class="token number">210</span> <span class="token keyword">row</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span>
</code></pre> 
<h4><a id="1137_Top1020_3263"></a>11.3.7 统计上传视频最多的用户Top10以及它们上传的视频观看次数在前20的视频</h4> 
<p>有三种理解<br> 理解一：取Top10中所有人上传的视频的观看次数前20<br> 1、思路<br> 1）去用户表gulivideo_user_orc求出上传视频最多的十个用户<br> 2）关联gulivideo_orc表，求出这10个用户上传的所有的视频，按照观看数取前20<br> 2、代码</p> 
<pre><code class="prism language-sql"><span class="token keyword">SELECT</span>
    t1<span class="token punctuation">.</span>uploader<span class="token punctuation">,</span>
    t2<span class="token punctuation">.</span>videoid<span class="token punctuation">,</span>
    t2<span class="token punctuation">.</span>views
<span class="token keyword">FROM</span>
    <span class="token punctuation">(</span>
        <span class="token keyword">select</span>
            uploader<span class="token punctuation">,</span>
            videos
        <span class="token keyword">from</span> gulivideo_user_orc
        <span class="token keyword">order</span> <span class="token keyword">by</span> videos <span class="token keyword">DESC</span>
        <span class="token keyword">limit</span> <span class="token number">10</span>
    <span class="token punctuation">)</span> t1
        <span class="token keyword">JOIN</span>
    gulivideo_orc t2
    <span class="token keyword">on</span> t1<span class="token punctuation">.</span>uploader <span class="token operator">=</span> t2<span class="token punctuation">.</span>uploader
<span class="token keyword">ORDER</span> <span class="token keyword">BY</span> t2<span class="token punctuation">.</span>views <span class="token keyword">DESC</span>
<span class="token keyword">LIMIT</span> <span class="token number">20</span><span class="token punctuation">;</span>
<span class="token comment">// 结果显示</span>
OK
t1<span class="token punctuation">.</span>uploader     t2<span class="token punctuation">.</span>videoid      t2<span class="token punctuation">.</span>views
expertvillage   <span class="token operator">-</span>IxHBW0YpZw     <span class="token number">39059</span>
expertvillage   BU<span class="token operator">-</span>fT5XI_8I     <span class="token number">29975</span>
expertvillage   ADOcaBYbMl0     <span class="token number">26270</span>
expertvillage   yAqsULIDJFE     <span class="token number">25511</span>
expertvillage   vcm<span class="token operator">-</span>t0TJXNg     <span class="token number">25366</span>
expertvillage   <span class="token number">0</span>KYGFawp14c     <span class="token number">24659</span>
expertvillage   j4DpuPvMLF4     <span class="token number">22593</span>
expertvillage   Msu4lZb2oeQ     <span class="token number">18822</span>
expertvillage   ZHZVj44rpjE     <span class="token number">16304</span>
expertvillage   foATQY3wovI     <span class="token number">13576</span>
expertvillage   <span class="token operator">-</span>UnQ8rcBOQs     <span class="token number">13450</span>
expertvillage   crtNd46CDks     <span class="token number">11639</span>
expertvillage   D1leA0JKHhE     <span class="token number">11553</span>
expertvillage   NJu2oG1Wm98     <span class="token number">11452</span>
expertvillage   CapbXdyv4j4     <span class="token number">10915</span>
expertvillage   epr5erraEp4     <span class="token number">10817</span>
expertvillage   IyQoDgaLM7U     <span class="token number">10597</span>
expertvillage   tbZibBnusLQ     <span class="token number">10402</span>
expertvillage   _GnCHodc7mk     <span class="token number">9422</span>
expertvillage   hvEYlSlRitU     <span class="token number">7123</span>
<span class="token keyword">Time</span> taken: <span class="token number">57.272</span> seconds<span class="token punctuation">,</span> Fetched: <span class="token number">20</span> <span class="token keyword">row</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span>

</code></pre> 
<p>理解二：取Top10中每个人上传的视频的观看次数前20<br> 1、思路<br> 1）去用户表gulivideo_user_orc求出上传视频最多的10个用户<br> 2）关联gulivideo_orc表，求出这10个用户上传的所有视频id，视频观看次数，还要按照uploader分区，views倒叙排序，求出每个uploder的上传的视频的观看排名<br> 3）按照rk进行where过滤，求出rk&lt;=20的数据<br> 2、代码</p> 
<pre><code class="prism language-sql"><span class="token keyword">select</span>
    t3<span class="token punctuation">.</span>uploader<span class="token punctuation">,</span>
    t3<span class="token punctuation">.</span>videoId<span class="token punctuation">,</span>
    t3<span class="token punctuation">.</span>views<span class="token punctuation">,</span>
    t3<span class="token punctuation">.</span>rk
<span class="token keyword">from</span> <span class="token punctuation">(</span>
     <span class="token keyword">select</span>
         t2<span class="token punctuation">.</span>uploader<span class="token punctuation">,</span>
         t2<span class="token punctuation">.</span>videoId<span class="token punctuation">,</span>
         t2<span class="token punctuation">.</span>views<span class="token punctuation">,</span>
         rank<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">over</span><span class="token punctuation">(</span><span class="token keyword">partition</span> <span class="token keyword">by</span> uploader <span class="token keyword">order</span> <span class="token keyword">by</span> t2<span class="token punctuation">.</span>views <span class="token keyword">desc</span> <span class="token punctuation">)</span> rk
     <span class="token keyword">from</span> <span class="token punctuation">(</span>
              <span class="token keyword">select</span>
                  t1<span class="token punctuation">.</span>uploader<span class="token punctuation">,</span>
                  g<span class="token punctuation">.</span>videoId<span class="token punctuation">,</span>
                  g<span class="token punctuation">.</span><span class="token identifier"><span class="token punctuation">`</span>views<span class="token punctuation">`</span></span>
              <span class="token keyword">from</span> <span class="token punctuation">(</span>
                       <span class="token keyword">select</span>
                           uploader
                       <span class="token keyword">from</span> gulivideo_user_orc
                       <span class="token keyword">order</span> <span class="token keyword">by</span> videos <span class="token keyword">desc</span>
                       <span class="token keyword">limit</span> <span class="token number">10</span>
                   <span class="token punctuation">)</span> t1 <span class="token keyword">join</span> gulivideo_orc g <span class="token keyword">on</span> t1<span class="token punctuation">.</span>uploader <span class="token operator">=</span> g<span class="token punctuation">.</span>uploader
          <span class="token punctuation">)</span> t2    
<span class="token punctuation">)</span> t3
<span class="token keyword">where</span> rk <span class="token operator">&lt;=</span><span class="token number">20</span><span class="token punctuation">;</span>
<span class="token comment">// 结果显示</span>
OK
t3<span class="token punctuation">.</span>uploader     t3<span class="token punctuation">.</span>videoid      t3<span class="token punctuation">.</span>views        t3<span class="token punctuation">.</span>rk
expertvillage   <span class="token operator">-</span>IxHBW0YpZw     <span class="token number">39059</span>   <span class="token number">1</span>
expertvillage   BU<span class="token operator">-</span>fT5XI_8I     <span class="token number">29975</span>   <span class="token number">2</span>
expertvillage   ADOcaBYbMl0     <span class="token number">26270</span>   <span class="token number">3</span>
expertvillage   yAqsULIDJFE     <span class="token number">25511</span>   <span class="token number">4</span>
expertvillage   vcm<span class="token operator">-</span>t0TJXNg     <span class="token number">25366</span>   <span class="token number">5</span>
expertvillage   <span class="token number">0</span>KYGFawp14c     <span class="token number">24659</span>   <span class="token number">6</span>
expertvillage   j4DpuPvMLF4     <span class="token number">22593</span>   <span class="token number">7</span>
expertvillage   Msu4lZb2oeQ     <span class="token number">18822</span>   <span class="token number">8</span>
expertvillage   ZHZVj44rpjE     <span class="token number">16304</span>   <span class="token number">9</span>
expertvillage   foATQY3wovI     <span class="token number">13576</span>   <span class="token number">10</span>
expertvillage   <span class="token operator">-</span>UnQ8rcBOQs     <span class="token number">13450</span>   <span class="token number">11</span>
expertvillage   crtNd46CDks     <span class="token number">11639</span>   <span class="token number">12</span>
expertvillage   D1leA0JKHhE     <span class="token number">11553</span>   <span class="token number">13</span>
expertvillage   NJu2oG1Wm98     <span class="token number">11452</span>   <span class="token number">14</span>
expertvillage   CapbXdyv4j4     <span class="token number">10915</span>   <span class="token number">15</span>
expertvillage   epr5erraEp4     <span class="token number">10817</span>   <span class="token number">16</span>
expertvillage   IyQoDgaLM7U     <span class="token number">10597</span>   <span class="token number">17</span>
expertvillage   tbZibBnusLQ     <span class="token number">10402</span>   <span class="token number">18</span>
expertvillage   _GnCHodc7mk     <span class="token number">9422</span>    <span class="token number">19</span>
expertvillage   hvEYlSlRitU     <span class="token number">7123</span>    <span class="token number">20</span>
Ruchaneewan     <span class="token number">5</span>_T5Inddsuo     <span class="token number">3132</span>    <span class="token number">1</span>
Ruchaneewan     wje4lUtbYNU     <span class="token number">1086</span>    <span class="token number">2</span>
Ruchaneewan     i8rLbOUhAlM     <span class="token number">549</span>     <span class="token number">3</span>
Ruchaneewan     OwnEtde9_Co     <span class="token number">453</span>     <span class="token number">4</span>
Ruchaneewan     <span class="token number">5</span>Zf0lbAdJP0     <span class="token number">441</span>     <span class="token number">5</span>
Ruchaneewan     wenI5MrYT20     <span class="token number">426</span>     <span class="token number">6</span>
Ruchaneewan     Iq4e3SopjxQ     <span class="token number">420</span>     <span class="token number">7</span>
Ruchaneewan     <span class="token number">3</span>hzOiFP<span class="token operator">-</span><span class="token number">5</span>so     <span class="token number">420</span>     <span class="token number">7</span>
Ruchaneewan     JgyOlXjjuw0     <span class="token number">418</span>     <span class="token number">9</span>
Ruchaneewan     fGBVShTsuyo     <span class="token number">395</span>     <span class="token number">10</span>
Ruchaneewan     O3aoL70DlVc     <span class="token number">389</span>     <span class="token number">11</span>
Ruchaneewan     q4y2ZS5OQ88     <span class="token number">344</span>     <span class="token number">12</span>
Ruchaneewan     lyUJB2eMVVg     <span class="token number">271</span>     <span class="token number">13</span>
Ruchaneewan     _RF_3VhaQpw     <span class="token number">242</span>     <span class="token number">14</span>
Ruchaneewan     DDl2cjI<span class="token operator">-</span>aJs     <span class="token number">231</span>     <span class="token number">15</span>
Ruchaneewan     xbYyjUdhtJw     <span class="token number">227</span>     <span class="token number">16</span>
Ruchaneewan     <span class="token number">4</span>dkKeIUkN7E     <span class="token number">226</span>     <span class="token number">17</span>
Ruchaneewan     qCfuQA6N4K0     <span class="token number">213</span>     <span class="token number">18</span>
Ruchaneewan     TmYbGQaRcNM     <span class="token number">209</span>     <span class="token number">19</span>
Ruchaneewan     dOlfPsFSjw0     <span class="token number">206</span>     <span class="token number">20</span>
<span class="token keyword">Time</span> taken: <span class="token number">30.772</span> seconds<span class="token punctuation">,</span> Fetched: <span class="token number">40</span> <span class="token keyword">row</span><span class="token punctuation">(</span>s
</code></pre> 
<p>理解三：Top10用户上传的所有视频，有哪些视频是在视频观看次数前20的视频<br> 1、思路<br> 1）去用户表gulivideo_user_orc求出上传视频最多的10个用户<br> 2）关联gulivideo_orc表，求出这10个用户上传的所有的视频id，视频观看次数<br> 3）在第二步的结果上，与视频表观看次数前20的数据进行内连接，求出Top10用户上传的视频有哪些是观看次数前20的视频<br> 2、代码</p> 
<pre><code class="prism language-sql"><span class="token keyword">SELECT</span>
    t3<span class="token punctuation">.</span>uploader<span class="token punctuation">,</span>
    t3<span class="token punctuation">.</span>videoid<span class="token punctuation">,</span>
    t3<span class="token punctuation">.</span>views
<span class="token keyword">FROM</span>
    <span class="token punctuation">(</span>
        <span class="token keyword">SELECT</span>
            t1<span class="token punctuation">.</span>uploader<span class="token punctuation">,</span>
            t2<span class="token punctuation">.</span>videoid<span class="token punctuation">,</span>
            t2<span class="token punctuation">.</span>views
        <span class="token keyword">FROM</span>
            <span class="token punctuation">(</span>
                <span class="token keyword">select</span>
                    uploader<span class="token punctuation">,</span>
                    videos
                <span class="token keyword">from</span> gulivideo_user_orc
                <span class="token keyword">order</span> <span class="token keyword">by</span> videos <span class="token keyword">DESC</span>
                <span class="token keyword">limit</span> <span class="token number">10</span>
            <span class="token punctuation">)</span> t1
                <span class="token keyword">JOIN</span>
            gulivideo_orc t2
            <span class="token keyword">on</span> t1<span class="token punctuation">.</span>uploader <span class="token operator">=</span> t2<span class="token punctuation">.</span>uploader
    <span class="token punctuation">)</span> t3
        <span class="token keyword">JOIN</span>
    <span class="token punctuation">(</span>
        <span class="token keyword">select</span>
            videoid<span class="token punctuation">,</span>
            <span class="token identifier"><span class="token punctuation">`</span>views<span class="token punctuation">`</span></span>
        <span class="token keyword">from</span> gulivideo_orc
        <span class="token keyword">order</span> <span class="token keyword">by</span> <span class="token identifier"><span class="token punctuation">`</span>views<span class="token punctuation">`</span></span> <span class="token keyword">desc</span>
        <span class="token keyword">limit</span> <span class="token number">20</span>
    <span class="token punctuation">)</span> t4
<span class="token keyword">on</span> t3<span class="token punctuation">.</span>videoid <span class="token operator">=</span> t4<span class="token punctuation">.</span>videoid<span class="token punctuation">;</span>
</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/91585e47baa2bd44b175db938fb049a9/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Java&#43;Springboot&#43;Mysql个性化电影推荐系统 movielens电影数据集 基于深度学习/机器学习/人工智能 基于协同过滤推荐算法 爬虫 可视化数据分析</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/cc074de6b46492664f90c0bd5c27ec63/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">苹果(IOS)开发证书/发布证书申请</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>