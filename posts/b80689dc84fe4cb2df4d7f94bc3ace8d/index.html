<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>本地部署 Llama 3.1：Ollama、OpenWeb UI 和 Spring AI 的综合指南 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/b80689dc84fe4cb2df4d7f94bc3ace8d/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="本地部署 Llama 3.1：Ollama、OpenWeb UI 和 Spring AI 的综合指南">
  <meta property="og:description" content="、
本文介绍如何使用 Ollama 在本地部署 Llama 3.1:8B 模型，并通过 OpenWeb UI 和 Spring AI 来增强模型交互体验和简化 API 的调用过程。
Ollama Ollama 是一个开源的大语言模型服务工具，旨在简化大模型的本地部署和运行过程。用户只需要输入一行命令（如： ollama run llama3.1 ），即可在本地硬件环境中部署和使用大语言模型。Ollama 还提供了 REST API 接口，下文中会介绍如何使用 Spring AI 集成 Ollama，实现与大模型 API 接口的交互。
Ollama 支持下载 Llama、Gemma、qwen 和 glm4 等多种主流大语言模型和代码语言模型，我们可以在 官网 查看 Ollama 支持的所有模型及其相关信息和使用命令。 本机运行 7B 参数量的模型至少需要 8GB 内存，运行 13B 参数量的模型至少需要 16GB 内存，运行 33B 参数量的模型至少需要 32GB 内存。
模型参数大小使用命令Llama 3.18B4.7GBollama run llama3.1Llama 3.170B40GBollama run llama3.1:70bLlama 3.1405B231GBollama run llama3.1:405bGemma 29B5.5GBollama run gemma2Gemma 227B16GBollama run gemma2:27bqwen27B4.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-07-30T11:07:54+08:00">
    <meta property="article:modified_time" content="2024-07-30T11:07:54+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">本地部署 Llama 3.1：Ollama、OpenWeb UI 和 Spring AI 的综合指南</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>、</p> 
<blockquote> 
 <p>本文介绍如何使用 Ollama 在本地部署 Llama 3.1:8B 模型，并通过 OpenWeb UI 和 Spring AI 来增强模型交互体验和简化 API 的调用过程。</p> 
</blockquote> 
<p><img src="https://images2.imgbox.com/c2/3e/HnucsvPF_o.png" alt="外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传"></p> 
<h2><a id="Ollama_6"></a>Ollama</h2> 
<p>Ollama 是一个开源的大语言模型服务工具，旨在简化大模型的本地部署和运行过程。用户只需要输入一行命令（如： <code>ollama run llama3.1</code> ），即可在本地硬件环境中部署和使用大语言模型。Ollama 还提供了 REST API 接口，下文中会介绍如何使用 Spring AI 集成 Ollama，实现与大模型 API 接口的交互。</p> 
<p>Ollama 支持下载 Llama、Gemma、qwen 和 glm4 等多种主流大语言模型和代码语言模型，我们可以在 <a href="https://link.juejin.cn/?target=https%3A%2F%2Follama.com%2Flibrary" rel="nofollow" title="https://ollama.com/library">官网</a> 查看 Ollama 支持的所有模型及其相关信息和使用命令。 <strong>本机运行 7B 参数量的模型至少需要 8GB 内存，运行 13B 参数量的模型至少需要 16GB 内存，运行 33B 参数量的模型至少需要 32GB 内存。</strong></p> 
<table><thead><tr><th>模型</th><th>参数</th><th>大小</th><th>使用命令</th></tr></thead><tbody><tr><td>Llama 3.1</td><td>8B</td><td>4.7GB</td><td><code>ollama run llama3.1</code></td></tr><tr><td>Llama 3.1</td><td>70B</td><td>40GB</td><td><code>ollama run llama3.1:70b</code></td></tr><tr><td>Llama 3.1</td><td>405B</td><td>231GB</td><td><code>ollama run llama3.1:405b</code></td></tr><tr><td>Gemma 2</td><td>9B</td><td>5.5GB</td><td><code>ollama run gemma2</code></td></tr><tr><td>Gemma 2</td><td>27B</td><td>16GB</td><td><code>ollama run gemma2:27b</code></td></tr><tr><td>qwen2</td><td>7B</td><td>4.4GB</td><td><code>ollama run qwen2</code></td></tr><tr><td>qwen2</td><td>72B</td><td>41GB</td><td><code>ollama run qwen2:72b</code></td></tr><tr><td>glm4</td><td>9B</td><td>5.5GB</td><td><code>ollama run glm4</code></td></tr></tbody></table> 
<h3><a id="_24"></a>下载</h3> 
<p>访问 <a href="https://link.juejin.cn/?target=https%3A%2F%2Follama.com%2Fdownload" rel="nofollow" title="https://ollama.com/download">Ollama 官网</a>，选择操作系统，然后点击 download 按钮进行下载。<strong>操作系统要求 MacOS 11 和 Windows 10 及以上版本</strong>。下载完成后的 Ollama 其实是一个命令行工具，我们可以直接在终端中使用 Ollama。（执行 <code>ollama --help</code> 可查看 Ollama 提供的的命令）</p> 
<p><img src="https://images2.imgbox.com/5f/83/QDNLDKVw_o.png" alt="外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传"></p> 
<h3><a id="_Llama_31_31"></a>部署 Llama 3.1</h3> 
<p>在终端中执行命令 <code>ollama run llama3.1</code> ，即可下载 Llama3.1:8B 模型。模型下载完成后，会自动启动大模型，进入命令行交互模式，直接输入指令，就可以和模型进行对话了。</p> 
<p><img src="https://images2.imgbox.com/9e/cd/1xY2qwmp_o.png" alt="外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传"></p> 
<p>通过 Ollama，我们轻松的实现了本地大模型的部署和命令行式的交互，但是为了更好的使用大模型，以及对大模型进行管理和配置等方面的需求，就需要借助 Ollama 社区中一些强大的工具了，其中代表性的工具之一是 OpenWeb UI（之前称为 Ollama WebUI）。</p> 
<h2><a id="OpenWeb_UI_40"></a>OpenWeb UI</h2> 
<p>OpenWeb UI 是一个功能丰富且易于使用的大模型管理工具，它为用户提供了一个直观的图形化界面，以及广泛的功能和灵活的配置选项。</p> 
<ul><li>方便部署：使用 Docker 实现简单快捷的部署。</li><li>用户友好的页面：国际化多语言支持，提供多种主题样式，响应式设计，模型参数、Prompt 等便捷配置。</li><li>功能丰富：本地 RAG 支持，Web 浏览功能（可以在对话中访问网站），语音交互等。</li><li>API 支持：支持 OpenAI API 和其他兼容 API。</li><li>多模型支持：支持同时管理和操作多个大语言模型。</li></ul> 
<h3><a id="_51"></a>下载</h3> 
<p>部署 OpenWeb UI 需要使用 Docker 环境，我本机的 Docker 版本是 24.0.2。OpenWeb UI 提供了集成 Ollama 的部署方式， 因为 Ollama 已经下载到我本机上了，所以只需要执行以下命令即可完成部署。</p> 
<pre><code>docker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main

</code></pre> 
<p>容器启动成功后，可以访问 3000 端口，查看页面。首次登陆需要先填写邮箱和密码注册账号。登陆进来后，可以看到，OpenWeb UI 已经自动加载到了我们本地部署的 Llama3.1 模型。</p> 
<p><img src="https://images2.imgbox.com/4b/69/RlcvCu0A_o.png" alt="外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传"></p> 
<p>在模型编辑页面，我们可以修改模型的配置参数和 Prompt 等信息，并利用 Document 和 Tools 等工具来增强模型的能力和使用体验。</p> 
<p><img src="https://images2.imgbox.com/93/2e/oezayeuL_o.png" alt="外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传"></p> 
<h2><a id="Spring_AI_69"></a>Spring AI</h2> 
<p>Spring AI 是 Spring 生态里人工智能方向的应用框架，它提供了与各种大语言模型交互的高级抽象接口，极大地简化了Java 人工智能应用程序的开发过程，让 Java 开发者也能够开发 AI 应用。</p> 
<p>接下来将详细介绍 Spring AI 的使用流程，以及如何调用 Ollama 的 API 接口，与我们本地的 Llama 3.1 进行交互。</p> 
<h3><a id="_Ollama_76"></a>集成 Ollama</h3> 
<ol><li>创建一个新的 Spring Boot 项目，版本要求 Spring Boot 3 + JDK 17。</li><li>引入 Spring AI + Ollama 依赖。</li></ol> 
<pre><code>&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd"&gt;
    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;
    &lt;parent&gt;
        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;
        &lt;version&gt;3.3.1&lt;/version&gt;
        &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;
    &lt;/parent&gt;
    &lt;groupId&gt;com.cleaner&lt;/groupId&gt;
    &lt;artifactId&gt;culture-ai&lt;/artifactId&gt;
    &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;
    &lt;name&gt;Cleaner-ai&lt;/name&gt;
    &lt;description&gt;culture-ai&lt;/description&gt;
    &lt;properties&gt;
        &lt;java.version&gt;17&lt;/java.version&gt;
        &lt;spring-ai.version&gt;1.0.0-SNAPSHOT&lt;/spring-ai.version&gt;
    &lt;/properties&gt;
    &lt;dependencies&gt;
        &lt;!-- ollama --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.ai&lt;/groupId&gt;
            &lt;artifactId&gt;spring-ai-ollama-spring-boot-starter&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
        &lt;/dependency&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;
            &lt;scope&gt;test&lt;/scope&gt;
        &lt;/dependency&gt;
    &lt;/dependencies&gt;
    &lt;dependencyManagement&gt;
        &lt;dependencies&gt;
        &lt;!-- spring ai --&gt;
            &lt;dependency&gt;
                &lt;groupId&gt;org.springframework.ai&lt;/groupId&gt;
                &lt;artifactId&gt;spring-ai-bom&lt;/artifactId&gt;
                &lt;version&gt;${spring-ai.version}&lt;/version&gt;
                &lt;type&gt;pom&lt;/type&gt;
                &lt;scope&gt;import&lt;/scope&gt;
            &lt;/dependency&gt;
        &lt;/dependencies&gt;
    &lt;/dependencyManagement&gt;

    &lt;build&gt;
        &lt;plugins&gt;
            &lt;plugin&gt;
                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;
            &lt;/plugin&gt;
        &lt;/plugins&gt;
    &lt;/build&gt;
    &lt;repositories&gt;
        &lt;!-- spring ai --&gt;
        &lt;repository&gt;
            &lt;id&gt;spring-milestones&lt;/id&gt;
            &lt;name&gt;Spring Milestones&lt;/name&gt;
            &lt;url&gt;https://repo.spring.io/milestone&lt;/url&gt;
            &lt;snapshots&gt;
                &lt;enabled&gt;false&lt;/enabled&gt;
            &lt;/snapshots&gt;
        &lt;/repository&gt;
        &lt;repository&gt;
            &lt;id&gt;spring-snapshots&lt;/id&gt;
            &lt;name&gt;Spring Snapshots&lt;/name&gt;
            &lt;url&gt;https://repo.spring.io/snapshot&lt;/url&gt;
            &lt;releases&gt;
                &lt;enabled&gt;false&lt;/enabled&gt;
            &lt;/releases&gt;
        &lt;/repository&gt;
    &lt;/repositories&gt;

&lt;/project&gt;

</code></pre> 
<ol start="3"><li>编写 application.yaml 配置文件，添加 Ollama 的相关配置。</li></ol> 
<pre><code>server:
  port: 8888
spring:
  application:
    name: Cleaner-AI
  ai:
    ollama:
      # ollama API Server 地址
      base-url: http://localhost:11434
      chat:
        enabled: true
        # 使用的模型名称
        model:
          llama3.1:8b
        options:
          temperature: 0.7

</code></pre> 
<ol start="4"><li>编写接口。</li></ol> 
<pre><code>package com.cleaner.ai.controller;

import jakarta.annotation.Resource;
import org.springframework.ai.chat.messages.UserMessage;
import org.springframework.ai.chat.model.ChatResponse;
import org.springframework.ai.chat.prompt.Prompt;
import org.springframework.ai.ollama.OllamaChatModel;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RequestParam;
import org.springframework.web.bind.annotation.RestController;
import reactor.core.publisher.Flux;

@RestController
@RequestMapping("/ollama")
public class OllamaController {


    @Resource
    private OllamaChatModel ollamaChatModel;


    /**
     * 流式对话
     *
     * @param message 用户指令
     * @return
     */
    @GetMapping("/streamChat")
    public Flux&lt;ChatResponse&gt; generateStream(@RequestParam("message") String message) {
        message = "请使用中文简体回答：" + message;
        Prompt prompt = new Prompt(new UserMessage(message));
        return ollamaChatModel.stream(prompt);
    }

    /**
     * 普通对话
     * @param message   用户指令
     * @return
     */
    @GetMapping("/chat")
    public String generate(@RequestParam("message") String message) {
        message = "请使用中文简体回答：" + message;
        Prompt prompt = new Prompt(new UserMessage(message));
        ChatResponse chatResponse = ollamaChatModel.call(prompt);
        String content = chatResponse.getResult().getOutput().getContent();
        System.out.println("content = " + content);
        return chatResponse.toString();
    }
}

</code></pre> 
<ol start="5"><li>调用接口，可以看到 API 接口调用成功。（8B 模型生成的回答内容还是比较有限）</li></ol> 
<p><img src="https://images2.imgbox.com/00/bf/mxvL2kSc_o.png" alt="外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传"></p> 
<h2><a id="_245"></a>总结</h2> 
<p>本地部署的大模型可以脱离网络离线使用，但是要达到实际使用的要求，还需要对模型进行细致化的配置，当然部署模型的参数量越大，使用效果会更好，但也要考虑本机电脑的配置限制。对于学习了解大模型及其相关的技术知识而言，在条件允许的情况下，本机部署确实是一个不错的选择。</p> 
<h3><a id="AI_250"></a>如何学习AI大模型？</h3> 
<p>我在一线互联网企业工作十余年里，指导过不少同行后辈。帮助很多人得到了学习和成长。</p> 
<p>我意识到有很多经验和知识值得分享给大家，也可以通过我们的能力和经验解答大家在人工智能学习中的很多困惑，所以在工作繁忙的情况下还是坚持各种整理和分享。但苦于知识传播途径有限，很多互联网行业朋友无法获得正确的资料得到学习提升，故此将并将重要的AI大模型资料包括AI大模型入门学习思维导图、精品AI大模型学习书籍手册、视频教程、实战学习等录播视频免费分享出来。</p> 
<p><img src="https://images2.imgbox.com/ee/dd/Qm5kYBnI_o.png" alt="在这里插入图片描述"></p> 
<p>第一阶段： 从大模型系统设计入手，讲解大模型的主要方法；</p> 
<p>第二阶段： 在通过大模型提示词工程从Prompts角度入手更好发挥模型的作用；</p> 
<p>第三阶段： 大模型平台应用开发借助阿里云PAI平台构建电商领域虚拟试衣系统；</p> 
<p>第四阶段： 大模型知识库应用开发以LangChain框架为例，构建物流行业咨询智能问答系统；</p> 
<p>第五阶段： 大模型微调开发借助以大健康、新零售、新媒体领域构建适合当前领域大模型；</p> 
<p>第六阶段： 以SD多模态大模型为主，搭建了文生图小程序案例；</p> 
<p>第七阶段： 以大模型平台应用与开发为主，通过星火大模型，文心大模型等成熟大模型构建大模型行业应用。</p> 
<p><img src="https://images2.imgbox.com/ed/05/fMI9YXng_o.jpg" alt="在这里插入图片描述"></p> 
<p>👉学会后的收获：👈<br> • 基于大模型全栈工程实现（前端、后端、产品经理、设计、数据分析等），通过这门课可获得不同能力；</p> 
<p>• 能够利用大模型解决相关实际项目需求： 大数据时代，越来越多的企业和机构需要处理海量数据，利用大模型技术可以更好地处理这些数据，提高数据分析和决策的准确性。因此，掌握大模型应用开发技能，可以让程序员更好地应对实际项目需求；</p> 
<p>• 基于大模型和企业数据AI应用开发，实现大模型理论、掌握GPU算力、硬件、LangChain开发框架和项目实战技能， 学会Fine-tuning垂直训练大模型（数据准备、数据蒸馏、大模型部署）一站式掌握；</p> 
<p>• 能够完成时下热门大模型垂直领域模型训练能力，提高程序员的编码能力： 大模型应用开发需要掌握机器学习算法、深度学习框架等技术，这些技术的掌握可以提高程序员的编码能力和分析能力，让程序员更加熟练地编写高质量的代码。</p> 
<p><img src="https://images2.imgbox.com/fd/40/BpImhi2t_o.jpg" alt="在这里插入图片描述"></p> 
<blockquote> 
 <p><em><strong>1.AI大模型学习路线图<br> 2.100套AI大模型商业化落地方案<br> 3.100集大模型视频教程<br> 4.200本大模型PDF书籍<br> 5.LLM面试题合集<br> 6.AI产品经理资源合集</strong></em></p> 
</blockquote> 
<p>👉获取方式：<br> 😝有需要的小伙伴，可以保存图片到wx扫描二v码免费领取【保证100%免费】🆓</p> 
<p><img src="https://images2.imgbox.com/1e/77/L24LeHG0_o.jpg" alt="在这里插入图片描述"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/9b580837c71f6c53db90a49de21b2352/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">我出一道面试题，看看你能拿 3k 还是 30k！</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/d95bbb4262a9799847b1eec299baac19/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">ExcelJS：轻松实现Excel文件的读取、操作与写入</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>