<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>何恺明新作再战AI生成：入职MIT后首次带队，奥赛双料金牌得主邓明扬参与 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/404d94cfe7237d9e2a7440b4904bccde/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="何恺明新作再战AI生成：入职MIT后首次带队，奥赛双料金牌得主邓明扬参与">
  <meta property="og:description" content="梦晨 发自 凹非寺
量子位 | 公众号 QbitAI 何恺明入职MIT副教授后，首次带队的新作来了！
让自回归模型抛弃矢量量化，使用连续值生成图像。并借鉴扩散模型的思想，提出Diffusion Loss。
他加入MIT后，此前也参与过另外几篇CV方向的论文，不过都是和MIT教授Wojciech Matusik团队等合作的。
这次何恺明自己带队，参与者中还出现一个熟悉的名字：
邓明扬，IMO、IOI双料奥赛金牌得主，在竞赛圈人称“乖神”。
目前邓明扬MIT本科在读，按入学时间推算现在刚好大四，所以也有不少网友猜测他如果继续在MIT读博可能会加入何恺明团队。
接下来具体介绍一下，这篇论文研究了什么。
借鉴扩散模型，大改自回归生成 传统观点认为，图像生成的自回归模型通常伴随着矢量量化（Vector Quantization），比如DALL·E一代就使用了经典的VQ-VAE方法。
但团队观察到，自回归生成的本质是根据先前的值预测下一个token，这其实与值是离散还是连续没啥必然联系啊。
关键是要对token的概率分布进行建模，只要该概率分布可以通过损失函数来测量并用于从中抽取样本就行。
并且从另一个方面来看，矢量量化方法还会带来一系列麻烦：
需要一个离散的token词表，需要精心设计量化的目标函数，训练困难，对梯度近似策略很敏感
量化误差会带来信息损失，导致还原图像质量打折
离散token适合建模分类分布，有表达能力上的局限
那么有什么更好的替代方法？
何恺明团队选择在损失函数上动刀，借鉴近年大火的扩散模型的思想，提出Diffusion Loss，消除了离散tokenizer的必要性。
如此一来，在连续值空间中应用自回归模型生成图像就可行了。
具体来说，它让自回归模型输出一个潜变量z作为条件，去训练一个小型的去噪MLP网络。
通过反向扩散过程，这个小网络就学会了如何根据z去采样生成连续值的token x。扩散的过程天然能建模任意复杂的分布，所以没有类别分布的局限。
这个去噪网络和自回归模型是端到端联合训练的，链式法则直接把损失传给自回归模型，使其学会输出最佳的条件z。
这篇工作的另一个亮点，是各种自回归模型的变体都适用。它统一了标准的自回归AR、随机顺序的AR、以及何恺明擅长的掩码方法。
其中掩码自回归（MAR）模型，可以在任意随机位置同时预测多个token，同时还能和扩散损失完美配合。
在这个统一的框架下，所有变体要么逐个token预测，要么并行预测一批token，但本质上都是在已知token的基础上去预测未知token，都是广义的自回归模型，所以扩散损失都能适用。
通过消除矢量量化，团队训练的图像生成模型获得了强大的结果，同时享受序列建模的速度优势。
论文在AR、MAR的各种变体上做了大量实验，结果表明扩散损失比交叉熵损失稳定带来2-3倍的提升。
与其他领先模型一比也毫不逊色，小模型都能做到1.98的FID分数，大模型更是创下了1.55的SOTA。
而且它生成256x256图像速度也很快，不到0.3秒一张。这得益于自回归生成本来就很快，比扩散模型少采样很多步，再加上去噪网络又很小。
最后总结一下，这项工作通过自回归建模token间的相关性，再搭配扩散过程对每个token的分布进行建模。
这也有别于普通的潜空间扩散模型中用单个大扩散模型对所有token的联合分布建模，而是做局部扩散，在效果、速度和灵活性上都展现出了巨大的潜力。
当然，这个方法还有进一步探索的空间，团队提出，目前在在某些复杂的几何图形理解任务上还有待提高。
何恺明团队都有谁 最后再来介绍一下即将或可能加入何恺明课题组的团队成员。。
Tianhong LI（黎天鸿），清华姚班校友，MIT博士生在读，将于2024年9月加入何恺明的课题组，担任博士后。
Mingyang Deng（邓明扬），MIT本科数学和计算机科学专业在读。
他在高一获得IMO金牌，高三获得IOI金牌，是竞赛圈为数不多的双料金牌得主，也是IOI历史上第三位满分选手。
目前邓明扬的研究重点是机器学习，特别是理解和推进生成式基础模型，包括扩散模型和大型语言模型。
不过他的个人主页上还没有透露下一步计划。
One More Thing 何恺明当初在MIT的求职演讲备受关注，其中提到未来工作方向会是AI for Science，还引起圈内一阵热议。
现在，何恺明在AI4S方向的参与的首篇论文也来了：强化学习&#43;量子物理学方向。
把Transformer模型用在了动态异构量子资源调度问题上，利用自注意力机制处理量子比特对的序列信息。并在概率性环境中训练强化学习代理，提供动态实时调度指导，最终显著提升了量子系统性能，比基于规则的方法提高了3倍以上。
这样一来，何恺明在自己的成名领域CV和探索新领域AI4S上都没耽误，两开花，两开花。
论文：
https://arxiv.org/abs/2406.11838
参考链接：
[1]https://www.tianhongli.me
[2]https://lambertae.github.io
[3]https://arxiv.org/abs/2405.16380
— 完 —">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-06-23T11:35:28+08:00">
    <meta property="article:modified_time" content="2024-06-23T11:35:28+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">何恺明新作再战AI生成：入职MIT后首次带队，奥赛双料金牌得主邓明扬参与</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div id="js_content"> 
 <h6>梦晨 发自 凹非寺<br>量子位 | 公众号 QbitAI</h6> 
 <p style="text-align:left;"><strong>何恺明</strong>入职MIT副教授后，<strong>首次带队</strong>的新作来了！</p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/44/f5/OXAhJeJd_o.png" alt="044c7fe5b32f6d0a16234c79fd239a13.png"></p> 
 <p style="text-align:left;"><strong>让自回归模型抛弃矢量量化，使用连续值生成图像。</strong>并借鉴扩散模型的思想，<strong>提出Diffusion Loss</strong>。</p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/b7/13/KAGYRbrA_o.png" alt="d4245ad3865d6e4f4a3034f0f4c96d51.png"></p> 
 <p style="text-align:left;">他加入MIT后，此前也参与过另外几篇CV方向的论文，不过都是和MIT教授Wojciech Matusik团队等合作的。</p> 
 <p style="text-align:left;">这次何恺明自己带队，参与者中还出现一个熟悉的名字：</p> 
 <p style="text-align:left;"><strong>邓明扬</strong>，IMO、IOI双料奥赛金牌得主，在竞赛圈人称“乖神”。</p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/23/d7/qQlh2CLI_o.png" alt="61d6a0e8b3e66ce36db959c48d197f31.png"></p> 
 <p style="text-align:left;">目前邓明扬MIT本科在读，按入学时间推算现在刚好大四，所以也有不少网友猜测他如果继续在MIT读博可能会加入何恺明团队。</p> 
 <p style="text-align:left;">接下来具体介绍一下，这篇论文研究了什么。</p> 
 <h3>借鉴扩散模型，大改自回归生成</h3> 
 <p style="text-align:left;">传统观点认为，图像生成的自回归模型通常伴随着<strong>矢量量化</strong>（Vector Quantization），比如DALL·E一代就使用了经典的VQ-VAE方法。</p> 
 <p style="text-align:left;">但团队观察到，自回归生成的本质是根据先前的值预测下一个token，这其实<strong>与值是离散还是连续没啥必然联系</strong>啊。</p> 
 <p style="text-align:left;">关键是要对token的概率分布进行建模，只要该概率分布可以通过损失函数来测量并用于从中抽取样本就行。</p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/13/25/g7InPK1j_o.png" alt="c53ac2cacae154fafd6bb96d26790d73.png"></p> 
 <p style="text-align:left;">并且从另一个方面来看，矢量量化方法还会带来一系列麻烦：</p> 
 <ul><li><p>需要一个离散的token词表，需要精心设计量化的目标函数，训练困难，对梯度近似策略很敏感</p></li><li><p>量化误差会带来信息损失，导致还原图像质量打折</p></li><li><p>离散token适合建模分类分布，有表达能力上的局限</p></li></ul> 
 <p style="text-align:left;">那么有什么更好的替代方法？</p> 
 <p style="text-align:left;">何恺明团队选择在损失函数上动刀，借鉴近年大火的扩散模型的思想，提出<strong>Diffusion Loss</strong>，消除了离散tokenizer的必要性。</p> 
 <p style="text-align:left;">如此一来，在连续值空间中应用自回归模型生成图像就可行了。</p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/85/2b/RR25l0SW_o.png" alt="bfcea48626ca275cd0fe5e744031c543.png"></p> 
 <p style="text-align:left;">具体来说，它让自回归模型输出一个潜变量z作为条件，去训练一个小型的去噪MLP网络。</p> 
 <p style="text-align:left;">通过反向扩散过程，这个小网络就学会了如何根据z去采样生成连续值的token x。扩散的过程天然能建模任意复杂的分布，所以没有类别分布的局限。</p> 
 <p style="text-align:left;">这个去噪网络和自回归模型是端到端联合训练的，链式法则直接把损失传给自回归模型，使其学会输出最佳的条件z。</p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/53/1b/ky3PmQRh_o.png" alt="e9dc742e3ba4c2d588aa7b0cbcf62600.png"></p> 
 <p style="text-align:left;">这篇工作的另一个亮点，是各种自回归模型的变体都适用。它统一了标准的自回归AR、随机顺序的AR、以及何恺明擅长的掩码方法。</p> 
 <p style="text-align:left;">其中<strong>掩码自回归（MAR）</strong>模型，可以在任意随机位置同时预测多个token，同时还能和扩散损失完美配合。</p> 
 <p style="text-align:left;">在这个统一的框架下，所有变体要么逐个token预测，要么并行预测一批token，但本质上都是在已知token的基础上去预测未知token，都是广义的自回归模型，所以扩散损失都能适用。</p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/4b/ac/v0XO1JdA_o.png" alt="d426a0c97f1fdb2dce72bc7efc6acf35.png"></p> 
 <p style="text-align:left;">通过消除矢量量化，团队训练的图像生成模型获得了强大的结果，同时享受序列建模的速度优势。</p> 
 <p style="text-align:left;">论文在AR、MAR的各种变体上做了大量实验，结果表明扩散损失比交叉熵损失稳定带来2-3倍的提升。</p> 
 <p style="text-align:left;">与其他领先模型一比也毫不逊色，小模型都能做到1.98的FID分数，大模型更是创下了1.55的SOTA。</p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/4f/a3/1D3EnUQG_o.png" alt="f15b9760675dcfdb9db6e7f86c4cfe8a.png"></p> 
 <p style="text-align:left;">而且它生成256x256图像速度也很快，不到0.3秒一张。这得益于自回归生成本来就很快，比扩散模型少采样很多步，再加上去噪网络又很小。</p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/b5/a3/x4IpXFb7_o.png" alt="2469f1d423c69db86b842697dfb6a87e.png"></p> 
 <p style="text-align:left;">最后总结一下，这项工作通过自回归建模token间的相关性，再搭配扩散过程对每个token的分布进行建模。</p> 
 <p style="text-align:left;">这也有别于普通的潜空间扩散模型中用单个大扩散模型对所有token的联合分布建模，而是做局部扩散，在效果、速度和灵活性上都展现出了巨大的潜力。</p> 
 <p style="text-align:left;">当然，这个方法还有进一步探索的空间，团队提出，目前在在某些复杂的几何图形理解任务上还有待提高。</p> 
 <h3>何恺明团队都有谁</h3> 
 <p style="text-align:left;">最后再来介绍一下即将或可能加入何恺明课题组的团队成员。。</p> 
 <p style="text-align:left;"><strong>Tianhong LI（黎天鸿）</strong>，清华姚班校友，MIT博士生在读，将于2024年9月加入何恺明的课题组，担任博士后。</p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/f6/7a/era2xiHj_o.png" alt="4996f3c345e168676d5e9570a080dd92.png"></p> 
 <p style="text-align:left;"><strong>Mingyang Deng（邓明扬）</strong>，MIT本科数学和计算机科学专业在读。</p> 
 <p style="text-align:left;">他在高一获得IMO金牌，高三获得IOI金牌，是竞赛圈为数不多的双料金牌得主，也是IOI历史上第三位满分选手。</p> 
 <p style="text-align:left;">目前邓明扬的研究重点是机器学习，特别是理解和推进生成式基础模型，包括扩散模型和大型语言模型。</p> 
 <p style="text-align:left;">不过他的个人主页上还没有透露下一步计划。</p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/90/34/rmASsqWF_o.png" alt="eb825e11c21d3fde434a08b91657fb45.png"></p> 
 <h3>One More Thing</h3> 
 <p style="text-align:left;">何恺明当初在MIT的求职演讲备受关注，其中提到未来工作方向会是<strong>AI for Science</strong>，还引起圈内一阵热议。</p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/6c/01/ZpaqZzd7_o.png" alt="63c8a7c898e68e8ff11a801571a91169.png"></p> 
 <p style="text-align:left;">现在，何恺明在AI4S方向的参与的首篇论文也来了：<strong>强化学习+量子物理学方向</strong>。</p> 
 <p style="text-align:left;"><strong>把Transformer模型用在了动态异构量子资源调度问题上</strong>，利用自注意力机制处理量子比特对的序列信息。并在概率性环境中训练强化学习代理，提供动态实时调度指导，最终显著提升了量子系统性能，比基于规则的方法提高了3倍以上。</p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/ce/38/xN09XD3O_o.png" alt="2e8cac04d6761bf01459500bec712c90.png"></p> 
 <p style="text-align:left;">这样一来，何恺明在自己的成名领域CV和探索新领域AI4S上都没耽误，两开花，两开花。</p> 
 <p style="text-align:left;">论文：<br>https://arxiv.org/abs/2406.11838</p> 
 <p style="text-align:left;">参考链接：<br>[1]https://www.tianhongli.me<br>[2]https://lambertae.github.io<br>[3]https://arxiv.org/abs/2405.16380</p> 
 <p>— <strong>完</strong> —</p> 
 <p><strong>量子位年度AI主题策划</strong>正在征集中！</p> 
 <p>欢迎投稿专题 <strong>一千零一个AI应</strong><strong>用</strong>，<strong>365行AI落地方案</strong></p> 
 <p>或与我们分享你在<strong>寻找的AI产品</strong>，或发现的<strong>AI新动向</strong></p> 
 <p><img src="https://images2.imgbox.com/0a/25/e7Qkg8Bf_o.png" alt="02a30c72dcf723fa9ad4eab7b690cefb.png"></p> 
 <p style="text-align:center;"><strong>点这里👇关注我，记得标星哦～</strong></p> 
</div>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/95814ce0bbbdf8350560149f812464b1/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">（超简单、超易懂、超详细）算法精讲(十四)：广度优先搜索算法</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/844e3ced955557cd4131940d7c33bf58/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Hadoop 面试题（六）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>