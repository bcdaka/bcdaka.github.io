<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>ä½¿ç”¨seq2seqæ¶æ„å®ç°è‹±è¯‘æ³• - ç¼–ç¨‹å¤§å’–</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/a7a1b8190468b7c95c54101750f1553f/">
  <meta property="og:site_name" content="ç¼–ç¨‹å¤§å’–">
  <meta property="og:title" content="ä½¿ç”¨seq2seqæ¶æ„å®ç°è‹±è¯‘æ³•">
  <meta property="og:description" content="seq2seqä»‹ç»Â æ¨¡å‹æ¶æ„ï¼š
Seq2Seqï¼ˆSequence-to-Sequenceï¼‰æ¨¡å‹æ˜¯ä¸€ç§åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ä¸­å¹¿æ³›åº”ç”¨çš„æ¶æ„ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯å°†ä¸€ä¸ªåºåˆ—ä½œä¸ºè¾“å…¥ï¼Œå¹¶è¾“å‡ºå¦ä¸€ä¸ªåºåˆ—ã€‚è¿™ç§æ¨¡å‹ç‰¹åˆ«é€‚ç”¨äºæœºå™¨ç¿»è¯‘ã€èŠå¤©æœºå™¨äººã€è‡ªåŠ¨æ–‡æ‘˜ç­‰åœºæ™¯ï¼Œå…¶ä¸­è¾“å…¥å’Œè¾“å‡ºçš„é•¿åº¦éƒ½æ˜¯å¯å˜çš„ã€‚
embeddingå±‚åœ¨seq2seqæ¨¡å‹ä¸­èµ·ç€å°†ç¦»æ•£å•è¯è½¬æ¢ä¸ºè¿ç»­å‘é‡è¡¨ç¤ºçš„å…³é”®ä½œç”¨ï¼Œä¸ºåç»­çš„è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡æä¾›äº†æœ‰æ•ˆçš„ç‰¹å¾è¾“å…¥ã€‚Â æ•°æ®é›†Â ä¸‹è½½:Â https://download.pytorch.org/tutorial/data.zip
ğŸ¸ï¸æ­¥éª¤ï¼š
åŸºäºGRUçš„seq2seqæ¨¡å‹æ¶æ„å®ç°ç¿»è¯‘çš„è¿‡ç¨‹:
å¯¼å…¥å¿…å¤‡çš„å·¥å…·åŒ….å¯¹æ–‡ä»¶ä¸­æ•°æ®è¿›è¡Œå¤„ç†ï¼Œæ»¡è¶³æ¨¡å‹è®­ç»ƒè¦æ±‚.æ„å»ºåŸºäºGRUçš„ç¼–ç å™¨å’Œè§£ç æ„å»ºæ¨¡å‹è®­ç»ƒå‡½æ•°ï¼Œå¹¶è¿›è¡Œè®­ç»ƒæ„å»ºæ¨¡å‹è¯„ä¼°å‡½æ•°ï¼Œå¹¶è¿›è¡Œæµ‹è¯•ä»¥åŠAttentionæ•ˆæœåˆ†æ # ä»ioå·¥å…·åŒ…å¯¼å…¥openæ–¹æ³• from io import open # ç”¨äºå­—ç¬¦è§„èŒƒåŒ– import unicodedata # ç”¨äºæ­£åˆ™è¡¨è¾¾å¼ import re # ç”¨äºéšæœºç”Ÿæˆæ•°æ® import random # ç”¨äºæ„å»ºç½‘ç»œç»“æ„å’Œå‡½æ•°çš„torchå·¥å…·åŒ… import torch import torch.nn as nn import torch.nn.functional as F # torchä¸­é¢„å®šä¹‰çš„ä¼˜åŒ–æ–¹æ³•å·¥å…·åŒ… from torch import optim # è®¾å¤‡é€‰æ‹©, æˆ‘ä»¬å¯ä»¥é€‰æ‹©åœ¨cudaæˆ–è€…cpuä¸Šè¿è¡Œä½ çš„ä»£ç  device = torch.device(&#34;cuda&#34; if torch.cuda.is_available() else &#34;cpu&#34;) æ•°æ®é¢„å¤„ç† å°†æŒ‡å®šè¯­è¨€ä¸­çš„è¯æ±‡æ˜ å°„æˆæ•°å€¼ğŸ’«
# èµ·å§‹æ ‡å¿— SOS_token = 0 # ç»“æŸæ ‡å¿— EOS_token = 1 class Lang: def __init__(self, name): self.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-06-11T11:25:20+08:00">
    <meta property="article:modified_time" content="2024-06-11T11:25:20+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="ç¼–ç¨‹å¤§å’–" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">ç¼–ç¨‹å¤§å’–</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">ä½¿ç”¨seq2seqæ¶æ„å®ç°è‹±è¯‘æ³•</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p style="text-align:center;"><img alt="e5fcd827ceb04f33b1ba3f49f54fefba.jpeg" src="https://images2.imgbox.com/0d/67/FYU6gqXp_o.jpg"></p> 
<h3>seq2seqä»‹ç»Â </h3> 
<p><strong>æ¨¡å‹æ¶æ„ï¼š</strong><strong><img alt="9e4e8495162c4cb1919afa68ea45933a.png" src="https://images2.imgbox.com/03/f4/VSFSfHvQ_o.png"></strong></p> 
<blockquote> 
 <p>Seq2Seqï¼ˆSequence-to-Sequenceï¼‰æ¨¡å‹æ˜¯ä¸€ç§åœ¨è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰ä¸­å¹¿æ³›åº”ç”¨çš„æ¶æ„ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯å°†ä¸€ä¸ªåºåˆ—ä½œä¸ºè¾“å…¥ï¼Œå¹¶è¾“å‡ºå¦ä¸€ä¸ªåºåˆ—ã€‚è¿™ç§æ¨¡å‹ç‰¹åˆ«é€‚ç”¨äºæœºå™¨ç¿»è¯‘ã€èŠå¤©æœºå™¨äººã€è‡ªåŠ¨æ–‡æ‘˜ç­‰åœºæ™¯ï¼Œå…¶ä¸­è¾“å…¥å’Œè¾“å‡ºçš„é•¿åº¦éƒ½æ˜¯å¯å˜çš„ã€‚</p> 
</blockquote> 
<ul><li>embeddingå±‚åœ¨seq2seqæ¨¡å‹ä¸­èµ·ç€å°†ç¦»æ•£å•è¯è½¬æ¢ä¸ºè¿ç»­å‘é‡è¡¨ç¤ºçš„å…³é”®ä½œç”¨ï¼Œä¸ºåç»­çš„è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡æä¾›äº†æœ‰æ•ˆçš„ç‰¹å¾è¾“å…¥ã€‚Â </li></ul> 
<h3>æ•°æ®é›†Â </h3> 
<p>ä¸‹è½½:Â <a href="https://download.pytorch.org/tutorial/data.zip" rel="nofollow" title="https://download.pytorch.org/tutorial/data.zip">https://download.pytorch.org/tutorial/data.zip</a></p> 
<p>ğŸ¸ï¸æ­¥éª¤ï¼š</p> 
<p>åŸºäºGRUçš„seq2seqæ¨¡å‹æ¶æ„å®ç°ç¿»è¯‘çš„è¿‡ç¨‹:</p> 
<ul><li>å¯¼å…¥å¿…å¤‡çš„å·¥å…·åŒ….</li><li>å¯¹æ–‡ä»¶ä¸­æ•°æ®è¿›è¡Œå¤„ç†ï¼Œæ»¡è¶³æ¨¡å‹è®­ç»ƒè¦æ±‚.</li><li>æ„å»ºåŸºäºGRUçš„ç¼–ç å™¨å’Œè§£ç </li><li>æ„å»ºæ¨¡å‹è®­ç»ƒå‡½æ•°ï¼Œå¹¶è¿›è¡Œè®­ç»ƒ</li><li>æ„å»ºæ¨¡å‹è¯„ä¼°å‡½æ•°ï¼Œå¹¶è¿›è¡Œæµ‹è¯•ä»¥åŠAttentionæ•ˆæœåˆ†æ</li></ul> 
<p style="text-align:center;"><img alt="2e56c3e1f6204fcfbaf53decb45c1c3b.png" src="https://images2.imgbox.com/87/10/0qsX2ZQd_o.png"></p> 
<pre><code class="language-python"># ä»ioå·¥å…·åŒ…å¯¼å…¥openæ–¹æ³•
from io import open
# ç”¨äºå­—ç¬¦è§„èŒƒåŒ–
import unicodedata
# ç”¨äºæ­£åˆ™è¡¨è¾¾å¼
import re
# ç”¨äºéšæœºç”Ÿæˆæ•°æ®
import random
# ç”¨äºæ„å»ºç½‘ç»œç»“æ„å’Œå‡½æ•°çš„torchå·¥å…·åŒ…
import torch
import torch.nn as nn
import torch.nn.functional as F
# torchä¸­é¢„å®šä¹‰çš„ä¼˜åŒ–æ–¹æ³•å·¥å…·åŒ…
from torch import optim
# è®¾å¤‡é€‰æ‹©, æˆ‘ä»¬å¯ä»¥é€‰æ‹©åœ¨cudaæˆ–è€…cpuä¸Šè¿è¡Œä½ çš„ä»£ç 
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")</code></pre> 
<h3>æ•°æ®é¢„å¤„ç†</h3> 
<p style="text-align:center;"><img alt="b7e432a96dff4958b39b36b22bc45285.png" src="https://images2.imgbox.com/97/e4/vltBHffg_o.png"></p> 
<p><strong>å°†æŒ‡å®šè¯­è¨€ä¸­çš„è¯æ±‡æ˜ å°„æˆæ•°å€¼ğŸ’«</strong></p> 
<pre><code class="language-python"># èµ·å§‹æ ‡å¿—
SOS_token = 0
# ç»“æŸæ ‡å¿—
EOS_token = 1

class Lang:
    def __init__(self, name):
        self.name = name
        self.word2index = {}
        self.index2word = {0: "SOS", 1: "EOS"}
        self.n_words = 2  

    def addSentence(self, sentence):
        for word in sentence.split(' '):
            self.addWord(word)


    def addWord(self, word):
      
        if word not in self.word2index:
            self.word2index[word] = self.n_words
            self.index2word[self.n_words] = words
            self.n_words += 1</code></pre> 
<ul><li>æµ‹è¯•ï¼šå®ä¾‹åŒ–å‚æ•°:Â </li></ul> 
<pre><code class="language-python">name = "eng"
sentence = "hello I am Jay"

engl = Lang(name)
engl.addSentence(sentence)
print("word2index:", engl.word2index)
print("index2word:", engl.index2word)
print("n_words:", engl.n_words)

# è¾“å‡º
word2index: {'hello': 2, 'I': 3, 'am': 4, 'Jay': 5}
index2word: {0: 'SOS', 1: 'EOS', 2: 'hello', 3: 'I', 4: 'am', 5: 'Jay'}
n_words: 6
</code></pre> 
<p><strong>Â å­—ç¬¦è§„èŒƒåŒ–ğŸ’«</strong></p> 
<pre><code class="language-python">
def unicodeToAscii(s):
    return ''.join(
        c for c in unicodedata.normalize('NFD', s)
        if unicodedata.category(c) != 'Mn'
    )


def normalizeString(s):
    s = unicodeToAscii(s.lower().strip())
    s = re.sub(r"([.!?])", r" \1", s)
    s = re.sub(r"[^a-zA-Z.!?]+", r" ", s)
    return s</code></pre> 
<p><strong>å°†æ–‡ä»¶ä¸­çš„æ•°æ®åŠ è½½åˆ°å†…å­˜ï¼Œå®ä¾‹åŒ–ç±»LangğŸ’«</strong></p> 
<pre><code class="language-python">data_path = 'eng-fra.txt'

def readLangs(lang1, lang2):
    """è¯»å–è¯­è¨€å‡½æ•°, å‚æ•°lang1æ˜¯æºè¯­è¨€çš„åå­—, å‚æ•°lang2æ˜¯ç›®æ ‡è¯­è¨€çš„åå­—
       è¿”å›å¯¹åº”çš„class Langå¯¹è±¡, ä»¥åŠè¯­è¨€å¯¹åˆ—è¡¨"""
    # ä»æ–‡ä»¶ä¸­è¯»å–è¯­è¨€å¯¹å¹¶ä»¥/nåˆ’åˆ†å­˜åˆ°åˆ—è¡¨linesä¸­
    lines = open(data_path, encoding='utf-8').read().strip().split('\n')
    # å¯¹linesåˆ—è¡¨ä¸­çš„å¥å­è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†ï¼Œå¹¶ä»¥\tè¿›è¡Œå†æ¬¡åˆ’åˆ†, å½¢æˆå­åˆ—è¡¨, ä¹Ÿå°±æ˜¯è¯­è¨€å¯¹
    pairs = [[normalizeString(s) for s in l.split('\t')] for l in lines] 
    # ç„¶ååˆ†åˆ«å°†è¯­è¨€åå­—ä¼ å…¥Langç±»ä¸­, è·å¾—å¯¹åº”çš„è¯­è¨€å¯¹è±¡, è¿”å›ç»“æœ
    input_lang = Lang(lang1)
    output_lang = Lang(lang2)
    return input_lang, output_lang, pairs</code></pre> 
<ul><li>æµ‹è¯•ï¼šè¾“å…¥å‚æ•°:</li></ul> 
<pre><code class="language-python">lang1 = "eng"
lang2 = "fra"

input_lang, output_lang, pairs = readLangs(lang1, lang2)
print("pairsä¸­çš„å‰äº”ä¸ª:", pairs[:5])

# è¾“å‡º
pairsä¸­çš„å‰äº”ä¸ª: [['go .', 'va !'], ['run !', 'cours !'], ['run !', 'courez !'], ['wow !', 'ca alors !'], ['fire !', 'au feu !']]</code></pre> 
<p><strong>è¿‡æ»¤å‡ºç¬¦åˆæˆ‘ä»¬è¦æ±‚çš„è¯­è¨€å¯¹ğŸ’«</strong></p> 
<pre><code class="language-python"># è®¾ç½®ç»„æˆå¥å­ä¸­å•è¯æˆ–æ ‡ç‚¹çš„æœ€å¤šä¸ªæ•°
MAX_LENGTH = 10

eng_prefixes = (
    "i am ", "i m ",
    "he is", "he s ",
    "she is", "she s ",
    "you are", "you re ",
    "we are", "we re ",
    "they are", "they re "
)


def filterPair(p):
    return len(p[0].split(' ')) &lt; MAX_LENGTH and \
        p[0].startswith(eng_prefixes) and \
        len(p[1].split(' ')) &lt; MAX_LENGTH 


def filterPairs(pairs):
    return [pair for pair in pairs if filterPair(pair)]</code></pre> 
<p><strong>å¯¹ä»¥ä¸Šæ•°æ®å‡†å¤‡å‡½æ•°è¿›è¡Œæ•´åˆğŸ’«</strong></p> 
<pre><code class="language-python">def prepareData(lang1, lang2):

    input_lang, output_lang, pairs = readLangs(lang1, lang2)

    pairs = filterPairs(pairs)
    for pair in pairs:
        input_lang.addSentence(pair[0])
        output_lang.addSentence(pair[1])
    return input_lang, output_lang, pairs</code></pre> 
<p><strong>å°†è¯­è¨€å¯¹è½¬åŒ–ä¸ºæ¨¡å‹è¾“å…¥éœ€è¦çš„å¼ é‡ğŸ’«</strong></p> 
<pre><code class="language-python">def tensorFromSentence(lang, sentence):
    indexes = [lang.word2index[word] for word in sentence.split(' ')]

    indexes.append(EOS_token)
    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)


def tensorsFromPair(pair):

    input_tensor = tensorFromSentence(input_lang, pair[0])
    target_tensor = tensorFromSentence(output_lang, pair[1])
    return (input_tensor, target_tensor)</code></pre> 
<ul><li>æµ‹è¯•è¾“å…¥ï¼š</li></ul> 
<pre><code class="language-python"># å–pairsçš„ç¬¬ä¸€æ¡
pair = pairs[0]
pair_tensor = tensorsFromPair(pair)
print(pair_tensor)

# è¾“å‡º
(tensor([[2],
        [3],
        [4],
        [1]]), 
 tensor([[2],
        [3],
        [4],
        [5],
        [1]]))</code></pre> 
<h3>æ„å»ºç¼–ç å™¨å’Œè§£ç å™¨</h3> 
<p style="text-align:center;"><img alt="22c77655e7a243bcb6ad3078af321335.png" src="https://images2.imgbox.com/cf/a7/XBYQK1Pa_o.png"></p> 
<p><strong>æ„å»ºåŸºäºGRUçš„ç¼–ç å™¨Â </strong></p> 
<ul><li>â€œembeddingâ€æŒ‡çš„æ˜¯ä¸€ä¸ªå°†ç¦»æ•£å˜é‡ï¼ˆå¦‚å•è¯ã€ç¬¦å·ç­‰ï¼‰è½¬æ¢ä¸ºè¿ç»­å‘é‡è¡¨ç¤ºçš„è¿‡ç¨‹æˆ–æŠ€æœ¯</li><li>â€œembeddedâ€æ˜¯embeddingè¿‡ç¨‹çš„è¾“å‡ºï¼Œå³å·²ç»é€šè¿‡åµŒå…¥çŸ©é˜µè½¬æ¢åçš„è¿ç»­å‘é‡ã€‚åœ¨ç¥ç»ç½‘ç»œä¸­ï¼Œè¿™äº›å‘é‡å°†ä½œä¸ºåç»­å±‚çš„è¾“å…¥ã€‚</li></ul> 
<pre><code class="language-python">class EncoderRNN(nn.Module):
    def __init__(self, input_size, hidden_size):
        super(EncoderRNN, self).__init__()
        self.hidden_size = hidden_size

        self.embedding = nn.Embedding(input_size, hidden_size)
        self.gru = nn.GRU(hidden_size, hidden_size)

    def forward(self, input, hidden):
        output = self.embedding(input).view(1, 1, -1)
        output, hidden = self.gru(output, hidden)
        return output, hidden

    def initHidden(self):
        return torch.zeros(1, 1, self.hidden_size, device=device)</code></pre> 
<ul><li>Â æµ‹è¯•ï¼šå‚æ•°ï¼š</li></ul> 
<pre><code class="language-python">hidden_size = 25
input_size = 20

# pair_tensor[0]ä»£è¡¨æºè¯­è¨€å³è‹±æ–‡çš„å¥å­ï¼Œpair_tensor[0][0]ä»£è¡¨å¥å­ä¸­
çš„ç¬¬ä¸€ä¸ªè¯
input = pair_tensor[0][0]
# åˆå§‹åŒ–ç¬¬ä¸€ä¸ªéšå±‚å¼ é‡ï¼Œ1x1xhidden_sizeçš„0å¼ é‡
hidden = torch.zeros(1, 1, hidden_size)

encoder = EncoderRNN(input_size, hidden_size)
encoder_output, hidden = encoder(input, hidden)
print(encoder_output)

# è¾“å‡º
tensor([[[ 1.9149e-01, -2.0070e-01, -8.3882e-02, -3.3037e-02, -1.3491e-01,
          -8.8831e-02, -1.6626e-01, -1.9346e-01, -4.3996e-01,  1.8020e-02,
           2.8854e-02,  2.2310e-01,  3.5153e-01,  2.9635e-01,  1.5030e-01,
          -8.5266e-02, -1.4909e-01,  2.4336e-04, -2.3522e-01,  1.1359e-01,
           1.6439e-01,  1.4872e-01, -6.1619e-02, -1.0807e-02,  1.1216e-02]]],
       grad_fn=&lt;StackBackward&gt;)</code></pre> 
<p><strong>æ„å»ºåŸºäºGRUçš„è§£ç å™¨</strong></p> 
<pre><code class="language-python">class DecoderRNN(nn.Module):
    def __init__(self, hidden_size, output_size):
      
        super(DecoderRNN, self).__init__()

        self.hidden_size = hidden_size
        self.embedding = nn.Embedding(output_size, hidden_size)

        self.gru = nn.GRU(hidden_size, hidden_size)
        self.out = nn.Linear(hidden_size, output_size)
        self.softmax = nn.LogSoftmax(dim=1)


    def forward(self, input, hidden):

        output = self.embedding(input).view(1, 1, -1)
        output = F.relu(output)
        output, hidden = self.gru(output, hidden)

        output = self.softmax(self.out(output[0]))
        return output, hidden

    def initHidden(self):
        return torch.zeros(1, 1, self.hidden_size, device=device)</code></pre> 
<p><strong>æ„å»ºåŸºäºGRUå’ŒAttentionçš„è§£ç å™¨ğŸ’¥</strong></p> 
<p><strong>ğŸ’¥ä¸‰ä¸ªè¾“å…¥ï¼š</strong></p> 
<ul><li><strong>prev_hidden</strong>ï¼šæŒ‡ä¸Šä¸€ä¸ªæ—¶é—´æ­¥è§£ç å™¨çš„éšè—çŠ¶æ€</li><li><strong>inputï¼š</strong><code>input</code>Â æ˜¯å½“å‰æ—¶é—´æ­¥è§£ç å™¨çš„è¾“å…¥ã€‚åœ¨è§£ç çš„å¼€å§‹é˜¶æ®µï¼Œå®ƒå¯èƒ½æ˜¯ä¸€ä¸ªç‰¹æ®Šçš„èµ·å§‹ç¬¦å·ã€‚åœ¨éšåçš„è§£ç æ­¥éª¤ä¸­ï¼Œ<code>input</code>Â é€šå¸¸æ˜¯ä¸Šä¸€ä¸ªæ—¶é—´æ­¥è§£ç å™¨è¾“å‡ºçš„è¯ï¼ˆæˆ–å¯¹åº”çš„è¯å‘é‡ï¼‰ã€‚</li><li><strong><code>encoder_outputs</code></strong>Â ï¼šæ˜¯ç¼–ç å™¨å¤„ç†è¾“å…¥åºåˆ—åç”Ÿæˆçš„ä¸€ç³»åˆ—è¾“å‡ºå‘é‡ï¼Œåœ¨åŸºäºAttentionçš„è§£ç å™¨ä¸­ï¼Œè¿™äº›è¾“å‡ºå‘é‡å°†ä½œä¸ºæ³¨æ„åŠ›æœºåˆ¶çš„å€™é€‰è®°å¿†å•å…ƒï¼Œç”¨äºè®¡ç®—å½“å‰è§£ç æ­¥ä¸è¾“å…¥åºåˆ—ä¸­ä¸åŒä½ç½®çš„ç›¸å…³æ€§ã€‚</li></ul> 
<pre><code class="language-python">class AttnDecoderRNN(nn.Module):
    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):

        super(AttnDecoderRNN, self).__init__()
        self.hidden_size = hidden_size
        self.output_size = output_size
        self.dropout_p = dropout_p
        self.max_length = max_length

        self.embedding = nn.Embedding(self.output_size, self.hidden_size)
        
        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)
        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)
        self.dropout = nn.Dropout(self.dropout_p)

        self.gru = nn.GRU(self.hidden_size, self.hidden_size)
        self.out = nn.Linear(self.hidden_size, self.output_size)


    def forward(self, input, hidden, encoder_outputs):

        embedded = self.embedding(input).view(1, 1, -1)

        embedded = self.dropout(embedded)

        attn_weights = F.softmax(
            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)

        attn_applied = torch.bmm(attn_weights.unsqueeze(0),
                                 encoder_outputs.unsqueeze(0))


        output = torch.cat((embedded[0], attn_applied[0]), 1)

        output = self.attn_combine(output).unsqueeze(0)

        output = F.relu(output)

        output, hidden = self.gru(output, hidden)


        output = F.log_softmax(self.out(output[0]), dim=1)

        return output, hidden, attn_weights

    def initHidden(self):

        return torch.zeros(1, 1, self.hidden_size, device=device)</code></pre> 
<h3>æ„å»ºæ¨¡å‹è®­ç»ƒå‡½æ•°</h3> 
<p style="text-align:center;"><img alt="2a8c5559c3064e22877f2d88e17ad51a.png" src="https://images2.imgbox.com/ca/77/N6HNCT6F_o.png"></p> 
<p>teacher_forcingä»‹ç»</p> 
<p>Teacher Forcingæ˜¯ä¸€ç§åœ¨è®­ç»ƒåºåˆ—ç”Ÿæˆæ¨¡å‹ï¼Œç‰¹åˆ«æ˜¯å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰å’Œåºåˆ—åˆ°åºåˆ—ï¼ˆseq2seqï¼‰æ¨¡å‹æ—¶å¸¸ç”¨çš„æŠ€æœ¯ã€‚åœ¨seq2seqæ¶æ„ä¸­ï¼Œæ ¹æ®å¾ªç¯ç¥ç»ç½‘ç»œç†è®ºï¼Œè§£ç å™¨æ¯æ¬¡åº”è¯¥ä½¿ç”¨ä¸Šä¸€æ­¥çš„ç»“æœä½œä¸ºè¾“å…¥çš„ä¸€éƒ¨åˆ†, ä½†æ˜¯è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä¸€æ—¦ä¸Šä¸€æ­¥çš„ç»“æœæ˜¯é”™è¯¯çš„ï¼Œå°±ä¼šå¯¼è‡´è¿™ç§é”™è¯¯è¢«ç´¯ç§¯ï¼Œæ— æ³•è¾¾åˆ°è®­ç»ƒæ•ˆæœï¼Œæˆ‘ä»¬éœ€è¦ä¸€ç§æœºåˆ¶æ”¹å˜ä¸Šä¸€æ­¥å‡ºé”™çš„æƒ…å†µï¼Œå› ä¸ºè®­ç»ƒæ—¶æˆ‘ä»¬æ˜¯å·²çŸ¥æ­£ç¡®çš„è¾“å‡ºåº”è¯¥æ˜¯ä»€ä¹ˆï¼Œå› æ­¤å¯ä»¥å¼ºåˆ¶å°†ä¸Šä¸€æ­¥ç»“æœè®¾ç½®æˆæ­£ç¡®çš„è¾“å‡º, è¿™ç§æ–¹å¼å°±å«åšteacher_forcingã€‚</p> 
<p>teacher_forcingçš„ä½œç”¨</p> 
<ul><li>åŠ é€Ÿæ¨¡å‹æ”¶æ•›ä¸ç¨³å®šè®­ç»ƒï¼šé€šè¿‡ä½¿ç”¨çœŸå®çš„å†å²æ•°æ®ä½œä¸ºè§£ç å™¨çš„è¾“å…¥ï¼ŒTeacher ForcingæŠ€æœ¯å¯ä»¥åŠ é€Ÿæ¨¡å‹çš„æ”¶æ•›é€Ÿåº¦ï¼Œå¹¶ä½¿å¾—è®­ç»ƒè¿‡ç¨‹æ›´åŠ ç¨³å®šï¼Œå› ä¸ºå®ƒé¿å…äº†å› æ¨¡å‹æ—©æœŸé¢„æµ‹é”™è¯¯è€Œå¯¼è‡´çš„ç´¯ç§¯è¯¯å·®ã€‚</li><li>çŸ«æ­£é¢„æµ‹å¹¶é¿å…è¯¯å·®æ”¾å¤§ï¼šTeacher Forcingåœ¨è®­ç»ƒæ—¶èƒ½å¤ŸçŸ«æ­£æ¨¡å‹çš„é¢„æµ‹ï¼Œé˜²æ­¢åœ¨åºåˆ—ç”Ÿæˆè¿‡ç¨‹ä¸­è¯¯å·®çš„è¿›ä¸€æ­¥æ”¾å¤§ï¼Œä»è€Œæé«˜äº†æ¨¡å‹çš„é¢„æµ‹å‡†ç¡®æ€§ã€‚</li></ul> 
<pre><code class="language-python"># è®¾ç½®teacher_forcingæ¯”ç‡ä¸º0.5
teacher_forcing_ratio = 0.5


def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):

    encoder_hidden = encoder.initHidden()

    encoder_optimizer.zero_grad()
    decoder_optimizer.zero_grad()

    input_length = input_tensor.size(0)
    target_length = target_tensor.size(0)

    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)

    loss = 0

    for ei in range(input_length):
        
        encoder_output, encoder_hidden = encoder(
            input_tensor[ei], encoder_hidden)
   
        encoder_outputs[ei] = encoder_output[0, 0]


    decoder_input = torch.tensor([[SOS_token]], device=device)

    decoder_hidden = encoder_hidden

    use_teacher_forcing = True if random.random() &lt; teacher_forcing_ratio else False


    if use_teacher_forcing:

        for di in range(target_length):

            decoder_output, decoder_hidden, decoder_attention = decoder(
                decoder_input, decoder_hidden, encoder_outputs)

            loss += criterion(decoder_output, target_tensor[di])

            decoder_input = target_tensor[di]  

    else:

        for di in range(target_length):
            decoder_output, decoder_hidden, decoder_attention = decoder(
                decoder_input, decoder_hidden, encoder_outputs)

            topv, topi = decoder_output.topk(1)

            loss += criterion(decoder_output, target_tensor[di])

            if topi.squeeze().item() == EOS_token:
                break
           
            decoder_input = topi.squeeze().detach()


    # è¯¯å·®è¿›è¡Œåå‘ä¼ æ’­
    loss.backward()
    # ç¼–ç å™¨å’Œè§£ç å™¨è¿›è¡Œä¼˜åŒ–å³å‚æ•°æ›´æ–°
    encoder_optimizer.step()
    decoder_optimizer.step()

    # è¿”å›å¹³å‡æŸå¤±
    return loss.item() / target_length</code></pre> 
<p><strong>æ„å»ºæ—¶é—´è®¡ç®—å‡½æ•°</strong></p> 
<pre><code class="language-python">import time
import math

def timeSince(since):
    now = time.time()
    # è·å¾—æ—¶é—´å·®
    s = now - since
    # å°†ç§’è½¬åŒ–ä¸ºåˆ†é’Ÿ
    m = math.floor(s / 60)
    s -= m * 60
    return '%dm %ds' % (m, s)</code></pre> 
<p><strong>è°ƒç”¨è®­ç»ƒå‡½æ•°å¹¶æ‰“å°æ—¥å¿—å’Œåˆ¶å›¾</strong></p> 
<pre><code class="language-python">import matplotlib.pyplot as plt

def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):

    start = time.time()

    plot_losses = []

    print_loss_total = 0  

    plot_loss_total = 0  

    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)
    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)


    criterion = nn.NLLLoss()

    for iter in range(1, n_iters + 1):

        training_pair = tensorsFromPair(random.choice(pairs))

        input_tensor = training_pair[0]
        target_tensor = training_pair[1]


        loss = train(input_tensor, target_tensor, encoder,
                     decoder, encoder_optimizer, decoder_optimizer, criterion)

        print_loss_total += loss
        plot_loss_total += loss


        if iter % print_every == 0:

            print_loss_avg = print_loss_total / print_every
            print_loss_total = 0
            print('%s (%d %d%%) %.4f' % (timeSince(start),
                                         iter, iter / n_iters * 100, print_loss_avg))

        if iter % plot_every == 0:
            plot_loss_avg = plot_loss_total / plot_every
            plot_losses.append(plot_loss_avg)
            plot_loss_total = 0


    plt.figure()  
    plt.plot(plot_losses)
    plt.savefig("loss.png")</code></pre> 
<p>ğŸ’¥è®­ç»ƒæ¨¡å‹ï¼š</p> 
<pre><code class="language-python"># è®¾ç½®éšå±‚å¤§å°ä¸º256 ï¼Œä¹Ÿæ˜¯è¯åµŒå…¥ç»´åº¦      
hidden_size = 256
# é€šè¿‡input_lang.n_wordsè·å–è¾“å…¥è¯æ±‡æ€»æ•°ï¼Œä¸hidden_sizeä¸€åŒä¼ å…¥EncoderRNNç±»ä¸­
# å¾—åˆ°ç¼–ç å™¨å¯¹è±¡encoder1
encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)

# é€šè¿‡output_lang.n_wordsè·å–ç›®æ ‡è¯æ±‡æ€»æ•°ï¼Œä¸hidden_sizeå’Œdropout_pä¸€åŒä¼ å…¥AttnDecoderRNNç±»ä¸­
# å¾—åˆ°è§£ç å™¨å¯¹è±¡attn_decoder1
attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)

# è®¾ç½®è¿­ä»£æ­¥æ•° 
n_iters = 80000
# è®¾ç½®æ—¥å¿—æ‰“å°é—´éš”
print_every = 5000 

trainIters(encoder1, attn_decoder1, n_iters, print_every=print_every)</code></pre> 
<p>æ¨¡å‹ä¼šä¸æ–­æ‰“å°lossæŸå¤±å€¼å¹¶ä¸”ç»˜åˆ¶å›¾åƒ</p> 
<p style="text-align:center;"><img alt="d037317aa28d40b49bf1dac1cf22f680.png" src="https://images2.imgbox.com/2a/9c/x7be3AMI_o.png"></p> 
<ul><li>ä¸€ç›´ä¸‹é™çš„æŸå¤±æ›²çº¿, è¯´æ˜æ¨¡å‹æ­£åœ¨æ”¶æ•›Â </li></ul> 
<h3>æ„å»ºæ¨¡å‹è¯„ä¼°å‡½æ•°</h3> 
<p style="text-align:center;"><img alt="50f947b7416249b695abe3738cc64164.png" src="https://images2.imgbox.com/28/7b/yptNvqn5_o.png"></p> 
<pre><code class="language-python">def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):
    with torch.no_grad():
        # å¯¹è¾“å…¥çš„å¥å­è¿›è¡Œå¼ é‡è¡¨ç¤º
        input_tensor = tensorFromSentence(input_lang, sentence)
        # è·å¾—è¾“å…¥çš„å¥å­é•¿åº¦
        input_length = input_tensor.size()[0]
        encoder_hidden = encoder.initHidden()

        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)

        for ei in range(input_length):

            encoder_output, encoder_hidden = encoder(input_tensor[ei],
                                                     encoder_hidden)

            encoder_outputs[ei] += encoder_output[0, 0]

        decoder_input = torch.tensor([[SOS_token]], device=device) 

        decoder_hidden = encoder_hidden

        decoded_words = []
        # åˆå§‹åŒ–attentionå¼ é‡
        decoder_attentions = torch.zeros(max_length, max_length)
        # å¼€å§‹å¾ªç¯è§£ç 
        for di in range(max_length):

            decoder_output, decoder_hidden, decoder_attention = decoder(
                decoder_input, decoder_hidden, encoder_outputs)


            decoder_attentions[di] = decoder_attention.data
            topv, topi = decoder_output.data.topk(1)
            if topi.item() == EOS_token:
                decoded_words.append('&lt;EOS&gt;') 
                break

            else:
                
                decoded_words.append(output_lang.index2word[topi.item()])


            decoder_input = topi.squeeze().detach()
        return decoded_words, decoder_attentions[:di + 1]</code></pre> 
<p><strong>Â éšæœºé€‰æ‹©æŒ‡å®šæ•°é‡çš„æ•°æ®è¿›è¡Œè¯„ä¼°</strong></p> 
<pre><code class="language-python">def evaluateRandomly(encoder, decoder, n=6):
    for i in range(n):
        pair = random.choice(pairs)
        # &gt; ä»£è¡¨è¾“å…¥
        print('&gt;', pair[0])
        # = ä»£è¡¨æ­£ç¡®çš„è¾“å‡º
        print('=', pair[1])
        # è°ƒç”¨evaluateè¿›è¡Œé¢„æµ‹
        output_words, attentions = evaluate(encoder, decoder, pair[0])
        # å°†ç»“æœè¿æˆå¥å­
        output_sentence = ' '.join(output_words)
        # &lt; ä»£è¡¨æ¨¡å‹çš„è¾“å‡º
        print('&lt;', output_sentence)
        print('')

evaluateRandomly(encoder1, attn_decoder1)</code></pre> 
<p>æ•ˆæœï¼š</p> 
<pre><code class="language-python">&gt; i m impressed with your french .
= je suis impressionne par votre francais .
&lt; je suis impressionnee par votre francais . &lt;EOS&gt;

&gt; i m more than a friend .
= je suis plus qu une amie .
&lt; je suis plus qu une amie . &lt;EOS&gt;

&gt; she is beautiful like her mother .
= elle est belle comme sa mere .
&lt; elle est sa sa mere . &lt;EOS&gt;

&gt; you re winning aren t you ?
= vous gagnez n est ce pas ?
&lt; tu restez n est ce pas ? &lt;EOS&gt;

&gt; he is angry with you .
= il est en colere apres toi .
&lt; il est en colere apres toi . &lt;EOS&gt;

&gt; you re very timid .
= vous etes tres craintifs .
&lt; tu es tres craintive . &lt;EOS&gt;</code></pre> 
<p>Attentionå¼ é‡åˆ¶å›¾</p> 
<pre><code class="language-python">sentence = "we re both teachers ."
# è°ƒç”¨è¯„ä¼°å‡½æ•°
output_words, attentions = evaluate(
encoder1, attn_decoder1, sentence)
print(output_words)
# å°†attentionå¼ é‡è½¬åŒ–æˆnumpy, ä½¿ç”¨matshowç»˜åˆ¶
plt.matshow(attentions.numpy())
plt.savefig("attn.png")</code></pre> 
<p>å¦‚æœè¿­ä»£æ¬¡æ•°è¿‡å°‘ï¼Œè®­ç»ƒä¸å……åˆ†ï¼Œé‚£ä¹ˆæ³¨æ„åŠ›å°±ä¸ä¼šå¾ˆå¥½ï¼š</p> 
<p style="text-align:center;"><img alt="703e1e4cd170498c8fb211aa10694c02.png" src="https://images2.imgbox.com/99/54/hrNgGzyx_o.png"></p> 
<p>ğŸ’¯è¿­ä»£æ¬¡æ•°å˜å¤§ï¼š</p> 
<p style="text-align:center;"><img alt="5a4477724f3147ecaf4e846972d24293.png" src="https://images2.imgbox.com/9b/63/i3Lw1iMZ_o.png"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/f7da14cfd9167155003318fb370775c1/" rel="prev">
			<span class="pager__subtitle">Â«&thinsp;Previous</span>
			<p class="pager__title">Pythonï¼šåŸºç¡€&amp;çˆ¬è™«</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/d8ee0479e0e29561446e45d206fa014f/" rel="next">
			<span class="pager__subtitle">Next&thinsp;Â»</span>
			<p class="pager__title">çŸ­å‰§ç‰‡æºç«çˆ†ï¼Œåƒé‡‘éš¾æ±‚å¥½å‰§æº</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 ç¼–ç¨‹å¤§å’–.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>