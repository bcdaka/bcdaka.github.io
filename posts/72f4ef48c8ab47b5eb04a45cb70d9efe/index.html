<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Ollama &#43; Openwebui 本地部署大型模型与交互式可视化聊天 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/72f4ef48c8ab47b5eb04a45cb70d9efe/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="Ollama &#43; Openwebui 本地部署大型模型与交互式可视化聊天">
  <meta property="og:description" content="Ollama简介 Ollama是一个创新的平台，它允许用户在本地启动并运行大型语言模型。它提供了一个简单易用的内容生成接口，类似于OpenAI，但无需开发经验即可直接与模型进行交互。Ollama支持热切换模型，为用户提供了灵活性和多样性。
安装Ollama 要安装Ollama，请访问官方网站的下载页面：Ollama下载页面。在这里，你可以根据你的操作系统选择合适的版本进行下载，目前，Ollama支持macOS 11 Big Sur或更高版本。
macOS用户 对于macOS用户，可以直接点击下载链接获取Ollama的压缩包：Download for macOS。
Windows用户 对于Windows用户，可以参照上述链接中的步骤进行安装，安装过程中，你可以通过注册来接收新更新的通知。
使用Ollama 安装完成后，你可以通过命令行查看Ollama的可用命令。例如，在Windows的PowerShell中，输入ollama即可查看帮助信息和可用命令。
PS C:\Users\Admin&gt; ollama Usage: ollama [flags] ollama [command] Available Commands: serve Start ollama create Create a model from a Modelfile show Show information for a model run Run a model pull Pull a model from a registry push Push a model to a registry list List models cp Copy a model rm Remove a model help Help about any command Flags: -h, --help help for ollama -v, --version Show version information Use &#34;">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-03-19T11:10:56+08:00">
    <meta property="article:modified_time" content="2024-03-19T11:10:56+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Ollama &#43; Openwebui 本地部署大型模型与交互式可视化聊天</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="Ollama_1"></a>Ollama简介</h2> 
<p>Ollama是一个创新的平台，它允许用户在本地启动并运行大型语言模型。它提供了一个简单易用的内容生成接口，类似于OpenAI，但无需开发经验即可直接与模型进行交互。Ollama支持热切换模型，为用户提供了灵活性和多样性。<br> <img src="https://images2.imgbox.com/78/11/ms7kYB8m_o.png" alt="image.png"></p> 
<h3><a id="Ollama_6"></a>安装Ollama</h3> 
<p>要安装Ollama，请访问官方网站的下载页面：<a href="https://ollama.com/download" rel="nofollow">Ollama下载页面</a>。在这里，你可以根据你的操作系统选择合适的版本进行下载，目前，Ollama支持macOS 11 Big Sur或更高版本。<br> <img src="https://images2.imgbox.com/2e/57/Sm64abmR_o.png" alt="image.png"></p> 
<h4><a id="macOS_11"></a>macOS用户</h4> 
<p>对于macOS用户，可以直接点击下载链接获取Ollama的压缩包：<a href="https://ollama.com/download/Ollama-darwin.zip" rel="nofollow">Download for macOS</a>。</p> 
<h4><a id="Windows_15"></a>Windows用户</h4> 
<p>对于Windows用户，可以参照上述链接中的步骤进行安装，安装过程中，你可以通过注册来接收新更新的通知。</p> 
<h3><a id="Ollama_19"></a>使用Ollama</h3> 
<p>安装完成后，你可以通过命令行查看Ollama的可用命令。例如，在Windows的PowerShell中，输入<code>ollama</code>即可查看帮助信息和可用命令。</p> 
<pre><code>PS C:\Users\Admin&gt; ollama
Usage:
  ollama [flags]
  ollama [command]

Available Commands:
  serve       Start ollama
  create      Create a model from a Modelfile
  show        Show information for a model
  run         Run a model
  pull        Pull a model from a registry
  push        Push a model to a registry
  list        List models
  cp          Copy a model
  rm          Remove a model
  help        Help about any command

Flags:
  -h, --help      help for ollama
  -v, --version   Show version information

Use "ollama [command] --help" for more information about a command.
PS C:\Users\Admin&gt;
</code></pre> 
<h3><a id="_49"></a>下载和使用大型模型</h3> 
<p>Ollama的模型库提供了多种大型语言模型供用户选择。你可以通过访问<a href="https://ollama.com/library" rel="nofollow">Ollama模型库</a>来找到并下载你需要的模型。</p> 
<p><img src="https://images2.imgbox.com/37/c1/UVW8E9EV_o.png" alt="image.png"></p> 
<p><img src="https://images2.imgbox.com/95/44/U8cQQBQY_o.png" alt="image.png"></p> 
<h4><a id="_57"></a>查看已安装模型</h4> 
<p>安装模型后，使用<code>ollama list</code>命令可以查看已安装的模型列表。</p> 
<pre><code>PS C:\Users\Admin&gt; ollama list
NAME            ID              SIZE    MODIFIED
gemma:2b        b50d6c999e59    1.7 GB  About an hour ago
llama2:latest   78e26419b446    3.8 GB  9 hours ago
qwen:latest     d53d04290064    2.3 GB  8 hours ago
PS C:\Users\Admin&gt;
</code></pre> 
<h4><a id="_70"></a>运行模型</h4> 
<p>通过<code>ollama run</code>命令，你可以运行特定的模型。例如，<code>ollama run qwen</code>将启动qwen模型。</p> 
<p><img src="https://images2.imgbox.com/be/0d/Lzvm0oqL_o.png" alt="image.png"></p> 
<h3><a id="OpenWebUI_76"></a>OpenWebUI简介</h3> 
<p><a href="https://openwebui.com/" rel="nofollow">OpenWebUI</a>是一个可扩展、功能丰富且用户友好的自托管WebUI，它支持完全离线操作，并兼容Ollama和OpenAI的API。这为用户提供了一个可视化的界面，使得与大型语言模型的交互更加直观和便捷。<br> <img src="https://images2.imgbox.com/91/36/9DHUn68j_o.png" alt="image.png"></p> 
<h4><a id="_Openwebui_81"></a>安装 Openwebui</h4> 
<ul><li>如果您的计算机上有 Ollama，请使用以下命令：</li></ul> 
<pre><code class="prism language-docker">docker run -d -p 3000:8080 --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main
</code></pre> 
<ul><li><strong>如果 Ollama 位于不同的服务器上</strong>，请使用以下命令：</li><li>要连接到另一台服务器上的 Ollama，请将 更改<code>OLLAMA_BASE_URL</code>为服务器的 URL：</li></ul> 
<pre><code class="prism language-docker">docker run -d -p 3000:8080 -e OLLAMA_BASE_URL=https://example.com -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:main
</code></pre> 
<ul><li><a href="http://localhost:3000/" rel="nofollow">安装完成后，您可以通过http://localhost:3000</a> 访问OpenWebUI</li></ul> 
<p><img src="https://images2.imgbox.com/35/40/sksBvETa_o.png" alt="image.png"></p> 
<p>这个时候会发现【Select a model】可以选择我们刚刚下载好的模型：</p> 
<p><img src="https://images2.imgbox.com/77/ef/nbFxava8_o.png" alt="image.png"></p> 
<p>这样我们就有了一个类似GPT的可视化界面</p> 
<p><img src="https://images2.imgbox.com/a0/5b/Ta899dlb_o.png" alt="image.png"></p> 
<p>并且他还可以一次性加入多个模型，一起对话对比使用：</p> 
<p><img src="https://images2.imgbox.com/b7/2c/mISvw4yZ_o.png" alt="image.png"></p> 
<h4><a id="_Modelfiles_115"></a>使用 Modelfiles</h4> 
<p>可以自行按要求创建，也可去官网<a href="https://openwebui.com/" rel="nofollow">社区</a>快速设置其他用户创建好的Modelfiles。</p> 
<p><img src="https://images2.imgbox.com/10/03/7axlUED9_o.png" alt="image.png"></p> 
<p><img src="https://images2.imgbox.com/83/15/rwV23SPa_o.png" alt="image.png"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/ee382821007ee47dd4fe8e50749640c8/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【课程设计/毕业设计】python酒店客房管理系统源码&#43;开发文档</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/52e7567ec6afec50c46cc9dc2b0a8202/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Xcode发布AppStore与TestFlight全流程</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>