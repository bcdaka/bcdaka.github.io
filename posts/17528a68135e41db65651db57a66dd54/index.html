<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Hadoop平台安装及运行————详细版搭建流程 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/17528a68135e41db65651db57a66dd54/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="Hadoop平台安装及运行————详细版搭建流程">
  <meta property="og:description" content="目录
一、Hadoop平台安装
一、配置 Linux 系统基础环境
步骤一：查看服务器的 IP 地址 查看服务器的 IP 地址
步骤二：设置服务器的主机名称
步骤三：绑定主机名与 IP 地址
步骤四：查看 SSH 服务状态
步骤五：关闭防火墙
步骤六：创建 hadoop 用户
二：安装 JAVA 环境
步骤一：安装 JDK
步骤二：设置 JAVA 环境变量
二、安装 Hadoop 软件
一、安装 Hadoop 软件
步骤一：安装 Hadoop 软件
步骤二：配置 Hadoop 环境变量
步骤三：修改目录所有者和所有者组
三、安装单机版 Hadoop 系统
一：配置 Hadoop 配置文件
二：测试 Hadoop 本地模式的运行
步骤一: 切换到 hadoop 用户
步骤二: 创建输入数据存放目录
步骤三: 创建数据输入文件
步骤四: 测试 MapReduce 运行
四、Hadoop平台环境配置
一：实验环境下集群网络配置
二：SSH 无密码验证配置
一、生成 SSH 密钥">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-04-24T22:06:02+08:00">
    <meta property="article:modified_time" content="2024-04-24T22:06:02+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Hadoop平台安装及运行————详细版搭建流程</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p id="main-toc"><strong>目录</strong></p> 
<p id="%E4%B8%80%E3%80%81Hadoop%E5%B9%B3%E5%8F%B0%E5%AE%89%E8%A3%85-toc" style="margin-left:0px;"><a href="#%E4%B8%80%E3%80%81Hadoop%E5%B9%B3%E5%8F%B0%E5%AE%89%E8%A3%85" rel="nofollow">一、Hadoop平台安装</a></p> 
<p id="%E4%B8%80%E3%80%81%E9%85%8D%E7%BD%AE%20Linux%20%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83-toc" style="margin-left:40px;"><a href="#%E4%B8%80%E3%80%81%E9%85%8D%E7%BD%AE%20Linux%20%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83" rel="nofollow">一、配置 Linux 系统基础环境</a></p> 
<p id="%E6%AD%A5%E9%AA%A4%E4%B8%80%EF%BC%9A%E6%9F%A5%E7%9C%8B%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%20IP%20%E5%9C%B0%E5%9D%80%20%E6%9F%A5%E7%9C%8B%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%20IP%20%E5%9C%B0%E5%9D%80-toc" style="margin-left:80px;"><a href="#%E6%AD%A5%E9%AA%A4%E4%B8%80%EF%BC%9A%E6%9F%A5%E7%9C%8B%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%20IP%20%E5%9C%B0%E5%9D%80%20%E6%9F%A5%E7%9C%8B%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%20IP%20%E5%9C%B0%E5%9D%80" rel="nofollow">步骤一：查看服务器的 IP 地址 查看服务器的 IP 地址</a></p> 
<p id="%E6%AD%A5%E9%AA%A4%E4%BA%8C%EF%BC%9A%E8%AE%BE%E7%BD%AE%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E4%B8%BB%E6%9C%BA%E5%90%8D%E7%A7%B0-toc" style="margin-left:80px;"><a href="#%E6%AD%A5%E9%AA%A4%E4%BA%8C%EF%BC%9A%E8%AE%BE%E7%BD%AE%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E4%B8%BB%E6%9C%BA%E5%90%8D%E7%A7%B0" rel="nofollow">步骤二：设置服务器的主机名称</a></p> 
<p id="%E6%AD%A5%E9%AA%A4%E4%B8%89%EF%BC%9A%E7%BB%91%E5%AE%9A%E4%B8%BB%E6%9C%BA%E5%90%8D%E4%B8%8E%20IP%20%E5%9C%B0%E5%9D%80-toc" style="margin-left:80px;"><a href="#%E6%AD%A5%E9%AA%A4%E4%B8%89%EF%BC%9A%E7%BB%91%E5%AE%9A%E4%B8%BB%E6%9C%BA%E5%90%8D%E4%B8%8E%20IP%20%E5%9C%B0%E5%9D%80" rel="nofollow">步骤三：绑定主机名与 IP 地址</a></p> 
<p id="%E6%AD%A5%E9%AA%A4%E5%9B%9B%EF%BC%9A%E6%9F%A5%E7%9C%8B%20SSH%20%E6%9C%8D%E5%8A%A1%E7%8A%B6%E6%80%81-toc" style="margin-left:80px;"><a href="#%E6%AD%A5%E9%AA%A4%E5%9B%9B%EF%BC%9A%E6%9F%A5%E7%9C%8B%20SSH%20%E6%9C%8D%E5%8A%A1%E7%8A%B6%E6%80%81" rel="nofollow">步骤四：查看 SSH 服务状态</a></p> 
<p id="%E6%AD%A5%E9%AA%A4%E4%BA%94%EF%BC%9A%E5%85%B3%E9%97%AD%E9%98%B2%E7%81%AB%E5%A2%99-toc" style="margin-left:80px;"><a href="#%E6%AD%A5%E9%AA%A4%E4%BA%94%EF%BC%9A%E5%85%B3%E9%97%AD%E9%98%B2%E7%81%AB%E5%A2%99" rel="nofollow">步骤五：关闭防火墙</a></p> 
<p id="%E6%AD%A5%E9%AA%A4%E5%85%AD%EF%BC%9A%E5%88%9B%E5%BB%BA%20hadoop%20%E7%94%A8%E6%88%B7-toc" style="margin-left:80px;"><a href="#%E6%AD%A5%E9%AA%A4%E5%85%AD%EF%BC%9A%E5%88%9B%E5%BB%BA%20hadoop%20%E7%94%A8%E6%88%B7" rel="nofollow">步骤六：创建 hadoop 用户</a></p> 
<p id="%E4%BA%8C%EF%BC%9A%E5%AE%89%E8%A3%85%20JAVA%20%E7%8E%AF%E5%A2%83-toc" style="margin-left:40px;"><a href="#%E4%BA%8C%EF%BC%9A%E5%AE%89%E8%A3%85%20JAVA%20%E7%8E%AF%E5%A2%83" rel="nofollow">二：安装 JAVA 环境</a></p> 
<p id="%E6%AD%A5%E9%AA%A4%E4%B8%80%EF%BC%9A%E5%AE%89%E8%A3%85%20JDK-toc" style="margin-left:80px;"><a href="#%E6%AD%A5%E9%AA%A4%E4%B8%80%EF%BC%9A%E5%AE%89%E8%A3%85%20JDK" rel="nofollow">步骤一：安装 JDK</a></p> 
<p id="%E6%AD%A5%E9%AA%A4%E4%BA%8C%EF%BC%9A%E8%AE%BE%E7%BD%AE%20JAVA%20%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F-toc" style="margin-left:80px;"><a href="#%E6%AD%A5%E9%AA%A4%E4%BA%8C%EF%BC%9A%E8%AE%BE%E7%BD%AE%20JAVA%20%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F" rel="nofollow">步骤二：设置 JAVA 环境变量</a></p> 
<p id="%E4%BA%8C%E3%80%81%E5%AE%89%E8%A3%85%20Hadoop%20%E8%BD%AF%E4%BB%B6-toc" style="margin-left:0px;"><a href="#%E4%BA%8C%E3%80%81%E5%AE%89%E8%A3%85%20Hadoop%20%E8%BD%AF%E4%BB%B6" rel="nofollow">二、安装 Hadoop 软件</a></p> 
<p id="%E4%B8%80%E3%80%81%E5%AE%89%E8%A3%85%20Hadoop%20%E8%BD%AF%E4%BB%B6-toc" style="margin-left:40px;"><a href="#%E4%B8%80%E3%80%81%E5%AE%89%E8%A3%85%20Hadoop%20%E8%BD%AF%E4%BB%B6" rel="nofollow">一、安装 Hadoop 软件</a></p> 
<p id="%E6%AD%A5%E9%AA%A4%E4%B8%80%EF%BC%9A%E5%AE%89%E8%A3%85%20Hadoop%20%E8%BD%AF%E4%BB%B6-toc" style="margin-left:80px;"><a href="#%E6%AD%A5%E9%AA%A4%E4%B8%80%EF%BC%9A%E5%AE%89%E8%A3%85%20Hadoop%20%E8%BD%AF%E4%BB%B6" rel="nofollow">步骤一：安装 Hadoop 软件</a></p> 
<p id="%E6%AD%A5%E9%AA%A4%E4%BA%8C%EF%BC%9A%E9%85%8D%E7%BD%AE%20Hadoop%20%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F-toc" style="margin-left:80px;"><a href="#%E6%AD%A5%E9%AA%A4%E4%BA%8C%EF%BC%9A%E9%85%8D%E7%BD%AE%20Hadoop%20%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F" rel="nofollow">步骤二：配置 Hadoop 环境变量</a></p> 
<p id="%E6%AD%A5%E9%AA%A4%E4%B8%89%EF%BC%9A%E4%BF%AE%E6%94%B9%E7%9B%AE%E5%BD%95%E6%89%80%E6%9C%89%E8%80%85%E5%92%8C%E6%89%80%E6%9C%89%E8%80%85%E7%BB%84-toc" style="margin-left:80px;"><a href="#%E6%AD%A5%E9%AA%A4%E4%B8%89%EF%BC%9A%E4%BF%AE%E6%94%B9%E7%9B%AE%E5%BD%95%E6%89%80%E6%9C%89%E8%80%85%E5%92%8C%E6%89%80%E6%9C%89%E8%80%85%E7%BB%84" rel="nofollow">步骤三：修改目录所有者和所有者组</a></p> 
<p id="%E4%B8%89%E3%80%81%E5%AE%89%E8%A3%85%E5%8D%95%E6%9C%BA%E7%89%88%20Hadoop%20%E7%B3%BB%E7%BB%9F-toc" style="margin-left:0px;"><a href="#%E4%B8%89%E3%80%81%E5%AE%89%E8%A3%85%E5%8D%95%E6%9C%BA%E7%89%88%20Hadoop%20%E7%B3%BB%E7%BB%9F" rel="nofollow">三、安装单机版 Hadoop 系统</a></p> 
<p id="%E4%B8%80%EF%BC%9A%E9%85%8D%E7%BD%AE%20Hadoop%20%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6-toc" style="margin-left:40px;"><a href="#%E4%B8%80%EF%BC%9A%E9%85%8D%E7%BD%AE%20Hadoop%20%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6" rel="nofollow">一：配置 Hadoop 配置文件</a></p> 
<p id="%E4%BA%8C%EF%BC%9A%E6%B5%8B%E8%AF%95%20Hadoop%20%E6%9C%AC%E5%9C%B0%E6%A8%A1%E5%BC%8F%E7%9A%84%E8%BF%90%E8%A1%8C-toc" style="margin-left:40px;"><a href="#%E4%BA%8C%EF%BC%9A%E6%B5%8B%E8%AF%95%20Hadoop%20%E6%9C%AC%E5%9C%B0%E6%A8%A1%E5%BC%8F%E7%9A%84%E8%BF%90%E8%A1%8C" rel="nofollow">二：测试 Hadoop 本地模式的运行</a></p> 
<p id="%E6%AD%A5%E9%AA%A4%E4%B8%80%3A%20%E5%88%87%E6%8D%A2%E5%88%B0%20hadoop%20%E7%94%A8%E6%88%B7-toc" style="margin-left:80px;"><a href="#%E6%AD%A5%E9%AA%A4%E4%B8%80%3A%20%E5%88%87%E6%8D%A2%E5%88%B0%20hadoop%20%E7%94%A8%E6%88%B7" rel="nofollow">步骤一: 切换到 hadoop 用户</a></p> 
<p id="%E6%AD%A5%E9%AA%A4%E4%BA%8C%3A%20%E5%88%9B%E5%BB%BA%E8%BE%93%E5%85%A5%E6%95%B0%E6%8D%AE%E5%AD%98%E6%94%BE%E7%9B%AE%E5%BD%95-toc" style="margin-left:80px;"><a href="#%E6%AD%A5%E9%AA%A4%E4%BA%8C%3A%20%E5%88%9B%E5%BB%BA%E8%BE%93%E5%85%A5%E6%95%B0%E6%8D%AE%E5%AD%98%E6%94%BE%E7%9B%AE%E5%BD%95" rel="nofollow">步骤二: 创建输入数据存放目录</a></p> 
<p id="%E6%AD%A5%E9%AA%A4%E4%B8%89%3A%20%E5%88%9B%E5%BB%BA%E6%95%B0%E6%8D%AE%E8%BE%93%E5%85%A5%E6%96%87%E4%BB%B6-toc" style="margin-left:80px;"><a href="#%E6%AD%A5%E9%AA%A4%E4%B8%89%3A%20%E5%88%9B%E5%BB%BA%E6%95%B0%E6%8D%AE%E8%BE%93%E5%85%A5%E6%96%87%E4%BB%B6" rel="nofollow">步骤三: 创建数据输入文件</a></p> 
<p id="%E6%AD%A5%E9%AA%A4%E5%9B%9B%3A%20%E6%B5%8B%E8%AF%95%20MapReduce%20%E8%BF%90%E8%A1%8C-toc" style="margin-left:80px;"><a href="#%E6%AD%A5%E9%AA%A4%E5%9B%9B%3A%20%E6%B5%8B%E8%AF%95%20MapReduce%20%E8%BF%90%E8%A1%8C" rel="nofollow">步骤四: 测试 MapReduce 运行</a></p> 
<p id="%E5%9B%9B%E3%80%81Hadoop%E5%B9%B3%E5%8F%B0%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE-toc" style="margin-left:0px;"><a href="#%E5%9B%9B%E3%80%81Hadoop%E5%B9%B3%E5%8F%B0%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE" rel="nofollow">四、Hadoop平台环境配置</a></p> 
<p id="%E4%B8%80%EF%BC%9A%E5%AE%9E%E9%AA%8C%E7%8E%AF%E5%A2%83%E4%B8%8B%E9%9B%86%E7%BE%A4%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE-toc" style="margin-left:40px;"><a href="#%E4%B8%80%EF%BC%9A%E5%AE%9E%E9%AA%8C%E7%8E%AF%E5%A2%83%E4%B8%8B%E9%9B%86%E7%BE%A4%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE" rel="nofollow">一：实验环境下集群网络配置</a></p> 
<p id="%E4%BA%8C%EF%BC%9ASSH%20%E6%97%A0%E5%AF%86%E7%A0%81%E9%AA%8C%E8%AF%81%E9%85%8D%E7%BD%AE-toc" style="margin-left:40px;"><a href="#%E4%BA%8C%EF%BC%9ASSH%20%E6%97%A0%E5%AF%86%E7%A0%81%E9%AA%8C%E8%AF%81%E9%85%8D%E7%BD%AE" rel="nofollow">二：SSH 无密码验证配置</a></p> 
<p id="%E4%B8%80%E3%80%81%E7%94%9F%E6%88%90%20SSH%20%E5%AF%86%E9%92%A5-toc" style="margin-left:80px;"><a href="#%E4%B8%80%E3%80%81%E7%94%9F%E6%88%90%20SSH%20%E5%AF%86%E9%92%A5" rel="nofollow">一、生成 SSH 密钥</a></p> 
<p id="%E6%AD%A5%E9%AA%A4%E4%B8%80%EF%BC%9A%E6%AF%8F%E4%B8%AA%E8%8A%82%E7%82%B9%E5%AE%89%E8%A3%85%E5%92%8C%E5%90%AF%E5%8A%A8%20SSH%20%E5%8D%8F%E8%AE%AE-toc" style="margin-left:80px;"><a href="#%E6%AD%A5%E9%AA%A4%E4%B8%80%EF%BC%9A%E6%AF%8F%E4%B8%AA%E8%8A%82%E7%82%B9%E5%AE%89%E8%A3%85%E5%92%8C%E5%90%AF%E5%8A%A8%20SSH%20%E5%8D%8F%E8%AE%AE" rel="nofollow">步骤一：每个节点安装和启动 SSH 协议</a></p> 
<p id="%E6%AD%A5%E9%AA%A4%E4%BA%8C%EF%BC%9A%E5%88%87%E6%8D%A2%E5%88%B0%20hadoop%20%E7%94%A8%E6%88%B7-toc" style="margin-left:80px;"><a href="#%E6%AD%A5%E9%AA%A4%E4%BA%8C%EF%BC%9A%E5%88%87%E6%8D%A2%E5%88%B0%20hadoop%20%E7%94%A8%E6%88%B7" rel="nofollow">步骤二：切换到 hadoop 用户</a></p> 
<p id="%E6%AD%A5%E9%AA%A4%E4%B8%89%EF%BC%9A%E6%AF%8F%E4%B8%AA%E8%8A%82%E7%82%B9%E7%94%9F%E6%88%90%E7%A7%98%E9%92%A5%E5%AF%B9-toc" style="margin-left:80px;"><a href="#%E6%AD%A5%E9%AA%A4%E4%B8%89%EF%BC%9A%E6%AF%8F%E4%B8%AA%E8%8A%82%E7%82%B9%E7%94%9F%E6%88%90%E7%A7%98%E9%92%A5%E5%AF%B9" rel="nofollow">步骤三：每个节点生成秘钥对</a></p> 
<p id="%E6%AD%A5%E9%AA%A4%E5%9B%9B%EF%BC%9A%E6%9F%A5%E7%9C%8B%22%2Fhome%2Fhadoop%2F%22%E4%B8%8B%E6%98%AF%E5%90%A6%E6%9C%89%22.ssh%22%E6%96%87%E4%BB%B6%E5%A4%B9-toc" style="margin-left:80px;"><a href="#%E6%AD%A5%E9%AA%A4%E5%9B%9B%EF%BC%9A%E6%9F%A5%E7%9C%8B%22%2Fhome%2Fhadoop%2F%22%E4%B8%8B%E6%98%AF%E5%90%A6%E6%9C%89%22.ssh%22%E6%96%87%E4%BB%B6%E5%A4%B9" rel="nofollow">步骤四：查看"/home/hadoop/"下是否有".ssh"文件夹</a></p> 
<p id="%E6%AD%A5%E9%AA%A4%E4%BA%94%EF%BC%9A%E5%B0%86%20id_rsa.pub%20%E8%BF%BD%E5%8A%A0%E5%88%B0%E6%8E%88%E6%9D%83%20key%20%E6%96%87%E4%BB%B6%E4%B8%AD-toc" style="margin-left:80px;"><a href="#%E6%AD%A5%E9%AA%A4%E4%BA%94%EF%BC%9A%E5%B0%86%20id_rsa.pub%20%E8%BF%BD%E5%8A%A0%E5%88%B0%E6%8E%88%E6%9D%83%20key%20%E6%96%87%E4%BB%B6%E4%B8%AD" rel="nofollow">步骤五：将 id_rsa.pub 追加到授权 key 文件中</a></p> 
<p id="%E6%AD%A5%E9%AA%A4%E5%85%AD%EF%BC%9A%E4%BF%AE%E6%94%B9%E6%96%87%E4%BB%B6%22authorized_keys%22%E6%9D%83%E9%99%90-toc" style="margin-left:80px;"><a href="#%E6%AD%A5%E9%AA%A4%E5%85%AD%EF%BC%9A%E4%BF%AE%E6%94%B9%E6%96%87%E4%BB%B6%22authorized_keys%22%E6%9D%83%E9%99%90" rel="nofollow">步骤六：修改文件"authorized_keys"权限</a></p> 
<p id="%E6%AD%A5%E9%AA%A4%E4%B8%83%EF%BC%9A%E9%85%8D%E7%BD%AE%20SSH%20%E6%9C%8D%E5%8A%A1-toc" style="margin-left:80px;"><a href="#%E6%AD%A5%E9%AA%A4%E4%B8%83%EF%BC%9A%E9%85%8D%E7%BD%AE%20SSH%20%E6%9C%8D%E5%8A%A1" rel="nofollow">步骤七：配置 SSH 服务</a></p> 
<p id="%E4%BA%8C%EF%BC%9A%E4%BA%A4%E6%8D%A2%20SSH%20%E5%AF%86%E9%92%A5-toc" style="margin-left:40px;"><a href="#%E4%BA%8C%EF%BC%9A%E4%BA%A4%E6%8D%A2%20SSH%20%E5%AF%86%E9%92%A5" rel="nofollow">二：交换 SSH 密钥</a></p> 
<p id="%E6%AD%A5%E9%AA%A4%E4%B8%80%EF%BC%9A%E5%B0%86%20Master%20%E8%8A%82%E7%82%B9%E7%9A%84%E5%85%AC%E9%92%A5%20id_rsa.pub%20%E5%A4%8D%E5%88%B6%E5%88%B0%E6%AF%8F%E4%B8%AA%20Slave%20%E7%82%B9-toc" style="margin-left:80px;"><a href="#%E6%AD%A5%E9%AA%A4%E4%B8%80%EF%BC%9A%E5%B0%86%20Master%20%E8%8A%82%E7%82%B9%E7%9A%84%E5%85%AC%E9%92%A5%20id_rsa.pub%20%E5%A4%8D%E5%88%B6%E5%88%B0%E6%AF%8F%E4%B8%AA%20Slave%20%E7%82%B9" rel="nofollow">步骤一：将 Master 节点的公钥 id_rsa.pub 复制到每个 Slave 点</a></p> 
<p id="%E6%AD%A5%E9%AA%A4%E4%BA%8C%EF%BC%9A%E5%9C%A8%E6%AF%8F%E4%B8%AA%20Slave%20%E8%8A%82%E7%82%B9%E6%8A%8A%20Master%20%E8%8A%82%E7%82%B9%E5%A4%8D%E5%88%B6%E7%9A%84%E5%85%AC%E9%92%A5%E5%A4%8D%E5%88%B6%E5%88%B0authorized_keys%20%E6%96%87%E4%BB%B6-toc" style="margin-left:80px;"><a href="#%E6%AD%A5%E9%AA%A4%E4%BA%8C%EF%BC%9A%E5%9C%A8%E6%AF%8F%E4%B8%AA%20Slave%20%E8%8A%82%E7%82%B9%E6%8A%8A%20Master%20%E8%8A%82%E7%82%B9%E5%A4%8D%E5%88%B6%E7%9A%84%E5%85%AC%E9%92%A5%E5%A4%8D%E5%88%B6%E5%88%B0authorized_keys%20%E6%96%87%E4%BB%B6" rel="nofollow">步骤二：在每个 Slave 节点把 Master 节点复制的公钥复制到authorized_keys 文件</a></p> 
<p id="%E6%AD%A5%E9%AA%A4%E4%B8%89%EF%BC%9A%E5%9C%A8%E6%AF%8F%E4%B8%AA%20Slave%20%E8%8A%82%E7%82%B9%E5%88%A0%E9%99%A4%20id_rsa.pub%20%E6%96%87%E4%BB%B6-toc" style="margin-left:80px;"><a href="#%E6%AD%A5%E9%AA%A4%E4%B8%89%EF%BC%9A%E5%9C%A8%E6%AF%8F%E4%B8%AA%20Slave%20%E8%8A%82%E7%82%B9%E5%88%A0%E9%99%A4%20id_rsa.pub%20%E6%96%87%E4%BB%B6" rel="nofollow">步骤三：在每个 Slave 节点删除 id_rsa.pub 文件</a></p> 
<p id="%E6%AD%A5%E9%AA%A4%E5%9B%9B%EF%BC%9A%E5%B0%86%E6%AF%8F%E4%B8%AA%20Slave%20%E8%8A%82%E7%82%B9%E7%9A%84%E5%85%AC%E9%92%A5%E4%BF%9D%E5%AD%98%E5%88%B0%20Master-toc" style="margin-left:80px;"><a href="#%E6%AD%A5%E9%AA%A4%E5%9B%9B%EF%BC%9A%E5%B0%86%E6%AF%8F%E4%B8%AA%20Slave%20%E8%8A%82%E7%82%B9%E7%9A%84%E5%85%AC%E9%92%A5%E4%BF%9D%E5%AD%98%E5%88%B0%20Master" rel="nofollow">步骤四：将每个 Slave 节点的公钥保存到 Master</a></p> 
<p id="%E4%B8%89%EF%BC%9A%E9%AA%8C%E8%AF%81%20SSH%20%E6%97%A0%E5%AF%86%E7%A0%81%E7%99%BB%E5%BD%95-toc" style="margin-left:40px;"><a href="#%E4%B8%89%EF%BC%9A%E9%AA%8C%E8%AF%81%20SSH%20%E6%97%A0%E5%AF%86%E7%A0%81%E7%99%BB%E5%BD%95" rel="nofollow">三：验证 SSH 无密码登录</a></p> 
<p id="%E6%AD%A5%E9%AA%A4%E4%B8%80%EF%BC%9A%E6%9F%A5%E7%9C%8B%20Master%20%E8%8A%82%E7%82%B9%20authorized_keys%20%E6%96%87%E4%BB%B6-toc" style="margin-left:80px;"><a href="#%E6%AD%A5%E9%AA%A4%E4%B8%80%EF%BC%9A%E6%9F%A5%E7%9C%8B%20Master%20%E8%8A%82%E7%82%B9%20authorized_keys%20%E6%96%87%E4%BB%B6" rel="nofollow">步骤一：查看 Master 节点 authorized_keys 文件</a></p> 
<p id="%E6%AD%A5%E9%AA%A4%E4%BA%8C%EF%BC%9A%E6%9F%A5%E7%9C%8B%20Slave%20%E8%8A%82%E7%82%B9%20authorized_keys%20%E6%96%87%E4%BB%B6-toc" style="margin-left:80px;"><a href="#%E6%AD%A5%E9%AA%A4%E4%BA%8C%EF%BC%9A%E6%9F%A5%E7%9C%8B%20Slave%20%E8%8A%82%E7%82%B9%20authorized_keys%20%E6%96%87%E4%BB%B6" rel="nofollow">步骤二：查看 Slave 节点 authorized_keys 文件</a></p> 
<p id="%E6%AD%A5%E9%AA%A4%E4%B8%89%EF%BC%9A%E9%AA%8C%E8%AF%81%20Master%20%E5%88%B0%E6%AF%8F%E4%B8%AA%20Slave%20%E8%8A%82%E7%82%B9%E6%97%A0%E5%AF%86%E7%A0%81%E7%99%BB%E5%BD%95-toc" style="margin-left:80px;"><a href="#%E6%AD%A5%E9%AA%A4%E4%B8%89%EF%BC%9A%E9%AA%8C%E8%AF%81%20Master%20%E5%88%B0%E6%AF%8F%E4%B8%AA%20Slave%20%E8%8A%82%E7%82%B9%E6%97%A0%E5%AF%86%E7%A0%81%E7%99%BB%E5%BD%95" rel="nofollow">步骤三：验证 Master 到每个 Slave 节点无密码登录</a></p> 
<p id="%E6%AD%A5%E9%AA%A4%E5%9B%9B%EF%BC%9A%E9%AA%8C%E8%AF%81%E4%B8%A4%E4%B8%AA%20Slave%20%E8%8A%82%E7%82%B9%E5%88%B0%20Master%20%E8%8A%82%E7%82%B9%E6%97%A0%E5%AF%86%E7%A0%81%E7%99%BB%E5%BD%95-toc" style="margin-left:80px;"><a href="#%E6%AD%A5%E9%AA%A4%E5%9B%9B%EF%BC%9A%E9%AA%8C%E8%AF%81%E4%B8%A4%E4%B8%AA%20Slave%20%E8%8A%82%E7%82%B9%E5%88%B0%20Master%20%E8%8A%82%E7%82%B9%E6%97%A0%E5%AF%86%E7%A0%81%E7%99%BB%E5%BD%95" rel="nofollow">步骤四：验证两个 Slave 节点到 Master 节点无密码登录</a></p> 
<p id="%E6%AD%A5%E9%AA%A4%E4%BA%94%EF%BC%9A%E9%85%8D%E7%BD%AE%E4%B8%A4%E4%B8%AA%E5%AD%90%E8%8A%82%E7%82%B9slave1%E3%80%81slave2%E7%9A%84JDK%E7%8E%AF%E5%A2%83%E3%80%82-toc" style="margin-left:80px;"><a href="#%E6%AD%A5%E9%AA%A4%E4%BA%94%EF%BC%9A%E9%85%8D%E7%BD%AE%E4%B8%A4%E4%B8%AA%E5%AD%90%E8%8A%82%E7%82%B9slave1%E3%80%81slave2%E7%9A%84JDK%E7%8E%AF%E5%A2%83%E3%80%82" rel="nofollow">步骤五：配置两个子节点slave1、slave2的JDK环境。</a></p> 
<p id="%E4%BA%94%E3%80%81Hadoop%E9%9B%86%E7%BE%A4%E8%BF%90%E8%A1%8C-toc" style="margin-left:0px;"><a href="#%E4%BA%94%E3%80%81Hadoop%E9%9B%86%E7%BE%A4%E8%BF%90%E8%A1%8C" rel="nofollow">五、Hadoop集群运行</a></p> 
<p id="1%E3%80%81Hadoop%E6%96%87%E4%BB%B6%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE-toc" style="margin-left:40px;"><a href="#1%E3%80%81Hadoop%E6%96%87%E4%BB%B6%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE" rel="nofollow">1、Hadoop文件参数配置</a></p> 
<p id="%E4%B8%80%EF%BC%9A%E5%9C%A8%20Master%20%E8%8A%82%E7%82%B9%E4%B8%8A%E5%AE%89%E8%A3%85%20Hadoop-toc" style="margin-left:80px;"><a href="#%E4%B8%80%EF%BC%9A%E5%9C%A8%20Master%20%E8%8A%82%E7%82%B9%E4%B8%8A%E5%AE%89%E8%A3%85%20Hadoop" rel="nofollow">一：在 Master 节点上安装 Hadoop</a></p> 
<p id="1.%20%E5%B0%86%20hadoop-2.7.1%20%E6%96%87%E4%BB%B6%E5%A4%B9%E9%87%8D%E5%91%BD%E5%90%8D%E4%B8%BA%20Hadoop-toc" style="margin-left:120px;"><a href="#1.%20%E5%B0%86%20hadoop-2.7.1%20%E6%96%87%E4%BB%B6%E5%A4%B9%E9%87%8D%E5%91%BD%E5%90%8D%E4%B8%BA%20Hadoop" rel="nofollow">1. 将 hadoop-2.7.1 文件夹重命名为 Hadoop</a></p> 
<p id="2.%20%E9%85%8D%E7%BD%AE%20Hadoop%20%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F-toc" style="margin-left:120px;"><a href="#2.%20%E9%85%8D%E7%BD%AE%20Hadoop%20%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F" rel="nofollow">2. 配置 Hadoop 环境变量</a></p> 
<p id="3.%20%E4%BD%BF%E9%85%8D%E7%BD%AE%E7%9A%84%20Hadoop%20%E7%9A%84%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E7%94%9F%E6%95%88-toc" style="margin-left:120px;"><a href="#3.%20%E4%BD%BF%E9%85%8D%E7%BD%AE%E7%9A%84%20Hadoop%20%E7%9A%84%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E7%94%9F%E6%95%88" rel="nofollow">3. 使配置的 Hadoop 的环境变量生效</a></p> 
<p id="4.%20%E6%89%A7%E8%A1%8C%E4%BB%A5%E4%B8%8B%E5%91%BD%E4%BB%A4%E4%BF%AE%E6%94%B9%20hadoop-env.sh%20%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6-toc" style="margin-left:120px;"><a href="#4.%20%E6%89%A7%E8%A1%8C%E4%BB%A5%E4%B8%8B%E5%91%BD%E4%BB%A4%E4%BF%AE%E6%94%B9%20hadoop-env.sh%20%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6" rel="nofollow">4. 执行以下命令修改 hadoop-env.sh 配置文件</a></p> 
<p id="%E4%BA%8C%EF%BC%9A%E9%85%8D%E7%BD%AE%20hdfs-site.xml%20%E6%96%87%E4%BB%B6%E5%8F%82%E6%95%B0-toc" style="margin-left:80px;"><a href="#%E4%BA%8C%EF%BC%9A%E9%85%8D%E7%BD%AE%20hdfs-site.xml%20%E6%96%87%E4%BB%B6%E5%8F%82%E6%95%B0" rel="nofollow">二：配置 hdfs-site.xml 文件参数</a></p> 
<p id="%E4%B8%89%3A%E9%85%8D%E7%BD%AE%20core-site.xml%20%E6%96%87%E4%BB%B6%E5%8F%82%E6%95%B0-toc" style="margin-left:80px;"><a href="#%E4%B8%89%3A%E9%85%8D%E7%BD%AE%20core-site.xml%20%E6%96%87%E4%BB%B6%E5%8F%82%E6%95%B0" rel="nofollow">三:配置 core-site.xml 文件参数</a></p> 
<p id="%E5%9B%9B%3A%E9%85%8D%E7%BD%AE%20mapred-site.xml-toc" style="margin-left:80px;"><a href="#%E5%9B%9B%3A%E9%85%8D%E7%BD%AE%20mapred-site.xml" rel="nofollow">四:配置 mapred-site.xml</a></p> 
<p id="%E4%BA%94%EF%BC%9A%E9%85%8D%E7%BD%AE%20yarn-site.xml-toc" style="margin-left:80px;"><a href="#%E4%BA%94%EF%BC%9A%E9%85%8D%E7%BD%AE%20yarn-site.xml" rel="nofollow">五：配置 yarn-site.xml</a></p> 
<p id="%E5%85%AD%3AHadoop%20%E5%85%B6%E4%BB%96%E7%9B%B8%E5%85%B3%E9%85%8D%E7%BD%AE-toc" style="margin-left:80px;"><a href="#%E5%85%AD%3AHadoop%20%E5%85%B6%E4%BB%96%E7%9B%B8%E5%85%B3%E9%85%8D%E7%BD%AE" rel="nofollow">六:Hadoop 其他相关配置</a></p> 
<p id="1.%20%E9%85%8D%E7%BD%AE%20masters%20%E6%96%87%E4%BB%B6-toc" style="margin-left:120px;"><a href="#1.%20%E9%85%8D%E7%BD%AE%20masters%20%E6%96%87%E4%BB%B6" rel="nofollow">1. 配置 masters 文件</a></p> 
<p id="2.%20%E9%85%8D%E7%BD%AE%20slaves%20%E6%96%87%E4%BB%B6-toc" style="margin-left:120px;"><a href="#2.%20%E9%85%8D%E7%BD%AE%20slaves%20%E6%96%87%E4%BB%B6" rel="nofollow">2. 配置 slaves 文件</a></p> 
<p id="3.%20%E6%96%B0%E5%BB%BA%E7%9B%AE%E5%BD%95-toc" style="margin-left:120px;"><a href="#3.%20%E6%96%B0%E5%BB%BA%E7%9B%AE%E5%BD%95" rel="nofollow">3. 新建目录</a></p> 
<p id="4.%20%E4%BF%AE%E6%94%B9%E7%9B%AE%E5%BD%95%E6%9D%83%E9%99%90-toc" style="margin-left:120px;"><a href="#4.%20%E4%BF%AE%E6%94%B9%E7%9B%AE%E5%BD%95%E6%9D%83%E9%99%90" rel="nofollow">4. 修改目录权限</a></p> 
<p id="5.%20%E5%90%8C%E6%AD%A5%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E5%88%B0%20Slave%20%E8%8A%82%E7%82%B9-toc" style="margin-left:120px;"><a href="#5.%20%E5%90%8C%E6%AD%A5%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E5%88%B0%20Slave%20%E8%8A%82%E7%82%B9" rel="nofollow">5. 同步配置文件到 Slave 节点</a></p> 
<p id="2%E3%80%81%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E9%9B%86%E7%BE%A4%E8%BF%90%E8%A1%8C-toc" style="margin-left:40px;"><a href="#2%E3%80%81%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E9%9B%86%E7%BE%A4%E8%BF%90%E8%A1%8C" rel="nofollow">2、大数据平台集群运行</a></p> 
<p id="%E4%B8%80%EF%BC%9A%E9%85%8D%E7%BD%AE%20Hadoop%20%E6%A0%BC%E5%BC%8F%E5%8C%96-toc" style="margin-left:80px;"><a href="#%E4%B8%80%EF%BC%9A%E9%85%8D%E7%BD%AE%20Hadoop%20%E6%A0%BC%E5%BC%8F%E5%8C%96" rel="nofollow">一：配置 Hadoop 格式化</a></p> 
<p id="%E6%AD%A5%E9%AA%A4%E4%B8%80%EF%BC%9ANameNode%20%E6%A0%BC%E5%BC%8F%E5%8C%96-toc" style="margin-left:120px;"><a href="#%E6%AD%A5%E9%AA%A4%E4%B8%80%EF%BC%9ANameNode%20%E6%A0%BC%E5%BC%8F%E5%8C%96" rel="nofollow">步骤一：NameNode 格式化</a></p> 
<p id="%E6%AD%A5%E9%AA%A4%E4%BA%8C%EF%BC%9A%E5%90%AF%E5%8A%A8%20NameNode-toc" style="margin-left:120px;"><a href="#%E6%AD%A5%E9%AA%A4%E4%BA%8C%EF%BC%9A%E5%90%AF%E5%8A%A8%20NameNode" rel="nofollow">步骤二：启动 NameNode</a></p> 
<p id="%E4%BA%8C%EF%BC%9A%E6%9F%A5%E7%9C%8B%20Java%20%E8%BF%9B%E7%A8%8B-toc" style="margin-left:80px;"><a href="#%E4%BA%8C%EF%BC%9A%E6%9F%A5%E7%9C%8B%20Java%20%E8%BF%9B%E7%A8%8B" rel="nofollow">二：查看 Java 进程</a></p> 
<p id="%E6%AD%A5%E9%AA%A4%E4%B8%80%EF%BC%9Aslave%E8%8A%82%E7%82%B9%20%E5%90%AF%E5%8A%A8%20DataNode-toc" style="margin-left:120px;"><a href="#%E6%AD%A5%E9%AA%A4%E4%B8%80%EF%BC%9Aslave%E8%8A%82%E7%82%B9%20%E5%90%AF%E5%8A%A8%20DataNode" rel="nofollow">步骤一：slave节点 启动 DataNode</a></p> 
<p id="%E6%AD%A5%E9%AA%A4%E4%BA%8C%EF%BC%9A%E5%90%AF%E5%8A%A8%20SecondaryNameNode-toc" style="margin-left:120px;"><a href="#%E6%AD%A5%E9%AA%A4%E4%BA%8C%EF%BC%9A%E5%90%AF%E5%8A%A8%20SecondaryNameNode" rel="nofollow">步骤二：启动 SecondaryNameNode</a></p> 
<p id="%E6%AD%A5%E9%AA%A4%E4%B8%89%EF%BC%9A%E6%9F%A5%E7%9C%8B%20HDFS%20%E6%95%B0%E6%8D%AE%E5%AD%98%E6%94%BE%E4%BD%8D%E7%BD%AE-toc" style="margin-left:120px;"><a href="#%E6%AD%A5%E9%AA%A4%E4%B8%89%EF%BC%9A%E6%9F%A5%E7%9C%8B%20HDFS%20%E6%95%B0%E6%8D%AE%E5%AD%98%E6%94%BE%E4%BD%8D%E7%BD%AE" rel="nofollow">步骤三：查看 HDFS 数据存放位置</a></p> 
<p id="%E4%B8%89%EF%BC%9A%E6%9F%A5%E7%9C%8B%20HDFS%20%E7%9A%84%E6%8A%A5%E5%91%8A-toc" style="margin-left:80px;"><a href="#%E4%B8%89%EF%BC%9A%E6%9F%A5%E7%9C%8B%20HDFS%20%E7%9A%84%E6%8A%A5%E5%91%8A" rel="nofollow">三：查看 HDFS 的报告</a></p> 
<p id="%E5%9B%9B%EF%BC%9A%E4%BD%BF%E7%94%A8%E6%B5%8F%E8%A7%88%E5%99%A8%E6%9F%A5%E7%9C%8B%E8%8A%82%E7%82%B9%E7%8A%B6%E6%80%81-toc" style="margin-left:80px;"><a href="#%E5%9B%9B%EF%BC%9A%E4%BD%BF%E7%94%A8%E6%B5%8F%E8%A7%88%E5%99%A8%E6%9F%A5%E7%9C%8B%E8%8A%82%E7%82%B9%E7%8A%B6%E6%80%81" rel="nofollow">四：使用浏览器查看节点状态</a></p> 
<p id="%E6%AD%A5%E9%AA%A4%E4%B8%80%EF%BC%9A%E5%9C%A8%20HDFS%20%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%B8%AD%E5%88%9B%E5%BB%BA%E6%95%B0%E6%8D%AE%E8%BE%93%E5%85%A5%E7%9B%AE%E5%BD%95%20%E7%A1%AE%E4%BF%9D%20dfs%20%E5%92%8C%20yarn%20%E9%83%BD%E5%90%AF%E5%8A%A8%E6%88%90%E5%8A%9F-toc" style="margin-left:120px;"><a href="#%E6%AD%A5%E9%AA%A4%E4%B8%80%EF%BC%9A%E5%9C%A8%20HDFS%20%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%B8%AD%E5%88%9B%E5%BB%BA%E6%95%B0%E6%8D%AE%E8%BE%93%E5%85%A5%E7%9B%AE%E5%BD%95%20%E7%A1%AE%E4%BF%9D%20dfs%20%E5%92%8C%20yarn%20%E9%83%BD%E5%90%AF%E5%8A%A8%E6%88%90%E5%8A%9F" rel="nofollow">步骤一：在 HDFS 文件系统中创建数据输入目录 确保 dfs 和 yarn 都启动成功</a></p> 
<p id="%E6%AD%A5%E9%AA%A4%E4%BA%8C%EF%BC%9A%E5%B0%86%E8%BE%93%E5%85%A5%E6%95%B0%E6%8D%AE%E6%96%87%E4%BB%B6%E5%A4%8D%E5%88%B6%E5%88%B0%20HDFS%20%E7%9A%84%2Finput%20%E7%9B%AE%E5%BD%95%E4%B8%AD-toc" style="margin-left:120px;"><a href="#%E6%AD%A5%E9%AA%A4%E4%BA%8C%EF%BC%9A%E5%B0%86%E8%BE%93%E5%85%A5%E6%95%B0%E6%8D%AE%E6%96%87%E4%BB%B6%E5%A4%8D%E5%88%B6%E5%88%B0%20HDFS%20%E7%9A%84%2Finput%20%E7%9B%AE%E5%BD%95%E4%B8%AD" rel="nofollow">步骤二：将输入数据文件复制到 HDFS 的/input 目录中</a></p> 
<p id="%E6%AD%A5%E9%AA%A4%E4%B8%89%EF%BC%9A%E8%BF%90%E8%A1%8C%20WordCount%20%E6%A1%88%E4%BE%8B%EF%BC%8C%E8%AE%A1%E7%AE%97%E6%95%B0%E6%8D%AE%E6%96%87%E4%BB%B6%E4%B8%AD%E5%90%84%E5%8D%95%E8%AF%8D%E7%9A%84%E9%A2%91%E5%BA%A6%E3%80%82-toc" style="margin-left:120px;"><a href="#%E6%AD%A5%E9%AA%A4%E4%B8%89%EF%BC%9A%E8%BF%90%E8%A1%8C%20WordCount%20%E6%A1%88%E4%BE%8B%EF%BC%8C%E8%AE%A1%E7%AE%97%E6%95%B0%E6%8D%AE%E6%96%87%E4%BB%B6%E4%B8%AD%E5%90%84%E5%8D%95%E8%AF%8D%E7%9A%84%E9%A2%91%E5%BA%A6%E3%80%82" rel="nofollow">步骤三：运行 WordCount 案例，计算数据文件中各单词的频度。</a></p> 
<p id="%E4%BA%94%EF%BC%9A%E5%81%9C%E6%AD%A2%20Hadoop-toc" style="margin-left:80px;"><a href="#%E4%BA%94%EF%BC%9A%E5%81%9C%E6%AD%A2%20Hadoop" rel="nofollow">五：停止 Hadoop</a></p> 
<p id="%E6%AD%A5%E9%AA%A4%E4%B8%80%EF%BC%9A%E5%81%9C%E6%AD%A2%20yarn-toc" style="margin-left:120px;"><a href="#%E6%AD%A5%E9%AA%A4%E4%B8%80%EF%BC%9A%E5%81%9C%E6%AD%A2%20yarn" rel="nofollow">步骤一：停止 yarn</a></p> 
<p id="%E6%AD%A5%E9%AA%A4%E4%BA%8C%EF%BC%9A%E5%81%9C%E6%AD%A2%20DataNode-toc" style="margin-left:120px;"><a href="#%E6%AD%A5%E9%AA%A4%E4%BA%8C%EF%BC%9A%E5%81%9C%E6%AD%A2%20DataNode" rel="nofollow">步骤二：停止 DataNode</a></p> 
<p id="%E6%AD%A5%E9%AA%A4%E4%BA%8C%EF%BC%9A%E5%81%9C%E6%AD%A2%20NameNode-toc" style="margin-left:120px;"><a href="#%E6%AD%A5%E9%AA%A4%E4%BA%8C%EF%BC%9A%E5%81%9C%E6%AD%A2%20NameNode" rel="nofollow">步骤二：停止 NameNode</a></p> 
<p id="%E6%AD%A5%E9%AA%A4%E4%B8%89%EF%BC%9A%E5%81%9C%E6%AD%A2%20SecondaryNameNode-toc" style="margin-left:120px;"><a href="#%E6%AD%A5%E9%AA%A4%E4%B8%89%EF%BC%9A%E5%81%9C%E6%AD%A2%20SecondaryNameNode" rel="nofollow">步骤三：停止 SecondaryNameNode</a></p> 
<p id="%E6%AD%A5%E9%AA%A4%E5%9B%9B%EF%BC%9A%E6%9F%A5%E7%9C%8B%20JAVA%20%E8%BF%9B%E7%A8%8B%EF%BC%8C%E7%A1%AE%E8%AE%A4%20HDFS%20%E8%BF%9B%E7%A8%8B%E5%B7%B2%E5%85%A8%E9%83%A8%E5%85%B3%E9%97%AD-toc" style="margin-left:120px;"><a href="#%E6%AD%A5%E9%AA%A4%E5%9B%9B%EF%BC%9A%E6%9F%A5%E7%9C%8B%20JAVA%20%E8%BF%9B%E7%A8%8B%EF%BC%8C%E7%A1%AE%E8%AE%A4%20HDFS%20%E8%BF%9B%E7%A8%8B%E5%B7%B2%E5%85%A8%E9%83%A8%E5%85%B3%E9%97%AD" rel="nofollow">步骤四：查看 JAVA 进程，确认 HDFS 进程已全部关闭</a></p> 
<hr id="hr-toc"> 
<p></p> 
<h2 id="%E4%B8%80%E3%80%81Hadoop%E5%B9%B3%E5%8F%B0%E5%AE%89%E8%A3%85">一、Hadoop平台安装</h2> 
<h3 id="%E4%B8%80%E3%80%81%E9%85%8D%E7%BD%AE%20Linux%20%E7%B3%BB%E7%BB%9F%E5%9F%BA%E7%A1%80%E7%8E%AF%E5%A2%83">一、配置 Linux 系统基础环境</h3> 
<h4 id="%E6%AD%A5%E9%AA%A4%E4%B8%80%EF%BC%9A%E6%9F%A5%E7%9C%8B%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%20IP%20%E5%9C%B0%E5%9D%80%20%E6%9F%A5%E7%9C%8B%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%20IP%20%E5%9C%B0%E5%9D%80">步骤一：查看服务器的 IP 地址 查看服务器的 IP 地址</h4> 
<p>[root@localhost ~]# ip add show</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/2f/30/7BR3Zvte_o.png"></p> 
<h4 id="%E6%AD%A5%E9%AA%A4%E4%BA%8C%EF%BC%9A%E8%AE%BE%E7%BD%AE%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E4%B8%BB%E6%9C%BA%E5%90%8D%E7%A7%B0">步骤二：设置服务器的主机名称</h4> 
<p>[root@localhost ~]# hostnamectl set-hostname master</p> 
<p>[root@localhost ~]# bash</p> 
<p>[root@master ~]# hostname</p> 
<h4 id="%E6%AD%A5%E9%AA%A4%E4%B8%89%EF%BC%9A%E7%BB%91%E5%AE%9A%E4%B8%BB%E6%9C%BA%E5%90%8D%E4%B8%8E%20IP%20%E5%9C%B0%E5%9D%80">步骤三：绑定主机名与 IP 地址</h4> 
<p>[root@master ~]# vi /etc/hosts</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/e7/bc/Avoux06p_o.png"></p> 
<h4 id="%E6%AD%A5%E9%AA%A4%E5%9B%9B%EF%BC%9A%E6%9F%A5%E7%9C%8B%20SSH%20%E6%9C%8D%E5%8A%A1%E7%8A%B6%E6%80%81">步骤四：查看 SSH 服务状态</h4> 
<p>        SSH 为 Secure Shell 的缩写，是专为远程登录会话和其他网络服务提供安全性 的协议。一般的用法是在本地计算机安装 SSH 客服端，在服务器端安装 SSH服 务，然后本地计算机利用 SSH 协议远程登录服务器，对服务器进行管理。这样可 以非常方便地对多台服务器进行管理。同时在 Hadoop 分布式环境下，集群中的 各个节点之间（节点可以看作是一台主机）需要使用 SSH 协议进行通信。因此 Linux 系统必须安装并启用 SSH 服务。</p> 
<p>        CentOS 7 默认安装 SSH 服务，可以使用如下命令查看 SSH 的状态。</p> 
<p>[root@master ~]# systemctl status sshd</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/0d/2e/r2FvX2sQ_o.png"></p> 
<h4 id="%E6%AD%A5%E9%AA%A4%E4%BA%94%EF%BC%9A%E5%85%B3%E9%97%AD%E9%98%B2%E7%81%AB%E5%A2%99">步骤五：关闭防火墙</h4> 
<p>Hadoop 可以使用 Web 页面进行管理，但需要关闭防火墙，否则打不开 Web 页面。 同时不关闭防火墙也会造成 Hadoop 后台运行脚本出现莫名其妙的错误。关闭命令如 下： [root@master ~]# systemctl stop firewalld</p> 
<p>关闭防火墙后要查看防火墙的状态，确认一下。</p> 
<p>[root@master ~]# systemctl status firewalld</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/2b/c8/PeVJrEKN_o.png"></p> 
<p>看到 inactive (dead)就表示防火墙已经关闭。不过这样设置后，Linux 系统如 果重启，防火墙仍然会重新启动。执行如下命令可以永久关闭防火墙。</p> 
<h4 id="%E6%AD%A5%E9%AA%A4%E5%85%AD%EF%BC%9A%E5%88%9B%E5%BB%BA%20hadoop%20%E7%94%A8%E6%88%B7">步骤六：创建 hadoop 用户</h4> 
<p>[root@master ~]# useradd hadoop</p> 
<p>[root@master ~]# echo "1" |passwd --stdin hadoop</p> 
<p>更改用户 hadoop 的密码 。</p> 
<p>passwd：所有的身份验证令牌已经成功更新。</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/b1/0b/MIEKAh2v_o.png"></p> 
<h3 id="%E4%BA%8C%EF%BC%9A%E5%AE%89%E8%A3%85%20JAVA%20%E7%8E%AF%E5%A2%83">二：安装 JAVA 环境</h3> 
<h4 id="%E6%AD%A5%E9%AA%A4%E4%B8%80%EF%BC%9A%E5%AE%89%E8%A3%85%20JDK">步骤一：安装 JDK</h4> 
<p>Hadoop 2.7.1 要求 JDK 的版本为 1.7 以上，这里安装的是 JDK1.8 版 （即JAVA 8）。 安装命令如下，将安装包解压到/usr/local/src 目录下 ，注意/opt/software目录 下的软件包事先准备好。</p> 
<p>[root@master ~]# tar -zxvf /opt/software/jdk-8u152-linux-x64.tar.gz -C /usr/local/src/</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/f5/e2/c5nZBH2W_o.png"></p> 
<p>[root@master ~]# ls /usr/local/src/</p> 
<h4 id="%E6%AD%A5%E9%AA%A4%E4%BA%8C%EF%BC%9A%E8%AE%BE%E7%BD%AE%20JAVA%20%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F">步骤二：设置 JAVA 环境变量</h4> 
<p>在 Linux 中设置环境变量的方法比较多，较常见的有两种：</p> 
<p>一、是配置 /etc/profile 文件，配置结果对整个系统有效，系统所有用户都可以使用；</p> 
<p>二 、是配置~/.bashrc 文件，配置结果仅对当前用户有效。这里使用第一种方法。</p> 
<p>[root@master ~]# vi /etc/profile 在文件的最后增加如下两行：</p> 
<p>export JAVA_HOME=/usr/local/src/jdk1.8.0_152</p> 
<p>export PATH=$PATH:$JAVA_HOME/bin</p> 
<p>执行 source 使设置生效：</p> 
<p>[root@master ~]# source /etc/profile</p> 
<p>检查 JAVA 是否可用。</p> 
<p>[root@master ~]# echo $JAVA_HOME /usr/local/src/jdk1.8.0_152</p> 
<p>[root@master ~]# java -version</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/d3/e9/q2wUqmST_o.png"></p> 
<p>能够正常显示 Java 版本则说明 JDK 安装并配置成功。</p> 
<h2 id="%E4%BA%8C%E3%80%81%E5%AE%89%E8%A3%85%20Hadoop%20%E8%BD%AF%E4%BB%B6">二、安装 Hadoop 软件</h2> 
<h3 id="%E4%B8%80%E3%80%81%E5%AE%89%E8%A3%85%20Hadoop%20%E8%BD%AF%E4%BB%B6">一、安装 Hadoop 软件</h3> 
<h4 id="%E6%AD%A5%E9%AA%A4%E4%B8%80%EF%BC%9A%E5%AE%89%E8%A3%85%20Hadoop%20%E8%BD%AF%E4%BB%B6">步骤一：安装 Hadoop 软件</h4> 
<p>安装命令如下，将安装包解压到/usr/local/src/目录下</p> 
<p>[root@master ~]# tar -zxvf /opt/software/hadoop-2.7.1.tar.gz -C /usr/local/src/</p> 
<p>[root@master ~]# ll /usr/local/src/</p> 
<p>查看 Hadoop 目录,得知 Hadoop 目录内容如下:</p> 
<p>[root@master ~]# ll /usr/local/src/hadoop-2.7.1/</p> 
<p><img alt="" src="https://images2.imgbox.com/fd/9a/SEwEC6OV_o.png"></p> 
<p>解析： bin：此目录中存放 Hadoop、HDFS、YARN 和 MapReduce 运行程序和管理 软件。</p> 
<p> etc：存放 Hadoop 配置文件。</p> 
<p>include: 类似 C 语言的头文件</p> 
<p>lib：本地库文件，支持对数据进行压缩和解压。</p> 
<p>libexe：同 lib sbin：Hadoop 集群启动、停止命令</p> 
<p>share：说明文档、案例和依赖 jar 包。</p> 
<h4 id="%E6%AD%A5%E9%AA%A4%E4%BA%8C%EF%BC%9A%E9%85%8D%E7%BD%AE%20Hadoop%20%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F">步骤二：配置 Hadoop 环境变量</h4> 
<p>和设置 JAVA 环境变量类似，修改/etc/profile 文件。</p> 
<p>[root@master ~]# vi /etc/profile</p> 
<p>在文件的最后增加如下两行：</p> 
<p>export HADOOP_HOME=/usr/local/src/hadoop-2.7.1</p> 
<p>export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</p> 
<p>执行 source 使用设置生效：</p> 
<p>[root@master ~]# source /etc/profile</p> 
<p>检查设置是否生效：</p> 
<p>[root@master ~]# hadoop</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/65/30/tHbomL2k_o.png"></p> 
<p>出现上述 Hadoop 帮助信息就说明 Hadoop 已经安装好了。</p> 
<h4 id="%E6%AD%A5%E9%AA%A4%E4%B8%89%EF%BC%9A%E4%BF%AE%E6%94%B9%E7%9B%AE%E5%BD%95%E6%89%80%E6%9C%89%E8%80%85%E5%92%8C%E6%89%80%E6%9C%89%E8%80%85%E7%BB%84">步骤三：修改目录所有者和所有者组</h4> 
<p>上述安装完成的 Hadoop 软件只能让 root 用户使用，要让 hadoop 用户能够 运行 Hadoop 软件，需要将目录/usr/local/src 的所有者改为 hadoop 用户。</p> 
<p>[root@master ~]# chown -R hadoop:hadoop /usr/local/src/</p> 
<p>[root@master ~]# ll /usr/local/src/</p> 
<p><img alt="" src="https://images2.imgbox.com/5f/0a/UEArwqCb_o.png"></p> 
<h2 id="%E4%B8%89%E3%80%81%E5%AE%89%E8%A3%85%E5%8D%95%E6%9C%BA%E7%89%88%20Hadoop%20%E7%B3%BB%E7%BB%9F">三、安装单机版 Hadoop 系统</h2> 
<h3 id="%E4%B8%80%EF%BC%9A%E9%85%8D%E7%BD%AE%20Hadoop%20%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6">一：配置 Hadoop 配置文件</h3> 
<p>[root@master ~]# cd /usr/local/src/hadoop-2.7.1/</p> 
<p>[root@master hadoop-2.7.1]# ls</p> 
<p>[root@master hadoop-2.7.1]# vi etc/hadoop/hadoop-env.sh</p> 
<p>在文件中查找 export JAVA_HOME 这行，将其改为如下所示内容:</p> 
<p>export JAVA_HOME=/usr/local/src/jdk1.8.0_152</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/5a/3d/SAKW3IHi_o.png"></p> 
<h3 id="%E4%BA%8C%EF%BC%9A%E6%B5%8B%E8%AF%95%20Hadoop%20%E6%9C%AC%E5%9C%B0%E6%A8%A1%E5%BC%8F%E7%9A%84%E8%BF%90%E8%A1%8C">二：测试 Hadoop 本地模式的运行</h3> 
<h4 id="%E6%AD%A5%E9%AA%A4%E4%B8%80%3A%20%E5%88%87%E6%8D%A2%E5%88%B0%20hadoop%20%E7%94%A8%E6%88%B7">步骤一: 切换到 hadoop 用户</h4> 
<p>使用 hadoop 这个用户来运行 Hadoop 软件。</p> 
<p>[root@master hadoop-2.7.1]# su - hadoop</p> 
<p>[hadoop@master ~]$ id</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/72/c8/H88iS1w5_o.png"></p> 
<h4 id="%E6%AD%A5%E9%AA%A4%E4%BA%8C%3A%20%E5%88%9B%E5%BB%BA%E8%BE%93%E5%85%A5%E6%95%B0%E6%8D%AE%E5%AD%98%E6%94%BE%E7%9B%AE%E5%BD%95">步骤二: 创建输入数据存放目录</h4> 
<p>将输入数据存放在~/input 目录（hadoop 用户主目录下的 input 目录中）。</p> 
<p>[hadoop@master ~]$ mkdir ~/input</p> 
<p>[hadoop@master ~]$ ls</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/38/1d/mkBMENcG_o.png"></p> 
<h4 id="%E6%AD%A5%E9%AA%A4%E4%B8%89%3A%20%E5%88%9B%E5%BB%BA%E6%95%B0%E6%8D%AE%E8%BE%93%E5%85%A5%E6%96%87%E4%BB%B6">步骤三: 创建数据输入文件</h4> 
<p>创建数据文件 data.txt，将要测试的数据内容输入到 data.txt 文件中。</p> 
<p>[hadoop@master ~]$ vi input/data.txt 输入如下内容，保存退出。</p> 
<p>Hello World</p> 
<p>Hello Hadoop</p> 
<p>Hello Husan</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/36/6d/EAUbDcHD_o.png"></p> 
<h4 id="%E6%AD%A5%E9%AA%A4%E5%9B%9B%3A%20%E6%B5%8B%E8%AF%95%20MapReduce%20%E8%BF%90%E8%A1%8C">步骤四: 测试 MapReduce 运行</h4> 
<p>运行 WordCount 官方案例，统计 data.txt 文件中单词的出现频度。这个案例可 以用来统计年度十大热销产品、年度风云人物、年度最热名词等。</p> 
<p>命令如下:</p> 
<p>[hadoop@master ~]$ hadoop jar /usr/local/src/hadoop2.7.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar wordcount ~/input/data.txt ~/output</p> 
<p><img alt="" src="https://images2.imgbox.com/10/a2/1t6iBFsN_o.png"></p> 
<p>运行结果保存在~/output 目录中(注：结果输出目录不能事先存在)，命令执 行后查看结果：</p> 
<p>[hadoop@master ~]$ ll output/</p> 
<p>文件_SUCCESS 表示处理成功，处理的结果存放在 part-r-00000 文件中，查看该 文件。 [hadoop@master ~]$ cat output/part-r-00000</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/be/44/hWVdAZYk_o.png"></p> 
<h2 id="%E5%9B%9B%E3%80%81Hadoop%E5%B9%B3%E5%8F%B0%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE">四、Hadoop平台环境配置</h2> 
<h3 id="%E4%B8%80%EF%BC%9A%E5%AE%9E%E9%AA%8C%E7%8E%AF%E5%A2%83%E4%B8%8B%E9%9B%86%E7%BE%A4%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE">一：实验环境下集群网络配置</h3> 
<p>修改 slave1 机器主机名</p> 
<p>[root@localhost ~]# hostnamectl set-hostname slave1</p> 
<p>[root@localhost ~]# bash</p> 
<p>[root@slave1 ~]#</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/d6/1f/ugrUhwX4_o.png"></p> 
<p>修改 slave2 机器主机名</p> 
<p>[root@localhost ~]# hostnamectl set-hostname slave2</p> 
<p>[root@localhost ~]# bash</p> 
<p>[root@slave2 ~]#</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/f7/a3/33sDsCDN_o.png"></p> 
<p>根据实验环境下集群网络 IP 地址规划（根据自己主机的ip即可）：</p> 
<p>master 设置 IP 地址是“192.168.47.140”，掩码是“255.255.255.0”；</p> 
<p>slave1 设置 IP 地址“192.168.47.141”，掩码是“255.255.255.0”；</p> 
<p>slave2 设置 IP 地址是“192.168.47.142”，掩码是“255.255.255.0”。</p> 
<p>        根据我们为 Hadoop 设置的主机名为“master、slave1、slave2”，映地址是 “192.168.47.140、192.168.47.141、192.168.47.142”，分别修改主机配置文件“/etc/hosts”， 在命令终端输入如下命令：</p> 
<p>[root@master ~]# vi /etc/hosts</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/96/59/VtBnLm9s_o.png"></p> 
<p>[root@slave1 ~]# vi /etc/hosts</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/c3/ba/91tjfFZ4_o.png"></p> 
<p>[root@slave2 ~]# vi /etc/hosts</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/94/42/Q3cxT8ck_o.png"></p> 
<h3 id="%E4%BA%8C%EF%BC%9ASSH%20%E6%97%A0%E5%AF%86%E7%A0%81%E9%AA%8C%E8%AF%81%E9%85%8D%E7%BD%AE">二：SSH 无密码验证配置</h3> 
<h4 id="%E4%B8%80%E3%80%81%E7%94%9F%E6%88%90%20SSH%20%E5%AF%86%E9%92%A5">一、生成 SSH 密钥</h4> 
<h4 id="%E6%AD%A5%E9%AA%A4%E4%B8%80%EF%BC%9A%E6%AF%8F%E4%B8%AA%E8%8A%82%E7%82%B9%E5%AE%89%E8%A3%85%E5%92%8C%E5%90%AF%E5%8A%A8%20SSH%20%E5%8D%8F%E8%AE%AE">步骤一：每个节点安装和启动 SSH 协议</h4> 
<p>实现 SSH 登录需要 openssh 和 rsync 两个服务，一般情况下默认已经安装（如没有自行安 装），可以通过下面命令查看结果。</p> 
<p>[root@master ~]# rpm -qa | grep openssh</p> 
<p>[root@master ~]# rpm -qa | grep rsync</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/f0/dd/30H3YiKJ_o.png"></p> 
<h4 id="%E6%AD%A5%E9%AA%A4%E4%BA%8C%EF%BC%9A%E5%88%87%E6%8D%A2%E5%88%B0%20hadoop%20%E7%94%A8%E6%88%B7">步骤二：切换到 hadoop 用户</h4> 
<p>[root@master ~]# su - hadoop</p> 
<p>[hadoop@master ~]$</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/53/29/iN4j5IVB_o.png"></p> 
<p>[root@slave1 ~]# useradd hadoop</p> 
<p>[root@slave1 ~]# su - hadoop</p> 
<p>[hadoop@slave1 ~]$</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/32/bd/MQPxCOFL_o.png"></p> 
<p>[root@slave2 ~]# useradd hadoop</p> 
<p>[root@slave2 ~]# su - hadoop</p> 
<p>[hadoop@slave2 ~]$</p> 
<p><img alt="" src="https://images2.imgbox.com/28/e7/2PR62fYv_o.png"></p> 
<h4 id="%E6%AD%A5%E9%AA%A4%E4%B8%89%EF%BC%9A%E6%AF%8F%E4%B8%AA%E8%8A%82%E7%82%B9%E7%94%9F%E6%88%90%E7%A7%98%E9%92%A5%E5%AF%B9">步骤三：每个节点生成秘钥对</h4> 
<p>#在 master 上生成密钥</p> 
<p>[hadoop@master ~]$ ssh-keygen -t rsa</p> 
<p><img alt="" src="https://images2.imgbox.com/28/b6/HThwfSJG_o.png"></p> 
<p>#slave1 生成密钥 [hadoop@slave1 ~]$ ssh-keygen -t rsa</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/9c/a9/dY7WmTfl_o.png"></p> 
<p>#slave2 生成密钥 [hadoop@slave2 ~]$ ssh-keygen -t rsa</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/55/f2/BLjySVpM_o.png"></p> 
<h4 id="%E6%AD%A5%E9%AA%A4%E5%9B%9B%EF%BC%9A%E6%9F%A5%E7%9C%8B%22%2Fhome%2Fhadoop%2F%22%E4%B8%8B%E6%98%AF%E5%90%A6%E6%9C%89%22.ssh%22%E6%96%87%E4%BB%B6%E5%A4%B9">步骤四：查看"/home/hadoop/"下是否有".ssh"文件夹</h4> 
<p>且".ssh"文件下是否有两个刚 生产的无密码密钥对。</p> 
<p>[hadoop@master ~]$ ls ~/.ssh/ </p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/2e/2b/ceqMgMGY_o.png"></p> 
<h4 id="%E6%AD%A5%E9%AA%A4%E4%BA%94%EF%BC%9A%E5%B0%86%20id_rsa.pub%20%E8%BF%BD%E5%8A%A0%E5%88%B0%E6%8E%88%E6%9D%83%20key%20%E6%96%87%E4%BB%B6%E4%B8%AD">步骤五：将 id_rsa.pub 追加到授权 key 文件中</h4> 
<p>#master</p> 
<p>[hadoop@master ~]$ cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</p> 
<p>[hadoop@master ~]$ ls ~/.ssh/</p> 
<p><img alt="" src="https://images2.imgbox.com/d2/94/I40JFu5H_o.png"></p> 
<p>#slave1</p> 
<p>[hadoop@slave1 ~]$ cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</p> 
<p>[hadoop@slave1 ~]$ ls ~/.ssh/</p> 
<p><img alt="" height="113" src="https://images2.imgbox.com/df/8f/mjY8i9sO_o.png" width="1200"></p> 
<p>#slave2</p> 
<p>[hadoop@slave2 ~]$ cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</p> 
<p>[hadoop@slave2 ~]$ ls ~/.ssh/</p> 
<p><img alt="" height="126" src="https://images2.imgbox.com/cd/97/o73gmtIw_o.png" width="1180"></p> 
<h4 id="%E6%AD%A5%E9%AA%A4%E5%85%AD%EF%BC%9A%E4%BF%AE%E6%94%B9%E6%96%87%E4%BB%B6%22authorized_keys%22%E6%9D%83%E9%99%90">步骤六：修改文件"authorized_keys"权限</h4> 
<p>通过 ll 命令查看，可以看到修改后 authorized_keys 文件的权限为“rw-------”，表示所有者 可读写，其他用户没有访问权限。如果该文件权限太大，ssh 服务会拒绝工作，出现无法 通过密钥文件进行登录认证的情况。</p> 
<p>#master</p> 
<p>[hadoop@master ~]$ chmod 600 ~/.ssh/authorized_keys</p> 
<p>[hadoop@master ~]$ ll ~/.ssh/</p> 
<p><img alt="" height="180" src="https://images2.imgbox.com/c3/bc/Zqqp8rpo_o.png" width="1101"></p> 
<p>#slave1</p> 
<p>[hadoop@slave1 ~]$ chmod 600 ~/.ssh/authorized_keys</p> 
<p>[hadoop@slave1 ~]$ ll ~/.ssh/</p> 
<p><img alt="" height="304" src="https://images2.imgbox.com/36/d4/xRZjPQGi_o.png" width="1102"></p> 
<p>#slave2</p> 
<p>[hadoop@slave2 ~]$ chmod 600 ~/.ssh/authorized_keys</p> 
<p>[hadoop@slave2 ~]$ ll ~/.ssh/</p> 
<p><img alt="" height="298" src="https://images2.imgbox.com/0a/d5/Luk0Kb4n_o.png" width="1146"></p> 
<h4 id="%E6%AD%A5%E9%AA%A4%E4%B8%83%EF%BC%9A%E9%85%8D%E7%BD%AE%20SSH%20%E6%9C%8D%E5%8A%A1">步骤七：配置 SSH 服务</h4> 
<p>使用 root 用户登录，修改 SSH 配置文件"/etc/ssh/sshd_config"的下列内容，需要将该配 置字段前面的#号删除，启用公钥私钥配对认证方式。</p> 
<p>#master</p> 
<p>[hadoop@master ~]$ su - root</p> 
<p>[root@master ~]# vi /etc/ssh/sshd_config</p> 
<p>PubkeyAuthentication yes #找到此行，并把#号注释删除。</p> 
<p><img alt="" height="124" src="https://images2.imgbox.com/38/7e/kf7d0mIW_o.png" width="887"></p> 
<p>#slave1</p> 
<p>[hadoop@ slave1 ~]$ su - root</p> 
<p>[root@ slave1 ~]# vi /etc/ssh/sshd_config</p> 
<p>PubkeyAuthentication yes #找到此行，并把#号注释删除。</p> 
<p>#slave2</p> 
<p>[hadoop@ slave2 ~]$ su - root</p> 
<p>[root@ slave2 ~]# vi /etc/ssh/sshd_config</p> 
<p>PubkeyAuthentication yes #找到此行，并把#号注释删除。</p> 
<p>步骤八：重启 SSH 服务</p> 
<p>设置完后需要重启 SSH 服务，才能使配置生效。</p> 
<p>[root@master ~]# systemctl restart sshd</p> 
<p>步骤九：切换到 hadoop 用户</p> 
<p>[root@master ~]# su - hadoop</p> 
<p>步骤十：验证 SSH 登录本机</p> 
<p>在 hadoop 用户下验证能否嵌套登录本机，若可以不输入密码登录，则本机通过密钥登录认证成功。</p> 
<p>[hadoop@master ~]$ ssh localhost</p> 
<p><img alt="" height="287" src="https://images2.imgbox.com/b7/34/ApxAzmv9_o.png" width="1200"></p> 
<p>首次登录时会提示系统无法确认 host 主机的真实性，只知道它的公钥指纹，询问用户是 否还想继续连接。需要输入“yes”，表示继续登录。第二次再登录同一个主机，则不会再 出现该提示，可以直接进行登录。</p> 
<p>读者需要关注是否在登录过程中是否需要输入密码，不需要输入密码才表示通过密钥认 证成功。</p> 
<h3 id="%E4%BA%8C%EF%BC%9A%E4%BA%A4%E6%8D%A2%20SSH%20%E5%AF%86%E9%92%A5">二：交换 SSH 密钥</h3> 
<h4 id="%E6%AD%A5%E9%AA%A4%E4%B8%80%EF%BC%9A%E5%B0%86%20Master%20%E8%8A%82%E7%82%B9%E7%9A%84%E5%85%AC%E9%92%A5%20id_rsa.pub%20%E5%A4%8D%E5%88%B6%E5%88%B0%E6%AF%8F%E4%B8%AA%20Slave%20%E7%82%B9">步骤一：将 Master 节点的公钥 id_rsa.pub 复制到每个 Slave 点</h4> 
<p>hadoop 用户登录，通过 scp 命令实现密钥拷贝。</p> 
<p>[hadoop@master ~]$ scp ~/.ssh/id_rsa.pub hadoop@slave1:~/</p> 
<p>[hadoop@master ~]$ scp ~/.ssh/id_rsa.pub hadoop@slave2:~/</p> 
<p><img alt="" height="474" src="https://images2.imgbox.com/f4/ee/bEjmNvsF_o.png" width="1200"></p> 
<p>首次远程连接时系统会询问用户是否要继续连接。需要输入“yes”，表示继续。因为目 前尚未完成密钥认证的配置，所以使用 scp 命令拷贝文件需要输入slave1 节点 hadoop 用户的密码。</p> 
<h4 id="%E6%AD%A5%E9%AA%A4%E4%BA%8C%EF%BC%9A%E5%9C%A8%E6%AF%8F%E4%B8%AA%20Slave%20%E8%8A%82%E7%82%B9%E6%8A%8A%20Master%20%E8%8A%82%E7%82%B9%E5%A4%8D%E5%88%B6%E7%9A%84%E5%85%AC%E9%92%A5%E5%A4%8D%E5%88%B6%E5%88%B0authorized_keys%20%E6%96%87%E4%BB%B6">步骤二：在每个 Slave 节点把 Master 节点复制的公钥复制到authorized_keys 文件</h4> 
<p>hadoop 用户登录 slave1 和 slave2 节点，执行命令。</p> 
<p>[hadoop@slave1 ~]$ cat ~/id_rsa.pub &gt;&gt;~/.ssh/authorized_keys</p> 
<p><img alt="" height="93" src="https://images2.imgbox.com/e8/35/8BRG3ucy_o.png" width="1043"></p> 
<p>[hadoop@slave2 ~]$ cat ~/id_rsa.pub &gt;&gt;~/.ssh/authorized_keys</p> 
<p><img alt="" height="94" src="https://images2.imgbox.com/7f/df/xmF1ijwU_o.png" width="1036"></p> 
<h4 id="%E6%AD%A5%E9%AA%A4%E4%B8%89%EF%BC%9A%E5%9C%A8%E6%AF%8F%E4%B8%AA%20Slave%20%E8%8A%82%E7%82%B9%E5%88%A0%E9%99%A4%20id_rsa.pub%20%E6%96%87%E4%BB%B6">步骤三：在每个 Slave 节点删除 id_rsa.pub 文件</h4> 
<p>[hadoop@slave1 ~]$ rm -rf ~/id_rsa.pub</p> 
<p>[hadoop@slave2 ~]$ rm -rf ~/id_rsa.pub</p> 
<h4 id="%E6%AD%A5%E9%AA%A4%E5%9B%9B%EF%BC%9A%E5%B0%86%E6%AF%8F%E4%B8%AA%20Slave%20%E8%8A%82%E7%82%B9%E7%9A%84%E5%85%AC%E9%92%A5%E4%BF%9D%E5%AD%98%E5%88%B0%20Master">步骤四：将每个 Slave 节点的公钥保存到 Master</h4> 
<p>（1）将 Slave1 节点的公钥复制到 Master</p> 
<p>[hadoop@slave1 ~]$ scp ~/.ssh/id_rsa.pub hadoop@master:~/</p> 
<p><img alt="" height="237" src="https://images2.imgbox.com/c5/7f/NR9GGyOm_o.png" width="1200"></p> 
<p>（2）在 Master 节点把从 Slave 节点复制的公钥复制到 authorized_keys 文件</p> 
<p>[hadoop@master ~]$ cat ~/id_rsa.pub &gt;&gt;~/.ssh/authorized_keys</p> 
<p>（3）在 Master 节点删除 id_rsa.pub 文件</p> 
<p>[hadoop@master ~]$ rm -rf ~/id_rsa.pub</p> 
<p>（4）将 Slave2 节点的公钥复制到 Master</p> 
<p>[hadoop@slave2 ~]$ scp ~/.ssh/id_rsa.pub hadoop@master:~/</p> 
<p><img alt="" height="232" src="https://images2.imgbox.com/12/d9/1uDDiq40_o.png" width="1200"></p> 
<p>（5）在 Master 节点把从 Slave 节点复制的公钥复制到 authorized_keys 文件</p> 
<p>[hadoop@master ~]$ cat ~/id_rsa.pub &gt;&gt;~/.ssh/authorized_keys</p> 
<p>（6）在 Master 节点删除 id_rsa.pub 文件</p> 
<p>[hadoop@master ~]$ rm -rf ~/id_rsa.pub</p> 
<h3 id="%E4%B8%89%EF%BC%9A%E9%AA%8C%E8%AF%81%20SSH%20%E6%97%A0%E5%AF%86%E7%A0%81%E7%99%BB%E5%BD%95">三：验证 SSH 无密码登录</h3> 
<h4 id="%E6%AD%A5%E9%AA%A4%E4%B8%80%EF%BC%9A%E6%9F%A5%E7%9C%8B%20Master%20%E8%8A%82%E7%82%B9%20authorized_keys%20%E6%96%87%E4%BB%B6">步骤一：查看 Master 节点 authorized_keys 文件</h4> 
<p>[hadoop@master ~]$ cat ~/.ssh/authorized_keys</p> 
<p><img alt="" height="260" src="https://images2.imgbox.com/57/d6/aUX3MomQ_o.png" width="1200"></p> 
<p>可以看到 Master 节点 authorized_keys 文件中包括 master、slave1、slave2 三个节点 的公钥。</p> 
<h4 id="%E6%AD%A5%E9%AA%A4%E4%BA%8C%EF%BC%9A%E6%9F%A5%E7%9C%8B%20Slave%20%E8%8A%82%E7%82%B9%20authorized_keys%20%E6%96%87%E4%BB%B6">步骤二：查看 Slave 节点 authorized_keys 文件</h4> 
<p>[hadoop@slave1 ~]$ cat ~/.ssh/authorized_keys</p> 
<p><img alt="" height="221" src="https://images2.imgbox.com/8f/ee/xXf1BzS4_o.png" width="1200"></p> 
<p>[hadoop@slave2 ~]$ cat ~/.ssh/authorized_keys</p> 
<p><img alt="" height="215" src="https://images2.imgbox.com/1a/34/fC3j1VXt_o.png" width="1200"></p> 
<h4 id="%E6%AD%A5%E9%AA%A4%E4%B8%89%EF%BC%9A%E9%AA%8C%E8%AF%81%20Master%20%E5%88%B0%E6%AF%8F%E4%B8%AA%20Slave%20%E8%8A%82%E7%82%B9%E6%97%A0%E5%AF%86%E7%A0%81%E7%99%BB%E5%BD%95">步骤三：验证 Master 到每个 Slave 节点无密码登录</h4> 
<p>hadoop 用户登录 master 节点，执行 SSH 命令登录 slave1 和 slave2 节点。可以观察 到不需要输入密码即可实现 SSH 登录。</p> 
<p>[hadoop@master ~]$ ssh slave1</p> 
<p><img alt="" height="67" src="https://images2.imgbox.com/31/0e/MLMsmpKv_o.png" width="896"></p> 
<p>[hadoop@master ~]$ ssh slave2</p> 
<p><img alt="" height="50" src="https://images2.imgbox.com/8e/58/oCPoojPM_o.png" width="856"></p> 
<h4 id="%E6%AD%A5%E9%AA%A4%E5%9B%9B%EF%BC%9A%E9%AA%8C%E8%AF%81%E4%B8%A4%E4%B8%AA%20Slave%20%E8%8A%82%E7%82%B9%E5%88%B0%20Master%20%E8%8A%82%E7%82%B9%E6%97%A0%E5%AF%86%E7%A0%81%E7%99%BB%E5%BD%95">步骤四：验证两个 Slave 节点到 Master 节点无密码登录</h4> 
<p>[hadoop@slave1 ~]$ ssh master</p> 
<p>[hadoop@slave2 ~]$ ssh master</p> 
<p><img alt="" height="76" src="https://images2.imgbox.com/a8/18/Q7BlZHJm_o.png" width="873"></p> 
<h4 id="%E6%AD%A5%E9%AA%A4%E4%BA%94%EF%BC%9A%E9%85%8D%E7%BD%AE%E4%B8%A4%E4%B8%AA%E5%AD%90%E8%8A%82%E7%82%B9slave1%E3%80%81slave2%E7%9A%84JDK%E7%8E%AF%E5%A2%83%E3%80%82">步骤五：配置两个子节点slave1、slave2的JDK环境。</h4> 
<p>[root@master ~]# cd /usr/local/src/</p> 
<p>[root@master src]# ls </p> 
<p>[root@master src]# scp -r jdk1.8.0_152 root@slave1:/usr/local/src/</p> 
<p><img alt="" height="924" src="https://images2.imgbox.com/a1/5c/AW0Xw08B_o.png" width="1200"></p> 
<p>[root@master src]# scp -r jdk1.8.0_152 root@slave2:/usr/local/src/</p> 
<p><img alt="" height="714" src="https://images2.imgbox.com/94/37/63h4CpjS_o.png" width="1200"></p> 
<p>#slave1</p> 
<p>[root@slave1 ~]# ls /usr/local/src/</p> 
<p>[root@slave1 ~]# vi /etc/profile #此文件最后添加下面两行</p> 
<p>export JAVA_HOME=/usr/local/src/jdk1.8.0_152</p> 
<p>export PATH=$PATH:$JAVA_HOME/bin</p> 
<p><img alt="" height="139" src="https://images2.imgbox.com/72/a3/IeVjDmhp_o.png" width="987"></p> 
<p>[root@slave1 ~]# source /etc/profile</p> 
<p>[root@slave1 ~]# java -version</p> 
<p><img alt="" height="228" src="https://images2.imgbox.com/c1/c4/xUBdzY14_o.png" width="1033"></p> 
<p>#slave2</p> 
<p>[root@slave2 ~]# ls /usr/local/src/</p> 
<p>[root@slave2 ~]# vi /etc/profile #此文件最后添加下面两行</p> 
<p>export JAVA_HOME=/usr/local/src/jdk1.8.0_152</p> 
<p>export PATH=$PATH:$JAVA_HOME/bin</p> 
<p><img alt="" height="139" src="https://images2.imgbox.com/33/6c/rN7Ele43_o.png" width="987"></p> 
<p>[root@slave2 ~]# source /etc/profile</p> 
<p>[root@slave2 ~]# java -version</p> 
<p><img alt="" height="235" src="https://images2.imgbox.com/43/15/2UGyHjX3_o.png" width="1027"></p> 
<h2 id="%E4%BA%94%E3%80%81Hadoop%E9%9B%86%E7%BE%A4%E8%BF%90%E8%A1%8C">五、Hadoop集群运行</h2> 
<h3 id="1%E3%80%81Hadoop%E6%96%87%E4%BB%B6%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE">1、Hadoop文件参数配置</h3> 
<h4 id="%E4%B8%80%EF%BC%9A%E5%9C%A8%20Master%20%E8%8A%82%E7%82%B9%E4%B8%8A%E5%AE%89%E8%A3%85%20Hadoop">一：在 Master 节点上安装 Hadoop</h4> 
<h5 id="1.%20%E5%B0%86%20hadoop-2.7.1%20%E6%96%87%E4%BB%B6%E5%A4%B9%E9%87%8D%E5%91%BD%E5%90%8D%E4%B8%BA%20Hadoop">1. 将 hadoop-2.7.1 文件夹重命名为 Hadoop</h5> 
<p>[root@master ~]# cd /usr/local/src/</p> 
<p>[root@master src]# mv hadoop-2.7.1 hadoop</p> 
<p>[root@master src]# ls </p> 
<p><img alt="" height="852" src="https://images2.imgbox.com/f2/44/a752dyxi_o.png" width="1200"></p> 
<h5 id="2.%20%E9%85%8D%E7%BD%AE%20Hadoop%20%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F">2. 配置 Hadoop 环境变量</h5> 
<p>[root@master src]# yum install -y vim</p> 
<p>[root@master src]# vim /etc/profile</p> 
<p>[root@master src]# tail -n 4 /etc/profile</p> 
<p><img alt="" height="375" src="https://images2.imgbox.com/03/aa/jW4e21J9_o.png" width="1200"></p> 
<h5 id="3.%20%E4%BD%BF%E9%85%8D%E7%BD%AE%E7%9A%84%20Hadoop%20%E7%9A%84%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E7%94%9F%E6%95%88">3. 使配置的 Hadoop 的环境变量生效</h5> 
<p>[root@master src]# su - hadoop </p> 
<p>[hadoop@master ~]$ source /etc/profile</p> 
<p>[hadoop@master ~]$ exit</p> 
<p><img alt="" height="232" src="https://images2.imgbox.com/99/e3/mKapY72g_o.png" width="1200"></p> 
<h5 id="4.%20%E6%89%A7%E8%A1%8C%E4%BB%A5%E4%B8%8B%E5%91%BD%E4%BB%A4%E4%BF%AE%E6%94%B9%20hadoop-env.sh%20%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6">4. 执行以下命令修改 hadoop-env.sh 配置文件</h5> 
<p>[root@master src]# cd /usr/local/src/hadoop/etc/hadoop/</p> 
<p>[root@master hadoop]# vim hadoop-env.sh #修改以下配置 </p> 
<h4 id="%E4%BA%8C%EF%BC%9A%E9%85%8D%E7%BD%AE%20hdfs-site.xml%20%E6%96%87%E4%BB%B6%E5%8F%82%E6%95%B0">二：配置 hdfs-site.xml 文件参数</h4> 
<p>[root@master hadoop]# vim hdfs-site.xml #编辑以下内容</p> 
<p>[root@master hadoop]# tail -n 14 hdfs-site.xml</p> 
<p><img alt="" height="470" src="https://images2.imgbox.com/74/b9/VjKMJyAn_o.png" width="977"></p> 
<h4 id="%E4%B8%89%3A%E9%85%8D%E7%BD%AE%20core-site.xml%20%E6%96%87%E4%BB%B6%E5%8F%82%E6%95%B0">三:配置 core-site.xml 文件参数</h4> 
<p>[root@master hadoop]# vim core-site.xml #编辑以下内容</p> 
<p>[root@master hadoop]# tail -n 14 core-site.xml</p> 
<p><img alt="" height="468" src="https://images2.imgbox.com/a5/bb/3xuDc55s_o.png" width="1047"></p> 
<h4 id="%E5%9B%9B%3A%E9%85%8D%E7%BD%AE%20mapred-site.xml">四:配置 mapred-site.xml</h4> 
<p>[root@master hadoop]# pwd </p> 
<p>[root@master hadoop]# cp mapred-site.xml.template mapred-site.xml</p> 
<p>[root@master hadoop]# vim mapred-site.xml #添加以下配置</p> 
<p>[root@master hadoop]# tail -n 14 mapred-site.xml</p> 
<p><img alt="" height="571" src="https://images2.imgbox.com/7f/c6/kBMtVAj3_o.png" width="1200"></p> 
<h4 id="%E4%BA%94%EF%BC%9A%E9%85%8D%E7%BD%AE%20yarn-site.xml">五：配置 yarn-site.xml</h4> 
<p>[root@master hadoop]# vim yarn-site.xml #添加以下配置</p> 
<p>[root@master hadoop]# tail -n 32 yarn-site.xml</p> 
<p><img alt="" height="987" src="https://images2.imgbox.com/43/16/4kH6Q7pb_o.png" width="1200"></p> 
<h4 id="%E5%85%AD%3AHadoop%20%E5%85%B6%E4%BB%96%E7%9B%B8%E5%85%B3%E9%85%8D%E7%BD%AE">六:Hadoop 其他相关配置</h4> 
<h5 id="1.%20%E9%85%8D%E7%BD%AE%20masters%20%E6%96%87%E4%BB%B6">1. 配置 masters 文件</h5> 
<p>[root@master hadoop]# vim masters</p> 
<p>[root@master hadoop]# cat masters</p> 
<h5 id="2.%20%E9%85%8D%E7%BD%AE%20slaves%20%E6%96%87%E4%BB%B6">2. 配置 slaves 文件</h5> 
<p>[root@master hadoop]# vim slaves</p> 
<p>[root@master hadoop]# cat slaves</p> 
<h5 id="3.%20%E6%96%B0%E5%BB%BA%E7%9B%AE%E5%BD%95">3. 新建目录</h5> 
<p>[root@master hadoop]# mkdir /usr/local/src/hadoop/tmp</p> 
<p>[root@master hadoop]# mkdir /usr/local/src/hadoop/dfs/name -p</p> 
<p>[root@master hadoop]# mkdir /usr/local/src/hadoop/dfs/data -p</p> 
<h5 id="4.%20%E4%BF%AE%E6%94%B9%E7%9B%AE%E5%BD%95%E6%9D%83%E9%99%90">4. 修改目录权限</h5> 
<p>[root@master hadoop]# chown -R hadoop:hadoop /usr/local/src/hadoop/</p> 
<p><img alt="" height="322" src="https://images2.imgbox.com/c9/63/zshHanLm_o.png" width="1088"></p> 
<h5 id="5.%20%E5%90%8C%E6%AD%A5%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E5%88%B0%20Slave%20%E8%8A%82%E7%82%B9">5. 同步配置文件到 Slave 节点</h5> 
<p>[root@master ~]# scp -r /usr/local/src/hadoop/ root@slave1:/usr/local/src/</p> 
<p><img alt="" height="416" src="https://images2.imgbox.com/c1/81/u01D29gZ_o.png" width="1200"></p> 
<p>[root@master ~]# scp -r /usr/local/src/hadoop/ root@slave2:/usr/local/src/</p> 
<p></p> 
<p>#slave1 配置</p> 
<p>[root@slave1 ~]# yum install -y vim</p> 
<p><img alt="" height="979" src="https://images2.imgbox.com/9c/f7/LlYbrdKc_o.png" width="1200"></p> 
<p>[root@slave1 ~]# vim /etc/profile</p> 
<p>[root@slave1 ~]# tail -n 4 /etc/profile</p> 
<p>[root@slave1 ~]# chown -R hadoop:hadoop /usr/local/src/hadoop/</p> 
<p>[root@slave1 ~]# su - hadoop</p> 
<p>[hadoop@slave1 ~]$ source /etc/profile</p> 
<p><img alt="" height="469" src="https://images2.imgbox.com/6a/77/Oe4wq3A4_o.png" width="1121"></p> 
<p>#slave2 配置</p> 
<p>[root@slave2 ~]# yum install -y vim</p> 
<p><img alt="" height="337" src="https://images2.imgbox.com/0b/3f/kkaTtmSH_o.png" width="1200"></p> 
<p>[root@slave2 ~]# vim /etc/profile</p> 
<p>[root@slave2 ~]# tail -n 4 /etc/profile</p> 
<p>[root@slave2 ~]# chown -R hadoop:hadoop /usr/local/src/hadoop/</p> 
<p>[root@slave2 ~]# su - hadoop</p> 
<p>[hadoop@slave2 ~]$ source /etc/profile</p> 
<p><img alt="" height="426" src="https://images2.imgbox.com/c8/d3/qIVAK2Wj_o.png" width="1159"></p> 
<h3 id="2%E3%80%81%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E9%9B%86%E7%BE%A4%E8%BF%90%E8%A1%8C">2、大数据平台集群运行</h3> 
<h4 id="%E4%B8%80%EF%BC%9A%E9%85%8D%E7%BD%AE%20Hadoop%20%E6%A0%BC%E5%BC%8F%E5%8C%96">一：配置 Hadoop 格式化</h4> 
<h5 id="%E6%AD%A5%E9%AA%A4%E4%B8%80%EF%BC%9ANameNode%20%E6%A0%BC%E5%BC%8F%E5%8C%96">步骤一：NameNode 格式化</h5> 
<p>将 NameNode 上的数据清零，第一次启动 HDFS 时要进行格式化，以后启动无 需再格式化，否则会缺失 DataNode 进程。另外，只要运行过 HDFS，Hadoop 的 工作目录（本书设置为/usr/local/src/hadoop/tmp）就会有数据，如果需要重 新格式化，则在格式化之前一定要先删除工作目录下的数据，否则格式化时会 出问题。</p> 
<p>执行如下命令，格式化 NameNode</p> 
<p>[root@master ~]# su – hadoop</p> 
<p>[hadoop@master ~]# cd /usr/local/src/hadoop/</p> 
<p>[hadoop@master hadoop]$ bin/hdfs namenode –format</p> 
<p><img alt="" height="207" src="https://images2.imgbox.com/cd/04/OXWgseIK_o.png" width="1093"></p> 
<h5 id="%E6%AD%A5%E9%AA%A4%E4%BA%8C%EF%BC%9A%E5%90%AF%E5%8A%A8%20NameNode">步骤二：启动 NameNode</h5> 
<p>执行如下命令，启动 NameNode：</p> 
<p>[hadoop@master hadoop]$ hadoop-daemon.sh start namenode</p> 
<p><img alt="" height="159" src="https://images2.imgbox.com/21/46/J3YLkDrx_o.png" width="1200"></p> 
<h4 id="%E4%BA%8C%EF%BC%9A%E6%9F%A5%E7%9C%8B%20Java%20%E8%BF%9B%E7%A8%8B">二：查看 Java 进程</h4> 
<p>启动完成后，可以使用 JPS 命令查看是否成功。JPS 命令是 Java 提供的一个显示当前所有 Java 进程 pid 的命令。</p> 
<p>[hadoop@master hadoop]$ jps</p> 
<p><img alt="" height="226" src="https://images2.imgbox.com/ab/df/n5pjb6yY_o.png" width="1200"></p> 
<h5 id="%E6%AD%A5%E9%AA%A4%E4%B8%80%EF%BC%9Aslave%E8%8A%82%E7%82%B9%20%E5%90%AF%E5%8A%A8%20DataNode">步骤一：slave节点 启动 DataNode</h5> 
<p>执行如下命令，启动 DataNode：</p> 
<p>[hadoop@slave1 hadoop]$ hadoop-daemon.sh start datanode</p> 
<p>[hadoop@slave2 hadoop]$ hadoop-daemon.sh start datanode</p> 
<p>[hadoop@slave1 hadoop]$ jps</p> 
<p>[hadoop@slave2 hadoop]$ jps</p> 
<h5 id="%E6%AD%A5%E9%AA%A4%E4%BA%8C%EF%BC%9A%E5%90%AF%E5%8A%A8%20SecondaryNameNode">步骤二：启动 SecondaryNameNode</h5> 
<p>执行如下命令，启动 SecondaryNameNode：</p> 
<p>[hadoop@master hadoop]$ hadoop-daemon.sh start secondarynamenode</p> 
<p>[hadoop@master hadoop]$ jps</p> 
<p>查看到有 NameNode 和 SecondaryNameNode 两个进程，就表明 HDFS 启动成功。</p> 
<h5 id="%E6%AD%A5%E9%AA%A4%E4%B8%89%EF%BC%9A%E6%9F%A5%E7%9C%8B%20HDFS%20%E6%95%B0%E6%8D%AE%E5%AD%98%E6%94%BE%E4%BD%8D%E7%BD%AE">步骤三：查看 HDFS 数据存放位置</h5> 
<p>执行如下命令，查看 Hadoop 工作目录：</p> 
<p>[hadoop@master hadoop]$ ll dfs/</p> 
<p>[hadoop@master hadoop]$ ll ./tmp/dfs</p> 
<p><img alt="" height="221" src="https://images2.imgbox.com/82/65/DWQYaueK_o.png" width="1087"></p> 
<h4 id="%E4%B8%89%EF%BC%9A%E6%9F%A5%E7%9C%8B%20HDFS%20%E7%9A%84%E6%8A%A5%E5%91%8A">三：查看 HDFS 的报告</h4> 
<p>[hadoop@master sbin]$ hdfs dfsadmin -report</p> 
<p><img alt="" height="1200" src="https://images2.imgbox.com/c7/64/jpnyVJei_o.png" width="1200"></p> 
<h4 id="%E5%9B%9B%EF%BC%9A%E4%BD%BF%E7%94%A8%E6%B5%8F%E8%A7%88%E5%99%A8%E6%9F%A5%E7%9C%8B%E8%8A%82%E7%82%B9%E7%8A%B6%E6%80%81">四：使用浏览器查看节点状态</h4> 
<p>在浏览器的地址栏输入http://master:50070，进入页面可以查看NameNode和DataNode 信息。</p> 
<p><img alt="" height="1200" src="https://images2.imgbox.com/6d/2f/6ObnpDep_o.png" width="1200"></p> 
<p>在浏览器的地址栏输入 http://master:50090，进入页面可以查看 SecondaryNameNode信息</p> 
<p><img alt="" height="1200" src="https://images2.imgbox.com/a9/76/uKIHsF2y_o.png" width="1200"></p> 
<p>可以使用 start-dfs.sh 命令启动 HDFS。这时需要配置 SSH 免密码登录，否则在 启动过程中系统将多次要求确认连接和输入 Hadoop 用户密码。</p> 
<p>[hadoop@master hadoop]$ stop-dfs.sh</p> 
<p>[hadoop@master hadoop]$ start-dfs.sh</p> 
<p><img alt="" height="781" src="https://images2.imgbox.com/7b/27/QmgIPtfP_o.png" width="1200"></p> 
<p>运行测试： 下面运行 WordCount 官方案例，统计 data.txt 文件中单词的出现频度。这个案例可 以用来统计年度十大热销产品、年度风云人物、年度最热名词等。</p> 
<h5 id="%E6%AD%A5%E9%AA%A4%E4%B8%80%EF%BC%9A%E5%9C%A8%20HDFS%20%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E4%B8%AD%E5%88%9B%E5%BB%BA%E6%95%B0%E6%8D%AE%E8%BE%93%E5%85%A5%E7%9B%AE%E5%BD%95%20%E7%A1%AE%E4%BF%9D%20dfs%20%E5%92%8C%20yarn%20%E9%83%BD%E5%90%AF%E5%8A%A8%E6%88%90%E5%8A%9F">步骤一：在 HDFS 文件系统中创建数据输入目录 确保 dfs 和 yarn 都启动成功</h5> 
<p>[hadoop@master hadoop]$ start-yarn.sh</p> 
<p>[hadoop@master hadoop]$ jps</p> 
<p><img alt="" height="492" src="https://images2.imgbox.com/d5/45/EhG4s7Fo_o.png" width="1200"></p> 
<p>如果是第一次运行 MapReduce 程序，需要先在 HDFS 文件系统中创建数据输入目 录，存放输入数据。这里指定/input 目录为输入数据的存放目录。 执行如下命 令，在 HDFS 文件系统中创建/input 目录：</p> 
<p>[hadoop@master hadoop]$ hdfs dfs -mkdir /input</p> 
<p>[hadoop@master hadoop]$ hdfs dfs -ls /</p> 
<p>此处创建的/input 目录是在 HDFS 文件系统中，只能用 HDFS 命令查看和操作。</p> 
<h5 id="%E6%AD%A5%E9%AA%A4%E4%BA%8C%EF%BC%9A%E5%B0%86%E8%BE%93%E5%85%A5%E6%95%B0%E6%8D%AE%E6%96%87%E4%BB%B6%E5%A4%8D%E5%88%B6%E5%88%B0%20HDFS%20%E7%9A%84%2Finput%20%E7%9B%AE%E5%BD%95%E4%B8%AD">步骤二：将输入数据文件复制到 HDFS 的/input 目录中</h5> 
<p>测试用数据文件仍然是上一节所用的测试数据文件~/input/data.txt，内容如下所示。</p> 
<p>[hadoop@master hadoop]$ cat ~/input/data.txt</p> 
<p>执行如下命令，将输入数据文件复制到 HDFS 的/input 目录中：</p> 
<p>[hadoop@master hadoop]$ hdfs dfs -put ~/input/data.txt /input</p> 
<p>确认文件已复制到 HDFS 的/input 目录：</p> 
<p>[hadoop@master hadoop]$ hdfs dfs -ls /input</p> 
<p><img alt="" height="241" src="https://images2.imgbox.com/c6/6b/X6wtCncr_o.png" width="1200"></p> 
<h5 id="%E6%AD%A5%E9%AA%A4%E4%B8%89%EF%BC%9A%E8%BF%90%E8%A1%8C%20WordCount%20%E6%A1%88%E4%BE%8B%EF%BC%8C%E8%AE%A1%E7%AE%97%E6%95%B0%E6%8D%AE%E6%96%87%E4%BB%B6%E4%B8%AD%E5%90%84%E5%8D%95%E8%AF%8D%E7%9A%84%E9%A2%91%E5%BA%A6%E3%80%82">步骤三：运行 WordCount 案例，计算数据文件中各单词的频度。</h5> 
<p>运行 MapReduce 命令需要指定数据输出目录，该目录为 HDFS 文件系统中的目录，会自 动生成。如果在执行 MapReduce 命令前，该目录已经存在，则执行 MapReduce 命令会出 错。</p> 
<p>例如 MapReduce 命令指定数据输出目录为/output，/output 目录在 HDFS 文件系统中已 经存在，则执行相应的 MapReduce 命令就会出错。所以如果不是第一次运行 MapReduce，就要先查看HDFS中的文件，是否存在/output目录。如果已经存在/output 目录，就要先删除/output目录，再执行上述命令。自动创建的/output 目录在 HDFS 文件 系统中，使用 HDFS 命令查看和操作。</p> 
<p>[hadoop@master hadoop]$ hdfs dfs -mkdir /output</p> 
<p>先执行如下命令查看 HDFS 中的文件：</p> 
<p>[hadoop@master hadoop]$ hdfs dfs -ls</p> 
<p><img alt="" height="121" src="https://images2.imgbox.com/99/e1/6qlKkjaA_o.png" width="991"></p> 
<p>上述目录中/input 目录是输入数据存放的目录，/output 目录是输出数据存放的目录。执 行如下命令，删除/output 目录。</p> 
<p>[hadoop@master hadoop]$ hdfs dfs -rm -r -f /output</p> 
<p><img alt="" height="141" src="https://images2.imgbox.com/ee/04/mfyw9fwK_o.png" width="1192"></p> 
<p>执行如下命令运行 WordCount 案例：</p> 
<p>[hadoop@master hadoop]$ hadoop jar share/hadoop/mapreduce/hado map op-- reduce-examples-2.7.1.jar wordcount /input/data.txt /output</p> 
<p><img alt="" height="879" src="https://images2.imgbox.com/26/33/2snlgzu5_o.png" width="1200"></p> 
<p>由上述信息可知 MapReduce 程序提交了一个作业，作业先进行 Map，再进行 Reduce 操作。 MapReduce 作业运行过程也可以在 YARN 集群网页中查看。在浏 览器的地址栏输入：http://master:8088 可以看到 MapReduce 程序刚刚完成了一个作业。</p> 
<p><img alt="" height="1016" src="https://images2.imgbox.com/a6/b7/sMbItFxf_o.png" width="1200"></p> 
<p>除了可以用 HDFS 命令查看 HDFS 文件系统中的内容，也可使用网页查看 HDFS 文件 系统。在浏览器的地址栏输入 http://master:50070，进入页面，在 Utilities 菜单中 选择 Browse the file system，可以查看 HDFS 文件系统内容。查看 HDFS 的根目录，可以看到 HDFS 根目录中有三个目录，input、output 和 tmp。</p> 
<p><img alt="" height="587" src="https://images2.imgbox.com/05/9b/jhoLEJ2s_o.png" width="1200"></p> 
<p>查看 output 目录，发现有两个文件。文件_SUCCESS 表示处理成功，处理的结果 存放在 part-r-00000 文件中。在页面上不能直接查看文件内容，需要下载到本地系统才行。</p> 
<p><img alt="" height="1075" src="https://images2.imgbox.com/c2/a1/mMzT8AyK_o.png" width="1200"></p> 
<p>可以使用 HDFS 命令直接查看 part-r-00000 文件内容，结果如下所示：</p> 
<p>[hadoop@master hadoop]$ hdfs dfs -cat /output/part-r-00000</p> 
<h4 id="%E4%BA%94%EF%BC%9A%E5%81%9C%E6%AD%A2%20Hadoop">五：停止 Hadoop</h4> 
<h5 id="%E6%AD%A5%E9%AA%A4%E4%B8%80%EF%BC%9A%E5%81%9C%E6%AD%A2%20yarn">步骤一：停止 yarn</h5> 
<p>[hadoop@master hadoop]$ stop-yarn.sh</p> 
<p><img alt="" height="178" src="https://images2.imgbox.com/dd/8b/vaM9xA4t_o.png" width="996"></p> 
<h5 id="%E6%AD%A5%E9%AA%A4%E4%BA%8C%EF%BC%9A%E5%81%9C%E6%AD%A2%20DataNode">步骤二：停止 DataNode</h5> 
<p>[hadoop@slave1 hadoop]$ hadoop-daemon.sh stop datanode </p> 
<p><img alt="" height="78" src="https://images2.imgbox.com/3c/3b/9S2U9DZv_o.png" width="1109"></p> 
<p>[hadoop@slave2 hadoop]$ hadoop-daemon.sh stop datanode </p> 
<p><img alt="" height="78" src="https://images2.imgbox.com/b4/6b/SmUxw7p4_o.png" width="1109"></p> 
<h5 id="%E6%AD%A5%E9%AA%A4%E4%BA%8C%EF%BC%9A%E5%81%9C%E6%AD%A2%20NameNode">步骤二：停止 NameNode</h5> 
<p>[hadoop@master hadoop]$ hadoop-daemon.sh stop namenode </p> 
<h5 id="%E6%AD%A5%E9%AA%A4%E4%B8%89%EF%BC%9A%E5%81%9C%E6%AD%A2%20SecondaryNameNode">步骤三：停止 SecondaryNameNode</h5> 
<p>[hadoop@master hadoop]$ hadoop-daemon.sh stop secondarynamenode </p> 
<h5 id="%E6%AD%A5%E9%AA%A4%E5%9B%9B%EF%BC%9A%E6%9F%A5%E7%9C%8B%20JAVA%20%E8%BF%9B%E7%A8%8B%EF%BC%8C%E7%A1%AE%E8%AE%A4%20HDFS%20%E8%BF%9B%E7%A8%8B%E5%B7%B2%E5%85%A8%E9%83%A8%E5%85%B3%E9%97%AD">步骤四：查看 JAVA 进程，确认 HDFS 进程已全部关闭</h5> 
<p>[hadoop@master hadoop]$ jps</p> 
<p><img alt="" height="175" src="https://images2.imgbox.com/d1/d4/kBpoliL5_o.png" width="1004"></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p style="text-align:center;"></p> 
<p></p> 
<p style="text-align:center;"></p> 
<p></p> 
<p style="text-align:center;"></p> 
<p style="text-align:center;"></p> 
<p style="text-align:center;"></p> 
<p></p> 
<p style="text-align:center;"></p> 
<p style="text-align:center;"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/806907b1b088d8ac707141e357dace64/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">基于Java的物联网云平台完整源码及功能模块解析</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/3974d503979d6bd3ea8eb32139ef9726/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">学生或教师免费申请copilot</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>