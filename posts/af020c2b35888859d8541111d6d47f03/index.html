<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Windows下安装LLama-Factory - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/af020c2b35888859d8541111d6d47f03/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="Windows下安装LLama-Factory">
  <meta property="og:description" content="在进行安装前，请先确认你的GPU能支撑起训练的显存。如果和可怜的我一样是4GB可以选择上云或者换一个好一点的显卡。并且确定你安装了显卡驱动版本在官方给的版本以上，如果没有安装，详细参考我的另一篇文章：LLama-Factory运行异常，CUDA没安装，nvidia-smi的版本假的？-CSDN博客
注意nvidia-smi不一定是你的版本，我也被坑了一次，然后重新装了一遍。
一、下载LLamaFactory llama-factory地址，如果你使用git拉取代码，可能会因为网络问题拉取失败，可以多试几次，或者直接下载文件包。
git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git 二、环境准备 针对LLamaFactory的安装软硬件环境，官方文档已经给出了软硬件的要求：
· 如果你有Python环境可以直接进行跳过以下步骤，如果你是conda选手需要创建虚拟环境并且激活环境。
新建虚拟环境
conda create -n llama_factory python=3.11 -y 激活虚拟环境
conda activate llama_factory 三、依赖安装 确认你的Python环境生效，在你的LLama-Factory的文件夹下执行以下命令
在LLama-Factory的官方文档中，有各个依赖，推荐是按需下载，我这里省事直接全部下载了
pip install -e . 按需下载
pip install -e .[metrics,modelscope,qwen] 官方给的额外依赖项：torch、torch-npu、metrics、deepspeed、bitsandbytes、hqq、eetq、gptq、awq、aqlm、vllm、galore、badam、qwen、modelscope、quality
安装torch依赖--&gt;gpu版本
这里你可以去官方链接找你的版本，只要下翻就能看见或者查看更多版本。这里一定要确认你的cuda版本，可以向下兼容，如果你是conda环境请选Conda。
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 安装成功可以在Python环境下使用下面命令，如果是True，则安装成功
import torch torch.cuda.is_available() 针对windows用户，官方要求安装bitsandbytes
pip install https://github.com/jllllll/bitsandbytes-windows-webui/releases/download/wheels/bitsandbytes-0.41.2.post2-py3-none-win_amd64.whl 安装tensorboard与启用ModelScope Hub （这两个命令我没有在官方中看到必须，但我参考了其他博客试了一遍，对项目也没影响我也执行了）
pip install tensorboard Set USE MODELSCOPE HUB=1 四、启动项目 两种方式都可以
llamafactory-cli webui 或">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-07-16T15:18:16+08:00">
    <meta property="article:modified_time" content="2024-07-16T15:18:16+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Windows下安装LLama-Factory</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>        在进行安装前，请先确认你的GPU能支撑起训练的显存。如果和可怜的我一样是4GB可以选择上云或者换一个好一点的显卡。并且确定你安装了显卡驱动版本在官方给的版本以上，如果没有安装，详细参考我的另一篇文章：<a href="https://blog.csdn.net/lx15983596831/article/details/140466261?spm=1001.2014.3001.5502" title="LLama-Factory运行异常，CUDA没安装，nvidia-smi的版本假的？-CSDN博客">LLama-Factory运行异常，CUDA没安装，nvidia-smi的版本假的？-CSDN博客</a></p> 
<p>        注意nvidia-smi不一定是你的版本，我也被坑了一次，然后重新装了一遍。</p> 
<h2>一、下载LLamaFactory</h2> 
<p>       <a class="link-info" href="https://github.com/hiyouga/LLaMA-Factory" title="llama-factory地址">llama-factory地址</a>，如果你使用git拉取代码，可能会因为网络问题拉取失败，可以多试几次，或者直接下载文件包。</p> 
<pre><code class="language-python">git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git</code></pre> 
<h2>二、环境准备</h2> 
<p>        针对LLamaFactory的安装软硬件环境，官方文档已经给出了软硬件的要求：</p> 
<p class="img-center"><img alt="" height="576" src="https://images2.imgbox.com/b0/2e/o2nASAzN_o.png" width="429"></p> 
<p>·        如果你有Python环境可以直接进行跳过以下步骤，如果你是conda选手需要创建虚拟环境并且激活环境。</p> 
<p>        新建虚拟环境</p> 
<pre><code>conda create -n llama_factory python=3.11 -y</code></pre> 
<p>        激活虚拟环境</p> 
<pre><code>conda activate llama_factory</code></pre> 
<h2>三、依赖安装</h2> 
<p>        确认你的Python环境生效，在你的LLama-Factory的文件夹下执行以下命令</p> 
<p>        在LLama-Factory的官方文档中，有各个依赖，推荐是按需下载，我这里省事直接全部下载了</p> 
<pre><code class="language-bash">pip install -e .
</code></pre> 
<p>        按需下载</p> 
<pre><code class="language-bash">pip install -e .[metrics,modelscope,qwen]</code></pre> 
<blockquote> 
 <p>官方给的额外依赖项：torch、torch-npu、metrics、deepspeed、bitsandbytes、hqq、eetq、gptq、awq、aqlm、vllm、galore、badam、qwen、modelscope、quality</p> 
</blockquote> 
<p>        安装torch依赖--&gt;gpu版本</p> 
<p>        这里你可以去<a class="link-info" href="https://pytorch.org/" rel="nofollow" title="官方链接">官方链接</a>找你的版本，只要下翻就能看见或者查看更多版本。这里一定要确认你的cuda版本，可以向下兼容，如果你是conda环境请选Conda。</p> 
<p class="img-center"><img alt="" height="240" src="https://images2.imgbox.com/99/52/5MPs3snP_o.png" width="434"></p> 
<pre><code class="language-bash">pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118</code></pre> 
<p>       安装成功可以在Python环境下使用下面命令，如果是True，则安装成功</p> 
<pre><code class="language-bash">import torch
torch.cuda.is_available()</code></pre> 
<p>         针对windows用户，官方要求安装<code>bitsandbytes</code></p> 
<pre><code class="language-bash">pip install https://github.com/jllllll/bitsandbytes-windows-webui/releases/download/wheels/bitsandbytes-0.41.2.post2-py3-none-win_amd64.whl</code></pre> 
<p>        安装tensorboard与启用ModelScope Hub （这两个命令我没有在官方中看到必须，但我参考了<a class="link-info" href="https://blog.csdn.net/m0_60683691/article/details/138505394" title="其他博客">其他博客</a>试了一遍，对项目也没影响我也执行了）</p> 
<pre><code class="language-bash">pip install tensorboard</code></pre> 
<pre><code class="language-bash">Set USE MODELSCOPE HUB=1</code></pre> 
<h2>四、启动项目</h2> 
<p>        两种方式都可以</p> 
<pre><code class="language-bash">llamafactory-cli webui</code></pre> 
<p>或</p> 
<pre><code class="language-bash">python src/webui.py</code></pre> 
<p>         如果顺利：</p> 
<p> <img alt="" height="884" src="https://images2.imgbox.com/b1/c4/oiP0Pa28_o.png" width="1200"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/d1ce5f3e33e23876b5116101985f8783/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">欢迎来到 Mint Expedition：Web3 和 NFT 的新时代开始</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/87857c323bbb2f62a83bd87caebd4750/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">解析 Mira ：基于 Web3，让先进的 AI 技术易于访问和使用</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>