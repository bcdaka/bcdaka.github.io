<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【论文阅读-问答】人工智能生成内容增强的甲状腺结节计算机辅助诊断模型:CHATGPT风格的助手 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/56e37e37ec3b1cc9c77dd7d58eff8224/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="【论文阅读-问答】人工智能生成内容增强的甲状腺结节计算机辅助诊断模型:CHATGPT风格的助手">
  <meta property="og:description" content="人工智能生成内容增强的甲状腺结节计算机辅助诊断模型:CHATGPT风格的助手 写在最前面作者单位摘要ABSTRACT1. 简介2. 材料与方法1. 患者2. 总体设计4. 图像采集5. 标注和预处理6. 统计分析 3. 结果4. 讨论参考文献References 🌈你好呀！我是 是Yu欸 🌌 2024每日百字篆刻时光，感谢你的陪伴与支持 ~ 🚀 欢迎一起踏上探险之旅，挖掘无限可能，共同成长！ 写在最前面 主题：医学、对话模型、问答、多模态（图文）
原文：AI-Generated Content Enhanced Computer-Aided Diagnosis Model for Thyroid Nodules: A ChatGPT-Style Assistant
链接：https://arxiv.org/abs/2402.02401
（1）该模型首次尝试使用包括医生诊断报告、病理结果、国际诊断指南、研究报告、超声图像等多源 信息的大规模综合构建甲状腺结节风险LLM。
（2）首次提出了AIGC-CAD的概念。AIGC-CAD使模型能够使用生成式大型模型为人工智能辅助诊断过程中涉及的病变的不同组成部分和图像语义生成解释性文本和特征标记。该方法提供了更直观的显示和分析，从而更好地辅助临床医生。
作者单位 Jincao Yao1*,2,3,4,5,6#, Yunpeng Wang7#, Zhikai Lei8#, Kai Wang9#, Xiaoxian Li10*, Jianhua Zhou10, Xiang Hao7, Jiafei Shen1*,2, Zhenping Wang9*, Rongrong Ru11, Yaqing Chen11, Yahan Zhou6,**
Chen Chen1*,2*, Yanming Zhang12*,13∗, Ping Liang14∗*, Dong Xu**1*,2,3,4,5,*6∗">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-04-18T08:30:00+08:00">
    <meta property="article:modified_time" content="2024-04-18T08:30:00+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【论文阅读-问答】人工智能生成内容增强的甲状腺结节计算机辅助诊断模型:CHATGPT风格的助手</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-tomorrow-night">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>人工智能生成内容增强的甲状腺结节计算机辅助诊断模型:CHATGPT风格的助手</h4> 
 <ul><li><a href="#_15" rel="nofollow">写在最前面</a></li><li><a href="#_23" rel="nofollow">作者单位</a></li><li><a href="#ABSTRACT_53" rel="nofollow">摘要ABSTRACT</a></li><li><a href="#1__64" rel="nofollow">1. 简介</a></li><li><a href="#2__79" rel="nofollow">2. 材料与方法</a></li><li><ul><li><a href="#1___81" rel="nofollow">1. 患者</a></li><li><a href="#2___87" rel="nofollow">2. 总体设计</a></li><li><a href="#4___106" rel="nofollow">4. 图像采集</a></li><li><a href="#5___110" rel="nofollow">5. 标注和预处理</a></li><li><a href="#6___121" rel="nofollow">6. 统计分析</a></li></ul> 
  </li><li><a href="#3__127" rel="nofollow">3. 结果</a></li><li><a href="#4__165" rel="nofollow">4. 讨论</a></li><li><a href="#References_178" rel="nofollow">参考文献References</a></li></ul> 
</div> 
<p></p> 
<hr> 
<p><img src="https://images2.imgbox.com/40/8d/WxKH1U7N_o.png" alt="请添加图片描述" width="100" height="100"></p> 
<center> 
 <font color="#FF77A9" face="STKaiti" size="4">🌈你好呀！我是 <a href="https://blog.csdn.net/WTYuong?spm=1010.2135.3001.5343">是Yu欸 </a></font> 
</center> 
<center> 
 <font color="#007FFF" face="KaiTi">🌌 2024每日百字篆刻时光，感谢你的陪伴与支持 ~</font> 
</center> 
<center> 
 <font color="#007FFF" face="KaiTi">🚀 欢迎一起踏上探险之旅，挖掘无限可能，共同成长！</font> 
</center> 
<hr> 
<h2><a id="_15"></a>写在最前面</h2> 
<p>主题：医学、对话模型、问答、多模态（图文）<br> 原文：AI-Generated Content Enhanced Computer-Aided Diagnosis Model for Thyroid Nodules: A ChatGPT-Style Assistant<br> 链接：<a href="https://arxiv.org/abs/2402.02401" rel="nofollow">https://arxiv.org/abs/2402.02401</a></p> 
<p>（1）该模型首次尝试使用包括医生诊断报告、病理结果、国际诊断指南、研究报告、超声图像等多源 信息的大规模综合构建甲状腺结节风险LLM。<br> （2）首次提出了AIGC-CAD的概念。AIGC-CAD使模型能够使用生成式大型模型为人工智能辅助诊断过程中涉及的病变的不同组成部分和图像语义生成解释性文本和特征标记。该方法提供了更直观的显示和分析，从而更好地辅助临床医生。</p> 
<h2><a id="_23"></a>作者单位</h2> 
<blockquote> 
 <p><strong>Jincao Yao</strong>1*,<em>2</em>,<em>3</em>,<em>4</em>,<em>5</em>,<em>6#<strong>, Yunpeng Wang</strong>7#<strong>, Zhikai Lei</strong>8#<strong>, Kai Wang</strong>9#<strong>, Xiaoxian Li</strong>10</em>*, Jianhua Zhou<strong>10</strong>, Xiang Hao<strong>7</strong>, Jiafei Shen<em><em>1*,<em>2</em></em>, Zhenping Wang</em><em>9</em>*, Rongrong Ru<strong>11</strong>, Yaqing Chen<strong>11</strong>, Yahan Zhou<strong>6</strong>,**</p> 
 <p><strong>Chen Chen</strong>1*,<em>2</em>*, Yanming Zhang<em><em>12*,<em>13∗</em></em>, Ping Liang</em><em>14∗</em>*, Dong Xu**1*,<em>2</em>,<em>3</em>,<em>4</em>,<em>5</em>,*6∗</p> 
 <p><sup>1</sup>Department of Radiology, Zhejiang Cancer Hospital, Hangzhou, 310022, China</p> 
 <p><sup>2</sup>Hangzhou Institute of Medicine (HIM), Chinese Academy of Sciences, Hangzhou, 310000, China</p> 
 <p><sup>3</sup>Key Laboratory of Head &amp; Neck Cancer Translational Research of Zhejiang Province, Hangzhou, 310022, China</p> 
 <p><sup>4</sup>Zhejiang Provincial Research Center for Cancer Intelligent Diagnosis and Molecular Technology, Hangzhou, 310000, China</p> 
 <p><sup>5</sup>Wenling Medical Big Data and Artificial Intelligence Research Institute, 24th Floor, Machang Road, Taizhou, 310061, China</p> 
 <p><sup>6</sup>Taizhou Key Laboratory of Minimally Invasive Interventional Therapy &amp; Artificial Intelligence, Taizhou Campus of Zhejiang Cancer Hospital (Taizhou Cancer Hospital), Taizhou, 317502, China <sup>7</sup>College of Optical Science and Engineering, Zhejiang University,</p> 
 <p>No.38 of Zheda Road, Hangzhou, Zhejiang Province, China</p> 
 <p><sup>8</sup>Zhejiang Provincial Hospital of Chinese Medicine, 54 Youdian Road, Hangzhou, 310003, China <sup>9</sup>Department of Ultrasound, The Affiliated Dongyang Hospital of Wenzhou Medical University, Dongyang, 322100, China</p> 
 <p><sup>10</sup>Department of Ultrasound, Sun Yat-sen University Cancer Center, State Key Laboratory of Oncology in South China, Collaborative Innovation Center for Cancer Medicine, Guangzhou, 510060, China <sup>11</sup>Affiliated Xiaoshan Hospital, Hangzhou Normal University, No.728 North Yucai Road,</p> 
 <p>Hangzhou, 311202, China</p> 
 <p><sup>12</sup>Zhejiang Provincial People’s Hospital Affiliated People’s Hospital, Hangzhou Medical College, Hangzhou, 314408, China</p> 
 <p><sup>13</sup>Key Laboratory of Endocrine Gland Diseases of Zhejiang Province, Hangzhou, 314408, China <sup>14</sup>Department of Ultrasound, Chinese PLA General Hospital, Chinese PLA Medical School, Beijing, 100853, China</p> 
</blockquote> 
<h2><a id="ABSTRACT_53"></a>摘要ABSTRACT</h2> 
<p>本文提出了一个人工智能生成的内容增强计算机辅助诊断模型(artificial intelligence-generated content-enhanced computer-aided diagnosis, AIGC-CAD)。</p> 
<p>该模型受ChatGPT架构启发，可通过语义级人机交互协助放射科医生评估甲状腺结节的风险。</p> 
<p>为了方便模型的训练和验 证，构建了一个由浙江省肿瘤医院19165例甲状腺结节超声病例组成的数据集。</p> 
<p>经过培 训后，ThyGPT可以自动评估甲状腺结节，并通过人机交互与医生进行有效沟通。使用既 定的指标，如受试者工作特征(ROC)曲线、曲线下面积(AUC)、敏感性和特异性，严格量 化ThyGPT的性能。</p> 
<p>实证结果显示，放射科医生在补充ThyGPT时，明显超过了他们使用传统方法的同行的诊断灵敏度，以及单独使用模型的性能。这些发现表明，以ThyGPT为例 的AIGC-CAD系统有望在未来几年从根本上改变放射科医生的诊断工作流程。</p> 
<h2><a id="1__64"></a>1. 简介</h2> 
<blockquote> 
 <p>甲状腺结节是一种常见的内分泌疾病，高达68％的成年人患有此病，其中大约7-15％是甲状腺癌[<a href="#bookmark0" rel="nofollow">1</a>–<a href="#bookmark1" rel="nofollow">3</a>]。 超声由于其无创、无辐射、用户友好的特点，是评估甲状腺结节的首选影像诊断方法[<a href="#bookmark1" rel="nofollow">3</a>]。然而，超声 诊断高度依赖临床医师经验，导致主观性和不一致性[<a href="#bookmark2" rel="nofollow">4</a>]。为了更客观准确地评估甲状腺结节，许多研究人员已经开始建立计算机辅助诊断(Computer-Aided Diagnosis, CAD)模型。这些模型旨在从超声图像中提取特征，以辅助临床医生进行更客观和精确的评估。一系列研究表明，基于深度学习的CAD模型， 如ThyNet和RadImageNet <a href="#bookmark4" rel="nofollow">[5–7]</a>，取得了良好的效果。</p> 
 <p>尽管有这些进步，上述CAD方法仍有不可忽视的重大缺陷。一方面，传统的CAD模型无法提供其诊断或分 析决策过程声后的基本原理，在医生和CAD模型之间造成了理解上的差距[<a href="#bookmark4" rel="nofollow">7</a>, <a href="#bookmark5" rel="nofollow">8</a>]。这种"黑箱"特性削弱了医生、患者和医疗保健管理员对诊断结果的信心[<a href="#bookmark6" rel="nofollow">9</a>]。另一方面，大多数现有的CAD模型仅机械地提供模式识 别概率，如恶性肿瘤或转移的概率，而没有与临床医生进一步交互[<a href="#bookmark7" rel="nofollow">10</a>, <a href="#bookmark8" rel="nofollow">11</a>]。这种"静音盒"特性导致许多临床医生放弃这些CAD模型，转而采用透明、可理解和可解释的传统诊断方法[<a href="#bookmark9" rel="nofollow">12</a>–<a href="#bookmark10" rel="nofollow">16</a>]。这一现象引发了关于 人工智能在医学影像应用中的实际作用的争论，并在一定程度上阻碍了大数据和人工智能技术在辅助诊断 领域的发展和应用<a href="#bookmark12" rel="nofollow">[17–20]</a>。</p> 
 <p>最近，以ChatGPT为代表的生成式大型语言模型(llm)发展迅速，在语义理解、人机交互和机器人技术等方 面表现出了优于其他传统模型的性能[<a href="#bookmark13" rel="nofollow">21</a>–<a href="#bookmark15" rel="nofollow">25</a>]。这些llm的出现为弥合医生和AI模型之间的"互动"和"理解"差距提供了机会[<a href="#bookmark16" rel="nofollow">26</a>–<a href="#bookmark18" rel="nofollow">31</a>]。同时，也为构建下一代ai生成内容增强的计算机辅助诊断(AIGC-CAD)框架奠定了基础。本文构建了一个大型语言模型------甲状腺结节生成预训练Transformer (ThyGPT)，专注于甲状腺结节的风险评估。为了有效地训练ThyGPT，我们回顾性地收集了超声图像、匿名超声诊断报告、美国、欧洲等 国的甲状腺结节诊断指南和研究报告作为训练语料库。经过训练后，ThyGPT能够通过人机交互直观地展 示CAD模型的决策原理以及临床医生感兴趣的超声特征对辅助诊断的贡献。与前几代只能输出良恶性条件概率的诊断模型相比，ThyGPT模型使AI分析的逻辑更加透明。它还允许临床医生在模型辅助诊断过程中观察和考虑各种中间结果，显著提高了使用CAD模型的信心。</p> 
</blockquote> 
<p>本研究的创新之处有两个:<br> (1)据我们所知，ThyGPT是人工智能辅助诊断甲状腺结节领域的第一个大型语言模 型研究。该模型首次尝试使用包括医生诊断报告、病理结果、国际诊断指南、研究报告、超声图像等多源 信息的大规模综合构建甲状腺结节风险LLM。<br> (2)首次提出了AIGC-CAD的概念。AIGC-CAD使模型能够使用生成式大型模型为人工智能辅助诊断过程中涉及的病变的不同组成部分和图像语义生成解释性文本和特 征标记。该方法提供了更直观的显示和分析，从而更好地辅助临床医生。</p> 
<p>本文所构建的ThyGPT只是甲状腺领域这一新范式的初步探索。这种新的CAD范式有可能成为下一代CAD的主流方向，并彻底改变临床医生 使用CAD工具的方式。</p> 
<h2><a id="2__79"></a>2. 材料与方法</h2> 
<h3><a id="1___81"></a>1. 患者</h3> 
<blockquote> 
 <p>本回顾性研究经参与医院伦理委员会批准，免予知情同意。这项研究是根据《赫尔辛基宣言》的道德准则 进行的，所有数据都是匿名的。最初，我们随机收集了总计135,861张甲状腺结节超声图像，来自21,674例患者，均获得了病理结果。收集了包括ACR和EU甲状腺结节诊断指南在内的12,781份匿名超声诊断报告和 超过100万字的相关文本，用于构建模型的训练和测试集。</p> 
 <p>回顾性病例入选标准为:(1)超声检查时发现甲状腺结节，并记录超声图像;(2)术后行甲状腺全切或甲状腺叶切 除术，并记录病理结果;(3)患者行细针穿刺，明确阳性结果。排除标准为:(1)甲状腺结节对应超声图像缺失或 不完整，如结节过大而无法在单张图像中显示或关键图像缺失;(2)术前接受其他类型治疗，如I131治疗;(3)患者临床信息不完整，如患者基本信息缺失、既往治疗史缺失等。排除后，保留了19,165例患者和12,073份匿名超声诊断报告的数据。其中，随机选取15136例患者作为训练集，1933例患者作为独立测试集1,2096例患者作为独立测试集2。</p> 
</blockquote> 
<h3><a id="2___87"></a>2. 总体设计</h3> 
<blockquote> 
 <p>图1是我们提出的用于甲状腺结节辅助诊断的AIGC-CAD模型的总体设计。首先，我们将预先标记的结节病理信息、匿名的诊断报告、甲状腺相关诊断指南、研究文档以及手动圈定的结节掩模和边界框输入到模型 中，用于ThyGPT模型的训练和参数优化。一旦训练完成，ThyGPT模型的相关参数就固定了。然后，将独立测试集的数据输入到ThyGPT模型中进行结节分析和辅助诊断;该模型可以自动扫描典型的超声特征，如钙化、边缘情况等，并结合特征热图分析哪些特征对最终的分化贡献最大。</p> 
</blockquote> 
<ol start="3"><li>模型</li></ol> 
<blockquote> 
 <p>本文使用的基本框架是LlaMA2-13B模型[<a href="#bookmark13" rel="nofollow">21</a>]，在此基础上进一步进行训练，包括监督式训练，包括描述甲状腺病例的任务说明和甲状腺医生的语言习惯。采用Bleu评分和人工评价作为综合评价指标。该模型的骨干 网络采用基于GPT系列设计的Lang-Chain框架，利用文档加载器、文本分割器和向量库对甲状腺相关知识和病例进行分割、向量化和存储。图像分析模型在Swin-Transformer和DCNN模型的混合上进行训练[<a href="#bookmark14" rel="nofollow">23</a>, <a href="#bookmark17" rel="nofollow">27</a>]，</p> 
</blockquote> 
<p><img src="https://images2.imgbox.com/21/9d/rXjCnkri_o.png" alt="Figure 1: 甲状腺结节的ThyGPT模型的总体设计。"></p> 
<p>Figure 1: 甲状腺结节的ThyGPT模型的总体设计。</p> 
<blockquote> 
 <p>该模型涉及自注意力、卷积和编码器-解码器架构。最后，融合图像分析模型和结节识别模型建立ThyGPT模型。图2显示了我们大型模型的内部设计架构，包括骨干网络、图像分析网络和结节识别网络。</p> 
</blockquote> 
<p><img src="https://images2.imgbox.com/37/13/LFaTfx6A_o.png" alt="在这里插入图片描述"><br> Figure 2: ThyGPT模型的内部设计架构。</p> 
<h3><a id="4___106"></a>4. 图像采集</h3> 
<blockquote> 
 <p>图像采集时，患者取仰卧位，伸直颈部，暂时避免吞咽，充分暴露颈部。检查医生扫描甲状腺并存储至少 一个横断面、纵向或特征断面超声图像。本研究回顾性收集的超声成像数据来自31台机器，包括GE、西门子、东芝和飞利浦。所有收集超声图像的放射科医生均经过专业培训，所有数据均由至少一名具有10年以 上工作经验的资深放射科医生进行质量控制。</p> 
</blockquote> 
<h3><a id="5___110"></a>5. 标注和预处理</h3> 
<p>使用掩膜标注来描述结节的形状和具有不同语义的感兴趣区域；<br> 此外，我们记录结节的良恶性、钙化、 边缘、回声等。</p> 
<p>所有超声图像都进行了匿名化，删除了任何可能识别患者的信息，从而保护了患者的隐 私。</p> 
<p>采用常用的图像增强方法扩充训练集，提高模型训练的鲁棒性，包括正负10度旋转、随机裁剪、80％ ～120％的随机缩放。</p> 
<h3><a id="6___121"></a>6. 统计分析</h3> 
<blockquote> 
 <p>使用ROC和AUC(曲线下面积)、敏感性和特异性值评估模型的性能。<br> 此外，设计了一个综合的性能评估来 评估ThyGPT模型的有效性，包括放射科医生单独阅读图像的性能、模型的独立识别能力以及放射科医生 与AIGC-CAD模型交互的二级判断。采用DeLong方法计算指标的95％置信区间(confidence interval, CIs)。<br> 所有指标的计算和ROC曲线的绘制均使用Python编程语言，使用matplotlib和sklearn等库。</p> 
</blockquote> 
<h2><a id="3__127"></a>3. 结果</h2> 
<blockquote> 
 <p>我们的实验结果在两个独立的测试集上进行了验证。第一个独立的测试集由1933名患者组成，其中947名 患者术后被证实患有恶性肿瘤。第二组包括2096例患者，其中1021例术后确诊为恶性肿瘤。<br> 在本研究中， 我们建立了一套辅助医生使用ThyGPT的诊断规则，即:<br> (1)由医生和ThyGPT进行初步独立评估;<br> (2)当医生和ThyGPT的判断达成一致时，不作修改;<br> (3)当评估结果有差异时，医生引导和询问ThyGPT;<br> (4)最终，医生可以根据ThyGPT产生的反应来修正他们的初步判断。</p> 
</blockquote> 
<p><img src="https://images2.imgbox.com/3b/02/ZjZAYj08_o.png" alt="在这里插入图片描述"></p> 
<p>Figure 3: 样本病例的医生错误和正确的ThyGPT评估。</p> 
<blockquote> 
 <p>图3和图4显示了几个代表性的案例。图3显示了临床医生最初错误的样本，但在审查了ThyGPT的分析后，他们修改了他们的诊断。具体来说，在图3的样本1中，放射学的初步诊断倾向于恶性，而胸腺pt扫 描图像后，识别结节为良性，提供了包括长宽比、钙化特性和结节组成的基本原理。因此，医生在考虑 了ThyGPT的输出后修订了诊断。在样本2的诊断中，临床医生观察到环形钙化，典型与良性结节相关，因此初步判断结节为良性。然而，胸腺pt评估结节为恶性，忽略了环形钙化的良性特征，并强调关键的恶性特 征位于结节的边缘区域。互动后，医生接受了ThyGPT的评估ThyGPT的详细响应如图3所示。</p> 
</blockquote> 
<p><img src="https://images2.imgbox.com/0c/13/LI24cynG_o.png" alt="在这里插入图片描述"><br> Figure 4: 医生正确和错误的ThyGPT评估样本案例。</p> 
<blockquote> 
 <p>图4为临床医生正确诊断的病例，而ThyGPT出现错误，但经沟通后医生否决了ThyGPT的判断。例如，在样本1中，病理结果为恶性，但模型评估结节为良性，概率为0.303。在检查模型的热图后，医生得出结论，高重量区域没有传达关键信息，模型的目标区域偏离了实际的结节位置，使得模型的诊断不可靠。因此，医 生维持恶性诊断。对于样本2，病理结果为良性结节，模型错误地将其评估为恶性。医生认为热图过于集中 在囊性区域，缺乏参考价值，质疑模型的判断，指导模型重新计算，忽略了囊性区域的错误特征。然后， 该模型根据医生的指示提供正确的诊断。</p> 
</blockquote> 
<blockquote> 
 <p>图X(a)展示了测试集1中不同方法的ROC曲线以及四位临床医生的真阳性率(TPR)和真阴性率(TNR)。最初， 我们将ThyGPT的性能(如图X中红色曲线所示)与几个当代模型进行了比较，ThyGPT在测试集1中获得了0.909的AUC。另外， 我们比较了两名初级医师(5年经验)和两名高级医师(10年以上经验)独立及在ThyGPT辅助下的结果。图6提供了敏感性和特异性的比较分析:没有ThyGPT，初级医生在测试集1和2上的平均敏感性分别为69.8％和67.8％，特异性平均为67.2％和71.7％。当参考传统CAD模型时，初级医生在两个测试集上的平均敏感性分别增加到88.7％和87.1％，特异性分别增加到81.5％和85.6％。在没有ThyGPT的情况下，高级医生表现出82.7％和82.0％的敏感性和80.5％至81.3％的特异性。<br> 经咨询ThyGPT，高级医师的敏感性提高到94.5％和91.1％，特异性提高到89.0％和88.8％。单独ThyGPT在独立测试集上的敏感性 为86.2％和84.7％，特异性为88.3％和87.0％。数据表明，在咨询了ThyGPT后，初级医生的诊断性能超过了高级医生，达到了与经过广泛培训的ThyGPT相当的诊断效能。此外，高级医生提高了他们的诊断能力，超越了独立的AI模型的独立判断，达到了前所未有的准确性水平。</p> 
</blockquote> 
<p>红色曲线为ThyGPT的检测曲线;<br> 黑色十字和x线表示初级医师独立判断曲线;<br> 黑色三角形和五角形代表高级医师的独立判断结果;<br> 绿色叉和x标记表示初级医师参考可解释模型后的诊断结果;<br> 绿色三角形和五角形表示高 级医师参考可解释模型后的诊断结果。</p> 
<p><img src="https://images2.imgbox.com/e8/bb/DojbmDEl_o.png" alt="在这里插入图片描述"></p> 
<blockquote> 
 <p>Figure 5: 临床医生对深度学习方法的诊断结果与ROC曲线。</p> 
</blockquote> 
<h2><a id="4__165"></a>4. 讨论</h2> 
<blockquote> 
 <p>在这项研究中，我们训练和建立了一个基于下一代生成式Transformer架构的大型模型ThyGPT。该模型是 一个能够与临床医生进行深度交互的AIGC-CAD (Artificial Intelligence-Generated Content-Computer Aided Diagnosis)系统。经过训练，ThyGPT成功理解了甲状腺结节超声图像中的各种成像特征及其对应的结节成分，通过人机交互展示了每个感兴趣的超声特征在CAD模型决策过程中的贡献。该模型在提高诊断准确性方面具有优势，特别是对初级放射科医生。观察者之间的差异在超声图像解释是重要的，特别是在初级放 射科医师。在两个独立的测试集上，初级放射科医生在参考甲状腺pt后，显示了27.1％和28.5％的敏感性增 加，21.3％和19.4％的特异性增加。高级医师在参考ThyGPT后，敏感性增加了14.3％和11.1％，特异性增加了10.6％到9.2％。结果表明，由于缺乏 信心和经验，初级放射科医生可能更容易接受ThyGPT的建议。</p> 
</blockquote> 
<blockquote> 
 <p>先前的研究表明，CAD模型在某些临床结果上优于医疗保健专业人员。然而，现实是，传统的CAD模型在临床实践中不适合单独使用。一方面，传统CAD模型仅输出模式识别概率，无法与医生有效沟通，导致医生、患者和医疗机构管理人员对辅助诊断结果缺乏信心;另一方面，在实际临床工作中，数据噪声、图像遗 漏、机器模型差异等造成的干扰远远超出算法模型的范围，导致识别概率不稳定。因此，即使CAD模型被报告为比医生具有更好的鉴别性能，现实世界的决策仍然应该由医生主导，由医生做出最终决定。与之前 的一些代表性CAD工作相比，ThyGPT模型可以弥补"交互和理解"的差距，为医生、患者甚至监管机构提供人工智能辅助评估甲状腺结节风险的基础。这样的交流有助于消除由于数据噪声、机器模型差异或算法本 身造成的不稳定因素，医生可以在观察ThyGPT模型的诊断原理后决定是否参考模型的诊断结果。在某种程度上，这使得ThyGPT等AIGC-CAD系统更加透明和可控，显著提高了临床医生使用CAD工具的信心。</p> 
</blockquote> 
<p>我们的研究也有一定的局限性:<br> (a)由于数据来自不同的机器，机器之间存在图像差异。虽然我们使用了一些必要的数据增强方法来提高模型对不同机器类型数据的鲁棒性，但图像差异对模型的影响不可忽视。<br> (b)由 于本研究是初步探索，虽然我们建立了独立的测试集，但我们只使用了单个中心的数据。进一步的数据收 集用于训练和验证可以产生具有更好的鲁棒性和稳定性的模型。</p> 
<p>未来，我们将重点关注上述问题的影响， 并不断完善模型以实现最优设置。</p> 
<h2><a id="References_178"></a>参考文献References</h2> 
<ol><li> <p><span id="bookmark0" class="anchor"></span>Miller K. D. Wagle N. S. Siegel, R. L. and A. Jemal. Cancer statistics, 2023. <em>Ca Cancer J Clin</em>, 73(1):17–48, 2023. doi: 10.3322/caac.21763.</p> </li><li> <p>E. D. Rossi and Z. Baloch. The impact of the 2022 who classification of thyroid neoplasms on everyday practice of cytopathology. <em>Endocrine Pathology</em>, 34(1):23–33, 2023. doi: 10.1007/s12022-023-09756-2.</p> </li><li> <p><span id="bookmark1" class="anchor"></span>Mete O. Christofer Juhlin, C. and Z. W. Baloch. The 2022 who classification of thyroid tumors: novel concepts in nomenclature and grading. <em>Endocrine-Related Cancer</em>, 30(2), 2023. doi: 10.1530/ERC-22-0293.</p> </li><li> <p><span id="bookmark2" class="anchor"></span>Alexander E. K. Bible K. C. Doherty G. M. Mandel S. J. Nikiforov Y. E. Pacini F. Randolph G. W. Sawka A. M. Schlumberger M. et al. Haugen, B. R. 2015 american thyroid association management guidelines for adult patients with thyroid nodules and differentiated thyroid cancer: the american thyroid association guidelines task force on thyroid nodules and differentiated thyroid cancer. <em>Thyroid</em>, 26(1):1–133, 2016. doi: 10.1089/thy.2015.0020.</p> </li><li> <p>Liu Y. Lv W. Liu L. Zhou Q. Yang H. Ren J. Liu G. Wang X. Zhang X. et al. Peng, S. Deep learning-based artificial intelligence model to assist thyroid nodule diagnosis and management: a multicentre diagnostic study. <em>The Lancet Digital Health</em>, 3(4):e250–e259, 2021. doi: 10.1016/S2589-7500(21)00041-8.</p> </li><li> <p>Liu Z. Robson P. M. Marinelli B. Huang M. Doshi A. Jacobi A. Cao C. Link K. E. Yang T. et al. Mei, X. Radimagenet: an open radiologic deep learning research dataset for effective transfer learning. <em>Radiology: Artificial Intelligence</em>, 4(5):e210315, 2022. doi: 10.1148/ryai.210315.</p> </li><li> <p><span id="bookmark4" class="anchor"></span>Deng Y. Liu T. Zhou J. Jia X. Xiao T. Zhou S. Li J. Guo Y. Wang Y. et al Yu, J. Lymph node metastasis prediction of papillary thyroid carcinoma based on transfer learning radiomics. <em>Nature communications</em>, 11(1):4807, 2020. doi: 10.1038/s41467-020-18497-3.</p> </li><li> <p><span id="bookmark5" class="anchor"></span>Asa S. L. Barletta J. A. Ghossein R. A. Juhlin C. C. Jung C. K. LiVolsi V. A. Papotti M. G. Sobrinho-Simões</p> </li></ol> 
<blockquote> 
 <p>M. Tallini G. et al. Baloch, Z. W. Overview of the 2022 who classification of thyroid neoplasms. <em>Endocrine pathology</em>, 33(1):27–63, 2022. doi: <a href="https://doi.org/10.1007/s12022-022-09707-3" rel="nofollow">10.1007/s12022-022-09707-3.</a></p> 
</blockquote> 
<ol start="9"><li> <p><span id="bookmark6" class="anchor"></span>Gooding W. E. Nikitski A. Wald A. I. Carty S. E. Karslioglu-French E. Seethala R. R. Zandberg D. P. Ferris R. L.-Nikiforova M. N. et al. Yip, L. Risk assessment for distant metastasis in differentiated thyroid cancer using molecular profiling: a matched case-control study. <em>Cancer</em>, 127(11):1779–1787, 2021. doi: <a href="https://doi.org/10.1002/cncr.33421" rel="nofollow">10.1002/cncr.33421.</a></p> </li><li> <p><span id="bookmark7" class="anchor"></span>Wu M. H. Chen K. Y. Hsieh M. S. Chen. A. Kuo, T. C. and C. N. Chen. Ultrasonographic features for differentiating follicular thyroid carcinoma and follicular adenoma. <em>Asian journal of surgery</em>, 43(1):339–346, 2020. doi: <a href="https://doi.org/10.1016/j.asjsur.2019.04.016" rel="nofollow">10.1016/j.asjsur.2019.04.016.</a></p> </li><li> <p><span id="bookmark8" class="anchor"></span>Suh C. H. Baek J. H. Chung S. R. Choi Y. J. Kim, P. H. and J. H. Lee. Unnecessary thyroid nodule biopsy rates under four ultrasound risk stratification systems: a systematic review and meta-analysis. <em>European radiology</em>, 31:2877–2885, 2021. doi: <a href="https://doi.org/10.1007/s00330-020-07384-6" rel="nofollow">10.1007/s00330-020-07384-6.</a></p> </li><li> <p><span id="bookmark9" class="anchor"></span>Shin J. H. Oh Y. L. Kim T. H. Lim Y. Hahn, S. Y. and J. S. Choi. Role of ultrasound in predicting tumor invasiveness in follicular variant of papillary thyroid carcinoma. <em>Thyroid</em>, 27(9):1177–1184, 2017. doi: <a href="https://doi.org/10.1089/thy.2016.0677" rel="nofollow">10.1089/thy.2016.0677.</a></p> </li><li> <p>Matos P. S. Pavin E. J. Vassallo J. Maia, F. F. and D. E. Zantut-Wittmann. Value of ultrasound and cytological classification system to predict the malignancy of thyroid nodules with indeterminate cytology. <em>Endocrine pathology</em>, 22:66–73, 2011. doi: <a href="https://doi.org/10.1016/j.asjsur.2019.04.016" rel="nofollow">10.1016/j.asjsur.2019.04.016.</a></p> </li><li> <p>Angell T. E. Babiarz J. Barth N. M. Blevins T. Duh Q. Y. Ghossein R. A. Harrell R. M. Huang J. Kennedy-G. C. et al. Patel, K. N. Performance of a genomic sequencing classifier for the preoperative diagnosis of cytologically indeterminate thyroid nodules. <em>JAMA surgery</em>, 153(9):817–824, 2018. doi: <a href="https://doi.org/10.1001/jamasurg.2018.1153" rel="nofollow">10.1001/jamasurg.2018.1153.</a></p> </li><li> <p>Taneja C. Liu J. B. Wald A. I. Nikitski A. V. Chiosea S. I. Seethala R. R. Ohori N. P. Karslioglu-French-E. Carty</p> </li></ol> 
<blockquote> 
 <p>S. E. et al. Skaugen, J. M. Performance of a multigene genomic classifier in thyroid nodules with suspicious for malignancy cytology. <em>Thyroid</em>, 32(12):1500–1508, 2022. doi: <a href="https://doi.org/10.1089/thy.2022.0282" rel="nofollow">10.1089/thy.2022.0282.</a></p> 
</blockquote> 
<ol start="16"><li> <p><span id="bookmark10" class="anchor"></span>Smola B. Lew M. Pang J. Cantley R. Pantanowitz L. Heider A. Zhang, L. and X. Jing. Performance of afirma genomic sequencing classifier vs gene expression classifier in bethesda category iii thyroid nodules: an institutional experience. <em>Diagnostic Cytopathology</em>, 49(8):921–927, 2021. doi: <a href="https://doi.org/10.1002/dc.24765" rel="nofollow">10.1002/dc.24765.</a></p> </li><li> <p>Zheng Y. Machiraju G. Sadee C. Mittermaier M. Gertler M. Salinas J. L. Srinivasan K. Gyawali P. Carrillo-Perez</p> </li></ol> 
<blockquote> 
 <p>F. et al. Thieme, A. H. A deep-learning algorithm to classify skin lesions from mpox virus infection. <em>Nature medicine</em>, 29(3):738–747, 2023. doi: <a href="https://doi.org/10.1038/s41591-023-02225-7" rel="nofollow">10.1038/s41591-023-02225-7.</a></p> 
</blockquote> 
<ol start="18"><li> <p>Carty S. E. Sippel R. S. Yang S. P. Sosa J. A. Sipos J. A. Figge J. J.-Mandel S. Haugen B. R. Burman K. D. Baloch Z. W. et al. Steward, D. L. Performance of a multigene genomic classifier in thyroid nodules with indeterminate cytology: a prospective blinded multicenter study. <em>JAMA oncology</em>, 5(2):204–212, 2019. doi: 10.1001/jamaoncol.2018.4616.</p> </li><li> <p>L. Kiani. Mri-based deep learning for tle diagnosis. <em>Nature Reviews Neurology</em>, 19(4):197–197, 2023. doi: 10.1038/s41582-023-00798-y.</p> </li><li> <p><span id="bookmark12" class="anchor"></span>D. M. Korngiebel and S. D. Mooney. Considering the possibilities and pitfalls of generative pre-trained transformer 3 (gpt-3) in healthcare delivery. <em>NPJ Digital Medicine</em>, 4(1):93, 2021. doi: 10.1038/s41746-021-00464-x.</p> </li><li> <p><span id="bookmark13" class="anchor"></span>Norn C. Kipnis Y. Tischer D. Pellock S. J. Evans D. Ma P. Lee G. R. Zhang J. Z. Anishchenko I. et al. Yeh, A. H. De novo design of luciferases using deep learning. <em>Nature</em>, 614(7949):774–780, 2023. doi: 10.1038/s41586-023- 05696-3.</p> </li><li> <p>Lin Y. Cao Y. Hu H. Wei Y. Zhang Z. Lin S. Liu, Z. and B. Guo. Swin transformer: Hierarchical vision transformer using shifted windows. In <em>Proceedings of the IEEE/CVF international conference on computer vision</em>, pages 10012–10022, 2021. doi: 10.48550/arXiv.2103.14030.</p> </li><li> <p><span id="bookmark14" class="anchor"></span>Wu X. Lin D. Zhao L. Li M. Yun D. Lin Z. Pang J. Li L. Wu Y. et al. Liu, L. Deepfundus: A flow-cytometry-like image quality classifier for boosting the whole life cycle of medical artificial intelligence. <em>Cell Reports Medicine</em>, 4(2), 2023. doi: 10.1016/j.xcrm.2022.100912.</p> </li><li> <p>Bataillon G. Naylor P. Popova T. Bidard F. C. Stoppa-Lyonnet D. Stern M. H. Decencière E. Walter T. Lazard, T. and A. Vincent-Salomon. Deep learning identifies morphological patterns of homologous recombination deficiency in luminal breast cancers from whole slide images. <em>Cell Reports Medicine</em>, 3(12), 2022. doi: 10.1016/j.xcrm.</p> </li><li> <p><span id="bookmark15" class="anchor"></span>Schoppe O. Parra-Damas A. Cai R. Todorov M. I.-Gondi G. von Neubeck B. Bög˘ürcü-Seidel N. Seidel S. Sleiman</p> </li></ol> 
<blockquote> 
 <p>K. et al. Pan, C. Deep learning reveals cancer metastasis and therapeutic antibody targeting in the entire body.<em>Cell</em>, 179(7):1661–1676, 2019. doi: 10.1016/j.cell.2019.11.013.</p> 
</blockquote> 
<ol start="26"><li> <p><span id="bookmark16" class="anchor"></span>Liu W. DeLair-D. Razavian N. Hong, R. and D. Fenyö. Predicting endometrial cancer subtypes and molecular features from histopathology images using multi-resolution deep learning models. <em>Cell Reports Medicine</em>, 2(9), 2021. doi: 10.1016/j.xcrm.2021.100400.</p> </li><li> <p><span id="bookmark17" class="anchor"></span>Lei Z. Yue-W. Feng B. Li W. Ou D.-Feng N. Lu Y. Xu J.-Chen W. et al. Yao, J. Deepthy-net: A multimodal deep learning method for predicting cervical lymph node metastasis in papillary thyroid cancer. <em>Advanced Intelligent Systems</em>, 4(10):2200100, 2022. doi: 10.1002/aisy.202200100.</p> </li><li> <p>Zhang X.-Ren S. ResNet: He, K. and J. Sun. Deep residual learning for image recognition. In <em>Proceedings of the IEEE conference on computer vision and pattern recognition</em>, pages 770–778, 2016. doi: 10.1109/CVPR.2016.90.</p> </li><li> <p>Liu Y. Lv-W. Liu L. Zhou Q. Yang H.-Ren J. Liu G. Wang X.-Zhang X. et al. Peng, S. Deep learning-based artificial intelligence model to assist thyroid nodule diagnosis and management: a multicentre diagnostic study. <em>The Lancet Digital Health</em>, 3(4):e250–e259, 2021. doi: 10.1016/S2589-7500(21)00041-8.</p> </li><li> <p>Middleton W. D. Grant E. G. Hoang J. K.-Berland L. L. Teefey S. A.-Cronan J. J. Beland M. D. Desser T. S. Frates</p> </li></ol> 
<blockquote> 
 <p>M. C. et al. Tessler, F. N. Acr thyroid imaging, reporting and data system (ti-rads): white paper of the acr ti-rads committee. <em>Journal of the American college of radiology</em>, 14(5):587–595, 2017. doi: 10.1016/j.jacr.2017.01.046.</p> 
</blockquote> 
<ol start="31"><li> <p><span id="bookmark18" class="anchor"></span>E. S. Cibas and S. Z. Ali. The 2017 bethesda system for reporting thyroid cytopathology. <em>Thyroid</em>, 27(11):1341-- 1346, 2017. doi: 10.1089/thy.2017.0500.<br> .</p> </li><li> <p><span id="bookmark18" class="anchor"></span>E. S. Cibas and S. Z. Ali. The 2017 bethesda system for reporting thyroid cytopathology. <em>Thyroid</em>, 27(11):1341-- 1346, 2017. doi: 10.1089/thy.2017.0500.</p> </li></ol> 
<hr> 
<p>欢迎大家添加好友，持续发放粉丝福利！</p> 
<p><img src="https://images2.imgbox.com/92/ba/9BxUpfbV_o.png" alt="请添加图片描述"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/02c646c2142ec683aa2658eb5ee8b3b8/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Oracle-数据库升级到19C用户登录报错问题</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/5fa42be7bd99e7414fc5a19a0703b59e/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">基于llama.cpp的GGUF量化与基于llama-cpp-python的部署</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>