<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【大数据·hadoop】在hdfs上运行shell基本常用命令 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/78e0cb0304befa174d448fc23b7f8285/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="【大数据·hadoop】在hdfs上运行shell基本常用命令">
  <meta property="og:description" content="一、准备工作 1.1启动Hadoop服务 参见Hadoop在ubuntu虚拟机上的伪分布式部署|保姆级教程的4.7节
二、HDFS常用命令 接着，就愉快地在刚刚的命令行里敲命令啦
1.显示hdfs目录结构 hadoop fs -ls -R / hadoop fs: 这是Hadoop文件系统命令行的一部分，用于与HDFS进行交互。-ls: 类似于UNIX/Linux中的 ls 命令，用于列出目录内容。-R: 这个参数使得 ls 命令递归地列出所有目录和子目录的内容。没有这个参数，ls 命令只会列出指定目录的直接内容。/: 指定要列出内容的目录路径。在这个命令中，它是根目录。
🌸Tips：这里的Hadoop的目录结构，是指hdfs文件系统的目录结构，而非hadoop这个软件所在的目录结构
根据运行结果我们可以得到以下信息：
1. 目录和权限:
/tmp: 这是一个临时目录，权限设置为 drwxrwx---，表明目录的拥有者（hadoop）和其所在的组（supergroup）具有读、写、执行权限，而其他用户没有任何权限。/tmp/hadoop-yarn: 这是存放与Hadoop YARN（资源管理器）相关的临时数据的目录，权限同上。/tmp/hadoop-yarn/staging: 用于存放YARN作业的准备阶段数据的目录，权限同上。/tmp/hadoop-yarn/staging/history: 存放YARN作业历史信息的目录，权限同上。/tmp/hadoop-yarn/staging/history/done: 存放已完成的YARN作业历史信息的目录，权限同上。/tmp/hadoop-yarn/staging/history/done_intermediate: 存放正在处理中的YARN作业历史信息的目录，权限设置为 drwxrwxrwt。这里的 t 权限（粘滞位）表明只有文件的拥有者、目录的拥有者或超级用户才能删除或重命名目录中的文件。 2. 所有者和组:
所有列出的目录均由用户 hadoop 拥有，并且属于 supergroup 组。在Hadoop生态系统中，supergroup 是一个默认的用户组，通常与HDFS的超级用户（即 Hadoop 的管理员账户，类似于 Unix 系统中的 root 用户）关联。超级用户和属于 supergroup 组的用户通常有着对HDFS上所有文件和目录的全权限，这包括读取、写入和执行权限。
3. 大小:所有目录的大小均为 0，这是因为在大多数文件系统中，目录不占用可见的存储空间，或者说目录的大小表示的是目录结构本身的大小，而不是其中包含的文件大小。 2.在hdfs指定目录内创建新目录 hadoop fs -mkdir /yaoyao 3.删除hdfs上指定文件夹（包含子目录等） hadoop fs -rm -r /yaoyao 4.在hdfs上创建文件和编辑❌ 其实我一开始就完全把HDFS当作像windows和linux那样的文件操作系统了，其实忽略了hdfs的本质：它是一个分布式文件存储系统，专为大文件的存储和处理设计，而非像windows和Linux那样常规的对本地文件进行操作（创建和编辑），因此一般不直接在hdfs上进行文件的创建和编辑。">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-06-10T15:50:02+08:00">
    <meta property="article:modified_time" content="2024-06-10T15:50:02+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【大数据·hadoop】在hdfs上运行shell基本常用命令</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-dracula">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_0"></a>一、准备工作</h2> 
<h3><a id="11Hadoop_2"></a>1.1启动Hadoop服务</h3> 
<p>参见<a href="https://blog.csdn.net/Yaoyao2024/article/details/137048127?spm=1001.2014.3001.5501">Hadoop在ubuntu虚拟机上的伪分布式部署|保姆级教程</a>的4.7节</p> 
<p><img src="https://images2.imgbox.com/7b/f7/OTITpbui_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="HDFS_8"></a>二、HDFS常用命令</h2> 
<p>接着，就愉快地在刚刚的命令行里敲命令啦</p> 
<h3><a id="1hdfs_12"></a>1.显示hdfs目录结构</h3> 
<pre><code class="prism language-shell">hadoop fs <span class="token parameter variable">-ls</span> <span class="token parameter variable">-R</span> /
</code></pre> 
<ul><li><code>hadoop fs</code>: 这是Hadoop文件系统命令行的一部分，用于与HDFS进行交互。</li><li><code>-ls</code>: 类似于UNIX/Linux中的 ls 命令，用于列出目录内容。</li><li><code>-R</code>: 这个参数使得 ls 命令<strong>递归地列出所有目录和子目录的内容</strong>。没有这个参数，ls 命令只会列出指定目录的直接内容。</li><li><code>/</code>: 指定要列出内容的目录路径。在这个命令中，它是根目录。<br> <img src="https://images2.imgbox.com/d0/97/lwqEvYGy_o.png" alt="在这里插入图片描述"></li></ul> 
<blockquote> 
 <p>🌸Tips：这里的Hadoop的目录结构，是指<strong>hdfs文件系统的目录结构</strong>，而非hadoop这个软件所在的目录结构</p> 
</blockquote> 
<p>根据运行结果我们可以得到以下信息：</p> 
<p><strong>1. 目录和权限:</strong></p> 
<ul><li><code>/tmp</code>: 这是一个临时目录，权限设置为 <code>drwxrwx---</code>，表明目录的拥有者（hadoop）和其所在的组（supergroup）具有读、写、执行权限，而其他用户没有任何权限。</li><li><code>/tmp/hadoop-yarn</code>: 这是存放与<code>Hadoop YARN</code>（资源管理器）相关的临时数据的目录，权限同上。</li><li><code>/tmp/hadoop-yarn/staging</code>: 用于存放YARN作业的准备阶段数据的目录，权限同上。</li><li><code>/tmp/hadoop-yarn/staging/history</code>: 存放YARN作业历史信息的目录，权限同上。</li><li><code>/tmp/hadoop-yarn/staging/history/done:</code> 存放已完成的YARN作业历史信息的目录，权限同上。</li><li><code>/tmp/hadoop-yarn/staging/history/done_intermediate</code>: 存放正在处理中的YARN作业历史信息的目录，权限设置为 drwxrwxrwt。这里的 t 权限（粘滞位）表明只有文件的拥有者、目录的拥有者或超级用户才能删除或重命名目录中的文件。</li></ul> 
<p><strong>2. 所有者和组:</strong></p> 
<ul><li>所有列出的目录均由用户 hadoop 拥有，并且属于 supergroup 组。</li><li>在Hadoop生态系统中，supergroup 是一个默认的用户组，通常与HDFS的超级用户（即 Hadoop 的管理员账户，类似于 Unix 系统中的 root 用户）关联。超级用户和属于 supergroup 组的用户通常有着对HDFS上所有文件和目录的全权限，这包括读取、写入和执行权限。<br> <strong>3. 大小:</strong></li><li>所有目录的大小均为 0，这是因为在大多数文件系统中，目录不占用可见的存储空间，或者说目录的大小表示的是目录结构本身的大小，而不是其中包含的文件大小。</li></ul> 
<h3><a id="2hdfs_41"></a>2.在hdfs指定目录内创建新目录</h3> 
<pre><code class="prism language-shell">hadoop fs <span class="token parameter variable">-mkdir</span> /yaoyao
</code></pre> 
<p><img src="https://images2.imgbox.com/36/43/naYmaC91_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="3hdfs_47"></a>3.删除hdfs上指定文件夹（包含子目录等）</h3> 
<pre><code class="prism language-shell">hadoop fs <span class="token parameter variable">-rm</span> <span class="token parameter variable">-r</span> /yaoyao
</code></pre> 
<p><img src="https://images2.imgbox.com/9c/05/5uIOJ1oa_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="4hdfs_53"></a>4.在hdfs上创建文件和编辑❌</h3> 
<p>其实我一开始就完全把HDFS当作像<code>windows</code>和<code>linux</code>那样的文件操作系统了，其实忽略了hdfs的本质：它是一个分布式文件<strong>存储</strong>系统，专为<strong>大文件的存储和处理</strong>设计，而非像windows和Linux那样常规的对本地文件进行操作（创建和编辑），因此一般不直接在hdfs上进行文件的创建和编辑。</p> 
<p>它的设计理念是：<strong>一次写入，多次读取</strong>（保证<strong>数据的一致性</strong>）：HDFS不支持文件的随机写入或修改。一旦文件在HDFS上创建和写入，我们不能修改文件的某一部分内容。我们只能追加数据或重写整个文件。</p> 
<p>这里的“写入”就是将本地文件写入系统，而非用户自己在Hdfs上创建文件</p> 
<h3><a id="5hdfs_63"></a>5.文件写入：将本地数据写入hdfs⭐</h3> 
<p>文件写入的原理图如下，但是我们写shell命令时，这些原理是由hdfs底层实现的了，我们只需要敲命令就好<br> <img src="https://images2.imgbox.com/0b/4d/asInS9vK_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="51_67"></a>5.1：本地文件准备</h4> 
<p>我们现在本地系统上创建一个文件，待会把它写入hdfs系统中：</p> 
<ul><li> <p>先在用户目录下创建一个<code>hadoop_file</code>的文件夹，待会用来存储要写入到<code>hdfs</code>中的文件<br> <img src="https://images2.imgbox.com/6c/3a/lgEXq5Kl_o.png" alt="在这里插入图片描述"></p> </li><li> <p>在终端打开这个文件夹，创建文件<code>hello.txt</code></p> <pre><code class="prism language-shell"><span class="token function">touch</span> hello.txt
</code></pre> <p><img src="https://images2.imgbox.com/64/ab/zMb6Vp4j_o.png" alt="在这里插入图片描述"></p> </li><li> <p>使用vim编辑器：</p> <pre><code class="prism language-shell"><span class="token function">vim</span> hello.txt
</code></pre> 
  <blockquote> 
   <p>启动后按<code>i</code>进入插入模式，可以开始输入文本。完成后，按<code>Esc</code>退出插入模式，输入<code>:wq</code>保存并退出vim。<br> <img src="https://images2.imgbox.com/50/60/89yh2rjW_o.png" alt="在这里插入图片描述"></p> 
  </blockquote> </li></ul> 
<h4><a id="52hdfs_88"></a>5.2：将本地文件上传到hdfs</h4> 
<p>有两种命令实现：</p> 
<ol><li><code>-copyFromLocal</code></li></ol> 
<pre><code class="prism language-shell">hadoop fs <span class="token parameter variable">-copyFromLocal</span> <span class="token punctuation">[</span>本地地址<span class="token punctuation">]</span> <span class="token punctuation">[</span>hadoop目录<span class="token punctuation">]</span>
</code></pre> 
<ol start="2"><li><code>-put</code></li></ol> 
<pre><code class="prism language-shell">hadoop fs <span class="token parameter variable">-put</span> <span class="token punctuation">[</span>本地地址<span class="token punctuation">]</span> <span class="token punctuation">[</span>hadoop目录<span class="token punctuation">]</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/de/58/ZIj1zwKF_o.png" alt="在这里插入图片描述"><br> 这里对于本地地址一定要清楚<code>linux</code>的目录结构：<br> <img src="https://images2.imgbox.com/b5/77/Arbkp0Dl_o.png" alt="在这里插入图片描述"><br> <code>home：</code><br> 用户的主目录，在 Linux 中，每个用户都有一个自己的目录，一般该目录名是以用户的账号命名的，如上图中的 alice、bob 和 eve。</p> 
<p>我在当前用户（用户名为<code>hadoop</code>的<code>home</code>目录下创建了<code>hadoop_file</code>文件夹，那么我们文件的路径应该为：</p> 
<pre><code class="prism language-shell">/home/hadoop/hadoop_file/hello.txt
</code></pre> 
<h3><a id="6_114"></a>6.查看指定目录下内容</h3> 
<pre><code class="prism language-shell">hadoop fs <span class="token parameter variable">-ls</span> <span class="token punctuation">[</span>hdfs的文件目录<span class="token punctuation">]</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/e9/6b/SCxeKhl9_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="7_120"></a>7.打开查看某个已存在文件</h3> 
<pre><code class="prism language-shell">hadoop fs <span class="token parameter variable">-cat</span> <span class="token punctuation">[</span>file_path<span class="token punctuation">]</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/7a/6e/BOqV1Fin_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="8hdfs_126"></a>8.在hdfs指定目录下新建一个空文件</h3> 
<pre><code class="prism language-shell">hadoop fs <span class="token parameter variable">-touchz</span> <span class="token punctuation">[</span>hdfs的文件路径+文件名<span class="token punctuation">]</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/e9/16/m2b9qcZV_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="9hdfs_133"></a>9.将hdfs上某个文件重命名</h3> 
<pre><code class="prism language-shell">hadoop fs <span class="token parameter variable">-mv</span> /yaoyao/test.txt /yaoyao/test02.txt
</code></pre> 
<p><img src="https://images2.imgbox.com/9b/98/ZNTwaBMn_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="10hdfsdown_140"></a>10.将hdfs上的文件down到本地⭐</h3> 
<ol><li> <p><code>-get</code></p> <pre><code class="prism language-shell">hadoop fs <span class="token parameter variable">-get</span> <span class="token punctuation">[</span>hdfs目录<span class="token punctuation">]</span> <span class="token punctuation">[</span>本地目录<span class="token punctuation">]</span> 
</code></pre> <p><img src="https://images2.imgbox.com/d4/48/MXDwt4QG_o.png" alt="在这里插入图片描述"></p> </li><li> <p><code>-copyToLocal</code></p> <pre><code class="prism language-shell">hadoop fs <span class="token parameter variable">-copyToLocal</span> <span class="token punctuation">[</span>hdfs目录<span class="token punctuation">]</span> <span class="token punctuation">[</span>本地目录<span class="token punctuation">]</span> 
</code></pre> </li></ol> 
<h3><a id="11_154"></a>11.其他常用命令</h3> 
<ol><li> <p><code>-count</code>：显示hdfs目录下的子<strong>目录数、文件数、占用字节数、所有文件和目录名</strong>，-q 选项显示目录和空间的配额信息。实例代码如下所示：</p> <pre><code class="prism language-shell">hadoop fs <span class="token parameter variable">-count</span> /yaoyao
</code></pre> <p>命令输出格式为：</p> <pre><code class="prism language-shell">DIR_COUNT FILE_COUNT CONTENT_SIZE PATH_NAME
</code></pre> <p><img src="https://images2.imgbox.com/30/9c/6CSifvJ4_o.png" alt="在这里插入图片描述"><br> DIR_COUNT - 2：/yaoyao路径下有2个子目录。<br> FILE_COUNT - 3：/yaoyao路径下有3个文件。<br> CONTENT_SIZE - 50：这3个文件的总字节数为50字节。<br> PATH_NAME - /yaoyao：这是你指定的HDFS路径。</p> </li><li> <p><code>-df</code>：查看 HDFS 中目录空间的使用情况，使用 <code>-df</code> 选项查看Hadoop文件系统（HDFS）的磁盘空间使用情况，而 <code>-h</code> 选项让输出以易读的格式（例如GB、KB）显示。实例代码如下所示：</p> <pre><code class="prism language-shell">hadoop fs <span class="token parameter variable">-df</span> <span class="token parameter variable">-h</span> /yaoyao
</code></pre> <p><img src="https://images2.imgbox.com/de/8b/m11NSGsJ_o.png" alt="在这里插入图片描述"><br> Filesystem：显示文件系统的名称。这里是 hdfs://localhost:9000，表示这是运行在本地主机上，默认端口为9000的HDFS实例。<br> Size：显示文件系统的总大小。这里是 38.6 G，表示HDFS的总空间为38.6吉字节（GB）。<br> Used：显示已经使用的空间大小。这里是 52 K，表示已经有52千字节（KB）的空间被使用。<br> Available：显示还可用的空间大小。这里是 22.4 G，表示还有22.4吉字节（GB）的空间可用。<br> Use%：显示已使用的空间百分比。这里是 0%，由于展示的精度问题，实际已使用空间非零（52 KB），但相对于总空间来说非常小，所以使用百分比显示为0%。</p> </li><li> <p><code>-tail</code>：显示一个文件的末尾数据，通常是显示文件最后的 1KB 的数据。-f 选项可以监听文件的变化，当有内容追加到文件中时，-f 选项能够实时显示追加的内容。实例代码如下所示：</p> <pre><code class="prism language-shell">hadoop fs <span class="token parameter variable">-tail</span> /yaoyao/hello.txt
</code></pre> <p><img src="https://images2.imgbox.com/c4/bb/Hwziilet_o.png" alt="在这里插入图片描述"></p> </li></ol>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/b5a3ca41708dd5634a323d9706e2665a/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">探析—面向存算架构的神经网络数字系统【存内计算开发者社区】</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/4a54bc9026e9d908aee2f4a789846e21/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">数据仓库技术及应用（Hive索引）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>