<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Text-to-SQL小白入门（十）RLHF在Text2SQL领域的探索实践 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/802c136cff89d033261bb52d2605b0e1/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="Text-to-SQL小白入门（十）RLHF在Text2SQL领域的探索实践">
  <meta property="og:description" content="本文内容主要基于以下开源项目探索实践，
Awesome-Text2SQL:GitHub - eosphoros-ai/Awesome-Text2SQL: Curated tutorials and resources for Large Language Models, Text2SQL, Text2DSL、Text2API、Text2Vis and more.DB-GPT-Hub：GitHub - eosphoros-ai/DB-GPT-Hub: A repository that contains models, datasets, and fine-tuning techniques for DB-GPT, with the purpose of enhancing model performance in Text-to-SQLDB-GPT：GitHub - eosphoros-ai/DB-GPT: Revolutionizing Database Interactions with Private LLM TechnologyDeepSpeedExamples:GitHub - microsoft/DeepSpeedExamples: Example models using DeepSpeed 开源不易，希望大家给个star支持一下，感谢！
Text2SQL简介 本章主要对Text2SQL的基本定义、使用的开源数据集和评测指标做了介绍，同时也介绍了一些实践项目，供大家参考。
定义 Text-to-SQL（简写为Text2SQL），顾名思义就是把文本转化为SQL语言，更学术一点的定义是：把数据库领域下的自然语言（Natural Language，简写为NL）问题，转化为在关系型数据库中可以执行的结构化查询语言（Structured Query Language，简写为SQL），因此Text2SQL也可以被简写为NL2SQL。
举个例子比较直观：
输入：自然语言问题。 查询表t_user的所有信息，结果按id降序排序，只保留前10个数据 输出：SQL语句。 SELECT * FROM t_user ORDER BY id DESC LIMIT 10 实验：如图1所示，在DB-GPT项目中，直接使用原生对话，使用Proxy LLM（GPT-3.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2023-12-26T20:13:24+08:00">
    <meta property="article:modified_time" content="2023-12-26T20:13:24+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Text-to-SQL小白入门（十）RLHF在Text2SQL领域的探索实践</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <blockquote> 
 <p id="u1f00e725">本文内容主要基于以下开源项目探索实践，</p> 
 <ul><li id="ucf2c83e6">Awesome-Text2SQL:<a href="https://github.com/eosphoros-ai/Awesome-Text2SQL" title="GitHub - eosphoros-ai/Awesome-Text2SQL: Curated tutorials and resources for Large Language Models, Text2SQL,  Text2DSL、Text2API、Text2Vis and more.">GitHub - eosphoros-ai/Awesome-Text2SQL: Curated tutorials and resources for Large Language Models, Text2SQL, Text2DSL、Text2API、Text2Vis and more.</a></li><li id="u675b8f26">DB-GPT-Hub：<a href="https://github.com/eosphoros-ai/DB-GPT-Hub" title="GitHub - eosphoros-ai/DB-GPT-Hub: A repository that contains models, datasets, and fine-tuning techniques for DB-GPT, with the purpose of enhancing model performance  in Text-to-SQL">GitHub - eosphoros-ai/DB-GPT-Hub: A repository that contains models, datasets, and fine-tuning techniques for DB-GPT, with the purpose of enhancing model performance in Text-to-SQL</a></li><li id="u24a41b6f">DB-GPT：<a href="https://github.com/eosphoros-ai/DB-GPT" title="GitHub - eosphoros-ai/DB-GPT: Revolutionizing Database Interactions with Private LLM Technology">GitHub - eosphoros-ai/DB-GPT: Revolutionizing Database Interactions with Private LLM Technology</a></li><li id="udbb36a16">DeepSpeedExamples:<a href="https://github.com/microsoft/DeepSpeedExamples" title="GitHub - microsoft/DeepSpeedExamples: Example models using DeepSpeed">GitHub - microsoft/DeepSpeedExamples: Example models using DeepSpeed</a></li></ul> 
 <p id="uca195916">开源不易，希望大家给个star支持一下，感谢！</p> 
</blockquote> 
<h2 id="AbLzZ">Text2SQL简介</h2> 
<p id="u1e08a817">本章主要对Text2SQL的基本定义、使用的开源数据集和评测指标做了介绍，同时也介绍了一些实践项目，供大家参考。</p> 
<h3 id="TOfGl">定义</h3> 
<p id="u32fd96d8">Text-to-SQL（简写为Text2SQL），顾名思义就是把文本转化为SQL语言，<strong>更学术一点的定义</strong>是：把数据库领域下的自然语言（Natural Language，简写为<strong>NL</strong>）问题，转化为在关系型数据库中可以执行的结构化查询语言（Structured Query Language，简写为<strong>SQL</strong>），因此Text2SQL也可以被简写为<strong>NL2SQL</strong>。</p> 
<p id="u43025649">举个例子比较直观：</p> 
<ul><li id="ud9276924">输入：自然语言问题。</li></ul> 
<pre id="Oa6ag"><code>查询表t_user的所有信息，结果按id降序排序，只保留前10个数据</code></pre> 
<ul><li id="u8cad5e4a">输出：SQL语句。</li></ul> 
<pre id="gRZW4"><code>SELECT * FROM t_user ORDER BY id DESC LIMIT 10</code></pre> 
<ul><li id="uc539c6b4">实验：如图1所示，在<a href="https://github.com/eosphoros-ai/DB-GPT" title="DB-GPT">DB-GPT</a>项目中，直接使用原生对话，使用Proxy LLM（GPT-3.5）提问上述问题，大模型可以准确给出SQL答案，这也是因为LLM本身语言理解能力强大，同时提问的自然语言问题比较easy。</li></ul> 
<p id="u1640d52c"></p> 
<p class="img-center"><img alt="" height="522" id="u953bbc7c" src="https://images2.imgbox.com/a1/40/OIc6a98V_o.png" width="1200"></p> 
<p id="uc2285ee0">图1 DB-GPT项目原生对话示意图</p> 
<h3 id="oPAro">数据集</h3> 
<p id="u604b836d">公开的Text2SQL数据集比较多，这里仅介绍目前使用较多的几个数据集：</p> 
<ul><li id="u7f520ba6">WikiSQL [<a href="https://arxiv.org/pdf/1709.00103.pdf" rel="nofollow" title="paper">paper</a>] [<a href="https://github.com/salesforce/WikiSQL" title="code">code</a>] [<a href="https://github.com/salesforce/WikiSQL" title="dataset">dataset</a>]</li></ul> 
<ul><li> 
  <ul><li id="u580410e7">2017年9月，Salesforce提出的一个大型的Text-to-SQL数据集，数据来源于Wikipedia，属于单领域，包含了80654个自然语言问题，77840个SQL语句，SQL语句形式比较简单，不包含排序、分组、子查询等复杂操作。</li></ul></li></ul> 
<ul><li id="ufd22917c">Spider [<a href="https://arxiv.org/pdf/1809.08887.pdf" rel="nofollow" title="paper">paper</a>] [<a href="https://github.com/taoyds/spider" title="code">code</a>] [<a href="https://yale-lily.github.io/spider" rel="nofollow" title="dataset">dataset</a>]</li></ul> 
<ul><li> 
  <ul><li id="uf27905fd">2018年9月，耶鲁大学提出的多数据库、多表、单轮查询的Text-to-SQL数据集，也是业界公认难度最大的大规模跨领域评测榜单，包含了10181个自然语言问题，5693个SQL语句，涉及138个不同领域的200多个数据库，难易程度分为：简单、中等、困难、特别困难。</li></ul></li></ul> 
<ul><li id="u0aee693e">CoSQL [<a href="https://arxiv.org/pdf/1909.05378.pdf" rel="nofollow" title="paper">paper</a>] [<a href="https://yale-lily.github.io/cosql" rel="nofollow" title="code">code</a>] [<a href="https://yale-lily.github.io/cosql" rel="nofollow" title="dataset">dataset</a>]</li></ul> 
<ul><li> 
  <ul><li id="uad06800a">2019/09, 耶鲁大学和Salesforce Research提出了一种跨域数据库CoSQL，它由30k+轮次和10k+带注释的SQL查询组成，这些查询是从Wizard-of-Oz (WOZ)集合中获得的，该集合包含3k个对话，查询跨越 138个域的200个复杂数据库。</li></ul></li></ul> 
<ul><li id="u394bee41">CHASE [<a href="https://aclanthology.org/2021.acl-long.180.pdf" rel="nofollow" title="paper">paper</a>] [<a href="https://github.com/xjtu-intsoft/chase" title="code">code</a>] [<a href="https://github.com/xjtu-intsoft/chase/tree/page/data" title="dataset">dataset</a>]</li></ul> 
<ul><li> 
  <ul><li id="u4a1b2d83">2021年8月，西安交通大学和微软等提出了首个跨领域、多轮Text-to-SQL中文数据集，包含了5459个多轮问题组成的列表，17940个&lt;query, SQL&gt;二元组。</li></ul></li></ul> 
<ul><li id="u3167965b">BIRD-SQL [<a href="https://arxiv.org/pdf/2305.03111.pdf" rel="nofollow" title="paper">paper</a>] [<a href="https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/bird" title="code">code</a>] [<a href="https://bird-bench.github.io/" rel="nofollow" title="dataset">dataset</a>]</li></ul> 
<ul><li> 
  <ul><li id="uec406835">2023年5月，香港大学和阿里巴巴提出了一个大规模跨域数据集BIRD，其中包含超过12751个独特的问题 SQL、95个大数据库，总大小为33.4GB。它还涵盖区块链、曲棍球、医疗保健和教育等超过37个专业领域。</li></ul></li></ul> 
<blockquote> 
 <p id="u16b5f62a">如何还想了解更多数据集以及Text2SQL的基本知识，可以查看我之前知乎的Text2QL综述文章：<a href="https://zhuanlan.zhihu.com/p/647249972" rel="nofollow" title="Text-to-SQL小白入门（一）综述文章学习">Text-to-SQL小白入门（一）综述文章学习</a></p> 
</blockquote> 
<h3 id="Dg8sB">评测指标</h3> 
<p id="u50c551d3">以Spider数据集为例：主要有两个指标，分别是执行准确率（Execution Accuracy，简称EX）和逻辑形式准确率（Exact Match，简称EM)</p> 
<ul><li id="ua1d2f4ee">EX</li></ul> 
<ul><li> 
  <ul><li id="uc86a14c4">计算SQL执行<strong>结果正确</strong>的数量在数据集中的比例，结果存在高估的可能。</li></ul></li></ul> 
<ul><li id="u85ebfb51">EM</li></ul> 
<ul><li> 
  <ul><li id="u44db083b">计算模型生成的SQL和标注SQL的匹配程度，结果存在低估的可能。</li></ul></li></ul> 
<p id="u4e742ff2">在<a href="https://github.com/eosphoros-ai/Awesome-Text2SQL" title="Awesome-Text2SQL">Awesome-Text2SQL</a>项目中，列举了常见的数据以及对应的指标榜单，如图2所示，比如Spider数据集上，目前EX得分第一是MiniSeek组织提交的91.2，EM得分第一也是MiniSeek提交的81.5，因为运用了GPT-4以及一些其他的trick，所以得分最高。</p> 
<p id="uedbc8d65"></p> 
<p class="img-center"><img alt="" height="1200" id="u3198fcce" src="https://images2.imgbox.com/75/a7/rDcyMhRZ_o.png" width="1200"></p> 
<p id="u5f371804">图2 Awesome-Text2SQL项目数据集得分榜单</p> 
<h3 id="VlChy">实验方法</h3> 
<p id="u91a2e87a">Text2SQL研究主要有基于模版和匹配的方法、基于Seq2Seq框架的方法和基于模型预训练的方法，随着LLM的崛起，如今利用LLM微调完成Text2SQL任务也越来越常见，比如在<a href="https://github.com/eosphoros-ai/DB-GPT-Hub" title="DB-GPT-Hub">DB-GPT-Hub</a>项目中，就实现了利用各种开源模型在Spider数据集上进行lora和qlora方法微调，亲测好用！（方法详情可以参考代码仓库）</p> 
<h2 id="mltP6">RLHF简介</h2> 
<p id="u14859eff">本章主要介绍了RLHF的基本定义，以及介绍了强化学习的基础概念和RLHF框架。</p> 
<h3 id="FGY5U">定义</h3> 
<p id="u37bfcb21"><strong>RLHF：R</strong>einforcement <strong>L</strong>earning from <strong>H</strong>uman <strong>F</strong>eedback，通过强化学习方式方式根据人类反馈优化语言模型，使得在一般文本数据语料库的语言模型能够和复杂人类价值观对齐。</p> 
<h3 id="BwJQW">强化学习基础概念</h3> 
<p id="u0d75c583">RL：指的是<strong>Reinforcement learning。</strong></p> 
<ul><li id="u5d6e1c7e">强化学习是一种机器学习方法，旨在通过智能体（<strong>agent</strong>）与环境（<strong>environment</strong>）的交互学习如何在动态环境中做出决策（<strong>action</strong>）以最大化累积回报（<strong>reward</strong>）。在强化学习中，智能体通过观察环境的状态、采取行动和接收奖励来学习与环境的交互。智能体的目标是通过学习最优的策略（<strong>policy</strong>），在不断尝试和调整中，使得长期累积的奖励最大化。</li><li id="u4782be1f">强化学习最早在游戏中应用比较多。</li></ul> 
<p id="u2cedfaa0"></p> 
<p id="ue76713a6">为了更好理解强化学习，我们可以先了解一下比较常见的有监督学习（Supervised Learning, SL）。对于有监督学习而言，模型完整的训练pipline通常可以分成如图3所示：</p> 
<p id="u0980e9cf"></p> 
<p class="img-center"><img alt="" height="648" id="uc5bd9f10" src="https://images2.imgbox.com/bc/7e/MXf5j5dh_o.png" width="1200"></p> 
<p id="u46bf584c">图3 有监督学习示意图</p> 
<p id="ue43f5f59"></p> 
<ul><li id="u8df095a4">输入标注好的数据labeled data（有标签ground truth+原始数据）</li></ul> 
<ul><li> 
  <ul><li id="u92290315">1.从标签数据中获取原始数据</li><li id="ub29a0879">2.把原始数据拿给模型训练（比如卷积神经网络CNN）</li><li id="u43718b6a">3.模型根据当前数据输出预测值predict</li><li id="u460417aa">4.通过损失函数loss function计算预测值和真实值之间的loss</li><li id="u9af8ba2d">5.loss更新给模型</li><li id="u5ff8dcbf">然后重复上述1-5步骤，训练模型。【优化目标：把loss变小】</li></ul></li></ul> 
<ul><li id="u40d2779c">输出训练好的模型</li></ul> 
<p id="uee695ac8">对于强化学习而言，模型训练的pipline也是类似的，如图4所示。</p> 
<ul><li id="u08f6db6a">输入初始化的环境environment</li></ul> 
<ul><li> 
  <ul><li id="uf9b618f8">1.从环境获取当前状态state</li><li id="ud84a4c02">2.把当前state拿给智能体agent</li><li id="u7d32db41">3.agent根据环境的状态输出采取的动作action</li><li id="u766ab902">4.action和环境进行交互，通过奖励函数reward function计算当前奖励</li><li id="ub16130c1">5.奖励和状态更新给智能体agent</li><li id="ud43b6ff0">然后重复上述1-5步骤，训练agent。【优化目标：把reward变大】</li></ul></li></ul> 
<p id="uc4f276d5"></p> 
<p class="img-center"><img alt="" height="956" id="u040e86cd" src="https://images2.imgbox.com/91/0e/WgHOMP6x_o.png" width="1200"></p> 
<p id="ub8241ed0">图4 有监督学习和强化学习对比示意图</p> 
<p id="u1873029d">由上面讲述可知，强化学习的基本组成主要由以下部分：</p> 
<ul><li id="u2c90d8cd">environment</li><li id="u2dbfd071">agent</li><li id="u1792be91">state</li><li id="ua13a71e1">reward</li><li id="uead50c0f">action</li><li id="u2c48198a">policy: 策略。定义了agent如何根据当前的state来做出action。策略主要可以分为on-policy和off-policy。</li></ul> 
<ul><li> 
  <ul><li id="ufd4882cd">On-policy: 学习到的agent以及和环境进行互动的agent是<strong>同一个agent ，</strong>比如PPO算法<strong>（eg:</strong>你在打游戏，你在实战中变强。<strong>）</strong></li><li id="u4c5a177c">Off-policy: 学习到的agent以及和环境进行互动的agent是<strong>不同的agent，</strong>比如DQN算法<strong>（eg: </strong>你在看直播，你在观摩中变强。<strong>)</strong></li></ul></li></ul> 
<h3 id="mv3ZO">RLHF框架</h3> 
<p id="u4c7a7131">RLHF方法最早是在是2017年论文（Deep reinforcement learning from human preferences）提出。</p> 
<ul><li id="u159092f0">在2020年的论文（Learning to summarize from human feedback）中RM训练使用了交叉熵损失。</li><li id="ucf6c5504">在2023年3月OpenAI发表的论文（Training language models to follow instructions with human feedback）中进一步提供了RLHF实现的标准范式（论文中训练的模型为InstructGPT，ChatGPT是改进后的InstructGPT，比如InstructGPT是基于GPT-3训练，而ChatGPT是基于GPT-3.5训练），如图5所示。</li></ul> 
<blockquote> 
 <p id="ue057bc75">如果想了解InstructGPT论文的详细内容，可以参考我之前的知乎文章：<a href="https://zhuanlan.zhihu.com/p/669312778" rel="nofollow" title="Text-to-SQL小白入门（九）InstructGPT论文：教你如何训练ChatGPT">Text-to-SQL小白入门（九）InstructGPT论文：教你如何训练ChatGPT</a></p> 
</blockquote> 
<p id="u9c8a0a07"></p> 
<p class="img-center"><img alt="" height="1200" id="ub289b720" src="https://images2.imgbox.com/a5/76/W0r6OLZB_o.png" width="1200"></p> 
<p id="uca49a57b">图5 InstructGPT论文中的RLHF实现范式</p> 
<p id="ue8672d9c"></p> 
<p id="ufca4858e">RLHF主要流程有3步：</p> 
<p id="uaa29a6f9">第一阶段：SFT</p> 
<ul><li id="u0ebaed6d">Supervised Fine-tuning有监督微调，简称为SFT。这是InstructGPT（ChatGPT等）训练过程中的一个重要步骤，主要采用有监督的方式对与预训练的LLM进行微调，这个方法比较依赖于标注的数据，SFT数据集标注质量越高（质量不等同于数据），模型的效果越好。</li></ul> 
<blockquote> 
 <p id="u5e5b27f5">之前听一个大学教授的讲座，有个观点很有意思：Open AI做大模型为什么比谷歌强，因为包括transformer在内的一些创新模型大多是谷歌研究的，那为什么Open AI在大模型领域为什么比谷歌强？答：因为Open AI在数据清洗，数据质量把控这方面做的很好。——所以数据是相当重要的！</p> 
</blockquote> 
<p id="uea0158b6">第二阶段：RM</p> 
<ul><li id="u203d29cd">Reward Model奖励模型训练，是InstructGPT训练过程的第二阶段，它的目标是训练一个模型来适应人类的偏好（这里主要是标注人员的偏好）。在RM训练阶段，输入prompt，会使LLM生成多个响应response，然后标注人员对这些响应进行排名，根据这些排名训练一个奖励模型。</li></ul> 
<p id="ub2c8797c">第三阶段：RL</p> 
<ul><li id="u4ef0650a">Reinforcement Learning，是InstructGPT训练中的最后步骤，主要是通过PPO策略（proximal policy optimization 近端策略优化）迭代，它通过引入奖励信号来调整模型的行为，使模型生成的内容更符合人类的偏好。</li></ul> 
<ul><li> 
  <ul><li id="u17835131">输入一个标注数据，模型经过PPO输出一个response</li><li id="uf13f84fc">RM模型对response打分</li><li id="u83649f0f">根据打分score更新PPO策略。</li></ul></li></ul> 
<h2 id="SSdqR">RLHF+Text2SQL的实践探索</h2> 
<p id="ud8315325">本章节主要结合DB-GPT-Hub项目代码以及一些RLHF代码对Text2SQL进行了实践探索。</p> 
<h3 id="HLJOS">SFT</h3> 
<p id="u7ffbb248">SFT模块的实现主要参考<a href="https://github.com/eosphoros-ai/DB-GPT-Hub" title="DB-GPT-Hub">DB-GPT-Hub</a>，比如在Spider数据集上进行实现。</p> 
<h4 id="zpgTo">数据预处理</h4> 
<pre id="NIJxp"><code>sh dbgpt_hub/scripts/gen_train_eval_data.sh</code></pre> 
<p id="u3aec1098">经过数据预处理后，可以得到example_text2sql_train.json和example_text2sql_dev.json</p> 
<p id="ua8486e74"></p> 
<p class="img-center"><img alt="" height="550" id="u5e7e6f99" src="https://images2.imgbox.com/db/62/2fpDYzos_o.png" width="1200"></p> 
<h4 id="RGOFg">数据格式</h4> 
<p id="u24568a32">数据格式如下所示：</p> 
<ul><li id="u2a05404c">db_id-instruction-input-output-history</li></ul> 
<pre id="vTMZB"><code>{
    "db_id": "department_management",
    "instruction": "I want you to act as a SQL terminal in front of an example database, you need only to return the sql command to me.Below is an instruction that describes a task, Write a response that appropriately completes the request.\n\"\n##Instruction:\ndepartment_management contains tables such as department, head, management. Table department has columns such as Department_ID, Name, Creation, Ranking, Budget_in_Billions, Num_Employees. Department_ID is the primary key.\nTable head has columns such as head_ID, name, born_state, age. head_ID is the primary key.\nTable management has columns such as department_ID, head_ID, temporary_acting. department_ID is the primary key.\nThe head_ID of management is the foreign key of head_ID of head.\nThe department_ID of management is the foreign key of Department_ID of department.\n\n",
    "input": "###Input:\nHow many heads of the departments are older than 56 ?\n\n###Response:",
    "output": "SELECT count(*) FROM head WHERE age  &gt;  56",
    "history": []
}</code></pre> 
<ul><li id="u9c7570e5">最终经过代码后会形成为这样的格式：prompt-output</li></ul> 
<pre id="ZL39c"><code>{"prompt": "I want you to act as a SQL terminal in front of an example database, you need only to return the sql command to me.Below is an instruction that describes a task, Write a response that appropriately completes the request.\n\"\n##Instruction:\ndepartment_management contains tables such as department, head, management. Table department has columns such as Department_ID, Name, Creation, Ranking, Budget_in_Billions, Num_Employees. Department_ID is the primary key.\nTable head has columns such as head_ID, name, born_state, age. head_ID is the primary key.\nTable management has columns such as department_ID, head_ID, temporary_acting. department_ID is the primary key.\nThe head_ID of management is the foreign key of head_ID of head.\nThe department_ID of management is the foreign key of Department_ID of department.\n###Input:\nHow many heads of the departments are older than 56 ?\n\n###Response:","output": "SELECT count(*) FROM head WHERE age  &gt;  56"}
</code></pre> 
<h4 id="VScZK">训练</h4> 
<pre id="NKTSm"><code>sh dbgpt_hub/scripts/train_sft.sh</code></pre> 
<blockquote> 
 <p id="u54119801">训练的基础大模型为CodeLlama-13b-instruct，如果想了解该开源模型，可以参考论文讲解：<a href="https://zhuanlan.zhihu.com/p/656493371" rel="nofollow" title="Text-to-SQL小白入门（五）开源代码大模型Code Llama">Text-to-SQL小白入门（五）开源代码大模型Code Llama</a></p> 
</blockquote> 
<p id="ua71913be">训练的参数如下所示：</p> 
<pre id="lzpbu"><code>CUDA_VISIBLE_DEVICES=0 python dbgpt_hub/train/sft_train.py \
    --model_name_or_path /home/model/CodeLlama-13B-Instruct \
    --do_train \
    --dataset example_text2sql_train \
    --max_source_length 2048 \
    --max_target_length 512 \
    --template llama2 \
    --finetuning_type lora \
    --lora_rank 64 \
    --lora_alpha 32 \
    --lora_target q_proj,v_proj \
    --output_dir dbgpt_hub/output/adapter/CodeLlama-13B-Instruct-lora \
    --overwrite_cache \
    --overwrite_output_dir \
    --per_device_train_batch_size 1 \
    --gradient_accumulation_steps 16 \
    --lr_scheduler_type cosine_with_restarts \
    --logging_steps 500 \
    --save_steps 2000 \
    --learning_rate 2e-4 \
    --num_train_epochs 8 \
    --plot_loss \
    --bf16</code></pre> 
<h4 id="gFh4T">预测</h4> 
<pre id="Y2b2q"><code>sh dbgpt_hub/scripts/predict_sft.sh</code></pre> 
<p id="u9c3a17bb">预测完成后，会生成一个predict.sql文件，文件中存放了dev集合中1034个sql.</p> 
<p id="uc4b7ecfe"></p> 
<p class="img-center"><img alt="" height="1056" id="u49dec9fe" src="https://images2.imgbox.com/ef/aa/j1znLak2_o.png" width="1200"></p> 
<h4 id="NAyAQ">评估</h4> 
<p id="u1f2e0c97">测试的库为<a href="https://github.com/taoyds/test-suite-sql-eval" title="ts库">ts库</a></p> 
<pre id="rsh1U"><code> python dbgpt_hub/eval/evaluation.py --plug_value --input Your_model_pred_file</code></pre> 
<p id="u2eed9b45">评估过程如下所示：会对每一个sql进行对比，对错误的sql进行打印输出展示。</p> 
<p id="u3a6c03a4"></p> 
<p class="img-center"><img alt="" height="706" id="u615905e9" src="https://images2.imgbox.com/10/c8/eE1Y16Uo_o.png" width="1200"></p> 
<p id="u0c571887">最终对1034条sql验证完成后，可以得到EX、EM精度得分。</p> 
<ul><li id="u35309e5c">EX-0.746</li></ul> 
<p id="u2c4ed7d4">其他模型的一些baseline分数也可以通过DB-GPT-Hub获取。</p> 
<p id="uc40a8c5c"></p> 
<p class="img-center"><img alt="" height="975" id="u393ee04a" src="https://images2.imgbox.com/c7/e9/Vm9roeCC_o.png" width="1200"></p> 
<h3 id="w2BVT">RM</h3> 
<p id="u7f46ee02">RM模型训练的模型以SFT阶段的模型为基础，参考<a href="https://github.com/microsoft/DeepSpeedExamples/tree/master/applications/DeepSpeed-Chat" title="微软代码">微软代码</a>进行训练（Hub项目近期也会增加RLHF功能，敬请期待），自行构建了少量Text2SQL的RM训练数据集用于测试训练。</p> 
<h4 id="sriWe">数据格式</h4> 
<p id="uc66ce940">数据格式如下所示：</p> 
<ul><li id="u8a44270e">prompy-chosen-rejected</li><li id="u35354a79">chosen就是在SFT阶段的ground truth</li><li id="u01da1744">rejected就是模型的错误输出结果</li></ul> 
<pre id="HZJsj"><code>{"prompt": "I want you to act as a SQL terminal in front of an example database, you need only to return the sql command to me.Below is an instruction that describes a task, Write a response that appropriately completes the request.\n\"\n##Instruction:\ndepartment_management contains tables such as department, head, management. Table department has columns such as Department_ID, Name, Creation, Ranking, Budget_in_Billions, Num_Employees. Department_ID is the primary key.\nTable head has columns such as head_ID, name, born_state, age. head_ID is the primary key.\nTable management has columns such as department_ID, head_ID, temporary_acting. department_ID is the primary key.\nThe head_ID of management is the foreign key of head_ID of head.\nThe department_ID of management is the foreign key of Department_ID of department.\n###Input:\nHow many heads of the departments are older than 56 ?\n\n###Response:","chosen": "SELECT count(*) FROM head WHERE age  &gt;  56","rejected":"SELECT COUNT(head_name) FROM head WHERE age &gt; 56;"}</code></pre> 
<h4 id="wKHhj">训练</h4> 
<ul><li id="uf9143bcc">比如训练10个epoch的训练结果如下：</li></ul> 
<pre id="lfE9W"><code>deepspeed --num_gpus=$n_gpu \
   main.py \
   --data_path $data_path \
   --data_split 2,4,4 \
   --model_name_or_path $model_name_or_path \
   --per_device_train_batch_size 8 \
   --per_device_eval_batch_size 8 \
   --max_seq_len 1024 \
   --learning_rate 9.65e-6 \
   --weight_decay 0.1 \
   --num_padding_at_beginning 0 \
   --num_train_epochs 10  \
   --gradient_accumulation_steps 1 \
   --lr_scheduler_type cosine \
   --num_warmup_steps 0 \
   --seed 1234 \
   --gradient_checkpointing \
   --zero_stage $ZERO_STAGE \
   --deepspeed \
   --offload \
   --lora_dim 128 \
   --lora_module_name "layers." \
   --output_dir $OUTPUT \
   2&gt;&amp;1 | tee $OUTPUT/log.txt</code></pre> 
<p id="u40054bd9"></p> 
<p class="img-center"><img alt="" height="950" id="u57cfde1f" src="https://images2.imgbox.com/2c/ca/4SThM5VC_o.png" width="1200"></p> 
<h4 id="Eh13k">结果</h4> 
<p id="u36d3445c">训练完成后，会在制定目前生成训练好的模型，比如有以下文件：</p> 
<ul><li id="u66be5bbf">config.json</li><li id="u3f8cb414">log.txt</li><li id="ub92ea08e">pytorch_model.bin</li><li id="u14d76685">tokenizer.model</li></ul> 
<p id="u0effa2b3"></p> 
<p class="img-center"><img alt="" height="126" id="u495c4d12" src="https://images2.imgbox.com/80/5e/9IIz3YDB_o.png" width="460"></p> 
<h3 id="qWNUz">RL</h3> 
<h4 id="inR2a">数据格式</h4> 
<p id="u9918ff19">RL阶段和SFT阶段的数据格式保持一致，以Text2SQL任务举例子，RL数据可以构造为（prompt，output}的二元组，如下所示：</p> 
<ul><li id="uc7bd5871">prompt-otput</li></ul> 
<pre id="cjjWg"><code>{"prompt": "I want you to act as a SQL terminal in front of an example database, you need only to return the sql command to me.Below is an instruction that describes a task, Write a response that appropriately completes the request.\n\"\n##Instruction:\ndepartment_management contains tables such as department, head, management. Table department has columns such as Department_ID, Name, Creation, Ranking, Budget_in_Billions, Num_Employees. Department_ID is the primary key.\nTable head has columns such as head_ID, name, born_state, age. head_ID is the primary key.\nTable management has columns such as department_ID, head_ID, temporary_acting. department_ID is the primary key.\nThe head_ID of management is the foreign key of head_ID of head.\nThe department_ID of management is the foreign key of Department_ID of department.\n###Input:\nHow many heads of the departments are older than 56 ?\n\n###Response:","output": "SELECT count(*) FROM head WHERE age  &gt;  56"}</code></pre> 
<h4 id="wAW1G">训练</h4> 
<ul><li id="u18f5efe6">训练参数</li></ul> 
<ul><li> 
  <ul><li id="ua75f8c05">SFT模型即为上面训练的SFT模型</li><li id="u55f3a4f8">RM模型即为上面训练的RM模型</li><li id="u4e3ae699">训练10epoch</li></ul></li></ul> 
<pre id="va0l0"><code>deepspeed --master_port 12346 main.py \
   --data_path $data_path \
   --data_split 2,4,4 \
   --actor_model_name_or_path $ACTOR_MODEL_PATH \
   --critic_model_name_or_path $CRITIC_MODEL_PATH \
   --num_padding_at_beginning 1 \
   --per_device_generation_batch_size 8 \
   --per_device_training_batch_size 8 \
   --generation_batches 1 \
   --ppo_epochs 1 \
   --max_answer_seq_len 256 \
   --max_prompt_seq_len 1024 \
   --actor_learning_rate ${Actor_Lr} \
   --critic_learning_rate ${Critic_Lr} \
   --actor_weight_decay 0.1 \
   --critic_weight_decay 0.1 \
   --num_train_epochs 10 \
   --lr_scheduler_type cosine \
   --gradient_accumulation_steps 1 \
   --actor_gradient_checkpointing \
   --critic_gradient_checkpointing \
   --offload_reference_model \
   --disable_actor_dropout \
   --num_warmup_steps 100 \
   --deepspeed --seed 1234 \
   --actor_zero_stage $ACTOR_ZERO_STAGE \
   --critic_zero_stage $CRITIC_ZERO_STAGE \
   --enable_hybrid_engine \
   --actor_lora_dim 64 \
   --critic_lora_dim 64 \
   --critic_lora_module_name "layers." \
   --actor_lora_module_name "layers." \
   --output_dir $OUTPUT \
   2&gt;&amp;1 | tee $OUTPUT/log.txt</code></pre> 
<ul><li id="u4a0968c8">训练结束</li></ul> 
<p id="u87d1220a"></p> 
<p class="img-center"><img alt="" height="1018" id="u97e3e4be" src="https://images2.imgbox.com/51/7e/CkZFWd05_o.png" width="1200"></p> 
<h4 id="uVaXb">结果</h4> 
<p id="u3f002526">训练结束会得到两个模型，actor模型即为需要的最终评测模型。</p> 
<p id="u5b12433a"></p> 
<p class="img-center"><img alt="" height="92" id="ueaca1ead" src="https://images2.imgbox.com/6e/d1/bszVHW6q_o.png" width="380"></p> 
<h4 id="fCUV3">验证</h4> 
<ul><li id="u653e28e3">验证得到的模型</li><li id="u696cf18e">EX-0.752</li><li id="ua5c90318">EM-0.717</li></ul> 
<p id="udd93fa3e"></p> 
<p class="img-center"><img alt="" height="756" id="TCbXS" src="https://images2.imgbox.com/95/e0/833fYXwB_o.png" width="1200"></p> 
<p id="u27c6090b">可以发现的是，RLHF相比SFT方法，精度有轻微提升，主要是数据质量的问题，后续还可以进一步探索。</p> 
<p id="u185be67c"></p> 
<h2 id="j2Phm">其他文章学习</h2> 
<p id="u994c3a97"><a href="https://zhuanlan.zhihu.com/p/647249972" rel="nofollow" title="xt-to-SQL小白入门（一）综述文章学习">xt-to-SQL小白入门（一）综述文章学习</a></p> 
<p id="u07f29def"><a href="https://zhuanlan.zhihu.com/p/650407036" rel="nofollow" title="Text-to-SQL小白入门（二）Transformer学习">Text-to-SQL小白入门（二）Transformer学习</a></p> 
<p id="u17eeca78"><a href="https://zhuanlan.zhihu.com/p/652294152" rel="nofollow" title="Text-to-SQL小白入门（三）IRNet：引入中间表示SemQL">Text-to-SQL小白入门（三）IRNet：引入中间表示SemQL</a></p> 
<p id="ufdbf6d92"><a href="https://zhuanlan.zhihu.com/p/654162068" rel="nofollow" title="Text-to-SQL小白入门（四）指令进化大模型WizardLM">Text-to-SQL小白入门（四）指令进化大模型WizardLM</a></p> 
<p id="u7e0fe3f5"><a href="https://zhuanlan.zhihu.com/p/656493371" rel="nofollow" title="Text-to-SQL小白入门（五）开源代码大模型Code Llama">Text-to-SQL小白入门（五）开源代码大模型Code Llama</a></p> 
<p id="u31665cd0"><a href="https://zhuanlan.zhihu.com/p/656918007" rel="nofollow" title="Text-to-SQL小白入门（六）Awesome-Text2SQL项目介绍">Text-to-SQL小白入门（六）Awesome-Text2SQL项目介绍</a></p> 
<p id="uec41fe00"><a href="https://zhuanlan.zhihu.com/p/658543614" rel="nofollow" title="Text-to-SQL小白入门（七）PanGu-Coder2论文——RRTF">Text-to-SQL小白入门（七）PanGu-Coder2论文——RRTF</a></p> 
<p id="u8e92ea3b"><a href="https://zhuanlan.zhihu.com/p/660920800" rel="nofollow" title="Text-to-SQL小白入门（八）RLAIF论文：AI代替人类反馈的强化学习">Text-to-SQL小白入门（八）RLAIF论文：AI代替人类反馈的强化学习</a></p> 
<p id="u264fa536"><a href="https://zhuanlan.zhihu.com/p/669312778" rel="nofollow" title="Text-to-SQL小白入门（九）InstructGPT论文：教你如何训练ChatGPT">Text-to-SQL小白入门（九）InstructGPT论文：教你如何训练ChatGPT</a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/3744b9a7c2fbcde2d80baa3b59338786/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【大数据毕设】基于Hadoop的招聘网站可视化的设计与实现(一)</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/70e31c6b5f15208960365b819194d0af/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">ONNX格式模型 学习笔记 (onnxRuntime部署)---用java调用yolov8模型来举例</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>