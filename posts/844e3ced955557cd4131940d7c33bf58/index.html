<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Hadoop 面试题（六） - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/844e3ced955557cd4131940d7c33bf58/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="Hadoop 面试题（六）">
  <meta property="og:description" content="1. 简述Google三驾马车是Hadoop等分布式系统的基石，其中论文()不属于三驾马车之一 ？ A：GFS B：MapReduce C：OpenTSDB D：BigTable 选项C：OpenTSDB 不属于Google三驾马车之一。
Google的三驾马车是指以下三篇具有里程碑意义的论文，它们对Hadoop等分布式系统的设计理念产生了深远影响：
A: GFS (Google File System) —— GFS是Google开发的一个分布式文件系统，其论文描述了GFS的架构和设计，对Hadoop的HDFS（Hadoop Distributed File System）有重要影响。
B: MapReduce —— MapReduce是Google提出的一种编程模型，用于大规模数据集的并行处理。Hadoop的MapReduce是受Google MapReduce论文启发而开发的。
D: BigTable —— BigTable是Google开发的一种分布式存储系统，用于结构化数据。它的设计影响了Hadoop生态系统中的HBase等NoSQL数据库。
OpenTSDB是一个开源的时间序列数据库，它并不是Google三驾马车之一。OpenTSDB用于处理和存储时间序列数据，通常用于监控和测量系统。
2. 简述现有一个安装 2.6.5 版本的 Hadoop 集群，在不修改默认配置的情况下，存储 200 个每个 200M 的文本文件，请问最终会在集群中产生多少个数据块（包括副本） ？ A：200 B：40000 C：400 D：1200 在Hadoop中，默认的数据块大小（dfs.blocksize）是128MB。给定的文本文件每个是200MB，但由于Hadoop的块大小是128MB，文件会被分割成两个数据块：一个128MB的块和一个不足128MB的剩余部分块。
由于每个文件会产生至少两个数据块（第一个块128MB，第二个块小于128MB），200个文件将产生至少400个数据块。
然而，由于默认的副本因子（dfs.replication）是3，这意味着每个数据块会有3个副本。所以，最终产生的数据块总数将是文件产生的数据块数乘以副本因子。
计算如下：
[ \text{总数据块数} = \frac{200 \times 200MB}{128MB} \times 3 ]
[ \text{总数据块数} = 2 \times 200 \times 3 ]
[ \text{总数据块数} = 400 \times 3 ]">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-06-23T11:54:01+08:00">
    <meta property="article:modified_time" content="2024-06-23T11:54:01+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Hadoop 面试题（六）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h4><a id="1_GoogleHadoop__0"></a>1. 简述Google三驾马车是Hadoop等分布式系统的基石，其中论文()不属于三驾马车之一 ？</h4> 
<pre><code class="prism language-text">A：GFS
B：MapReduce
C：OpenTSDB
D：BigTable
</code></pre> 
<p>选项C：<strong>OpenTSDB</strong> 不属于Google三驾马车之一。</p> 
<p>Google的三驾马车是指以下三篇具有里程碑意义的论文，它们对Hadoop等分布式系统的设计理念产生了深远影响：</p> 
<p>A: <strong>GFS (Google File System)</strong> —— GFS是Google开发的一个分布式文件系统，其论文描述了GFS的架构和设计，对Hadoop的HDFS（Hadoop Distributed File System）有重要影响。</p> 
<p>B: <strong>MapReduce</strong> —— MapReduce是Google提出的一种编程模型，用于大规模数据集的并行处理。Hadoop的MapReduce是受Google MapReduce论文启发而开发的。</p> 
<p>D: <strong>BigTable</strong> —— BigTable是Google开发的一种分布式存储系统，用于结构化数据。它的设计影响了Hadoop生态系统中的HBase等NoSQL数据库。</p> 
<p>OpenTSDB是一个开源的时间序列数据库，它并不是Google三驾马车之一。OpenTSDB用于处理和存储时间序列数据，通常用于监控和测量系统。</p> 
<h4><a id="2__265__Hadoop__200__200M___20"></a>2. 简述现有一个安装 2.6.5 版本的 Hadoop 集群，在不修改默认配置的情况下，存储 200 个每个 200M 的文本文件，请问最终会在集群中产生多少个数据块（包括副本） ？</h4> 
<pre><code class="prism language-text">A：200
B：40000
C：400
D：1200
</code></pre> 
<p>在Hadoop中，默认的数据块大小（<code>dfs.blocksize</code>）是128MB。给定的文本文件每个是200MB，但由于Hadoop的块大小是128MB，文件会被分割成两个数据块：一个128MB的块和一个不足128MB的剩余部分块。</p> 
<p>由于每个文件会产生至少两个数据块（第一个块128MB，第二个块小于128MB），200个文件将产生至少400个数据块。</p> 
<p>然而，由于默认的副本因子（<code>dfs.replication</code>）是3，这意味着每个数据块会有3个副本。所以，最终产生的数据块总数将是文件产生的数据块数乘以副本因子。</p> 
<p>计算如下：<br> [ \text{总数据块数} = \frac{200 \times 200MB}{128MB} \times 3 ]<br> [ \text{总数据块数} = 2 \times 200 \times 3 ]<br> [ \text{总数据块数} = 400 \times 3 ]<br> [ \text{总数据块数} = 1200 ]</p> 
<p>所以正确答案是D：1200个数据块（包括副本）。</p> 
<h4><a id="3_HadoopDataNode123DataNode123Block1Clientfile1HadoopHadoop__42"></a>3. 假设有Hadoop系统中有DataNode节点1、2、3，且DataNode节点1、2、3上有Block1，Client请求上传文件file1至Hadoop系统，下面描述该Hadoop系统写流程错误的是（） ？</h4> 
<pre><code class="prism language-text">A：Client第一次请求NameNode上传文件file1
B：当NameNode返回可以上传后，Client第二个请求会请求file1上传到哪个DataNode节点上
C：当Client第三次请求时，DataNode数据管道搭建完毕后，会由NameNode应答Client
D：当Client第三次请求时，DataNode数据管道搭建完毕后，会由多个DataNode节点等依次逐级应答Client
</code></pre> 
<p>描述错误的是选项C：<strong>当Client第三次请求时，DataNode数据管道搭建完毕后，会由NameNode应答Client</strong>。</p> 
<p>以下是对每个选项的简述：</p> 
<p>A: <strong>Client第一次请求NameNode上传文件file1</strong> —— 这个描述是正确的。在写操作开始前，Client会首先与NameNode通信，请求上传文件。</p> 
<p>B: <strong>当NameNode返回可以上传后，Client第二个请求会请求file1上传到哪个DataNode节点上</strong> —— 这个描述是正确的。NameNode会告诉Client将数据发送到哪些DataNode上。</p> 
<p>C: <strong>当Client第三次请求时，DataNode数据管道搭建完毕后，会由NameNode应答Client</strong> —— 这个描述是错误的。在数据管道搭建完毕后，Client开始发送数据，数据会直接发送到DataNode，不需要NameNode介入应答。</p> 
<p>D: <strong>当Client第三次请求时，DataNode数据管道搭建完毕后，会由多个DataNode节点等依次逐级应答Client</strong> —— 这个描述是正确的。在Hadoop写操作中，Client会将数据发送到第一个DataNode（管道的源头），然后这个DataNode会将数据发送到下一个DataNode，依此类推，每个DataNode在接收并转发数据后会向源DataNode发送确认信息。</p> 
<p>在Hadoop的写流程中，Client首先与NameNode通信以确定数据块的存储位置，然后直接与DataNode建立连接并发送数据。数据在DataNode之间通过pipeline方式传输，每个DataNode在接收数据后会向其上游DataNode发送确认，直到最后一个DataNode接收完毕并保存数据。</p> 
<h4><a id="4__Hadoop___64"></a>4. 简述关于 Hadoop 技术描述错误的是（） ？</h4> 
<pre><code class="prism language-text">A：HDFS 是一个分布式文件存储系统
B：HDFS 不适合低延时数据访问的场景
C：HDFS 适合存储大量的小文件
D：HDFS 存储空间由数据节点数决定
</code></pre> 
<p>描述错误的是选项C：<strong>HDFS 适合存储大量的小文件</strong>。</p> 
<p>以下是对每个选项的简述：</p> 
<p>A: <strong>HDFS 是一个分布式文件存储系统</strong> —— 这个描述是正确的。HDFS（Hadoop Distributed File System）是一个分布式文件系统，设计用于跨多个机器存储和处理大量数据。</p> 
<p>B: <strong>HDFS 不适合低延时数据访问的场景</strong> —— 这个描述是正确的。HDFS 优化了高吞吐量的数据处理，但不是为低延时访问设计，尤其是在需要频繁的随机写操作时。</p> 
<p>C: <strong>HDFS 适合存储大量的小文件</strong> —— 这个描述是错误的。HDFS 并不适合存储大量的小文件，因为这会导致NameNode有大量的元数据需要管理，从而可能导致性能问题。</p> 
<p>D: <strong>HDFS 存储空间由数据节点数决定</strong> —— 这个描述是部分正确的，但有些误导。HDFS的存储容量确实受到DataNode数量和每个DataNode存储容量的限制，但也受到HDFS块大小和副本因子等配置的影响。</p> 
<p>HDFS 最适合的是存储大文件和大数据集，这些数据集可以分布在集群中的多个DataNode上进行并行处理。对于小文件，Hadoop社区推荐使用其他工具，比如HBase或Alluxio，这些工具更适合处理小文件或低延迟数据访问的场景。</p> 
<h4><a id="5_MapReduce__86"></a>5. 简述关于MapReduce的描述错误的是（） ？</h4> 
<pre><code class="prism language-text">A：MapReduce框架由一个单独的master JobTracker 和每个集群设备一个slave TaskTracker共同组成
B：master负责调度构成一个作业的所有任务，这些任务分布在不同的slave上
C：master监控slave上任务的执行，重新执行已经失败的任务。而slave仅负责执行由master指派的任务
D：slave不仅负责执行由master指派的任务，还会重新执行失败的任务
</code></pre> 
<p>描述错误的是选项D：<strong>slave不仅负责执行由master指派的任务，还会重新执行失败的任务</strong>。</p> 
<p>以下是对每个选项的简述：</p> 
<p>A: <strong>MapReduce框架由一个单独的master JobTracker 和每个集群设备一个slave TaskTracker共同组成</strong> —— 这个描述是正确的，适用于Hadoop 1.x版本。JobTracker是负责作业调度和监控的master节点，而TaskTracker是运行在集群的每个slave设备上的进程，负责执行任务。</p> 
<p>B: <strong>master负责调度构成一个作业的所有任务，这些任务分布在不同的slave上</strong> —— 这个描述是正确的。在MapReduce框架中，master节点（JobTracker或ResourceManager）负责整个作业的任务调度。</p> 
<p>C: <strong>master监控slave上任务的执行，重新执行已经失败的任务。而slave仅负责执行由master指派的任务</strong> —— 这个描述是正确的。master节点监控所有任务的执行状态，并在任务失败时重新调度执行，而slave节点（TaskTracker或NodeManager）仅执行由master指派的任务。</p> 
<p>D: <strong>slave不仅负责执行由master指派的任务，还会重新执行失败的任务</strong> —— 这个描述是错误的。在MapReduce框架中，slave节点通常不负责重新执行失败的任务，这是由master节点监控并执行的操作。</p> 
<p>在Hadoop 2.x及更高版本中，JobTracker的角色被ResourceManager取代，而TaskTracker的角色被NodeManager取代，但基本原理相同。</p> 
<h4><a id="6_Hadoop011_108"></a>6. 简述下列关于Hadoop命令中，命令执行成功返回0，执行失败返回-1，下列命令返回-1的是（）</h4> 
<pre><code class="prism language-text">A：hadoop fs -mv /user/hadoop/file1 /user/hadoop/file2
B：hdfs dfs -mv hdfs:///testData file:///tmp/testData
C：hadoop fs -put localfile hdfs://host:port/hadoop/hadoopfile
D：hadoop fs -put localfile /user/hadoop/hadoopfile
</code></pre> 
<p>命令返回-1通常表示执行失败。以下是对每个选项的简述：</p> 
<p>A: <strong>hadoop fs -mv /user/hadoop/file1 /user/hadoop/file2</strong> —— 如果<code>file1</code>存在并且<code>file2</code>不存在，这个移动操作可能会成功，返回0。如果<code>file2</code>已经存在，或者<code>file1</code>不存在，命令可能会失败，返回-1。</p> 
<p>B: <strong>hdfs dfs -mv hdfs:///testData file:///tmp/testData</strong> —— 这个命令尝试将HDFS上的文件或目录移动到本地文件系统的一个不同的位置。如果本地目录<code>/tmp/testData</code>不存在或者移动操作因为其他原因失败（如权限问题），命令将返回-1。</p> 
<p>C: <strong>hadoop fs -put localfile hdfs://host:port/hadoop/hadoopfile</strong> —— 如果<code>localfile</code>存在并且HDFS路径<code>hdfs://host:port/hadoop/hadoopfile</code>是有效的，文件将被上传，命令返回0。如果本地文件不存在，或者HDFS路径无效（如端口错误或NameNode不可达），命令将失败，返回-1。</p> 
<p>D: <strong>hadoop fs -put localfile /user/hadoop/hadoopfile</strong> —— 这个命令尝试将本地文件<code>localfile</code>上传到HDFS的指定路径。如果本地文件存在并且HDFS路径有效，命令将成功，返回0。如果本地文件不存在或HDFS路径无效，命令将失败，返回-1。</p> 
<p>根据这些描述，无法确定哪个命令一定返回-1，因为返回值取决于命令执行时的具体情况（如文件是否存在、路径是否有效等）。然而，如果我们要假设一个命令因为无效的路径或操作失败而返回-1，那么最可能是选项B，因为如果<code>hdfs:///testData</code>是一个目录或<code>file:///tmp/testData</code>的本地路径不可写，该命令可能会失败。但请注意，在没有具体执行环境和上下文的情况下，我们不能确定哪个命令一定返回-1。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/404d94cfe7237d9e2a7440b4904bccde/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">何恺明新作再战AI生成：入职MIT后首次带队，奥赛双料金牌得主邓明扬参与</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/6c002a911ff161c437974db31dba7055/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">苹果解锁工具iToolab UnlockGo 中文安装版(附教程&#43;补丁) 2024年6月ios17.4.1可用（记得点赞）解压密码请看文章最后 评论区获取最新链接</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>