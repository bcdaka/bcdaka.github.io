<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Python一元和多元线性回归模型的原理及评估【附代码】 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/33cb5ef968ad9d4e97f35b6dd0e7e9d5/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="Python一元和多元线性回归模型的原理及评估【附代码】">
  <meta property="og:description" content="目录
1.一元线性回归
（1）线性回归模型的定义
（2）一元线性回归的数学原理
（3）一元线性回归的代码实现
1.绘制散点图
2. 引入Scikit-learn库搭建模型
3.模型预测
4.模型可视化
5.线性回归方程构造
（4）案例：不同行业工作年限与收入的线性回归模型
1.案例背景
2.读取数据
3.模型搭建
4.模型可视化
5.线性回归方程构造
6.补充：一元多线性回归
2.线性回归模型评估
（1）模型评估的编程实现
（2）模型评估的数学原理
1.R-squared的理解
2.Adj. R-squared的理解（过拟合与欠拟合）
3.P值的理解
3.多元线性回归
（1）多元线性回归的数学原理和代码实现
（2）案例：客户价值预测模型
1.案例背景
2.读取数据
3.模型搭建
4.线性回归方程构造
5.模型评估
1.一元线性回归 （1）线性回归模型的定义 线性回归模型是利用线性拟合的方式来探寻数据背后的规律，如下图所示，就是通过搭建线性回归模型来寻找这些散点（也称样本点）背后的趋势线（也称回归曲线），而通过这个回归曲线我们就能进行一些简单的预测分析或因果关系分析。
线性回归中，我们根据特征变量（也称自变量）来对反应变量（也称因变量）进行预测，根据特征变量的个数可将线性回归模型分为一元线性回归和多元线性回归。通过一个特征变量：工作年限对收入进行预测，就属于一元线性回归；通过多个特征变量：工作年限、行业、所在城市等对收入进行预测，就属于多元线性回归。这一小节主要先讲解下一元线性回归模型。
（2）一元线性回归的数学原理 一元线性回归模型也称为简单线性回归模型，其形式可以通过如下公式表达：
其中y为因变量，x为自变量，a表示回归系数，b表示截距。其中为实际值，为预测值，一元线性回归的目的就是拟合出一条线来使得预测值和实际值尽可能的接近，如果大部分点都落在拟合出来的线上，那么该线性回归模型则拟合较好。
我们通过两者差值的平方和（该和也称为残差平方和）来进行衡量，公式如下，其中为∑为求和符号。此外，补充说明一句，在机器学习领域，该残差平方和也被称之为回归模型的损失函数。
显然我们希望这个和越小越好，这样实际值和预测值就更加接近，而数学上求最小值的方法为求导数，当导数为0时，该残差平方和最小。那么通过对残差平方和进行求导，然后令其导数为0便可以求得一元线性回归模型的系数a和截距b，这个便是一元线性回归的数学原理，学术上称其为最小二乘法。而在Python中就有专门的库来求解这里的系数a和截距b，而不需要我们去计算复杂的数学公式。
（3）一元线性回归的代码实现 1.绘制散点图 首先通过Matplotlib库先绘制几个散点，代码如下：
X=[[1],[2],[3],[4],[5]] Y=[2,4,6,8] 其中自变量集合X需要写成二维结构形式，也即大列表里包含着小列表，这个其实是符合之后多元回归的逻辑，因为多元回归，一个因变量y可能对应着多个自变量x，比如对于三元线性回归(即有三个特征变量)，此时的自变量集合X就需要写成类似如下形式：
X=[[1,2,3],[2,4,5],[4,6,8],[5,7,9]] 此时的散点如下图所示（附代码）：
import matplotlib.pyplot as plt X = [[1], [2], [4], [5]] Y = [2, 4, 6, 8] plt.scatter(X, Y) plt.show() 2.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-03-09T19:55:00+08:00">
    <meta property="article:modified_time" content="2024-03-09T19:55:00+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Python一元和多元线性回归模型的原理及评估【附代码】</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p id="main-toc"><strong>目录</strong></p> 
<p id="1.%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92-toc" style="margin-left:0px;"><a href="#1.%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92" rel="nofollow">1.一元线性回归</a></p> 
<p id="%EF%BC%881%EF%BC%89%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%AE%9A%E4%B9%89-toc" style="margin-left:80px;"><a href="#%EF%BC%881%EF%BC%89%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%AE%9A%E4%B9%89" rel="nofollow">（1）线性回归模型的定义</a></p> 
<p id="%EF%BC%882%EF%BC%89%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86-toc" style="margin-left:80px;"><a href="#%EF%BC%882%EF%BC%89%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86" rel="nofollow">（2）一元线性回归的数学原理</a></p> 
<p id="%EF%BC%883%EF%BC%89%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9A%84%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0-toc" style="margin-left:80px;"><a href="#%EF%BC%883%EF%BC%89%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9A%84%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0" rel="nofollow">（3）一元线性回归的代码实现</a></p> 
<p id="1.%E7%BB%98%E5%88%B6%E6%95%A3%E7%82%B9%E5%9B%BE-toc" style="margin-left:120px;"><a href="#1.%E7%BB%98%E5%88%B6%E6%95%A3%E7%82%B9%E5%9B%BE" rel="nofollow">1.绘制散点图</a></p> 
<p id="2.%C2%A0%E5%BC%95%E5%85%A5Scikit-learn%E5%BA%93%E6%90%AD%E5%BB%BA%E6%A8%A1%E5%9E%8B-toc" style="margin-left:120px;"><a href="#2.%C2%A0%E5%BC%95%E5%85%A5Scikit-learn%E5%BA%93%E6%90%AD%E5%BB%BA%E6%A8%A1%E5%9E%8B" rel="nofollow">2. 引入Scikit-learn库搭建模型</a></p> 
<p id="3.%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B-toc" style="margin-left:120px;"><a href="#3.%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B" rel="nofollow">3.模型预测</a></p> 
<p id="4.%E6%A8%A1%E5%9E%8B%E5%8F%AF%E8%A7%86%E5%8C%96-toc" style="margin-left:120px;"><a href="#4.%E6%A8%A1%E5%9E%8B%E5%8F%AF%E8%A7%86%E5%8C%96" rel="nofollow">4.模型可视化</a></p> 
<p id="5.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%96%B9%E7%A8%8B%E6%9E%84%E9%80%A0-toc" style="margin-left:120px;"><a href="#5.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%96%B9%E7%A8%8B%E6%9E%84%E9%80%A0" rel="nofollow">5.线性回归方程构造</a></p> 
<p id="(4)%E6%A1%88%E4%BE%8B%EF%BC%9A%E4%B8%8D%E5%90%8C%E8%A1%8C%E4%B8%9A%E5%B7%A5%E4%BD%9C%E5%B9%B4%E9%99%90%E4%B8%8E%E6%94%B6%E5%85%A5%E7%9A%84%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B-toc" style="margin-left:80px;"><a href="#%284%29%E6%A1%88%E4%BE%8B%EF%BC%9A%E4%B8%8D%E5%90%8C%E8%A1%8C%E4%B8%9A%E5%B7%A5%E4%BD%9C%E5%B9%B4%E9%99%90%E4%B8%8E%E6%94%B6%E5%85%A5%E7%9A%84%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B" rel="nofollow">（4）案例：不同行业工作年限与收入的线性回归模型</a></p> 
<p id="1.%E6%A1%88%E4%BE%8B%E8%83%8C%E6%99%AF-toc" style="margin-left:120px;"><a href="#1.%E6%A1%88%E4%BE%8B%E8%83%8C%E6%99%AF" rel="nofollow">1.案例背景</a></p> 
<p id="2.%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE-toc" style="margin-left:120px;"><a href="#2.%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE" rel="nofollow">2.读取数据</a></p> 
<p id="3.%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA-toc" style="margin-left:120px;"><a href="#3.%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA" rel="nofollow">3.模型搭建</a></p> 
<p id="4.%E6%A8%A1%E5%9E%8B%E5%8F%AF%E8%A7%86%E5%8C%96-toc" style="margin-left:120px;"><a href="#4.%E6%A8%A1%E5%9E%8B%E5%8F%AF%E8%A7%86%E5%8C%96" rel="nofollow">4.模型可视化</a></p> 
<p id="5.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%96%B9%E7%A8%8B%E6%9E%84%E9%80%A0-toc" style="margin-left:120px;"><a href="#5.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%96%B9%E7%A8%8B%E6%9E%84%E9%80%A0" rel="nofollow">5.线性回归方程构造</a></p> 
<p id="6.%E8%A1%A5%E5%85%85%EF%BC%9A%E4%B8%80%E5%85%83%E5%A4%9A%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92-toc" style="margin-left:120px;"><a href="#6.%E8%A1%A5%E5%85%85%EF%BC%9A%E4%B8%80%E5%85%83%E5%A4%9A%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92" rel="nofollow">6.补充：一元多线性回归</a></p> 
<p id="2.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0-toc" style="margin-left:0px;"><a href="#2.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0" rel="nofollow">2.线性回归模型评估</a></p> 
<p id="%EF%BC%881%EF%BC%89%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E7%9A%84%E7%BC%96%E7%A8%8B%E5%AE%9E%E7%8E%B0-toc" style="margin-left:80px;"><a href="#%EF%BC%881%EF%BC%89%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E7%9A%84%E7%BC%96%E7%A8%8B%E5%AE%9E%E7%8E%B0" rel="nofollow">（1）模型评估的编程实现</a></p> 
<p id="%EF%BC%882%EF%BC%89%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86-toc" style="margin-left:80px;"><a href="#%EF%BC%882%EF%BC%89%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86" rel="nofollow">（2）模型评估的数学原理</a></p> 
<p id="1.R-squared%E7%9A%84%E7%90%86%E8%A7%A3-toc" style="margin-left:120px;"><a href="#1.R-squared%E7%9A%84%E7%90%86%E8%A7%A3" rel="nofollow">1.R-squared的理解</a></p> 
<p id="2.Adj.%20R-squared%E7%9A%84%E7%90%86%E8%A7%A3%EF%BC%88%E8%BF%87%E6%8B%9F%E5%90%88%E4%B8%8E%E6%AC%A0%E6%8B%9F%E5%90%88%EF%BC%89-toc" style="margin-left:120px;"><a href="#2.Adj.%20R-squared%E7%9A%84%E7%90%86%E8%A7%A3%EF%BC%88%E8%BF%87%E6%8B%9F%E5%90%88%E4%B8%8E%E6%AC%A0%E6%8B%9F%E5%90%88%EF%BC%89" rel="nofollow">2.Adj. R-squared的理解（过拟合与欠拟合）</a></p> 
<p id="3.P%E5%80%BC%E7%9A%84%E7%90%86%E8%A7%A3-toc" style="margin-left:120px;"><a href="#3.P%E5%80%BC%E7%9A%84%E7%90%86%E8%A7%A3" rel="nofollow">3.P值的理解</a></p> 
<p id="3.%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92-toc" style="margin-left:0px;"><a href="#3.%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92" rel="nofollow">3.多元线性回归</a></p> 
<p id="%EF%BC%881%EF%BC%89%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86%E5%92%8C%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0-toc" style="margin-left:80px;"><a href="#%EF%BC%881%EF%BC%89%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86%E5%92%8C%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0" rel="nofollow">（1）多元线性回归的数学原理和代码实现</a></p> 
<p id="%EF%BC%882%EF%BC%89%E6%A1%88%E4%BE%8B%EF%BC%9A%E5%AE%A2%E6%88%B7%E4%BB%B7%E5%80%BC%E9%A2%84%E6%B5%8B%E6%A8%A1%E5%9E%8B-toc" style="margin-left:80px;"><a href="#%EF%BC%882%EF%BC%89%E6%A1%88%E4%BE%8B%EF%BC%9A%E5%AE%A2%E6%88%B7%E4%BB%B7%E5%80%BC%E9%A2%84%E6%B5%8B%E6%A8%A1%E5%9E%8B" rel="nofollow">（2）案例：客户价值预测模型</a></p> 
<p id="1.%E6%A1%88%E4%BE%8B%E8%83%8C%E6%99%AF-toc" style="margin-left:120px;"><a href="#1.%E6%A1%88%E4%BE%8B%E8%83%8C%E6%99%AF" rel="nofollow">1.案例背景</a></p> 
<p id="2.%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE-toc" style="margin-left:120px;"><a href="#2.%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE" rel="nofollow">2.读取数据</a></p> 
<p id="3.%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA-toc" style="margin-left:120px;"><a href="#3.%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA" rel="nofollow">3.模型搭建</a></p> 
<p id="4.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%96%B9%E7%A8%8B%E6%9E%84%E9%80%A0-toc" style="margin-left:120px;"><a href="#4.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%96%B9%E7%A8%8B%E6%9E%84%E9%80%A0" rel="nofollow">4.线性回归方程构造</a></p> 
<p id="5.%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0-toc" style="margin-left:120px;"><a href="#5.%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0" rel="nofollow">5.模型评估</a></p> 
<hr id="hr-toc"> 
<p></p> 
<h2 id="1.%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92">1.一元线性回归</h2> 
<h4 id="%EF%BC%881%EF%BC%89%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%AE%9A%E4%B9%89">（1）线性回归模型的定义</h4> 
<p style="margin-left:0in;"><span style="color:#000000;">        线性回归模型是利用线性拟合的方式来探寻数据背后的规律，如下图所示，就是通过搭建线性回归模型来寻找这些散点（也称样本点）背后的趋势线（也称回归曲线），而通过这个回归曲线我们就能进行一些简单的预测分析或因果关系分析。</span></p> 
<p class="img-center"><img alt="" height="260" src="https://images2.imgbox.com/15/c0/P7DBtJ9f_o.png" width="380"></p> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       线性回归中，我们根据特征变量（也称自变量）来对反应变量（也称因变量）进行预测，根据特征变量的个数可将线性回归模型分为一元线性回归和多元线性回归</span><span style="color:#000000;">。通过一个特征变量：工作年限对收入进行预测，就属于一元线性回归；通过多个特征变量：工作年限、行业、所在城市等对收入进行预测，就属于多元线性回归。这一小节主要先讲解下一元线性回归模型。</span></p> 
<h4 id="%EF%BC%882%EF%BC%89%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86" style="margin-left:0in;text-align:left;"><span style="color:#000000;">（2）一元线性回归的数学原理</span></h4> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       一</span><span style="color:#000000;">元线性回归模型也称为简单线性回归模型，其形式可以通过如下公式表达</span><span style="color:#000000;">：</span></p> 
<p class="img-center"><img alt="" height="45" src="https://images2.imgbox.com/54/94/001CGqxY_o.png" width="223"></p> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       其中y</span><span style="color:#000000;">为因变量，</span><span style="color:#000000;">x</span><span style="color:#000000;">为自变量，</span><span style="color:#000000;">a</span><span style="color:#000000;">表示回归系数，</span><span style="color:#000000;">b</span><span style="color:#000000;">表示截距</span><span style="color:#000000;">。其中</span><img alt="y^{i}" class="mathcode" src="https://images2.imgbox.com/25/53/QB7Im4rx_o.png"><span style="color:#000000;">为</span><span style="color:#000000;">实际值，</span><img alt="\hat{y}^{i}" class="mathcode" src="https://images2.imgbox.com/54/fc/aBIe7NPR_o.png"><span style="color:#000000;">为预测值，一元线性回归的目的就是拟合出一条线来使得预测值和实际值尽可能的接近，如果大部分点都落在拟合出来的线上，那么该线性回归模型则拟合较好。</span></p> 
<p class="img-center"><img alt="" height="312" src="https://images2.imgbox.com/d4/3c/PUJKZg9q_o.png" width="501"></p> 
<p style="margin-left:0in;"><span style="color:#000000;">       我们通过两者差值的平方和（该和也称为残差平方和）来进行衡量，公式如下，</span><span style="color:#000000;">其中</span><span style="color:#000000;">为</span>∑为<span style="color:#000000;">求和符号。此外，补充说明一句，在机器学习领域，该残差平方和也被称之为回归模型的损失函数。</span></p> 
<p class="img-center"><img alt="" height="55" src="https://images2.imgbox.com/20/ab/eLTVvOPX_o.png" width="381"></p> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       显然我们希望这个和越小越好，这样实际值和预测值就更加接近，而数学上求最小值的方法为求导数，当导数为</span><span style="color:#000000;">0时，该残差平方和最小。那么通过对残差平方和进行求导，然后令其导数为</span><span style="color:#000000;">0</span><span style="color:#000000;">便可以求得一元线性回归模型的系数</span><span style="color:#000000;">a</span><span style="color:#000000;">和截距</span><span style="color:#000000;">b</span><span style="color:#000000;">，这个便是一元线性回归的数学原理，学术上称其为</span><span style="color:#000000;"><strong>最小二乘法</strong></span><span style="color:#000000;">。而在</span><span style="color:#000000;">Python</span><span style="color:#000000;">中就有专门的库来求解这里的系数</span><span style="color:#000000;">a</span><span style="color:#000000;">和截距</span><span style="color:#000000;">b</span><span style="color:#000000;">，而不需要我们去计算复杂的数学公式。</span></p> 
<h4 id="%EF%BC%883%EF%BC%89%E4%B8%80%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9A%84%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0" style="margin-left:0in;text-align:left;">（3）一元线性回归的代码实现</h4> 
<h5 id="1.%E7%BB%98%E5%88%B6%E6%95%A3%E7%82%B9%E5%9B%BE" style="margin-left:0in;text-align:left;"><span style="color:#000000;">1.绘制散点图</span></h5> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       首先通过</span><span style="color:#000000;">Matplotlib</span><span style="color:#000000;">库先绘制几个散点，代码如下：</span></p> 
<pre><code class="language-python">X=[[1],[2],[3],[4],[5]]
Y=[2,4,6,8]</code></pre> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;"><strong>       </strong></span><span style="color:#000000;">其中</span><span style="color:#000000;">自变量集合</span><span style="color:#000000;">X</span><span style="color:#000000;">需要写成二维结构形式，也即大列表里包含着小列表，这个其实是符合之后多元回归的逻辑，因为多元回归，一个因变量</span><span style="color:#000000;">y</span><span style="color:#000000;">可能对应着多个自变量</span><span style="color:#000000;">x</span><span style="color:#000000;">，比如对于三元线性回归</span><span style="color:#000000;">(</span><span style="color:#000000;">即有三个特征变量</span><span style="color:#000000;">)</span><span style="color:#000000;">，此时的自变量集合</span><span style="color:#000000;">X</span><span style="color:#000000;">就需要写成类似如下</span><span style="color:#000000;">形式：</span></p> 
<pre><code class="language-python">X=[[1,2,3],[2,4,5],[4,6,8],[5,7,9]]</code></pre> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       此时的散点如下图所示（附代码）：</span></p> 
<pre><code class="language-python">import matplotlib.pyplot as plt
X = [[1], [2], [4], [5]]
Y = [2, 4, 6, 8]
plt.scatter(X, Y)
plt.show()</code></pre> 
<p class="img-center"><img alt="" height="343" src="https://images2.imgbox.com/41/1d/ZCgIWoL3_o.png" width="444"></p> 
<p style="margin-left:0in;"></p> 
<h5 id="2.%C2%A0%E5%BC%95%E5%85%A5Scikit-learn%E5%BA%93%E6%90%AD%E5%BB%BA%E6%A8%A1%E5%9E%8B" style="margin-left:0in;">2. <span style="color:#000000;">引入</span><span style="color:#000000;">Scikit</span><span style="color:#000000;">-learn</span><span style="color:#000000;">库搭建</span><span style="color:#000000;">模型</span></h5> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       有了原始数据后，引入</span><span style="color:#000000;">Scikit</span><span style="color:#000000;">-learn</span><span style="color:#000000;">库便可快速搭建线性回归模型，代码如下：</span></p> 
<pre><code class="language-python">from sklearn.linear_model import LinearRegression
regr = LinearRegression()
regr.fit(X,Y)</code></pre> 
<h5 id="3.%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B" style="margin-left:0in;">3.模型预测</h5> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       regr</span><span style="color:#000000;">已经是搭建好的模型了，此时就可以通过该模型来预测数据了，比如自变量是数字</span><span style="color:#000000;">1.5</span><span style="color:#000000;">，那么通过</span><span style="color:#000000;">predict()</span><span style="color:#000000;">函数就能预测当自变量</span><span style="color:#000000;">x=1.5</span><span style="color:#000000;">时对应的因变量</span><span style="color:#000000;">y</span><span style="color:#000000;">了，代码如下</span><span style="color:#000000;">：</span></p> 
<pre><code class="language-python">y = regr.predict([[1.5]])
print(y)</code></pre> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       注意这里的自变量还是得写成二维结构的形式，原理和之前绘制散点图时写成二维结构数据类似，此时获得的预测结果</span><span style="color:#000000;">y</span><span style="color:#000000;">如下所示，此时获得</span><span style="color:#000000;">y</span><span style="color:#000000;">为一个一维数组。      </span></p> 
<pre><code class="language-python">[2.9]</code></pre> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">        此外，如果想同时预测多个自变量，则可以使用如下代码</span><span style="color:#000000;">：</span></p> 
<pre><code class="language-python">y = regr.predict([[1.5], [2.5], [4.5]])
print(y)</code></pre> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       此时的预测结果如下：</span></p> 
<pre><code class="language-python">[2.9 4.3 7.1]</code></pre> 
<h5 id="4.%E6%A8%A1%E5%9E%8B%E5%8F%AF%E8%A7%86%E5%8C%96" style="margin-left:0in;">4.<span style="color:#000000;">模型可视化</span></h5> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       我们还可以将搭建好的模型可视化展示出来，代码如下：</span></p> 
<pre><code class="language-python">plt.scatter(X, Y)
plt.plot(X, regr.predict(X))
plt.show()</code></pre> 
<p class="img-center"><img alt="" height="361" src="https://images2.imgbox.com/48/68/e7IWbBzi_o.png" width="465"></p> 
<h5 id="5.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%96%B9%E7%A8%8B%E6%9E%84%E9%80%A0">5.<span style="color:#000000;">线性回归方程</span><span style="color:#000000;">构造</span></h5> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       可以通过</span><span style="color:#000000;">coef</span><span style="color:#000000;">_</span><span style="color:#000000;">和</span><span style="color:#000000;">intercept_</span><span style="color:#000000;">得到此时直线的系数及截距，代码如下：</span></p> 
<p style="margin-left:0in;text-align:left;"></p> 
<pre><code class="language-python">print('系数a为:' + str(regr.coef_[0]))
print('截距b为:' + str(regr.intercept_))</code></pre> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       运行结果如下：</span></p> 
<pre><code class="language-python">系数a为:1.4000000000000004
截距b为:0.7999999999999989</code></pre> 
<p style="margin-left:0in;text-align:left;">       那么此时的一元线性回归得到的线性回归方程就可以表示为如下形式：y = 1.4*x + 0.8</p> 
<h4 id="(4)%E6%A1%88%E4%BE%8B%EF%BC%9A%E4%B8%8D%E5%90%8C%E8%A1%8C%E4%B8%9A%E5%B7%A5%E4%BD%9C%E5%B9%B4%E9%99%90%E4%B8%8E%E6%94%B6%E5%85%A5%E7%9A%84%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B" style="margin-left:0in;text-align:left;">（4）案例：<span style="color:#000000;"><strong>不同行业工作年限与收入的线性回归</strong></span><span style="color:#000000;"><strong>模型</strong></span></h4> 
<h5 id="1.%E6%A1%88%E4%BE%8B%E8%83%8C%E6%99%AF" style="margin-left:0in;text-align:left;">1.案例背景</h5> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       通常</span><span style="color:#000000;">来说，收入都会随着工作年限的增长而增长，而在不同的行业中收入的增长速度都会有所不同，本小节就是来通过一元线性回归模型来探寻工作年限对收入的影响，也即搭建收入预测模型，同时比较多个行业的收入预测模型来分析各个行业的特点</span><span style="color:#000000;">。</span></p> 
<h5 id="2.%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE" style="margin-left:0in;text-align:left;">2.读取数据</h5> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       这里我们首先以目前比较火的</span><span style="color:#000000;">IT</span><span style="color:#000000;">行业为例，这里选取的是北京地区的</span><span style="color:#000000;">IT</span><span style="color:#000000;">行业工龄分布于</span><span style="color:#000000;">0-8</span><span style="color:#000000;">年的</span><span style="color:#000000;">100</span><span style="color:#000000;">个</span><span style="color:#000000;">IT</span><span style="color:#000000;">工程师月工资情况，通过如下代码读取</span><span style="color:#000000;">数据。</span></p> 
<pre><code class="language-python">import pandas as pd
df = pd.read_excel('IT行业收入表.xlsx')
df.head()</code></pre> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       使用</span><span style="color:#000000;">.head()</span><span style="color:#000000;">打印结果如下</span><span style="color:#000000;">：</span></p> 
<p class="img-center"><img alt="" height="188" src="https://images2.imgbox.com/80/c3/io819Irx_o.png" width="496"></p> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       此时的工龄为自变量，薪水为因变量，通过如下代码进行自变量、因变量选取：</span></p> 
<pre><code class="language-python">X = df[['工龄']]
Y = df['薪水']</code></pre> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       通过如下代码可以将此时的散点图绘制出来：</span></p> 
<pre><code class="language-python">from matplotlib import pyplot as plt
plt.rcParams['font.sans-serif'] = ['SimHei']  
plt.scatter(X,Y)
plt.xlabel('工龄')
plt.ylabel('薪水')
plt.show()</code></pre> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       最后运行</span><span style="color:#000000;">效果如下图所示：</span></p> 
<p class="img-center"><img alt="" height="287" src="https://images2.imgbox.com/17/16/G7AG5gXN_o.png" width="470"></p> 
<h5 id="3.%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA" style="margin-left:0in;text-align:left;">3.模型搭建</h5> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       通过如下代码即可搭建线性回归模型</span><span style="color:#000000;">：</span></p> 
<pre><code class="language-python">from sklearn.linear_model import LinearRegression
regr = LinearRegression() 
regr.fit(X,Y)  </code></pre> 
<h5 style="margin-left:0in;text-align:left;">4.模型可视化</h5> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       通过如下代码即可将线性回归模型可视化呈现：</span></p> 
<pre><code class="language-python">plt.scatter(X,Y)
plt.plot(X, regr.predict(X), color='red') 
plt.xlabel('工龄')
plt.ylabel('薪水')
plt.show()</code></pre> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       此时运行效果如下图所示：</span></p> 
<p class="img-center"><img alt="" height="298" src="https://images2.imgbox.com/9b/99/vDQ5LMmj_o.png" width="451"></p> 
<h5 style="margin-left:0in;text-align:left;">5.<span style="color:#000000;">线性回归</span><span style="color:#000000;">方程</span><span style="color:#000000;">构造</span></h5> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       我们还可以通过上一小节的知识点查看该直线的斜率系数</span><span style="color:#000000;">a</span><span style="color:#000000;">和截距</span><span style="color:#000000;">b</span><span style="color:#000000;">，代码如下</span><span style="color:#000000;">：</span></p> 
<pre><code class="language-python">print('系数a为:' + str(regr.coef_[0]))
print('截距b为:' + str(regr.intercept_))</code></pre> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       运行结果如下：</span></p> 
<pre><code class="language-python">系数a为:2497.1513476046866
截距b为:10143.131966873787
</code></pre> 
<h5 id="6.%E8%A1%A5%E5%85%85%EF%BC%9A%E4%B8%80%E5%85%83%E5%A4%9A%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92" style="margin-left:0in;text-align:left;">6.补充：一元多线性回归</h5> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       如何通过代码的方式来搭建一个一元二次线性回归模型，首先通过如下代码生成二次项数据</span><span style="color:#000000;">：</span></p> 
<pre><code class="language-python">from sklearn.preprocessing import PolynomialFeatures
poly_reg = PolynomialFeatures(degree=2)
X_ = poly_reg.fit_transform(X)</code></pre> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       生成完二次项数据后，就可以根据和之前一样的代码获得一元二次线性回归模型了</span><span style="color:#000000;">：</span></p> 
<pre><code class="language-python">regr = LinearRegression()
regr.fit(X_, Y)</code></pre> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       然后通过和类似的代码就可以绘制上面的曲线图了，注意此时的</span><span style="color:#000000;">predict()</span><span style="color:#000000;">函数中填的是</span><span style="color:#000000;">X_</span><span style="color:#000000;">。</span></p> 
<pre><code class="language-python">plt.scatter(X,Y)
plt.plot(X, regr.predict(X_), color='red')
plt.show()</code></pre> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       通过类似的手段，我们可以获取此时的一元二次回归方程的系数</span><span style="color:#000000;">a,b</span><span style="color:#000000;">和常数项</span><span style="color:#000000;">c</span><span style="color:#000000;">，代码如下：</span></p> 
<pre><code class="language-python">print(regr.coef_) 
print(regr.intercept_)</code></pre> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       结果如下：</span></p> 
<pre><code class="language-python">[   0.         -743.68080444  400.80398224]
13988.159332096882</code></pre> 
<p>       此时的系数项中为3个数，第一个0对应之前生成的X_常数项前面的系数，也对应之前说的X_的常数项不会产生影响；-743.68代表的X_一次项前面的系数，也即系数b；400.8代表的X_二次项前面的系数，也即系数a；而13988则代表常数项c，所以该一元二次线性回归方程为：</p> 
<p style="text-align:center;"><strong>y = 400.8<em>x^2 - 743.68</em>x + 13988</strong></p> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       用</span><span style="color:#000000;">同样的方法，我们可以获取到金融行业、汽车制造行业、餐饮服务行业的工龄与薪酬的线性相关性，这四个行业的一元二次线性回归模型如下图所示：</span></p> 
<p style="margin-left:0in;text-align:left;"><img alt="" height="537" src="https://images2.imgbox.com/b4/3b/lGsihab2_o.png" width="877"></p> 
<h2 id="2.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0">2.线性回归模型评估</h2> 
<h4 id="%EF%BC%881%EF%BC%89%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E7%9A%84%E7%BC%96%E7%A8%8B%E5%AE%9E%E7%8E%B0">（1）<span style="color:#000000;"><strong>模型评估的编程</strong></span><span style="color:#000000;"><strong>实现</strong></span></h4> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       模型搭建完成后，我们还需要对模型进行评估，这里我们主要以三个值作为评判标准</span><span style="color:#000000;">：</span></p> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       1.R-squared</span><span style="color:#000000;">（也即统计学中常说的</span><span style="color:#000000;">R^2</span><span style="color:#000000;">）</span></p> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       2.Adj</span><span style="color:#000000;">. R-squared</span><span style="color:#000000;">（也即</span><span style="color:#000000;">Adjusted R^2</span><span style="color:#000000;">）</span></p> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       3.P</span><span style="color:#000000;">值</span></p> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       其中</span><span style="color:#000000;">R-squared</span><span style="color:#000000;">和</span><span style="color:#000000;">Adj. R-squared</span><span style="color:#000000;">用来衡量线性拟合的</span><span style="color:#000000;">程度P值用来衡量特征变量的显著性。</span></p> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       在应用中，我们只需要记得</span><span style="color:#000000;">R squared</span><span style="color:#000000;">或者</span><span style="color:#000000;">Adj. R-squared</span><span style="color:#000000;">越高，那么模型的拟合程度越高；如果</span><span style="color:#000000;">P</span><span style="color:#000000;">值越低，那么该特征变量的显著性越高，也即真的和预测变量有相关性</span><span style="color:#000000;">。R-squared 和 Adj</span><span style="color:#000000;">. R-squared</span><span style="color:#000000;">的取值范围为</span><span style="color:#000000;">0-1，P值本质是个概率值，其取值范围也为</span><span style="color:#000000;">0-1。</span></p> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       在</span><span style="color:#000000;">Python</span><span style="color:#000000;">中，通过如下代码即可查看这三个参数：</span></p> 
<pre><code class="language-python">import statsmodels.api as sm
X2 = sm.add_constant(X)
est = sm.OLS(Y, X2).fit()
est.summary()  </code></pre> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       打印</span><span style="color:#000000;">est.summary</span><span style="color:#000000;">():</span></p> 
<p class="img-center"><img alt="" height="427" src="https://images2.imgbox.com/19/7a/dUFauRW2_o.png" width="476"></p> 
<h4 id="%EF%BC%882%EF%BC%89%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86">（2）<span style="color:#000000;"><strong>模型评估的数学</strong></span><span style="color:#000000;"><strong>原理</strong></span></h4> 
<h5 id="1.R-squared%E7%9A%84%E7%90%86%E8%A7%A3">1.<span style="color:#000000;">R-squared</span><span style="color:#000000;">的理解</span></h5> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       首先来看</span><span style="color:#000000;">R-squared</span><span style="color:#000000;">，要想理解</span><span style="color:#000000;">R-squared</span><span style="color:#000000;">，得先了解三个新的概念</span><span style="color:#000000;">：</span></p> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       1.整体平方和 <strong>TSS</strong>(Total </span><span style="color:#000000;">Sum of Squares</span><span style="color:#000000;">)</span></p> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       2.残差平方和 <strong>RSS</strong></span><span style="color:#000000;">(Residual </span><span style="color:#000000;">Sum of Squares</span><span style="color:#000000;">)</span></p> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       3.解释平方和 <strong>ESS</strong></span><span style="color:#000000;">(Explained </span><span style="color:#000000;">Sum of Squares</span><span style="color:#000000;">)</span></p> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       相关</span><span style="color:#000000;">内容解释都绘制在下图</span><span style="color:#000000;">中</span><span style="color:#000000;">:其中Yi</span><span style="color:#000000;">为实际</span><span style="color:#000000;">值，Yfitted为预测</span><span style="color:#000000;">值，Ymean为所有散点</span><span style="color:#000000;">平均值：</span></p> 
<p class="img-center"><img alt="" height="372" src="https://images2.imgbox.com/04/92/7yd8lKz3_o.png" width="489"></p> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       R-squared</span><span style="color:#000000;">的公式为</span><span style="color:#000000;">=</span> </p> 
<p class="img-center"><img alt="" height="65" src="https://images2.imgbox.com/50/5e/xjJSHvuU_o.png" width="126"></p> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       当</span><span style="color:#000000;">RSS</span><span style="color:#000000;">趋向于</span><span style="color:#000000;">0</span><span style="color:#000000;">的时候，说明实际值基本都落在了拟合曲线上，其拟合程度非常高，那么此时</span><span style="color:#000000;">R-squared</span><span style="color:#000000;">趋向于</span><span style="color:#000000;">1</span><span style="color:#000000;">，所以在实战当中，</span><span style="color:#000000;">R-squared</span><span style="color:#000000;">越大（越接近</span><span style="color:#000000;">1</span><span style="color:#000000;">），其拟合程度越高</span><span style="color:#000000;">。不过也不是拟合程度越高越好，当拟合程度过高的时候，可能会导致过拟合的现象。</span></p> 
<p style="margin-left:0in;text-align:left;"><img alt="" height="584" src="https://images2.imgbox.com/c8/b3/Py1EFarj_o.png" width="1200"></p> 
<h5 id="2.Adj.%20R-squared%E7%9A%84%E7%90%86%E8%A7%A3%EF%BC%88%E8%BF%87%E6%8B%9F%E5%90%88%E4%B8%8E%E6%AC%A0%E6%8B%9F%E5%90%88%EF%BC%89">2.<span style="color:#000000;">Adj. R-squared的理解（<strong>过拟合与欠</strong></span><span style="color:#000000;"><strong>拟合</strong>）</span></h5> 
<p><img alt="" height="439" src="https://images2.imgbox.com/be/15/DPpClHGc_o.png" width="1200"></p> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       所谓</span><span style="color:#000000;">过度拟合（简称过拟合），是指模型在训练样本中拟合程度过高，虽然它很好地贴合了训练集数据，但是却丧失了泛化能力，模型不具有推广性，导致在新的数据集中表现不佳</span><span style="color:#000000;">。过拟合相对的则是欠拟合，欠拟合是指模型拟合程度不高，数据距离拟合曲线较远，或指模型没有很好地捕捉到数据特征，不能够很好地拟合数据。Adj. R-squared是</span><span style="color:#000000;">R-squared</span><span style="color:#000000;">的改进</span><span style="color:#000000;">版，其目的是为了防止选取的特征变量过多，而导致虚高的R-squared，每当新增一个特征变量的时候，因为线性回归背后的数学原理，都会导致R-squared增加，但是可能这个新增的特征变量可能对模型并没有什么帮助，为了限制过多的特征变量，所以引入了</span><span style="color:#000000;">Adj. R-squared</span><span style="color:#000000;">的概念，Adj. R-squared</span><span style="color:#000000;">会</span><span style="color:#000000;">在原来</span><span style="color:#000000;">R-squared</span><span style="color:#000000;">的基础上额外考虑到特征变量数目这一值，其公式如下</span><span style="color:#000000;">：</span></p> 
<p class="img-center"><img alt="" height="61" src="https://images2.imgbox.com/2f/07/Dou6rh9v_o.png" width="295"></p> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       其中</span><span style="color:#000000;">n</span><span style="color:#000000;">为样本</span><span style="color:#000000;">数量，k为特征变量</span><span style="color:#000000;">数量，可以看到当特征变量数量</span><span style="color:#000000;">k</span><span style="color:#000000;">越多的时候，其实会对</span><span style="color:#000000;">Adj. R-squared</span><span style="color:#000000;">产生负影响，因此不要为了一味地追求高</span><span style="color:#000000;">R-squared</span><span style="color:#000000;">而过多的添加特征变量。</span></p> 
<p class="img-center"><img alt="" height="73" src="https://images2.imgbox.com/f3/5e/LOeVeoZD_o.png" width="522"></p> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       可以看到对于完全拟合的线性方程</span><span style="color:#000000;">Adj. R-squared</span><span style="color:#000000;">和</span><span style="color:#000000;">R-squared</span><span style="color:#000000;">是一致的，都为数字</span><span style="color:#000000;">1</span><span style="color:#000000;">。倘若不是完全拟合，例如此时的</span><span style="color:#000000;">R-squared</span><span style="color:#000000;">为</span><span style="color:#000000;">0.9</span><span style="color:#000000;">，那么此时</span><span style="color:#000000;">Adj. R-squared</span><span style="color:#000000;">的计算过程与结果如下所示：</span></p> 
<p class="img-center"><img alt="" height="62" src="https://images2.imgbox.com/09/2c/UaBJNoUc_o.png" width="324"></p> 
<h5 id="3.P%E5%80%BC%E7%9A%84%E7%90%86%E8%A7%A3">3.<span style="color:#000000;">P</span><span style="color:#000000;">值的理解</span></h5> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       P</span><span style="color:#000000;">值涉及统计学里假设检验中的</span><span style="color:#000000;">概念，其</span><span style="color:#000000;">原假设为特征变量与预测变量无显著相关性，</span><span style="color:#000000;">P</span><span style="color:#000000;">值是当原假设为真时所得到的样本观察结果或更极端结果出现的概率</span><span style="color:#000000;">。</span><span style="color:#000000;"><strong>通常来说，我们会以</strong></span><span style="color:#000000;"><strong>0.05</strong></span><span style="color:#000000;"><strong>为阈值，当</strong></span><span style="color:#000000;"><strong>P</strong></span><span style="color:#000000;"><strong>值小于</strong></span><span style="color:#000000;"><strong>0.05</strong></span><span style="color:#000000;"><strong>时，就认为该特征变量与预测变量显著相关。</strong></span></p> 
<h2 id="3.%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92">3.多元线性回归</h2> 
<h4 id="%EF%BC%881%EF%BC%89%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9A%84%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86%E5%92%8C%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0">（1）<span style="color:#000000;"><strong>多元线性回归的数学原理和代码</strong></span><span style="color:#000000;"><strong>实现</strong></span></h4> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       多元线性回归模型的原理其实和一元线性回归的原理类似，其形式可以用如下公式表达</span><span style="color:#000000;">：</span></p> 
<p style="margin-left:0in;text-align:center;"><span style="color:#000000;"><img alt="y=k_{0}+k_{1}\times x_{1}+......" class="mathcode" src="https://images2.imgbox.com/0f/07/2xtAdiPE_o.png"></span></p> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       其中：</span><span style="color:#000000;">x1</span><span style="color:#000000;">、</span><span style="color:#000000;">x2</span><span style="color:#000000;">、</span><span style="color:#000000;">x3……</span><span style="color:#000000;">为不同特征变量</span><span style="color:#000000;">，</span></p> 
<p style="margin-left:0in;text-align:left;">                  <span style="color:#000000;">k1</span><span style="color:#000000;">、</span><span style="color:#000000;">k2</span><span style="color:#000000;">、</span><span style="color:#000000;">k3……</span><span style="color:#000000;">则为这些特征变量前的系数</span><span style="color:#000000;">，</span></p> 
<p style="margin-left:0in;text-align:left;">                  <span style="color:#000000;">k0</span><span style="color:#000000;">为常数</span><span style="color:#000000;">项</span></p> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       多元线性回归模型的搭建也是通过数学计算来获取合适的系数，使得下图所示的残差平方和最小</span><span style="color:#000000;">，<img alt="y^{i}" class="mathcode" src="https://images2.imgbox.com/6f/e2/gY4ubssd_o.png"></span><span style="color:#000000;">其中</span><span style="color:#000000;">为实际值，<img alt="\hat{y}^{^{i}}" class="mathcode" src="https://images2.imgbox.com/05/eb/SnOyhdgp_o.png"></span><span style="color:#000000;">为预测值</span><span style="color:#000000;">。</span></p> 
<p class="img-center"><img alt="" height="60" src="https://images2.imgbox.com/a9/37/Mqmo9j4g_o.png" width="148"></p> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       其核心代码和一元线性回归其实是一致的，代码</span><span style="color:#000000;">如下</span><span style="color:#000000;">:</span></p> 
<pre><code class="language-python">from sklearn.linear_model import LinearRegression
regr = LinearRegression()
regr.fit(X,Y)</code></pre> 
<h4 id="%EF%BC%882%EF%BC%89%E6%A1%88%E4%BE%8B%EF%BC%9A%E5%AE%A2%E6%88%B7%E4%BB%B7%E5%80%BC%E9%A2%84%E6%B5%8B%E6%A8%A1%E5%9E%8B" style="margin-left:0in;text-align:left;">（2）案例：<span style="color:#000000;"><strong>客户价值</strong></span><span style="color:#000000;"><strong>预测模型</strong></span></h4> 
<h5>1.案例背景</h5> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       这里以信用卡客户的客户价值来解释下客户价值预测的具体含义：客户价值预测就是指客户未来一段时间能带来多少利润，其利润的来源可能来自于信用卡的年费、取现手续费、分期手续费、境外交易手续费用等。而分析出客户的价值后，在进行营销、电话接听、催收、产品咨询等各项服务时，就可以针对高价值的客户进行区别于普通客户的服务，有助于进一步挖掘这些高价值客户的价值，并提高这些高价值客户的忠诚度。</span></p> 
<h5 style="margin-left:0in;text-align:left;">2.读取数据</h5> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       通过如下代码读取相关数据，这里共选取了</span><span style="color:#000000;">100</span><span style="color:#000000;">多组已有的客户价值数据，其中一些数据已经经过一些简单预处理了。</span></p> 
<pre><code class="language-python">import pandas as pd
df = pd.read_excel('客户价值数据表.xlsx')
df.head()  </code></pre> 
<p style="margin-left:0in;text-align:left;"><img alt="" height="484" src="https://images2.imgbox.com/9c/df/6RabFzQ8_o.png" width="1200"></p> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       其中</span><span style="color:#000000;">客户价值为</span><span style="color:#000000;">1</span><span style="color:#000000;">年的客户价值，即在</span><span style="color:#000000;">1</span><span style="color:#000000;">年里能给银行带来的</span><span style="color:#000000;">收益；学历已经进行数据的预处理，其中2</span><span style="color:#000000;">表示高中学历，</span><span style="color:#000000;">3</span><span style="color:#000000;">表示本科学历，</span><span style="color:#000000;">4</span><span style="color:#000000;">表示研究生</span><span style="color:#000000;">学历；性别中0</span><span style="color:#000000;">表示女，</span><span style="color:#000000;">1</span><span style="color:#000000;">表示</span><span style="color:#000000;">男。</span></p> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       此时的后</span><span style="color:#000000;">5</span><span style="color:#000000;">列为自变量 ，“客户价值”为因变量，通过如下代码进行自变量、因变量选取</span><span style="color:#000000;">：</span></p> 
<pre><code class="language-python">X = df[['历史贷款金额', '贷款次数', '学历', '月收入', '性别']]
Y = df['客户价值']</code></pre> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       自变量</span><span style="color:#000000;">X</span><span style="color:#000000;">同样必须写成二维</span><span style="color:#000000;">数据结构，因变量Y</span><span style="color:#000000;">写成一维的数据结构即</span><span style="color:#000000;">可。</span></p> 
<h5 style="margin-left:0in;text-align:left;">3.模型搭建</h5> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       通过如下代码即可搭建线性回归模型</span><span style="color:#000000;">：</span></p> 
<pre><code class="language-python">from sklearn.linear_model import LinearRegression
regr = LinearRegression()
regr.fit(X,Y)</code></pre> 
<h5 id="4.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%96%B9%E7%A8%8B%E6%9E%84%E9%80%A0" style="margin-left:0in;text-align:left;"><span style="color:#000000;">4.线性回归</span><span style="color:#000000;">方程</span><span style="color:#000000;">构造</span></h5> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       看该直线的斜率系数</span><span style="color:#000000;">a</span><span style="color:#000000;">和截距</span><span style="color:#000000;">b</span><span style="color:#000000;">，代码如下</span><span style="color:#000000;">：</span></p> 
<pre><code class="language-python">print('各系数为:' + str(regr.coef_))
print('常数项系数k0为:' + str(regr.intercept_))</code></pre> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">       运行结果如下：</span></p> 
<pre><code class="language-python">各系数为:[5.71421731e-02 9.61723492e+01 1.13452022e+02 5.61326459e-02
 1.97874093e+00]
常数项系数k0为:-208.42004079958383</code></pre> 
<h5 id="5.%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0" style="margin-left:0in;text-align:left;">5.模型评估</h5> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">      利用</span><span style="color:#000000;">模型评估的方法我们也可以对多元线性回归进行模型评估，代码如下：</span></p> 
<pre><code class="language-python">import statsmodels.api as sm  
X2 = sm.add_constant(X)
est = sm.OLS(Y, X2).fit()
est.summary()</code></pre> 
<p class="img-center"><img alt="" height="559" src="https://images2.imgbox.com/ee/38/OGYKKsf3_o.png" width="553"></p> 
<p style="margin-left:0in;text-align:left;"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/30eda2ae20e81867770bbd45e9f822a3/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">[MySQL报错]关于发生net start mysql 服务无法启动，服务没有报告任何错误的五种解决方案。</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/fddfb81a4de181ccff54fdb7df6e4800/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">用小程序中的uni方法实现uView中的upload组件并将图片上传到腾讯云</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>