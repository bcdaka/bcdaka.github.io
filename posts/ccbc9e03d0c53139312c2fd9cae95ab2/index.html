<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>whisper之初步使用记录 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/ccbc9e03d0c53139312c2fd9cae95ab2/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="whisper之初步使用记录">
  <meta property="og:description" content="文章目录 前言
一、whisper是什么？
二、使用步骤
1.安装
2.python调用
3.识别效果评估
4.一点封装
5.参考链接
总结
前言 随着AI大模型的不断发展，语音识别等周边内容也再次引发关注，通过语音转文字再与大模型交互，从而实现语音与大模型交互。
今天我们介绍下语音识别领域的顶级选手whisper。
一、whisper是什么？ whisper是openai开源的语音识别模型，也是使用了Transformer架构。
openai宣称whisper的语音识别能力已经到了人类的水平。
接下来我们参考Github结合其他技术博客内容，实操下whisper的使用。
二、使用步骤 1.安装 1）pip安装whisper
pip install -U openai-whisper 2）安装ffmpeg
下载地址：ffmpeg下载地址https://github.com/BtbN/FFmpeg-Builds/releases
选择对应操作系统的安装包即可
Linux系统也可以直接命令方式安装。
对于Windows系统，下载到本地后解压缩即可，但是需要设置环境变量，路径bin（就是在这个路径下有ffmpeg.exe）
特意说明：whisper内部其实调用了ffmpeg，使用的就是cmd形式，应该是将音频文件转为流式以及按时间段分成小段音频（最终识别结果就是按时间段分开的）
2.python调用 import whisper model = whisper.load_model(&#34;base&#34;) result = model.transcribe(&#34;audio.mp3&#34;) print(result[&#34;text&#34;]) 第一次运行的时候，首先需要下载模型文件，base属于比较小尺寸的模型，还有small、large等。
另外如果可能报错，可以尝试重启下开发工具再试，可能就好了（我就遇到这种问题，可能没有重启开发工具，找不到ffmpeg）
3.识别效果评估 我使用了一个11分钟的会议录音文件测试。CPU环境。
使用base模型，用时约2分钟，质量还行
使用small模型，用时约4分钟，质量比base模型的好一些，但是有些反而不如base模型的。
整体上，还行吧。
4.一点封装 由于不同大小的模型识别速度上还是差不少，因此还要结合实际情况选择使用哪个模型，基于这个基础对调用做了一点封装
import whisper from datetime import datetime # 模型根路径 model_root=&#34;E:\Models\whisper&#34; class whisper_utils: # model_name=&#34;base&#34; # model_name=&#34;small&#34; def __init__(self,model_name=&#34;base&#34;): self.model = whisper.load_model(name=model_name,download_root=model_root) def audio_to_txt(self,audio_file: str): now = datetime.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-05-10T12:04:01+08:00">
    <meta property="article:modified_time" content="2024-05-10T12:04:01+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">whisper之初步使用记录</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2>文章目录</h2> 
<p id="%E5%89%8D%E8%A8%80-toc" style="margin-left:0px;"><a href="#%E5%89%8D%E8%A8%80" rel="nofollow">前言</a></p> 
<p id="%E4%B8%80%E3%80%81pandas%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F-toc" style="margin-left:0px;"><a href="#%E4%B8%80%E3%80%81pandas%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F" rel="nofollow">一、whisper是什么？</a></p> 
<p id="%E4%BA%8C%E3%80%81%E4%BD%BF%E7%94%A8%E6%AD%A5%E9%AA%A4-toc" style="margin-left:0px;"><a href="#%E4%BA%8C%E3%80%81%E4%BD%BF%E7%94%A8%E6%AD%A5%E9%AA%A4" rel="nofollow">二、使用步骤</a></p> 
<p id="1.%E5%BC%95%E5%85%A5%E5%BA%93-toc" style="margin-left:40px;"><a href="#1.%E5%BC%95%E5%85%A5%E5%BA%93" rel="nofollow">1.安装</a></p> 
<p id="2.%E8%AF%BB%E5%85%A5%E6%95%B0%E6%8D%AE-toc" style="margin-left:40px;"><a href="#2.%E8%AF%BB%E5%85%A5%E6%95%B0%E6%8D%AE" rel="nofollow">2.python调用</a></p> 
<p id="3.%E8%AF%86%E5%88%AB%E6%95%88%E6%9E%9C%E8%AF%84%E4%BC%B0-toc" style="margin-left:40px;"><a href="#3.%E8%AF%86%E5%88%AB%E6%95%88%E6%9E%9C%E8%AF%84%E4%BC%B0" rel="nofollow">3.识别效果评估</a></p> 
<p id="4.%E4%B8%80%E7%82%B9%E5%B0%81%E8%A3%85-toc" style="margin-left:40px;"><a href="#4.%E4%B8%80%E7%82%B9%E5%B0%81%E8%A3%85" rel="nofollow">4.一点封装</a></p> 
<p id="5.%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5-toc" style="margin-left:40px;"><a href="#5.%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5" rel="nofollow">5.参考链接</a></p> 
<p id="%E6%80%BB%E7%BB%93-toc" style="margin-left:0px;"><a href="#%E6%80%BB%E7%BB%93" rel="nofollow">总结</a></p> 
<hr> 
<h2 id="%E5%89%8D%E8%A8%80"><a id="_12"></a>前言</h2> 
<p>随着AI大模型的不断发展，语音识别等周边内容也再次引发关注，通过语音转文字再与大模型交互，从而实现语音与大模型交互。</p> 
<p>今天我们介绍下语音识别领域的顶级选手whisper。</p> 
<hr> 
<h2 id="%E4%B8%80%E3%80%81pandas%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><strong>一、whisper是什么？</strong></h2> 
<p>whisper是openai开源的语音识别模型，也是使用了Transformer架构。</p> 
<p>openai宣称whisper的语音识别能力已经到了人类的水平。</p> 
<p>接下来我们参考Github结合其他技术博客内容，实操下whisper的使用。</p> 
<h2 id="%E4%BA%8C%E3%80%81%E4%BD%BF%E7%94%A8%E6%AD%A5%E9%AA%A4"><a id="_26"></a>二、使用步骤</h2> 
<h3 id="1.%E5%BC%95%E5%85%A5%E5%BA%93"><a id="1_27"></a>1.安装</h3> 
<p>1）pip安装whisper</p> 
<pre><code class="hljs">pip install -U openai-whisper</code></pre> 
<p>2）安装ffmpeg</p> 
<p>下载地址：<a class="has-card" href="https://github.com/BtbN/FFmpeg-Builds/releases" title="ffmpeg下载地址"><span class="link-card-box"><span class="link-title">ffmpeg下载地址</span><span class="link-link"><img class="link-link-icon" src="https://images2.imgbox.com/ab/d5/vQIlVGSa_o.png" alt="icon-default.png?t=N7T8">https://github.com/BtbN/FFmpeg-Builds/releases</span></span></a></p> 
<p>选择对应操作系统的安装包即可</p> 
<p>Linux系统也可以直接命令方式安装。</p> 
<p>对于Windows系统，下载到本地后解压缩即可，但是需要设置环境变量，路径bin（就是在这个路径下有ffmpeg.exe）</p> 
<p><strong>特意说明：whisper内部其实调用了ffmpeg，使用的就是cmd形式，应该是将音频文件转为流式以及按时间段分成小段音频（最终识别结果就是按时间段分开的）</strong></p> 
<h3 id="2.%E8%AF%BB%E5%85%A5%E6%95%B0%E6%8D%AE"><a id="2_41"></a>2.python调用</h3> 
<pre><code class="language-python">import whisper

model = whisper.load_model("base")
result = model.transcribe("audio.mp3")
print(result["text"])</code></pre> 
<p>第一次运行的时候，首先需要下载模型文件，base属于比较小尺寸的模型，还有small、large等。</p> 
<p>另外如果可能报错，可以尝试重启下开发工具再试，可能就好了（我就遇到这种问题，可能没有重启开发工具，找不到ffmpeg）</p> 
<h3 id="3.%E8%AF%86%E5%88%AB%E6%95%88%E6%9E%9C%E8%AF%84%E4%BC%B0">3.识别效果评估</h3> 
<p>我使用了一个11分钟的会议录音文件测试。CPU环境。</p> 
<p>使用base模型，用时约2分钟，质量还行</p> 
<p>使用small模型，用时约4分钟，质量比base模型的好一些，但是有些反而不如base模型的。</p> 
<p>整体上，还行吧。</p> 
<h3 id="4.%E4%B8%80%E7%82%B9%E5%B0%81%E8%A3%85">4.一点封装</h3> 
<p>由于不同大小的模型识别速度上还是差不少，因此还要结合实际情况选择使用哪个模型，基于这个基础对调用做了一点封装</p> 
<pre><code class="language-python">import whisper
from datetime import datetime

# 模型根路径
model_root="E:\Models\whisper"

class whisper_utils:

    # model_name="base"
    # model_name="small"

    def __init__(self,model_name="base"):
        self.model = whisper.load_model(name=model_name,download_root=model_root)

    def audio_to_txt(self,audio_file: str):

        now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        print(f"{now} 开始识别…")
        result = self.model.transcribe(audio_file)

        now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        print(f"{now} 识别完成")

        return result
</code></pre> 
<p>这里我把模型路径自己设置了下。</p> 
<p>和多数模型文件一样，默认情况下，whisper模型也会下载到C盘Users下当前用户文件夹的.cache下，很容易导致C盘塞满。 </p> 
<h3 id="5.%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5">5.参考链接</h3> 
<p><a class="has-card" href="https://github.com/openai/whisper" title="openai/whisper: Robust Speech Recognition via Large-Scale Weak Supervision (github.com)"><span class="link-card-box"><span class="link-title">openai/whisper: Robust Speech Recognition via Large-Scale Weak Supervision (github.com)</span><span class="link-link"><img class="link-link-icon" src="https://images2.imgbox.com/90/6c/304tP83w_o.png" alt="icon-default.png?t=N7T8">https://github.com/openai/whisper</span></span></a></p> 
<hr> 
<h2 id="%E6%80%BB%E7%BB%93"><a id="_55"></a>总结</h2> 
<p>本篇主要介绍了whisper的安装、调用、识别效果评估以及一点调用封装。希望可以帮助正好有需要的小伙伴。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/a3e9b3819598f5d99ec44855553121fb/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">vue项目中使用websocke即时通讯实现系统公告实时获取并提醒</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/1c479c8473ed2a2bb7b7999a81932f7c/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">华为路由器配置WEB及Telnet登录</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>