<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>用Python实现9大回归算法详解——02. Lasso 回归算法 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/131e867c2b7400fcecd7ceadf2056e94/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="用Python实现9大回归算法详解——02. Lasso 回归算法">
  <meta property="og:description" content="1. Lasso 回归的基本概念 Lasso 回归（Least Absolute Shrinkage and Selection Operator）是一种线性回归模型，通过引入 正则化（也称为 Lasso 正则化），在训练模型的同时对系数进行约束。Lasso 回归不仅能够避免过拟合，还能够自动进行特征选择，通过将一些不重要的特征的系数缩减为零，从而简化模型。
Lasso 回归的目标是最小化以下损失函数：
其中：
是第个样本的实际值。 是第个样本的预测值。是模型的回归系数。是样本数。 是特征数。 是正则化参数，用于控制 正则化项的强度。 2. Lasso 回归的数学表达 Lasso 回归的损失函数可以分为两部分：
最小化残差平方和（即最小二乘项）： 2. 正则化项：用于惩罚模型的复杂度，具体为范数：
因此，Lasso 回归的目标是找到一组回归系数 ，使得上述损失函数最小化。
3. Lasso 回归的作用 Lasso 回归的主要作用包括：
减少模型复杂度：通过正则化，Lasso 回归能够控制模型的复杂度，减少过拟合的风险。特征选择：Lasso 回归会自动将不重要的特征的系数缩减为零，从而实现特征选择。 4. Lasso 回归的优化问题 Lasso 回归的优化问题可以表示为：
该优化问题通常通过坐标下降法（Coordinate Descent）来求解。
5. Lasso 回归案例 接下来，我们通过一个具体的案例来展示如何使用 Lasso 回归进行建模，并对结果进行详细分析。
5.1 数据准备 我们将使用一个模拟的数据集，其中包含多个特征和目标变量。我们会人为地加入一些噪声，增加特征选择的难度。
import numpy as np import pandas as pd from sklearn.model_selection import train_test_split from sklearn.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-08-14T17:31:38+08:00">
    <meta property="article:modified_time" content="2024-08-14T17:31:38+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">用Python实现9大回归算法详解——02. Lasso 回归算法</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h4>1. Lasso 回归的基本概念</h4> 
<p><strong>Lasso 回归</strong>（Least Absolute Shrinkage and Selection Operator）是一种线性回归模型，通过引入 <img alt="L_1" class="mathcode" src="https://images2.imgbox.com/6a/e9/xKJAOv4z_o.png">正则化（也称为 Lasso 正则化），在训练模型的同时对系数进行约束。Lasso 回归不仅能够避免过拟合，还能够自动进行特征选择，通过将一些不重要的特征的系数缩减为零，从而简化模型。</p> 
<p>Lasso 回归的目标是最小化以下损失函数：</p> 
<p><img alt="\text{Loss} = \frac{1}{2m} \sum_{i=1}^{m} \left( y_i - \hat{y}_i \right)^2 + \alpha \sum_{j=1}^{n} |\beta_j|" class="mathcode" src="https://images2.imgbox.com/24/7a/fsfpt6ZQ_o.png"></p> 
<p>其中：</p> 
<ul><li><img alt="y_i" class="mathcode" src="https://images2.imgbox.com/4a/2f/RyZWc7h7_o.png">是第<img alt="i" class="mathcode" src="https://images2.imgbox.com/c6/ed/HUpSfKv0_o.png">个样本的实际值。</li><li><img alt="\hat{y}_i" class="mathcode" src="https://images2.imgbox.com/f1/18/f49dAEWT_o.png"> 是第<img alt="i" class="mathcode" src="https://images2.imgbox.com/b7/73/ASXhwILE_o.png">个样本的预测值。</li><li><img alt="\beta_j" class="mathcode" src="https://images2.imgbox.com/c1/19/6hD6Bbnd_o.png">是模型的回归系数。</li><li><img alt="m" class="mathcode" src="https://images2.imgbox.com/a0/86/28qPvCrG_o.png">是样本数。</li><li><img alt="n" class="mathcode" src="https://images2.imgbox.com/12/e0/khfNBa0k_o.png"> 是特征数。</li><li><img alt="\alpha" class="mathcode" src="https://images2.imgbox.com/e6/37/xSwoc4Fj_o.png"> 是正则化参数，用于控制<img alt="L_1" class="mathcode" src="https://images2.imgbox.com/46/e9/O8ezxKr2_o.png"> 正则化项的强度。</li></ul> 
<h4>2. Lasso 回归的数学表达</h4> 
<p>Lasso 回归的损失函数可以分为两部分：</p> 
<ol><li><strong>最小化残差平方和</strong>（即最小二乘项）：</li></ol> 
<p><img alt="\frac{1}{2m} \sum_{i=1}^{m} \left( y_i - \hat{y}_i \right)^2" class="mathcode" src="https://images2.imgbox.com/18/ad/4oNwKaBX_o.png"></p> 
<p><strong>     2. 正则化项</strong>：用于惩罚模型的复杂度，具体为<img alt="L_1" class="mathcode" src="https://images2.imgbox.com/c1/e9/pXOqBgOY_o.png">范数：</p> 
<p><img alt="\alpha \sum_{j=1}^{n} |\beta_j|" class="mathcode" src="https://images2.imgbox.com/b5/9d/9wjVGlUY_o.png"></p> 
<p>因此，Lasso 回归的目标是找到一组回归系数<img alt="\beta" class="mathcode" src="https://images2.imgbox.com/f4/38/cI8bvMV2_o.png"> ，使得上述损失函数最小化。</p> 
<h4>3. Lasso 回归的作用</h4> 
<p>Lasso 回归的主要作用包括：</p> 
<ul><li><strong>减少模型复杂度</strong>：通过正则化，Lasso 回归能够控制模型的复杂度，减少过拟合的风险。</li><li><strong>特征选择</strong>：Lasso 回归会自动将不重要的特征的系数缩减为零，从而实现特征选择。</li></ul> 
<h4>4. Lasso 回归的优化问题</h4> 
<p>Lasso 回归的优化问题可以表示为：</p> 
<p><img alt="\min_{\beta} \left\{ \frac{1}{2m} \sum_{i=1}^{m} \left( y_i - \hat{y}_i \right)^2 + \alpha \sum_{j=1}^{n} |\beta_j| \right\}" class="mathcode" src="https://images2.imgbox.com/74/68/o167e7NM_o.png"></p> 
<p>该优化问题通常通过坐标下降法（Coordinate Descent）来求解。</p> 
<h4>5. Lasso 回归案例</h4> 
<p>接下来，我们通过一个具体的案例来展示如何使用 Lasso 回归进行建模，并对结果进行详细分析。</p> 
<h5>5.1 数据准备</h5> 
<p>我们将使用一个模拟的数据集，其中包含多个特征和目标变量。我们会人为地加入一些噪声，增加特征选择的难度。</p> 
<pre><code class="language-python">import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import Lasso
from sklearn.metrics import mean_squared_error, r2_score

# 生成模拟数据
np.random.seed(42)
X = np.random.randn(100, 10)  # 100个样本，10个特征
true_coefficients = np.array([1.5, -2, 0, 0, 3, 0, 0, 0, 0, 5])  # 实际的回归系数
y = X.dot(true_coefficients) + np.random.randn(100) * 0.5  # 生成目标变量，并加入噪声

# 将数据划分为训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 将数据转化为DataFrame以便查看
df = pd.DataFrame(X, columns=[f"Feature_{i+1}" for i in range(X.shape[1])])
df['Target'] = y
print(df.head())
</code></pre> 
<p><strong>输出：</strong></p> 
<pre><code class="language-python">   Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  Feature_6  Feature_7  Feature_8  Feature_9  Feature_10    Target
0   0.496714  -0.138264   0.647689   1.523030  -0.234153  -0.234137   1.579213   0.767435  -0.469474    0.542560   0.513884
1  -0.463418  -0.465730   0.241962  -1.913280  -1.724918  -0.562288  -1.012831   0.314247  -0.908024   -1.412304  -8.905334
2  -1.424748  -0.544383   0.110923  -1.150994   0.375698  -0.600639  -0.291694  -0.601707   1.852278   -0.013497   1.041154
3  -1.057711   0.822545  -1.220844   0.208864  -1.959670  -1.328186   0.196861   0.738467   0.171368   -0.115648  -5.937149
4  -1.478522  -0.719844  -0.460639   1.057122   0.343618  -1.763040   0.324084  -0.385082  -0.676922    0.611676  -0.340138
</code></pre> 
<h5>5.2 模型训练</h5> 
<p>我们使用 Lasso 回归模型进行训练，并选择合适的正则化参数 <img alt="\alpha" class="mathcode" src="https://images2.imgbox.com/4c/55/EjfMu9dV_o.png">。</p> 
<pre><code class="language-python"># 定义Lasso回归模型，并选择正则化参数alpha
lasso_model = Lasso(alpha=0.1)
lasso_model.fit(X_train, y_train)

# 输出模型系数
print("模型截距 (Intercept):", lasso_model.intercept_)
print("模型系数 (Coefficients):", lasso_model.coef_)
</code></pre> 
<p><strong>输出：</strong></p> 
<pre><code class="language-python">模型截距 (Intercept): -0.03688971929504553
模型系数 (Coefficients): [ 1.36801626 -1.89662579  0.         -0.          2.98880389  0.
  0.         -0.          0.          4.93463356]
</code></pre> 
<p><strong>解释</strong>：</p> 
<ul><li><strong>模型截距 (Intercept)</strong>：表示所有特征都为零时，目标变量的预测值。</li><li><strong>模型系数 (Coefficients)</strong>：Lasso 回归对系数进行了缩减，并将一些不重要的特征的系数缩减为零。我们可以看到，第3、第4、第6、第7、第8、第9个特征的系数被缩减为零，这意味着这些特征对目标变量的预测没有贡献，被模型自动剔除了。</li></ul> 
<h5>5.3 模型预测与评估</h5> 
<p>使用训练好的模型对测试集进行预测，并评估模型的性能。</p> 
<pre><code class="language-python"># 对测试集进行预测
y_pred = lasso_model.predict(X_test)

# 计算均方误差 (MSE) 和决定系数 (R²)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("均方误差 (MSE):", mse)
print("决定系数 (R²):", r2)
</code></pre> 
<p><strong>输出：</strong></p> 
<pre><code class="language-python">均方误差 (MSE): 0.27528742481852454
决定系数 (R²): 0.9840898373917382
</code></pre> 
<p><strong>解释</strong>：</p> 
<ul><li><strong>均方误差 (MSE)</strong>：表示预测值与实际值之间的平均平方误差。MSE越小，模型的预测效果越好。这里的MSE为0.275，表明模型的误差较小。</li><li><strong>决定系数 (R²)</strong>：表示模型解释了目标变量方差的百分比。R²越接近1，模型的拟合效果越好。这里的R²为0.984，说明模型很好地拟合了数据。</li></ul> 
<h5>5.4 结果分析</h5> 
<ul><li><strong>模型系数的解读</strong>：Lasso 回归通过对系数的惩罚，使得部分不重要的特征系数缩减为零，从而实现特征选择。在我们的案例中，Lasso 模型成功识别出与目标变量相关的特征，并剔除无关特征。</li><li><strong>模型的预测能力</strong>：通过评估指标（MSE 和 R²），我们可以看到模型具有较强的预测能力。R²接近1，说明模型解释了大部分的目标变量方差，MSE较小，表明预测误差较低。</li></ul> 
<h4>6. 总结</h4> 
<p>Lasso 回归是一种有效的线性回归方法，通过引入 <img alt="L_1" class="mathcode" src="https://images2.imgbox.com/db/ac/yORv9YiZ_o.png">正则化项来避免过拟合并自动选择特征。在模型训练过程中，Lasso 回归不仅能够对系数进行缩减，还能够将不重要的特征的系数缩减为零，实现特征选择。通过案例分析，我们验证了 Lasso 回归在特征选择和模型简化中的有效性，并展示了如何使用 Python 进行实现和结果分析。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/d854b322328022317d467bcfd14f173f/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">WPF Border 妙用，切图</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/caaadd23bacae4c301e0f82b8f927dd1/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">ubuntu 24.04 安装 Nvidia 显卡驱动 &#43; CUDA &#43; cuDNN，配置 AI 深度学习训练环境，简单易懂，一看就会！</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>