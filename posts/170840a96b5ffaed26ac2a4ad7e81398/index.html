<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>使用kafka-clients依赖 集成kafka - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/170840a96b5ffaed26ac2a4ad7e81398/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="使用kafka-clients依赖 集成kafka">
  <meta property="og:description" content="1.导入依赖配置 pom文件 XML
&lt;!--公司是对apache的进一步封装--&gt;
&lt;dependency&gt;
&lt;groupId&gt;com.ky.common&lt;/groupId&gt;
&lt;artifactId&gt;ky-common-kafka&lt;/artifactId&gt;
&lt;version&gt;1.8-SNAPSHOT&lt;/version&gt;
&lt;/dependency&gt;
&lt;!--调用的实质是--&gt;
&lt;dependency&gt;
&lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;
&lt;artifactId&gt;kafka-clients&lt;/artifactId&gt;
&lt;version&gt;2.8.0&lt;/version&gt;
&lt;/dependency&gt;
&lt;!--但一般spring集成kafka使用如下方案--&gt;
&lt;dependency&gt;
&lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt;
&lt;artifactId&gt;spring-kafka&lt;/artifactId&gt;
&lt;/dependency&gt;
yaml文件 在项目的yaml中增加相关依赖信息，如公司业务项目中的
YAML
kafka:
bootstrap:
servers: 172.16.39.227:9092
#阿里云kafka集群
ali_bootstrap:
servers: 172.17.0.34:9092
configuration类 简单情境下，直接使用kafka进行测试可以在producer和customer类中写，为求模块化，这里才开使用，合并以及拆开都不影响使用。
kafkaProducer类 Java
public abstract class AbstractKafkaProducer{
// 需要bean类实现的
public abstract KafkaProducerConfig getConfig();
// 内部提供的函数
public void send(String topic,String key,String vlaue){
this.getProducer().send(new ProducerRecord(topic,key,value);
}
// 内部1： 在bean注入后第一时间执行
@PostConstruct
public Producer&lt;String, String&gt; initProducer() {
if (this.producer != null) {">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-04-24T10:56:13+08:00">
    <meta property="article:modified_time" content="2024-04-24T10:56:13+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">使用kafka-clients依赖 集成kafka</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2 style="margin-left:.0001pt;text-align:justify;"><strong>1.导入依赖配置</strong></h2> 
<h3 style="margin-left:.0001pt;text-align:left;"><strong>pom文件</strong></h3> 
<table border="1" cellspacing="0" style="margin-left:-.6pt;"><tbody><tr><td style="background-color:#f5f6f7;width:414pt;"> <p style="margin-left:.0001pt;text-align:left;"><span style="color:#646a73;">XML</span><br> &lt;!--公司是对apache的进一步封装--&gt;<br> &lt;dependency&gt;<br>    &lt;groupId&gt;com.ky.common&lt;/groupId&gt;<br>    &lt;artifactId&gt;ky-common-kafka&lt;/artifactId&gt;<br>    &lt;version&gt;1.8-SNAPSHOT&lt;/version&gt;<br> &lt;/dependency&gt;<br><br> &lt;!--调用的实质是--&gt;<br> &lt;dependency&gt;<br>     &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;<br>     &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt;<br>     &lt;version&gt;2.8.0&lt;/version&gt;<br> &lt;/dependency&gt;<br><br> &lt;!--但一般spring集成kafka使用如下方案--&gt;<br> &lt;dependency&gt;<br>       &lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt;<br>       &lt;artifactId&gt;spring-kafka&lt;/artifactId&gt;<br> &lt;/dependency&gt;</p> </td></tr></tbody></table> 
<h3 style="margin-left:.0001pt;text-align:left;"><strong>yaml文件</strong></h3> 
<p style="margin-left:.0001pt;text-align:left;">在项目的yaml中增加相关依赖信息，如公司业务项目中的</p> 
<table border="1" cellspacing="0" style="margin-left:-.6pt;"><tbody><tr><td style="background-color:#f5f6f7;width:414pt;"> <p style="margin-left:.0001pt;text-align:left;"><span style="color:#646a73;">YAML</span><br> kafka:<br>   bootstrap:<br>     servers: <s><s><span style="background-color:#0d0016;">172.16.39.227</span>:9092</s></s><br>   <em>#阿里云kafka集群</em><br><em>  </em>ali_bootstrap:<br>     servers: <s><s><span style="background-color:#0d0016;">172.17.0.34</span>:9092</s></s></p> </td></tr></tbody></table> 
<h3 style="margin-left:.0001pt;text-align:left;"><strong>configuration类</strong></h3> 
<p style="margin-left:.0001pt;text-align:left;">简单情境下，直接使用kafka进行测试可以在producer和customer类中写，为求模块化，这里才开使用，合并以及拆开都不影响使用。</p> 
<ul><li style="text-align:left;"> <h4>kafkaProducer类</h4> </li></ul> 
<table border="1" cellspacing="0" style="margin-left:-.6pt;"><tbody><tr><td style="background-color:#f5f6f7;width:414pt;"> <p style="margin-left:.0001pt;text-align:left;"><span style="color:#646a73;">Java</span><br> public abstract class AbstractKafkaProducer{<!-- --><br>     // 需要bean类实现的<br>     public abstract  <u><u>KafkaProducerConfig</u></u> getConfig();<br>     <br>     // 内部提供的函数<br>     public void send(String topic,String key,String vlaue){<!-- --><br>         this.getProducer().send(new ProducerRecord(topic,key,value);<br>     }<br>     // 内部1： 在bean注入后第一时间执行<br>     <em>@PostConstruct</em><br>     <em>public </em>Producer&lt;String, String&gt; initProducer() {<!-- --><br>         <em>if </em>(<em>this</em>.producer != <em>null</em>) {<!-- --><br>             <em>return this</em>.producer;<br>         } <em>else </em>{<!-- --><br>             KafkaProducerConfig kafkaConfig = <em>this</em>.getKafkaConfig();<br>             <em>if </em>(kafkaConfig != <em>null </em>&amp;&amp; StringUtils.equalsAnyIgnoreCase(kafkaConfig.getEnable(), <em>new </em>CharSequence[]{"true", "open"})) {<!-- --><br>                 <em>this</em>.logger.info("abstract kafka producer,init producer,properties:{}", JSON.toJSONString(kafkaConfig));<br>                 Properties properties = <em>new </em>Properties();<br>                 String clientId = kafkaConfig.getProjectName() + "_producer_" + InetAddressUtils.getHostAddress();<br>                 properties.setProperty("client.id", clientId);<br>                 properties.put("bootstrap.servers", kafkaConfig.getBootstrapServers());<br>                 properties.put("acks", "all");<br>                 properties.put("retries", 1);<br>                 properties.put("batch.size", 16384);<br>                 properties.put("linger.ms", 50);<br>                 properties.put("buffer.memory", 33554432);<br>                 properties.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");<br>                 properties.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");<br>                 <em>this</em>.producer = <em>new </em>KafkaProducer(properties);<br>                 <em>return this</em>.producer;<br>             } <em>else </em>{<!-- --><br>                 <em>this</em>.logger.error("abstract kafka producer,init producer fail,kafka config is null,properties:{}", JSON.toJSONString(kafkaConfig));<br>                 <em>return null</em>;<br>             }<br>         }<br>     }<br>     // 内部2： 在bean销毁前执行<br>     <em>@PreDestroy</em><br>     <em>public void </em>close() {<!-- --><br>         <em>if </em>(<em>this</em>.producer != <em>null</em>) {<!-- --><br>             <em>try </em>{<!-- --><br>                 <em>this</em>.producer.close();<br>             } <em>catch </em>(Exception var2) {<!-- --><br>                 <em>this</em>.logger.error("abstract kafka producer,producer close fail,error                             message:{}", var2.getMessage(), var2);<br>             }<br>         }<br>     }    <br> }</p> </td></tr></tbody></table> 
<ul><li style="text-align:left;"> <h4>kafkaCostomer类</h4> </li></ul> 
<table border="1" cellspacing="0" style="margin-left:-.6pt;"><tbody><tr><td style="background-color:#f5f6f7;width:414pt;"> <p style="margin-left:.0001pt;text-align:left;"><span style="color:#646a73;">Java</span><br> public abstract class ByteArrayAbstractKafkaConsumer{<!-- --><br>     private String clientNumber;<br>     <br>     // 需要bean类实现的<br>     public abstract  <u><u>KafkaConsumerConfig</u></u> getConfig();<br>     <em>public abstract </em>String topic();<br>     public abstract void handler(CustomerRecords&lt;String, byte[]&gt; var1);<br>     <br>     // 内部提供的<br>     public String clientId(String clientNumber)// 标示clientID，根据业务设置<br>     public void handler(){this.handler("01")} // 提供外部接口的使用<br>     public handler(String clientNumber){ // 配置以及实行相关<br>         KafkaConsumerConfig kafkaConfig = <em>this</em>.getKafkaConfig();<br>         <em>if </em>(kafkaConfig == <em>null</em>) {<!-- --><br>             <em>this</em>.logger.error("abstract kafka consumer,consumer fail,kafka config is null");<br>         } <em>else </em>{<!-- --><br>             // 配置读取的相关信息<br>            <em>this</em>.clientNumber = clientNumber;<br>             Duration timeout = Duration.ofMillis(kafkaConfig.getPollTimeout() &lt;= 0 ? 500L : (<em>long</em>)kafkaConfig.getPollTimeout());<br>             String topic = <em>this</em>.topic();<br>             Properties properties = <em>new </em>Properties();<br>             properties.put("bootstrap.servers", kafkaConfig.getBootstrapServers());<br>             properties.put("group.id", kafkaConfig.getGroupId());<br>             properties.put("key.deserializer", StringUtils.defaultString(kafkaConfig.getKeyDeserializer(), "org.apache.kafka.common.serialization.StringDeserializer"));<br>             properties.put("value.deserializer", "org.apache.kafka.common.serialization.ByteArrayDeserializer");<br>             properties.put("enable.auto.commit", "true");<br>             properties.put("auto.commit.interval.ms", "1000");<br>             properties.put("auto.offset.reset", "latest");<br>             properties.put("session.timeout.ms", "30000");<br>             properties.put("max.poll.interval.ms", "300000");<br>             <em>if </em>(StringUtils.isNotBlank(kafkaConfig.getPartitionAssignmentStrategy())) {<!-- --><br>                 properties.put("partition.assignment.strategy", kafkaConfig.getPartitionAssignmentStrategy());<br>             }<br><br>             String clientId = <em>this</em>.clientId(clientNumber);<br>             properties.setProperty("client.id", clientId);<br>             List&lt;String&gt; subTopic = Arrays.asList(topic);<br>             Thread thread = <em>new </em>Thread(() -&gt; {<!-- --><br>                 <em>this</em>.consumer(properties, subTopic, timeout, 0); // 实际的执行<br>             });<br>             thread.setName("kafka-consumer-thread-" + clientNumber + "_" + topic);<br>             thread.start();<br>        }<br>     }<br>     private void consumer(Properties properties, Liat&lt;String&gt; subTopic, Duration time, int retryCount){<!-- --><br>         MDC.put("code", "0");<br>         <em>try </em>{<!-- --><br>             KafkaConsumer&lt;String, <em>byte</em>[]&gt; consumer = <em>new </em>KafkaConsumer(properties);<br>             Throwable var6 = <em>null</em>;<br><br>             <em>try </em>{<!-- --><br>                 consumer.subscribe(subTopic);<br>                 <em>this</em>.logger.info("abstract kafka consumer,consumer start,clientId:{},kafka config:{}", <em>this</em>.clientId(<em>this</em>.clientNumber), JSON.toJSONString(<em>this</em>.getKafkaConfig()));<br>                 <em>while</em>(<em>true</em>) {<!-- --><br>                     <em>while</em>(<em>true</em>) {<!-- --><br>                         <em>try </em>{<!-- --><br>                             ConsumerRecords&lt;String, <em>byte</em>[]&gt; records = consumer.poll(timeout);<br>                             <em>if </em>(records != <em>null </em>&amp;&amp; records.count() != 0) {<!-- --><br>                                 <em>this</em>.handler(records);<br>                             }<br>                         } <em>catch </em>(Throwable var16) {<!-- --><br>                             AlarmLogger.error("abstract kafka consumer,consumer fail,topic:{},error message:{}", <em>new </em>Object[]{JSON.toJSONString(subTopic), var16.getMessage(), var16});<br>                         }<br>                     }<br>                 }<br>             } <em>catch </em>(Throwable var17) {<!-- --><br>                 var6 = var17;<br>                 <em>throw </em>var17;<br>             } <em>finally </em>{<!-- --><br>                 <em>if </em>(consumer != <em>null</em>) {<!-- --><br>                     <em>if </em>(var6 != <em>null</em>) {<!-- --><br>                         <em>try </em>{<!-- --><br>                             consumer.close();<br>                         } <em>catch </em>(Throwable var15) {<!-- --><br>                             var6.addSuppressed(var15);<br>                         }<br>                     } <em>else </em>{<!-- --><br>                         consumer.close();<br>                     }<br>                 }<br>             }<br>         } <em>catch </em>(Throwable var19) {<!-- --><br>             <em>if </em>(retryCount &gt;= 10) {<!-- --><br>                 AlarmLogger.error("system error,abstract kafka consumer,consumer fail,retry count is too long,shutdown current kafka consumer,properties:{},topic:{},retryCount:{},error message:{}", <em>new </em>Object[]{JSON.toJSONString(properties), JSON.toJSONString(subTopic), retryCount, var19.getMessage(), var19});<br>             } <em>else </em>{<!-- --><br>                 AlarmLogger.error("abstract kafka consumer,consumer fail,topic:{},retryCount:{},error message:{}", <em>new </em>Object[]{JSON.toJSONString(subTopic), retryCount, var19.getMessage(), var19});<br>                 ++retryCount;<br>                 <em>this</em>.consumer(properties, subTopic, timeout, retryCount);<br>             }<br>         }<br>     }    <br> }</p> </td></tr></tbody></table> 
<h2 style="margin-left:.0001pt;text-align:left;"><strong>2.业务操作</strong></h2> 
<p style="margin-left:.0001pt;text-align:left;">在producer中，先创建类实现抽象类的方法，便于后续装配</p> 
<table border="1" cellspacing="0" style="margin-left:-.6pt;"><tbody><tr><td style="background-color:#f5f6f7;width:414pt;"> <p style="margin-left:.0001pt;text-align:left;"><span style="color:#646a73;">Java</span><br> @Component<br> public class KafkaProducer extends AbstractKafkaProducer{<!-- --><br>     <em>@Value</em>("${kafka.bootstrap.servers}")<br>     <em>private </em>String bootstrapServers;<br><br>     <em>@Override</em><br><em>    public </em>KafkaProducerConfig getKafkaConfig() {<!-- --><br>         KafkaProducerConfig kafkaProducerConfig = <em>new </em>KafkaProducerConfig();<br>         kafkaProducerConfig.setBootstrapServers(bootstrapServers);<br>         kafkaProducerConfig.setProjectName("ky-recommend-backend");<br>         <em>return </em>kafkaProducerConfig;<br>     }<br> }</p> </td></tr></tbody></table> 
<p style="margin-left:.0001pt;text-align:left;">同理 consumer类中</p> 
<table border="1" cellspacing="0" style="margin-left:-.6pt;"><tbody><tr><td style="background-color:#f5f6f7;width:414pt;"> <p style="margin-left:.0001pt;text-align:left;"><span style="color:#646a73;">Java</span><br><br><em>@Component</em><br><em>public class </em>JsonMusicSunoConsumer <em>extends </em>AbstractJsonKafkaConsumer{<!-- --><br>     Logger logger = LoggerFactory.getLogger(JsonMusicSunoConsumer.<em>class</em>);<br><br>     <em>@Resource</em><br><em>    private </em>MusicLoadCsvService musicLoadCsvService;<br><br>     <em>public </em>JsonMusicSunoConsumer(<em>@Qualifier</em>("bigDataKafkaJson") KafkaConsumerConfig kafkaConsumerConfig) {<!-- --><br>         <em>super</em>(kafkaConsumerConfig);<br>     }<br><br>     <em>@Override</em><br><em>    public </em>String topic() {<!-- --><br>         <em>return </em>KafkaTopic.MUSIC_SUNO_CONTINUE.getTopic();<br>     }<br><br>     <em>@Override</em><br><em>    public </em>KafkaConsumerConfig getKafkaConfig() {<!-- --><br>         <em>return super</em>.getKafkaConsumerConfig();<br>     }<br><br>     <em>@Override</em><br><em>    public void </em>handler(ConsumerRecords&lt;String, <em>byte</em>[]&gt; consumerRecords) {<!-- --><br>         <em>for </em>(ConsumerRecord&lt;String, <em>byte</em>[]&gt; record : consumerRecords) {<!-- --><br>             String consumerRecord = <em>new </em>String(record.value());<br>             <em>try </em>{<!-- --><br>                 MusicSunoKafka musicSunoKafka = JSON.parseObject(consumerRecord, MusicSunoKafka.<em>class</em>);<br>                 <em>if </em>(musicSunoKafka == <em>null</em>) {<!-- --><br>                     logger.warn("JsonMusicSunoConsumer#handler, parse json failed, record: {}", consumerRecord);<br>                     <em>continue</em>;<br>                 }<br>                 <em>if </em>(!musicSunoKafka.isValid()) {<!-- --><br>                     <em>continue</em>;<br>                 }<br>                 <span style="background-color:#fbbfbc;">musicLoadCsvService.submitForKafkaWork(musicSunoKafka);</span><br>             } <em>catch </em>(Exception e) {<!-- --><br>                 logger.error("JsonMusicSunoConsumer#handler, handler record err, record: {}, errMsg: {}",<br>                         consumerRecord, e.getMessage(), e);<br>             }<br>         }<br>     }<br> }</p> </td></tr></tbody></table> 
<p style="margin-left:.0001pt;text-align:left;">标红地方属于自己的业务逻辑。</p> 
<table border="1" cellspacing="0" style="margin-left:-.6pt;"><tbody><tr><td style="background-color:#f5f6f7;width:414pt;"> <p style="margin-left:.0001pt;text-align:left;"><span style="color:#646a73;">Java</span><br> //。。。。 <span style="background-color:#fbbfbc;">submitForKafkaWork(musicSunoKafka) </span>的业务续写</p> </td></tr></tbody></table> 
<p style="margin-left:.0001pt;text-align:left;">启动调用</p> 
<p style="margin-left:.0001pt;text-align:left;">在启动类application中，必须先 注册消费类，让消费类运行</p> 
<table border="1" cellspacing="0" style="margin-left:-.6pt;"><tbody><tr><td style="background-color:#f5f6f7;width:414pt;"> <p style="margin-left:.0001pt;text-align:left;"><span style="color:#646a73;">Java</span><br><em>@Override</em><br><em>public void </em>run(String... args) {<!-- --><br>     <em><span style="background-color:#fff67a;">// 注册consumer消费者</span></em><br><em>    </em><span style="background-color:#fff67a;">musicSunoConsumer.handler(); </span><br><br>     logger.info(" ky recommend backend application,env:{},user.home:{},current timezone:{}", env, System.getProperty("user.home"), System.getProperty("user.timezone"));<br> }</p> </td></tr></tbody></table> 
<p style="margin-left:.0001pt;text-align:left;">最终可以简单写一个test的测试向kafka传递数据，就可以查看数据，并也可以设置断点，查看步骤，like this。</p> 
<table border="1" cellspacing="0" style="margin-left:-.6pt;"><tbody><tr><td style="background-color:#f5f6f7;width:414pt;"> <p style="margin-left:.0001pt;text-align:left;"><span style="color:#646a73;">Java</span><br>  <em>@Resource</em><br><em>    private </em>KafkaProducer kafkaProducer;<br>     <em>@PostMapping</em>("/test")<br>     <em>@ResponseBody</em><br><em>    public </em>Result&lt;Object&gt; ProcessKafka(HttpServletRequest request){<!-- --><br>         Environment env = getEnvironment(request);<br>         String value = "  {\"id\":1,\"prompt\":\"Apeacefulmorninginthecountryside\",\"desc\":\"Inspiredbythetranquilityofrurallife,withchirpingbirdsandrustlingleaves.\",\"diy_lrc\":\"Verse1:\\nWakinguptothegentlebreeze,\\nFieldsofgreenasfarastheeyecansee.\\nChirpingbirdssingtheirsweetmelodies,\\nInthispeacefulmorning,Ifeelfree.\\n\\nChorus:\\nOh,whatabeautifulday,\\nInthecountrysidewhereI'llstay.\\nWitheverybreath,Ifindmyway,\\nToalifeofpeaceandserenity.\\n\\n...\",\"diy_music_name\":\"MorningSerenity\"," +<br>                 "\"assign_uid\":123456,\"source_url\":\"https://example.com/countryside.mp3\",\"status\":0,\"reason\":\"\",\"music_id\":0,\"create_time\":1648486800,\"update_time\":1648519200}";<br>         kafkaProducer.send("music_suno_continue",value);<br><em>//        MusicSunoKafka musicSunoKafka = JSON.parseObject(value, MusicSunoKafka.class);</em><br><em>//        musicLoadCsvService.submitForKafkaWork(musicSunoKafka);</em><br><em>        </em>logger.info("CsvLoadController#ProcessKafka, process kafka and storage success, request: {}, env: {}", request, env);<br>         <em>return </em>build(ErrorCode.OK);<br>     }</p> </td></tr></tbody></table> 
<p style="margin-left:.0001pt;text-align:left;">ok，</p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<h2 style="margin-left:.0001pt;text-align:left;"><strong>相关问题</strong></h2> 
<p style="margin-left:.0001pt;text-align:left;">原先的公司包中有这些文件abstractProducer，ByteArrayAbstractKafkaConsumer，</p> 
<table border="1" cellspacing="0" style="margin-left:-.6pt;"><tbody><tr><td style="background-color:#f5f6f7;width:414pt;"> <p style="margin-left:.0001pt;text-align:left;"><span style="color:#646a73;">Markdown</span><br> # producerConfig<br> 包含 bootstrapServers，projectName，enable<br> 简单的一个实体类<br> # KafkaConsumerConfig<br> 包含partitionAssignmentStrategy，clientId，keyDeserializer等<br><br> # AbstractKafkaProducer<br> getconfig，主要功能：send的函数，内部就是以及getProducer和initProducer和关闭<br> （为什么必须是自动移交（enale为true））？-- 可以刷新偏移量。<br> # ByteArrayAbstractKafkaConsumer<br> topics，getconfig，handler的抽象，提供生成1调用consumer2调用handler（records）<br> （为什么没有关闭）-- 因为是一直获取读取的信息 可以不关闭，如果只获得特定信息，可以选择关闭<br> # StringAbstractKafkaConsumer<br> 和byte只是获取的区别，并有一个拼接string的函数</p> </td></tr></tbody></table> 
<p style="margin-left:.0001pt;text-align:left;">我看网上都是使用的spring-kafka来整合整个项目，但是该项目使用的是<span style="background-color:#eff0f1;">kafka-clients</span>依赖。</p> 
<p style="margin-left:.0001pt;text-align:left;"></p> 
<p style="margin-left:.0001pt;text-align:left;"></p> 
<p style="margin-left:.0001pt;text-align:left;"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/98b901bcc3cb8ef6da87a1d990b80204/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【AIGC调研系列】Phi-3 VS Llama3</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/94a3f75bf8865ff1bab1ce76d2470afb/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">javax.net.ssl.SSLException: closing inbound before receiving peer‘s close_notify 错误解决，同时支持开启SSL认证</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>