<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Python 机器学习求解 PDE 学习项目 基础知识（2）TensorFlow 优化器使用 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/3b8c5fe61a9010331a197575aaf3670e/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="Python 机器学习求解 PDE 学习项目 基础知识（2）TensorFlow 优化器使用">
  <meta property="og:description" content="TensorFlow 优化器以及会话使用指南 在我的系列专栏：深度学习求解PDE 的多数文章中将用到TensoFlow 优化器及其计算图学习框架，那么本篇文章就 将解释 如何在 TensorFlow 中使用 Adam 和 L-BFGS-B 优化器进行优化，并介绍了 TensorFlow 会话的框架。
优化器简介 Adam 优化器 Adam 优化器是深度学习中常用的一种优化算法，结合了动量法和 RMSProp 的优点。
案例：使用tf.train.AdamOptimizer 优化线性模型
假设我们有一个简单的线性模型 y=wx&#43;b，其中 w 是权重，b 是偏置，我们希望通过训练来找到最优的 w 和 b，使得模型能够较好地拟合一组给定的数据点。读者可以从这个简单的案例学会此优化器使用方法.
#test1 # 步骤 1: 导入必要的库 import tensorflow as tf import numpy as np # 步骤 2: 创建数据 #为了简单起见，我们手动创建一些线性数据并添加一些噪声。 # 生成数据 np.random.seed(0) x_data = np.linspace(-1, 1, 100)[:, np.newaxis] # 100个数据点，形状为[100, 1] noise = np.random.randn(*x_data.shape) * 0.1 # 添加噪声 y_data = 2 * x_data &#43; 1 &#43; noise # 真实模型为 y = 2x &#43; 1 #步骤 3: 定义模型 # TensorFlow 1.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-07-23T21:58:15+08:00">
    <meta property="article:modified_time" content="2024-07-23T21:58:15+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Python 机器学习求解 PDE 学习项目 基础知识（2）TensorFlow 优化器使用</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="TensorFlow__0"></a>TensorFlow 优化器以及会话使用指南</h2> 
<p>在我的系列专栏：<strong>深度学习求解PDE</strong> 的多数文章中将用到TensoFlow 优化器及其计算图学习框架，那么本篇文章就 将解释 如何在 TensorFlow 中使用 Adam 和 L-BFGS-B 优化器进行优化，并介绍了 TensorFlow 会话的框架。</p> 
<h3><a id="_3"></a>优化器简介</h3> 
<p><img src="https://images2.imgbox.com/76/6e/VeXHPNf7_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="Adam__6"></a>Adam 优化器</h4> 
<p>Adam 优化器是深度学习中常用的一种优化算法，结合了动量法和 RMSProp 的优点。<br> <strong>案例</strong>：使用tf.train.AdamOptimizer 优化线性模型<br> 假设我们有一个简单的线性模型 y=wx+b，其中 w 是权重，b 是偏置，我们希望通过训练来找到最优的 w 和 b，使得模型能够较好地拟合一组给定的数据点。读者可以从这个简单的案例学会此优化器使用方法.</p> 
<pre><code class="prism language-python"><span class="token comment">#test1</span>
<span class="token comment"># 步骤 1: 导入必要的库</span>
<span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf  
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token comment"># 步骤 2: 创建数据</span>
<span class="token comment">#为了简单起见，我们手动创建一些线性数据并添加一些噪声。</span>
<span class="token comment"># 生成数据  </span>
np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>  
x_data <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>newaxis<span class="token punctuation">]</span>  <span class="token comment"># 100个数据点，形状为[100, 1]  </span>
noise <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token operator">*</span>x_data<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">0.1</span>  <span class="token comment"># 添加噪声  </span>
y_data <span class="token operator">=</span> <span class="token number">2</span> <span class="token operator">*</span> x_data <span class="token operator">+</span> <span class="token number">1</span> <span class="token operator">+</span> noise  <span class="token comment"># 真实模型为 y = 2x + 1</span>
<span class="token comment">#步骤 3: 定义模型</span>
<span class="token comment"># TensorFlow 1.x 风格  </span>
x <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  
y <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  
  
<span class="token comment"># 定义模型参数  </span>
W <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'weight'</span><span class="token punctuation">)</span>  
b <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'bias'</span><span class="token punctuation">)</span>  
  
<span class="token comment"># 定义模型  </span>
y_pred <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x<span class="token punctuation">,</span> W<span class="token punctuation">)</span> <span class="token operator">+</span> b

<span class="token comment">#步骤 4: 定义损失函数和优化器</span>
<span class="token comment"># 定义损失函数  </span>
loss <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>square<span class="token punctuation">(</span>y_pred <span class="token operator">-</span> y<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># MSE损失  </span>
  
<span class="token comment"># 定义优化器  </span>
optimizer <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>AdamOptimizer<span class="token punctuation">(</span>learning_rate<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>  
train <span class="token operator">=</span> optimizer<span class="token punctuation">.</span>minimize<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>

<span class="token comment">#步骤 5: 训练模型</span>
<span class="token comment"># 初始化变量  </span>
init <span class="token operator">=</span> tf<span class="token punctuation">.</span>global_variables_initializer<span class="token punctuation">(</span><span class="token punctuation">)</span>  
  
<span class="token comment"># 启动会话  </span>
<span class="token keyword">with</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> sess<span class="token punctuation">:</span>  
    sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>init<span class="token punctuation">)</span>  
      
    <span class="token comment"># 训练模型  </span>
    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  
        sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>train<span class="token punctuation">,</span> feed_dict<span class="token operator">=</span><span class="token punctuation">{<!-- --></span>x<span class="token punctuation">:</span> x_data<span class="token punctuation">,</span> y<span class="token punctuation">:</span> y_data<span class="token punctuation">}</span><span class="token punctuation">)</span>  
          
        <span class="token keyword">if</span> epoch <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>  
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Epoch </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>epoch<span class="token punctuation">}</span></span><span class="token string">, Loss: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>loss<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span>feed_dict<span class="token operator">=</span><span class="token punctuation">{<!-- --></span>x<span class="token punctuation">:</span> x_data<span class="token punctuation">,</span> y<span class="token punctuation">:</span> y_data<span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>  
      
    <span class="token comment"># 获取训练后的参数  </span>
    w_value<span class="token punctuation">,</span> b_value <span class="token operator">=</span> sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token punctuation">[</span>W<span class="token punctuation">,</span> b<span class="token punctuation">]</span><span class="token punctuation">)</span>  
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Trained w: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>w_value<span class="token punctuation">}</span></span><span class="token string">, b: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>b_value<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
</code></pre> 
<p>运行结果：<br> <img src="https://images2.imgbox.com/0d/8c/4VdF9Fx0_o.png" alt="在这里插入图片描述"><br> 可见拟合效果还是不错的！</p> 
<blockquote> 
 <p>注意：从TensorFlow 2.x开始，推荐使用tf.keras.optimizers.Adam而不是tf.train.AdamOptimizer，因为TensorFlow 2.x更强调使用Keras API。</p> 
</blockquote> 
<h4><a id="LBFGSB_70"></a>L-BFGS-B</h4> 
<p>L-BFGS-B 是一种基于准牛顿法的优化算法，适用于大规模无约束或有边界约束的优化问题。<br> 下面这个简单的案例教你使用此优化器：</p> 
<pre><code class="prism language-python"><span class="token comment">#test2 </span>
<span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf  
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np  
  
<span class="token comment"># 定义TensorFlow图  </span>
<span class="token keyword">with</span> tf<span class="token punctuation">.</span>Graph<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>as_default<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  
    <span class="token comment"># 定义变量  </span>
    x <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'x'</span><span class="token punctuation">)</span>  
  
    <span class="token comment"># 定义损失函数  </span>
    loss <span class="token operator">=</span> <span class="token punctuation">(</span>x <span class="token operator">-</span> <span class="token number">3.0</span><span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span>  <span class="token operator">+</span> <span class="token number">2</span>
  
    <span class="token comment"># 初始化变量  </span>
    init <span class="token operator">=</span> tf<span class="token punctuation">.</span>global_variables_initializer<span class="token punctuation">(</span><span class="token punctuation">)</span>  
  
    <span class="token comment"># 创建ScipyOptimizerInterface  </span>
    train_lbfgs <span class="token operator">=</span> tf<span class="token punctuation">.</span>contrib<span class="token punctuation">.</span>opt<span class="token punctuation">.</span>ScipyOptimizerInterface<span class="token punctuation">(</span>  
        loss<span class="token punctuation">,</span>  
        var_list<span class="token operator">=</span><span class="token punctuation">[</span>x<span class="token punctuation">]</span><span class="token punctuation">,</span>  
        method<span class="token operator">=</span><span class="token string">"L-BFGS-B"</span><span class="token punctuation">,</span>  
        options<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token string">'maxiter'</span><span class="token punctuation">:</span> <span class="token number">10000</span><span class="token punctuation">,</span> <span class="token string">'ftol'</span><span class="token punctuation">:</span> <span class="token number">1.0</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>finfo<span class="token punctuation">(</span><span class="token builtin">float</span><span class="token punctuation">)</span><span class="token punctuation">.</span>eps<span class="token punctuation">}</span>  
    <span class="token punctuation">)</span>  
  
    <span class="token comment"># 启动会话  </span>
    <span class="token keyword">with</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> sess<span class="token punctuation">:</span>  
        sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>init<span class="token punctuation">)</span>  
          
        <span class="token comment"># 运行优化  </span>
        train_lbfgs<span class="token punctuation">.</span>minimize<span class="token punctuation">(</span>sess<span class="token punctuation">)</span>  
          
        <span class="token comment"># 获取优化后的变量值  </span>
        optimized_x <span class="token operator">=</span> x<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span>sess<span class="token punctuation">)</span>  
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Optimized x:"</span><span class="token punctuation">,</span> optimized_x<span class="token punctuation">)</span>
        
</code></pre> 
<p>运行结果：</p> 
<pre><code class="prism language-python">INFO<span class="token punctuation">:</span>tensorflow<span class="token punctuation">:</span>Optimization terminated <span class="token keyword">with</span><span class="token punctuation">:</span>
  Message<span class="token punctuation">:</span> CONVERGENCE<span class="token punctuation">:</span> NORM_OF_PROJECTED_GRADIENT_<span class="token operator">&lt;=</span>_PGTOL
  Objective function value<span class="token punctuation">:</span> <span class="token number">2.000000</span>
  Number of iterations<span class="token punctuation">:</span> <span class="token number">2</span>
  Number of functions evaluations<span class="token punctuation">:</span> <span class="token number">3</span>
Optimized x<span class="token punctuation">:</span> <span class="token number">3.0</span>
</code></pre> 
<p>快狠准！</p> 
<blockquote> 
 <p>请注意，由于tf.contrib在TensorFlow 2.x中不再可用，如果你正在使用TensorFlow 2.x，并且需要类似的功能， 可能需要考虑使用TensorFlow的tf.keras.optimizers中的优化器，这些优化器虽然不包括L-BFGS-B，但提供了许多其他有效的优化算法。</p> 
</blockquote> 
<h3><a id="Session_123"></a>会话（Session）</h3> 
<p>在 TensorFlow 中，会话 (Session) 是运行计算图的环境。它负责分配资源（如变量）并执行操作。下面笔者给个例子，帮助读者理解使用 session 在 TF学习框架中的作用：</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token comment"># 定义占位符和变量</span>
x <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 构建神经网络</span>
layer <span class="token operator">=</span> tf<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>dense<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> activation<span class="token operator">=</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">)</span>
output <span class="token operator">=</span> tf<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>dense<span class="token punctuation">(</span>layer<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

<span class="token comment"># 定义损失函数</span>
loss <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>square<span class="token punctuation">(</span>output <span class="token operator">-</span> y<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 定义优化器</span>
train_adam <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>AdamOptimizer<span class="token punctuation">(</span><span class="token number">0.0008</span><span class="token punctuation">)</span><span class="token punctuation">.</span>minimize<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>
train_lbfgs <span class="token operator">=</span> tf<span class="token punctuation">.</span>contrib<span class="token punctuation">.</span>opt<span class="token punctuation">.</span>ScipyOptimizerInterface<span class="token punctuation">(</span>
    loss<span class="token punctuation">,</span>
    method<span class="token operator">=</span><span class="token string">"L-BFGS-B"</span><span class="token punctuation">,</span>
    options<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token string">'maxiter'</span><span class="token punctuation">:</span> <span class="token number">10000</span><span class="token punctuation">,</span> <span class="token string">'ftol'</span><span class="token punctuation">:</span> <span class="token number">1.0</span> <span class="token operator">*</span> np<span class="token punctuation">.</span>finfo<span class="token punctuation">(</span><span class="token builtin">float</span><span class="token punctuation">)</span><span class="token punctuation">.</span>eps<span class="token punctuation">}</span>
<span class="token punctuation">)</span>

<span class="token comment"># 初始化变量</span>
init <span class="token operator">=</span> tf<span class="token punctuation">.</span>global_variables_initializer<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 创建会话并运行</span>
<span class="token keyword">with</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> sess<span class="token punctuation">:</span>
    sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>init<span class="token punctuation">)</span>
    
    <span class="token comment"># 使用 Adam 优化器进行训练</span>
    <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>train_adam<span class="token punctuation">,</span> feed_dict<span class="token operator">=</span><span class="token punctuation">{<!-- --></span>x<span class="token punctuation">:</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">:</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
    
    <span class="token comment"># 使用 L-BFGS-B 优化器进行训练</span>
    train_lbfgs<span class="token punctuation">.</span>minimize<span class="token punctuation">(</span>sess<span class="token punctuation">,</span> feed_dict<span class="token operator">=</span><span class="token punctuation">{<!-- --></span>x<span class="token punctuation">:</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">:</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">)</span>

    <span class="token comment"># 打印损失值</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Final loss:"</span><span class="token punctuation">,</span> sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>loss<span class="token punctuation">,</span> feed_dict<span class="token operator">=</span><span class="token punctuation">{<!-- --></span>x<span class="token punctuation">:</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">:</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

</code></pre> 
<p>运行结果：</p> 
<pre><code class="prism language-python">INFO<span class="token punctuation">:</span>tensorflow<span class="token punctuation">:</span>Optimization terminated <span class="token keyword">with</span><span class="token punctuation">:</span>
  Message<span class="token punctuation">:</span> CONVERGENCE<span class="token punctuation">:</span> NORM_OF_PROJECTED_GRADIENT_<span class="token operator">&lt;=</span>_PGTOL
  Objective function value<span class="token punctuation">:</span> <span class="token number">0.080921</span>
  Number of iterations<span class="token punctuation">:</span> <span class="token number">7</span>
  Number of functions evaluations<span class="token punctuation">:</span> <span class="token number">10</span>
Final loss<span class="token punctuation">:</span> <span class="token number">0.048916824</span>
</code></pre> 
<ul><li>Session确保了TensorFlow计算图的正确执行，是获取正确计算结果的关键步骤。没有Session，计算图只是定义在前端系统中的静态结构，无法转化为实际的计算任务。</li><li>优化资源利用：<br> 通过Session的资源分配和管理功能，TensorFlow能够更高效地利用硬件资源，提高计算效率。这对于大规模的计算任务尤为重要。</li><li>支持复杂计算任务：<br> 在处理复杂的计算任务时，如深度学习模型的训练，Session提供了必要的控制手段，使得用户能够更精细地管理计算过程，包括指定计算设备、控制资源使用等。</li></ul> 
<p>今天的基础知识就讲到这里！请持续关注~</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/3b5ba647dc74c06bcbbedf4c883c1cd8/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">CSP-J模拟赛day2——试题</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/8882d0539d3744a4cf74daff8b1f8f35/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">利用【MATLAB】和【Python】进行【图与网络模型】的高级应用与分析】</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>