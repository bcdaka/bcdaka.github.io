<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>本地部署大模型ollama&#43;docker&#43;open WebUI/Lobe Chat - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/b2977985b37155f85829c381cb4338f4/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="本地部署大模型ollama&#43;docker&#43;open WebUI/Lobe Chat">
  <meta property="og:description" content="文章目录 大模型工具Ollama下载安装运行Spring Ai 代码测试加依赖配置写代码 ollama的web&amp;Desktop搭建部署Open WebUI有两种方式Docker DesktopDocker部署Open WebUIDocker部署Lobe Chat可以配置OpenAI的key也可以配置ollama 大模型的选择 本篇基于windows环境下配置 大模型工具Ollama https://ollama.com/
下载 https://ollama.com/download
windows环境下就安装windows版本
安装 点击下载的exe文件进行傻瓜式安装
运行 去ollama官网（models模块下）找大模型的名字，然后复制ollama的运行名字
https://ollama.com/library
ollama run qwen:4b Spring Ai 代码测试 默认ollama会监听11434端口，可以使用下面命令查看
netstat -ano | findstr 11434 可以使用ollama list指令查看本地已经下好的大模型
ollama list 加依赖 &lt;dependency&gt; &lt;groupId&gt;org.springframework.ai&lt;/groupId&gt; &lt;artifactId&gt;spring-ai-ollama-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; 或者使用23版以上的idea，创建spring项目的时候选最新版本，直接勾选上AI模块下的ollama模块
配置 spring: application: name: open-ai-05-ollama ai: ollama: base-url: http://localhost:11434 chat: options: model: qwen:4b 写代码 @RestController public class OllamaController { @Autowired private OllamaChatClient ollamaChatClient; @RequestMapping(value = &#34;/ai/ollama&#34;) public Object ollama(@RequestParam(value = &#34;">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-05-04T20:05:00+08:00">
    <meta property="article:modified_time" content="2024-05-04T20:05:00+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">本地部署大模型ollama&#43;docker&#43;open WebUI/Lobe Chat</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#Ollama_2" rel="nofollow">大模型工具Ollama</a></li><li><ul><li><a href="#_7" rel="nofollow">下载</a></li><li><a href="#_15" rel="nofollow">安装</a></li><li><a href="#_18" rel="nofollow">运行</a></li><li><a href="#Spring_Ai__26" rel="nofollow">Spring Ai 代码测试</a></li><li><ul><li><a href="#_40" rel="nofollow">加依赖</a></li><li><a href="#_49" rel="nofollow">配置</a></li><li><a href="#_62" rel="nofollow">写代码</a></li></ul> 
  </li></ul> 
  </li><li><a href="#ollamawebDesktop_95" rel="nofollow">ollama的web&amp;Desktop</a></li><li><ul><li><a href="#Open_WebUI_100" rel="nofollow">搭建部署Open WebUI有两种方式</a></li><li><ul><li><a href="#Docker_Desktop_104" rel="nofollow">Docker Desktop</a></li><li><a href="#DockerOpen_WebUI_112" rel="nofollow">Docker部署Open WebUI</a></li><li><a href="#DockerLobe_Chat_148" rel="nofollow">Docker部署Lobe Chat</a></li><li><ul><li><a href="#OpenAIkey_174" rel="nofollow">可以配置OpenAI的key</a></li><li><a href="#ollama_179" rel="nofollow">也可以配置ollama</a></li></ul> 
   </li></ul> 
  </li></ul> 
  </li><li><a href="#_184" rel="nofollow">大模型的选择</a></li></ul> 
</div> 
<br> 本篇基于windows环境下配置 
<p></p> 
<h2><a id="Ollama_2"></a>大模型工具Ollama</h2> 
<p><a href="https://ollama.com/" rel="nofollow">https://ollama.com/</a></p> 
<p><img src="https://images2.imgbox.com/b8/0b/Xd8s0W9Y_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="_7"></a>下载</h3> 
<p><a href="https://ollama.com/download" rel="nofollow">https://ollama.com/download</a><br> windows环境下就安装windows版本<br> <img src="https://images2.imgbox.com/5f/5e/m6aX3e9m_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/43/ec/0I3X6EvQ_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="_15"></a>安装</h3> 
<p>点击下载的exe文件进行傻瓜式安装</p> 
<h3><a id="_18"></a>运行</h3> 
<p>去ollama官网（models模块下）找大模型的名字，然后复制ollama的运行名字<br> <a href="https://ollama.com/library" rel="nofollow">https://ollama.com/library</a><br> <img src="https://images2.imgbox.com/95/e2/MgDOUkb4_o.png" alt="在这里插入图片描述"></p> 
<pre><code class="prism language-java">ollama run qwen<span class="token operator">:</span><span class="token number">4</span>b
</code></pre> 
<h3><a id="Spring_Ai__26"></a>Spring Ai 代码测试</h3> 
<p>默认ollama会监听11434端口，可以使用下面命令查看<br> <img src="https://images2.imgbox.com/80/05/1MVxPxoo_o.png" alt="在这里插入图片描述"></p> 
<pre><code class="prism language-java">netstat <span class="token operator">-</span>ano <span class="token operator">|</span> findstr <span class="token number">11434</span>
</code></pre> 
<p>可以使用ollama list指令查看本地已经下好的大模型</p> 
<pre><code class="prism language-java">ollama list
</code></pre> 
<p><img src="https://images2.imgbox.com/5f/6d/uYm2p8VW_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="_40"></a>加依赖</h4> 
<pre><code class="prism language-java"><span class="token generics"><span class="token punctuation">&lt;</span>dependency<span class="token punctuation">&gt;</span></span>
            <span class="token generics"><span class="token punctuation">&lt;</span>groupId<span class="token punctuation">&gt;</span></span>org<span class="token punctuation">.</span>springframework<span class="token punctuation">.</span>ai<span class="token operator">&lt;</span><span class="token operator">/</span>groupId<span class="token operator">&gt;</span>
            <span class="token generics"><span class="token punctuation">&lt;</span>artifactId<span class="token punctuation">&gt;</span></span>spring<span class="token operator">-</span>ai<span class="token operator">-</span>ollama<span class="token operator">-</span>spring<span class="token operator">-</span>boot<span class="token operator">-</span>starter<span class="token operator">&lt;</span><span class="token operator">/</span>artifactId<span class="token operator">&gt;</span>
        <span class="token operator">&lt;</span><span class="token operator">/</span>dependency<span class="token operator">&gt;</span>
</code></pre> 
<p>或者使用23版以上的idea，创建spring项目的时候选最新版本，直接勾选上AI模块下的ollama模块</p> 
<h4><a id="_49"></a>配置</h4> 
<pre><code class="prism language-java">spring<span class="token operator">:</span>
  application<span class="token operator">:</span>
    name<span class="token operator">:</span> <span class="token keyword">open</span><span class="token operator">-</span>ai<span class="token operator">-</span><span class="token number">05</span><span class="token operator">-</span>ollama
  ai<span class="token operator">:</span>
    ollama<span class="token operator">:</span>
      base<span class="token operator">-</span>url<span class="token operator">:</span> http<span class="token operator">:</span><span class="token operator">/</span><span class="token operator">/</span>localhost<span class="token operator">:</span><span class="token number">11434</span>
      chat<span class="token operator">:</span>
        options<span class="token operator">:</span>
          model<span class="token operator">:</span> qwen<span class="token operator">:</span><span class="token number">4</span>b   
</code></pre> 
<h4><a id="_62"></a>写代码</h4> 
<p><img src="https://images2.imgbox.com/cf/a5/RCcKIF3b_o.png" alt="在这里插入图片描述"></p> 
<pre><code class="prism language-java"><span class="token annotation punctuation">@RestController</span>
<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">OllamaController</span> <span class="token punctuation">{<!-- --></span>

    <span class="token annotation punctuation">@Autowired</span>
    <span class="token keyword">private</span> <span class="token class-name">OllamaChatClient</span> ollamaChatClient<span class="token punctuation">;</span>


    <span class="token annotation punctuation">@RequestMapping</span><span class="token punctuation">(</span>value <span class="token operator">=</span> <span class="token string">"/ai/ollama"</span><span class="token punctuation">)</span>
    <span class="token keyword">public</span> <span class="token class-name">Object</span> <span class="token function">ollama</span><span class="token punctuation">(</span><span class="token annotation punctuation">@RequestParam</span><span class="token punctuation">(</span>value <span class="token operator">=</span> <span class="token string">"msg"</span><span class="token punctuation">)</span> <span class="token class-name">String</span> msg<span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
        <span class="token class-name">String</span> call <span class="token operator">=</span> ollamaChatClient<span class="token punctuation">.</span><span class="token function">call</span><span class="token punctuation">(</span>msg<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>call<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">return</span> call<span class="token punctuation">;</span>
    <span class="token punctuation">}</span>


    <span class="token annotation punctuation">@RequestMapping</span><span class="token punctuation">(</span>value <span class="token operator">=</span> <span class="token string">"/ai/ollama2"</span><span class="token punctuation">)</span>
    <span class="token keyword">public</span> <span class="token class-name">Object</span> <span class="token function">ollama2</span><span class="token punctuation">(</span><span class="token annotation punctuation">@RequestParam</span><span class="token punctuation">(</span>value <span class="token operator">=</span> <span class="token string">"msg"</span><span class="token punctuation">)</span> <span class="token class-name">String</span> msg<span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
        <span class="token class-name">ChatResponse</span> response <span class="token operator">=</span> ollamaChatClient<span class="token punctuation">.</span><span class="token function">call</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Prompt</span><span class="token punctuation">(</span>
                msg<span class="token punctuation">,</span>
                <span class="token class-name">OllamaOptions</span><span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
                        <span class="token punctuation">.</span><span class="token function">withModel</span><span class="token punctuation">(</span><span class="token string">"qwen:4b"</span><span class="token punctuation">)</span>
                        <span class="token punctuation">.</span><span class="token function">withTemperature</span><span class="token punctuation">(</span><span class="token number">0.4f</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">String</span> content <span class="token operator">=</span> response<span class="token punctuation">.</span><span class="token function">getResult</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getOutput</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getContent</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>content<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">return</span> content<span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<h2><a id="ollamawebDesktop_95"></a>ollama的web&amp;Desktop</h2> 
<p>看ollama的github主页下面有很多的web&amp;Desktop，比较流行的是Open WenUI<br> Open WenUI Github <a href="https://github.com/open-webui/open-webui">https://github.com/open-webui/open-webui</a><br> Open WenUI 官网：<a href="https://github.com/open-webui/open-webui">https://github.com/open-webui/open-webui</a></p> 
<h3><a id="Open_WebUI_100"></a>搭建部署Open WebUI有两种方式</h3> 
<ol><li>Docker方式（官网推荐）</li><li>源代码部署安装方式：（文档<a href="https://docs.openwebui.com/getting-started/" rel="nofollow">https://docs.openwebui.com/getting-started/</a>）</li></ol> 
<h4><a id="Docker_Desktop_104"></a>Docker Desktop</h4> 
<p>windows环境下推荐使用Docker Desktop</p> 
<p>轻量化，界面化操作Docker容器<br> 官网下载安装包<br> <a href="https://www.docker.com/products/docker-desktop/" rel="nofollow">https://www.docker.com/products/docker-desktop/</a><br> 下载后傻瓜式安装即可，安装后需要重启，然后打开Docker Desktop后的界面如下：<br> <img src="https://images2.imgbox.com/35/be/ngjFSsr5_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="DockerOpen_WebUI_112"></a>Docker部署Open WebUI</h4> 
<p>在docker中运行Open WebUI<br> 在命令行运行docker指令</p> 
<pre><code class="prism language-java">docker run <span class="token operator">-</span>d <span class="token operator">-</span>p <span class="token number">3000</span><span class="token operator">:</span><span class="token number">8080</span> <span class="token operator">--</span>add<span class="token operator">-</span>host<span class="token operator">=</span>host<span class="token punctuation">.</span>docker<span class="token punctuation">.</span>internal<span class="token operator">:</span>host<span class="token operator">-</span>gateway <span class="token operator">-</span>v <span class="token class-name">D</span><span class="token operator">:</span>\dev\<span class="token keyword">open</span><span class="token operator">-</span>webui<span class="token operator">:</span><span class="token operator">/</span>app<span class="token operator">/</span>backend<span class="token operator">/</span>data <span class="token operator">--</span>name <span class="token keyword">open</span><span class="token operator">-</span>webui <span class="token operator">--</span>restart always ghcr<span class="token punctuation">.</span>io<span class="token operator">/</span><span class="token keyword">open</span><span class="token operator">-</span>webui<span class="token operator">/</span><span class="token keyword">open</span><span class="token operator">-</span>webui<span class="token operator">:</span>main

</code></pre> 
<p>这是一个 docker run 命令，用于启动一个新的 Docker 容器，下面是这个命令各个部分的解释：</p> 
<ul><li>docker run：这是 Docker 的命令，用于从指定的镜像启动一个新的容器；</li><li>-d：表示在“分离”模式下运行容器，即后台运行；</li><li>-p 3000:8080：端口映射，表示将宿主机的3000端口映射到容器的8080端口，当你访问宿主机的3000端口时，实际上会访问容器内的8080端口；</li><li>–add-host=host.docker.internal:host-gateway：这个选项向容器的 /etc/hosts 文件中添加一条记录，这通常用于让容器能够解析到宿主机的名称，并且将其 IP 地址设置为宿主机的网关地址，这在某些网络配置中很有用，尤其是当容器需要知道宿主机的地址时；</li><li>-v D:\dev\open-webui:/app/backend/data：卷挂载，这表示将宿主机的 D:\dev\open-webui 目录挂载到容器内的 /app/backend/data 目录，这样，容器和宿主机之间可以共享这个目录中的数据；</li><li>–name open-webui：为容器指定一个名称，这里是 open-webui；</li><li>–restart always：这个选项告诉 Docker 在容器退出时总是自动重启它，无论容器是因为何种原因退出，它都会自动重启；</li><li>ghcr.io/open-webui/open-webui:main：这是你要运行的 Docker 镜像的完整名称，ghcr.io 是 GitHub Container Registry 的地址，open-webui/open-webui 是镜像的仓库和名称，main是标签，通常表示该镜像的最新或主分支版本；</li></ul> 
<p>第一次运行需要拉取镜像比较慢，等待执行完成<br> <img src="https://images2.imgbox.com/a0/d7/E3q0H3KH_o.png" alt="在这里插入图片描述"><br> 这时候打开docker desktop就可以在images模块下看到拉取到的镜像<br> <img src="https://images2.imgbox.com/39/cd/zquWrZn4_o.png" alt="在这里插入图片描述"></p> 
<p>我们在拉取镜像的时候指定了Web UI的端口为3000，所以访问3000端口即可</p> 
<pre><code class="prism language-java">http<span class="token operator">:</span><span class="token operator">/</span><span class="token operator">/</span>localhost<span class="token operator">:</span><span class="token number">3000</span><span class="token operator">/</span>
</code></pre> 
<p>第一次会要求登录<br> <img src="https://images2.imgbox.com/08/c7/lf0WKBsq_o.png" alt="在这里插入图片描述"><br> 注册并登录<br> <img src="https://images2.imgbox.com/f6/76/nTHKxU1q_o.png" alt="在这里插入图片描述"><br> 上来后和Chatgpt的页面很像的。</p> 
<p><img src="https://images2.imgbox.com/72/8b/CH5UyfMD_o.png" alt="在这里插入图片描述"><br> select model的地方选择上我们通过ollama部署的模型。然后就可以开心聊天了</p> 
<h4><a id="DockerLobe_Chat_148"></a>Docker部署Lobe Chat</h4> 
<p>官网：<a href="https://lobehub.com/" rel="nofollow">https://lobehub.com/</a><br> Github：<a href="https://github.com/lobehub/lobe-chat">https://github.com/lobehub/lobe-chat </a></p> 
<ul><li>Built for you the Super Individual （专为你打造的超级个人）</li><li>现代化设计的开源 ChatGPT/LLMs</li><li>聊天应用与开发的UI框架； 支持语音合成、多模态、可扩展的（function call）插件系统；</li><li>一键免费拥有你自己的ChatGPT/Gemini/Claude/Ollama 应用；</li></ul> 
<p><strong>Lobe Chat 部署</strong></p> 
<ol><li>使用 Vercel、Zeabur 或 Sealos 部署；</li><li>使用 Docker 部署；</li></ol> 
<pre><code class="prism language-java">docker run <span class="token operator">-</span>d <span class="token operator">-</span>p <span class="token number">3210</span><span class="token operator">:</span><span class="token number">3210</span> <span class="token operator">-</span>e <span class="token constant">OPENAI_API_KEY</span><span class="token operator">=</span>sk<span class="token operator">-</span>xxxx <span class="token operator">-</span>e <span class="token constant">ACCESS_CODE</span><span class="token operator">=</span>lobe66 <span class="token operator">--</span>name lobe<span class="token operator">-</span>chat lobehub<span class="token operator">/</span>lobe<span class="token operator">-</span>chat
</code></pre> 
<p>完整的部署文档：<a href="https://lobehub.com/zh/docs/self-hosting/start" rel="nofollow">https://lobehub.com/zh/docs/self-hosting/start </a></p> 
<p>同样的，在拉取完成后，docker desktop中也会有镜像，<br> <img src="https://images2.imgbox.com/3a/21/3pgfp0G2_o.png" alt="在这里插入图片描述"><br> 同样的方式，访问我们指定的3210端口<br> <img src="https://images2.imgbox.com/7c/ab/Qh1WsbQf_o.png" alt="在这里插入图片描述"><br> 这个需要点击设置去配置模型</p> 
<h5><a id="OpenAIkey_174"></a>可以配置OpenAI的key</h5> 
<p><img src="https://images2.imgbox.com/13/f7/jMO39Dr7_o.png" alt="在这里插入图片描述"><br> <strong>注意</strong>代理的地址要在后面加上<code>/v1</code><br> 配置好后就可以访问openai</p> 
<h5><a id="ollama_179"></a>也可以配置ollama</h5> 
<p><img src="https://images2.imgbox.com/ba/0e/Bx7XHoLV_o.png" alt="在这里插入图片描述"><br> 本机默认代理地址可以不用配，模型列表中选上你的模型就可以使用了。<br> 还可以加插件使用<br> 也可以在本地部署更强大的模型，使用图片，文件，音频等模态</p> 
<h2><a id="_184"></a>大模型的选择</h2> 
<ul><li>大语言模型主要分为国外大模型 和 国内大模型；</li><li>国外大模型，可能受到一些限制，或者不稳定；</li><li>国内也有非常优秀的大模型，国内大模型排行榜： 
  <ul><li><a href="https://www.superclueai.com/" rel="nofollow">https://www.superclueai.com/</a></li><li>基于中文语言理解测评基准，包括代表性的数据集、基准(预训练)模型、语料库、排行榜；</li><li>选择一系列有一定代表性的任务对应的数据集，做为测试基准的数据集，这些数据集会覆盖不同的任务、数据量、任务难度；</li></ul> </li></ul>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/4f8f572462629265a78232d7206e93b9/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">在windows 11本地搭建RAG数据查询的AI大模型环境</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/9c70c2b9a0e985b0f068b4cad1eb6db2/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">ZooKeeper以及DolphinScheduler的用法</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>