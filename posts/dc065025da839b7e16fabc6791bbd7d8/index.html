<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>å¦‚ä½•åˆ©ç”¨Pythonè¿›è¡Œæ–‡æœ¬æ•°æ®åˆ†æï¼šæ·±å…¥è§£æä¸å®ä¾‹ä»£ç  - ç¼–ç¨‹å¤§å’–</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/dc065025da839b7e16fabc6791bbd7d8/">
  <meta property="og:site_name" content="ç¼–ç¨‹å¤§å’–">
  <meta property="og:title" content="å¦‚ä½•åˆ©ç”¨Pythonè¿›è¡Œæ–‡æœ¬æ•°æ®åˆ†æï¼šæ·±å…¥è§£æä¸å®ä¾‹ä»£ç ">
  <meta property="og:description" content="æ›´å¤šèµ„æ–™è·å– ğŸ“š ä¸ªäººç½‘ç«™ï¼šipengtao.com
æ–‡æœ¬æ•°æ®åˆ†æåœ¨å½“ä»Šä¿¡æ¯æ—¶ä»£å…·æœ‰é‡è¦åœ°ä½ï¼Œè€ŒPythonä½œä¸ºä¸€é—¨å¼ºå¤§çš„ç¼–ç¨‹è¯­è¨€ï¼Œæä¾›äº†ä¸°å¯Œçš„å·¥å…·å’Œåº“æ¥å¤„ç†å’Œåˆ†ææ–‡æœ¬æ•°æ®ã€‚æœ¬æ–‡å°†æ·±å…¥ç ”ç©¶å¦‚ä½•ä½¿ç”¨Pythonè¿›è¡Œæ–‡æœ¬æ•°æ®åˆ†æï¼Œæä¾›è¯¦ç»†å…¨é¢çš„å†…å®¹å’Œä¸°å¯Œçš„ç¤ºä¾‹ä»£ç ã€‚
è¯»å–æ–‡æœ¬æ•°æ® ä½¿ç”¨Pythonå†…ç½®çš„open()å‡½æ•°æˆ–ç¬¬ä¸‰æ–¹åº“å¦‚pandasè¯»å–æ–‡æœ¬æ–‡ä»¶ï¼š
# ä½¿ç”¨open()å‡½æ•°è¯»å–æ–‡æœ¬æ–‡ä»¶ with open(&#39;text_data.txt&#39;, &#39;r&#39;) as file: text_content = file.read() # ä½¿ç”¨pandasè¯»å–æ–‡æœ¬æ–‡ä»¶ import pandas as pd df = pd.read_csv(&#39;text_data.csv&#39;, delimiter=&#39;\t&#39;) æ–‡æœ¬é¢„å¤„ç† æ¸…ç†æ–‡æœ¬æ•°æ®æ˜¯æ–‡æœ¬åˆ†æçš„ç¬¬ä¸€æ­¥ï¼ŒåŒ…æ‹¬å»é™¤åœç”¨è¯ã€æ ‡ç‚¹ç¬¦å·ï¼Œè½¬æ¢ä¸ºå°å†™ç­‰ï¼š
import re from nltk.corpus import stopwords def preprocess_text(text): text = text.lower() text = re.sub(r&#39;\W&#39;, &#39; &#39;, text) text = re.sub(r&#39;\s&#43;&#39;, &#39; &#39;, text) stop_words = set(stopwords.words(&#39;english&#39;)) tokens = [word for word in text.split() if word not in stop_words] return &#39; &#39;.join(tokens) preprocessed_text = preprocess_text(text_content) è¯é¢‘ç»Ÿè®¡ ä½¿ç”¨nltkæˆ–Counteråº“è¿›è¡Œè¯é¢‘ç»Ÿè®¡ï¼š">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2023-12-18T19:00:00+08:00">
    <meta property="article:modified_time" content="2023-12-18T19:00:00+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="ç¼–ç¨‹å¤§å’–" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">ç¼–ç¨‹å¤§å’–</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">å¦‚ä½•åˆ©ç”¨Pythonè¿›è¡Œæ–‡æœ¬æ•°æ®åˆ†æï¼šæ·±å…¥è§£æä¸å®ä¾‹ä»£ç </h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-tomorrow-night">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p><img src="https://images2.imgbox.com/3c/51/5QOSEoln_o.png" alt=""></p> 
<h2><a id="_1"></a>æ›´å¤šèµ„æ–™è·å–</h2> 
<p>ğŸ“š ä¸ªäººç½‘ç«™ï¼š<a href="http://ipengtao.com/" rel="nofollow">ipengtao.com</a></p> 
<hr> 
<p>æ–‡æœ¬æ•°æ®åˆ†æåœ¨å½“ä»Šä¿¡æ¯æ—¶ä»£å…·æœ‰é‡è¦åœ°ä½ï¼Œè€ŒPythonä½œä¸ºä¸€é—¨å¼ºå¤§çš„ç¼–ç¨‹è¯­è¨€ï¼Œæä¾›äº†ä¸°å¯Œçš„å·¥å…·å’Œåº“æ¥å¤„ç†å’Œåˆ†ææ–‡æœ¬æ•°æ®ã€‚æœ¬æ–‡å°†æ·±å…¥ç ”ç©¶å¦‚ä½•ä½¿ç”¨Pythonè¿›è¡Œæ–‡æœ¬æ•°æ®åˆ†æï¼Œæä¾›è¯¦ç»†å…¨é¢çš„å†…å®¹å’Œä¸°å¯Œçš„ç¤ºä¾‹ä»£ç ã€‚</p> 
<h3><a id="_8"></a>è¯»å–æ–‡æœ¬æ•°æ®</h3> 
<p>ä½¿ç”¨Pythonå†…ç½®çš„<code>open()</code>å‡½æ•°æˆ–ç¬¬ä¸‰æ–¹åº“å¦‚<code>pandas</code>è¯»å–æ–‡æœ¬æ–‡ä»¶ï¼š</p> 
<pre><code class="prism language-python"><span class="token comment"># ä½¿ç”¨open()å‡½æ•°è¯»å–æ–‡æœ¬æ–‡ä»¶</span>
<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'text_data.txt'</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> <span class="token builtin">file</span><span class="token punctuation">:</span>
    text_content <span class="token operator">=</span> <span class="token builtin">file</span><span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># ä½¿ç”¨pandasè¯»å–æ–‡æœ¬æ–‡ä»¶</span>
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'text_data.csv'</span><span class="token punctuation">,</span> delimiter<span class="token operator">=</span><span class="token string">'\t'</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="_22"></a>æ–‡æœ¬é¢„å¤„ç†</h3> 
<p>æ¸…ç†æ–‡æœ¬æ•°æ®æ˜¯æ–‡æœ¬åˆ†æçš„ç¬¬ä¸€æ­¥ï¼ŒåŒ…æ‹¬å»é™¤åœç”¨è¯ã€æ ‡ç‚¹ç¬¦å·ï¼Œè½¬æ¢ä¸ºå°å†™ç­‰ï¼š</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> re
<span class="token keyword">from</span> nltk<span class="token punctuation">.</span>corpus <span class="token keyword">import</span> stopwords

<span class="token keyword">def</span> <span class="token function">preprocess_text</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>
    text <span class="token operator">=</span> text<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span>
    text <span class="token operator">=</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">r'\W'</span><span class="token punctuation">,</span> <span class="token string">' '</span><span class="token punctuation">,</span> text<span class="token punctuation">)</span>
    text <span class="token operator">=</span> re<span class="token punctuation">.</span>sub<span class="token punctuation">(</span><span class="token string">r'\s+'</span><span class="token punctuation">,</span> <span class="token string">' '</span><span class="token punctuation">,</span> text<span class="token punctuation">)</span>
    stop_words <span class="token operator">=</span> <span class="token builtin">set</span><span class="token punctuation">(</span>stopwords<span class="token punctuation">.</span>words<span class="token punctuation">(</span><span class="token string">'english'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    tokens <span class="token operator">=</span> <span class="token punctuation">[</span>word <span class="token keyword">for</span> word <span class="token keyword">in</span> text<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> word <span class="token keyword">not</span> <span class="token keyword">in</span> stop_words<span class="token punctuation">]</span>
    <span class="token keyword">return</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>tokens<span class="token punctuation">)</span>

preprocessed_text <span class="token operator">=</span> preprocess_text<span class="token punctuation">(</span>text_content<span class="token punctuation">)</span>
</code></pre> 
<h3><a id="_41"></a>è¯é¢‘ç»Ÿè®¡</h3> 
<p>ä½¿ç”¨<code>nltk</code>æˆ–<code>Counter</code>åº“è¿›è¡Œè¯é¢‘ç»Ÿè®¡ï¼š</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> nltk <span class="token keyword">import</span> FreqDist
<span class="token keyword">from</span> collections <span class="token keyword">import</span> Counter

<span class="token comment"># ä½¿ç”¨nltkè¿›è¡Œè¯é¢‘ç»Ÿè®¡</span>
freq_dist <span class="token operator">=</span> FreqDist<span class="token punctuation">(</span>preprocessed_text<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>freq_dist<span class="token punctuation">.</span>most_common<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># ä½¿ç”¨Counterè¿›è¡Œè¯é¢‘ç»Ÿè®¡</span>
word_count <span class="token operator">=</span> Counter<span class="token punctuation">(</span>preprocessed_text<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>word_count<span class="token punctuation">.</span>most_common<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="_58"></a>æ–‡æœ¬æƒ…æ„Ÿåˆ†æ</h3> 
<p>ä½¿ç”¨<code>nltk</code>æˆ–<code>TextBlob</code>åº“è¿›è¡Œæƒ…æ„Ÿåˆ†æï¼š</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> nltk<span class="token punctuation">.</span>sentiment <span class="token keyword">import</span> SentimentIntensityAnalyzer
<span class="token keyword">from</span> textblob <span class="token keyword">import</span> TextBlob

<span class="token comment"># ä½¿ç”¨nltkè¿›è¡Œæƒ…æ„Ÿåˆ†æ</span>
sia <span class="token operator">=</span> SentimentIntensityAnalyzer<span class="token punctuation">(</span><span class="token punctuation">)</span>
sentiment_nltk <span class="token operator">=</span> sia<span class="token punctuation">.</span>polarity_scores<span class="token punctuation">(</span>text_content<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>sentiment_nltk<span class="token punctuation">)</span>

<span class="token comment"># ä½¿ç”¨TextBlobè¿›è¡Œæƒ…æ„Ÿåˆ†æ</span>
blob <span class="token operator">=</span> TextBlob<span class="token punctuation">(</span>text_content<span class="token punctuation">)</span>
sentiment_textblob <span class="token operator">=</span> blob<span class="token punctuation">.</span>sentiment
<span class="token keyword">print</span><span class="token punctuation">(</span>sentiment_textblob<span class="token punctuation">)</span>
</code></pre> 
<h3><a id="_77"></a>æ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—</h3> 
<p>ä½¿ç”¨<code>nltk</code>æˆ–<code>gensim</code>åº“è¿›è¡Œæ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—ï¼š</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> nltk<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> jaccard_distance
<span class="token keyword">from</span> gensim<span class="token punctuation">.</span>models <span class="token keyword">import</span> Word2Vec

<span class="token comment"># ä½¿ç”¨nltkè®¡ç®—Jaccardç›¸ä¼¼åº¦</span>
text1 <span class="token operator">=</span> <span class="token string">"This is a sample text."</span>
text2 <span class="token operator">=</span> <span class="token string">"This is another example text."</span>
set1 <span class="token operator">=</span> <span class="token builtin">set</span><span class="token punctuation">(</span>text1<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
set2 <span class="token operator">=</span> <span class="token builtin">set</span><span class="token punctuation">(</span>text2<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
similarity_nltk <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">-</span> jaccard_distance<span class="token punctuation">(</span>set1<span class="token punctuation">,</span> set2<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>similarity_nltk<span class="token punctuation">)</span>

<span class="token comment"># ä½¿ç”¨gensimè®¡ç®—Word2Vecç›¸ä¼¼åº¦</span>
model <span class="token operator">=</span> Word2Vec<span class="token punctuation">(</span><span class="token punctuation">[</span>text1<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> text2<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> min_count<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
similarity_gensim <span class="token operator">=</span> model<span class="token punctuation">.</span>wv<span class="token punctuation">.</span>similarity<span class="token punctuation">(</span><span class="token string">'sample'</span><span class="token punctuation">,</span> <span class="token string">'example'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>similarity_gensim<span class="token punctuation">)</span>
</code></pre> 
<h3><a id="_99"></a>æ–‡æœ¬åˆ†ç±»</h3> 
<p>ä½¿ç”¨<code>scikit-learn</code>åº“è¿›è¡Œæ–‡æœ¬åˆ†ç±»ï¼š</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text <span class="token keyword">import</span> TfidfVectorizer
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>naive_bayes <span class="token keyword">import</span> MultinomialNB
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> accuracy_score<span class="token punctuation">,</span> classification_report

<span class="token comment"># ä½¿ç”¨TfidfVectorizerå°†æ–‡æœ¬è½¬æ¢ä¸ºTF-IDFç‰¹å¾</span>
vectorizer <span class="token operator">=</span> TfidfVectorizer<span class="token punctuation">(</span><span class="token punctuation">)</span>
X <span class="token operator">=</span> vectorizer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>text_data<span class="token punctuation">)</span>
y <span class="token operator">=</span> labels

<span class="token comment"># åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†</span>
X_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span>

<span class="token comment"># ä½¿ç”¨Multinomial Naive Bayesè¿›è¡Œæ–‡æœ¬åˆ†ç±»</span>
classifier <span class="token operator">=</span> MultinomialNB<span class="token punctuation">(</span><span class="token punctuation">)</span>
classifier<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>

<span class="token comment"># è¿›è¡Œé¢„æµ‹å’Œè¯„ä¼°</span>
y_pred <span class="token operator">=</span> classifier<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Accuracy:"</span><span class="token punctuation">,</span> accuracy_score<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Classification Report:\n"</span><span class="token punctuation">,</span> classification_report<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="_127"></a>ä¸»é¢˜å»ºæ¨¡</h3> 
<p>ä½¿ç”¨<code>gensim</code>åº“è¿›è¡Œä¸»é¢˜å»ºæ¨¡ï¼Œä¾‹å¦‚ä½¿ç”¨Latent Dirichlet Allocation (LDA)ï¼š</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> gensim <span class="token keyword">import</span> corpora<span class="token punctuation">,</span> models

<span class="token comment"># åˆ›å»ºè¯­æ–™åº“å’Œå­—å…¸</span>
corpus <span class="token operator">=</span> <span class="token punctuation">[</span>text<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> text <span class="token keyword">in</span> text_data<span class="token punctuation">]</span>
dictionary <span class="token operator">=</span> corpora<span class="token punctuation">.</span>Dictionary<span class="token punctuation">(</span>corpus<span class="token punctuation">)</span>

<span class="token comment"># å°†æ–‡æœ¬è½¬æ¢ä¸ºè¯è¢‹è¡¨ç¤º</span>
bow_corpus <span class="token operator">=</span> <span class="token punctuation">[</span>dictionary<span class="token punctuation">.</span>doc2bow<span class="token punctuation">(</span>text<span class="token punctuation">)</span> <span class="token keyword">for</span> text <span class="token keyword">in</span> corpus<span class="token punctuation">]</span>

<span class="token comment"># ä½¿ç”¨LDAè¿›è¡Œä¸»é¢˜å»ºæ¨¡</span>
lda_model <span class="token operator">=</span> models<span class="token punctuation">.</span>LdaModel<span class="token punctuation">(</span>bow_corpus<span class="token punctuation">,</span> num_topics<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> id2word<span class="token operator">=</span>dictionary<span class="token punctuation">,</span> passes<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>

<span class="token comment"># æ‰“å°ä¸»é¢˜</span>
<span class="token keyword">for</span> idx<span class="token punctuation">,</span> topic <span class="token keyword">in</span> lda_model<span class="token punctuation">.</span>print_topics<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Topic </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>idx <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>topic<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="_149"></a>æ–‡æœ¬ç”Ÿæˆ</h3> 
<p>ä½¿ç”¨å¾ªç¯ç¥ç»ç½‘ç»œ (RNN) è¿›è¡Œæ–‡æœ¬ç”Ÿæˆï¼Œä¾‹å¦‚ä½¿ç”¨<code>tensorflow</code>å’Œ<code>keras</code>ï¼š</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>models <span class="token keyword">import</span> Sequential
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> Embedding<span class="token punctuation">,</span> LSTM<span class="token punctuation">,</span> Dense
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>preprocessing<span class="token punctuation">.</span>text <span class="token keyword">import</span> Tokenizer
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>preprocessing<span class="token punctuation">.</span>sequence <span class="token keyword">import</span> pad_sequences

<span class="token comment"># ä½¿ç”¨Tokenizerå°†æ–‡æœ¬è½¬æ¢ä¸ºåºåˆ—</span>
tokenizer <span class="token operator">=</span> Tokenizer<span class="token punctuation">(</span><span class="token punctuation">)</span>
tokenizer<span class="token punctuation">.</span>fit_on_texts<span class="token punctuation">(</span>text_data<span class="token punctuation">)</span>
total_words <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>tokenizer<span class="token punctuation">.</span>word_index<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span>

<span class="token comment"># åˆ›å»ºè¾“å…¥åºåˆ—</span>
input_sequences <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> line <span class="token keyword">in</span> text_data<span class="token punctuation">:</span>
    token_list <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>texts_to_sequences<span class="token punctuation">(</span><span class="token punctuation">[</span>line<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>token_list<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        n_gram_sequence <span class="token operator">=</span> token_list<span class="token punctuation">[</span><span class="token punctuation">:</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span>
        input_sequences<span class="token punctuation">.</span>append<span class="token punctuation">(</span>n_gram_sequence<span class="token punctuation">)</span>

<span class="token comment"># å¯¹è¾“å…¥åºåˆ—è¿›è¡Œå¡«å……</span>
max_sequence_length <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token builtin">len</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> input_sequences<span class="token punctuation">]</span><span class="token punctuation">)</span>
input_sequences <span class="token operator">=</span> pad_sequences<span class="token punctuation">(</span>input_sequences<span class="token punctuation">,</span> maxlen<span class="token operator">=</span>max_sequence_length<span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'pre'</span><span class="token punctuation">)</span>

<span class="token comment"># åˆ›å»ºæ¨¡å‹</span>
model <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Embedding<span class="token punctuation">(</span>total_words<span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> input_length<span class="token operator">=</span>max_sequence_length<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>LSTM<span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span>total_words<span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># ç¼–è¯‘æ¨¡å‹</span>
model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string">'categorical_crossentropy'</span><span class="token punctuation">,</span> optimizer<span class="token operator">=</span><span class="token string">'adam'</span><span class="token punctuation">,</span> metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="_187"></a>æ–‡æœ¬å¯è§†åŒ–</h3> 
<p>ä½¿ç”¨<code>wordcloud</code>åº“åˆ¶ä½œè¯äº‘å›¾ï¼Œå±•ç¤ºè¯è¯­çš„é¢‘ç‡ï¼š</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> wordcloud <span class="token keyword">import</span> WordCloud
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

<span class="token comment"># ç”Ÿæˆè¯äº‘å›¾</span>
wordcloud <span class="token operator">=</span> WordCloud<span class="token punctuation">(</span>width<span class="token operator">=</span><span class="token number">800</span><span class="token punctuation">,</span> height<span class="token operator">=</span><span class="token number">400</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">21</span><span class="token punctuation">,</span> max_font_size<span class="token operator">=</span><span class="token number">110</span><span class="token punctuation">)</span><span class="token punctuation">.</span>generate_from_frequencies<span class="token punctuation">(</span>word_count<span class="token punctuation">)</span>

<span class="token comment"># ç»˜åˆ¶è¯äº‘å›¾</span>
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>wordcloud<span class="token punctuation">,</span> interpolation<span class="token operator">=</span><span class="token string">"bilinear"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">'off'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="_205"></a>è‡ªå®šä¹‰æ–‡æœ¬åˆ†æä»»åŠ¡</h3> 
<p>åœ¨æ–‡æœ¬æ•°æ®åˆ†æä¸­ï¼Œæœ‰æ—¶å€™éœ€è¦æ‰§è¡Œä¸€äº›å®šåˆ¶åŒ–çš„ä»»åŠ¡ï¼Œå¦‚å‘½åå®ä½“è¯†åˆ« (NER)ã€å…³é”®è¯æå–ç­‰ã€‚ä»¥ä¸‹æ˜¯ä½¿ç”¨ä¸¤ä¸ªæµè¡Œçš„åº“ï¼Œ<code>spaCy</code> å’Œ <code>bert-for-tf2</code>ï¼Œæ¥æ‰§è¡Œè¿™äº›ä»»åŠ¡çš„ç®€å•ç¤ºä¾‹ï¼š</p> 
<h4><a id="1__NER__spaCy_209"></a>1. å‘½åå®ä½“è¯†åˆ« (NER) ä½¿ç”¨ spaCy</h4> 
<pre><code class="prism language-python"><span class="token keyword">import</span> spacy

<span class="token comment"># åŠ è½½spaCyçš„è‹±æ–‡æ¨¡å‹</span>
nlp <span class="token operator">=</span> spacy<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"en_core_web_sm"</span><span class="token punctuation">)</span>

<span class="token comment"># ç¤ºä¾‹æ–‡æœ¬</span>
text <span class="token operator">=</span> <span class="token string">"Apple Inc. was founded by Steve Jobs, Steve Wozniak, and Ronald Wayne."</span>

<span class="token comment"># å¤„ç†æ–‡æœ¬å¹¶è¿›è¡Œå‘½åå®ä½“è¯†åˆ«</span>
doc <span class="token operator">=</span> nlp<span class="token punctuation">(</span>text<span class="token punctuation">)</span>

<span class="token comment"># æ‰“å°è¯†åˆ«åˆ°çš„å‘½åå®ä½“åŠå…¶ç±»å‹</span>
<span class="token keyword">for</span> ent <span class="token keyword">in</span> doc<span class="token punctuation">.</span>ents<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Entity: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>ent<span class="token punctuation">.</span>text<span class="token punctuation">}</span></span><span class="token string">, Type: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>ent<span class="token punctuation">.</span>label_<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
</code></pre> 
<h4><a id="2__bertfortf2_228"></a>2. å…³é”®è¯æå–ä½¿ç”¨ <code>bert-for-tf2</code></h4> 
<p>é¦–å…ˆï¼Œç¡®ä¿å·²ç»å®‰è£…äº† <code>bert-for-tf2</code> åº“ï¼š</p> 
<pre><code class="prism language-bash">pip <span class="token function">install</span> bert-for-tf2
</code></pre> 
<p>ç„¶åï¼Œæ‰§è¡Œä»¥ä¸‹ç¤ºä¾‹ä»£ç ï¼š</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> bert <span class="token keyword">import</span> BertModelLayer
<span class="token keyword">from</span> bert<span class="token punctuation">.</span>loader <span class="token keyword">import</span> StockBertConfig<span class="token punctuation">,</span> load_stock_weights
<span class="token keyword">from</span> transformers <span class="token keyword">import</span> BertTokenizer

<span class="token comment"># åŠ è½½ BERT æ¨¡å‹å’Œ tokenizer</span>
bert_model_name <span class="token operator">=</span> <span class="token string">'bert-base-uncased'</span>
bert_ckpt_dir <span class="token operator">=</span> <span class="token string">'path/to/bert/ckpt/directory'</span>

bert_tokenizer <span class="token operator">=</span> BertTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>bert_model_name<span class="token punctuation">)</span>
bert_config <span class="token operator">=</span> StockBertConfig<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>bert_model_name<span class="token punctuation">)</span>
bert_layer <span class="token operator">=</span> BertModelLayer<span class="token punctuation">.</span>from_params<span class="token punctuation">(</span>bert_config<span class="token punctuation">.</span>to_json<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'bert'</span><span class="token punctuation">)</span>

<span class="token comment"># ç¤ºä¾‹æ–‡æœ¬</span>
text <span class="token operator">=</span> <span class="token string">"Natural language processing (NLP) is a subfield of artificial intelligence."</span>

<span class="token comment"># åˆ©ç”¨ tokenizer ç¼–ç æ–‡æœ¬</span>
input_ids <span class="token operator">=</span> bert_tokenizer<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>text<span class="token punctuation">,</span> add_special_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment"># æ‰“å°å…³é”®è¯</span>
keywords <span class="token operator">=</span> bert_tokenizer<span class="token punctuation">.</span>convert_ids_to_tokens<span class="token punctuation">(</span>input_ids<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Keywords:"</span><span class="token punctuation">,</span> keywords<span class="token punctuation">)</span>
</code></pre> 
<h3><a id="_262"></a>æ€»ç»“</h3> 
<p>åœ¨æœ¬æ–‡ä¸­ï¼Œæ·±å…¥ç ”ç©¶äº†å¦‚ä½•åˆ©ç”¨Pythonè¿›è¡Œæ–‡æœ¬æ•°æ®åˆ†æï¼Œå¹¶æä¾›äº†è¯¦ç»†è€Œå…¨é¢çš„ç¤ºä¾‹ä»£ç ã€‚é¦–å…ˆä»‹ç»äº†æ–‡æœ¬æ•°æ®çš„è¯»å–ä¸é¢„å¤„ç†ï¼ŒåŒ…æ‹¬ä»æ–‡ä»¶è¯»å–æ–‡æœ¬ã€æ¸…ç†æ–‡æœ¬å’Œè½¬æ¢ä¸ºå°å†™ã€‚æ¥ç€ï¼Œè®¨è®ºäº†æ–‡æœ¬åˆ†æçš„æ ¸å¿ƒä»»åŠ¡ï¼ŒåŒ…æ‹¬è¯é¢‘ç»Ÿè®¡ã€æƒ…æ„Ÿåˆ†æã€æ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—å’Œæ–‡æœ¬åˆ†ç±»ï¼Œé€šè¿‡ä½¿ç”¨<code>nltk</code>ã€<code>TextBlob</code>ã€<code>scikit-learn</code>å’Œ<code>gensim</code>ç­‰åº“æä¾›äº†ä¸°å¯Œçš„ç¤ºä¾‹ã€‚</p> 
<p>è¿˜æ·±å…¥ç ”ç©¶äº†ä¸»é¢˜å»ºæ¨¡å’Œæ–‡æœ¬ç”Ÿæˆçš„ä»»åŠ¡ï¼Œåˆ†åˆ«åˆ©ç”¨<code>gensim</code>å’Œ<code>tensorflow</code>åº“å±•ç¤ºäº†å¦‚ä½•è¿›è¡Œè¿™äº›é«˜çº§çš„æ–‡æœ¬åˆ†æã€‚æ­¤å¤–ï¼Œä»‹ç»äº†ä½¿ç”¨<code>wordcloud</code>åº“åˆ¶ä½œè¯äº‘å›¾ï¼Œå°†æ–‡æœ¬æ•°æ®çš„å…³é”®è¯å¯è§†åŒ–å‘ˆç°ã€‚</p> 
<p>æœ€åï¼Œå¼ºè°ƒäº†è‡ªå®šä¹‰æ–‡æœ¬åˆ†æä»»åŠ¡çš„é‡è¦æ€§ï¼Œä¾‹å¦‚å‘½åå®ä½“è¯†åˆ« (NER) å’Œå…³é”®è¯æå–ï¼Œå¹¶ä½¿ç”¨æµè¡Œçš„åº“å¦‚<code>spaCy</code>å’Œ<code>bert-for-tf2</code>å±•ç¤ºäº†ç›¸åº”çš„ç¤ºä¾‹ä»£ç ã€‚é€šè¿‡è¿™äº›å®šåˆ¶åŒ–ä»»åŠ¡ï¼Œå¯ä»¥æ›´çµæ´»åœ°é€‚åº”ä¸åŒçš„æ–‡æœ¬åˆ†æåœºæ™¯ã€‚</p> 
<p>æ€»çš„æ¥è¯´ï¼Œæœ¬æ–‡æä¾›äº†ä¸€ä¸ªå…¨é¢çš„è§†è§’ï¼Œæ¶µç›–äº†æ–‡æœ¬æ•°æ®åˆ†æçš„å„ä¸ªæ–¹é¢ã€‚è¿™äº›ç¤ºä¾‹ä»£ç æ—¨åœ¨å¸®åŠ©å¤§å®¶æ›´å¥½åœ°ç†è§£å’Œåº”ç”¨Pythonå·¥å…·æ¥å¤„ç†å’Œåˆ†ææ–‡æœ¬æ•°æ®ï¼Œæ— è®ºæ˜¯ç®€å•çš„è¯é¢‘ç»Ÿè®¡ï¼Œè¿˜æ˜¯å¤æ‚çš„ä¸»é¢˜å»ºæ¨¡å’Œæ–‡æœ¬ç”Ÿæˆä»»åŠ¡ã€‚</p> 
<hr> 
<h2><a id="Python_273"></a>Pythonå­¦ä¹ è·¯çº¿</h2> 
<p><img src="https://images2.imgbox.com/d4/46/rnQKLHty_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<h2><a id="_275"></a>æ›´å¤šèµ„æ–™è·å–</h2> 
<p>ğŸ“š ä¸ªäººç½‘ç«™ï¼š<a href="http://ipengtao.com/" rel="nofollow">ipengtao.com</a></p> 
<p>å¦‚æœè¿˜æƒ³è¦é¢†å–æ›´å¤šæ›´ä¸°å¯Œçš„èµ„æ–™ï¼Œå¯ä»¥ç‚¹å‡»æ–‡ç« ä¸‹æ–¹åç‰‡ï¼Œå›å¤ã€<strong>ä¼˜è´¨èµ„æ–™</strong>ã€‘ï¼Œå³å¯è·å– å…¨æ–¹ä½å­¦ä¹ èµ„æ–™åŒ…ã€‚</p> 
<p><img src="https://images2.imgbox.com/00/75/QI6H82Ds_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"><br> ç‚¹å‡»æ–‡ç« ä¸‹æ–¹é“¾æ¥å¡ç‰‡ï¼Œå›å¤ã€<strong>ä¼˜è´¨èµ„æ–™</strong>ã€‘ï¼Œå¯ç›´æ¥é¢†å–èµ„æ–™å¤§ç¤¼åŒ…ã€‚</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/806bcbd4f1a60cfb3471e8d43e726240/" rel="prev">
			<span class="pager__subtitle">Â«&thinsp;Previous</span>
			<p class="pager__title">ã€pythonã€‘åŠ¨æ€å¯è§†åŒ–&#43;çˆ¬è™«ï¼ˆè¶…ç‡ƒè¶…ç®€å•ï¼‰</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/d22a749520539d3c0136b58368654d38/" rel="next">
			<span class="pager__subtitle">Next&thinsp;Â»</span>
			<p class="pager__title">ã€JAVAã€‘getterä¸setteræ–¹æ³•çš„å®šä¹‰ä¸ä½¿ç”¨</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 ç¼–ç¨‹å¤§å’–.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>