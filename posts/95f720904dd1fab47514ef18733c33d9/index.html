<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>avx sse系列介绍 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/95f720904dd1fab47514ef18733c33d9/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="avx sse系列介绍">
  <meta property="og:description" content="SSE（Streaming SIMD Extensions）家族是由英特尔引入的一组指令集扩展，用于提高多媒体、科学计算和其他领域的处理性能。SSE家族随着时间的发展，增加了多个版本和子集。以下是SSE家族的主要分类：
SSE (SSE1):
引入时间：1999年，随Pentium III处理器发布。特点：增加了70条新指令，主要用于加速浮点运算和多媒体任务。 SSE2:
引入时间：2001年，随Pentium 4处理器发布。特点：扩展了SSE1指令集，包括144条新指令，支持双精度浮点运算和整数运算。 SSE3:
引入时间：2004年，随Prescott内核的Pentium 4处理器发布。特点：增加了13条新指令，优化了线程同步和浮点数水平加法等操作。 SSSE3 (Supplemental SSE3):
引入时间：2006年，随Intel Core 2处理器发布。特点：增加了16条新指令，进一步优化了多媒体处理和加密计算。 SSE4:
SSE4.1: 引入时间：2007年，随Penryn内核的处理器发布。特点：增加了47条新指令，支持文本处理和视频编解码等任务。 SSE4.2: 引入时间：2008年，随Nehalem内核的处理器发布。特点：增加了7条新指令，进一步优化了字符串和文本处理。 SSE4a:
引入时间：2007年，随AMD K10处理器（如Phenom）发布。特点：包含4条新指令，用于加速某些特定的计算任务。需要注意的是，SSE4a是由AMD引入的，而不是英特尔。 AES-NI (Advanced Encryption Standard New Instructions):
引入时间：2010年，随Westmere内核的处理器发布。特点：虽然不完全属于SSE家族，但常与SSE相关联。AES-NI包含一组指令，用于优化AES加密算法的处理性能。 总的来说，SSE家族通过逐步增加新指令和优化现有指令，显著提高了处理器在多媒体、科学计算、加密等领域的性能。这些改进使得SSE成为了现代处理器中不可或缺的一部分。
AVX（Advanced Vector Extensions）家族是英特尔和AMD处理器中用于提高浮点和整数运算性能的一组指令集扩展。AVX家族包含多个版本和子集，每个版本都在前一版本的基础上增加了新的功能和优化。以下是AVX家族的主要分类：
AVX (AVX1):
引入时间：2011年，随英特尔Sandy Bridge处理器发布。特点：扩展了128位的SSE指令集到256位，支持更高效的浮点和整数运算。 AVX2:
引入时间：2013年，随英特尔Haswell处理器发布。特点：增加了对整数操作的支持，扩展了FMA（Fused Multiply-Add）指令，进一步提高了数据处理能力。 AVX-512:
引入时间：2016年，随英特尔Xeon Phi处理器和Skylake-X系列处理器发布。特点：扩展到512位宽度，提供更高的并行处理能力和更丰富的指令集。AVX-512包含多个子集，例如AVX-512F（基础指令）、AVX-512CD（冲突检测）、AVX-512ER（指数和倒数计算）、AVX-512PF（预取指令）等。 AVX-512子集:
AVX-512 Foundation (AVX-512F): 基础指令集，包含了最基本的512位宽向量操作指令。AVX-512 Conflict Detection Instructions (AVX-512CD): 提供冲突检测指令，主要用于优化并行算法。AVX-512 Exponential and Reciprocal Instructions (AVX-512ER): 包括指数和倒数计算的专用指令，主要用于科学计算和金融应用。AVX-512 Prefetch Instructions (AVX-512PF): 包含预取指令，用于加速内存访问。AVX-512 Byte and Word Instructions (AVX-512BW): 扩展了字节和字的操作，增加了对更小数据类型的支持。AVX-512 Vector Length Extensions (AVX-512VL): 允许使用128位和256位的向量操作，这使得它可以与AVX和AVX2指令集兼容。AVX-512 Doubleword and Quadword Instructions (AVX-512DQ): 扩展了对双字和四字操作的支持。AVX-512 Vector Bit Manipulation Instructions (AVX-512VBMI): 提供了向量比特操作的指令，主要用于数据压缩和加密。AVX-512 Vector Bit Manipulation Instructions 2 (AVX-512VBMI2): 这是AVX-512VBMI的扩展版本，增加了更多的比特操作指令。AVX-512 Population Count (AVX-512VPOPCNTDQ): 包含了向量人口计数指令，用于计算向量内每个元素的二进制1的数量。AVX-512 Neural Network Instructions (AVX-512NNI): 优化了神经网络相关的计算。AVX-512 Neural Network Instructions 2 (AVX-512NNI2): 扩展了神经网络指令集，以支持更多的神经网络操作。AVX-512 Bit Algorithms (AVX-512BITALG): 包括了一些新的比特操作算法指令。AVX-512 GFNI (AVX-512 GFNI): 包含了基于有限域的指令，主要用于加密计算。AVX-512 VP2INTERSECT (AVX-512 VP2INTERSECT): 提供了新的交集指令。 AVX-512 BFloat16 (AVX512_BF16):">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-08-11T11:40:58+08:00">
    <meta property="article:modified_time" content="2024-08-11T11:40:58+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">avx sse系列介绍</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-github-gist">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>SSE（Streaming SIMD Extensions）家族是由英特尔引入的一组指令集扩展，用于提高多媒体、科学计算和其他领域的处理性能。SSE家族随着时间的发展，增加了多个版本和子集。以下是SSE家族的主要分类：</p> 
<ol><li> <p><strong>SSE (SSE1)</strong>:</p> 
  <ul><li>引入时间：1999年，随Pentium III处理器发布。</li><li>特点：增加了70条新指令，主要用于加速浮点运算和多媒体任务。</li></ul> </li><li> <p><strong>SSE2</strong>:</p> 
  <ul><li>引入时间：2001年，随Pentium 4处理器发布。</li><li>特点：扩展了SSE1指令集，包括144条新指令，支持双精度浮点运算和整数运算。</li></ul> </li><li> <p><strong>SSE3</strong>:</p> 
  <ul><li>引入时间：2004年，随Prescott内核的Pentium 4处理器发布。</li><li>特点：增加了13条新指令，优化了线程同步和浮点数水平加法等操作。</li></ul> </li><li> <p><strong>SSSE3 (Supplemental SSE3)</strong>:</p> 
  <ul><li>引入时间：2006年，随Intel Core 2处理器发布。</li><li>特点：增加了16条新指令，进一步优化了多媒体处理和加密计算。</li></ul> </li><li> <p><strong>SSE4</strong>:</p> 
  <ul><li>SSE4.1: 
    <ul><li>引入时间：2007年，随Penryn内核的处理器发布。</li><li>特点：增加了47条新指令，支持文本处理和视频编解码等任务。</li></ul> </li><li>SSE4.2: 
    <ul><li>引入时间：2008年，随Nehalem内核的处理器发布。</li><li>特点：增加了7条新指令，进一步优化了字符串和文本处理。</li></ul> </li></ul> </li><li> <p><strong>SSE4a</strong>:</p> 
  <ul><li>引入时间：2007年，随AMD K10处理器（如Phenom）发布。</li><li>特点：包含4条新指令，用于加速某些特定的计算任务。需要注意的是，SSE4a是由AMD引入的，而不是英特尔。</li></ul> </li><li> <p><strong>AES-NI (Advanced Encryption Standard New Instructions)</strong>:</p> 
  <ul><li>引入时间：2010年，随Westmere内核的处理器发布。</li><li>特点：虽然不完全属于SSE家族，但常与SSE相关联。AES-NI包含一组指令，用于优化AES加密算法的处理性能。</li></ul> </li></ol> 
<p>总的来说，SSE家族通过逐步增加新指令和优化现有指令，显著提高了处理器在多媒体、科学计算、加密等领域的性能。这些改进使得SSE成为了现代处理器中不可或缺的一部分。</p> 
<p>AVX（Advanced Vector Extensions）家族是英特尔和AMD处理器中用于提高浮点和整数运算性能的一组指令集扩展。AVX家族包含多个版本和子集，每个版本都在前一版本的基础上增加了新的功能和优化。以下是AVX家族的主要分类：</p> 
<ol><li> <p><strong>AVX (AVX1)</strong>:</p> 
  <ul><li>引入时间：2011年，随英特尔Sandy Bridge处理器发布。</li><li>特点：扩展了128位的SSE指令集到256位，支持更高效的浮点和整数运算。</li></ul> </li><li> <p><strong>AVX2</strong>:</p> 
  <ul><li>引入时间：2013年，随英特尔Haswell处理器发布。</li><li>特点：增加了对整数操作的支持，扩展了FMA（Fused Multiply-Add）指令，进一步提高了数据处理能力。</li></ul> </li><li> <p><strong>AVX-512</strong>:</p> 
  <ul><li>引入时间：2016年，随英特尔Xeon Phi处理器和Skylake-X系列处理器发布。</li><li>特点：扩展到512位宽度，提供更高的并行处理能力和更丰富的指令集。AVX-512包含多个子集，例如AVX-512F（基础指令）、AVX-512CD（冲突检测）、AVX-512ER（指数和倒数计算）、AVX-512PF（预取指令）等。</li></ul> </li><li> <p><strong>AVX-512子集</strong>:</p> 
  <ul><li><strong>AVX-512 Foundation (AVX-512F)</strong>: 基础指令集，包含了最基本的512位宽向量操作指令。</li><li><strong>AVX-512 Conflict Detection Instructions (AVX-512CD)</strong>: 提供冲突检测指令，主要用于优化并行算法。</li><li><strong>AVX-512 Exponential and Reciprocal Instructions (AVX-512ER)</strong>: 包括指数和倒数计算的专用指令，主要用于科学计算和金融应用。</li><li><strong>AVX-512 Prefetch Instructions (AVX-512PF)</strong>: 包含预取指令，用于加速内存访问。</li><li><strong>AVX-512 Byte and Word Instructions (AVX-512BW)</strong>: 扩展了字节和字的操作，增加了对更小数据类型的支持。</li><li><strong>AVX-512 Vector Length Extensions (AVX-512VL)</strong>: 允许使用128位和256位的向量操作，这使得它可以与AVX和AVX2指令集兼容。</li><li><strong>AVX-512 Doubleword and Quadword Instructions (AVX-512DQ)</strong>: 扩展了对双字和四字操作的支持。</li><li><strong>AVX-512 Vector Bit Manipulation Instructions (AVX-512VBMI)</strong>: 提供了向量比特操作的指令，主要用于数据压缩和加密。</li><li><strong>AVX-512 Vector Bit Manipulation Instructions 2 (AVX-512VBMI2)</strong>: 这是AVX-512VBMI的扩展版本，增加了更多的比特操作指令。</li><li><strong>AVX-512 Population Count (AVX-512VPOPCNTDQ)</strong>: 包含了向量人口计数指令，用于计算向量内每个元素的二进制1的数量。</li><li><strong>AVX-512 Neural Network Instructions (AVX-512NNI)</strong>: 优化了神经网络相关的计算。</li><li><strong>AVX-512 Neural Network Instructions 2 (AVX-512NNI2)</strong>: 扩展了神经网络指令集，以支持更多的神经网络操作。</li><li><strong>AVX-512 Bit Algorithms (AVX-512BITALG)</strong>: 包括了一些新的比特操作算法指令。</li><li><strong>AVX-512 GFNI (AVX-512 GFNI)</strong>: 包含了基于有限域的指令，主要用于加密计算。</li><li><strong>AVX-512 VP2INTERSECT (AVX-512 VP2INTERSECT)</strong>: 提供了新的交集指令。</li></ul> </li><li> <p><strong>AVX-512 BFloat16 (AVX512_BF16)</strong>:</p> 
  <ul><li>引入时间：2020年，随英特尔Cooper Lake处理器发布。</li><li>特点：支持BFloat16格式的浮点运算，用于提高机器学习和人工智能任务的性能。</li></ul> </li><li> <p><strong>AVX-512 VPCLMULQDQ (AVX-512 VPCLMULQDQ)</strong>:</p> 
  <ul><li>特点：提供了矢量化的PCLMULQDQ指令，用于加速加密算法中的乘法操作。</li></ul> </li><li> <p><strong>AVX-512 IFMA (AVX-512 IFMA)</strong>:</p> 
  <ul><li>特点：提供了整数FMA（Fused Multiply-Add）指令，主要用于加密和大整数运算。</li></ul> </li></ol> 
<p>AVX家族通过不断扩展和优化，显著提高了处理器在科学计算、机器学习、多媒体处理和加密等领域的性能。这些改进使得AVX成为了现代高性能计算不可或缺的一部分。<br> AMX（Advanced Matrix Extensions）是英特尔（Intel）引入的一组指令集扩展，旨在加速矩阵计算，特别是用于人工智能（AI）和机器学习（ML）工作负载。AMX指令集是英特尔的高级矢量扩展（AVX）系列的一部分，进一步增强了处理单元对复杂矩阵操作的效率。</p> 
<p>以下是一些关于AMX指令集的关键点：</p> 
<p>矩阵计算加速：<br> AMX专门用于加速矩阵乘法和其他相关操作，这些操作在深度学习和其他AI算法中非常常见。</p> 
<p>Tile-Based Architecture：<br> AMX引入了一种称为“tiles”的新型寄存器结构，这些寄存器用来存储矩阵数据。每个tile寄存器可以存储一个固定大小的矩阵块，从而可以高效地进行大规模矩阵计算。</p> 
<pre><code>// mul
        template &lt;class A, class T, class = typename std::enable_if&lt;std::is_integral&lt;T&gt;::value, void&gt;::type&gt;
        inline batch&lt;T, A&gt; mul(batch&lt;T, A&gt; const&amp; self, batch&lt;T, A&gt; const&amp; other, requires_arch&lt;avx512bw&gt;) noexcept
        {
            if constexpr(sizeof(T) == 1)
            {
                __m512i upper = _mm512_and_si512(_mm512_mullo_epi16(self, other), _mm512_srli_epi16(_mm512_set1_epi16(-1), 8));
                __m512i lower = _mm512_slli_epi16(_mm512_mullo_epi16(_mm512_srli_epi16(self, 8), _mm512_srli_epi16(other, 8)), 8);
                return _mm512_or_si512(upper, lower);
            }
            else if constexpr(sizeof(T) == 2)
            {
                return _mm512_mullo_epi16(self, other);
            }
            else
            {
                return mul(self, other, avx512dq {});
            }
        }

</code></pre> 
<h3><a id="_111"></a>参考</h3> 
<ul><li><a href="https://github1s.com/Nic-bit/turbo/blob/master/turbo/simd/arch/avx512bw.h#L299-L318" rel="nofollow">turbo/simd</a></li><li><a href="https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html#ig_expand=5811,325,40,40,10,11,34&amp;text=abs&amp;avx512techs=AVX512F" rel="nofollow">intrinsics-guide</a></li></ul>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/e8a509bbf5dd70b4e2acfde56b0493eb/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【多线程】乐观/悲观锁、重量级/轻量级锁、挂起等待/自旋锁、公平/非公锁、可重入/不可重入锁、读写锁</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/f7ec5274b0c3f26d67f048f232d49fec/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">二叉树相关的算法题</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>