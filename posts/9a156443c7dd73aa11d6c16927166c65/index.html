<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【机器学习】K-means&#43;&#43;: 一种改进的聚类算法详解 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/9a156443c7dd73aa11d6c16927166c65/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="【机器学习】K-means&#43;&#43;: 一种改进的聚类算法详解">
  <meta property="og:description" content="🌈个人主页: 鑫宝Code
🔥热门专栏: 闲话杂谈｜ 炫酷HTML | JavaScript基础 ​💫个人格言: &#34;如无必要，勿增实体&#34; 文章目录 K-means&#43;&#43;: 一种改进的聚类算法详解引言1. K-means算法回顾1.1 基本概念1.2 局限性 2. K-means&#43;&#43;算法介绍2.1 初始质心选择策略2.2 算法优势 3. K-means&#43;&#43;算法实现步骤3.1 准备工作3.2 初始化质心3.3 迭代优化3.4 结果评估 4. 实际应用案例4.1 数据降维4.2 客户细分4.3 文档分类 5. 总结 K-means&#43;&#43;: 一种改进的聚类算法详解 引言 在数据分析与机器学习领域，聚类算法作为无监督学习的重要组成部分，被广泛应用于数据分组、模式识别和数据挖掘等场景。其中，K-means算法以其简单直观和高效的特点，成为最常用的聚类方法之一。然而，经典K-means算法在初始聚类中心的选择上存在随机性，可能导致算法陷入局部最优解。为解决这一问题，2007年，David Arthur 和 Sergei Vassilvitskii 提出了K-means&#43;&#43;算法，它通过一种智能化的初始化策略显著提高了聚类质量。本文将深入探讨K-means&#43;&#43;算法的原理、优势、实现步骤以及实际应用案例，旨在为读者提供一个全面且易于理解的K-means&#43;&#43;算法指南。
1. K-means算法回顾 1.1 基本概念 K-means算法的目标是将数据集划分为K个簇（clusters），每个簇由距离其质心（centroid）最近的数据点组成。算法迭代执行以下两个步骤直至收敛：
分配步骤：将每个数据点分配给最近的质心。更新步骤：重新计算每个簇的质心，即该簇所有点的均值。 1.2 局限性 对初始质心敏感：随机选择的初始质心可能导致算法陷入局部最优解。不适合处理不规则形状的簇：倾向于形成球形或凸形簇。难以处理大小和密度变化较大的簇。 2. K-means&#43;&#43;算法介绍 2.1 初始质心选择策略 K-means&#43;&#43;算法的核心改进在于其初始化过程，具体步骤如下：
从数据集中随机选择第一个质心。对于每个数据点x，计算其到已选择的所有质心的最短距离D(x)。选择一个新的数据点作为下一个质心，选择的概率与D(x)成正比，即概率P(x) = D(x) / ΣD(x)。重复步骤2和3，直到选择了K个质心。 这种选择策略确保了质心之间的分散性，从而提高了聚类效果。
2.2 算法优势 减少局部最优解的风险：更大概率选择相距较远的初始质心，提高聚类质量。理论保证：K-means&#43;&#43;能够给出接近最优解的界，即与最优聚类方案的距离平方误差最多是理论最小值的8倍。效率：虽然初始化复杂度有所增加，但整体算法依然保持高效，尤其是对于大规模数据集。 3. K-means&#43;&#43;算法实现步骤 3.1 准备工作 确定K值：根据实际需求预先设定簇的数量。数据预处理：标准化或归一化数据，以消除量纲影响。 3.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-06-27T08:27:04+08:00">
    <meta property="article:modified_time" content="2024-06-27T08:27:04+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【机器学习】K-means&#43;&#43;: 一种改进的聚类算法详解</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-tomorrow-night">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <hr> 
<img src="https://images2.imgbox.com/7f/98/fJT2lx5f_o.png" alt="鑫宝Code" width="150px"> 
<br> 
<img src="https://images2.imgbox.com/62/76/bT85i6hj_o.gif" width="300px"> 
<br> 
<p> <font color="#0099ff" size="3" face="粗体"><strong>🌈个人主页: <a href="https://xinbaocode.blog.csdn.net/" rel="nofollow">鑫宝Code</a></strong></font><br> <font color="#0099ff" size="3" face="粗体"><strong>🔥热门专栏: <a href="https://xinbaocode.blog.csdn.net/category_12565077.html" rel="nofollow">闲话杂谈</a>｜ <a href="https://xinbaocode.blog.csdn.net/category_12578048.html" rel="nofollow">炫酷HTML</a> | <a href="https://xinbaocode.blog.csdn.net/category_12578047.html" rel="nofollow">JavaScript基础</a> </strong></font><br> ​<font color="#0099ff" size="3" face="粗体"><strong>💫个人格言: "如无必要，勿增实体" </strong></font> <br><br> <img src="https://images2.imgbox.com/5e/98/F0LCTeZ2_o.gif" width="100%"> </p> 
<hr> 
<p></p> 
<p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#Kmeans__40" rel="nofollow">K-means++: 一种改进的聚类算法详解</a></li><li><ul><li><a href="#_43" rel="nofollow">引言</a></li><li><a href="#1_Kmeans_47" rel="nofollow">1. K-means算法回顾</a></li><li><ul><li><a href="#11__50" rel="nofollow">1.1 基本概念</a></li><li><a href="#12__57" rel="nofollow">1.2 局限性</a></li></ul> 
   </li><li><a href="#2_Kmeans_63" rel="nofollow">2. K-means++算法介绍</a></li><li><ul><li><a href="#21__65" rel="nofollow">2.1 初始质心选择策略</a></li><li><a href="#22__76" rel="nofollow">2.2 算法优势</a></li></ul> 
   </li><li><a href="#3_Kmeans_82" rel="nofollow">3. K-means++算法实现步骤</a></li><li><ul><li><a href="#31__84" rel="nofollow">3.1 准备工作</a></li><li><a href="#32__89" rel="nofollow">3.2 初始化质心</a></li><li><a href="#33__93" rel="nofollow">3.3 迭代优化</a></li><li><a href="#34__99" rel="nofollow">3.4 结果评估</a></li></ul> 
   </li><li><a href="#4__138" rel="nofollow">4. 实际应用案例</a></li><li><ul><li><a href="#41__140" rel="nofollow">4.1 数据降维</a></li><li><a href="#42__144" rel="nofollow">4.2 客户细分</a></li><li><a href="#43__148" rel="nofollow">4.3 文档分类</a></li></ul> 
   </li><li><a href="#5__152" rel="nofollow">5. 总结</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h2><a id="Kmeans__40"></a>K-means++: 一种改进的聚类算法详解</h2> 
<p><img src="https://images2.imgbox.com/2d/2d/LFbpivbZ_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="_43"></a>引言</h3> 
<p>在数据分析与机器学习领域，聚类算法作为无监督学习的重要组成部分，被广泛应用于数据分组、模式识别和数据挖掘等场景。其中，K-means算法以其简单直观和高效的特点，成为最常用的聚类方法之一。然而，经典K-means算法在初始聚类中心的选择上存在随机性，可能导致算法陷入局部最优解。为解决这一问题，2007年，David Arthur 和 Sergei Vassilvitskii 提出了K-means++算法，它通过一种智能化的初始化策略显著提高了聚类质量。本文将深入探讨K-means++算法的原理、优势、实现步骤以及实际应用案例，旨在为读者提供一个全面且易于理解的K-means++算法指南。</p> 
<h3><a id="1_Kmeans_47"></a>1. K-means算法回顾</h3> 
<p><img src="https://images2.imgbox.com/cc/26/u9JI5Lr0_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="11__50"></a>1.1 基本概念</h4> 
<p>K-means算法的目标是将数据集划分为K个簇（clusters），每个簇由距离其质心（centroid）最近的数据点组成。算法迭代执行以下两个步骤直至收敛：</p> 
<ul><li><strong>分配步骤</strong>：将每个数据点分配给最近的质心。</li><li><strong>更新步骤</strong>：重新计算每个簇的质心，即该簇所有点的均值。</li></ul> 
<h4><a id="12__57"></a>1.2 局限性</h4> 
<ul><li><strong>对初始质心敏感</strong>：随机选择的初始质心可能导致算法陷入局部最优解。</li><li><strong>不适合处理不规则形状的簇</strong>：倾向于形成球形或凸形簇。</li><li><strong>难以处理大小和密度变化较大的簇</strong>。</li></ul> 
<h3><a id="2_Kmeans_63"></a>2. K-means++算法介绍</h3> 
<h4><a id="21__65"></a>2.1 初始质心选择策略</h4> 
<p>K-means++算法的核心改进在于其初始化过程，具体步骤如下：</p> 
<ol><li><strong>从数据集中随机选择第一个质心</strong>。</li><li>对于每个数据点<code>x</code>，计算其到已选择的所有质心的最短距离<code>D(x)</code>。</li><li>选择一个新的数据点作为下一个质心，选择的概率与<code>D(x)</code>成正比，即概率<code>P(x)</code> = <code>D(x)</code> / Σ<code>D(x)</code>。</li><li>重复步骤2和3，直到选择了K个质心。</li></ol> 
<p>这种选择策略确保了质心之间的分散性，从而提高了聚类效果。</p> 
<h4><a id="22__76"></a>2.2 算法优势</h4> 
<ul><li><strong>减少局部最优解的风险</strong>：更大概率选择相距较远的初始质心，提高聚类质量。</li><li><strong>理论保证</strong>：K-means++能够给出接近最优解的界，即与最优聚类方案的距离平方误差最多是理论最小值的8倍。</li><li><strong>效率</strong>：虽然初始化复杂度有所增加，但整体算法依然保持高效，尤其是对于大规模数据集。</li></ul> 
<h3><a id="3_Kmeans_82"></a>3. K-means++算法实现步骤</h3> 
<h4><a id="31__84"></a>3.1 准备工作</h4> 
<ul><li><strong>确定K值</strong>：根据实际需求预先设定簇的数量。</li><li><strong>数据预处理</strong>：标准化或归一化数据，以消除量纲影响。</li></ul> 
<h4><a id="32__89"></a>3.2 初始化质心</h4> 
<ul><li>按照K-means++策略选取K个初始质心。</li></ul> 
<h4><a id="33__93"></a>3.3 迭代优化</h4> 
<ol><li><strong>分配数据点</strong>：将每个数据点分配给最近的质心。</li><li><strong>更新质心</strong>：根据新分配结果，重新计算每个簇的质心。</li><li><strong>检查收敛</strong>：如果质心位置变化不大于预定阈值或达到最大迭代次数，则停止迭代。</li></ol> 
<h4><a id="34__99"></a>3.4 结果评估</h4> 
<ul><li>使用如轮廓系数、Calinski-Harabasz指数等评价指标评估聚类质量</li></ul> 
<p>下面是一个使用Python和scikit-learn库实现K-means++算法的示例代码。首先，确保你已经安装了scikit-learn库，如果没有安装，可以通过运行<code>pip install scikit-learn</code>来安装。代码仅供参考</p> 
<pre><code class="prism language-py"><span class="token comment"># 导入所需库</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>cluster <span class="token keyword">import</span> KMeans
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> make_blobs

<span class="token comment"># 生成模拟数据</span>
<span class="token comment"># 这里我们创建一个包含3个类别的数据集，每个类别有不同数量的点和方差</span>
X<span class="token punctuation">,</span> _ <span class="token operator">=</span> make_blobs<span class="token punctuation">(</span>n_samples<span class="token operator">=</span><span class="token number">300</span><span class="token punctuation">,</span> centers<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> cluster_std<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">1.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span>

<span class="token comment"># 使用KMeans++算法进行聚类</span>
kmeans_plus <span class="token operator">=</span> KMeans<span class="token punctuation">(</span>n_clusters<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> init<span class="token operator">=</span><span class="token string">'k-means++'</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span> <span class="token comment"># 'k-means++' 是关键参数</span>
kmeans_plus<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">)</span>

<span class="token comment"># 可视化结果</span>
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 绘制原始数据点</span>
plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'grey'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Original Data'</span><span class="token punctuation">)</span>

<span class="token comment"># 绘制K-means++聚类结果</span>
plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> c<span class="token operator">=</span>kmeans_plus<span class="token punctuation">.</span>labels_<span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">'viridis'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>kmeans_plus<span class="token punctuation">.</span>cluster_centers_<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> kmeans_plus<span class="token punctuation">.</span>cluster_centers_<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">300</span><span class="token punctuation">,</span> c<span class="token operator">=</span><span class="token string">'red'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'Centroids'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'K-means++ Clustering Result'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p>这段代码首先生成了一个具有三个聚类中心的二维模拟数据集，然后使用scikit-learn的KMeans类，并设置<code>init='k-means++'</code>来应用<code>K-means++</code>初始化策略进行聚类。最后，通过matplotlib库可视化了原始数据点和聚类后的结果，其中红色点表示各个簇的质心。这个例子简洁地展示了如何在Python中实施K-means++算法并评估其效果。</p> 
<h3><a id="4__138"></a>4. 实际应用案例</h3> 
<h4><a id="41__140"></a>4.1 数据降维</h4> 
<ul><li>在PCA（主成分分析）之前，使用K-means++进行初步聚类，可以有效降低数据维度，提高后续分析效率。<br> <img src="https://images2.imgbox.com/e9/46/RTi005kc_o.png" alt="在这里插入图片描述"></li></ul> 
<h4><a id="42__144"></a>4.2 客户细分</h4> 
<ul><li>在市场营销中，通过对客户消费行为数据进行K-means++聚类，企业可以识别不同的客户群体，定制个性化营销策略。</li></ul> 
<h4><a id="43__148"></a>4.3 文档分类</h4> 
<ul><li>在文本挖掘领域，利用K-means++对文档向量化后的特征进行聚类，有助于自动分类和主题发现。</li></ul> 
<h3><a id="5__152"></a>5. 总结</h3> 
<p>K-means++算法通过一种更加智能的初始化策略，显著改善了经典K-means算法的性能，尤其在解决初始质心选择的随机性和局部最优问题上表现出色。它不仅在理论上提供了性能保证，而且在实践中广泛应用于多个领域，展现了强大的实用价值。随着大数据和机器学习技术的发展，K-means++及其变种将继续在数据科学中扮演重要角色。</p> 
<img src="https://images2.imgbox.com/1f/84/enqqe1JN_o.png" width="250" height="250"> 
<p> <img src="https://images2.imgbox.com/52/df/QueIZZJR_o.gif" alt="End"> </p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/65f0bf840f79d693c939d07eb6a615fc/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">VUE JS 将html转成pdf 例子</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/4e94880dce3f11c7d30afbf03529c7e4/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">SpringMVC 请求参数接收</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>