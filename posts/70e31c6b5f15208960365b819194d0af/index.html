<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>ONNX格式模型 学习笔记 (onnxRuntime部署)---用java调用yolov8模型来举例 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/70e31c6b5f15208960365b819194d0af/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="ONNX格式模型 学习笔记 (onnxRuntime部署)---用java调用yolov8模型来举例">
  <meta property="og:description" content="ONNX（Open Neural Network Exchange）是一个开源项目，旨在建立一个开放的标准，使深度学习模型可以在不同的软件平台和工具之间轻松移动和重用。
ONNX模型可以用于各种应用场景，例如机器翻译、图像识别、语音识别、自然语言处理等。
由于ONNX模型的互操作性，开发人员可以使用不同的框架来训练，模型可以更容易地在不同的框架之间转换，例如从PyTorch转换到TensorFlow，或从TensorFlow转换到MXNet等。然后将其部署到不同的环境中，例如云端、边缘设备或移动设备等。
ONNX还提供了一组工具和库，帮助开发人员更容易地创建、训练和部署深度学习模型。
ONNX模型是由多个节点（node）组成的图（graph），每个节点代表一个操作或一个张量（tensor）。ONNX模型还包含了一些元数据，例如模型的版本、输入和输出张量的名称等。
onnx官网 ONNX | Home
pytorch官方使用onnx模型格式举例 (optional) Exporting a Model from PyTorch to ONNX and Running it using ONNX Runtime — PyTorch Tutorials 2.2.0&#43;cu121 documentation
TensorFlow官方使用onnx模型格式举例 https://github.com/onnx/tutorials/blob/master/tutorials/TensorflowToOnnx-1.ipynb
Netron可视化模型结构工具 Netron
你可通过该工具看到onnx具体的模型结构，点击每层都能看到其对应的内容信息
onnxRuntime | 提供各种编程语言推导onnx格式模型的接口 ONNX Runtime | Home
比如我需要在java环境下调用一个onnx模型，我可以先导入onnxRuntime的依赖，对数据预处理后，调用onnx格式模型正向传播导出数据，然后将数据处理成我要的数据。 onnxRuntime也提供了其他编程语言的接口，如C&#43;&#43;、C#、JavaScript、python等等。
实际案例举例 python部分 python下利用ultralytics从网上下载并导出yolov8的onnx格式模型，用java调用onnxruntim接口，正向传播推导模型数据。
pip install ultralytics from ultralytics import YOLO # 加载模型 model = YOLO(&#39;yolov8n.pt&#39;) # 加载官方模型 #加载自定义训练的模型 #model = YOLO(&#39;F:\\File\\AI\\Object\\yolov8_test\\runs\\detect\\train\\weights\\best.pt&#39;) # 导出模型 model.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2023-12-26T22:27:32+08:00">
    <meta property="article:modified_time" content="2023-12-26T22:27:32+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">ONNX格式模型 学习笔记 (onnxRuntime部署)---用java调用yolov8模型来举例</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p><img alt="" height="109" src="https://images2.imgbox.com/4f/85/ELIdTWEj_o.png" width="452"></p> 
<p>ONNX（Open Neural Network Exchange）是一个开源项目，旨在建立一个开放的标准，使深度学习模型<strong>可以在不同的软件平台和工具之间轻松移动和重用</strong>。</p> 
<p>ONNX模型可以用于各种应用场景，例如机器翻译、图像识别、语音识别、自然语言处理等。</p> 
<p>由于ONNX模型的互操作性，开发人员<span style="color:#fe2c24;"><strong>可以使用不同的框架来训练，模型可以更容易地在不同的框架之间转换</strong>，例如从PyTorch转换到TensorFlow，或从TensorFlow转换到MXNet等。<strong>然后将其部署到不同的环境中</strong>，例如云端、边缘设备或移动设备等</span>。</p> 
<p>ONNX还提供了一组工具和库，帮助开发人员<strong>更容易地创建、训练和部署深度学习模型。</strong></p> 
<p>ONNX模型是由多个节点（node）组成的图（graph），每个节点代表一个操作或一个张量（tensor）。ONNX模型还包含了一些元数据，例如模型的版本、输入和输出张量的名称等。</p> 
<p></p> 
<h3>onnx官网</h3> 
<p><a href="https://onnx.ai/" rel="nofollow" title="ONNX | Home">ONNX | Home</a></p> 
<p></p> 
<h3><strong>pytorch官方使用onnx模型格式举例</strong></h3> 
<p><a href="https://pytorch.org/tutorials/advanced/super_resolution_with_onnxruntime.html" rel="nofollow" title="(optional) Exporting a Model from PyTorch to ONNX and Running it using ONNX Runtime — PyTorch Tutorials 2.2.0+cu121 documentation">(optional) Exporting a Model from PyTorch to ONNX and Running it using ONNX Runtime — PyTorch Tutorials 2.2.0+cu121 documentation</a></p> 
<h4></h4> 
<h3>TensorFlow<strong>官方使用onnx模型格式举例</strong></h3> 
<p><a href="https://github.com/onnx/tutorials/blob/master/tutorials/TensorflowToOnnx-1.ipynb" title="https://github.com/onnx/tutorials/blob/master/tutorials/TensorflowToOnnx-1.ipynb">https://github.com/onnx/tutorials/blob/master/tutorials/TensorflowToOnnx-1.ipynb</a></p> 
<h4></h4> 
<h3>Netron可视化模型结构工具</h3> 
<p><a href="https://netron.app/" rel="nofollow" title="Netron">Netron</a></p> 
<p>你可通过该工具看到onnx具体的模型结构，点击每层都能看到其对应的内容信息</p> 
<p><img alt="" height="283" src="https://images2.imgbox.com/ef/18/ApMF6cqs_o.png" width="386"></p> 
<p></p> 
<h3><strong>onnxRuntime  | 提供各种编程语言推导onnx格式模型的接口</strong></h3> 
<p><a href="https://onnxruntime.ai/" rel="nofollow" title="ONNX Runtime | Home">ONNX Runtime | Home</a></p> 
<p>比如我需要在java环境下调用一个onnx模型，我可以先导入onnxRuntime的依赖，对数据预处理后，调用onnx格式模型正向传播导出数据，然后将数据处理成我要的数据。 </p> 
<p>onnxRuntime也提供了其他编程语言的接口，如C++、C#、JavaScript、python等等。</p> 
<p></p> 
<p></p> 
<p></p> 
<h3>实际案例举例</h3> 
<h4>python部分</h4> 
<p>python下利用ultralytics从网上下载并导出yolov8的onnx格式模型，用java调用onnxruntim接口，正向传播推导模型数据。</p> 
<pre><code class="hljs">pip install ultralytics</code></pre> 
<pre><code class="language-python">from ultralytics import YOLO

# 加载模型
model = YOLO('yolov8n.pt')  # 加载官方模型
#加载自定义训练的模型
#model = YOLO('F:\\File\\AI\\Object\\yolov8_test\\runs\\detect\\train\\weights\\best.pt')  

# 导出模型
model.export(format='onnx')</code></pre> 
<p></p> 
<h4>java部分</h4> 
<p>前提安装java的opencv（<a href="https://opencv.org/get-started/" rel="nofollow" title="Get Started - OpenCV">Get Started - OpenCV</a>），我这安装的是opencv480</p> 
<p>maven依赖</p> 
<pre><code class="hljs">&lt;dependencies&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;com.microsoft.onnxruntime&lt;/groupId&gt;
            &lt;artifactId&gt;onnxruntime&lt;/artifactId&gt;
            &lt;version&gt;1.12.0&lt;/version&gt;
        &lt;/dependency&gt;


        &lt;!-- 加载lib目录下的opencv包 --&gt;
        &lt;dependency&gt;
            &lt;groupId&gt;org.opencv&lt;/groupId&gt;
            &lt;artifactId&gt;opencv&lt;/artifactId&gt;
            &lt;version&gt;4.8.0&lt;/version&gt;
            &lt;scope&gt;system&lt;/scope&gt;
            &lt;!--通过路径加载OpenCV480的jar包--&gt;
            &lt;systemPath&gt;${basedir}/lib/opencv-480.jar&lt;/systemPath&gt;
        &lt;/dependency&gt;


        &lt;dependency&gt;
            &lt;groupId&gt;com.alibaba&lt;/groupId&gt;
            &lt;artifactId&gt;fastjson&lt;/artifactId&gt;
            &lt;version&gt;2.0.32&lt;/version&gt;
        &lt;/dependency&gt;
&lt;/dependencies&gt;</code></pre> 
<p>java完整代码</p> 
<pre><code class="language-java">package com.sky;

//天宇 2023/12/21 20:23:13


import ai.onnxruntime.*;
import com.alibaba.fastjson.JSONObject;
import org.opencv.core.*;
import org.opencv.core.Point;
import org.opencv.highgui.HighGui;
import org.opencv.imgcodecs.Imgcodecs;
import org.opencv.imgproc.Imgproc;

import java.nio.FloatBuffer;
import java.text.DecimalFormat;
import java.util.*;
import java.util.List;

/**
 * onnx学习笔记  GTianyu
 */
public class onnxLoadTest01 {
    public static OrtEnvironment env;
    public static OrtSession session;
    public static JSONObject names;
    public static long count;
    public static long channels;
    public static long netHeight;
    public static long netWidth;
    public static  float srcw;
    public static  float srch;
    public static float confThreshold = 0.25f;
    public static float nmsThreshold = 0.5f;
    static Mat src;

    public static void load(String path) {
         String weight = path;
        try{
            env = OrtEnvironment.getEnvironment();
            session = env.createSession(weight, new OrtSession.SessionOptions());
            OnnxModelMetadata metadata = session.getMetadata();
            Map&lt;String, NodeInfo&gt; infoMap = session.getInputInfo();
            TensorInfo nodeInfo = (TensorInfo)infoMap.get("images").getInfo();
            String nameClass = metadata.getCustomMetadata().get("names");
            System.out.println("getProducerName="+metadata.getProducerName());
            System.out.println("getGraphName="+metadata.getGraphName());
            System.out.println("getDescription="+metadata.getDescription());
            System.out.println("getDomain="+metadata.getDomain());
            System.out.println("getVersion="+metadata.getVersion());
            System.out.println("getCustomMetadata="+metadata.getCustomMetadata());
            System.out.println("getInputInfo="+infoMap);
            System.out.println("nodeInfo="+nodeInfo);
            System.out.println(nameClass);
            names = JSONObject.parseObject(nameClass.replace("\"","\"\""));
            count = nodeInfo.getShape()[0];//1 模型每次处理一张图片
            channels = nodeInfo.getShape()[1];//3 模型通道数
            netHeight = nodeInfo.getShape()[2];//640 模型高
            netWidth = nodeInfo.getShape()[3];//640 模型宽
            System.out.println(names.get(0));
            // 加载opencc需要的动态库
            System.loadLibrary(Core.NATIVE_LIBRARY_NAME);
        }
        catch (Exception e){
            e.printStackTrace();
            System.exit(0);
        }
    }


    public static Map&lt;Object, Object&gt; predict(String imgPath) throws Exception {
        src=Imgcodecs.imread(imgPath);
        return predictor();
    }

    public static Map&lt;Object, Object&gt; predict(Mat mat) throws Exception {
        src=mat;
        return predictor();
    }


    public static OnnxTensor transferTensor(Mat dst){
        Imgproc.cvtColor(dst, dst, Imgproc.COLOR_BGR2RGB);
        dst.convertTo(dst, CvType.CV_32FC1, 1. / 255);
        float[] whc = new float[ Long.valueOf(channels).intValue() * Long.valueOf(netWidth).intValue() * Long.valueOf(netHeight).intValue() ];
        dst.get(0, 0, whc);
        float[] chw = whc2cwh(whc);
        OnnxTensor tensor = null;
        try {
            tensor = OnnxTensor.createTensor(env, FloatBuffer.wrap(chw), new long[]{count,channels,netWidth,netHeight});
        }
        catch (Exception e){
            e.printStackTrace();
            System.exit(0);
        }
        return tensor;
    }


    //宽 高 类型 to 类 宽 高
    public static float[] whc2cwh(float[] src) {
        float[] chw = new float[src.length];
        int j = 0;
        for (int ch = 0; ch &lt; 3; ++ch) {
            for (int i = ch; i &lt; src.length; i += 3) {
                chw[j] = src[i];
                j++;
            }
        }
        return chw;
    }

    public static Map&lt;Object, Object&gt; predictor() throws Exception{
        srcw = src.width();
        srch = src.height();
        System.out.println("width:"+srcw+" hight:"+srch);
        System.out.println("resize: \n width:"+netWidth+" hight:"+netHeight);
        float scaleW=srcw/netWidth;
        float scaleH=srch/netHeight;
        // resize
        Mat dst=new Mat();
        Imgproc.resize(src, dst, new Size(netWidth, netHeight));
        // 转换成Tensor数据格式
        OnnxTensor tensor = transferTensor(dst);
        OrtSession.Result result = session.run(Collections.singletonMap("images", tensor));
        System.out.println("res Data: "+result.get(0));
        OnnxTensor res = (OnnxTensor)result.get(0);
        float[][][] dataRes = (float[][][])res.getValue();
        float[][] data = dataRes[0];

        // 将矩阵转置
        // 先将xywh部分转置
        float rawData[][]=new float[data[0].length][6];
        System.out.println(data.length-1);
        for(int i=0;i&lt;4;i++){
            for(int j=0;j&lt;data[0].length;j++){
                rawData[j][i]=data[i][j];
            }
        }
        // 保存每个检查框置信值最高的类型置信值和该类型下标
        for(int i=0;i&lt;data[0].length;i++){
            for(int j=4;j&lt;data.length;j++){
                if(rawData[i][4]&lt;data[j][i]){
                    rawData[i][4]=data[j][i];           //置信值
                    rawData[i][5]=j-4;                  //类型编号
                }
            }
        }
        List&lt;ArrayList&lt;Float&gt;&gt; boxes=new LinkedList&lt;ArrayList&lt;Float&gt;&gt;();
        ArrayList&lt;Float&gt; box=null;
        // 置信值过滤,xywh转xyxy
        for(float[] d:rawData){
            // 置信值过滤
            if(d[4]&gt;confThreshold){
                // xywh(xy为中心点)转xyxy
                d[0]=d[0]-d[2]/2;
                d[1]=d[1]-d[3]/2;
                d[2]=d[0]+d[2];
                d[3]=d[1]+d[3];
                // 置信值符合的进行插入法排序保存
                box=new ArrayList&lt;Float&gt;();
                for(float num:d) {
                    box.add(num);
                }
                if(boxes.size()==0){
                    boxes.add(box);
                }else {
                    int i;
                    for(i=0;i&lt;boxes.size();i++){
                        if(box.get(4)&gt;boxes.get(i).get(4)){
                            boxes.add(i,box);
                            break;
                        }
                    }
                    // 插入到最后
                    if(i==boxes.size()){
                        boxes.add(box);
                    }
                }
            }
        }

        // 每个框分别有x1、x1、x2、y2、conf、class
        //System.out.println(boxes);

        // 非极大值抑制
        int[] indexs=new int[boxes.size()];
        Arrays.fill(indexs,1);                       //用于标记1保留，0删除
        for(int cur=0;cur&lt;boxes.size();cur++){
            if(indexs[cur]==0){
                continue;
            }
            ArrayList&lt;Float&gt; curMaxConf=boxes.get(cur);   //当前框代表该类置信值最大的框
            for(int i=cur+1;i&lt;boxes.size();i++){
                if(indexs[i]==0){
                    continue;
                }
                float classIndex=boxes.get(i).get(5);
                // 两个检测框都检测到同一类数据，通过iou来判断是否检测到同一目标，这就是非极大值抑制
                if(classIndex==curMaxConf.get(5)){
                    float x1=curMaxConf.get(0);
                    float y1=curMaxConf.get(1);
                    float x2=curMaxConf.get(2);
                    float y2=curMaxConf.get(3);
                    float x3=boxes.get(i).get(0);
                    float y3=boxes.get(i).get(1);
                    float x4=boxes.get(i).get(2);
                    float y4=boxes.get(i).get(3);
                    //将几种不相交的情况排除。提示:x1y1、x2y2、x3y3、x4y4对应两框的左上角和右下角
                    if(x1&gt;x4||x2&lt;x3||y1&gt;y4||y2&lt;y3){
                        continue;
                    }
                    // 两个矩形的交集面积
                    float intersectionWidth =Math.max(x1, x3) - Math.min(x2, x4);
                    float intersectionHeight=Math.max(y1, y3) - Math.min(y2, y4);
                    float intersectionArea =Math.max(0,intersectionWidth * intersectionHeight);
                    // 两个矩形的并集面积
                    float unionArea = (x2-x1)*(y2-y1)+(x4-x3)*(y4-y3)-intersectionArea;
                    // 计算IoU
                    float iou = intersectionArea / unionArea;
                    // 对交并比超过阈值的标记
                    indexs[i]=iou&gt;nmsThreshold?0:1;
                    //System.out.println(cur+" "+i+" class"+curMaxConf.get(5)+" "+classIndex+"  u:"+unionArea+" i:"+intersectionArea+"  iou:"+ iou);
                }
            }
        }


        List&lt;ArrayList&lt;Float&gt;&gt; resBoxes=new LinkedList&lt;ArrayList&lt;Float&gt;&gt;();
        for(int index=0;index&lt;indexs.length;index++){
            if(indexs[index]==1) {
                resBoxes.add(boxes.get(index));
            }
        }
        boxes=resBoxes;

        System.out.println("boxes.size : "+boxes.size());
        for(ArrayList&lt;Float&gt; box1:boxes){
            box1.set(0,box1.get(0)*scaleW);
            box1.set(1,box1.get(1)*scaleH);
            box1.set(2,box1.get(2)*scaleW);
            box1.set(3,box1.get(3)*scaleH);
        }
        System.out.println("boxes: "+boxes);
        //detect(boxes);
        Map&lt;Object,Object&gt; map=new HashMap&lt;Object,Object&gt;();
        map.put("boxes",boxes);
        map.put("classNames",names);
        return map;
    }


    public static Mat showDetect(Map&lt;Object,Object&gt; map){
        List&lt;ArrayList&lt;Float&gt;&gt; boxes=(List&lt;ArrayList&lt;Float&gt;&gt;)map.get("boxes");
        JSONObject names=(JSONObject) map.get("classNames");
        Imgproc.resize(src,src,new Size(srcw,srch));
        // 画框，加数据
        for(ArrayList&lt;Float&gt; box:boxes){
            float x1=box.get(0);
            float y1=box.get(1);
            float x2=box.get(2);
            float y2=box.get(3);
            float config=box.get(4);
            String className=(String)names.get((int)box.get(5).intValue());;
            Point point1=new Point(x1,y1);
            Point point2=new Point(x2,y2);
            Imgproc.rectangle(src,point1,point2,new Scalar(0,0,255),2);
            String conf=new DecimalFormat("#.###").format(config);
            Imgproc.putText(src,className+" "+conf,new Point(x1,y1-5),0,0.5,new Scalar(255,0,0),1);
        }
        HighGui.imshow("image",src);
        HighGui.waitKey();
        return src;
    }


    public static void main(String[] args) throws Exception {
        String modelPath="C:\\Users\\tianyu\\IdeaProjects\\test1\\src\\main\\java\\com\\sky\\best.onnx";
        String path="C:\\Users\\tianyu\\IdeaProjects\\test1\\src\\main\\resources\\img\\img.png";
        onnxLoadTest01.load(modelPath);
        Map&lt;Object,Object&gt; map=onnxLoadTest01.predict(path);
        showDetect(map);
    }
}

</code></pre> 
<p><strong>效果：</strong></p> 
<p><img alt="" height="211" src="https://images2.imgbox.com/5b/4e/akHZmloT_o.png" width="310"><br><img alt="" height="459" src="https://images2.imgbox.com/c8/21/MGp2ce9U_o.png" width="597"></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p>参考文献：</p> 
<p><a href="https://blog.csdn.net/qq_34448345/article/details/129692031" title="使用 java-onnx 部署 yolovx 目标检测_java onnx-CSDN博客">使用 java-onnx 部署 yolovx 目标检测_java onnx-CSDN博客</a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/802c136cff89d033261bb52d2605b0e1/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Text-to-SQL小白入门（十）RLHF在Text2SQL领域的探索实践</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/9e9498d81545bf87e32505673fe8633f/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">使用宝塔面板部署node项目、数据库及react项目</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>