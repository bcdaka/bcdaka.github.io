<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>大数据Hadoop完全分布式及心得体会 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/52ff7c887228d3bde9a2f9bc52b08135/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="大数据Hadoop完全分布式及心得体会">
  <meta property="og:description" content="文章目录 前言认识hadoop，根据所学知识完成作业，并总结本学期心得体会。 一、认识hadoop二、一课一得作业讲解实现步骤1. 搭建集群2. 模拟生成新能源车辆数据编写一个程序3. 最终部署，将这些数据写到HDFS中。 三、学习收获 前言 认识hadoop，根据所学知识完成作业，并总结本学期心得体会。 一、认识hadoop Hadoop是一个分布式系统基础技术框架，利用hadoop，开发用户可以在不了解分布式底层细节的情况下，开发分布式程序，从而达到充分利用集群的威力高速运算和存储的目的；而在本学期中，我们的专业老师带我们学习了Hadoop框架中最核心的设计：MapReduce和HDFS。
MapReduce从字面上就能看出，是由两个动词Map和Reduce组成，“Map” 就是将一个任务分解成为多个任务，“Reduce” 就是将分解后多任务处理的结果汇总起来，得出最后的分析结果。即把一个巨大的任务分割成许许多多的小任务单元，最后再将每个小任务单元的结果汇总，并求得最终结果。
而map的输出和reduce的输入之间的还有一个数据处理过程，即为shuffle过程。该过程涉及分区、排序、分组等操作。
数据流转过程
HDFS的中文翻译是Hadoop分布式文件系统（Hadoop Distributed File System）。它本质还是程序，主要还是以树状目录结构来管理文件（和linux类似，/表示根路径），且可以运行在多个节点上（即分布式）；它可以存储海量离线数据（如TB、PB、ZB级别的数据），并且保证数据高可用，支持高并发访问。但并不适合将大量的小文件存到HDFS。其主要原因是：HDFS的NameNode进程在内存中存储文件的元数据，故文件越多，消耗的内存就越大。大量的小文件，耗尽NameNode节点的内存，而实际存的文件总量却很小，HDFS存海量数据的优势没有发挥出来。
HDFS的框架
HDFS存文件的时候，会将文件按照一定的大小（默认是128M）进行分割，独立存储，这些独立的文件即为数据块（Block）。
二、一课一得作业讲解 题： 模拟生成新能源车辆数据编写一个程序，每天凌晨3点模拟生成当天的新能源车辆数据（字段信息必须包含：车架号、行驶总里程、车速、车辆状态、充电状态、剩余电量SOC、SOC低报警、数据生成时间等）。
1、最终部署时，要将这些数据写到第一题的HDFS中。
2、车辆数据要按天存储，数据格式是JSON格式，另外如果数据文件大于100M，则另起一个文件存。每天的数据总量不少于300M。比如假设程序是2023-01-1 03点运行，那么就将当前模拟生成的数据写入到HDFS的/can_data/2023-01-01文件夹的can-2023-01-01.json文件中，写满100M，则继续写到can-2023-01-01.json.2文件中，依次类推；
3、每天模拟生成的车辆数据中，必须至少包含20辆车的数据，即要含有20个车架号（一个车架号表示一辆车，用字符串表示）；
4、每天生成的数据中要有少量（20条左右）重复数据（所有字段都相同的两条数据则认为是重复数据），且同一辆车的两条数据的数据生成时间间隔两秒；
5、每天生成的数据中要混有少量前几天的数据（即数据生成时间不是当天，而是前几天的）。
实现步骤 搭建集群模拟生成新能源车辆数据编写一个程序最终部署，将这些数据写到HDFS中。 1. 搭建集群 集群规划
主机IP主机名HDFSYARN192.168.91.4masterNameNode DataNodeResourceManager NodeManager192.168.91.5save1SecondaryNameNode DataNodeNodeManager192.168.91.6save2DataNodeNodeManager （1） 准备三台虚拟机，之前在伪分布式中部署过一台虚拟机了，因此直接复制三份虚拟机即可
1.1 先创建三个文件夹，并分别在每一个文件夹中复制一个虚拟机
1.2 启动VMware，重命名三个节点的名称分别为master save1 save2
1.3 分别修改master、save1、save2中的ip并重启网卡
修改IP命令 vi /etc/sysconfig/network-scripts/ifcfg-ens33; Esc 保存退出 :wq 重启网卡命令：service network restart;
（2） 修改master、save1、save2的主机名
重命名命令： hostnamectl set-hostname master //master hostnamectl set-hostname save1 //save1 hostnamectl set-hostname save2 //save2 (3) 添加IP的映射">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2023-06-26T16:31:27+08:00">
    <meta property="article:modified_time" content="2023-06-26T16:31:27+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">大数据Hadoop完全分布式及心得体会</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#_4" rel="nofollow">前言</a></li><li><ul><li><a href="#hadoop_5" rel="nofollow">认识hadoop，根据所学知识完成作业，并总结本学期心得体会。</a></li></ul> 
  </li><li><a href="#hadoop_10" rel="nofollow">一、认识hadoop</a></li><li><a href="#_26" rel="nofollow">二、一课一得作业讲解</a></li><li><ul><li><a href="#_41" rel="nofollow">实现步骤</a></li><li><a href="#1__47" rel="nofollow">1. 搭建集群</a></li><li><a href="#2__205" rel="nofollow">2. 模拟生成新能源车辆数据编写一个程序</a></li><li><a href="#3_HDFS_284" rel="nofollow">3. 最终部署，将这些数据写到HDFS中。</a></li></ul> 
  </li><li><a href="#_287" rel="nofollow">三、学习收获</a></li></ul> 
</div> 
<p></p> 
<hr> 
<h2><a id="_4"></a>前言</h2> 
<h3><a id="hadoop_5"></a>认识hadoop，根据所学知识完成作业，并总结本学期心得体会。</h3> 
<hr> 
<h2><a id="hadoop_10"></a>一、认识hadoop</h2> 
<p>Hadoop是一个<strong>分布式系统</strong>基础技术框架，利用hadoop，开发用户可以在不了解分布式底层细节的情况下，开发分布式程序，从而达到充分利用集群的威力高速运算和存储的目的；而在本学期中，我们的专业老师带我们学习了Hadoop框架中最<strong>核心</strong>的设计：<strong>MapReduce</strong>和<strong>HDFS</strong>。<br> MapReduce从字面上就能看出，是由两个动词Map和Reduce组成，“<strong>Map</strong>” 就是将一个任务<strong>分解成为多个任务</strong>，“<strong>Reduce</strong>” 就是将分解后多任务处理的结果<strong>汇总</strong>起来，得出最后的<strong>分析</strong>结果。即把一个巨大的任务分割成许许多多的小任务单元，最后再将每个小任务单元的结果汇总，并求得最终结果。<br> 而map的输出和reduce的输入之间的还有一个数据处理过程，即为<strong>shuffle</strong>过程。该过程涉及<strong>分区、排序、分组</strong>等操作。</p> 
<p><strong>数据流转过程</strong><br> <img src="https://images2.imgbox.com/de/49/IUiHMMaU_o.png" alt="在这里插入图片描述"><br> <strong>HDFS</strong>的中文翻译是<strong>Hadoop分布式文件系统</strong>（Hadoop Distributed File System）。它本质还是程序，主要还是以<strong>树状目录结构</strong>来管理文件（和linux类似，/表示根路径），且可以运行在多个节点上（即分布式）；它可以<strong>存储海量离线数据</strong>（如TB、PB、ZB级别的数据），并且保证数据高可用，<strong>支持高并发访问</strong>。但并<strong>不适合将大量的小文件存到HDFS</strong>。其主要原因是：HDFS的NameNode进程在内存中存储文件的元数据，故文件越多，消耗的内存就越大。大量的小文件，耗尽NameNode节点的内存，而实际存的文件总量却很小，HDFS存海量数据的优势没有发挥出来。</p> 
<p><strong>HDFS的框架</strong><br> <img src="https://images2.imgbox.com/68/16/HWEBb25i_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/b4/bc/0CZJCopS_o.png" alt="在这里插入图片描述"><br> HDFS存文件的时候，会将文件按照一定的大小（<strong>默认是128M</strong>）进行分割，独立存储，这些独立的文件即为数据块（Block）。</p> 
<hr> 
<h2><a id="_26"></a>二、一课一得作业讲解</h2> 
<blockquote> 
 <p><strong>题：</strong> 模拟生成新能源车辆数据编写一个程序，每天凌晨3点模拟生成当天的新能源车辆数据（字段信息必须包含：车架号、行驶总里程、车速、车辆状态、充电状态、剩余电量SOC、SOC低报警、数据生成时间等）。</p> 
</blockquote> 
<p>1、最终部署时，要将这些数据写到第一题的HDFS中。</p> 
<p>2、车辆数据要按天存储，数据格式是JSON格式，另外如果数据文件大于100M，则另起一个文件存。每天的数据总量不少于300M。比如假设程序是2023-01-1 03点运行，那么就将当前模拟生成的数据写入到HDFS的/can_data/2023-01-01文件夹的can-2023-01-01.json文件中，写满100M，则继续写到can-2023-01-01.json.2文件中，依次类推；</p> 
<p>3、每天模拟生成的车辆数据中，必须至少包含20辆车的数据，即要含有20个车架号（一个车架号表示一辆车，用字符串表示）；</p> 
<p>4、每天生成的数据中要有少量（20条左右）重复数据（所有字段都相同的两条数据则认为是重复数据），且同一辆车的两条数据的数据生成时间间隔两秒；</p> 
<p>5、每天生成的数据中要混有少量前几天的数据（即数据生成时间不是当天，而是前几天的）。</p> 
<h3><a id="_41"></a>实现步骤</h3> 
<ol><li>搭建集群</li><li>模拟生成新能源车辆数据编写一个程序</li><li>最终部署，将这些数据写到HDFS中。</li></ol> 
<h3><a id="1__47"></a>1. 搭建集群</h3> 
<p><strong>集群规划</strong></p> 
<table><thead><tr><th>主机IP</th><th>主机名</th><th>HDFS</th><th>YARN</th></tr></thead><tbody><tr><td>192.168.91.4</td><td>master</td><td>NameNode DataNode</td><td>ResourceManager NodeManager</td></tr><tr><td>192.168.91.5</td><td>save1</td><td>SecondaryNameNode DataNode</td><td>NodeManager</td></tr><tr><td>192.168.91.6</td><td>save2</td><td>DataNode</td><td>NodeManager</td></tr></tbody></table> 
<hr> 
<p><strong>（1） 准备三台虚拟机，之前在伪分布式中部署过一台虚拟机了，因此直接复制三份虚拟机即可</strong></p> 
<p>1.1 先创建三个文件夹，并分别在每一个文件夹中复制一个虚拟机</p> 
<p><img src="https://images2.imgbox.com/56/2e/3IMColpx_o.jpg" alt="p1"></p> 
<p><strong>1.2 启动VMware，重命名三个节点的名称分别为master save1 save2</strong></p> 
<p><strong>1.3 分别修改master、save1、save2中的ip并重启网卡</strong></p> 
<p><img src="https://images2.imgbox.com/6a/de/eOfjk3R0_o.jpg" alt="p3"></p> 
<pre><code>修改IP命令
vi /etc/sysconfig/network-scripts/ifcfg-ens33;

Esc 保存退出
:wq
</code></pre> 
<p>重启网卡命令：<strong>service network restart;</strong></p> 
<hr> 
<p><strong>（2） 修改master、save1、save2的主机名</strong></p> 
<p><img src="https://images2.imgbox.com/3f/9b/A1Vx8pZU_o.jpg" alt="p2"></p> 
<pre><code>重命名命令：
hostnamectl set-hostname master  //master
hostnamectl set-hostname save1  //save1
hostnamectl set-hostname save2  //save2
</code></pre> 
<p><strong>(3) 添加IP的映射</strong><br> <img src="https://images2.imgbox.com/d7/bd/pO0idUL8_o.jpg" alt="p4"></p> 
<pre><code>添加IP的映射命令
vi /etc/hosts

Esc 保存退出
:wq
</code></pre> 
<hr> 
<p><strong>(4) 免密登录</strong><br> 因为master、save1、save2三个节点都是从之前的已经安装好Hadoop伪分布式的虚拟机复制得来，而当时已经设置了免密登录，故不需再设置了。也就是master可以免密登录到master、save1、save2。</p> 
<p><strong>(5) 关闭防火墙</strong><br> 同理，之前已经设置不允许防火墙开机自启，默认开机是关闭的，故也不需要操作。</p> 
<p><strong>(6) 删除伪分布式data的数据</strong></p> 
<pre><code>切换到该路径下
cd /usr/local/hadoop-2.7.1/

删除命令
rm -rf ./data/
</code></pre> 
<hr> 
<p><strong>(7) 修改master 的配置文件</strong></p> 
<p>7.1<br> <img src="https://images2.imgbox.com/4c/e5/WOdVrolK_o.jpg" alt="p5"></p> 
<pre><code>命令示例
vi core-site.xml;

Esc 保存退出
:wq
</code></pre> 
<p>7.2<br> <img src="https://images2.imgbox.com/0f/fe/GSuaan9O_o.jpg" alt="p6"></p> 
<pre><code>命令示例

vi hdfs-site.xml;

Esc 保存退出
:wq
</code></pre> 
<p>7.3<br> <img src="https://images2.imgbox.com/62/a2/jIX3c8qT_o.jpg" alt="p7"></p> 
<pre><code>命令示例

vi yarn-site.xml;

Esc 保存退出
:wq
</code></pre> 
<p>7.4<br> <img src="https://images2.imgbox.com/8a/20/7P4LHMnP_o.jpg" alt="p8"></p> 
<pre><code>命令示例

vi saves;

Esc 保存退出
:wq
</code></pre> 
<hr> 
<p><strong>（8）将刚才master的配置信息同步到saev1、saev2上</strong></p> 
<p><img src="https://images2.imgbox.com/25/ce/leU4hY8l_o.jpg" alt="p9"></p> 
<pre><code>同步到saev1
scp /etc/hosts root@save1:/etc;

同步到saev2
scp /etc/hosts root@save2:/etc;
</code></pre> 
<p><strong>（9）时间同步</strong></p> 
<blockquote> 
 <ol><li>下载ntpdate插件<br> yum install -y ntpdata<br> 2.时间同步命令<br> ntpdate ntp4.aliyun.com；</li></ol> 
</blockquote> 
<p><strong>（10）将NameNode格式化</strong></p> 
<pre><code>hdfs namenode -format
</code></pre> 
<p>ps：禁止重复格式化</p> 
<hr> 
<p><strong>（11）启动集群</strong></p> 
<blockquote> 
 <p>分别在master、save1，save2节点上都输入一遍start-all.sh</p> 
</blockquote> 
<pre><code>代码示例：
start-all.sh
</code></pre> 
<hr> 
<p><strong>至此，三个节点的集群就可以算搭建成功！</strong></p> 
<h3><a id="2__205"></a>2. 模拟生成新能源车辆数据编写一个程序</h3> 
<p><strong>2.1 生成车辆数据</strong><br> （1）先随机生成20辆车的车架号，并把它存入一个空的列表中；<br> （2）设置每一个值的状态；<br> （3）设置数据生成的时间；<br> （4）把数据存入列表中；</p> 
<p><img src="https://images2.imgbox.com/25/e4/ZgSIaYji_o.jpg" alt="p10"></p> 
<p>代码示例：</p> 
<pre><code class="prism language-C">def generate_data():
    vin_list = ['VIN{}'.format(i) for i in range(1，21)] # 车架号列表
    data_list = []
    for vin in vin_list:
    mileage = round(random.uniform(1000，10000)，2) # 行驶总里程
        speed = round(random.uniform(0，120)，2) # 车速
        status = random.choice(['running’，'stopped']) # 车辆状态
        charge_status = random.choice(['charging'，'discharging'，'idle']) # 充电状态
        soc = round(random.uniform(0，100)，2) # 剩余电量SOC
        soc_Low_alert = random.choice([True，False]) # SOC低报警
        timestamp = int(time.time()) # 数据生成时间
        data = {
            'vin': vin,
            'mileage': mileage
            ' speed': speed,
            ' status': status ,
            ' charge_status': charge_status
            ' soc': soc,
            'soc_low_alert': soc_low_alert
            'timestamp': timestamp
        }
        data_list.append(data)
    return data_list

</code></pre> 
<hr> 
<p><strong>2.2.添加重复数据</strong><br> （1）添加重复数据，使用随机添加，在20辆车中随机添加一些重复的数据;<br> （2）看题目要求：每天生成的数据中要混有少量前几天的数据（即数据生成时间不是当天，而是前几天的），所以我们要添加前几天的数据；<br> （3）按时间排序：data.sort(key=lambda x:x[‘timestamp’])<br> （4）添加时间间隔为2秒的重复数据<br> （5）将数据写入HDFS</p> 
<p><img src="https://images2.imgbox.com/5c/cc/RhHQxU3M_o.jpg" alt="p11"><br> 代码示例：</p> 
<pre><code class="prism language-C">data = generate_data()
#添加重复数据
repeat_data = random.sample(data, 20)
data += repeat_data
#添加前几天的数据
for i in range(20):
	timestamp = int(time.time()) - (i + 1) * 24 * 60 * 60
	vin = 	random.choice(['VIN{}'.format(i) for i in range(1，21)])
	data.append({
		' vin': vin,
		'mileage': round(random.uniform(1000，10000)，2),
		'speed': round(random.uniform(0，120)， 2),
		' status': random.choice(['running','stopped']),
		'charge_status': random.choice(['charging','discharging','idle']),
		' soc': round(random.uniform(0, 100)，2),
		'soc_Low_alert': random.choice([True, False]),
		'timestamp': timestamp
	})
	#按时间排序
data.sort(key=lambda x: x['timestamp'])  #添加时间间隔为2秒的重复数据
for i in range(len(data) - 1):
	if data[i]['vin'] == data[i + 1]['vin']:
	data.insert(i + 1,data[i].copy())
	data[i + 1]['timestamp'] += 2
	#写入HDFS
write_to_hdfs(data, hdfs_path)

</code></pre> 
<hr> 
<h3><a id="3_HDFS_284"></a>3. 最终部署，将这些数据写到HDFS中。</h3> 
<p>1.打包生成jar包，并提交至Hadoop集群运行<br> 2.设置定时任务，规定每天凌晨三点的第一分钟运行一次</p> 
<h2><a id="_287"></a>三、学习收获</h2> 
<p>互联网的快速发展带来了数据快速增加，海量数据的存储已经不是一台机器所能处理的问题了。Hadoop的技术就应运而生。在本学期中专业老师的授课下，我对于这个概念有了一个比较系统的了解。<br> 大数据Hadoop是一个非常重要的实际项目，对于所有想要了解大数据和Hadoop生态系统的人来说都是一个很好的机会。在课上课后的实操过程中，我不仅学到了Hadoop的基础知识，同时也学到了如何使用Hadoop来处理大数据。实操的过程需要我们掌握一些关于大数据的技能，如如何使用MapReduce算法，以及如何使用IDEA API来进行大数据分析。<br> 总的来说，通过学习本学期这门课程，我对大数据和Hadoop系统有了较深入的了解，并且也加深了我的实操应用能力。我相信，随着大数据和人工智能的不断发展，这项技能将在未来发挥更大的作用。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/9d998a43e2778e5da64e3e7c4def6397/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">绝地求生 压q python版</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/5bda357bc8db3d3a250f48c41700b7a0/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">oracle ORA-01704: string literal too long字符串文字太长报错解决方法</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>