<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【小沐学AI】Python实现语音识别（faster-whisper） - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/8b8ea4f31ce681619ebcf312a966a3f8/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="【小沐学AI】Python实现语音识别（faster-whisper）">
  <meta property="og:description" content="文章目录 1、简介1.1 CTranslate21.2 Intel MKL1.3 cuDNN1.4 Transformer 2、下载和安装2.1 命令行2.2 代码 3、模型下载3.1 在线测试3.1.1 tiny3.1.2 large-v2 3.2 离线测试3.2.1 tiny3.2.1 large-v2 结语 1、简介 https://github.com/SYSTRAN/faster-whisper
https://pypi.org/project/faster-whisper/
Faster-Whisper是Whisper开源后的第三方进化版本，它对原始的 Whisper 模型结构进行了改进和优化。
faster-whisper 是使用 CTranslate2 重新实现 OpenAI 的 Whisper 模型，CTranslate2 是 Transformer 模型的快速推理引擎。
此实现比 openai/whisper 快 4 倍，同时使用更少的内存实现相同的准确性。通过对 CPU 和 GPU 进行 8 位量化，可以进一步提高效率。
1.1 CTranslate2 https://github.com/OpenNMT/CTranslate2/
CTranslate2 是一个 C&#43;&#43; 和 Python 库，用于使用 Transformer 模型进行高效推理。
该项目实现了一个自定义运行时，该运行时应用了许多性能优化技术，例如权重量化、层融合、批量重新排序等，以加速和减少 Transformer 模型在 CPU 和 GPU 上的内存使用。
CTranslate2 可以用 pip 安装：">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-06-29T23:50:00+08:00">
    <meta property="article:modified_time" content="2024-06-29T23:50:00+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【小沐学AI】Python实现语音识别（faster-whisper）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atelier-sulphurpool-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#1_2" rel="nofollow">1、简介</a></li><li><ul><li><a href="#11_CTranslate2_11" rel="nofollow">1.1 CTranslate2</a></li><li><a href="#12_Intel_MKL_21" rel="nofollow">1.2 Intel MKL</a></li><li><a href="#13_cuDNN_29" rel="nofollow">1.3 cuDNN</a></li><li><a href="#14_Transformer_33" rel="nofollow">1.4 Transformer</a></li></ul> 
  </li><li><a href="#2_40" rel="nofollow">2、下载和安装</a></li><li><ul><li><a href="#21__41" rel="nofollow">2.1 命令行</a></li><li><a href="#22__59" rel="nofollow">2.2 代码</a></li></ul> 
  </li><li><a href="#3_65" rel="nofollow">3、模型下载</a></li><li><ul><li><a href="#31__66" rel="nofollow">3.1 在线测试</a></li><li><ul><li><a href="#311_tiny_67" rel="nofollow">3.1.1 tiny</a></li><li><a href="#312_largev2_80" rel="nofollow">3.1.2 large-v2</a></li></ul> 
   </li><li><a href="#32__93" rel="nofollow">3.2 离线测试</a></li><li><ul><li><a href="#321_tiny_107" rel="nofollow">3.2.1 tiny</a></li><li><a href="#321_largev2_147" rel="nofollow">3.2.1 large-v2</a></li></ul> 
  </li></ul> 
  </li><li><a href="#_183" rel="nofollow">结语</a></li></ul> 
</div> 
<p></p> 
<h2><a id="1_2"></a>1、简介</h2> 
<p><a href="https://github.com/SYSTRAN/faster-whisper">https://github.com/SYSTRAN/faster-whisper</a><br> <a href="https://pypi.org/project/faster-whisper/" rel="nofollow">https://pypi.org/project/faster-whisper/</a></p> 
<p>Faster-Whisper是Whisper开源后的第三方进化版本，它对原始的 Whisper 模型结构进行了改进和优化。<br> faster-whisper 是使用 CTranslate2 重新实现 OpenAI 的 Whisper 模型，CTranslate2 是 Transformer 模型的快速推理引擎。</p> 
<p>此实现比 openai/whisper 快 4 倍，同时使用更少的内存实现相同的准确性。通过对 CPU 和 GPU 进行 8 位量化，可以进一步提高效率。</p> 
<h3><a id="11_CTranslate2_11"></a>1.1 CTranslate2</h3> 
<p><a href="https://github.com/OpenNMT/CTranslate2/">https://github.com/OpenNMT/CTranslate2/</a><br> CTranslate2 是一个 C++ 和 Python 库，用于使用 Transformer 模型进行高效推理。<br> 该项目实现了一个自定义运行时，该运行时应用了许多性能优化技术，例如权重量化、层融合、批量重新排序等，以加速和减少 Transformer 模型在 CPU 和 GPU 上的内存使用。</p> 
<p>CTranslate2 可以用 pip 安装：</p> 
<pre><code class="prism language-bash">pip <span class="token function">install</span> ctranslate2
</code></pre> 
<h3><a id="12_Intel_MKL_21"></a>1.2 Intel MKL</h3> 
<blockquote> 
 <p>获取英特尔® oneAPI 数学核心函数库 （oneMKL）</p> 
</blockquote> 
<p><a href="https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl.html" rel="nofollow">https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl.html</a><br> <a href="https://www.intel.cn/content/www/cn/zh/developer/tools/oneapi/onemkl-download.html" rel="nofollow">https://www.intel.cn/content/www/cn/zh/developer/tools/oneapi/onemkl-download.html</a></p> 
<p>CTranslate2 的核心是其高度优化的模型推理实现。它支持多种硬件平台，包括 CPU 和 GPU，并利用了底层的并行计算库如 Intel MKL 或者 cuDNN 来最大化性能。</p> 
<h3><a id="13_cuDNN_29"></a>1.3 cuDNN</h3> 
<p><a href="https://developer.nvidia.com/cudnn" rel="nofollow">https://developer.nvidia.com/cudnn</a><br> NVIDIA CUDA® 深度神经网络库 （cuDNN） 是用于深度神经网络的 GPU 加速基元库。cuDNN 为标准例程（如前向和后向卷积、注意力、matmul、池化和归一化）提供高度优化的实现。</p> 
<h3><a id="14_Transformer_33"></a>1.4 Transformer</h3> 
<p><a href="https://arxiv.org/pdf/1706.03762" rel="nofollow">https://arxiv.org/pdf/1706.03762</a><br> 目前，自然语言处理中，有三种特征处理器：卷积神经网络、递归神经网络和后起之秀 Transformer。Transformer 风头已经盖过两个前辈，它抛弃了传统的卷积神经网络和递归神经网络，整个网络结构完全是由注意力机制组成。准确地讲，Transformer 仅由自注意力和前馈神经网络组成。</p> 
<p><img src="https://images2.imgbox.com/6a/4d/6FATRs7Q_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/ea/ae/5pWKRRJ6_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="2_40"></a>2、下载和安装</h2> 
<h3><a id="21__41"></a>2.1 命令行</h3> 
<p><a href="https://github.com/Purfview/whisper-standalone-win">https://github.com/Purfview/whisper-standalone-win</a><br> Whisper &amp; Faster-Whisper 独立可执行文件，适合那些不想打扰 Python 的人。<br> <img src="https://images2.imgbox.com/c2/19/a7iQfw0u_o.png" alt="在这里插入图片描述"><br> 解压文件夹如下：<br> <img src="https://images2.imgbox.com/9b/6a/4tVROvik_o.png" alt="在这里插入图片描述"><br> 测试如下：</p> 
<pre><code class="prism language-bash">whisper-faster.exe <span class="token string">"D:<span class="token entity" title="\v">\v</span>ideofile.mkv"</span> <span class="token parameter variable">--language</span> English <span class="token parameter variable">--model</span> medium <span class="token parameter variable">--output_dir</span> <span class="token builtin class-name">source</span>
whisper-faster.exe <span class="token string">"D:<span class="token entity" title="\v">\v</span>ideofile.mkv"</span> <span class="token parameter variable">-l</span> English <span class="token parameter variable">-m</span> medium <span class="token parameter variable">-o</span> <span class="token builtin class-name">source</span> <span class="token parameter variable">--sentence</span>
whisper-faster.exe <span class="token string">"D:<span class="token entity" title="\v">\v</span>ideofile.mkv"</span> <span class="token parameter variable">-l</span> Japanese <span class="token parameter variable">-m</span> medium <span class="token parameter variable">--task</span> translate <span class="token parameter variable">--standard</span>
whisper-faster.exe <span class="token parameter variable">--help</span>

faster-whisper-xxl.exe <span class="token parameter variable">--language</span> zh <span class="token parameter variable">--model</span> <span class="token string">"large-v2"</span> <span class="token parameter variable">--compute_type</span><span class="token operator">=</span>int8 <span class="token parameter variable">--sentence</span> <span class="token parameter variable">-prompt</span> auto <span class="token parameter variable">--beep_off</span> <span class="token parameter variable">--print_progress</span> <span class="token parameter variable">--vad_alt_method</span> pyannote_v3 <span class="token parameter variable">--ff_mdx_kim2</span> <span class="token parameter variable">--mdx_device</span> cpu <span class="token string">"yxy_audio.mp3"</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/58/74/YUnPxpdS_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="22__59"></a>2.2 代码</h3> 
<p>从 PyPI 安装：</p> 
<pre><code class="prism language-bash">pip <span class="token function">install</span> faster-whisper
</code></pre> 
<p><img src="https://images2.imgbox.com/ec/6b/mOV4LcLk_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="3_65"></a>3、模型下载</h2> 
<h3><a id="31__66"></a>3.1 在线测试</h3> 
<h4><a id="311_tiny_67"></a>3.1.1 tiny</h4> 
<pre><code class="prism language-python"><span class="token keyword">from</span> faster_whisper <span class="token keyword">import</span> WhisperModel

model <span class="token operator">=</span> WhisperModel<span class="token punctuation">(</span><span class="token string">"tiny"</span><span class="token punctuation">)</span>

segments<span class="token punctuation">,</span> info <span class="token operator">=</span> model<span class="token punctuation">.</span>transcribe<span class="token punctuation">(</span><span class="token string">"yxy_audio.mp3"</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> segment <span class="token keyword">in</span> segments<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"[%.2fs -&gt; %.2fs] %s"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>segment<span class="token punctuation">.</span>start<span class="token punctuation">,</span> segment<span class="token punctuation">.</span>end<span class="token punctuation">,</span> segment<span class="token punctuation">.</span>text<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/26/8c/P3zckCa4_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/3c/c3/s92a1rIN_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="312_largev2_80"></a>3.1.2 large-v2</h4> 
<pre><code class="prism language-python"><span class="token keyword">from</span> faster_whisper <span class="token keyword">import</span> WhisperModel

model <span class="token operator">=</span> WhisperModel<span class="token punctuation">(</span><span class="token string">"large-v2"</span><span class="token punctuation">)</span>

segments<span class="token punctuation">,</span> info <span class="token operator">=</span> model<span class="token punctuation">.</span>transcribe<span class="token punctuation">(</span><span class="token string">"yxy_audio.mp3"</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> segment <span class="token keyword">in</span> segments<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"[%.2fs -&gt; %.2fs] %s"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>segment<span class="token punctuation">.</span>start<span class="token punctuation">,</span> segment<span class="token punctuation">.</span>end<span class="token punctuation">,</span> segment<span class="token punctuation">.</span>text<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/17/c0/SNW95cCS_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/77/bb/lCNw5l7X_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="32__93"></a>3.2 离线测试</h3> 
<pre><code class="prism language-bash">large-v3模型：https://huggingface.co/Systran/faster-whisper-large-v3/tree/main
large-v2模型：https://huggingface.co/guillaumekln/faster-whisper-large-v2/tree/main
large-v1模型：https://huggingface.co/guillaumekln/faster-whisper-large-v1/tree/main
medium模型：https://huggingface.co/guillaumekln/faster-whisper-medium/tree/main
small模型：https://huggingface.co/guillaumekln/faster-whisper-small/tree/main
base模型：https://huggingface.co/guillaumekln/faster-whisper-base/tree/main
tiny模型：https://huggingface.co/guillaumekln/faster-whisper-tiny/tree/main

or 
https://aifasthub.com/models/guillaumekln
</code></pre> 
<h4><a id="321_tiny_107"></a>3.2.1 tiny</h4> 
<p>这里下载tiny模型到本地：<br> <img src="https://images2.imgbox.com/8f/fb/BbopH5Dd_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/d6/b0/vt0yI5eU_o.png" alt="在这里插入图片描述"></p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> faster_whisper <span class="token keyword">import</span> WhisperModel

model_size <span class="token operator">=</span> <span class="token string">"large-v2"</span>
path <span class="token operator">=</span> <span class="token string">r"C:\Users\tomcat\Desktop\tiny"</span>

<span class="token comment"># Run on GPU with FP16</span>
model <span class="token operator">=</span> WhisperModel<span class="token punctuation">(</span>model_size_or_path<span class="token operator">=</span>path<span class="token punctuation">,</span> device<span class="token operator">=</span><span class="token string">"cpu"</span><span class="token punctuation">,</span> local_files_only<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment"># or run on GPU with INT8</span>
<span class="token comment"># model = WhisperModel(model_size, device="cuda", compute_type="int8_float16")</span>
<span class="token comment"># or run on CPU with INT8</span>
<span class="token comment"># model = WhisperModel(model_size, device="cpu", compute_type="int8")</span>

segments<span class="token punctuation">,</span> info <span class="token operator">=</span> model<span class="token punctuation">.</span>transcribe<span class="token punctuation">(</span><span class="token string">"yxy_audio2.mp3"</span><span class="token punctuation">,</span> beam_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> language<span class="token operator">=</span><span class="token string">"zh"</span><span class="token punctuation">,</span> vad_filter<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> vad_parameters<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>min_silence_duration_ms<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Detected language '%s' with probability %f"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>info<span class="token punctuation">.</span>language<span class="token punctuation">,</span> info<span class="token punctuation">.</span>language_probability<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> segment <span class="token keyword">in</span> segments<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"[%.2fs -&gt; %.2fs] %s"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>segment<span class="token punctuation">.</span>start<span class="token punctuation">,</span> segment<span class="token punctuation">.</span>end<span class="token punctuation">,</span> segment<span class="token punctuation">.</span>text<span class="token punctuation">)</span><span class="token punctuation">)</span>

</code></pre> 
<p><img src="https://images2.imgbox.com/9d/43/4hD8aL9m_o.png" alt="在这里插入图片描述"></p> 
<pre><code class="prism language-bash"><span class="token assign-left variable">local_files_only</span><span class="token operator">=</span>True 表示加载本地模型
<span class="token assign-left variable">model_size_or_path</span><span class="token operator">=</span>path 指定加载模型路径
<span class="token assign-left variable">device</span><span class="token operator">=</span><span class="token string">"cuda"</span> 指定使用cuda or cpu
<span class="token assign-left variable">compute_type</span><span class="token operator">=</span><span class="token string">"int8_float16"</span> 量化为8位
<span class="token assign-left variable">language</span><span class="token operator">=</span><span class="token string">"zh"</span> 指定音频语言
<span class="token assign-left variable">vad_filter</span><span class="token operator">=</span>True 开启vad
<span class="token assign-left variable">vad_parameters</span><span class="token operator">=</span>dict<span class="token punctuation">(</span>min_silence_duration_ms<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">)</span> 设置vad参数
</code></pre> 
<h4><a id="321_largev2_147"></a>3.2.1 large-v2</h4> 
<p>这里下载large-v2模型到本地：<br> <img src="https://images2.imgbox.com/01/03/fiZMJERg_o.png" alt="在这里插入图片描述"></p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> faster_whisper <span class="token keyword">import</span> WhisperModel

model_size <span class="token operator">=</span> <span class="token string">"large-v2"</span>
path <span class="token operator">=</span> <span class="token string">r"C:\Users\tomcat\Desktop\large-v2"</span>

<span class="token comment"># Run on GPU with FP16</span>
model <span class="token operator">=</span> WhisperModel<span class="token punctuation">(</span>model_size_or_path<span class="token operator">=</span>path<span class="token punctuation">,</span> device<span class="token operator">=</span><span class="token string">"cpu"</span><span class="token punctuation">,</span> local_files_only<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment"># or run on GPU with INT8</span>
<span class="token comment"># model = WhisperModel(model_size, device="cuda", compute_type="int8_float16")</span>
<span class="token comment"># or run on CPU with INT8</span>
<span class="token comment"># model = WhisperModel(model_size, device="cpu", compute_type="int8")</span>

segments<span class="token punctuation">,</span> info <span class="token operator">=</span> model<span class="token punctuation">.</span>transcribe<span class="token punctuation">(</span><span class="token string">"yxy_audio2.mp3"</span><span class="token punctuation">,</span> beam_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> language<span class="token operator">=</span><span class="token string">"zh"</span><span class="token punctuation">,</span> vad_filter<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> vad_parameters<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>min_silence_duration_ms<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Detected language '%s' with probability %f"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>info<span class="token punctuation">.</span>language<span class="token punctuation">,</span> info<span class="token punctuation">.</span>language_probability<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> segment <span class="token keyword">in</span> segments<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"[%.2fs -&gt; %.2fs] %s"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>segment<span class="token punctuation">.</span>start<span class="token punctuation">,</span> segment<span class="token punctuation">.</span>end<span class="token punctuation">,</span> segment<span class="token punctuation">.</span>text<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p>下载cuBLAS and cuDNN：</p> 
<pre><code class="prism language-bash">https://github.com/Purfview/whisper-standalone-win/releases/tag/libs
</code></pre> 
<p><img src="https://images2.imgbox.com/d1/6e/w7VsgBrR_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/d5/69/bQp1aUGz_o.png" alt="在这里插入图片描述"><br> <font color="blue" face="楷体" size="4">2024第四届人工智能、自动化与高性能计算国际会议(AIAHPC 2024)将于2024年7月19-21日在中国·珠海召开。<br> <font color="black" face="黑体" size="4">大会网站：<a href="https://ais.cn/u/zA73En" rel="nofollow">更多会议详情</a><br> 时间地点：<a href="https://ais.cn/u/zA73En" rel="nofollow">中国珠海-中山大学珠海校区｜2024年7月19-21日</a></font></font></p> 
<h2><a id="_183"></a>结语</h2> 
<p><code>如果您觉得该方法或代码有一点点用处，可以给作者点个赞，或打赏杯咖啡；</code>╮(￣▽￣)╭<br> <code>如果您感觉方法或代码不咋地</code>//(ㄒoㄒ)//<code>，就在评论处留言，作者继续改进；</code>o_O???<br> <code>如果您需要相关功能的代码定制化开发，可以留言私信作者；</code>(✿◡‿◡)<br> <code>感谢各位大佬童鞋们的支持！</code>( ´ ▽´ )ﾉ ( ´ ▽´)っ！！！</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/414dd5f6ae03eb5cacccb3d82ecc8de8/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">GPT-5的预测</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/2f8dc4e8f9238b9d6eb836fe257d2948/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">深入分析 Android Service (六)(完)</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>