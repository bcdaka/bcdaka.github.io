<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Hadoop学习心得 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/08bfea7f133a924d064394b94de2fddf/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="Hadoop学习心得">
  <meta property="og:description" content="自从我开始接触Hadoop，这个大数据处理的开源框架，我的学习之路就充满了挑战与收获。Hadoop以其强大的数据处理能力和高度的可扩展性，成为了大数据领域的一颗璀璨明星。以下是我对Hadoop学习的一些心得和体会。
一、初识Hadoop 在开始学习Hadoop之前，我对大数据和分布式计算的概念还相对模糊。但随着对Hadoop的深入了解，我逐渐认识到它的重要性。Hadoop不仅仅是一个技术框架，更是一种处理大数据的思维方式。它通过将数据划分为多个小块，并在集群中的多个节点上并行处理，从而实现了对海量数据的快速处理。
二、学习过程中的挑战 在学习Hadoop的过程中，我遇到了很多挑战。首先，Hadoop的生态系统庞大而复杂，包括HDFS、MapReduce、YARN等多个组件，每个组件都有其独特的功能和用法。我需要花费大量的时间和精力去熟悉这些组件，并理解它们之间的相互作用。其次，Hadoop的配置和部署也是一个复杂的过程，需要仔细配置各种参数和环境变量，以确保集群的稳定运行。此外，Hadoop的编程模型MapReduce也具有一定的学习难度，需要掌握其编程范式和数据处理流程。
三、 hadoop的核心构架 Hadoop 由许多元素构成。其最底部是 Hadoop Distributed File System（HDFS），它存储 Hadoop 集群中所有存储节点上的文件。HDFS的上一层是MapReduce 引擎，该引擎由 JobTrackers 和 TaskTrackers 组成。通过对Hadoop分布式计算平台最核心的分布式文件系统HDFS、MapReduce处理过程，以及数据仓库工具Hive和分布式数据库Hbase的介绍，基本涵盖了Hadoop分布式平台的所有技术核心。
1.HDFS 对外部客户机而言，HDFS就像一个传统的分级文件系统。可以创建、删除、移动或重命名文件，等等。
2.NemeNode NameNode 是一个通常在 HDFS 实例中的单独机器上运行的软件
3.DetaNode DataNode 也是一个通常在 HDFS实例中的单独机器上运行的软件
四、MapReduce编程 现有以下数据,现要求统计本次月考各科目平均成绩
Map类
package task1; import org.apache.hadoop.io.IntWritable; import org.apache.hadoop.io.LongWritable; import org.apache.hadoop.io.Text; import org.apache.hadoop.mapreduce.Mapper; import java.io.IOException; public class ScoreMapper extends Mapper&lt;LongWritable, Text, Text, IntWritable&gt; { @Override protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException { // 将文本行拆分为字段 String[] fields = value.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-05-06T11:39:24+08:00">
    <meta property="article:modified_time" content="2024-05-06T11:39:24+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Hadoop学习心得</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>自从我开始接触Hadoop，这个大数据处理的开源框架，我的学习之路就充满了挑战与收获。Hadoop以其强大的数据处理能力和高度的可扩展性，成为了大数据领域的一颗璀璨明星。以下是我对Hadoop学习的一些心得和体会。</p> 
<h2><strong>一、初识Hadoop</strong></h2> 
<p>在开始学习Hadoop之前，我对大数据和分布式计算的概念还相对模糊。但随着对Hadoop的深入了解，我逐渐认识到它的重要性。Hadoop不仅仅是一个技术框架，更是一种处理大数据的思维方式。它通过将数据划分为多个小块，并在集群中的多个节点上并行处理，从而实现了对海量数据的快速处理。</p> 
<h2>二、学习过程中的挑战</h2> 
<p>在学习Hadoop的过程中，我遇到了很多挑战。首先，Hadoop的生态系统庞大而复杂，包括HDFS、MapReduce、YARN等多个组件，每个组件都有其独特的功能和用法。我需要花费大量的时间和精力去熟悉这些组件，并理解它们之间的相互作用。其次，Hadoop的配置和部署也是一个复杂的过程，需要仔细配置各种参数和环境变量，以确保集群的稳定运行。此外，Hadoop的编程模型MapReduce也具有一定的学习难度，需要掌握其编程范式和数据处理流程。</p> 
<h2>三、 hadoop的核心构架</h2> 
<p> Hadoop 由许多元素构成。其最底部是 Hadoop Distributed File System（HDFS），它存储 Hadoop 集群中所有存储节点上的文件。HDFS的上一层是MapReduce 引擎，该引擎由 JobTrackers 和 TaskTrackers 组成。通过对Hadoop分布式计算平台最核心的分布式文件系统HDFS、MapReduce处理过程，以及数据仓库工具Hive和分布式数据库Hbase的介绍，基本涵盖了Hadoop分布式平台的所有技术核心。</p> 
<p>1.HDFS  </p> 
<p>       对外部客户机而言，HDFS就像一个传统的分级文件系统。可以创建、删除、移动或重命名文件，等等。</p> 
<p>2.NemeNode   </p> 
<p>        NameNode 是一个通常在 HDFS 实例中的单独机器上运行的软件</p> 
<p>3.DetaNode  </p> 
<p>        DataNode 也是一个通常在 HDFS实例中的单独机器上运行的软件</p> 
<h2><br> 四、MapReduce编程</h2> 
<p>现有以下数据,现要求统计本次月考各科目平均成绩</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/0a/37/Nb7vHVgT_o.png"></p> 
<p>Map类</p> 
<pre><code class="language-python">package task1;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

import java.io.IOException;

public class ScoreMapper extends Mapper&lt;LongWritable, Text, Text, IntWritable&gt; {

    @Override
    protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {
        // 将文本行拆分为字段
        String[] fields = value.toString().split(",");
        // 获取课程和分数
        String course = fields[1];
        int score = Integer.parseInt(fields[2]);
        // 发送课程和分数到Reduce阶段
        context.write(new Text(course), new IntWritable(score));
    }
}


</code></pre> 
<p> Reduce类</p> 
<pre><code class="language-python">package task1;

import org.apache.hadoop.io.DoubleWritable;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;

import java.io.IOException;

public class ScoreReducer extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt; {
    @Override
    protected void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context) throws IOException, InterruptedException {
        int sum = 0;
        int count = 0;
        // 遍历所有分数，求和并计数
        for (IntWritable value : values) {
            sum += value.get();
            count++;
        }
        // 求平均数
        int average = Math.round((float) sum / count); // 四舍五入到最接近的整数
        // 输出键值对
        context.write(key, new IntWritable(average));
    }
}

</code></pre> 
<p>main方法</p> 
<pre><code class="language-python">package task1;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.DoubleWritable;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

public class ScoreAverage {
    public static void main(String[] args) throws Exception {
        Configuration conf = new Configuration();
        Job job = Job.getInstance(conf, "Score Average");
        job.setJarByClass(ScoreAverage.class);

        job.setMapperClass(ScoreMapper.class);
        job.setReducerClass(ScoreReducer.class);

        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(IntWritable.class);

        FileInputFormat.setInputPaths(job,new Path("D:\\Hadoop课程\\代码\\begin\\Hadoop\\input\\subject_score.csv"));
        FileOutputFormat.setOutputPath(job,new Path("D:\\Hadoop课程\\代码\\begin\\Hadoop\\output1\\avgcount"));

        System.exit(job.waitForCompletion(true) ? 0 : 1);
    }
}
</code></pre> 
<p>输出结果</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/65/43/wYHk7WG4_o.png"></p> 
<h2>五、总结 学习心得</h2> 
<p><br> 通过这一个学期的学习，我对hadoop的理解也多了很多，学习了很多东西这里我就写了很少的一部分。</p> 
<p>可以讲Hadoop的核心内容看作是两个部分，一个是分布式存储，一个是分布式计算。</p> 
<p>对于分布式存储，Hadoop有自己的一套系统来处理叫Hadoop distribution file system。为什么分布式存储需要一个额外的系统来处理呢，而不是就把1TB以上的文件分开存放就好了呢。如果不采用新的系统，我们存放的东西没办进行一个统一的管理。存放在A电脑的东西只能在连接到A去找，存在B的又得单独去B找。繁琐且不便于管理。而这个分布式存储文件系统能把这些文件分开存储的过程透明化，用户看不到文件是怎么存储在不同电脑上，看到的只是一个统一的管理界面。现在的云盘就是很好的给用户这种体验。</p> 
<p>对于分布式计算。在对海量数据进行处理的时候，一台机器肯定也是不够用的。所以也需要考虑将将数据分在不同的机器上并行的进行计算，这样不经可以节省大量的硬件的I/O开销。也能够将加快计算的速度。Hadoop对分布式计算的系统为MapReduce。</p> 
<p>Map即将数据分开存放进行计算，Reduce将分布计算的得到的结果进行整合，最后汇总得到一个最终的结果。这样对Hadoop的技术有一个清晰框架思路。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/d664cdb14a185c0ca780a6975b55fca2/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">基于uniapp&#43;vue3&#43;vite实现小程序构建Android、iOS多端项目配置详解</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/541ca4a4cd03e7488f869652501b2d27/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【深度学习】最强算法之：残差网络（ResNet）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>