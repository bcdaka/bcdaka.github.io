<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Intellij IDEA安装配置Spark与运行 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/e952919188f25e4944429ccce01ab950/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="Intellij IDEA安装配置Spark与运行">
  <meta property="og:description" content="目录
Scala配置教程
配置Spark运行环境
编写Spark程序
1、包和导入
2、定义对象
3、主函数
4、创建Spark配置和上下文
5、定义输入文件路径
6、单词计数逻辑
7、输出结果
8、完整代码：
Scala配置教程 IDEA配置Scala：教程
配置Spark运行环境 添加Spark开发依赖包（快捷键：Ctrl&#43;Alt&#43;Shift&#43;S）
找到Spark安装目录下的jars文件夹，将整个文件夹导入 Spark编程环境配置完成 在com.tipdm.sparkDemo包下新建WordCount类并指定类型为object，编写spark程序实现单词计数器。
选择Dependencies勾选Scala-sdk-2.12.15和jars
添加Add Content root Root
选择jars点击ok
编写Spark程序 在Scala的基础上（教程）
1、包和导入 package com.tipdm.sparkDemo import org.apache.spark.{SparkConf, SparkContext} 这里定义了一个包（com.tipdm.sparkDemo），并导入了SparkConf和SparkContext这两个类，它们都是Apache Spark的核心组件。
2、定义对象 object WordCount { 这里定义了一个单例对象WordCount。在Scala中，对象可以包含方法和字段，并且可以作为程序的入口点。
3、主函数 def main(args: Array[String]): Unit = { 这是程序的入口点，main函数。它接收一个字符串数组作为参数（通常用于命令行参数），并返回Unit（在Scala中，这相当于Java中的void）。
4、创建Spark配置和上下文 val conf = new SparkConf().setAppName(&#34;WordCount&#34;).setMaster(&#34;local&#34;) val sc = new SparkContext(conf) 首先，创建一个SparkConf对象并设置应用程序的名称为&#34;WordCount&#34;。然后，使用这个配置创建一个SparkContext对象，它是Spark应用程序的入口点。
5、定义输入文件路径 val input = &#34;C:\\Users\\John\\Desktop\\words.txt&#34; 这里定义了一个字符串变量input，它包含了要读取的文件的路径。
6、单词计数逻辑 val count = sc.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-03-27T11:00:18+08:00">
    <meta property="article:modified_time" content="2024-03-27T11:00:18+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Intellij IDEA安装配置Spark与运行</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p id="main-toc"></p> 
<p id="main-toc"><strong>目录</strong></p> 
<p id="Scala%E9%85%8D%E7%BD%AE%E6%95%99%E7%A8%8B-toc" style="margin-left:0px;"><a href="#Scala%E9%85%8D%E7%BD%AE%E6%95%99%E7%A8%8B" rel="nofollow">Scala配置教程</a></p> 
<p id="%E9%85%8D%E7%BD%AESpark%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83-toc" style="margin-left:0px;"><a href="#%E9%85%8D%E7%BD%AESpark%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83" rel="nofollow">配置Spark运行环境</a></p> 
<p id="%E7%BC%96%E5%86%99Spark%E7%A8%8B%E5%BA%8F-toc" style="margin-left:0px;"><a href="#%E7%BC%96%E5%86%99Spark%E7%A8%8B%E5%BA%8F" rel="nofollow">编写Spark程序</a></p> 
<p id="%C2%A01%E3%80%81%E5%8C%85%E5%92%8C%E5%AF%BC%E5%85%A5-toc" style="margin-left:80px;"><a href="#%C2%A01%E3%80%81%E5%8C%85%E5%92%8C%E5%AF%BC%E5%85%A5" rel="nofollow"> 1、包和导入</a></p> 
<p id="2%E3%80%81%E5%AE%9A%E4%B9%89%E5%AF%B9%E8%B1%A1-toc" style="margin-left:80px;"><a href="#2%E3%80%81%E5%AE%9A%E4%B9%89%E5%AF%B9%E8%B1%A1" rel="nofollow">2、定义对象</a></p> 
<p id="3%E3%80%81%E4%B8%BB%E5%87%BD%E6%95%B0-toc" style="margin-left:80px;"><a href="#3%E3%80%81%E4%B8%BB%E5%87%BD%E6%95%B0" rel="nofollow">3、主函数</a></p> 
<p id="4%E3%80%81%E5%88%9B%E5%BB%BASpark%E9%85%8D%E7%BD%AE%E5%92%8C%E4%B8%8A%E4%B8%8B%E6%96%87-toc" style="margin-left:80px;"><a href="#4%E3%80%81%E5%88%9B%E5%BB%BASpark%E9%85%8D%E7%BD%AE%E5%92%8C%E4%B8%8A%E4%B8%8B%E6%96%87" rel="nofollow">4、创建Spark配置和上下文</a></p> 
<p id="5%E3%80%81%E5%AE%9A%E4%B9%89%E8%BE%93%E5%85%A5%E6%96%87%E4%BB%B6%E8%B7%AF%E5%BE%84-toc" style="margin-left:80px;"><a href="#5%E3%80%81%E5%AE%9A%E4%B9%89%E8%BE%93%E5%85%A5%E6%96%87%E4%BB%B6%E8%B7%AF%E5%BE%84" rel="nofollow">5、定义输入文件路径</a></p> 
<p id="6%E3%80%81%E5%8D%95%E8%AF%8D%E8%AE%A1%E6%95%B0%E9%80%BB%E8%BE%91-toc" style="margin-left:80px;"><a href="#6%E3%80%81%E5%8D%95%E8%AF%8D%E8%AE%A1%E6%95%B0%E9%80%BB%E8%BE%91" rel="nofollow">6、单词计数逻辑</a></p> 
<p id="7%E3%80%81%E8%BE%93%E5%87%BA%E7%BB%93%E6%9E%9C-toc" style="margin-left:80px;"><a href="#7%E3%80%81%E8%BE%93%E5%87%BA%E7%BB%93%E6%9E%9C" rel="nofollow">7、输出结果</a></p> 
<p id="8%E3%80%81%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81%EF%BC%9A-toc" style="margin-left:80px;"><a href="#8%E3%80%81%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81%EF%BC%9A" rel="nofollow">8、完整代码：</a></p> 
<hr id="hr-toc"> 
<p></p> 
<h2 id="Scala%E9%85%8D%E7%BD%AE%E6%95%99%E7%A8%8B">Scala配置教程</h2> 
<p>IDEA配置Scala：<a class="link-info" href="http://t.csdnimg.cn/v0jnf" rel="nofollow" title="教程">教程</a></p> 
<h2 id="%E9%85%8D%E7%BD%AESpark%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83">配置Spark运行环境</h2> 
<p>添加Spark开发依赖包（快捷键：Ctrl+Alt+Shift+S）</p> 
<p><img alt="" height="471" src="https://images2.imgbox.com/7d/50/DPUY6uXH_o.png" width="331"></p> 
<p><img alt="" height="458" src="https://images2.imgbox.com/d2/eb/nqnllReI_o.png" width="324"></p> 
<p>找到Spark安装目录下的jars文件夹，将整个文件夹导入 </p> 
<p><img alt="" height="293" src="https://images2.imgbox.com/0d/6b/g4dEqS5y_o.png" width="631"></p> 
<p>Spark编程环境配置完成 </p> 
<p><img alt="" height="517" src="https://images2.imgbox.com/ed/e4/iNFcKkq8_o.png" width="800"></p> 
<p>在com.tipdm.sparkDemo包下新建WordCount类并指定类型为object，编写spark程序实现单词计数器。</p> 
<p><img alt="" height="735" src="https://images2.imgbox.com/93/18/rVAc7oSX_o.png" width="777"></p> 
<p><img alt="" height="545" src="https://images2.imgbox.com/9c/1c/FOUIfNEX_o.png" width="810"></p> 
<p class="img-center"><img alt="" height="204" src="https://images2.imgbox.com/b7/c8/RpQxo9d2_o.png" width="330"></p> 
<p> <img alt="" height="316" src="https://images2.imgbox.com/4a/4a/sG1ch5lG_o.png" width="808"> <img alt="" height="433" src="https://images2.imgbox.com/e7/d4/uT0yN4E4_o.png" width="1200"></p> 
<p> 选择Dependencies勾选Scala-sdk-2.12.15和jars</p> 
<p> <img alt="" height="790" src="https://images2.imgbox.com/a4/8a/bxi8oIYV_o.png" width="1003"></p> 
<p> 添加Add Content root Root</p> 
<p><img alt="" height="794" src="https://images2.imgbox.com/3e/d9/LmTrD7FM_o.png" width="1005"></p> 
<p> 选择jars点击ok</p> 
<p><img alt="" height="603" src="https://images2.imgbox.com/01/4d/PgGntRkK_o.png" width="591"></p> 
<h2 id="%E7%BC%96%E5%86%99Spark%E7%A8%8B%E5%BA%8F">编写Spark程序</h2> 
<p>        在Scala的基础上（<a class="link-info" href="http://t.csdnimg.cn/qgK9Z" rel="nofollow" title="教程">教程</a>）</p> 
<h4 id="%C2%A01%E3%80%81%E5%8C%85%E5%92%8C%E5%AF%BC%E5%85%A5"> 1、<strong>包和导入</strong></h4> 
<pre><code>package com.tipdm.sparkDemo  
import org.apache.spark.{SparkConf, SparkContext}</code></pre> 
<p> 这里定义了一个包（<code>com.tipdm.sparkDemo</code>），并导入了<code>SparkConf</code>和<code>SparkContext</code>这两个类，它们都是Apache Spark的核心组件。</p> 
<h4 id="2%E3%80%81%E5%AE%9A%E4%B9%89%E5%AF%B9%E8%B1%A1"><strong>2、定义对象</strong></h4> 
<pre><code>object WordCount {<!-- --></code></pre> 
<p> 这里定义了一个单例对象<code>WordCount</code>。在Scala中，对象可以包含方法和字段，并且可以作为程序的入口点。</p> 
<h4 id="3%E3%80%81%E4%B8%BB%E5%87%BD%E6%95%B0">3、<strong>主函数</strong></h4> 
<pre><code>def main(args: Array[String]): Unit = {<!-- --></code></pre> 
<p>这是程序的入口点，<code>main</code>函数。它接收一个字符串数组作为参数（通常用于命令行参数），并返回<code>Unit</code>（在Scala中，这相当于Java中的<code>void</code>）。</p> 
<h4 id="4%E3%80%81%E5%88%9B%E5%BB%BASpark%E9%85%8D%E7%BD%AE%E5%92%8C%E4%B8%8A%E4%B8%8B%E6%96%87"><strong>4、创建Spark配置和上下文</strong></h4> 
<pre><code>val conf = new SparkConf().setAppName("WordCount").setMaster("local")
val sc = new SparkContext(conf)</code></pre> 
<p> 首先，创建一个<code>SparkConf</code>对象并设置应用程序的名称为"WordCount"。然后，使用这个配置创建一个<code>SparkContext</code>对象，它是Spark应用程序的入口点。</p> 
<h4 id="5%E3%80%81%E5%AE%9A%E4%B9%89%E8%BE%93%E5%85%A5%E6%96%87%E4%BB%B6%E8%B7%AF%E5%BE%84"><strong>5、定义输入文件路径</strong></h4> 
<pre><code>val input = "C:\\Users\\John\\Desktop\\words.txt"</code></pre> 
<p>这里定义了一个字符串变量<code>input</code>，它包含了要读取的文件的路径。</p> 
<h4 id="6%E3%80%81%E5%8D%95%E8%AF%8D%E8%AE%A1%E6%95%B0%E9%80%BB%E8%BE%91">6、<strong>单词计数逻辑</strong></h4> 
<pre><code>val count = sc.textFile(input).flatMap(x =&gt; x.split(" ")).map(  
  x =&gt; (x, 1)).reduceByKey((x, y) =&gt; x + y)</code></pre> 
<p></p> 
<pre><code>* `sc.textFile(input)`：从指定的路径读取文件，并返回一个RDD（弹性分布式数据集），其中每个元素是文件中的一行。  
* `flatMap(x =&gt; x.split(" "))`：将每一行分割成单词，并扁平化结果。这意味着所有行的单词都会合并到一个单一的RDD中。  
* `map(x =&gt; (x, 1))`：为每个单词映射一个键值对，其中键是单词，值是1。这表示每个单词都出现了一次。  
* `reduceByKey((x, y) =&gt; x + y)`：对于具有相同键的所有值，执行reduce操作。在这里，它简单地将所有1相加，从而计算每个单词的出现次数。</code></pre> 
<h4 id="7%E3%80%81%E8%BE%93%E5%87%BA%E7%BB%93%E6%9E%9C">7、<strong>输出结果</strong></h4> 
<pre><code>count.foreach(x =&gt; println(x._1 + "," + x._2))</code></pre> 
<p>使用<code>foreach</code>操作遍历结果RDD，并打印每个单词及其出现次数。<code>x._1</code>是键（单词），<code>x._2</code>是值（出现次数）。</p> 
<p>整个程序会读取指定路径下的文件，计算每个单词的出现次数，并打印结果。这是一个使用Spark进行基本文本分析的常见示例。</p> 
<p><img alt="" height="384" src="https://images2.imgbox.com/af/20/4hUF419H_o.png" width="781"></p> 
<p> words.txt放在桌面了所以路径为</p> 
<pre><code>C:\Users\John\Desktop\words.txt</code></pre> 
<p><img alt="" height="386" src="https://images2.imgbox.com/89/bd/7oBw8yco_o.png" width="931"></p> 
<p> words.txt文件内容为：</p> 
<pre><code>Hello World Our World
Hello BigData Real BigData
Hello Hadoop Great Hadoop
HadoopMapReduce
</code></pre> 
<h4 id="8%E3%80%81%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81%EF%BC%9A">8、完整代码：</h4> 
<pre><code class="hljs">package com.tipdm.sparkDemo
import org.apache.spark.{SparkConf, SparkContext}
object WordCount {
  def main(args: Array[String]): Unit = {
    val conf = new SparkConf().setAppName("WordCount").setMaster("local")
    val sc = new SparkContext(conf)
      val input = "C:\\Users\\John\\Desktop\\words.txt"
    // 计算各个单词出现次数
    val count = sc.textFile(input).flatMap(x =&gt; x.split(" ")).map(
      x =&gt; (x, 1)).reduceByKey((x, y) =&gt; x + y)
    count.foreach(x =&gt; println(x._1 + "," + x._2))
  }
}
</code></pre> 
<p>运行成功</p> 
<p><img alt="" height="185" src="https://images2.imgbox.com/a5/77/7WxBXANB_o.png" width="1060"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/347d988917c6a05f928d8ee3fd213770/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">MySQL中使用distinct单、多字段去重方法</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/f70067b4048953ac4776eafdb1729152/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Python抓取抖音直播间数据：技术探索与实践</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>