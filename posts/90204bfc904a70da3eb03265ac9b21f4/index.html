<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>AI绘画利器：Stable-Diffusion-ComfyUI保姆级教程 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/90204bfc904a70da3eb03265ac9b21f4/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="AI绘画利器：Stable-Diffusion-ComfyUI保姆级教程">
  <meta property="og:description" content="AI绘画在今天，已经发展到了炽手可热的地步，相比于过去，无论是从画面精细度，真实性，风格化，还是对于操作的易用性，都有了很大的提升。并且如今有众多的绘画工具可选择。今天我们主要来聊聊基于stable diffusion的comfyUI！
comfyUI具有可分享，易上手，快速出图，以及配置要求不高的特点，comfyUI以节点链接的工作流方式进行绘图，对于整个出图流程也更容易理解。因此comfyUI比较适合新手入门
一、主流AI绘画工具 说到AI绘画工具，现在应该能找出很多，比较主流的有Midjourney（简称MJ），Stable Diffusion（简称SD），DallE，文心一格，Leonardo.Ai等等
• Midjourney：https://www.midjourney.com/ Midjourney
• Stable Diffusion：https://github.com/AUTOMATIC1111/stable-diffusion-webui Stable Diffusion
• DallE：https://openai.com/dall-e-3 DallE
• 文心一格：https://yige.baidu.com/ 文心一格
• Leonardo：https://app.leonardo.ai/ Leonardo
我们对主流AI工具做个简单的对比
还有一些可白嫖的AI绘画站点，大家也可以自行体验一下：
1. 神采AI（每月可白嫖100张）：https://www.promeai.com/zh-CN
2. ImageFX：https://aitestkitchen.withgoogle.com/tools/image-fx
3. Meta AI：https://imagine.meta.com/
不同的绘画工具有不同的优劣势，大家可自行探索最适合自己的工具。本文着重介绍Stable Diffusion ComfyUI
二、SD主流 UI Stable Diffusion因为其开源特性，有着较高的受欢迎程度，并且基于SD的开源社区及教程、插件等，都是所有工具里最多的。基于SD，有不同的操作界面，可以理解为一个工具的不同客户端。目前主流的操作界面有 WebUI和ComfyUI。
1. WebUI 优点：界面友好，插件丰富，新手小白基本也能秒上手 缺点：吃显存，对配置要求较高，出图较慢
WebUI
2. ComfyUI 优点：性能好，速度快，支持工作流的导入导出分享，对小显存友好（GPU小于3G以下依然可以工作），基于工作流，对出图逻辑理解更清晰 缺点：对新手用户不太友好，有一定学习成本
ComfyUI
二者各有优缺点，根据自身情况选择即可。我个人更推荐ComfyUI
三、ComfyUI 安装 对于stable-diffusion-webui，我之前有一篇文章有了比较详细的介绍，本文重点介绍ComfyUI的安装部署及使用。
传送门：看完就会！手把手入门开源AI绘图Stable Diffusion
ComfyUI 的节点流程式使用方式，非常便于对SD的绘制过程的理解，并且工作流可以导入导出以及分享，这样对于流程重现以及第三方分享更友好。整体的使用上限更高
详细的安装过程可参考B站详细教程 【【AI绘画】ComfyUI整合包发布！解压即用 一键启动 工作流版界面 超多节点 ☆更新 ☆汉化 秋叶整合包】 https://www.bilibili.com/video/BV1Ew411776J/?share_source=copy_web&amp;vd_source=b8d0b2c4c1a84965a2546f0efe2f5759
1. 安装包说明 ComfyUI 开源地址：https://github.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-03-30T14:28:25+08:00">
    <meta property="article:modified_time" content="2024-03-30T14:28:25+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">AI绘画利器：Stable-Diffusion-ComfyUI保姆级教程</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <blockquote> 
 <p>AI绘画在今天，已经发展到了炽手可热的地步，相比于过去，无论是从画面精细度，真实性，风格化，还是对于操作的易用性，都有了很大的提升。并且如今有众多的绘画工具可选择。今天我们主要来聊聊基于stable diffusion的<strong>comfyUI</strong>！</p> 
</blockquote> 
<p><code>comfyUI具有可分享，易上手，快速出图，以及配置要求不高的特点，comfyUI以节点链接的工作流方式进行绘图，对于整个出图流程也更容易理解。因此comfyUI比较适合新手入门</code></p> 
<h2><a id="AI_4"></a>一、主流AI绘画工具</h2> 
<p>说到AI绘画工具，现在应该能找出很多，比较主流的有Midjourney（简称MJ），Stable Diffusion（简称SD），DallE，文心一格，Leonardo.Ai等等</p> 
<ul><li>• <strong>Midjourney</strong>：https://www.midjourney.com/</li></ul> 
<p><img src="https://images2.imgbox.com/28/79/LrmpNzaM_o.png" alt=""></p> 
<p>Midjourney</p> 
<ul><li>• <strong>Stable Diffusion</strong>：https://github.com/AUTOMATIC1111/stable-diffusion-webui</li></ul> 
<p><img src="https://images2.imgbox.com/f4/29/WApsDdjD_o.png" alt=""></p> 
<p>Stable Diffusion</p> 
<ul><li>• <strong>DallE</strong>：https://openai.com/dall-e-3</li></ul> 
<p><img src="https://images2.imgbox.com/a8/df/tB03h3QY_o.png" alt=""></p> 
<p>DallE</p> 
<ul><li>• <strong>文心一格</strong>：https://yige.baidu.com/</li></ul> 
<p><img src="https://images2.imgbox.com/1f/55/3nq6qqqg_o.png" alt=""></p> 
<p>文心一格</p> 
<ul><li>• <strong>Leonardo</strong>：https://app.leonardo.ai/</li></ul> 
<p><img src="https://images2.imgbox.com/fc/f9/7Xxd7HOO_o.png" alt=""></p> 
<p>Leonardo</p> 
<p>我们对主流AI工具做个简单的对比</p> 
<p><img src="https://images2.imgbox.com/6d/9f/hQzQkbCg_o.png" alt=""></p> 
<blockquote> 
 <p>还有一些可白嫖的AI绘画站点，大家也可以自行体验一下：</p> 
 <ol><li> <p>1. 神采AI（每月可白嫖100张）：https://www.promeai.com/zh-CN</p> </li><li> <p>2. ImageFX：https://aitestkitchen.withgoogle.com/tools/image-fx</p> </li><li> <p>3. Meta AI：https://imagine.meta.com/</p> </li></ol> 
</blockquote> 
<blockquote> 
 <p>不同的绘画工具有不同的优劣势，大家可自行探索最适合自己的工具。本文着重介绍<strong>Stable Diffusion ComfyUI</strong></p> 
</blockquote> 
<h2><a id="SD_UI_59"></a>二、SD主流 UI</h2> 
<p>Stable Diffusion因为其开源特性，有着较高的受欢迎程度，并且基于SD的开源社区及教程、插件等，都是所有工具里最多的。基于SD，有不同的操作界面，可以理解为一个工具的不同客户端。目前主流的操作界面有 WebUI和ComfyUI。</p> 
<ol><li> <p>1. <strong>WebUI 优点</strong>：界面友好，插件丰富，新手小白基本也能秒上手 缺点：吃显存，对配置要求较高，出图较慢</p> <p><img src="https://images2.imgbox.com/12/71/l4z1Kkhb_o.png" alt=""></p> <p>WebUI</p> </li><li> <p>2. <strong>ComfyUI 优点</strong>：性能好，速度快，支持工作流的导入导出分享，对小显存友好（GPU小于3G以下依然可以工作），基于工作流，对出图逻辑理解更清晰 缺点：对新手用户不太友好，有一定学习成本</p> <p><img src="https://images2.imgbox.com/18/f6/vPTffap4_o.png" alt=""></p> <p>ComfyUI</p> </li></ol> 
<p><code>二者各有优缺点，根据自身情况选择即可。我个人更推荐ComfyUI</code></p> 
<h2><a id="ComfyUI__79"></a>三、ComfyUI 安装</h2> 
<p>对于stable-diffusion-webui，我之前有一篇文章有了比较详细的介绍，本文重点介绍ComfyUI的安装部署及使用。</p> 
<p><strong>传送门</strong>：<a href="http://mp.weixin.qq.com/s?__biz=MzI1MjI4NTM5MQ==&amp;mid=2247484094&amp;idx=1&amp;sn=5111272b24756f274dc777b1dae37dff&amp;chksm=e9e75a1ede90d30873d374841fb7ce0f9cd9cbfe71144399076cf609cde568373aa5815a00df&amp;scene=21#wechat_redirect" rel="nofollow">看完就会！手把手入门开源AI绘图Stable Diffusion</a></p> 
<p><code>ComfyUI 的节点流程式使用方式，非常便于对SD的绘制过程的理解，并且工作流可以导入导出以及分享，这样对于流程重现以及第三方分享更友好。整体的使用上限更高</code></p> 
<p>详细的安装过程可参考B站详细教程 【【AI绘画】ComfyUI整合包发布！解压即用 一键启动 工作流版界面 超多节点 ☆更新 ☆汉化 秋叶整合包】 https://www.bilibili.com/video/BV1Ew411776J/?share_source=copy_web&amp;vd_source=b8d0b2c4c1a84965a2546f0efe2f5759</p> 
<h3><a id="1__90"></a>1. 安装包说明</h3> 
<p><strong>ComfyUI 开源地址</strong>：https://github.com/comfyanonymous/ComfyUI</p> 
<p>对于程序员朋友来说，对于github的使用已经非常熟悉了，但考虑到不熟悉github的读者，以及国内对于github的网络环境的不稳定，除了github的clone之外，也推荐使用秋叶整合包，<strong>下载地址放在最后自取</strong>。</p> 
<ul><li> <p>• 若使用github自行clone项目，需要git、python等必备环境，适合对github已经git和python环境熟悉的朋友使用</p> </li><li> <p>• 若使用秋叶整合包，里面包含了所有运行时需要的环境，因此此方法适合所有人，解压即用</p> </li></ul> 
<h3><a id="2__102"></a>2. 安装文件</h3> 
<p>网盘（文末自取）中包含以下文件</p> 
<p><img src="https://images2.imgbox.com/36/56/UxAZJDbz_o.png" alt=""></p> 
<p>安装文件</p> 
<ol><li> <p>1. <strong>旧版本</strong>：基本不用管了</p> </li><li> <p>2. <strong>模型</strong>：只有基本的大模型，更多的大模型可自行去国外的C站或国内的liblib站点下载</p> </li><li> <p>C站：https://civitai.com/</p> </li><li> <p>liblib：https://www.liblib.art/</p> </li><li> <p>3. <strong>contronet</strong>：提供contronet所需模型文件，控图必须下载</p> </li><li> <p>4. <strong>入门工作流</strong>：提供基本的入门工作流，导入可直接使用</p> </li><li> <p>5. <strong>ComfyUI-aki-v1.2.7.7z</strong>：整合包压缩包，下载后解压即可使用</p> </li></ol> 
<p><code>吐槽 ：国内网盘都是坑，没有会员就慢慢下吧</code></p> 
<h3><a id="3__130"></a>3. 安装步骤</h3> 
<p>不同于傻瓜式的安装步骤，这里需要稍微做一些配置，主要是配置模型路径</p> 
<ol><li> 
  <ol><li>配置模型路径</li></ol> </li></ol> 
<ul><li> <p>• 这里分两种情况，如果你之前装了webui，并且本身已经下了很多模型了，那么恭喜你，ComfyUI对webui的模型地址做了兼容，可以通过一个配置文件即可与webui共享模型 解压后的根目录，有“extra model_paths.yaml.example”文件，我们对这个文件进行修改</p> <p><img src="https://images2.imgbox.com/b9/b8/3dEExkFk_o.png" alt=""></p> <p>extra model_paths.yaml.example</p> <p>修改完成之后，去掉example后缀，保存为yaml文件即可</p> </li><li> <p>• 如果你没有装过webui，即首次使用stable diffusion的话，那么直接解压即可，后续下载的模型只需要放在ComfyUI读取的默认路径即可</p> </li></ul> 
<table><thead><tr><th>模型</th><th>路径</th></tr></thead><tbody><tr><td>checkpoint模型（大模型）</td><td>models/checkpoints/</td></tr><tr><td>lora模型</td><td>models/loras/</td></tr><tr><td>controlNet模型</td><td>models/controlnet/</td></tr><tr><td>vae模型</td><td>models/vae/</td></tr></tbody></table> 
<ol><li> <p>2. 启动</p> </li><li> <p>启动“A 绘世启动器.exe”即可。启动后进行主界面，就可以开始ComfyUI的探索之旅了</p> </li></ol> 
<blockquote> 
 <p>若是用github自行安装的朋友，还需要下载“插件管理器”，方便后续安装插件（秋叶整合包已经包含了插件管理器），安装步骤如下 分三步：</p> 
 <ol><li> <p>1. 命令行窗口中运行：cd D:\COMFYUI路径XXXX\custom_nodes</p> </li><li> <p>2. 继续运行：git clone https://github.com/ltdrdata/ComfyUI-Manager.git</p> </li><li> 
   <ol start="3"><li>重启 ComfyUI</li></ol> </li></ol> 
</blockquote> 
<h3><a id="4__170"></a>4. 汉化</h3> 
<ul><li> <p>• 整合包可以直接点击右边设置小按钮，并对语言设为中文即可</p> </li><li> <p>• 非整合包需自行下载汉化插件，通过插件管理器搜索AIGODLIKE-ComfyUI-Translation安装即可，或类似下载插件管理器的方式在custom_nodes下git clone https://github.com/AIGODLIKE/AIGODLIKE-ComfyUI-Translation.git后重启ComfyUI</p> </li></ul> 
<h3><a id="5__178"></a>5. 学习参考</h3> 
<p>ComfyUI由于工作流的导入导出的便利，使得工作流可以互相分享学习，甚至直接使用。目前有很多工作流分享的站点，可以通过导入其他人的工作流进行学习和实践，对自身学习会非常有帮助</p> 
<ul><li> <p>ComfyUI官方示例：https://comfyanonymous.github.io/ComfyUI_examples/</p> </li><li> <p>基础工作流示范：https://github.com/wyrde/wyrde-comfyui-workflows</p> </li><li> <p>comfyworkflows：https://comfyworkflows.com/</p> </li><li> <p>esheep（国内站点，访问快）：https://www.esheep.com/</p> </li></ul> 
<h3><a id="6__192"></a>6. 插件安装</h3> 
<p>使用其他人的工作流时，我们往往会发现他们使用了某些我们并没有的节点，导致出现节点缺失的现象，这种情况下，需要我们安装缺失的节点。以下是几种安装插件的常见方式</p> 
<p>1、有KX上网环境推荐直接通过界面中的管理器安装缺失节点即可，若没有KX上网，这个过程会很痛苦</p> 
<p>2、使用整合包推荐通过启动器安装：版本管理–安装新插件–搜索插件–点击安装</p> 
<p>3、单独下载插件：单独下载插件包解压到:comfyui 安装根目录lcustom nodes目录下（与前文提到的安装插件管理器方法一致），然后重启即可。</p> 
<h2><a id="ComfyUI__203"></a>四、ComfyUI 能干啥?</h2> 
<ol><li> 
  <ol><li>基础文生图</li></ol> </li><li> 
  <ol start="2"><li>基础图生图</li></ol> </li><li> 
  <ol start="3"><li>真人转动漫/动漫转真人</li></ol> </li><li> 
  <ol start="4"><li>线稿上色</li></ol> </li><li> 
  <ol start="5"><li>老旧照片修复</li></ol> </li><li> 
  <ol start="6"><li>隐藏艺术字</li></ol> </li><li> 
  <ol start="7"><li>改变人物姿态</li></ol> </li><li> 
  <ol start="8"><li>四维彩超宝宝长相预测</li></ol> </li><li> 
  <ol start="9"><li>红包封面</li></ol> </li><li> 
  <ol start="10"><li>真人电子AI写真定制</li></ol> </li><li> 
  <ol start="11"><li>赛博朋克风格转换</li></ol> </li><li> 
  <ol start="12"><li>专属表情包</li></ol> </li><li> 
  <ol start="13"><li>手机壁纸</li></ol> </li><li> <p>14. 更多：这里不一一举例了，类似的玩法在网上可以看到很多，ComfyUI只是一个工具，具体如何应用，就要依靠自身的想象力了</p> </li></ol> 
<h2><a id="_235"></a>五、文生图工作流</h2> 
<p>在首次使用ComfyUI时，启动后就可以看到它默认提供的一个工作流，其实就是一个非常基础的<strong>文生图</strong>工作流，我们就以这个工作流对基础节点做个简单的介绍</p> 
<p>在ComfyUI中，节点和节点之间的链接以相同颜色链接即可，熟悉常用工作流之后，大概就能明白节点的链接逻辑了</p> 
<h3><a id="1K_242"></a>1、K采样器</h3> 
<p><img src="https://images2.imgbox.com/3e/82/93E9aAN1_o.png" alt=""></p> 
<p>K采样器</p> 
<blockquote> 
 <p>K采样器是SD出图流程中的核心节点，所有节点载入，数据输入，参数配置，最后都会汇总到K采样器，它会结合载入的模型，提示词的输入以及Latent输入，进行采样计算，输出得到最终图像</p> 
 <p><code>Latent，即潜空间，可以理解为SD内部流程中的图像格式，如果我们将图像作为输入，则需要通过VAE编码将其转换为Latent数据，在最后输出时，我们也需要通过VAE解码将其转换为像素空间，也就是我们最终图像</code></p> 
</blockquote> 
<h3><a id="2Checkpoint_253"></a>2、Checkpoint加载器</h3> 
<p><img src="https://images2.imgbox.com/60/16/6LIwXJOK_o.png" alt=""></p> 
<p>checkpoint加载器</p> 
<blockquote> 
 <p>checkpoint 也就是大模型，这个节点是起始点，需要选择相应的大模型，以及vae输入给采样器，clip则连接正反向提示词 <code>其中VAE可以直接使用大模型的vae去链接，也可以单独使用vae解码节点，来选择自定义的vae</code></p> 
</blockquote> 
<h3><a id="3CLIP_262"></a>3、CLIP文本编码器</h3> 
<p><img src="https://images2.imgbox.com/82/7e/emvLnaqE_o.png" alt=""></p> 
<p>CLIP文本编码器</p> 
<blockquote> 
 <p>CLIP节点则需要输入提示词，其中CLIP节点需要两个，一个作为正向提示词链接K采样器，一个作为负向提示词链接采样器</p> 
</blockquote> 
<h3><a id="4Latent_271"></a>4、空Latent</h3> 
<p><img src="https://images2.imgbox.com/e2/a3/2ixhs7Xp_o.png" alt=""></p> 
<p>空Latent</p> 
<p>使用空latent建立潜空间图像，这里主要用于控制图像尺寸和批次数量的</p> 
<h3><a id="5VAE_280"></a>5、VAE解码</h3> 
<p><img src="https://images2.imgbox.com/08/5a/eAG79XZO_o.png" alt=""></p> 
<p>VAE解码</p> 
<p>前面已经提到对于Latent潜空间图像和输出的像素图像之间，需要进行一次转换，VAE解码节点则是对这个过程转换的节点</p> 
<h3><a id="6_289"></a>6、保存图像</h3> 
<p><img src="https://images2.imgbox.com/05/27/K47Qsv76_o.png" alt=""></p> 
<p>保存图像</p> 
<p>顾名思义，即保存当前生成的图像，保存的图像除了在当前页面能看到以外，也可以在本地文件夹目录（x:\xxx\ComfyUI根目录\output）下看到所有生成的图片</p> 
<p><code>默认流程整体就这么简单，输入提示词，点击添加提示词队列，即可生成你的第一张ComfyUI图片了</code></p> 
<p><img src="https://images2.imgbox.com/64/04/KRNUih4F_o.png" alt=""></p> 
<p>ComfyUI</p> 
<h2><a id="_304"></a>六、图生图工作流</h2> 
<p>使用过WebUI的小伙伴可能要问了，文生图我懂了，那图生图怎么做呢？其实很简单，加一个图像载入节点作为数据输入就好了。前面提到，像素空间到潜空间需要做一次转换，所以我们就需要“加载图像”和“VAE编码”两个节点。</p> 
<h3><a id="1__309"></a>1. 加载图像</h3> 
<p><img src="https://images2.imgbox.com/46/cd/Md76cTws_o.png" alt=""></p> 
<p>加载图像</p> 
<h3><a id="2_VAE_316"></a>2. VAE编码</h3> 
<p><img src="https://images2.imgbox.com/bc/79/bynMxgNv_o.png" alt=""></p> 
<p>VAE编码</p> 
<p><code>通过简单地加两个节点，即把工作流改为了最基础的图生图模式，如以下工作流就是一个简单通过动漫大模型把真人转动漫的工作流，其中K采样器的降噪也就是对应WebUI中的重绘幅度，这个值越大生成图像越靠近提示词，越小则越靠近参考图像，我这里用的 0.6，看情况调整即可</code></p> 
<p><img src="https://images2.imgbox.com/c9/02/Jdj9l0hf_o.png" alt=""></p> 
<p>ComfyUI</p> 
<p><img src="https://images2.imgbox.com/2c/bd/wSi9Y4uM_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="Lora_334"></a>七、Lora</h2> 
<p>在Stable Diffusion中，Lora可谓是灵魂级别的东西，有了Lora，让模型训练的成本陡然下降，任何人都可以训练出一个自己想要的Lora模型。Lora输入SD中的微调模型，它可以通过训练素材实现主体风格的控制，或画面特征的控制，通过训练Lora，我们可以得到画风Lora，人物Lora，物体Lora等。</p> 
<p>lora 是对大模型的后续微调，所以我们在ComfyUI中添加lora只需要在大模型后面新加Lora节点即可</p> 
<p><img src="https://images2.imgbox.com/e8/2a/er1HBM7b_o.png" alt=""></p> 
<p>lora</p> 
<p>我们可以直接通过右键checkpoint加载节点即可添加lora节点</p> 
<p><img src="https://images2.imgbox.com/81/91/uL3bdkNd_o.png" alt=""></p> 
<p>添加lora节点</p> 
<p><code>当然 lora 不仅仅控制风格，可以把人物、衣服等进行炼制，控制出图的人物形象，控制出图人物的穿着都是可以的，这里推荐大家去C站寻宝吧，总有一款你喜欢的，如果没有也可以自己炼制哦。</code></p> 
<p>我们以上面的图生图工作流为例，对整体工作流添加lora节点添加宫崎骏画风lora，于是我们就得到了<strong>真人转宫崎骏动漫画风</strong>的图片</p> 
<p><img src="https://images2.imgbox.com/d4/54/u0xCTw32_o.png" alt=""></p> 
<p>工作流</p> 
<p><img src="https://images2.imgbox.com/49/47/HkUOkEhs_o.png" alt=""></p> 
<p>宫崎骏画风</p> 
<h2><a id="ControlNet_363"></a>八、ControlNet</h2> 
<p>SD相比于其他AI绘图工具的强大之处就在于它的控图能力，SD的控图依赖于它的ControNet模型（模型下载参考前文介绍），这是对于使用SD控图不得不得掌握的技能，结合大模型，Lora模型，和ControlNet，三者结合能更好的创造出你所想的画面<br> ControINet 有独立的控制图像，通过对图像的预处理，再结合提示词进行生成图像<br> <code>不同的预处理可以对生成的图像进行不同的控制，一般有风格约束、线条约束、姿态约束、景深控制等，不管是WebUI还是ComfyUI， 都有强大ControlNet，这里不详细介绍ControlNet，主要讲下如何在ComfyUI中使用ControlNet。</code></p> 
<p>因此，在使用ControlNet时，需要添加几个关键节点：<strong>预处理器</strong>、<strong>ControlNet应用</strong>、<strong>ControlNet加载器</strong>、<strong>加载图像</strong>、<strong>预览图像</strong>、<strong>VAE解码</strong></p> 
<h3><a id="1__373"></a>1. 预处理器</h3> 
<p><img src="https://images2.imgbox.com/99/53/MItrHtch_o.png" alt=""></p> 
<p>预处理器节点</p> 
<p><img src="https://images2.imgbox.com/82/a7/cmUNehT6_o.png" alt=""></p> 
<p>添加预处理器</p> 
<blockquote> 
 <p>预处理器的作用是选择需要对图像进行的控制方向，这里我们以线条控制为例，让预处理器导出一份预览图像，这样我们能直观的看到预处理的结果</p> 
</blockquote> 
<p><img src="https://images2.imgbox.com/bb/41/scGbrW7E_o.png" alt=""></p> 
<p>预处理结果</p> 
<h3><a id="2_ControlNet_390"></a>2. ControlNet加载器</h3> 
<p>ControlNet加载器则用于加载我们需要控图的模型，与预处理器对应就好，前面我们选了线条处理，所以这里我们使用线条的加载器“<strong>control v11p sd15 lineart.pth</strong>”</p> 
<p><img src="https://images2.imgbox.com/e1/b6/DihPbDyq_o.png" alt=""></p> 
<p>ControlNet加载器</p> 
<h3><a id="3_ControlNet_399"></a>3. ControlNet应用</h3> 
<p>ControlNet应用则用于把正想提示词、预处理器、以及加载器进行统一应用的节点，相当于中间连接器</p> 
<p><img src="https://images2.imgbox.com/a5/32/B7DFBWyF_o.png" alt=""></p> 
<p>ControlNet应用</p> 
<p>以下则是一个通过文生图+ControlNet线条控制进行真人转动漫的工作流</p> 
<p><img src="https://images2.imgbox.com/08/78/ksP3ZpES_o.png" alt=""></p> 
<p>工作流</p> 
<p><code>没错，真人转动漫可以直接图生图，也可以通过文生图+ControlNet进行控图转换，使用ControlNet转换的好处在于可以对图片细节进行更加精细的控制，比如我使用线条处理，那么最后出图效果会更加基于原图的线条来生成</code></p> 
<h2><a id="_416"></a>九、资源下载</h2> 
<p>大家可以在我前面提到的站点下载别人分享的工作流来学习实践，我这里也存了一些常用的工作流</p> 
<p><img src="https://images2.imgbox.com/df/d9/GduMvdfh_o.png" alt=""></p> 
<h3><a id="_436"></a>写在最后</h3> 
<p>AIGC技术的未来发展前景广阔，随着人工智能技术的不断发展，AIGC技术也将不断提高。未来，AIGC技术将在游戏和计算领域得到更广泛的应用，使游戏和计算系统具有更高效、更智能、更灵活的特性。同时，AIGC技术也将与人工智能技术紧密结合，在更多的领域得到广泛应用，对程序员来说影响至关重要。未来，AIGC技术将继续得到提高，同时也将与人工智能技术紧密结合，在更多的领域得到广泛应用。</p> 
<p><font face="幼圆" size="4" color="red">感兴趣的小伙伴，赠送全套AIGC学习资料和安装工具，包含AI绘画、AI人工智能等前沿科技教程，模型插件，具体看下方。<br> </font><br> <img src="https://images2.imgbox.com/37/4f/Oalgj2aW_o.jpg"></p> 
<p><strong>一、AIGC所有方向的学习路线</strong></p> 
<p>AIGC所有方向的技术点做的整理，形成各个领域的知识点汇总，它的用处就在于，你可以按照下面的知识点去找对应的学习资源，保证自己学得较为全面。</p> 
<p><img src="https://images2.imgbox.com/9e/97/8hr1w159_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/3f/b8/XVFpbUOY_o.png" alt="在这里插入图片描述"></p> 
<p><strong>二、AIGC必备工具</strong></p> 
<p>工具都帮大家整理好了，安装就可直接上手！<br> <img src="https://images2.imgbox.com/6b/00/8FiMhh5F_o.png" alt="在这里插入图片描述"></p> 
<p><strong>三、最新AIGC学习笔记</strong></p> 
<p>当我学到一定基础，有自己的理解能力的时候，会去阅读一些前辈整理的书籍或者手写的笔记资料，这些笔记详细记载了他们对一些技术点的理解，这些理解是比较独到，可以学到不一样的思路。<br> <img src="https://images2.imgbox.com/03/8b/WqFAbLkE_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/76/18/nqkfPZQX_o.png" alt="在这里插入图片描述"></p> 
<p><strong>四、AIGC视频教程合集</strong></p> 
<p>观看全面零基础学习视频，看视频学习是最快捷也是最有效果的方式，跟着视频中老师的思路，从基础到深入，还是很容易入门的。</p> 
<p><img src="https://images2.imgbox.com/df/cc/uKsjne1r_o.png" alt="在这里插入图片描述"></p> 
<p><strong>五、实战案例</strong></p> 
<p>纸上得来终觉浅，要学会跟着视频一起敲，要动手实操，才能将自己的所学运用到实际当中去，这时候可以搞点实战案例来学习。<br> <img src="https://images2.imgbox.com/3a/df/DiBvToQs_o.png" alt="在这里插入图片描述"></p> 
<img src="https://images2.imgbox.com/60/04/mkUzcpos_o.jpg"> 若有侵权，请联系删除
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/ca5941f529f224e01d6bf37a2dbf3855/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">单链表——单链表的定义及基本操作（头插法尾插法建表、查找、插入、删除等）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/d3b816a758ebc3edb947f51b019ace14/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">AI绘画SD神器插件Inpaint Anything---简单快速实现换装换脸</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>