<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>常见AI模型参数量-以及算力需求评估 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/6427c0f525b3a8a061c8e543b5f8f6dc/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="常见AI模型参数量-以及算力需求评估">
  <meta property="og:description" content="文章目录 token和byte有换算关系吗？大模型开源链接和大模型套件大模型对推理算力需求4-bit Model Requirements for LLaMA昇思和业界开源大模型关于算力、训练时长不同参数量下算力需求典型大模型下算力需求常见小模型参数量推理训练算力需求分析训练推理 参考 token和byte有换算关系吗？ 盘古一个token=0.75个单词，1token相当于1.5个汉字；
以中文为例：token和byte的关系
1GB=0.5G token=0.25B token；
Token 设计原则理解：英文中有些单词会根据语义拆分，如overweight会被设计为2个token，over和weight；
中文中有些汉语会根据语义被整合，如“等于”、“王者荣耀”；
大模型开源链接和大模型套件 大模型应用方向开源链接悟空画画文生图https://github.com/mindspore-lab/minddiffusion/tree/main/vision/wukong-huahuaTaichu-GLIDE文生图https://github.com/mindspore-lab/minddiffusion/tree/main/vision/Taichu-GLIDECodeGeex代码生成https://github.com/THUDM/CodeGeeX鹏城盘古文本生成预训练https://gitee.com/mindspore/models/tree/master/official/nlp/Pangu_alpha紫东太初图文音三模型https://gitee.com/mindspore/zidongtaichuLuojiaNet遥感框架https://github.com/WHULuoJiaTeam/luojianet空天灵眸多模态遥感（当前为10亿级别参数）https://gitee.com/mindspore/ringmo-framework大模型套件套件内容开源链接mindformerstransformer大模型套件https://gitee.com/mindspore/mindformersminddiffusiondiffusion模型套件https://github.com/mindspore-lab/minddiffusionMindPet微调套件https://github.com/mindspore-lab/mindpet 大模型对推理算力需求 4-bit Model Requirements for LLaMA ModelModel SizeMinimum Total VRAMCard examplesRAM/Swap to Load*LLaMA-7B3.5GB6GBRTX 1660, 2060, AMD 5700xt, RTX 3050, 306016 GBLLaMA-13B6.5GB10GBAMD 6900xt, RTX 2060 12GB, 3060 12GB, 3080, A200032 GBLLaMA-30B15.8GB20GBRTX 3080 20GB, A4500, A5000, 3090, 4090, 6000, Tesla V10064 GBLLaMA-65B31.2GB40GBA100 40GB, 2x3090, 2x4090, A40, RTX A6000, 8000, Titan Ada128 GB 来源：https://gist.github.com/cedrickchee/255f121a991e75d271035d8a659ae44d">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2023-08-01T09:29:03+08:00">
    <meta property="article:modified_time" content="2023-08-01T09:29:03+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">常见AI模型参数量-以及算力需求评估</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><ul><li><a href="#tokenbyte_4" rel="nofollow">token和byte有换算关系吗？</a></li><li><a href="#_11" rel="nofollow">大模型开源链接和大模型套件</a></li><li><a href="#_27" rel="nofollow">大模型对推理算力需求</a></li><li><a href="#4bit_Model_Requirements_for_LLaMA_29" rel="nofollow">4-bit Model Requirements for LLaMA</a></li><li><a href="#_40" rel="nofollow">昇思和业界开源大模型关于算力、训练时长</a></li><li><a href="#_61" rel="nofollow">不同参数量下算力需求</a></li><li><a href="#_72" rel="nofollow">典型大模型下算力需求</a></li><li><a href="#_102" rel="nofollow">常见小模型参数量</a></li><li><a href="#_154" rel="nofollow">推理训练算力需求分析</a></li><li><ul><li><a href="#_156" rel="nofollow">训练</a></li><li><a href="#_193" rel="nofollow">推理</a></li></ul> 
   </li><li><a href="#_205" rel="nofollow">参考</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h3><a id="tokenbyte_4"></a>token和byte有换算关系吗？</h3> 
<p>盘古一个token=0.75个单词，1token相当于1.5个汉字；<br> 以中文为例：token和byte的关系<br> 1GB=0.5G token=0.25B token；<br> Token 设计原则理解：英文中有些单词会根据语义拆分，如overweight会被设计为2个token，over和weight；<br> 中文中有些汉语会根据语义被整合，如“等于”、“王者荣耀”；</p> 
<h3><a id="_11"></a>大模型开源链接和大模型套件</h3> 
<table><thead><tr><th>大模型</th><th>应用方向</th><th>开源链接</th></tr></thead><tbody><tr><td>悟空画画</td><td>文生图</td><td>https://github.com/mindspore-lab/minddiffusion/tree/main/vision/wukong-huahua</td></tr><tr><td>Taichu-GLIDE</td><td>文生图</td><td>https://github.com/mindspore-lab/minddiffusion/tree/main/vision/Taichu-GLIDE</td></tr><tr><td>CodeGeex</td><td>代码生成</td><td>https://github.com/THUDM/CodeGeeX</td></tr><tr><td>鹏城盘古</td><td>文本生成预训练</td><td>https://gitee.com/mindspore/models/tree/master/official/nlp/Pangu_alpha</td></tr><tr><td>紫东太初</td><td>图文音三模型</td><td>https://gitee.com/mindspore/zidongtaichu</td></tr><tr><td>LuojiaNet</td><td>遥感框架</td><td>https://github.com/WHULuoJiaTeam/luojianet</td></tr><tr><td>空天灵眸</td><td>多模态遥感（当前为10亿级别参数）</td><td>https://gitee.com/mindspore/ringmo-framework</td></tr><tr><td><strong>大模型套件</strong></td><td><strong>套件内容</strong></td><td><strong>开源链接</strong></td></tr><tr><td>mindformers</td><td>transformer大模型套件</td><td>https://gitee.com/mindspore/mindformers</td></tr><tr><td>minddiffusion</td><td>diffusion模型套件</td><td>https://github.com/mindspore-lab/minddiffusion</td></tr><tr><td>MindPet</td><td>微调套件</td><td>https://github.com/mindspore-lab/mindpet</td></tr></tbody></table> 
<h3><a id="_27"></a>大模型对推理算力需求</h3> 
<h3><a id="4bit_Model_Requirements_for_LLaMA_29"></a>4-bit Model Requirements for LLaMA</h3> 
<table><thead><tr><th>Model</th><th>Model Size</th><th>Minimum Total VRAM</th><th>Card examples</th><th>RAM/Swap to Load*</th></tr></thead><tbody><tr><td>LLaMA-7B</td><td>3.5GB</td><td>6GB</td><td>RTX 1660, 2060, AMD 5700xt, RTX 3050, 3060</td><td>16 GB</td></tr><tr><td>LLaMA-13B</td><td>6.5GB</td><td>10GB</td><td>AMD 6900xt, RTX 2060 12GB, 3060 12GB, 3080, A2000</td><td>32 GB</td></tr><tr><td>LLaMA-30B</td><td>15.8GB</td><td>20GB</td><td>RTX 3080 20GB, A4500, A5000, 3090, 4090, 6000, Tesla V100</td><td>64 GB</td></tr><tr><td>LLaMA-65B</td><td>31.2GB</td><td>40GB</td><td>A100 40GB, 2x3090, 2x4090, A40, RTX A6000, 8000, Titan Ada</td><td>128 GB</td></tr></tbody></table> 
<p>来源：https://gist.github.com/cedrickchee/255f121a991e75d271035d8a659ae44d</p> 
<h3><a id="_40"></a>昇思和业界开源大模型关于算力、训练时长</h3> 
<table><thead><tr><th></th><th>参数</th><th>数据</th><th>训练算力</th><th>时长</th></tr></thead><tbody><tr><td>鹏城盘古</td><td>100B</td><td>300B token</td><td>512P Ascend910</td><td>28天</td></tr><tr><td>鹏城盘古</td><td>200B</td><td>300B token</td><td>512P Ascend910</td><td>41天</td></tr><tr><td>紫东太初</td><td>1B</td><td>1.3亿图文对</td><td>16P Ascend910</td><td>10天</td></tr><tr><td>紫东太初</td><td>100B</td><td>300万图文对</td><td>128P Ascend910</td><td>30天</td></tr><tr><td>空天灵眸</td><td>1B</td><td>200w遥感图片（250G）</td><td>20P Ascend910</td><td>3天</td></tr><tr><td>空天灵眸</td><td>10B</td><td>500w遥感图片（600G）</td><td>20P Ascend910</td><td>30天</td></tr><tr><td>燃灯</td><td>20B</td><td>400B token（加载预训练权重）+200B token（新数据）</td><td>64P Ascend910</td><td>27天</td></tr><tr><td>CodeGeeX</td><td>13B</td><td>850B token</td><td>384P Ascend910</td><td>60天</td></tr><tr><td>盘古Sigma</td><td>1T</td><td>300B token</td><td>128P Ascend910</td><td>100天</td></tr><tr><td>悟空画画</td><td>1B</td><td>5000万图文对</td><td>64P Ascend910</td><td>30天</td></tr><tr><td>东方御风</td><td>2B</td><td>10W流场图</td><td>16P Ascend910</td><td>3天</td></tr><tr><td>GPT3</td><td>175B</td><td>300B token</td><td>2048卡 A100</td><td>15天</td></tr><tr><td>GPT3</td><td>175B</td><td>300B token</td><td>1024卡 A100</td><td>34天</td></tr><tr><td>ChatGPT</td><td>175B（预训练）+6B（强化）</td><td>300B token估算</td><td>2048卡 A100</td><td>15.25天</td></tr><tr><td>ASR</td><td>千万</td><td>178小时语音</td><td>4卡 Ascend910</td><td>15H</td></tr><tr><td>wav2vec2.0</td><td>3亿</td><td>3000小时语音</td><td>32卡 Ascend910</td><td>120H</td></tr><tr><td>hubert</td><td>3亿</td><td>1w小时语音</td><td>32卡 Ascend910</td><td>10天</td></tr></tbody></table> 
<h3><a id="_61"></a>不同参数量下算力需求</h3> 
<table><thead><tr><th></th><th>模型参数量（亿）</th><th>数据量</th><th>并行卡数（如A100）</th><th>时间（天）</th><th>算力（P/天）</th></tr></thead><tbody><tr><td>1</td><td>10</td><td>300 billion token</td><td>12</td><td>40</td><td>312Tx12=<strong>3.7P</strong>;</td></tr><tr><td>2</td><td>100</td><td>300 billion token</td><td>128</td><td>40</td><td>312Tx128=<strong>40P</strong>;</td></tr><tr><td>3</td><td>1000</td><td>1 trillion token</td><td>2048</td><td>60</td><td>312Tx2048=<strong>638P</strong>;</td></tr><tr><td>4</td><td></td><td></td><td></td><td></td><td></td></tr></tbody></table> 
<h3><a id="_72"></a>典型大模型下算力需求</h3> 
<table><thead><tr><th></th><th>模型参数量（亿）</th><th>数据量</th><th>时间（天）</th><th>算力（P/天）</th><th>金额</th></tr></thead><tbody><tr><td>盘古</td><td>2.6B</td><td>600G</td><td>3</td><td>110</td><td></td></tr><tr><td>盘古</td><td>13B</td><td>600G</td><td>7</td><td>110</td><td></td></tr><tr><td><strong>ChatGPT</strong></td><td>13</td><td>300 billion token</td><td>27.5</td><td>27.5</td><td>一次模型训练成本超过1200万美元</td></tr><tr><td>GPT-3 XL</td><td>13</td><td>300 billion token</td><td>27.5</td><td>27.5</td><td></td></tr><tr><td>GPT-3</td><td>1746</td><td>300 billion token</td><td>1</td><td>3640</td><td>一次模型训练成本超过460万美元</td></tr><tr><td>GPT-3.5</td><td></td><td></td><td>1</td><td>3640</td><td></td></tr></tbody></table> 
<p>注：ChatGPT训练所用的模型是基于13亿参数的GPT-3.5模型微调而来</p> 
<p><img src="https://images2.imgbox.com/66/5a/fwG6BXSY_o.png" alt="在这里插入图片描述"></p> 
<p>来源：https://arxiv.org/abs/2005.14165</p> 
<p><img src="https://images2.imgbox.com/8b/2c/7sYqo599_o.png" alt="在这里插入图片描述"></p> 
<p>来源：https://arxiv.org/abs/2104.12369</p> 
<p><img src="https://images2.imgbox.com/29/18/M8EyWQ6w_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/28/2c/PM4rhRo8_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="_102"></a>常见小模型参数量</h3> 
<p>来源： https://github.com/Lyken17/pytorch-OpCounter</p> 
<table><thead><tr><th>Model</th><th>Params(M)</th><th>MACs(G)</th></tr></thead><tbody><tr><td>alexnet</td><td>61.10</td><td>0.77</td></tr><tr><td>vgg11</td><td>132.86</td><td>7.74</td></tr><tr><td>vgg11_bn</td><td>132.87</td><td>7.77</td></tr><tr><td>vgg13</td><td>133.05</td><td>11.44</td></tr><tr><td>vgg13_bn</td><td>133.05</td><td>11.49</td></tr><tr><td>vgg16</td><td>138.36</td><td>15.61</td></tr><tr><td>vgg16_bn</td><td>138.37</td><td>15.66</td></tr><tr><td>vgg19</td><td>143.67</td><td>19.77</td></tr><tr><td>vgg19_bn</td><td>143.68</td><td>19.83</td></tr><tr><td>resnet18</td><td>11.69</td><td>1.82</td></tr><tr><td>resnet34</td><td>21.80</td><td>3.68</td></tr><tr><td>resnet50</td><td>25.56</td><td>4.14</td></tr><tr><td>resnet101</td><td>44.55</td><td>7.87</td></tr><tr><td>resnet152</td><td>60.19</td><td>11.61</td></tr><tr><td>wide_resnet101_2</td><td>126.89</td><td>22.84</td></tr><tr><td>wide_resnet50_2</td><td>68.88</td><td>11.46</td></tr></tbody></table> 
<table><thead><tr><th>Model</th><th>Params(M)</th><th>MACs(G)</th></tr></thead><tbody><tr><td>resnext50_32x4d</td><td>25.03</td><td>4.29</td></tr><tr><td>resnext101_32x8d</td><td>88.79</td><td>16.54</td></tr><tr><td>densenet121</td><td>7.98</td><td>2.90</td></tr><tr><td>densenet161</td><td>28.68</td><td>7.85</td></tr><tr><td>densenet169</td><td>14.15</td><td>3.44</td></tr><tr><td>densenet201</td><td>20.01</td><td>4.39</td></tr><tr><td>squeezenet1_0</td><td>1.25</td><td>0.82</td></tr><tr><td>squeezenet1_1</td><td>1.24</td><td>0.35</td></tr><tr><td>mnasnet0_5</td><td>2.22</td><td>0.14</td></tr><tr><td>mnasnet0_75</td><td>3.17</td><td>0.24</td></tr><tr><td>mnasnet1_0</td><td>4.38</td><td>0.34</td></tr><tr><td>mnasnet1_3</td><td>6.28</td><td>0.53</td></tr><tr><td>mobilenet_v2</td><td>3.50</td><td>0.33</td></tr><tr><td>shufflenet_v2_x0_5</td><td>1.37</td><td>0.05</td></tr><tr><td>shufflenet_v2_x1_0</td><td>2.28</td><td>0.15</td></tr><tr><td>shufflenet_v2_x1_5</td><td>3.50</td><td>0.31</td></tr><tr><td>shufflenet_v2_x2_0</td><td>7.39</td><td>0.60</td></tr><tr><td>inception_v3</td><td>27.16</td><td>5.75</td></tr></tbody></table> 
<h3><a id="_154"></a>推理训练算力需求分析</h3> 
<h4><a id="_156"></a>训练</h4> 
<p>主要以机器视觉应用使能人工智能算力分析为课题，其中的视觉能力训练平台、图像增强模型、目标检测、图像分割、人员跟踪需求。</p> 
<p>对人工智能算力需求计算过程如下：</p> 
<p>参考业界流行的视频训练算法(表一、第四章)，训练一个模型需要2560TFLOPS FP16算力（8卡/周，单卡算力为320 TFLOPS FP16），运算时间为7天左右，且通常需要训练大于8~10次才能找到一个满意的模型。</p> 
<p>考虑2天的调测，安装和模型更新时间，则一个模型的训练周一为10天。</p> 
<p>综上，至少需占用要2560*8=20480 TFLOPS FP16算力，才能在10天内找到一个满意的训练模型；</p> 
<p>按照目标检测，分割，跟踪等常规模型统计，预计一年有30+任务需要分别训练；总算力需求20PFLOPS FP16。</p> 
<center>
  表一：业界流行的视频训练算法 
 <center> 
 </center> 
 <table><thead><tr><th><strong>序号</strong></th><th><strong>算法分类</strong></th><th><strong>算法需求</strong></th><th><strong>模型参考</strong></th><th><strong>数据量参考</strong></th><th><strong>所需算力</strong> (TFLOPS FP16)</th><th><strong>训练时间</strong>/周</th><th><strong>训练次数</strong></th></tr></thead><tbody><tr><td><strong>1</strong></td><td>视频异常检测</td><td>CLAWS</td><td></td><td>＞200G视频数据</td><td>20480</td><td>1</td><td>10</td></tr><tr><td><strong>2</strong></td><td>视频异常检测</td><td>C3D</td><td></td><td></td><td>20480</td><td>1</td><td>10</td></tr><tr><td><strong>3</strong></td><td>视频活动分析</td><td>SlowFast</td><td></td><td></td><td>20480</td><td>1</td><td>10</td></tr><tr><td><strong>4</strong></td><td>视频活动分析</td><td>AlphAction</td><td></td><td></td><td>20480</td><td>1</td><td>10</td></tr><tr><td><strong>5</strong></td><td>图像分类基础网络</td><td>ResNet系列：resnet18, resnet34, resnet50, resnet101</td><td>resnet50,</td><td>ImageNet, ~150G图片</td><td>2560</td><td>1</td><td>8</td></tr><tr><td><strong>6</strong></td><td></td><td>MobileNet系列：MobileNetV1, MobileNetV2, MobileNetV3</td><td>mobilenetv2,</td><td></td><td>2560</td><td>1</td><td>8</td></tr><tr><td><strong>7</strong></td><td>人脸识别算法</td><td>图像分类Backbone，FaceNet</td><td>FaceNet NN1,</td><td>MS-Celeb-1M LFW, 1万+张图片 Adience, 2万+张图片 Color FERET, 1万+张图片</td><td>2560</td><td>1</td><td>8</td></tr><tr><td><strong>8</strong></td><td>目标检测</td><td>一阶段：SSD，yolo系列：yolov3, yolov4, yolov5</td><td>YOLOv3-608,</td><td>COCO 2017, ＞25F数据</td><td>2560</td><td>1</td><td>8</td></tr><tr><td><strong>9</strong></td><td>二阶段：FasterRCNN</td><td>faster rcnn + resnet101,</td><td></td><td></td><td>2560</td><td>1</td><td>8</td></tr><tr><td><strong>10</strong></td><td>分割算法</td><td>yolact, yolact++（unet、unet++）</td><td>maskrcnn+resnet50 fpn,</td><td></td><td>2560</td><td>1</td><td>8</td></tr><tr><td><strong>11</strong></td><td></td><td>MaskRCNN</td><td></td><td></td><td>2560</td><td>1</td><td>8</td></tr><tr><td><strong>12</strong></td><td>人员跟踪</td><td>DensePeds</td><td></td><td>100G图片</td><td>2560</td><td>1</td><td>8</td></tr><tr><td><strong>13</strong></td><td>底层图像增强</td><td>CycleGAN等</td><td></td><td>＞10G视频数据</td><td>2560</td><td>1</td><td>8</td></tr><tr><td><strong>14</strong></td><td>维护预测算法</td><td></td><td></td><td>＞1G数据</td><td>2560</td><td>1</td><td>8</td></tr><tr><td><strong>15</strong></td><td>洗煤优化算法</td><td></td><td></td><td>＞1G数据</td><td>2560</td><td>1</td><td>8</td></tr></tbody></table> 
 <h4><a id="_193"></a>推理</h4> 
 <p>推理服务器算力资源：采用适合张量计算的创新人工智能芯片架构，提供高性能视频解析能力和人工智能算力，用于AI应用场景人工智能算法的推理，系统支持3000路视频流解析；</p> 
 <p>基于昇腾芯片的AI推理卡，主要用于视频对象和行为分析，需要从视频流中提取对象和行为数据，每块AI推理卡的算力为88T（INT8）。</p> 
 <p>不同的算法模型对计算能力的要求不同，对于视频分析场景，通过业界主流ISV在该AI推理卡的测试结果来看，在每路视频的分辨率为不低于1080P，帧率不低于25帧，同屏检测目标数不低于5个的情况下，每路视频需要5.5T(INT8)的算力进行解析。单张AI推理卡算力为88T（INT8），所以每张推理卡可支持16路视频的分析。</p> 
 <p>如当前业务需要接入3000路视频的需求来计算，共需要的AI推理卡的数量为：3000/16≈188块。考虑到数据加工集群建模的并行效率（一般集群的并行效率为90%左右），留出适当的资源后需要的NPU卡的数量为：188/0.9≈209块。</p> 
 <h3><a id="_205"></a>参考</h3> 
 <p>1、https://arxiv.org/abs/2005.14165</p> 
 <p>2、<a href="https://blog.csdn.net/weixin_39833897/article/details/105807172">CNN的参数量、计算量（FLOPs、MACs）与运行速度</a></p> 
</center>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/d7ad9a2c359bad4b3a027cee7c9359b9/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【Python系列】Python基础语法轻松入门—从变量到循环</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/99083a46c8a13a5e7a3b66f0c37f3a2d/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【Android】SDK安装及配置</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>