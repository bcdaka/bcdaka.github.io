<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>在Jupyter Notebook中进行大数据分析：集成Apache Spark - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/1ffffdebafd94ac25e0db490b669fc1f/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="在Jupyter Notebook中进行大数据分析：集成Apache Spark">
  <meta property="og:description" content="在Jupyter Notebook中进行大数据分析：集成Apache Spark 介绍 Jupyter Notebook是一款广泛使用的数据科学工具，结合Apache Spark后，能够处理和分析大规模数据。Apache Spark是一个快速的统一分析引擎，支持大数据处理和分布式计算。本教程将详细介绍如何在Jupyter Notebook中集成和使用Spark进行大数据分析。
前提条件 基本的Python编程知识基本的Spark和大数据处理概念安装必要的软件：Jupyter Notebook、Apache Spark 教程大纲 环境设置Spark安装与配置Jupyter Notebook与Spark的集成Spark DataFrame基础操作数据处理与分析高级分析与机器学习总结与展望 1. 环境设置 1.1 安装Jupyter Notebook 在终端中执行以下命令来安装Jupyter Notebook：
pip install jupyter 1.2 安装Apache Spark 从Apache Spark官网下载并解压Spark：
wget https://downloads.apache.org/spark/spark-3.1.2/spark-3.1.2-bin-hadoop2.7.tgz tar -xzf spark-3.1.2-bin-hadoop2.7.tgz 1.3 配置环境变量 将Spark添加到环境变量中。在~/.bashrc或~/.zshrc文件中添加以下内容：
export SPARK_HOME=~/spark-3.1.2-bin-hadoop2.7 export PATH=$SPARK_HOME/bin:$PATH 然后执行以下命令使配置生效：
source ~/.bashrc 2. Spark安装与配置 2.1 安装PySpark 在终端中执行以下命令来安装PySpark：
pip install pyspark 2.2 验证安装 在终端中执行以下命令验证安装是否成功：
pyspark 如果进入了Spark Shell，说明安装成功。输入exit()退出Spark Shell。
3. Jupyter Notebook与Spark的集成 3.1 启动Jupyter Notebook 在终端中执行以下命令启动Jupyter Notebook：">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-07-20T13:23:35+08:00">
    <meta property="article:modified_time" content="2024-07-20T13:23:35+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">在Jupyter Notebook中进行大数据分析：集成Apache Spark</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="Jupyter_NotebookApache_Spark_0"></a>在Jupyter Notebook中进行大数据分析：集成Apache Spark</h2> 
<h3><a id="_2"></a>介绍</h3> 
<p>Jupyter Notebook是一款广泛使用的数据科学工具，结合Apache Spark后，能够处理和分析大规模数据。Apache Spark是一个快速的统一分析引擎，支持大数据处理和分布式计算。本教程将详细介绍如何在Jupyter Notebook中集成和使用Spark进行大数据分析。</p> 
<h3><a id="_6"></a>前提条件</h3> 
<ul><li>基本的Python编程知识</li><li>基本的Spark和大数据处理概念</li><li>安装必要的软件：Jupyter Notebook、Apache Spark</li></ul> 
<h3><a id="_12"></a>教程大纲</h3> 
<ol><li>环境设置</li><li>Spark安装与配置</li><li>Jupyter Notebook与Spark的集成</li><li>Spark DataFrame基础操作</li><li>数据处理与分析</li><li>高级分析与机器学习</li><li>总结与展望</li></ol> 
<h3><a id="1__22"></a>1. 环境设置</h3> 
<h4><a id="11_Jupyter_Notebook_24"></a>1.1 安装Jupyter Notebook</h4> 
<p>在终端中执行以下命令来安装Jupyter Notebook：</p> 
<pre><code class="prism language-bash">pip <span class="token function">install</span> jupyter
</code></pre> 
<h4><a id="12_Apache_Spark_32"></a>1.2 安装Apache Spark</h4> 
<p>从Apache Spark官网下载并解压Spark：</p> 
<pre><code class="prism language-bash"><span class="token function">wget</span> https://downloads.apache.org/spark/spark-3.1.2/spark-3.1.2-bin-hadoop2.7.tgz
<span class="token function">tar</span> <span class="token parameter variable">-xzf</span> spark-3.1.2-bin-hadoop2.7.tgz
</code></pre> 
<h4><a id="13__41"></a>1.3 配置环境变量</h4> 
<p>将Spark添加到环境变量中。在<code>~/.bashrc</code>或<code>~/.zshrc</code>文件中添加以下内容：</p> 
<pre><code class="prism language-bash"><span class="token builtin class-name">export</span> <span class="token assign-left variable">SPARK_HOME</span><span class="token operator">=~</span>/spark-3.1.2-bin-hadoop2.7
<span class="token builtin class-name">export</span> <span class="token assign-left variable"><span class="token environment constant">PATH</span></span><span class="token operator">=</span><span class="token variable">$SPARK_HOME</span>/bin:<span class="token environment constant">$PATH</span>
</code></pre> 
<p>然后执行以下命令使配置生效：</p> 
<pre><code class="prism language-bash"><span class="token builtin class-name">source</span> ~/.bashrc
</code></pre> 
<h3><a id="2_Spark_56"></a>2. Spark安装与配置</h3> 
<h4><a id="21_PySpark_58"></a>2.1 安装PySpark</h4> 
<p>在终端中执行以下命令来安装PySpark：</p> 
<pre><code class="prism language-bash">pip <span class="token function">install</span> pyspark
</code></pre> 
<h4><a id="22__66"></a>2.2 验证安装</h4> 
<p>在终端中执行以下命令验证安装是否成功：</p> 
<pre><code class="prism language-bash">pyspark
</code></pre> 
<p>如果进入了Spark Shell，说明安装成功。输入<code>exit()</code>退出Spark Shell。</p> 
<h3><a id="3_Jupyter_NotebookSpark_76"></a>3. Jupyter Notebook与Spark的集成</h3> 
<h4><a id="31_Jupyter_Notebook_78"></a>3.1 启动Jupyter Notebook</h4> 
<p>在终端中执行以下命令启动Jupyter Notebook：</p> 
<pre><code class="prism language-bash">jupyter notebook
</code></pre> 
<h4><a id="32_Notebook_86"></a>3.2 创建新的Notebook</h4> 
<p>在Jupyter Notebook界面中，选择<code>New</code> -&gt; <code>Python 3</code>创建一个新的Notebook。</p> 
<h4><a id="33_Spark_90"></a>3.3 配置Spark会话</h4> 
<p>在新的Notebook中，配置并启动Spark会话：</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> findspark
findspark<span class="token punctuation">.</span>init<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">from</span> pyspark<span class="token punctuation">.</span>sql <span class="token keyword">import</span> SparkSession

spark <span class="token operator">=</span> SparkSession<span class="token punctuation">.</span>builder \
    <span class="token punctuation">.</span>appName<span class="token punctuation">(</span><span class="token string">"Jupyter Notebook with Spark"</span><span class="token punctuation">)</span> \
    <span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 验证Spark会话</span>
spark<span class="token punctuation">.</span>version
</code></pre> 
<h3><a id="4_Spark_DataFrame_108"></a>4. Spark DataFrame基础操作</h3> 
<h4><a id="41_DataFrame_110"></a>4.1 创建DataFrame</h4> 
<p>创建一个简单的DataFrame：</p> 
<pre><code class="prism language-python">data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">"Alice"</span><span class="token punctuation">,</span> <span class="token number">34</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"Bob"</span><span class="token punctuation">,</span> <span class="token number">45</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">"Cathy"</span><span class="token punctuation">,</span> <span class="token number">29</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
columns <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"Name"</span><span class="token punctuation">,</span> <span class="token string">"Age"</span><span class="token punctuation">]</span>

df <span class="token operator">=</span> spark<span class="token punctuation">.</span>createDataFrame<span class="token punctuation">(</span>data<span class="token punctuation">,</span> columns<span class="token punctuation">)</span>
df<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<h4><a id="42__122"></a>4.2 加载数据</h4> 
<p>从CSV文件加载数据：</p> 
<pre><code class="prism language-python">df <span class="token operator">=</span> spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>csv<span class="token punctuation">(</span><span class="token string">"path/to/your/csvfile.csv"</span><span class="token punctuation">,</span> header<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> inferSchema<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
df<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<h4><a id="43_DataFrame_131"></a>4.3 DataFrame基本操作</h4> 
<p>进行一些基本的DataFrame操作，如选择列、过滤数据、聚合等：</p> 
<pre><code class="prism language-python"><span class="token comment"># 选择列</span>
df<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">"Name"</span><span class="token punctuation">,</span> <span class="token string">"Age"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 过滤数据</span>
df<span class="token punctuation">.</span><span class="token builtin">filter</span><span class="token punctuation">(</span>df<span class="token punctuation">[</span><span class="token string">"Age"</span><span class="token punctuation">]</span> <span class="token operator">&gt;</span> <span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 聚合</span>
df<span class="token punctuation">.</span>groupBy<span class="token punctuation">(</span><span class="token string">"Age"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>count<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="5__146"></a>5. 数据处理与分析</h3> 
<h4><a id="51__148"></a>5.1 数据清洗</h4> 
<p>对数据进行清洗，如处理缺失值和重复值：</p> 
<pre><code class="prism language-python"><span class="token comment"># 处理缺失值</span>
df <span class="token operator">=</span> df<span class="token punctuation">.</span>na<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token punctuation">)</span>
df<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 删除重复值</span>
df <span class="token operator">=</span> df<span class="token punctuation">.</span>dropDuplicates<span class="token punctuation">(</span><span class="token punctuation">)</span>
df<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<h4><a id="52__162"></a>5.2 数据转换</h4> 
<p>对数据进行转换，如添加新列和修改列值：</p> 
<pre><code class="prism language-python"><span class="token comment"># 添加新列</span>
df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"Age_in_10_years"</span><span class="token punctuation">,</span> df<span class="token punctuation">[</span><span class="token string">"Age"</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token number">10</span><span class="token punctuation">)</span>
df<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 修改列值</span>
df <span class="token operator">=</span> df<span class="token punctuation">.</span>withColumn<span class="token punctuation">(</span><span class="token string">"Age"</span><span class="token punctuation">,</span> df<span class="token punctuation">[</span><span class="token string">"Age"</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">)</span>
df<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="6__176"></a>6. 高级分析与机器学习</h3> 
<h4><a id="61__178"></a>6.1 机器学习管道</h4> 
<p>构建机器学习管道并进行训练和评估：</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> pyspark<span class="token punctuation">.</span>ml <span class="token keyword">import</span> Pipeline
<span class="token keyword">from</span> pyspark<span class="token punctuation">.</span>ml<span class="token punctuation">.</span>feature <span class="token keyword">import</span> StringIndexer<span class="token punctuation">,</span> VectorAssembler
<span class="token keyword">from</span> pyspark<span class="token punctuation">.</span>ml<span class="token punctuation">.</span>classification <span class="token keyword">import</span> LogisticRegression
<span class="token keyword">from</span> pyspark<span class="token punctuation">.</span>ml<span class="token punctuation">.</span>evaluation <span class="token keyword">import</span> MulticlassClassificationEvaluator

<span class="token comment"># 数据准备</span>
indexer <span class="token operator">=</span> StringIndexer<span class="token punctuation">(</span>inputCol<span class="token operator">=</span><span class="token string">"Name"</span><span class="token punctuation">,</span> outputCol<span class="token operator">=</span><span class="token string">"NameIndex"</span><span class="token punctuation">)</span>
assembler <span class="token operator">=</span> VectorAssembler<span class="token punctuation">(</span>inputCols<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"Age"</span><span class="token punctuation">,</span> <span class="token string">"NameIndex"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> outputCol<span class="token operator">=</span><span class="token string">"features"</span><span class="token punctuation">)</span>

<span class="token comment"># 模型构建</span>
lr <span class="token operator">=</span> LogisticRegression<span class="token punctuation">(</span>featuresCol<span class="token operator">=</span><span class="token string">"features"</span><span class="token punctuation">,</span> labelCol<span class="token operator">=</span><span class="token string">"label"</span><span class="token punctuation">)</span>

<span class="token comment"># 构建管道</span>
pipeline <span class="token operator">=</span> Pipeline<span class="token punctuation">(</span>stages<span class="token operator">=</span><span class="token punctuation">[</span>indexer<span class="token punctuation">,</span> assembler<span class="token punctuation">,</span> lr<span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 划分数据集</span>
train_data<span class="token punctuation">,</span> test_data <span class="token operator">=</span> df<span class="token punctuation">.</span>randomSplit<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.8</span><span class="token punctuation">,</span> <span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> seed<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span>

<span class="token comment"># 训练模型</span>
model <span class="token operator">=</span> pipeline<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_data<span class="token punctuation">)</span>

<span class="token comment"># 评估模型</span>
predictions <span class="token operator">=</span> model<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>test_data<span class="token punctuation">)</span>
evaluator <span class="token operator">=</span> MulticlassClassificationEvaluator<span class="token punctuation">(</span>labelCol<span class="token operator">=</span><span class="token string">"label"</span><span class="token punctuation">,</span> predictionCol<span class="token operator">=</span><span class="token string">"prediction"</span><span class="token punctuation">,</span> metricName<span class="token operator">=</span><span class="token string">"accuracy"</span><span class="token punctuation">)</span>
accuracy <span class="token operator">=</span> evaluator<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>predictions<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"Test Accuracy: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>accuracy <span class="token operator">*</span> <span class="token number">100</span><span class="token punctuation">:</span><span class="token format-spec">.2f</span><span class="token punctuation">}</span></span><span class="token string">%"</span></span><span class="token punctuation">)</span>
</code></pre> 
<h4><a id="62__211"></a>6.2 高级数据分析</h4> 
<p>进行一些高级数据分析，如使用Spark SQL：</p> 
<pre><code class="prism language-python"><span class="token comment"># 创建临时视图</span>
df<span class="token punctuation">.</span>createOrReplaceTempView<span class="token punctuation">(</span><span class="token string">"people"</span><span class="token punctuation">)</span>

<span class="token comment"># 使用Spark SQL查询数据</span>
result <span class="token operator">=</span> spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">"SELECT Name, AVG(Age) as Average_Age FROM people GROUP BY Name"</span><span class="token punctuation">)</span>
result<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="7__224"></a>7. 总结与展望</h3> 
<p>通过本教程，您已经学习了如何在Jupyter Notebook中集成和使用Spark进行大数据分析。从环境设置、数据加载与预处理到数据处理与分析，再到高级分析与机器学习，您掌握了完整的工作流程。接下来，您可以尝试使用更复杂的数据集和分析方法，进一步提高大数据处理和分析的技能。希望本教程能帮助您在大数据分析领域取得更大进步！</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/5556498096b844c3a4c78c44b0667c8b/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">CUE-云原生配置语言</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/5614fca15155bdb235c435025a6b1e0d/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">《样式设计011：模组-瓷片区》</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>