<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>逐步掌握最佳Ai Agents框架-AutoGen 九 RAG应用 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/4299a51d3b11d86faf49364b9e35c1ba/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="逐步掌握最佳Ai Agents框架-AutoGen 九 RAG应用">
  <meta property="og:description" content="在最近的几篇文章里，我们使用AutoGen实现了一些Demo。这篇文章，我们将使用AutoGen来完成RAG应用开发。
RAG应用 RAG全称&#34;Retrieval-Augmented Generation&#34;,即检索增强生成，它是自然语言处理中的一项技术。这种模型结合了检索式（retrieval-based）和生成式（generative）两种组件，以生成更准确、更相关的回答。
在之前我们的基于文档的聊天机器人的例子，就是RAG的一种应用。在本系列的逐步掌握最佳Ai Agents框架-AutoGen 五 与LangChain手拉手 - 掘金 (juejin.cn)，我们将文档读取、向量化和存储工作交给了LangChain, AutoGen以agent with function calls 的方式调用LangChain封装好的函数。AutoGen在最近版本里，新增了RetriveChat，可以减少对LangChain的依赖。那么，我们一起来看下AutoGen如何独立完成RAG应用开发。
RetrievalAgent 让我们来看下，官方文档对Retrieval-Augmented Generation (RAG) Applications with AutoGen | AutoGen (microsoft.github.io)的介绍。
从上图可以看出，AutoGen提供了Retrieval-augmented User Proxy 和Retrieval-augmented Assistant两个agent。
现在就让我们开干。
实战 文档 之前的RAG项目中我们用到的是Uniswap的白皮书，这个项目里，我们换成了arxiv.org/pdf/2308.00…, 这是一份rag和向量技术在医疗教育中的相关研究文章。让我们在notebook里把它下载到当前项目中。
python 复制代码!wget -o rag.pdf https://arxiv.org/pdf/2308.00479.pdf 安装库 python 复制代码%pip install pyautogen[retrievechat] langchain &#34;chromadb&lt;0.4.15&#34; -q 这次安装pyautogen,多加了retrieveChat功能包的声明。我们依然安装了langchain, 在这里主要使用它的splitter功能，当然autogen也是提供了。最后我们安装了指定版本的chromadb 向量数据库，存储文档embedding。
配置autogen config_list css复制代码import autogen # 大家可以使用gpt-4 或其它，我这里用的是3.5, 还能用。 config_list = [ { &#39;model&#39;: &#39;gpt-3.5-turbo&#39;, &#39;api_key&#39;: &#39;&#39; }] llm_config={ &#34;">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-06-05T17:06:22+08:00">
    <meta property="article:modified_time" content="2024-06-05T17:06:22+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">逐步掌握最佳Ai Agents框架-AutoGen 九 RAG应用</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>在最近的几篇文章里，我们使用AutoGen实现了一些Demo。这篇文章，我们将使用AutoGen来完成<code>RAG</code>应用开发。</p> 
<h3><a id="RAG_4"></a>RAG应用</h3> 
<p><code>RAG</code>全称"Retrieval-Augmented Generation",即检索增强生成，它是自然语言处理中的一项技术。这种模型结合了检索式（retrieval-based）和生成式（generative）两种组件，以生成更准确、更相关的回答。</p> 
<p>在之前我们的基于文档的聊天机器人的例子，就是RAG的一种应用。在本系列的<a href="https://juejin.cn/post/7302357332913717258" rel="nofollow">逐步掌握最佳Ai Agents框架-AutoGen 五 与LangChain手拉手 - 掘金 (juejin.cn)</a>，我们将文档读取、向量化和存储工作交给了LangChain, AutoGen以agent with function calls 的方式调用LangChain封装好的函数。AutoGen在最近版本里，新增了<code>RetriveChat</code>，可以减少对LangChain的依赖。那么，我们一起来看下AutoGen如何独立完成RAG应用开发。</p> 
<h3><a id="RetrievalAgent_10"></a>RetrievalAgent</h3> 
<p>让我们来看下，官方文档对<a href="https://link.juejin.cn/?target=https%3A%2F%2Fmicrosoft.github.io%2Fautogen%2Fblog%2F2023%2F10%2F18%2FRetrieveChat" rel="nofollow">Retrieval-Augmented Generation (RAG) Applications with AutoGen | AutoGen (microsoft.github.io)</a>的介绍。</p> 
<p><img src="https://images2.imgbox.com/c4/42/kM4hadGp_o.png" alt="image.png"></p> 
<p>从上图可以看出，AutoGen提供了Retrieval-augmented User Proxy 和Retrieval-augmented Assistant两个agent。</p> 
<p>现在就让我们开干。</p> 
<h3><a id="_20"></a>实战</h3> 
<ul><li>文档</li></ul> 
<p>之前的RAG项目中我们用到的是Uniswap的白皮书，这个项目里，我们换成了<a href="https://link.juejin.cn/?target=https%3A%2F%2Farxiv.org%2Fpdf%2F2308.00479.pdf" rel="nofollow">arxiv.org/pdf/2308.00…</a>, 这是一份rag和向量技术在医疗教育中的相关研究文章。让我们在notebook里把它下载到当前项目中。</p> 
<pre><code class="prism language-python">python

复制代码!wget <span class="token operator">-</span>o rag<span class="token punctuation">.</span>pdf https<span class="token punctuation">:</span><span class="token operator">//</span>arxiv<span class="token punctuation">.</span>org<span class="token operator">/</span>pdf<span class="token operator">/</span><span class="token number">2308.00479</span><span class="token punctuation">.</span>pdf
</code></pre> 
<p><img src="https://images2.imgbox.com/79/89/OVjt9DtV_o.png" alt="image.png"></p> 
<ul><li>安装库</li></ul> 
<pre><code class="prism language-python">python

复制代码<span class="token operator">%</span>pip install pyautogen<span class="token punctuation">[</span>retrievechat<span class="token punctuation">]</span> langchain <span class="token string">"chromadb&lt;0.4.15"</span> <span class="token operator">-</span>q
</code></pre> 
<p>这次安装pyautogen,多加了retrieveChat功能包的声明。我们依然安装了langchain, 在这里主要使用它的splitter功能，当然autogen也是提供了。最后我们安装了指定版本的chromadb 向量数据库，存储文档embedding。</p> 
<ul><li>配置autogen config_list</li></ul> 
<pre><code class="prism language-css"><span class="token selector">css复制代码import autogen # 大家可以使用gpt-4 或其它，我这里用的是3.5, 还能用。 config_list = [</span> <span class="token punctuation">{<!-- --></span> <span class="token string">'model'</span><span class="token punctuation">:</span> <span class="token string">'gpt-3.5-turbo'</span><span class="token punctuation">,</span> <span class="token string">'api_key'</span><span class="token punctuation">:</span> <span class="token string">''</span> <span class="token punctuation">}</span><span class="token selector">]
llm_config=</span><span class="token punctuation">{<!-- --></span> <span class="token string">"seed"</span><span class="token punctuation">:</span> 42<span class="token punctuation">,</span> #为缓存做的配置 <span class="token string">"config_list"</span><span class="token punctuation">:</span> config_list <span class="token punctuation">}</span>
</code></pre> 
<blockquote> 
 <p>接下来是比较典型的文档机器人的构建步骤</p> 
</blockquote> 
<ul><li>配置embedding函数</li></ul> 
<p>我们会对question和文档都在embedding, AI助理回答问题的过程，其实就是将question的embedding和文档的embedding进行cosine 计算，得到相似度的过程。我们使用openai 做embedding。</p> 
<pre><code class="prism language-ini">ini复制代码# 从chromadb数据库中引入embedding_functions
from chromadb.utils import embedding_functions
# 调用OpenAIEmbeddingFunction 
openai_embedding_function = embedding_functions.OpenAIEmbeddingFunction(api_key = config_list[0]["api_key"])
</code></pre> 
<ul><li>设置文本拆分器</li></ul> 
<pre><code class="prism language-python">python复制代码<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>text_splitter <span class="token keyword">import</span> RecursiveCharacterTextSplitter

text_splitter <span class="token operator">=</span> RecursiveCharacterTextSplitter<span class="token punctuation">(</span>separators<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"\n\n"</span><span class="token punctuation">,</span> <span class="token string">"\n"</span><span class="token punctuation">,</span> <span class="token string">"\r"</span><span class="token punctuation">,</span> <span class="token string">"\t"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<ul><li>实例化arg agents</li></ul> 
<pre><code class="prism language-python">python复制代码<span class="token keyword">from</span> autogen<span class="token punctuation">.</span>agentchat<span class="token punctuation">.</span>contrib<span class="token punctuation">.</span>retrieve_assistant_agent <span class="token keyword">import</span> RetrieveAssistantAgent
<span class="token keyword">from</span> autogen<span class="token punctuation">.</span>agentchat<span class="token punctuation">.</span>contrib<span class="token punctuation">.</span>retrieve_user_proxy_agent <span class="token keyword">import</span> RetrieveUserProxyAgent

llm_config <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token string">"request_timeout"</span><span class="token punctuation">:</span> <span class="token number">600</span><span class="token punctuation">,</span>
    <span class="token string">"config_list"</span><span class="token punctuation">:</span> config_list<span class="token punctuation">,</span>
    <span class="token string">"temperature"</span><span class="token punctuation">:</span> <span class="token number">0</span>
<span class="token punctuation">}</span>

assistant <span class="token operator">=</span> RetrieveAssistantAgent<span class="token punctuation">(</span>
    name<span class="token operator">=</span><span class="token string">"assistant"</span><span class="token punctuation">,</span>
    system_message<span class="token operator">=</span><span class="token string">"You are a helpful assistant."</span><span class="token punctuation">,</span>
    llm_config<span class="token operator">=</span>llm_config<span class="token punctuation">,</span>
<span class="token punctuation">)</span>

rag_agent <span class="token operator">=</span> RetrieveUserProxyAgent<span class="token punctuation">(</span>
    human_input_mode<span class="token operator">=</span><span class="token string">"NEVER"</span><span class="token punctuation">,</span>
    retrieve_config<span class="token operator">=</span><span class="token punctuation">{<!-- --></span>
        <span class="token string">"task"</span><span class="token punctuation">:</span> <span class="token string">"qa"</span><span class="token punctuation">,</span>
        <span class="token string">"docs_path"</span><span class="token punctuation">:</span> <span class="token string">"./rag.pdf"</span><span class="token punctuation">,</span>
        <span class="token string">"collection_name"</span><span class="token punctuation">:</span> <span class="token string">"rag_collection"</span><span class="token punctuation">,</span>
        <span class="token string">"embedding_function"</span><span class="token punctuation">:</span> openai_embedding_function<span class="token punctuation">,</span>
        <span class="token string">"custom_text_split_function"</span><span class="token punctuation">:</span> text_splitter<span class="token punctuation">.</span>split_text<span class="token punctuation">,</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
</code></pre> 
<p>首先我们引入了<code>RetrieveUserProxyAgent</code>和<code>RetrieveAssistantAgent</code>两个agent。从引入的路径<code>autogen.agentchat.contrib.retrieve_assistant_agent</code>来看，rag agent也是由autogen的chat agent派生,它这里称为"contrib"。接着，我们定义了llm_config，autogen使用的大模型配置，注意，这里的<code>temperature</code>为0， 基于文档的Q/A应该严谨。<code>RetrieveAssistantAgent</code>负责执行rag工作,system_message 指定了assistant的角色。<code>RetrieveUserProxyAgent</code> 的retrieve_config，提起了RAG的重担，我们做了以下配置：</p> 
<ol><li><code>task:qa</code> 指定任务为 QA问答任务类型</li><li><code>docs_path</code> 指定文档路径</li><li><code>collection_name</code> chromadb 向量数据库的名字</li><li><code>embedding_function</code>为上面设置的openai_embedding_function</li><li><code>custom_text_split_function</code>为上面设置的langchain的文本分割器</li></ol> 
<ul><li>启动对话，执行QA</li></ul> 
<pre><code class="prism language-python">python复制代码assistant<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>
rag_agent<span class="token punctuation">.</span>initiate_chat<span class="token punctuation">(</span>assistant<span class="token punctuation">,</span> problem<span class="token operator">=</span><span class="token string">"What is the workflow in docGPT?"</span><span class="token punctuation">,</span> n_results<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
</code></pre> 
<p>Rag_agent 初始化任务，提的问题是<code>What is the workflow in docGPT?</code>, n_results 表示返回多少个结果，默认是20个， 这里只需要2个。</p> 
<p><img src="https://images2.imgbox.com/d6/c4/LFC29B5m_o.png" alt="image.png"></p> 
<ul><li>结果分析</li></ul> 
<p><img src="https://images2.imgbox.com/1a/96/rSRoVd8C_o.png" alt="image.png"></p> 
<p>在这里看到有两个文档分块被加入到上下文当中。上下文即context，等下将会交给assistant 进行回答生成。<code>RetrieveChatAgent(to assistant)</code> 表示向assistant提供了如下的内容，也就是上下文。</p> 
<p><img src="https://images2.imgbox.com/3f/42/UtAcphuM_o.png" alt="image.png"></p> 
<p>如上图，它包括了RAG QA任务的模板(<code>You're a retrieve aumented chatbot. You answer user's questions based on your own knowledge and the context provied by the user....</code>)和内容（context）。模板中也说的很清楚，如果基于context无法回复用户提出的问题，那么就向proxy 发出<code>UPDATE CONTEXT</code>的需要。上图的后半部分，就是通过embedding查询获得的文档内容。</p> 
<p><img src="https://images2.imgbox.com/10/03/EzUxLbSu_o.png" alt="image.png"></p> 
<p>最后， RetrieveAssistantAgent根据RetrieveUserProxyAgent提供的context,完成了回答的生成， 这也是大模型最擅长的summarize。</p> 
<h3><a id="_135"></a>总结</h3> 
<p>RAG是LLM的经典应用，AutoGen通过提供chat agent的 rag 升级agent,完成了相应功能。</p> 
<ul><li>RetrieveUserProxyAgent的配置需要完成文档读取、向量数据库、分词器的配置</li><li>RetrieveUserProxyAgent的prompt模板预置了QA 内容。</li><li>RetrieveAssistantAgent对RetrieveUserProxyAgent提供的context，完成回答生成。</li></ul>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/e6669bdb2a3e54c7fbadace93a1df475/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【wiki知识库】05.分类管理模块--后端SpringBoot模块</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/e6691557adc4a1ebbdf5c5d00115a7de/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">C语言——内存函数</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>