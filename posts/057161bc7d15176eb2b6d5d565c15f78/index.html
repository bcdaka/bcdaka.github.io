<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>基于LLaMA-Factory的微调记录 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/057161bc7d15176eb2b6d5d565c15f78/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="基于LLaMA-Factory的微调记录">
  <meta property="og:description" content="文章目录 数据模型准备基于网页的简单微调基于网页的简单评测基于网页的简单聊天基于网页的模型合并微调问题测试与解决问题测试模板修改强化训练持续训练单数据集训练微调总结 LLaMA-Factory是一个非常好用的无代码微调框架，不管是在模型、微调方式还是参数设置上都提供了非常完备的支持，下面是对微调全过程的一个记录。 数据模型准备 微调时一般需要准备三个数据集：一个是自我认知数据集（让大模型知道自己是谁），一个是特定任务数据集（微调时需要完成的目标任务），一个是通用任务数据集（保持大模型的通用能力，防止变傻）。前两个一般要自己定义，最后一个用现成的就行。
自定义数据集可采用alpaca和sharegpt格式，这里采用的是alpaca格式：
[ { &#34;instruction&#34;: &#34;用户指令（必填）&#34;, &#34;input&#34;: &#34;用户输入（选填）&#34;, &#34;output&#34;: &#34;模型回答（必填）&#34;, &#34;system&#34;: &#34;系统提示词（选填）&#34;, &#34;history&#34;: [ [&#34;第一轮指令（选填）&#34;, &#34;第一轮回答（选填）&#34;], [&#34;第二轮指令（选填）&#34;, &#34;第二轮回答（选填）&#34;] ] } ] 由于不需要考虑多轮对话，所以history可以不要，这里采用了两种数据集的组织方式，一种是只有instruction和output，把问题作为instruction，另外一种是把问题作为input，把回答问题这一要求作为instruction。这两种格式分别记为format2和format3。
在根据若干个不同的专业领域生成完多个自定义的问答json文件之后，分别生成其format2和format3的文件以及test测试文件，根据以下代码计算其sha1值：
import hashlib def calculate_sha1(file_path): sha1 = hashlib.sha1() try: with open(file_path, &#39;rb&#39;) as file: while True: data = file.read(8192) # Read in chunks to handle large files if not data: break sha1.update(data) return sha1.hexdigest() except FileNotFoundError: return &#34;File not found.&#34; # 使用示例 file_path = &#39;.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-02-04T16:11:43+08:00">
    <meta property="article:modified_time" content="2024-02-04T16:11:43+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">基于LLaMA-Factory的微调记录</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-dracula">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><ul><li><a href="#_3" rel="nofollow">数据模型准备</a></li><li><a href="#_51" rel="nofollow">基于网页的简单微调</a></li><li><a href="#_57" rel="nofollow">基于网页的简单评测</a></li><li><a href="#_67" rel="nofollow">基于网页的简单聊天</a></li><li><a href="#_70" rel="nofollow">基于网页的模型合并</a></li><li><a href="#_73" rel="nofollow">微调问题测试与解决</a></li><li><ul><li><a href="#_74" rel="nofollow">问题测试</a></li><li><a href="#_85" rel="nofollow">模板修改</a></li><li><a href="#_88" rel="nofollow">强化训练</a></li><li><a href="#_96" rel="nofollow">持续训练</a></li><li><a href="#_103" rel="nofollow">单数据集训练</a></li><li><a href="#_124" rel="nofollow">微调总结</a></li></ul> 
  </li></ul> 
 </li></ul> 
</div> 
<br> 
<a href="https://github.com/hiyouga/LLaMA-Factory/blob/main/README_zh.md">LLaMA-Factory</a>是一个非常好用的无代码微调框架，不管是在模型、微调方式还是参数设置上都提供了非常完备的支持，下面是对微调全过程的一个记录。 
<p></p> 
<h3><a id="_3"></a>数据模型准备</h3> 
<p>微调时一般需要准备三个数据集：一个是自我认知数据集（让大模型知道自己是谁），一个是特定任务数据集（微调时需要完成的目标任务），一个是通用任务数据集（保持大模型的通用能力，防止变傻）。前两个一般要自己定义，最后一个用现成的就行。</p> 
<p><a href="https://github.com/hiyouga/LLaMA-Factory/blob/main/data/README_zh.md">自定义数据集</a>可采用alpaca和sharegpt格式，这里采用的是alpaca格式：</p> 
<pre><code class="prism language-py"><span class="token punctuation">[</span>
  <span class="token punctuation">{<!-- --></span>
    <span class="token string">"instruction"</span><span class="token punctuation">:</span> <span class="token string">"用户指令（必填）"</span><span class="token punctuation">,</span>
    <span class="token string">"input"</span><span class="token punctuation">:</span> <span class="token string">"用户输入（选填）"</span><span class="token punctuation">,</span>
    <span class="token string">"output"</span><span class="token punctuation">:</span> <span class="token string">"模型回答（必填）"</span><span class="token punctuation">,</span>
    <span class="token string">"system"</span><span class="token punctuation">:</span> <span class="token string">"系统提示词（选填）"</span><span class="token punctuation">,</span>
    <span class="token string">"history"</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>
      <span class="token punctuation">[</span><span class="token string">"第一轮指令（选填）"</span><span class="token punctuation">,</span> <span class="token string">"第一轮回答（选填）"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token punctuation">[</span><span class="token string">"第二轮指令（选填）"</span><span class="token punctuation">,</span> <span class="token string">"第二轮回答（选填）"</span><span class="token punctuation">]</span>
    <span class="token punctuation">]</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">]</span>
</code></pre> 
<p>由于不需要考虑多轮对话，所以history可以不要，这里采用了两种数据集的组织方式，一种是只有instruction和output，把问题作为instruction，另外一种是把问题作为input，把回答问题这一要求作为instruction。这两种格式分别记为<code>format2</code>和<code>format3</code>。</p> 
<p>在根据若干个不同的专业领域生成完多个自定义的问答json文件之后，分别生成其<code>format2</code>和<code>format3</code>的文件以及<code>test</code>测试文件，根据以下代码计算其sha1值：</p> 
<pre><code class="prism language-py">
<span class="token keyword">import</span> hashlib

<span class="token keyword">def</span> <span class="token function">calculate_sha1</span><span class="token punctuation">(</span>file_path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    sha1 <span class="token operator">=</span> hashlib<span class="token punctuation">.</span>sha1<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">try</span><span class="token punctuation">:</span>
        <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>file_path<span class="token punctuation">,</span> <span class="token string">'rb'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> <span class="token builtin">file</span><span class="token punctuation">:</span>
            <span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>
                data <span class="token operator">=</span> <span class="token builtin">file</span><span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token number">8192</span><span class="token punctuation">)</span>  <span class="token comment"># Read in chunks to handle large files</span>
                <span class="token keyword">if</span> <span class="token keyword">not</span> data<span class="token punctuation">:</span>
                    <span class="token keyword">break</span>
                sha1<span class="token punctuation">.</span>update<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
        <span class="token keyword">return</span> sha1<span class="token punctuation">.</span>hexdigest<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">except</span> FileNotFoundError<span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token string">"File not found."</span>

<span class="token comment"># 使用示例</span>
file_path <span class="token operator">=</span> <span class="token string">'./data/self_cognition_modified.json'</span>  <span class="token comment"># 替换为您的文件路径</span>
sha1_hash <span class="token operator">=</span> calculate_sha1<span class="token punctuation">(</span>file_path<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"SHA-1 Hash:"</span><span class="token punctuation">,</span> sha1_hash<span class="token punctuation">)</span>
</code></pre> 
<p>将这些json文件放入<code>data</code>文件夹下，同步修改<code>dataset_info.json</code>文件，输入新增的文件名称和对应的sha1值。</p> 
<p>测试的大模型可以使用这些，注意要下载最新版，老版的模型结构不太匹配。</p> 
<p><img src="https://images2.imgbox.com/8a/df/VYNwZh5Z_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="_51"></a>基于网页的简单微调</h3> 
<p>在后台执行<code>CUDA_VISIBLE_DEVICES=0 python src/train_web.py</code>命令，成功开启网页，设置如下，手动输入模型路径。<br> <img src="https://images2.imgbox.com/c7/62/ADCB21Jd_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/76/77/T21cKGHd_o.png" alt="在这里插入图片描述"><br> 训练完成之后的界面，可以查看损失函数<br> <img src="https://images2.imgbox.com/04/d3/0JUW4miV_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="_57"></a>基于网页的简单评测</h3> 
<ul><li>原始模型评测<br> <img src="https://images2.imgbox.com/43/2e/o2QGoHJh_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/3a/ed/uuY5HtVw_o.png" alt="在这里插入图片描述"></li><li>微调后模型评测<br> 首先加载lora<br> <img src="https://images2.imgbox.com/2d/7d/S9rnnlsz_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/2d/91/ioVMmDcm_o.png" alt="在这里插入图片描述"><br> 可以看到，微调之后的模型在各个指标上有了显著提升</li></ul> 
<h3><a id="_67"></a>基于网页的简单聊天</h3> 
<p>切换到Chat并点击加载模型后，可以进入聊天<br> <img src="https://images2.imgbox.com/e6/90/wDga4a6f_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="_70"></a>基于网页的模型合并</h3> 
<p>把lora的权重合并到原始模型中<br> <img src="https://images2.imgbox.com/73/fc/knCfkSRT_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="_73"></a>微调问题测试与解决</h3> 
<h4><a id="_74"></a>问题测试</h4> 
<p>虽然在评估时看着分数挺高，但实际使用起来，问题还是挺大的：</p> 
<ul><li>自我认知无法更新<br> <img src="https://images2.imgbox.com/b8/a8/1DL4C2O6_o.png" alt="在这里插入图片描述"></li><li>专业问题答不上来<br> 这是训练集中的一条数据<br> <img src="https://images2.imgbox.com/c9/12/LoO1Iryj_o.png" alt="在这里插入图片描述"><br> 这是无lora的情况：<br> <img src="https://images2.imgbox.com/47/82/nlLaTk1M_o.png" alt="在这里插入图片描述"><br> 这是带lora的情况：<br> <img src="https://images2.imgbox.com/a3/99/Mdh2t5al_o.png" alt="在这里插入图片描述"></li></ul> 
<h4><a id="_85"></a>模板修改</h4> 
<p>ChatGLM之所以一口咬定自己是智谱开发的，主要原因是有个系统提示词，打开<code>src/llmtuner/data/template.py</code>文件，将以下部分删除<br> <img src="https://images2.imgbox.com/f7/3c/hJogSAeq_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="_88"></a>强化训练</h4> 
<p>为了让大模型学习更深入，补充通用数据集，增加学习率和epoch，再来一次微调<br> <img src="https://images2.imgbox.com/b3/d3/bhIm7U2V_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/3c/53/EyDPQLuT_o.png" alt="在这里插入图片描述"><br> 这一次自我认知倒是调出来了<br> <img src="https://images2.imgbox.com/bb/69/l5xuFHXR_o.png" alt="在这里插入图片描述"><br> 但是专业问题还是不行<br> <img src="https://images2.imgbox.com/77/3f/Sg51Nws9_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="_96"></a>持续训练</h4> 
<p>在训练出来的这个lora的基础上，为了进一步增强其专业能力，将数据集中的通用和认知数据集去掉，仅保留目前回答不好的几个专业问答数据集，并减小截断长度和增大batch大小：<br> <img src="https://images2.imgbox.com/48/a3/BUcUWC6o_o.png" alt="在这里插入图片描述"><br> 可以看到训练曲线又下降了一点<br> <img src="https://images2.imgbox.com/85/69/eGqpITAM_o.png" alt="在这里插入图片描述"><br> 但是此时专业问答能力依然不太行，并且认知也退化了，看来洗脑不能停：<br> <img src="https://images2.imgbox.com/fd/89/aILN2at2_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="_103"></a>单数据集训练</h4> 
<p>考虑到不同数据集的专业领域不同，模型可能无法一次集中学习，因此我们尝试使用单个数据集进行微调，包括了其<code>format2</code>和<code>format3</code>格式，实验结果显示format3更好一些。</p> 
<ul><li> <p>format2格式<br> 其下降曲线如下图所示<br> <img src="https://images2.imgbox.com/92/6f/2hoLKU9k_o.png" alt="在这里插入图片描述"><br> <strong>专业问答能力实现</strong><br> <img src="https://images2.imgbox.com/8d/d5/glDDBX9K_o.png" alt="在这里插入图片描述"><br> <strong>但通用问答能力被大大削弱</strong><br> <img src="https://images2.imgbox.com/b9/05/yYxMzcfQ_o.png" alt="在这里插入图片描述"></p> </li><li> <p>format3格式<br> 其下降曲线如下图所示<br> <img src="https://images2.imgbox.com/c9/40/m7KxT4KC_o.png" alt="在这里插入图片描述"><strong>专业问答能力在输入指令的情况下实现</strong></p> <p>直接提问只会瞎说<img src="https://images2.imgbox.com/c9/5e/912pAaXh_o.png" alt="在这里插入图片描述"><br> 加入数据集中的指令后正确回答<br> <img src="https://images2.imgbox.com/1a/e7/rUDZBqnV_o.png" alt="在这里插入图片描述"></p> <p><strong>通用问答能力保持</strong><br> <img src="https://images2.imgbox.com/f3/0c/aTaU4xOE_o.png" alt="在这里插入图片描述"></p> </li></ul> 
<h4><a id="_124"></a>微调总结</h4> 
<p>以下是根据手头几个问答数据集的测试结果做的总结，不一定对，具体问题还需具体分析。</p> 
<ul><li>数据集是决定微调效果的核心因素。一方面，数据集的数量要尽可能多；另一方面，其质量也很关键，问题和答案要明确，不能含糊和模棱两可，可以通过思维链和多轮对话等技巧增强模型微调后的推理性能。</li><li>微调时最好不要混合使用多个领域的数据集，不然会降低学习效果，最好是同一领域下的相关问题。也不要尝试一开始用一个数据集训练，之后用另一个训练，这样并不会有什么好下场。</li><li>微调时最好采用<code>format3</code>，将指令和输入相分离，指令可以看成是上下文学习，让模型进入相应的任务模式，然后执行特定领域的问答。这就像是一种精准的手术，给大模型做观念植入时不会动大脑的所有神经元，而只是针对一小片区域，并将其与指令触发词相关联，这样就能实现模型通用和专业问答的兼顾。</li><li>不要仅用指标衡量微调的效果，我发现胡说八道的模型和大体正确的模型指标上相差不太大，还是要实际体验一下问答效果。</li><li>微调时留意一下模型默认的系统提示词，那是常常被忽视的一项超参数。</li><li>如果微调之后的回答效果不稳定，尝试一下降低模型推理时的温度参数。</li></ul>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/5ef35c8aa53ef073d9a9128cdd1ab9f5/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Android中 Gradle与 AGP 版本对应关系表</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/c9887d116c6aeb797779d52a56b3e748/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">SpringBoot集成Flowable工作流</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>