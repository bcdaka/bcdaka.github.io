<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>安卓手机部署大模型实战 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/a341e2e68e642d9ac1d5b74f3344dc61/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="安卓手机部署大模型实战">
  <meta property="og:description" content="本文作者系360奇舞团前端开发工程师
前言 自ChatGPT发布以来，大语言模型（Large language model, LLM)就成了AI乃至整个计算机科学的话题中心。学术界，工业界围绕大语言模型本身及其应用展开了广泛的讨论，大量的新的实践层出不穷。
由于LLM对计算资源的需求极大，有能力部署大语言模型的公司和实验室一般通过搭建集群，然后开放API或者网页demo的方式让用户可以使用模型。在人们纷纷发挥想象力尝试各种prompt与模型对话的时候，我们也注意到在一些应用场景中，出于定制化、个性化或者隐私性的目的，人们想要自己在各种终端设备中本地运行大语言模型，不需要/不希望连接互联网或者依赖于服务器，例如
1、智能汽车的终端可以对驾驶员的操作习惯定制化
2、智能家居的终端可以对户主的生活习惯定制化
3、手机游戏，或者主机游戏中NPC的对话可以根据玩家的行为而改变
4、PC端的应用希望本地部署聊天机器人，但是用户的显卡可能是N卡，A卡，或者集成显卡，安装了CUDA/Vulkan/OpenCL驱动
希望能够让每个人都可以开发，优化和部署AI大模型，让它工作在每个人都能方便获得的设备上。
如何做 我们采用了机器学习编译技术来解决这一类问题。
MLC LLM 是一个用于大型语言模型的机器学习编译器和高性能部署引擎。该项目的使命是让每个人都能够在每个人的平台上原生地开发、优化和部署 AI 模型。
本页是一个快速教程，介绍如何尝试 MLC LLM，以及使用 MLC LLM 部署您自己的模型的步骤。
MLC介绍 这里稍微讲解了一些MLC的基本概念，以帮助我们使用和了解 MLC LLM。MLC-LLM 由三个不同的子模块组成：模型定义、模型编译和模型运行。
MLC LLM 的三个独立子模块
1、Python 中的模型定义。MLC 提供各种预定义架构，例如 Llama（例如 Llama2、Vicuna、OpenLlama、Wizard）、GPT-NeoX（例如 RedPajama、Dolly）、RNN（例如 RWKV）和 GPT-J（例如MOSS）。开发人员可以仅使用纯 Python 定义模型，而无需接触编码。
2、Python 中的模型编译。模型由TVM Unity编译器编译，其中编译配置为纯 Python。MLC LLM 将基于 Python 的模型量化导出到模型库并量化模型权重。可以用纯 Python 开发量化和优化算法，以针对特定用例压缩和加速 LLM。
3、不同平台的模型运行。每个平台上都提供了 MLCChat 的变体：用于命令行的C&#43;&#43; 、用于 Web 的Javascript 、用于 iOS 的Swift 和用于 Android 的Java，可通过 JSON 进行配置。开发人员只需熟悉平台即可将 MLC 编译的 LLM 集成到他们的项目中。">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-07-25T18:00:43+08:00">
    <meta property="article:modified_time" content="2024-07-25T18:00:43+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">安卓手机部署大模型实战</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div id="js_content"> 
 <h3></h3> 
 <blockquote> 
  <p>本文作者系360奇舞团前端开发工程师</p> 
 </blockquote> 
 <h3>前言</h3> 
 <p>自ChatGPT发布以来，大语言模型（Large language model, LLM)就成了AI乃至整个计算机科学的话题中心。学术界，工业界围绕大语言模型本身及其应用展开了广泛的讨论，大量的新的实践层出不穷。</p> 
 <p>由于LLM对计算资源的需求极大，有能力部署大语言模型的公司和实验室一般通过搭建集群，然后开放API或者网页demo的方式让用户可以使用模型。在人们纷纷发挥想象力尝试各种prompt与模型对话的时候，我们也注意到在一些应用场景中，出于定制化、个性化或者隐私性的目的，人们想要自己在各种终端设备中本地运行大语言模型，不需要/不希望连接互联网或者依赖于服务器，例如</p> 
 <p>1、智能汽车的终端可以对驾驶员的操作习惯定制化<br>2、智能家居的终端可以对户主的生活习惯定制化<br>3、手机游戏，或者主机游戏中NPC的对话可以根据玩家的行为而改变<br>4、PC端的应用希望本地部署聊天机器人，但是用户的显卡可能是N卡，A卡，或者集成显卡，安装了CUDA/Vulkan/OpenCL驱动<br></p> 
 <p>希望能够让每个人都可以开发，优化和部署AI大模型，让它工作在每个人都能方便获得的设备上。</p> 
 <h3>如何做</h3> 
 <p>我们采用了机器学习编译技术来解决这一类问题。</p> 
 <p>MLC LLM 是一个用于大型语言模型的机器学习编译器和高性能部署引擎。该项目的使命是让每个人都能够在每个人的平台上原生地开发、优化和部署 AI 模型。</p> 
 <p>本页是一个快速教程，介绍如何尝试 MLC LLM，以及使用 MLC LLM 部署您自己的模型的步骤。</p> 
 <h3>MLC介绍</h3> 
 <p>这里稍微讲解了一些MLC的基本概念，以帮助我们使用和了解 MLC LLM。<img src="https://images2.imgbox.com/ee/a6/sbDkNf0y_o.jpg" alt="f0c18eb72adc8e92f8667305e2f25089.jpeg">MLC-LLM 由三个不同的子模块组成：模型定义、模型编译和模型运行。</p> 
 <p>MLC LLM 的三个独立子模块</p> 
 <p>1、Python 中的模型定义。MLC 提供各种预定义架构，例如 Llama（例如 Llama2、Vicuna、OpenLlama、Wizard）、GPT-NeoX（例如 RedPajama、Dolly）、RNN（例如 RWKV）和 GPT-J（例如MOSS）。开发人员可以仅使用纯 Python 定义模型，而无需接触编码。</p> 
 <p>2、Python 中的模型编译。模型由TVM Unity编译器编译，其中编译配置为纯 Python。MLC LLM 将基于 Python 的模型量化导出到模型库并量化模型权重。可以用纯 Python 开发量化和优化算法，以针对特定用例压缩和加速 LLM。</p> 
 <p>3、不同平台的模型运行。每个平台上都提供了 MLCChat 的变体：用于命令行的C++ 、用于 Web 的Javascript 、用于 iOS 的Swift 和用于 Android 的Java，可通过 JSON 进行配置。开发人员只需熟悉平台即可将 MLC 编译的 LLM 集成到他们的项目中。</p> 
 <p>MLC LLM 还有很多概念，这里不在过多赘述，下面我们直接开始实践。</p> 
 <h3>基本环境配置</h3> 
 <p>这是我这里的硬件配置</p> 
 <p>电脑：mac m2芯片 测试手机：Pixel 4,Android 11,运行内存6g</p> 
 <blockquote> 
   
  <p>电脑根据官网所说，在windows、linux、mac都可以跑通，主要强调一下手机，运行内存需至少需大于6g,这个配置上可以跑gemma-2b，Qwen2-1.5B等较小的模型，但如果是Llama2-13B较大的，很可能会超出内存</p> 
 </blockquote> 
 <p>需要的环境依赖不少，这里我们一步一步慢慢来</p> 
 <h4>Anaconda 配置</h4> 
 <p>在MLC中需要使用的python最低版本在3.10以上，为避免环境冲突，所以最好使用虚拟环境来进行环境配置，这里推荐使用Anconda来配置虚拟环境，相关的安装方法，可参考Anaconda安装</p> 
 <p>创建虚拟环境，后续的一些操作都尽量在虚拟环境中去操作</p> 
 <pre class="has"><code class="language-go"># 创建一个 your-environment的虚拟环境，python版本为3.10
conda create -n your-environment python==3.10 
# 进入虚拟环境
activate your-environment</code></pre> 
 <h4>Rust</h4> 
 <p>来自官网的介绍：Rust (install) is needed to cross-compile HuggingFace tokenizers to Android. Make sure rustc, cargo, and rustup are available in $PATH. 如此安装：</p> 
 <pre class="has"><code class="language-go">curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh</code></pre> 
 <h4>Android Studio</h4> 
 <p>要使用Android Studio就需要安装 SDK、NDK、CMake和JAVA。</p> 
 <p>其中Android Studio可以在官网中去下载。<img src="https://images2.imgbox.com/47/4e/udIXXARB_o.jpg" alt="13f4e0be4756c0f6c43fe40d1f27cb12.jpeg">在 Android Studio 单击“File → Settings → Languages &amp; Frameworks → Android SDK → SDK Tools”，选择安装NDK、CMake和Android SDK Platform-Tools。安装完成后，需要在环境变量中去对NDK等进行配置才可使用。</p> 
 <h4>配置环境变量</h4> 
 <pre class="has"><code class="language-go">export ANDROID_NDK="$HOME/Library/Android/sdk/ndk/27.0.11902837"
export ANDROID_HOME="$HOME/Library/Android/Sdk"
export PATH="$PATH:$HOME/Library/Android/Sdk/cmake/3.22.1/bin"
export PATH="$PATH:$HOME/Library/Android/Sdk/platform-tools"
export TVM_NDK_CC="$ANDROID_NDK/toolchains/llvm/prebuilt/darwin-x86_64/bin/aarch64-linux-android24-clang"
export TVM_SOURCE_DIR="$HOME/pyProjects/intelli-vista/3rdparty/tvm"
export TVM_HOME="$TVM_HOME/include/tvm/runtime"
export MLC_LLM_SOURCE_DIR="$HOME/pyProjects/intelli-vista"
export JAVA_HOME="/Applications/Android\ Studio.app/Contents/jbr/Contents/Home"</code></pre> 
 <h4>Java</h4> 
 <p>Android Studio需要安装openjdk，官方要求的版本是&gt;17。安装教程很多，这里以linux常用的安装方式为列：</p> 
 <pre class="has"><code class="language-go"># 更新update
sudo apt update
# 安装openjdk17
sudo apt install openjdk-17-jdk 
# 查看jdk17的安装路径
sudo update-alternatives --list java
# 用上面命令获取的路径，编入到bashrc文件的最后一行中
vi ~/.bashrc
# 将下面的命令，编入到bashrc文件的最后一行中
export JAVA_HOME=/usr/lib/jvm/java-17-openjdk-amd64/bin/java
# 更新环境变量
source ~/.bashrc</code></pre> 
 <h4>TVM Unity runtime</h4> 
 <p>这个就在我们接下来要git clone的包里，在 3rdparty/tvm里面，所以不需要额外下载，只需要在上面环境配置中路径写对即可。</p> 
 <h4>TVM Unity compiler</h4> 
 <p>我们需要用这个来对模型进行编译，也可以直接使用官网提供的prebuilt model，这样就不用安装，本章直接使用官网已经提供的作为展示。</p> 
 <pre class="has"><code class="language-go">conda activate your-environment
python -m pip install --pre -U -f https://mlc.ai/wheels mlc-ai-nightly</code></pre> 
 <p>TVM的安装验证：以下命令可以帮助确认 TVM 是否已正确安装为 python 包并提供 TVM python 包的位置</p> 
 <pre class="has"><code class="language-go">&gt;&gt;&gt; python -c "import tvm; print(tvm.__file__)"
/some-path/lib/python3.10/site-packages/tvm/__init__.py</code></pre> 
 <h4>MLC-LLM安装</h4> 
 <pre class="has"><code class="language-go"># 克隆源代码及源代码附属的子项目
git clone https://github.com/mlc-ai/mlc-llm.git --recursive
# 进入mlc-llm文件夹
cd mlc-llm
# 将mlc-llm安装进环境
pip install .</code></pre> 
 <p>验证安装</p> 
 <pre class="has"><code class="language-go">&gt;&gt;&gt; mlc_llm --help
usage: MLC LLM Command Line Interface. [-h]
                                       {compile,convert_weight,gen_config,chat,serve,bench}

positional arguments:
  {compile,convert_weight,gen_config,chat,serve,bench}
                        Subcommand to to run. (choices: compile,
                        convert_weight, gen_config, chat, serve, bench)

options:
  -h, --help            show this help message and exit</code></pre> 
 <h3>构建运行时和模型库</h3> 
 <p>Android 应用程序构建的模型在 中指定MLCChat/mlc-package-config.json：在 中model_list，model指向 Hugging Face 存储库，该存储库 model指向包含预转换模型权重的 Hugging Face 存储库。Android 应用程序将从 Hugging Face URL 下载模型权重。model_id是唯一的模型标识符。estimated_vram_bytes是对模型在运行时所占用的 vRAM 的估计。"bundle_weight": true意味着模型的模型权重将在构建时捆绑到应用程序中。overrides指定一些模型配置参数覆盖。</p> 
 <p>此处我们测试两个模型gemma-2b 和 Qwen2-1.5B，所以配置mlc-package-config.json为：</p> 
 <pre class="has"><code class="language-go">{
    "device": "android",
    "model_list": [
        {
            "model": "HF://mlc-ai/gemma-2b-it-q4f16_1-MLC",
            "model_id": "gemma-2b-q4f16_1-MLC",
            "estimated_vram_bytes": 3000000000,
            "bundle_weight": true
        },
        {
            "model": "HF://mlc-ai/Qwen2-1.5B-Instruct-q4f16_1-MLC",
            "estimated_vram_bytes": 3980990464,
            "model_id": "Qwen2-1.5B-Instruct-q4f16_1-MLC",
            "bundle_weight": true
        }
    ]
}</code></pre> 
 <p>我们有一个单行命令来构建和准备所有模型库：</p> 
 <pre class="has"><code class="language-go">cd /path/to/MLCChat  # e.g., "android/MLCChat"
export MLC_LLM_SOURCE_DIR=/path/to/mlc-llm  # e.g., "../.."
mlc_llm package</code></pre> 
 <p>该命令主要执行以下两个步骤：编译模型。我们将每个模型编译model_list成MLCChat/mlc-package-config.json二进制模型库。</p> 
 <p>构建运行时和标记器。除了模型本身之外，还需要轻量级运行时和标记器来实际运行 LLM。</p> 
 <p>该命令创建一个./dist/包含运行时和模型构建输出的目录。请确保以下所有文件都存在于中./dist/。</p> 
 <pre class="has"><code class="language-go">dist
└── lib
    └── mlc4j
        ├── build.gradle
        ├── output
        │   ├── arm64-v8a
        │   │   └── libtvm4j_runtime_packed.so
        │   └── tvm4j_core.jar
        └── src
            ├── cpp
            │   └── tvm_runtime.h
            └── main
                ├── AndroidManifest.xml
                ├── assets
                │   └── mlc-app-config.json
                └── java
                    └── ...</code></pre> 
 <p>移动 GPU 中的模型执行逻辑已整合到 中libtvm4j_runtime_packed.so，而tvm4j_core.jar是与之绑定的轻量级 (~60 kb) Java 。dist/lib/mlc4j是一个 gradle 子项目，您应将其包含在应用中，以便 Android 项目可以引用 mlc4j (MLC LLM java 库)。此库打包了执行模型所需的依赖模型库和必要的运行时。</p> 
 <p>我们定义的模型下载后会在这里</p> 
 <pre class="has"><code class="language-go">dist
├── bundle
│   ├── gemma-2b-q4f16_1   # The model weights that will be bundled into the app.
│   └── mlc-app-config.json
└── ...</code></pre> 
 <blockquote> 
   
  <p>由于环境和网络限制，可以使用国内大佬们提供好的下载，也可以采用一些特别手段，这里不在赘述。</p> 
 </blockquote> 
 <h3>构建Android应用程序</h3> 
 <p>生成 APK。进入 Android Studio，点击“Build → Generate Signed Bundle/APK”生成 APK 进行发布。如果是第一次生成 APK，需要根据Android 官方指南生成密钥。此 APK 将放置在 下android/MLCChat/app/release/app-release.apk。</p> 
 <p>在手机设置的开发者模式中启用“USB 调试”。运行以下命令，如果 ADB 安装正确，你的手机将显示为设备：</p> 
 <pre class="has"><code class="language-go">adb devices</code></pre> 
 <p>将 APK 和权重安装到您的手机。运行以下命令安装应用程序，并将本地权重推送到设备上的应用程序数据目录。完成后，您可以在设备上启动 MLCChat 应用程序。bundle_weight设置为 true 的模型的权重已存在于设备上。</p> 
 <pre class="has"><code class="language-go">cd /path/to/MLCChat  # e.g., "android/MLCChat"
python bundle_weight.py --apk-path app/release/app-release.apk</code></pre> 
 <p>现在已经可以在手机上运行大模型了<img src="https://images2.imgbox.com/15/4b/Na7h8Fd2_o.jpg" alt="1d0754cc3ffb55e2a2bf721428321527.jpeg"></p> 
 <blockquote> 
   
  <p>由于手机硬件问题，目前只能跑像gemma-2b 或者 Qwen2-1.5B较小的模型，后续会在其他手机上尝试跑一下更大的模型例如Llama-13B。</p> 
 </blockquote> 
 <h3>参考文档：</h3> 
 <p>https://llm.mlc.ai/docs/deploy/android.html</p> 
 <p style="text-align:center;">- END -</p> 
 <p style="text-align:center;"><strong>如果您关注前端+AI 相关领域可以扫码进群交流</strong></p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/0d/d5/O8YJS6eE_o.png" alt="9ee2274fce8059dbf135aac8ab4bbacf.png"> <img src="https://images2.imgbox.com/3d/f1/xdgbXBkV_o.jpg" alt="0ef8d6479381fa401e2b02ad896b5c54.jpeg"></p> 
 <p style="text-align:center;">扫码进群2或添加小编微信进群1😊<br></p> 
 <h3>关于奇舞团</h3> 
 <p style="text-align:left;">奇舞团是 360 集团最大的大前端团队，非常重视人才培养，有工程师、讲师、翻译官、业务接口人、团队 Leader 等多种发展方向供员工选择，并辅以提供相应的技术力、专业力、通用力、领导力等培训课程。奇舞团以开放和求贤的心态欢迎各种优秀人才关注和加入奇舞团。<br></p> 
 <p style="text-align:left;"><img src="https://images2.imgbox.com/48/da/0AgsZjf3_o.png" alt="1324a5da1336b89c6e4c2f090e48dbb7.png"></p> 
 <br> 
</div>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/d2052e66d19fef18985d649880ea2e82/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">LLM（大语言模型）和AIGC入门学习路线图</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/5d311057d05ad505eb8d14f40f2b5130/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">最大405B：Llama-3.1 发布，第一时间详解</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>