<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>大数据-80 Spark 简要概述 系统架构 部署模式 与Hadoop MapReduce对比 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/e5a7c5630cbf41f5b0dd3f3ceac917e8/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="大数据-80 Spark 简要概述 系统架构 部署模式 与Hadoop MapReduce对比">
  <meta property="og:description" content="点一下关注吧！！！非常感谢！！持续更新！！！ 目前已经更新到了： Hadoop（已更完）HDFS（已更完）MapReduce（已更完）Hive（已更完）Flume（已更完）Sqoop（已更完）Zookeeper（已更完）HBase（已更完）Redis （已更完）Kafka（已更完）Spark（新开的坑！正在更新！） 章节内容 上节我们完成了如下的内容：
Kafka集群监控方案JConsoleKafka EagleJavaAPI获取集群指标
简单介绍 在技术的不断迭代中，一路发展，三代技术引擎：
MapReduce 昨天Spark 今天Flink 未来 MapReduce和Spark都是类MR的处理引擎，底层原理非常相似。
什么是Spark Spark的发展历程如下图：
Spark特点 速度快，与MapReduce相比，Spark基于内存运算要快100倍以上，基于硬盘运算也要快10倍以上。Spark实现了高效的DAG执行引擎，可以通过基于内存来高效的处理流数据使用简单，Spark支持Scala、Java、Python、R的API，还支持超过80种算法，使用户可以快速构建不同的应用。而且Spark支持交互式的Python和Scala的Shell，可以非常方便的在这些Shell中使用Spark集群来验证解决问题的方法通用性好，Spark提供了统一的解决方案，Spark可以用于批处理、交互式查询（SparkSQL）、实时流处理（SparkStreaming）、机器学习（SparkMLlib）和图计算（GraphX）。这些不同类型的处理都可以在同一个应用中无缝衔接。Spark统一解决方案非常具有吸引力，企业想用统一的平台去处理遇到的问题，减少开发和维护人力的成本和部署平台的物力成本。兼容性好，Spark可以非常方便的和其他开源的产品进行融合，Spark可以使用YARN、Mesos作为它的资源管理和调度器。可以处理所有Hadoop支持的数据，包括HDFS、HBase、Cassandra等。这对于已经部署Hadoop集群的用户特别重要，因为不需要任何的数据迁移就可以使用Spark。Spark也可以不依赖于其它第三方的资源管理和调度器，它实现了Standalone作为其内置的资源管理和调度框架，这样进一步降低了Spark的使用门槛，使得所有人可以非常容器的部署和使用Spark。 Spark与Hadoop 狭义上 从狭义上看：Hadoop是一个分布式框架，由存储、资源调度、计算三部分组成
Spark是一个分布式计算引擎，是由Scala编写的计算框架，基于内存的快速、通用、可扩展的大数据分析引擎。
广义上 从广义上看：Spark是Hadoop生态中不可或缺的一部分。
MapReduce不足 表达能力有限磁盘IO开销大延迟高：任务之间有IO开销，在前一个任务完成之前，另一个任务无法开始。 相对于Spark，Spark的设计要更高效，Spark在借鉴MapReduce优点的同时，很好的解决了MapReduce所面临的问题：
两者对比 Spark的计算模式也属于MapReduce，是对MR框架的优化。
数据存储结构：MapReduce是磁盘HDFS，Spark是内存构建的弹性分布式数据集RDD编程范式：Map&#43;Reduce表达力欠缺，Spark提供了丰富操作使数据处理代码很短运行速度：MapReduce计算中间结果存磁盘，Spark中间结果在内存中任务速度：MapReduce任务以进程，需要数秒启动，Spark是小数据集读取在亚秒级 实际应用 批量处理（离线处理）：通常时间跨度在分钟到小时交互式查询：通常时间跨度在十秒到数十分钟流处理（实时处理）：通常跨度在数百毫秒到数秒 在面对上述的三个场景中，我们通常的解决方案是：
MapReduceHiveImpala 或 Storm 但是对应的也带来一些新的问题：
不同场景之间输入输出数据无法做到无缝共享，通常需要进行数据格式的转换、不同的软件需要不同的开发和维护团队，带来了较高的维护和使用成本比较难以通一个集群中的各个系统进行统一的资源协调和分配 系统架构 Spark运行包括如下：
Cluster ManagerWorker NodeDriverExecutor ClusterManager ClusterManager 是集群资源的管理者，Spark支持3中集群部署模式：
StandaloneYARNMesos WorkerNode WorkerNode是工作节点，负责管理本地资源。
Driver Program 运行应用的 main() 方法并且创建了 SparkContext。由ClusterManager分配资源，SparkContext发送Task到Executor上执行。
Executor Executor在工作节点上运行，执行Driver发送的Task，并向Driver汇报计算结果。
部署模式 Standalone 独立模式，自带完整的服务，可单独部署到一个集群中，无需依赖其他任何的资源管理系统，从一定程度上说，该模式是其他模式的基础Cluster Manager： MasterWorkerNode：Worker仅支持粗粒度的资源分配方式 SparkOnYARN YARN拥有强大的社区支持，且逐步成为大数据集群资源管理系统的标准在国内生产环境中运用最广泛的部署模式SparkOnYARN 支持的两种模式：yarn-cluster（生产环境），yarn-client（交互和调试）Cluster Manager：ResourceManagerWorkNode：NodeManager仅支持粗粒度的资源分配方式 SparkOnMesos 官方推荐模式，Spark开发之初就考虑到了支持MesosSpark运行在Mesos上会更加的灵活，更加自然ClusterManager：MesosMasterWorkNode: MesosSlave支持粗粒度、细粒度的资源分配方式 粗粒度模式 Coarse-grained Mode：每个程序的运行由一个Driver和若干个Executor组成，其中每个Executor占用若干资源，内部可以运行多个Task。应用程序的各个任务正式运行之前，需要将运行环境中的资源全部申请好，且运行过程中需要一直占用着这些资源，即使不用，最后程序运行结束后，自动回收这些资源。">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-08-13T09:15:08+08:00">
    <meta property="article:modified_time" content="2024-08-13T09:15:08+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">大数据-80 Spark 简要概述 系统架构 部署模式 与Hadoop MapReduce对比</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_0"></a>点一下关注吧！！！非常感谢！！持续更新！！！</h2> 
<h2><a id="_1"></a>目前已经更新到了：</h2> 
<ul><li>Hadoop（已更完）</li><li>HDFS（已更完）</li><li>MapReduce（已更完）</li><li>Hive（已更完）</li><li>Flume（已更完）</li><li>Sqoop（已更完）</li><li>Zookeeper（已更完）</li><li>HBase（已更完）</li><li>Redis （已更完）</li><li>Kafka（已更完）</li><li>Spark（新开的坑！正在更新！）</li></ul> 
<h2><a id="_14"></a>章节内容</h2> 
<p>上节我们完成了如下的内容：</p> 
<ul><li>Kafka集群监控方案</li><li>JConsole</li><li>Kafka Eagle</li><li>JavaAPI获取集群指标<br> <img src="https://images2.imgbox.com/4b/87/7vnjTurg_o.png" alt="在这里插入图片描述"></li></ul> 
<h2><a id="_21"></a>简单介绍</h2> 
<p>在技术的不断迭代中，一路发展，三代技术引擎：</p> 
<ul><li>MapReduce 昨天</li><li>Spark 今天</li><li>Flink 未来</li></ul> 
<p>MapReduce和Spark都是类MR的处理引擎，底层原理非常相似。</p> 
<h2><a id="Spark_29"></a>什么是Spark</h2> 
<p>Spark的发展历程如下图：<br> <img src="https://images2.imgbox.com/02/83/cfBO1RWz_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="Spark_33"></a>Spark特点</h2> 
<ul><li>速度快，与MapReduce相比，Spark基于内存运算要快100倍以上，基于硬盘运算也要快10倍以上。Spark实现了高效的DAG执行引擎，可以通过基于内存来高效的处理流数据</li><li>使用简单，Spark支持Scala、Java、Python、R的API，还支持超过80种算法，使用户可以快速构建不同的应用。而且Spark支持交互式的Python和Scala的Shell，可以非常方便的在这些Shell中使用Spark集群来验证解决问题的方法</li><li>通用性好，Spark提供了统一的解决方案，Spark可以用于批处理、交互式查询（SparkSQL）、实时流处理（SparkStreaming）、机器学习（SparkMLlib）和图计算（GraphX）。这些不同类型的处理都可以在同一个应用中无缝衔接。Spark统一解决方案非常具有吸引力，企业想用统一的平台去处理遇到的问题，减少开发和维护人力的成本和部署平台的物力成本。</li><li>兼容性好，Spark可以非常方便的和其他开源的产品进行融合，Spark可以使用YARN、Mesos作为它的资源管理和调度器。可以处理所有Hadoop支持的数据，包括HDFS、HBase、Cassandra等。这对于已经部署Hadoop集群的用户特别重要，因为不需要任何的数据迁移就可以使用Spark。Spark也可以不依赖于其它第三方的资源管理和调度器，它实现了Standalone作为其内置的资源管理和调度框架，这样进一步降低了Spark的使用门槛，使得所有人可以非常容器的部署和使用Spark。</li></ul> 
<h2><a id="SparkHadoop_39"></a>Spark与Hadoop</h2> 
<h3><a id="_40"></a>狭义上</h3> 
<p>从狭义上看：Hadoop是一个分布式框架，由存储、资源调度、计算三部分组成<br> Spark是一个分布式计算引擎，是由Scala编写的计算框架，基于内存的快速、通用、可扩展的大数据分析引擎。</p> 
<h3><a id="_45"></a>广义上</h3> 
<p>从广义上看：Spark是Hadoop生态中不可或缺的一部分。</p> 
<h3><a id="MapReduce_48"></a>MapReduce不足</h3> 
<ul><li>表达能力有限</li><li>磁盘IO开销大</li><li>延迟高：任务之间有IO开销，在前一个任务完成之前，另一个任务无法开始。</li></ul> 
<p><img src="https://images2.imgbox.com/69/06/PzVAGmwE_o.png" alt="在这里插入图片描述"><br> 相对于Spark，Spark的设计要更高效，Spark在借鉴MapReduce优点的同时，很好的解决了MapReduce所面临的问题：<br> <img src="https://images2.imgbox.com/9b/4e/59PCGAXz_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="_56"></a>两者对比</h3> 
<p>Spark的计算模式也属于MapReduce，是对MR框架的优化。</p> 
<ul><li>数据存储结构：MapReduce是磁盘HDFS，Spark是内存构建的弹性分布式数据集RDD</li><li>编程范式：Map+Reduce表达力欠缺，Spark提供了丰富操作使数据处理代码很短</li><li>运行速度：MapReduce计算中间结果存磁盘，Spark中间结果在内存中</li><li>任务速度：MapReduce任务以进程，需要数秒启动，Spark是小数据集读取在亚秒级</li></ul> 
<h2><a id="_63"></a>实际应用</h2> 
<ul><li>批量处理（离线处理）：通常时间跨度在分钟到小时</li><li>交互式查询：通常时间跨度在十秒到数十分钟</li><li>流处理（实时处理）：通常跨度在数百毫秒到数秒</li></ul> 
<p>在面对上述的三个场景中，我们通常的解决方案是：</p> 
<ul><li>MapReduce</li><li>Hive</li><li>Impala 或 Storm</li></ul> 
<p>但是对应的也带来一些新的问题：</p> 
<ul><li>不同场景之间输入输出数据无法做到无缝共享，通常需要进行数据格式的转换、</li><li>不同的软件需要不同的开发和维护团队，带来了较高的维护和使用成本</li><li>比较难以通一个集群中的各个系统进行统一的资源协调和分配</li></ul> 
<h2><a id="_78"></a>系统架构</h2> 
<p>Spark运行包括如下：</p> 
<ul><li>Cluster Manager</li><li>Worker Node</li><li>Driver</li><li>Executor</li></ul> 
<p><img src="https://images2.imgbox.com/76/05/jrHU1U8Z_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="ClusterManager_86"></a>ClusterManager</h3> 
<p>ClusterManager 是集群资源的管理者，Spark支持3中集群部署模式：</p> 
<ul><li>Standalone</li><li>YARN</li><li>Mesos</li></ul> 
<h3><a id="WorkerNode_92"></a>WorkerNode</h3> 
<p>WorkerNode是工作节点，负责管理本地资源。</p> 
<h3><a id="Driver_Program_95"></a>Driver Program</h3> 
<p>运行应用的 main() 方法并且创建了 SparkContext。由ClusterManager分配资源，SparkContext发送Task到Executor上执行。</p> 
<h3><a id="Executor_98"></a>Executor</h3> 
<p>Executor在工作节点上运行，执行Driver发送的Task，并向Driver汇报计算结果。</p> 
<h2><a id="_101"></a>部署模式</h2> 
<h3><a id="Standalone_102"></a>Standalone</h3> 
<ul><li>独立模式，自带完整的服务，可单独部署到一个集群中，无需依赖其他任何的资源管理系统，从一定程度上说，该模式是其他模式的基础</li><li>Cluster Manager： Master</li><li>WorkerNode：Worker</li><li>仅支持粗粒度的资源分配方式</li></ul> 
<h3><a id="SparkOnYARN_108"></a>SparkOnYARN</h3> 
<ul><li>YARN拥有强大的社区支持，且逐步成为大数据集群资源管理系统的标准</li><li>在国内生产环境中运用最广泛的部署模式</li><li>SparkOnYARN 支持的两种模式：yarn-cluster（生产环境），yarn-client（交互和调试）</li><li>Cluster Manager：ResourceManager</li><li>WorkNode：NodeManager</li><li>仅支持粗粒度的资源分配方式</li></ul> 
<h3><a id="SparkOnMesos_116"></a>SparkOnMesos</h3> 
<ul><li>官方推荐模式，Spark开发之初就考虑到了支持Mesos</li><li>Spark运行在Mesos上会更加的灵活，更加自然</li><li>ClusterManager：MesosMaster</li><li>WorkNode: MesosSlave</li><li>支持粗粒度、细粒度的资源分配方式</li></ul> 
<h3><a id="_123"></a>粗粒度模式</h3> 
<p>Coarse-grained Mode：每个程序的运行由一个Driver和若干个Executor组成，其中每个Executor占用若干资源，内部可以运行多个Task。应用程序的各个任务正式运行之前，需要将运行环境中的资源全部申请好，且运行过程中需要一直占用着这些资源，即使不用，最后程序运行结束后，自动回收这些资源。</p> 
<h3><a id="_126"></a>细粒度模式</h3> 
<p>鉴于粗粒度模式造成的大量资源的浪费，SparkOnMesos还提供了另一个调度模式就是细粒度模式。<br> 这种模式类似于现在的云计算思想，核心是按需分配。</p> 
<h3><a id="_130"></a>如何选择</h3> 
<ul><li>生产环境中原则YARN，国内使用最广的模式</li><li>Spark的初学者，Standalone模式，简单</li><li>开发测试环境可选Standalone</li><li>数据量不太大、应用不复杂，可使用Standalone</li></ul> 
<h2><a id="_136"></a>相关术语</h2> 
<ul><li>Application 用户提交的Spark应用程序，由集群中的一个Driver和许多的Executor组成</li><li>ApplicationJAR 一个包含Spark应用程序的JAR，JAR不应该包含Spark或者Hasoop的JAR</li><li>DriverProgram运行应用程序的main()，并创建SparkContext</li><li>ClusterManager管理集群资源的服务，如Standalone、YARN、Mesos</li><li>DeployMode区分Driver进程在何处运行，在Cluster模式下，在集群内部运行Driver，在Client模式下，Driver在集群外部运行</li><li>Worker Node 运行应用程序的工作节点</li><li>Executor 运行应用程序Task和保存数据，每个应用程序都有自己的Executors，并且和Executor相互独立</li><li>Task Executors 应用程序的最小单元</li><li>Job，在用户程序中，每次调用Action函数都会产生一个新的Job，也就是说每一个Action都会生成一个Job</li><li>Stage，一个Job被分解为多个Stage，每个Stage是一系列Task的集合</li></ul>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/f1f71dfb284059cae5f676c257333f81/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">2024年第四届智慧城市与绿色能源国际会议（ICSCGE 2024）即将召开！</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/860c5881a3527385609ec06279035435/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">腾讯云 AI 代码助手攻略</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>