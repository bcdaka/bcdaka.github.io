<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>阿里云ECS上搭建Hadoop分布式环境（会更新） - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/e12c83475788bd1ea54d7d48e95009f0/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="阿里云ECS上搭建Hadoop分布式环境（会更新）">
  <meta property="og:description" content="1.Java的安装 使用命令行工具安装（需要公网ip为60.205.163.33的实例提前启动nginx服务）
# 使用wget命令从指定的IP地址下载JDK安装包到/home/jdk目录 # -P 参数用于指定下载文件的保存路径，这里是 /home/jdk # 请注意，如果IP地址发生变化，需要相应地更新命令中的IP地址部分 wget http://60.205.163.33/download/jdk/jdk-8u261-linux-x64.tar.gz -P /home/jdk 1.3 解压jdk、配置、检验 step1：在云实例中创建一个存放jdk解压后的目录，
mkdir -p /opt/jdk1.8.0 step2：将 jre-8u261-linux-x64.tar.gz 解压到 /opt/jdk1.8.0 目录下
#将文件 jdk-8u261-linux-x64.tar.gz 从 /home/jdk/ 目录解压到 /opt/jdk1.8.0 目录 tar -zxvf /home/jdk/jdk-8u261-linux-x64.tar.gz -C /opt/jdk1.8.0 step3：勾选上显示/隐藏实例菜单栏：
step4：
检验是否解压成功：左侧查看 /opt/jdk1.8.0 目录，是否和图片中的目录一致。
step5：修改环境变量
vim /etc/profile 在profile文件中添加以下内容：（第一行路径需根据自己的存放路径修改）
# 设置环境变量 JAVA_HOME 指向 JDK 的安装路径 # 这里假设 JDK 安装在 /opt/jdk1.8.0/jdk1.8.0_261 export JAVA_HOME=/opt/jdk1.8.0/jdk1.8.0_261 # 设置环境变量 JRE_HOME 指向 JAVA_HOME 下的 jre 目录 # 这通常是 JDK 的一部分，包含 Java 运行时环境 export JRE_HOME=$JAVA_HOME/jre # 设置 CLASSPATH 环境变量，它告诉 Java 程序在哪里查找类和库 # .">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-06-14T23:40:30+08:00">
    <meta property="article:modified_time" content="2024-06-14T23:40:30+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">阿里云ECS上搭建Hadoop分布式环境（会更新）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2 id="1.Java%E7%9A%84%E5%AE%89%E8%A3%85">1.Java的安装</h2> 
<p>使用命令行工具安装（需要公网ip为60.205.163.33的实例提前启动nginx服务）</p> 
<pre><code class="language-python"># 使用wget命令从指定的IP地址下载JDK安装包到/home/jdk目录
# -P 参数用于指定下载文件的保存路径，这里是 /home/jdk
# 请注意，如果IP地址发生变化，需要相应地更新命令中的IP地址部分
wget http://60.205.163.33/download/jdk/jdk-8u261-linux-x64.tar.gz -P /home/jdk
</code></pre> 
<h3 id="1.3%20%E8%A7%A3%E5%8E%8Bjdk%E3%80%81%E9%85%8D%E7%BD%AE%E3%80%81%E6%A3%80%E9%AA%8C">1.3 解压jdk、配置、检验</h3> 
<p>step1：在云实例中创建一个存放jdk解压后的目录，</p> 
<pre><code class="language-python">mkdir -p /opt/jdk1.8.0
</code></pre> 
<p>step2：将 <code>jre-8u261-linux-x64.tar.gz</code> 解压到 <code>/opt/jdk1.8.0</code> 目录下</p> 
<pre><code class="language-python">#将文件 jdk-8u261-linux-x64.tar.gz 从 /home/jdk/ 目录解压到 /opt/jdk1.8.0 目录
tar -zxvf /home/jdk/jdk-8u261-linux-x64.tar.gz -C /opt/jdk1.8.0</code></pre> 
<p>step3：勾选上显示/隐藏实例菜单栏：</p> 
<p><img alt="" height="218" src="https://images2.imgbox.com/ea/d5/GbSWFPeY_o.png" width="632"></p> 
<p>step4：</p> 
<p>检验是否解压成功：左侧查看 <code>/opt/jdk1.8.0</code> 目录，是否和图片中的目录一致。</p> 
<p><img alt="" height="316" src="https://images2.imgbox.com/be/9b/ADGkP4n8_o.png" width="550"></p> 
<p>step5：修改环境变量</p> 
<pre><code class="language-python">vim /etc/profile</code></pre> 
<p>在profile文件中添加以下内容：（第一行路径需根据自己的存放路径修改）</p> 
<pre><code class="language-python"># 设置环境变量 JAVA_HOME 指向 JDK 的安装路径
# 这里假设 JDK 安装在 /opt/jdk1.8.0/jdk1.8.0_261
export JAVA_HOME=/opt/jdk1.8.0/jdk1.8.0_261

# 设置环境变量 JRE_HOME 指向 JAVA_HOME 下的 jre 目录
# 这通常是 JDK 的一部分，包含 Java 运行时环境
export JRE_HOME=$JAVA_HOME/jre

# 设置 CLASSPATH 环境变量，它告诉 Java 程序在哪里查找类和库
# . 表示当前目录，$JAVA_HOME/lib 和 $JRE_HOME/lib 包含 Java 核心库
# 使用 : 分隔不同的路径
export CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib:$CLASSPATH

# 更新 PATH 环境变量，添加 Java 的 bin 目录到系统路径中
# 这样可以在命令行中直接运行 java 和 javac 等命令，无需指定完整路径
# $JAVA_HOME/bin 和 $JRE_HOME/bin 包含 Java 的命令行工具
# $PATH 是系统原有的路径，确保其他程序仍然可以正常访问
export PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH
</code></pre> 
<p>保存并退出。</p> 
<p>step6：继续输入以下命令，使profile文件的修改生效：</p> 
<pre><code class="language-python">source /etc/profile</code></pre> 
<p>step7：测试Java的安装是否成功？</p> 
<pre><code class="language-python">java -version</code></pre> 
<p>输出结果如下图所示，表示Java安装成功</p> 
<p><img alt="" height="93" src="https://images2.imgbox.com/fc/96/cOBsNCd2_o.png" width="525"></p> 
<h2 id="2.Hadoop%E7%9A%84%E5%AE%89%E8%A3%85">2.Hadoop的安装</h2> 
<h3 id="2.1%C2%A0%20%E4%BF%AE%E6%94%B9%E4%B8%BB%E6%9C%BA%E5%90%8D">2.1  修改主机名</h3> 
<p>（1）在安装之前先修改一下每个人的主机名，修改的名称要求如下：主机（hadoop-master-“姓名拼音首字母"）、从机1（hadoop-slave1-“姓名拼音首字母"）、从机2（hadoop-slave2-“姓名拼音首字母"），<span style="color:#fe2c24;">下面涉及到的主机名需都保持一致。</span></p> 
<p>修改方式如下：</p> 
<pre><code class="language-python">#新主机名按照要求命名
sudo echo 新主机名 &gt; /etc/hostname
#检验是否修改成功，若一下命令返回新主机名，则代表成功
cat /etc/hostname
#若永久性修改，则需要使用以下命令重新启动，重新启动的过程需要等一会
reboot
</code></pre> 
<p>再次判断，修改成功左侧提示命令行则显示新主机名</p> 
<p style="text-align:center;"><img alt="" height="166" src="https://images2.imgbox.com/1e/f6/MbPJL59u_o.png" width="454"></p> 
<p>（2）配置主机名到 IP 地址的映射：配置文件中通常使用主机名而不是 IP 地址。为了确保集群中的节点可以通过主机名相互通信，您需要：在每个节点的 <code>/etc/hosts</code> 文件中配置主机名到 IP 地址的映射。具体方式如下：</p> 
<pre><code class="language-python">vim /etc/hosts</code></pre> 
<p>在这个 <code>/etc/hosts</code> 文件中，您可以添加或修改主机名到 IP 地址（选择私网ip，更安全）的映射。<span style="color:#fe2c24;">（每个节点都需要修改）</span></p> 
<pre><code class="language-python"># 127.0.0.1 是本地主机的回环地址，用于访问本地主机上的服务。
# 172.22.196.64、172.22.196.65 和 172.22.196.66 是集群中节点的 IP 地址，分别对应 hadoop-master、hadoop-slave1 和 hadoop-slave2 主机名。
127.0.0.1 localhost
172.22.196.64 hadoop-master
172.22.196.65 hadoop-slave1
172.22.196.66 hadoop-slave2
</code></pre> 
<ol><li>在云实例中/home目录下新建一个hadoop文件夹（命令方式和图标方式均可），存放hadoop安装包。命令方式如下：mkdir -p /home/hadoop</li><li>同Java的安装方式，将hadoop安装包从本地上传至云实例/home/hadoop目录中 <pre><code class="language-python">wget http://60.205.163.33/download/hadoop/hadoop-3.2.4.tar.gz -P /home/hadoop</code></pre> </li><li> <p>返回上一层目录，再创建一个存放hadoop解压后的目录</p> <pre><code class="language-python">cd
mkdir -p /opt/hadoop3.2.4
</code></pre> </li><li> <p>解压：</p> <pre><code class="language-python">tar -zxvf /home/hadoop/hadoop-3.2.4.tar.gz -C /opt/hadoop3.2.4</code></pre> </li><li> <p>配置hadoop环境</p> <pre><code class="language-python">vim /etc/profile</code></pre> </li><li> <p>在profile文件中添加以下内容：（原理同java）</p> <pre><code class="language-python">export HADOOP_HOME=/opt/hadoop3.2.4/hadoop-3.2.4
export CLASSPATH=$($HADOOP_HOME/bin/hadoop classpath):$CLASSPATH
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</code></pre> </li><li>添加后的效果如下图所示：<img alt="" height="458" src="https://images2.imgbox.com/9c/fe/LRlp8GYz_o.png" width="661"></li><li> <p>保存退出使profile文件生效</p> <pre><code class="language-python">source /etc/profile</code></pre> </li><li> <p>查看是否安装成功，命令及输出结果如下：</p> <pre><code class="language-python">hadoop version</code></pre> <p><img alt="" height="128" src="https://images2.imgbox.com/7c/bc/plmEO8lY_o.png" width="816"></p> </li><li> <p>配置HDFS集群，执行以下命令，修改配置文件yarn-env.sh和hadoop-env.sh。（更方面）</p> <pre><code class="language-python">echo "export JAVA_HOME=/opt/jdk1.8.0/jdk1.8.0_261" &gt;&gt; /opt/hadoop3.2.4/hadoop-3.2.4/etc/hadoop/yarn-env.sh
echo "export JAVA_HOME=/opt/jdk1.8.0/jdk1.8.0_261" &gt;&gt; /opt/hadoop3.2.4/hadoop-3.2.4/etc/hadoop/hadoop-env.sh</code></pre> </li><li> <p><span style="color:#fe2c24;">将Hadoop守护进程的用户设置为<code>root，具体修改方式如下：</code></span></p> <pre><code class="language-python">​​​​​​​cd /opt/hadoop3.2.4/hadoop-3.2.4/etc/hadoop 
vim hadoop-env.sh 
# 在hadoop-env.sh文件最下面添加如下内容
export HDFS_NAMENODE_USER=root
export HDFS_DATANODE_USER=root 
export HDFS_SECONDARYNAMENODE_USER=root 
export YARN_RESOURCEMANAGER_USER=root 
export YARN_NODEMANAGER_USER=root</code></pre> </li><li> <p>修改hadoop的配置信息，主要是在/opt/hadoop3.2.4/hadoop-3.2.4/etc/hadoop文件夹中的几个，具体修改内容如下（目录部分需要根据自己的安装位置进行修改）：</p> <pre><code class="language-python">#在 /opt/hadoop3.2.4/hadoop-3.2.4目录下新建一个tmp文件夹
cd /opt/hadoop3.2.4/hadoop-3.2.4/etc/hadoop
mkdir tmp</code></pre> <pre><code class="language-python">vim workers</code></pre> <p>在workers文件中添加如下内容：<span style="color:#fe2c24;">（对照你的主机名修改）</span></p> <pre><code class="language-python">hadoop-master
hadoop-slave1
hadoop-slave2</code></pre> <p>同上，在core-site.xml文件中添加如下内容：（注意&lt;configuration&gt;不要重复添加），（<span style="color:#fe2c24;">此处hadoop-master需要修改为你们组的主节点主机名</span>）</p> <pre><code class="language-python">&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
        &lt;value&gt;file:/opt/hadoop3.2.4/hadoop-3.2.4/tmp&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;fs.defaultFS&lt;/name&gt;
        &lt;value&gt;hdfs://hadoop-master:9000&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;</code></pre> <p>同上，在hdfs-site.xml文件中添加如下内容：（注意&lt;configuration&gt;不要重复添加）（<span style="color:#fe2c24;">此处hadoop-master需要修改为你们组的主节点主机名</span>）</p> <pre><code class="language-python">&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.replication&lt;/name&gt;
        &lt;value&gt;2&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;
        &lt;value&gt;hadoop-master:50090&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
        &lt;value&gt;file:/opt/hadoop3.2.4/hadoop-3.2.4/tmp/dfs/name&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
        &lt;value&gt;file:/opt/hadoop3.2.4/hadoop-3.2.4/tmp/dfs/data&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;</code></pre> <p>同上，在mapred-site.xml文件中添加如下内容：（注意&lt;configuration&gt;不要重复添加）（<span style="color:#fe2c24;">此处hadoop-master需要修改为你们组的主节点主机名</span>）</p> <pre><code class="language-python">&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
        &lt;value&gt;yarn&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;
        &lt;value&gt;hadoop-master:10020&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;
        &lt;value&gt;hadoop-master:19888&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;</code></pre> <p>同上，在yarn-site.xml文件中添加如下内容：（注意&lt;configuration&gt;不要重复添加）（<span style="color:#fe2c24;">此处hadoop-master需要修改为你们组的主节点主机名</span>）</p> <pre><code class="language-python">&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;
        &lt;value&gt;hadoop-master&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;
        &lt;value&gt;true&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.log-dirs&lt;/name&gt;
        &lt;value&gt;${yarn.log.dir}/userlogs&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;</code></pre> </li><li>其他两台也需要进行以上Java、Hadoop所有的安装配置工作。</li><li><span style="color:#fe2c24;">【选择一人一组的同学】：</span>由于阿里云不支持在现有实例上直接更换操作系统镜像（镜像相当于对已配置好的系统进行复制，然后粘贴到新系统），需要新建实例才能镜像，所以建议大家还是采用在另一个实例中再做一遍的方法（<span style="color:#fe2c24;">并非完全一模一样，如只需ssh连接被连接就行，无需再生成<strong>SSH公钥和私钥，建议看完下面的3.Hadoop的ssh连接之后再回来做这里。</strong></span>） 
  <hr>关于另一实例中如何获取主机中的Java、Hadoop安装包，需要建立好两台实例之间的ssh连接之后，通过在主机中输入以下命令将Java、Hadoop安装包传输至另一个实例中：（<span style="color:#fe2c24;">username@remote_instance_ip需要替换</span>），验证传输成功后，即可继续完成安装配置等工作。 <pre><code class="language-python"># 通过 SSH 协议来复制本地目录 /home/jdk 到远程实例的 /home/jdk 目录，该目录下是java的安装包
scp -r /home/jdk username@remote_instance_ip:/home/jdk
# /home/hadoop目录下是hadoop的安装包
scp -r /home/hadoop username@remote_instance_ip:/home/hadoop

#命令参数解释如下：
#-r：表示递归复制，用于目录的复制。
#/home/jdk：源路径，你的本地机器上的jdk目录路径。
#username@remote_instance_ip：目标机器，其中 username 是你在远程实例上的用户名，#remote_instance_ip 是远程实例的IP地址。
#/home/jdk：目标路径，表示文件或目录将被复制到远程机器的这个路径下。</code></pre> </li></ol> 
<h2 id="3.Hadoop%E7%9A%84ssh%E8%BF%9E%E6%8E%A5%E3%80%81%E6%B5%8B%E8%AF%95%E4%B8%8E%E5%90%AF%E5%8A%A8">3.Hadoop的ssh连接、测试与启动</h2> 
<ol><li> <p><span style="color:#fe2c24;">【更新】建立同区域（例如：同杭州）不同账号下不同vpc（虚拟共有私网）私网ip的对等连接，具体方式参考：<a class="link-info" href="https://blog.csdn.net/lshy0910/article/details/137038626?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522171688442716800182176296%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&amp;request_id=171688442716800182176296&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-1-137038626-null-null.142%5Ev100%5Epc_search_result_base9&amp;utm_term=%E9%98%BF%E9%87%8C%E4%BA%91%E5%8F%91%E8%B5%B7%E7%AB%AFVPC%E5%AE%9E%E4%BE%8B&amp;spm=1018.2226.3001.4187" title="通过VPC对等连接方式，实现阿里云不同账号下的VPC内网网络互通">通过VPC对等连接方式，实现阿里云不同账号下的VPC内网网络互通</a>。</span></p> </li><li> <p><strong>在<span style="color:#fe2c24;">master</span>主机上生成SSH公钥和私钥（其他两台从节点主机不用）</strong></p> <p>在终端中执行以下命令：</p> <pre><code class="language-python">ssh-keygen -t rsa</code></pre> <p>这将在你的用户主目录下的<code>.ssh</code>文件夹（如<code>~/.ssh</code>）中创建<code>id_rsa</code>（私钥）和<code>id_rsa.pub</code>（公钥）两个文件。</p> </li><li> <p><strong>将公钥复制到远程机器</strong></p> <p>使用<code>ssh-copy-id</code>命令将公钥添加到<span style="color:#fe2c24;">主机master和远程机器slave1和slave2（该命令需执行三遍）</span>。这将添加你的公钥到远程主机的<code>~/.ssh/authorized_keys</code>文件中。</p> <pre><code class="language-python">ssh-copy-id username@remote-host</code></pre> <p><span style="color:#fe2c24;">请将<code>username</code>替换为你的远程主机上的用户名，将<code>remote-host</code>替换为远程主机的IP地址或主机名。</span></p> </li><li> <p><strong>测试SSH连接</strong></p> <p>通过执行以下命令来测试你的SSH连接：</p> <pre><code class="language-python">ssh username@remote-host</code></pre> <p>如果配置正确，你将能够在不需要密码的情况下登录到远程主机。</p> </li><li> <p>Hadoop的启动</p> <pre><code class="language-python"># 格式化Hadoop的NameNode
# 该命令会清空HDFS的元数据目录并重新初始化文件系统
# 仅在首次设置HDFS时使用，已有数据的情况下运行会导致数据丢失
hdfs namenode -format

# 启动HDFS守护进程
# 该脚本会启动NameNode和DataNode，以便HDFS开始运行
start-dfs.sh

# 启动YARN守护进程
# 该脚本会启动ResourceManager和NodeManager，以便YARN开始管理集群资源和任务调度
start-yarn.sh

# 查看当前用户下运行的所有Java进程
# 该命令用于确认各个Hadoop守护进程（如NameNode、DataNode、ResourceManager、NodeManager等）是否正在运行
jps


</code></pre> </li><li> <p>Hadoop的关闭（<span style="color:#fe2c24;">不调试的时候记得停止，下次重新启动不容易出现问题</span>）</p> <pre><code class="language-python">#关闭
stop-dfs.sh
stop-yarn.sh</code></pre> </li></ol> 
<h2 id="4.%E7%BD%91%E9%A1%B5%E5%BD%A2%E5%BC%8F%E7%9A%84%E6%9F%A5%E7%9C%8B%E6%96%B9%E5%BC%8F">4.网页形式的查看方式</h2> 
<ol><li> <p>HDFS集群的网页查看方式：</p> </li></ol> 
<p>      访问地址：  <span style="color:#fe2c24;">公网ip：9870（Hadoop安装版本不一致，访问端口也不一致）</span></p> 
<p>能成功访问到的界面如下：</p> 
<p><img alt="" height="673" src="https://images2.imgbox.com/8a/83/75qaRLi2_o.png" width="1054"></p> 
<p><img alt="" height="629" src="https://images2.imgbox.com/05/01/VmI6rkiu_o.png" width="1105"></p> 
<ol><li> <p>YARN网页查看方式：</p> </li></ol> 
<p>     访问地址：    <span style="color:#fe2c24;">公网ip：8088</span></p> 
<p><img alt="" height="482" src="https://images2.imgbox.com/07/d3/ynAwL4BD_o.png" width="844"></p> 
<h2>5.<span style="color:#fe2c24;">出现的问题及解决方式：</span></h2> 
<p>（1）安全组访问端口需提前添加，有9000，50090、10020等实验中涉及的端口，或者<span style="color:#fe2c24;">直接打开所有的端口（这种方式便于做实践，但不安全）</span>，如下图所示：</p> 
<h2><img alt="" height="60" src="https://images2.imgbox.com/81/71/DmUdlbdC_o.png" width="564">             </h2> 
<p>（2）<span style="color:#fe2c24;">访问页面没响应，需关闭防火墙。</span>命令如下：</p> 
<pre><code class="language-python">systemctl stop firewalld</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/b42fa5deb600d0478553e518a01fffbd/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">力扣每日一题 6/11 暴力搜索</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/0aef8959d95e06282f7a76bcc3cd3465/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">WebGL 绘制正五边形</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>