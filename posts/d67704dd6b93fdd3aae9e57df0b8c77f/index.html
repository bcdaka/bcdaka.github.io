<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>用AI绘画-Stable Diffusion稳定生成指定人物的2-3人场景图，制作小说配图从未如此轻松！ - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/d67704dd6b93fdd3aae9e57df0b8c77f/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="用AI绘画-Stable Diffusion稳定生成指定人物的2-3人场景图，制作小说配图从未如此轻松！">
  <meta property="og:description" content="大家好，我是设计师阿威
最近，尝试在写故事，然后用sd配图。其中，单人场景很容易生成。
但是多人场景的话，很难稳定生成满意的图像。
今天就教大家一招，用additional networks &#43; controlnet openpose，可以稳定生成2-3人的场景，也分享给大家。
下面以一个双人场景为例
1.安装插件和模型
（1）下载安装好sd插件，additional network。地址：https://github.com/kohya-ss/sd-webui-additional-networks。
（注意：如无法下载，请扫描获取插件安装包哦）
（2）下载安装好sd插件，controlnet 和 Openpose引导模型。
（注意：如无法下载，请扫描获取插件安装包哦）
2.找到你想生成的双人场景真人图，方便 openpose识别人体姿态，比如下面这张图。
3.设置openpose
点击enable启用，pixel pefect，allow preview；
预处理器选择openpose，模型选择openpose，（如果模型这里没有openpose，则记得下载openpose引导模型并放在SD的extensions\sd-webui-controlnet\models文件夹里面后，点击模型右侧的刷新按钮）
Control weight 权重这里设置0.8，让ai控制的姿势更自然一些。
点击预处理器右侧的爆炸图标，就能看到骨架预览图，如果识别出来的骨架图觉得不太满意，需要微调也可以用openpose editor工具对骨架识别并微调动作之后，再放进来controlnet使用。
4.设置additional networks
（1）把你想使用的lora模型，放入SD的extensions\sd-webui-additional-networks\models\lora里面。
（2）启用附加网络，并在下方选择你想要用的lora模型，并分别设置权重为0.8.
（3）接下来就是重点了，展开额外参数extra args
上传一张用ps或者之类的工具制作的人物色块png图片。（除了色块之外，全部背景需要是透明的。）
颜色需要是标准的rgb颜色的红绿黄。
抠图就直接用快速选择工具或者之类的抠图工具，把人物抠出来，再用油漆桶工具填充纯色，再把图片导出成png即可。
5.设置提示词等基本参数
提示词我是随便写的，因为就要一个男生一个女生出现在图像里，其他的就懒得写了，你如果对背景有要求可以加一些更丰富更细致的提示词。
采样器：dpm&#43;2m sde karras
迭代步数step适度调高到25-30
图像尺寸比例参考你原来的底图，避免被压缩裁剪或拉伸变形。然后开始生成。
提醒一下，
如果你的小黑窗出现了报错，那么大概率additional networks出现了问题，虽然画面会出现两个人一男一女没问题，位置姿势也没问题，但你的lora未生效，要指定人物就完全无法做到。
类似下面这种报错。
报错的话，需要重新安装最新的additional networks再试。
而如果类似下面这种，没有lora报错，并且显示了应用蒙版通道apply mask channel，那么代表你这种用不同的lora控制不同的人物是成功且生效的。
6.你会发现生成的男女主基本都是稳定的形象，可以用lora很好控制人物形象和特征，保持人物的统一性，同时生成多人图像也不容易崩。
比如随着剧情推进，女主找上了前男友。（女主不变换男主）
男主一怒之下，找了个小三。（男主不变换女主）
啊这，有点狗血。（没办法，狗血的剧情才有更多人喜欢看）
7.接着，我们再回来教程这里，如果说，两人场景控制人物形象和面容能比较容易实现，那么三人场景能否做到呢？答案是可以的。
比如我们祭出这张李寻欢同学的名场面图片。
同样用上面的处理方式一步一步来生成。
然后我们可以得到这样的图。
如果你喜欢大女主，不想让臭男人左拥右抱，那么可不可以呢？可以。
但是三个人的控制程度比两个人的控制更难一些，很难指定某个人物用特定某个lora，还需要多生成一些图像来抽卡，才能得到相对满意的图像。
但至少，比之前生成2-3人的图像，相对来说已经可控高了不少。
不管你用来做小说配图还是插画什么的，都方便很多。
感兴趣的小伙伴，赠送全套AIGC学习资料，包含AI绘画、AI人工智能等前沿科技教程和软件工具，具体看这里。
AIGC技术的未来发展前景广阔，随着人工智能技术的不断发展，AIGC技术也将不断提高。未来，AIGC技术将在游戏和计算领域得到更广泛的应用，使游戏和计算系统具有更高效、更智能、更灵活的特性。同时，AIGC技术也将与人工智能技术紧密结合，在更多的领域得到广泛应用，对程序员来说影响至关重要。未来，AIGC技术将继续得到提高，同时也将与人工智能技术紧密结合，在更多的领域得到广泛应用。
一、AIGC所有方向的学习路线">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-06-18T13:55:39+08:00">
    <meta property="article:modified_time" content="2024-06-18T13:55:39+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">用AI绘画-Stable Diffusion稳定生成指定人物的2-3人场景图，制作小说配图从未如此轻松！</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>大家好，我是设计师阿威</p> 
<p>最近，尝试在写故事，然后用sd配图。其中，单人场景很容易生成。</p> 
<p>但是多人场景的话，很难稳定生成满意的图像。</p> 
<p>今天就教大家一招，用<strong>additional networks + controlnet openpose</strong>，可以稳定生成2-3人的场景，也分享给大家。</p> 
<p>下面以一个双人场景为例</p> 
<p>1.安装插件和模型</p> 
<p>（1）下载安装好sd插件，additional network。地址：https://github.com/kohya-ss/sd-webui-additional-networks。<br> （注意：如无法下载，请扫描获取插件安装包哦）</p> 
<p>（2）下载安装好sd插件，controlnet 和 Openpose引导模型。<br> （注意：如无法下载，请扫描获取插件安装包哦）<br> <img src="https://images2.imgbox.com/5b/9b/krYrfsQ5_o.png"></p> 
<p>2.找到你想生成的双人场景真人图，方便 openpose识别人体姿态，比如下面这张图。</p> 
<p><img src="https://images2.imgbox.com/c2/8c/SIWdR9UH_o.png" alt=""></p> 
<p>3.设置openpose</p> 
<p>点击enable启用，pixel pefect，allow preview；</p> 
<p>预处理器选择openpose，模型选择openpose，（如果模型这里没有openpose，则记得下载openpose引导模型并放在SD的extensions\sd-webui-controlnet\models文件夹里面后，点击模型右侧的刷新按钮）</p> 
<p>Control weight 权重这里设置0.8，让ai控制的姿势更自然一些。</p> 
<p><img src="https://images2.imgbox.com/cd/b8/aNULfcxF_o.png" alt=""></p> 
<p>点击预处理器右侧的爆炸图标，就能看到骨架预览图，如果识别出来的骨架图觉得不太满意，需要微调也可以用openpose editor工具对骨架识别并微调动作之后，再放进来controlnet使用。</p> 
<p>4.设置additional networks</p> 
<p>（1）把你想使用的lora模型，放入SD的extensions\sd-webui-additional-networks\models\lora里面。</p> 
<p>（2）启用附加网络，并在下方选择你想要用的lora模型，并分别设置权重为0.8.</p> 
<p><img src="https://images2.imgbox.com/34/40/Gfe9Wmml_o.png" alt=""></p> 
<p>（3）接下来就是重点了，展开额外参数extra args</p> 
<p>上传一张用ps或者之类的工具制作的人物色块png图片。（除了色块之外，全部背景需要是透明的。）</p> 
<p>颜色需要是标准的rgb颜色的红绿黄。</p> 
<p>抠图就直接用快速选择工具或者之类的抠图工具，把人物抠出来，再用油漆桶工具填充纯色，再把图片导出成png即可。</p> 
<p><img src="https://images2.imgbox.com/81/2c/1uvYBvcP_o.png" alt=""></p> 
<p>5.设置提示词等基本参数</p> 
<p>提示词我是随便写的，因为就要一个男生一个女生出现在图像里，其他的就懒得写了，你如果对背景有要求可以加一些更丰富更细致的提示词。</p> 
<p>采样器：dpm+2m sde karras</p> 
<p>迭代步数step适度调高到25-30</p> 
<p>图像尺寸比例参考你原来的底图，避免被压缩裁剪或拉伸变形。然后开始生成。</p> 
<p><img src="https://images2.imgbox.com/b4/1c/4tppOYRV_o.png" alt=""></p> 
<p><img src="https://images2.imgbox.com/44/81/VvyhSCzx_o.png" alt=""></p> 
<p>提醒一下，</p> 
<p>如果你的小黑窗出现了报错，那么大概率<strong>additional networks</strong>出现了问题，虽然画面会出现两个人一男一女没问题，位置姿势也没问题，但你的lora未生效，要指定人物就完全无法做到。</p> 
<p>类似下面这种报错。</p> 
<p><img src="https://images2.imgbox.com/36/41/vy6JaUbn_o.png" alt=""></p> 
<p>报错的话，需要重新安装最新的additional networks再试。</p> 
<p>而如果类似下面这种，没有lora报错，并且显示了应用蒙版通道apply mask channel，那么代表你这种用不同的lora控制不同的人物是成功且生效的。</p> 
<p><img src="https://images2.imgbox.com/28/b5/ak9A9tYK_o.png" alt=""></p> 
<p>6.你会发现生成的男女主基本都是稳定的形象，可以用lora很好控制人物形象和特征，保持人物的统一性，同时生成多人图像也不容易崩。</p> 
<p>比如随着剧情推进，女主找上了前男友。（女主不变换男主）</p> 
<p><img src="https://images2.imgbox.com/eb/ad/A6unGrU7_o.png" alt=""></p> 
<p>男主一怒之下，找了个小三。（男主不变换女主）</p> 
<p><img src="https://images2.imgbox.com/18/a8/5JPT16lO_o.png" alt=""></p> 
<p>啊这，有点狗血。（没办法，狗血的剧情才有更多人喜欢看）</p> 
<p>7.接着，我们再回来教程这里，如果说，两人场景控制人物形象和面容能比较容易实现，那么三人场景能否做到呢？答案是可以的。</p> 
<p>比如我们祭出这张李寻欢同学的名场面图片。</p> 
<p><img src="https://images2.imgbox.com/ec/d8/htdwx3nH_o.png" alt=""></p> 
<p>同样用上面的处理方式一步一步来生成。</p> 
<p>然后我们可以得到这样的图。</p> 
<p><img src="https://images2.imgbox.com/d4/4d/oOo6NFJh_o.png" alt=""></p> 
<p>如果你喜欢大女主，不想让臭男人左拥右抱，那么可不可以呢？可以。</p> 
<p><img src="https://images2.imgbox.com/c8/13/bitQ932G_o.png" alt=""></p> 
<p>但是三个人的控制程度比两个人的控制更难一些，很难指定某个人物用特定某个lora，还需要多生成一些图像来抽卡，才能得到相对满意的图像。</p> 
<p>但至少，比之前生成2-3人的图像，相对来说已经可控高了不少。</p> 
<p>不管你用来做小说配图还是插画什么的，都方便很多。</p> 
<p><font face="幼圆" size="4" color="red">感兴趣的小伙伴，赠送全套AIGC学习资料，包含AI绘画、AI人工智能等前沿科技教程和软件工具，具体看这里。<br> </font><br> <img src="https://images2.imgbox.com/ff/bf/DOdotmG6_o.png"></p> 
<p>AIGC技术的未来发展前景广阔，随着人工智能技术的不断发展，AIGC技术也将不断提高。未来，AIGC技术将在游戏和计算领域得到更广泛的应用，使游戏和计算系统具有更高效、更智能、更灵活的特性。同时，AIGC技术也将与人工智能技术紧密结合，在更多的领域得到广泛应用，对程序员来说影响至关重要。未来，AIGC技术将继续得到提高，同时也将与人工智能技术紧密结合，在更多的领域得到广泛应用。<br>  <br> <img src="https://images2.imgbox.com/df/b3/7a5n1nEk_o.png" alt="在这里插入图片描述"></p> 
<p><strong>一、AIGC所有方向的学习路线</strong></p> 
<p>AIGC所有方向的技术点做的整理，形成各个领域的知识点汇总，它的用处就在于，你可以按照下面的知识点去找对应的学习资源，保证自己学得较为全面。</p> 
<p><img src="https://images2.imgbox.com/10/a6/4H02qKoi_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/b8/bc/3q6u0EJ6_o.png" alt="在这里插入图片描述"></p> 
<p><strong>二、AIGC必备工具</strong></p> 
<p>工具都帮大家整理好了，安装就可直接上手！<br> <img src="https://images2.imgbox.com/3e/92/3gsP9nmP_o.png" alt="在这里插入图片描述"></p> 
<p><strong>三、最新AIGC学习笔记</strong></p> 
<p>当我学到一定基础，有自己的理解能力的时候，会去阅读一些前辈整理的书籍或者手写的笔记资料，这些笔记详细记载了他们对一些技术点的理解，这些理解是比较独到，可以学到不一样的思路。<br> <img src="https://images2.imgbox.com/ad/da/6CiedXVm_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/1f/5c/Mk25rf93_o.png" alt="在这里插入图片描述"></p> 
<p><strong>四、AIGC视频教程合集</strong></p> 
<p>观看全面零基础学习视频，看视频学习是最快捷也是最有效果的方式，跟着视频中老师的思路，从基础到深入，还是很容易入门的。</p> 
<p><img src="https://images2.imgbox.com/16/03/oi8vbgrg_o.png" alt="在这里插入图片描述"></p> 
<p><strong>五、实战案例</strong></p> 
<p>纸上得来终觉浅，要学会跟着视频一起敲，要动手实操，才能将自己的所学运用到实际当中去，这时候可以搞点实战案例来学习。<br> <img src="https://images2.imgbox.com/d9/94/UhMhYDrY_o.png" alt="在这里插入图片描述"></p> 
<img src="https://images2.imgbox.com/d9/71/huiKttqd_o.png"> 若有侵权，请联系删除
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/41ccfdb50edb4fdec321d18235c4dca2/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">利用Python进行音频信号处理和音乐生成</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/0c2471381918e01dace60fd0de6d4cef/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">java: java.lang.NoSuchFieldError:报错解决</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>