<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>沉浸式体验Stability AI文生图、图生图、图片PS功能（中篇） - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/a94a5ad3c494923c360c64c32e0335d0/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="沉浸式体验Stability AI文生图、图生图、图片PS功能（中篇）">
  <meta property="og:description" content="今天小李哥就来介绍亚马逊云科技推出的国际前沿人工智能模型平台Amazon Bedrock上的Stability Diffusion模型开发生成式AI图像生成应用！本系列共有3篇，在上篇中我们学习了如何在亚马逊云科技控制台上体验该模型的每个特色功能，如文生图、图生图、图像修复等。
接下来在中篇中我将带大家沉浸式实操通过API调用的方式访问Stability Difussion模型，体验该模型的特色功能。大家可以通过本博客中的实操项目自己学习AI技能，并应用到日常工作中。也欢迎大家继续关注本系列第三篇，通过Stability Difussion模型API调用的方式，开发一个属于自己的图片生成网页应用。
方案所需基础知识 什么是Amazon Bedrock Amazon Bedrock 是一项完全托管的服务，通过统一的 API 提供来自 AI21 Labs、Anthropic、Cohere、Meta、Mistral AI、Stability AI 和 Amazon 等领先 AI 公司的高性能基础模型（FMs），同时提供广泛的功能，让开发者能够在确保安全、隐私和负责任 AI 的前提下构建生成式 AI 应用。使用 Amazon Bedrock，开发者们可以：
轻松地测试、评估开发者的用例在不同基础模型下的表现；
使用微调和检索增强生成（RAG）等技术定制化开发应用程序；构建可以使用开发者的企业系统和数据源自动执行任务的智能 Agents。由于 Amazon Bedrock 是 Serverless 的服务，开发者无需管理任何基础设施，并且可以使用开发者已经熟悉其它的亚马逊云科技服务安全地集成和部署生成式 AI 功能到开发者的应用中。 什么是 Stability AI 模型？ Stability AI 是一家致力于开发和提供生成式人工智能模型的公司，其模型被广泛应用于图像生成领域。Stability AI 的模型中最著名的莫非是 Stable Diffusion 生成模型，能够根据用户输入的描述，自动生成高度逼真的图像和文本。这些模型以其卓越的生成能力和灵活性，在应用开发中管饭应用和认可。
Stability AI 模型的应用场景
创意设计： Stability AI 的生成模型广泛应用于创意设计领域，帮助设计师和美工快速生成高质量的图像、插画和视觉内容，可以用于产品展示、品牌推广，社交媒体内容创作。通过简单的文本描述，就可以快速生成符合特定主题或风格的视觉素材，大大提升了设计效率和创意表现力。
游戏开发： Stability AI 的图像生成技术也被广泛应用于游戏开发中。开发者可以利用这些模型快速生成游戏场景、角色设计和道具，节省大量的美术资源，并加速游戏开发。利用AI的图像生成能力，使得小型开发团队也能够制作出富有视觉冲击力的游戏内容。
教育和培训： 在教育和培训领域，Stability AI 模型能够根据教学需求生成个性化的学习材料和培训教案，帮助教师和培训师提高教学效果，特别是生成式AI相关的主题培训，提升学习者的参与度和学习体验。
本实践包括的内容 1. 通过Amazon Bedrock API调用的方式体验文生图功能 2.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-08-31T23:11:55+08:00">
    <meta property="article:modified_time" content="2024-08-31T23:11:55+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">沉浸式体验Stability AI文生图、图生图、图片PS功能（中篇）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>今天小李哥就来介绍亚马逊云科技推出的国际前沿人工智能模型平台Amazon Bedrock上的Stability Diffusion模型开发生成式AI图像生成应用！本系列共有3篇，在上篇中我们学习了如何在亚马逊云科技控制台上体验该模型的每个特色功能，如文生图、图生图、图像修复等。</p> 
<p>接下来在中篇中我将带大家沉浸式实操通过API调用的方式访问Stability Difussion模型，体验该模型的特色功能。大家可以通过本博客中的实操项目自己学习AI技能，并应用到日常工作中。也欢迎大家继续关注本系列第三篇，通过Stability Difussion模型API调用的方式，开发一个属于自己的图片生成网页应用。<img alt="" height="1200" src="https://images2.imgbox.com/cc/4c/7TtQgWMi_o.png" width="1200"></p> 
<h2>方案所需基础知识</h2> 
<h3>什么是Amazon Bedrock</h3> 
<p>Amazon Bedrock 是一项完全托管的服务，通过统一的 API 提供来自 AI21 Labs、Anthropic、Cohere、Meta、Mistral AI、Stability AI 和 Amazon 等领先 AI 公司的高性能基础模型（FMs），同时提供广泛的功能，让开发者能够在确保安全、隐私和负责任 AI 的前提下构建生成式 AI 应用。使用 Amazon Bedrock，开发者们可以：</p> 
<p>轻松地测试、评估开发者的用例在不同基础模型下的表现；</p> 
<ol><li>使用微调和检索增强生成（RAG）等技术定制化开发应用程序；</li><li>构建可以使用开发者的企业系统和数据源自动执行任务的智能 Agents。</li><li>由于 Amazon Bedrock 是 Serverless 的服务，开发者无需管理任何基础设施，并且可以使用开发者已经熟悉其它的亚马逊云科技服务安全地集成和部署生成式 AI 功能到开发者的应用中。</li></ol> 
<p><img alt="" height="1200" src="https://images2.imgbox.com/16/9a/72yH1TSp_o.png" width="1200"></p> 
<h3>什么是 Stability AI 模型？</h3> 
<p>Stability AI 是一家致力于开发和提供生成式人工智能模型的公司，其模型被广泛应用于图像生成领域。Stability AI 的模型中最著名的莫非是 Stable Diffusion 生成模型，能够根据用户输入的描述，自动生成高度逼真的图像和文本。这些模型以其卓越的生成能力和灵活性，在应用开发中管饭应用和认可。</p> 
<p><img alt="" height="768" src="https://images2.imgbox.com/8b/fd/WXg1a1Jt_o.png" width="1200"></p> 
<p>Stability AI 模型的应用场景</p> 
<h4>创意设计：</h4> 
<p>Stability AI 的生成模型广泛应用于创意设计领域，帮助设计师和美工快速生成高质量的图像、插画和视觉内容，可以用于产品展示、品牌推广，社交媒体内容创作。通过简单的文本描述，就可以快速生成符合特定主题或风格的视觉素材，大大提升了设计效率和创意表现力。</p> 
<h4>游戏开发：</h4> 
<p>Stability AI 的图像生成技术也被广泛应用于游戏开发中。开发者可以利用这些模型快速生成游戏场景、角色设计和道具，节省大量的美术资源，并加速游戏开发。利用AI的图像生成能力，使得小型开发团队也能够制作出富有视觉冲击力的游戏内容。</p> 
<h4>教育和培训：</h4> 
<p>在教育和培训领域，Stability AI 模型能够根据教学需求生成个性化的学习材料和培训教案，帮助教师和培训师提高教学效果，特别是生成式AI相关的主题培训，提升学习者的参与度和学习体验。</p> 
<h2>本实践包括的内容</h2> 
<h4>1. 通过Amazon Bedrock API调用的方式体验文生图功能</h4> 
<h4>2. 通过Amazon Bedrock API调用的方式体验和图像修复功能</h4> 
<h4>3. 通过Amazon Bedrock API调用的方式体验图生图功能</h4> 
<p></p> 
<h2>功能实践具体步骤</h2> 
<h3>文生图功能</h3> 
<p>1. 首先我们了解Stability模型的文生图推理参数，以Stability AI SDXL 1.0为例，模型参数共分为必要参数和可选参数。</p> 
<h4>必要参数有：</h4> 
<table><thead><tr><th>参数</th><th>描述</th><th>最低值</th><th>最高值</th></tr></thead><tbody><tr><td>text_prompts</td><td>生成文本提示数组，包含提示及权重</td><td>0</td><td>2000</td></tr></tbody></table> 
<h4>可选参数有：</h4> 
<table border="1" cellpadding="1" cellspacing="1" style="width:700px;"><thead><tr><th>参数</th><th>描述</th><th>默认值</th><th>最低值</th><th>最高值</th><th>可选值</th></tr></thead><tbody><tr><td>weight</td><td>模型应用于提示的权重</td><td>1</td><td></td><td></td><td></td></tr><tr><td>cfg_scale</td><td>决定最终图像对提示的描绘程度</td><td>7</td><td>0</td><td>35</td><td></td></tr><tr><td>clip_guidance_preset</td><td>预设参数</td><td></td><td></td><td></td><td>FAST_BLUE, FAST_GREEN, NONE, SIMPLE SLOW, SLOWER, SLOWEST</td></tr><tr><td>height</td><td>生成图像的高度</td><td></td><td></td><td></td><td>1024x1024, 1152x896, 1216x832, 1344x768, 1536x640, 640x1536, 768x1344, 832x1216, 896x1152</td></tr><tr><td>width</td><td>生成图像的宽度</td><td></td><td></td><td></td><td>1024x1024, 1152x896, 1216x832, 1344x768, 1536x640, 640x1536, 768x1344, 832x1216, 896x1152</td></tr><tr><td>sampler</td><td>扩散过程采样器</td><td></td><td></td><td></td><td>DDIM, DDPM, K_DPMPP_2M, K_DPMPP_2S_ANCESTRAL, K_DPM_2, K_DPM_2_ANCESTRAL, K_EULER, K_EULER_ANCESTRAL, K_HEUN, K_LMS</td></tr><tr><td>samples</td><td>要生成的图像数量</td><td>1</td><td>1</td><td>1</td><td></td></tr><tr><td>seed</td><td>决定初始噪声设置的种子</td><td>0</td><td>0</td><td>4294967295</td><td></td></tr><tr><td>steps</td><td>生成步骤数，影响采样次数和结果准确度</td><td>30</td><td>10</td><td>50</td><td></td></tr><tr><td>style_preset</td><td>将图像模型向特定样式引导的样式预设</td><td></td><td></td><td></td><td>3d-model, analog-film, anime, cinematic, comic-book, digital-art, enhance, fantasy-art, isometric, line-art, low-poly, modeling-compound, neon-punk, origami, photographic, pixel-art, tile-texture</td></tr></tbody></table> 
<h4>实操代码：</h4> 
<p>首先我们利用Amazon Bedrock API生成推理图片，确认已安装”boto3“、”PIL“和”botocore“等必要依赖，以下为实例代码(具体的代码解释在代码备注中)：</p> 
<pre><code class="language-python">import base64
import io
import json
import os
import sys

import boto3
from PIL import Image
import botocore

boto3_bedrock = boto3.client('bedrock-runtime')

prompt = "a beautiful mountain landscape" #提示词
negative_prompts = [
    "poorly rendered",
    "poor background details",
    "poorly drawn mountains",
    "disfigured mountain features",
]#负向提示词列表，用于指定不希望在生成的图片中出现的特征
style_preset = "photographic"  #风格预设，用于指定生成图片的风格。在这里，选择了“photographic”风格，意味着生成的图片将具有类似摄影照片的效果。 (e.g. photographic, digital-art, cinematic, ...)
clip_guidance_preset = "FAST_GREEN" #这是 Clip 引导预设，用于控制图像生成过程中的一些参数和行为。"FAST_GREEN" 是一种预设选项，可能会影响生成速度和结果的某些方面。 (e.g. FAST_BLUE FAST_GREEN NONE SIMPLE SLOW SLOWER SLOWEST)
sampler = "K_DPMPP_2S_ANCESTRAL" # 这是采样器的选择，用于确定在生成图片时使用的采样方法。"K_DPMPP_2S_ANCESTRAL" 是一种具体的采样器，不同的采样器可能会对生成的图片质量和多样性产生影响。(e.g. DDIM, DDPM, K_DPMPP_SDE, K_DPMPP_2M, K_DPMPP_2S_ANCESTRAL, K_DPM_2, K_DPM_2_ANCESTRAL, K_EULER, K_EULER_ANCESTRAL, K_HEUN, K_LMS)
width = 768 #这是设置生成图片的宽度，单位为像素。这里指定宽度为 768 像素

request = json.dumps({
    "text_prompts": (
        [{"text": prompt, "weight": 1.0}]
        + [{"text": negprompt, "weight": -1.0} for negprompt in negative_prompts]
    ),
    "cfg_scale": 5,
    "seed": 42,
    "steps": 60,
    "style_preset": style_preset,
    "clip_guidance_preset": clip_guidance_preset,
    "sampler": sampler,
    "width": width,
})
modelId = "stability.stable-diffusion-xl-v1"

response = boto3_bedrock.invoke_model(body=request, modelId=modelId)
response_body = json.loads(response.get("body").read())

print(response_body["result"])
base_64_img_str = response_body["artifacts"][0].get("base64")
print(f"{base_64_img_str[0:80]}...")

os.makedirs("data", exist_ok=True)
image_1 = Image.open(io.BytesIO(base64.decodebytes(bytes(base_64_img_str, "utf-8"))))
image_1.save("data/image_1.jpg")
</code></pre> 
<h4>推理结果</h4> 
<p>我们输入的提示词为”a beautiful mountain landscape“，生成一个漂亮的山景图，我们得到生成的图片：</p> 
<p><img alt="" height="1200" src="https://images2.imgbox.com/4d/60/ohLQ7ibz_o.png" width="1200"></p> 
<h3>图生图功能：</h3> 
<p>我们接下来了解Stability模型的图生图推理参数，以Stability AI SDXL 1.0为例，模型参数共分为必要参数和可选参数。</p> 
<h4>必要参数</h4> 
<table><thead><tr><th>参数</th><th>描述</th><th>最低值</th><th>最高值</th></tr></thead><tbody><tr><td>text_prompts</td><td>生成文本提示数组，包含提示及权重</td><td>0</td><td>2000</td></tr></tbody></table> 
<h4>可选参数</h4> 
<table><thead><tr><th>参数</th><th>描述</th><th>默认值</th><th>最低值</th><th>最高值</th><th>可选值</th></tr></thead><tbody><tr><td>weight</td><td>模型应用于提示的权重</td><td>1</td><td></td><td></td><td></td></tr><tr><td>cfg_scale</td><td>决定最终图像对提示的描绘程度</td><td>7</td><td>0</td><td>35</td><td></td></tr><tr><td>clip_guidance_preset</td><td>预设参数</td><td></td><td></td><td></td><td>FAST_BLUE, FAST_GREEN, NONE, SIMPLE SLOW, SLOWER, SLOWEST</td></tr><tr><td>height</td><td>生成图像的高度</td><td></td><td></td><td></td><td>1024x1024, 1152x896, 1216x832, 1344x768, 1536x640, 640x1536, 768x1344, 832x1216, 896x1152</td></tr><tr><td>width</td><td>生成图像的宽度</td><td></td><td></td><td></td><td>1024x1024, 1152x896, 1216x832, 1344x768, 1536x640, 640x1536, 768x1344, 832x1216, 896x1152</td></tr><tr><td>sampler</td><td>扩散过程采样器</td><td></td><td></td><td></td><td>DDIM, DDPM, K_DPMPP_2M, K_DPMPP_2S_ANCESTRAL, K_DPM_2, K_DPM_2_ANCESTRAL, K_EULER, K_EULER_ANCESTRAL, K_HEUN, K_LMS</td></tr><tr><td>samples</td><td>要生成的图像数量</td><td>1</td><td>1</td><td>1</td><td></td></tr><tr><td>seed</td><td>决定初始噪声设置的种子</td><td>0</td><td>0</td><td>4294967295</td><td></td></tr><tr><td>steps</td><td>生成步骤数，影响采样次数和结果准确度</td><td>30</td><td>10</td><td>50</td><td></td></tr><tr><td>style_preset</td><td>将图像模型向特定样式引导的样式预设</td><td></td><td></td><td></td><td>3d-model, analog-film, anime, cinematic, comic-book, digital-art, enhance, fantasy-art, isometric, line-art, low-poly, modeling-compound, neon-punk, origami, photographic, pixel-art, tile-texture</td></tr><tr><td>extras</td><td>传递给引擎的额外参数</td><td></td><td></td><td></td><td></td></tr></tbody></table> 
<h4>实操代码</h4> 
<p>我们利用Amazon Bedrock API基于现有图片生成图片推理，确认已安装”boto3“、”PIL“和”botocore“等必要依赖，以下为实例代码(具体的代码解释在代码备注中)：</p> 
<pre><code class="language-python">import base64
import io
import json
import os
import sys

import boto3
from PIL import Image
import botocore


def image_to_base64(img) -&gt; str:
    """Convert a PIL Image or local image file path to a base64 string for Amazon Bedrock"""
    if isinstance(img, str):
        if os.path.isfile(img):
            print(f"Reading image from file: {img}")
            with open(img, "rb") as f:
                return base64.b64encode(f.read()).decode("utf-8")
        else:
            raise FileNotFoundError(f"File {img} does not exist")
    elif isinstance(img, Image.Image):
        print("Converting PIL Image to base64 string")
        buffer = io.BytesIO()
        img.save(buffer, format="jpeg")
        return base64.b64encode(buffer.getvalue()).decode("utf-8")
    else:
        raise ValueError(f"Expected str (filename) or PIL Image. Got {type(img)}")

boto3_bedrock = boto3.client('bedrock-runtime')

img_path = '../image/data/image_1.jpg'
# 打开图片
img = Image.open(img_path)

init_image_b64 = image_to_base64(img)
print(init_image_b64[:80] + "...")

change_prompt = "add denser number of trees, extend lake"
negative_prompts = [
    "poorly rendered",
    "poor background details",
    "poorly drawn mountains",
    "disfigured mountain features",
]#负向提示词列表，用于指定不希望在生成的图片中出现的特征
style_preset = "cinematic"  #风格预设，用于指定生成图片的风格。在这里，选择了“photographic”风格，意味着生成的图片将具有类似摄影照片的效果。 (e.g. photographic, digital-art, cinematic, ...)
clip_guidance_preset = "FAST_BLUE" #这是 Clip 引导预设，用于控制图像生成过程中的一些参数和行为。"FAST_GREEN" 是一种预设选项，可能会影响生成速度和结果的某些方面。 (e.g. FAST_BLUE FAST_GREEN NONE SIMPLE SLOW SLOWER SLOWEST)
sampler = "K_DPMPP_2S_ANCESTRAL" # 这是采样器的选择，用于确定在生成图片时使用的采样方法。"K_DPMPP_2S_ANCESTRAL" 是一种具体的采样器，不同的采样器可能会对生成的图片质量和多样性产生影响。(e.g. DDIM, DDPM, K_DPMPP_SDE, K_DPMPP_2M, K_DPMPP_2S_ANCESTRAL, K_DPM_2, K_DPM_2_ANCESTRAL, K_EULER, K_EULER_ANCESTRAL, K_HEUN, K_LMS)
width = 768 #这是设置生成图片的宽度，单位为像素。这里指定宽度为 768 像素

request = json.dumps({
    "text_prompts": (
        [{"text": change_prompt, "weight": 1.0}]
        + [{"text": negprompt, "weight": -1.0} for negprompt in negative_prompts]
    ),
    "cfg_scale": 10,
    "init_image": init_image_b64,
    "seed": 321,
    "start_schedule": 0.6,
    "steps": 50,
    "style_preset": style_preset,
    "clip_guidance_preset": clip_guidance_preset,
    "sampler": sampler,
})
modelId = "stability.stable-diffusion-xl-v1"

response = boto3_bedrock.invoke_model(body=request, modelId=modelId)
response_body = json.loads(response.get("body").read())

print(response_body["result"])
image_2_b64_str = response_body["artifacts"][0].get("base64")
print(f"{image_2_b64_str[0:80]}...")

os.makedirs("data", exist_ok=True)
image_2 = Image.open(io.BytesIO(base64.decodebytes(bytes(image_2_b64_str, "utf-8"))))
image_2.save("data/image_2.jpg")
</code></pre> 
<h4> 推理结果</h4> 
<p>我们输入的提示词为”add denser number of trees, extend lake”，为现有图片添加一片茂密的树林和一个湖泊，我们得到生成的图片：</p> 
<p><img alt="" height="1200" src="https://images2.imgbox.com/a3/33/oRVfApv9_o.png" width="1200"></p> 
<h3>图片编辑功能</h3> 
<p>我们接下来了解Stability模型的图片编辑推理参数，主要是利用新生成的图片替换原图片中的蒙版部分，以Stability AI SDXL 1.0为例，模型参数共分为必要参数和可选参数。</p> 
<h4>必要参数</h4> 
<table><thead><tr><th>参数</th><th>描述</th><th>最低值</th><th>最高值</th></tr></thead><tbody><tr><td>text_prompt</td><td>用于生成的文本提示数组</td><td>0</td><td>2000</td></tr><tr><td>init_image</td><td>初始化扩散过程的base64编码图像</td><td></td><td></td></tr><tr><td>mask_source</td><td>确定蒙版来源</td><td></td><td></td></tr><tr><td>mask_image</td><td>用作init_image中源图像蒙版的base64编码</td><td></td><td></td></tr></tbody></table> 
<h4>可选参数</h4> 
<table><thead><tr><th>参数</th><th>默认值</th><th>最低值</th><th>最高值</th><th>描述和可选值</th></tr></thead><tbody><tr><td>weight</td><td>1</td><td></td><td></td><td>模型应用于提示的权重。</td></tr><tr><td>cfg_scale</td><td>7</td><td>0</td><td>35</td><td>确定最终图像对提示的描绘程度。</td></tr><tr><td>clip_guidance_preset</td><td></td><td></td><td></td><td>模型生成图像流程的预设参数。可选值：FAST_BLUE, FAST_GREEN, NONE, SIMPLE, SLOW, SLOWER, SLOWEST。</td></tr><tr><td>sampler</td><td></td><td></td><td></td><td>扩散过程的采样器。可选值：DDIM, DDPM, K_DPMPP_2M, K_DPMPP_2S_ANCESTRAL, K_DPM_2, K_DPM_2_ANCESTRAL, K_EULER, K_EULER_ANCESTRAL, K_HEUN, K_LMS。</td></tr><tr><td>samples</td><td>1</td><td>1</td><td>1</td><td>生成图像的数量。</td></tr><tr><td>seed</td><td>0</td><td>0</td><td>4294967295</td><td>初始化噪声设置的种子。</td></tr><tr><td>steps</td><td>30</td><td>10</td><td>50</td><td>对图像进行采样的生成步骤数。</td></tr><tr><td>style_preset</td><td></td><td></td><td></td><td>图像模型特定样式的预设。可选值：3d-model, analog-film, anime, cinematic, comic-book, digital-art, enhance, fantasy-art, isometric, line-art, low-poly, modeling-compound, neon-punk, origami, photographic, pixel-art, tile-texture。</td></tr><tr><td>extras</td><td></td><td></td><td></td><td>引擎的额外参数。注意：'extras'参数用于开发中或实验性功能，可能会有变更，应谨慎使用。</td></tr></tbody></table> 
<p></p> 
<h4>实操代码</h4> 
<p>我们利用Amazon Bedrock API进行图像编辑功能，确认已安装”boto3“、”PIL“和”botocore“等必要依赖，以下为实例代码(具体的代码解释在代码备注中)：</p> 
<pre><code class="language-python">import base64
import io
import json
import os
import sys

import boto3
from PIL import Image
import botocore

from PIL import ImageOps

def image_to_base64(img) -&gt; str:
    """Convert a PIL Image or local image file path to a base64 string for Amazon Bedrock"""
    if isinstance(img, str):
        if os.path.isfile(img):
            print(f"Reading image from file: {img}")
            with open(img, "rb") as f:
                return base64.b64encode(f.read()).decode("utf-8")
        else:
            raise FileNotFoundError(f"File {img} does not exist")
    elif isinstance(img, Image.Image):
        print("Converting PIL Image to base64 string")
        buffer = io.BytesIO()
        img.save(buffer, format="jpeg")
        return base64.b64encode(buffer.getvalue()).decode("utf-8")
    else:
        raise ValueError(f"Expected str (filename) or PIL Image. Got {type(img)}")

def inpaint_mask(img, box):
    """Generates a segmentation mask for inpainting"""
    img_size = img.size
    assert len(box) == 4  # (left, top, right, bottom)
    assert box[0] &lt; box[2]
    assert box[1] &lt; box[3]
    return ImageOps.expand(
        Image.new(
            mode = "RGB",
            size = (
                box[2] - box[0],
                box[3] - box[1]
            ),
            color = 'black'
        ),
        border=(
            box[0],
            box[1],
            img_size[0] - box[2],
            img_size[1] - box[3]
        ),
        fill='white'
    )
    
img_path = '../image_to_image/data/image_2.jpg'
# 打开图片
image_2 = Image.open(img_path)

img2_size = image_2.size
box = (
        (0),
        (img2_size[1] - 900) ,
        (img2_size[0]),
        img2_size[1] - 700
    )

# Mask
mask = inpaint_mask(
    image_2,
    box
)

# Debug
mask

boto3_bedrock = boto3.client('bedrock-runtime')

inpaint_prompt = "add a helicopter"#添加一架直升机
style_preset = "cinematic"  #风格预设，用于指定生成图片的风格。在这里，选择了“photographic”风格，意味着生成的图片将具有类似摄影照片的效果。 (e.g. photographic, digital-art, cinematic, ...)
clip_guidance_preset = "FAST_BLUE" #这是 Clip 引导预设，用于控制图像生成过程中的一些参数和行为。"FAST_GREEN" 是一种预设选项，可能会影响生成速度和结果的某些方面。 (e.g. FAST_BLUE FAST_GREEN NONE SIMPLE SLOW SLOWER SLOWEST)
sampler = "K_DPMPP_2S_ANCESTRAL" # 这是采样器的选择，用于确定在生成图片时使用的采样方法。"K_DPMPP_2S_ANCESTRAL" 是一种具体的采样器，不同的采样器可能会对生成的图片质量和多样性产生影响。(e.g. DDIM, DDPM, K_DPMPP_SDE, K_DPMPP_2M, K_DPMPP_2S_ANCESTRAL, K_DPM_2, K_DPM_2_ANCESTRAL, K_EULER, K_EULER_ANCESTRAL, K_HEUN, K_LMS)
width = 768 #这是设置生成图片的宽度，单位为像素。这里指定宽度为 768 像素
request = json.dumps({
    "text_prompts":[{"text": inpaint_prompt}],
    "init_image": image_to_base64(image_2),
    "mask_source": "MASK_IMAGE_BLACK",
    "mask_image": image_to_base64(mask),
    "cfg_scale": 10,
    "seed": 32123,
    "style_preset": style_preset,
})

modelId = "stability.stable-diffusion-xl-v1"

response = boto3_bedrock.invoke_model(body=request, modelId=modelId)
response_body = json.loads(response.get("body").read())

print(response_body["result"])
image_3_b64_str = response_body["artifacts"][0].get("base64")

os.makedirs("data", exist_ok=True)
inpaint = Image.open(io.BytesIO(base64.decodebytes(bytes(image_3_b64_str, "utf-8"))))
inpaint.save("data/inpaint.jpg")
</code></pre> 
<h4>推理结果</h4> 
<p>我们输入的提示词为"add a helicopter"，为现有图片在指定蒙版涂黑区域（图像底部向上900像素和700像素之间的正中间部分）添加一个直升机图像，我们得到生成的图片：</p> 
<p><img alt="" height="1200" src="https://images2.imgbox.com/9c/86/dQ7mMOZ3_o.png" width="1200"> </p> 
<p>以上就是在亚马逊云科技控制台中沉浸式体验Amazon Bedrock的Stability AI模型、并利用该图像生成模型API开发生成式AI应用，应用到开发者日常开发工作中的下篇内容。欢迎大家关注小李哥的亚马逊云科技AI服务深入调研系列，未来获取更多国际前沿的AWS云开发/云架构方案。 </p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/0090a66ada6f6a8e2936055540b879e5/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Nginx: 使用KeepAlived配置实现虚IP在多服务器节点漂移及Nginx高可用原理</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/2f358d70ecd199022415747a347f8564/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">数据仓库系列17：元数据管理在数据仓库中的作用是什么?</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>