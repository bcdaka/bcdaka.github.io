<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Spark Core内核调度机制详解(第5天） - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/93aeafa18a31bdc6425d8f7265b6eecd/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="Spark Core内核调度机制详解(第5天）">
  <meta property="og:description" content="系列文章目录 如何构建DAG执行流程图 (掌握)如何划分Stage阶段 (掌握)Driver底层是如何运转 (掌握)确定需要构建多少分区(线程) (掌握) 文章目录 系列文章目录引言一、Spark内核调度（掌握）1.1、内容概述1.2、RDD的依赖1.3、DAG和Stage1.4、Spark Shuffle1.5、Job调度流程1.6、Spark RDD并行度 二. 常见面试题1.简单介绍下RDD宽依赖和窄依赖的区别2.简单介绍下DAG有向无环图如何划分Stage阶段的3.请描述下rdd中job的整个调度流程 引言 本文主要介绍了
1.RDD的依赖
2.DAG和Stage
3.Spark Shuffle
4.job调度流程(掌握)
5.Spark RDD并行度
帮助读者更好地理解其工作原理和优化方法。
一、Spark内核调度（掌握） 1.1、内容概述 Spark内核调度的任务：
如何构建DAG执行流程图如何划分Stage阶段Driver底层是如何运转确定需要构建多少分区（线程） Spark内核调度的目的：尽可能用最少的资源高效地完成任务计算。
1.2、RDD的依赖 RDD依赖：一个RDD的形成可能是由一个或者多个RDD得到的，此时这个RDD和之前的RDD之间产生依赖关系。
在Spark中，RDD之间的依赖关系，主要有二种类型：
窄依赖 作用: 能够让Spark程序并行计算。也就是一个分区数据计算出现问题以后，其他的分区计算不受到任何影响。特点: 父RDD的分区和子RDD的分区关系是一对一的关系。也就是父RDD分区的数据会整个被下游子RDD的分区接收。 宽依赖 作用: 划分Stage的重要依据。宽依赖也叫做Shuffle依赖。特点: 父RDD的分区和子RDD的分区关系是一对多的关系，也就是父RDD的分区数据会被分成多份给到下游子RDD的多个分区所接收。注意:为了避免数据不完整，如果有宽依赖，shuffle下游的其他操作，必须等待shuffle执行完成以后才能够继续执行。 说明 在实际使用中，不需要纠结哪些算子会存在shuffle，以需求为目标。虽然shuffle的存在会影响一定的效率, 但是以完成任务为准则，该用那个算子，就使用那个算子即可，不要过分纠结。算子中一般以ByKey结尾的会发生shuffle另外是重分区算子也会发生shuffle。 1.3、DAG和Stage DAG：有向无环图，主要描述一段执行任务，从开始一直往下走，不允许出现回调操作,Spark应用程序中，遇到一个Action算子，就会触发形成一个Job任务的产生。
思考：对于每一个Job的任务，都会产生一个DAG执行流程图，那么这个流程图是如何形成的呢?
层级关系： 1- 一个application应用程序 -&gt; 遇到一个Action算子，就会触发形成一个Job任务 2- 一个Job任务只有一个DAG有向无环图 3- 一个DAG有向无环图 -&gt; 有多个Stage 4- 一个Stage -&gt; 有多个Task线程 5- 一个RDD -&gt; 有多个分区 6- 一个分区会被一个Task线程所处理 DAG执行流程图形成和Stage划分
1- Spark应用程序遇到Action算子后，就会触发一个Job任务的产生。Job任务会将它所依赖的所有算子全部加载进来，形成一个Stage。 2- 接着从Action算子从后往前进行回溯，遇到窄依赖就将算子放在同一个Stage当中；如果遇到宽依赖，就划分形成新的Stage，最后一直回溯完成。 细化剖析Stage内部的流程">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-06-30T12:01:51+08:00">
    <meta property="article:modified_time" content="2024-06-30T12:01:51+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Spark Core内核调度机制详解(第5天）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-tomorrow-night">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_1"></a>系列文章目录</h2> 
<ol><li>如何构建DAG执行流程图 (掌握)</li><li>如何划分Stage阶段 (掌握)</li><li>Driver底层是如何运转 (掌握)</li><li>确定需要构建多少分区(线程) (掌握)</li></ol> 
<hr> 
<p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#_1" rel="nofollow">系列文章目录</a></li><li><a href="#_9" rel="nofollow">引言</a></li><li><a href="#Spark_21" rel="nofollow">一、Spark内核调度（掌握）</a></li><li><ul><li><ul><li><a href="#11_22" rel="nofollow">1.1、内容概述</a></li><li><a href="#12RDD_34" rel="nofollow">1.2、RDD的依赖</a></li><li><a href="#13DAGStage_54" rel="nofollow">1.3、DAG和Stage</a></li><li><a href="#14Spark_Shuffle_91" rel="nofollow">1.4、Spark Shuffle</a></li><li><a href="#15Job_127" rel="nofollow">1.5、Job调度流程</a></li><li><a href="#16Spark_RDD_143" rel="nofollow">1.6、Spark RDD并行度</a></li></ul> 
  </li></ul> 
  </li><li><a href="#__197" rel="nofollow">二. 常见面试题</a></li><li><ul><li><ul><li><a href="#1RDD_198" rel="nofollow">1.简单介绍下RDD宽依赖和窄依赖的区别</a></li><li><a href="#2DAGStage_218" rel="nofollow">2.简单介绍下DAG有向无环图如何划分Stage阶段的</a></li><li><a href="#3rddjob_223" rel="nofollow">3.请描述下rdd中job的整个调度流程</a></li></ul> 
  </li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h2><a id="_9"></a>引言</h2> 
<p>本文主要介绍了<br> 1.RDD的依赖<br> 2.DAG和Stage<br> 3.Spark Shuffle<br> 4.job调度流程(掌握)<br> 5.Spark RDD并行度<br> 帮助读者更好地理解其工作原理和优化方法。</p> 
<hr> 
<h2><a id="Spark_21"></a>一、Spark内核调度（掌握）</h2> 
<h4><a id="11_22"></a>1.1、内容概述</h4> 
<p>Spark内核调度的任务：</p> 
<ul><li>如何构建DAG执行流程图</li><li>如何划分Stage阶段</li><li>Driver底层是如何运转</li><li>确定需要构建多少分区（线程）</li></ul> 
<p>Spark内核调度的目的：尽可能用最少的资源高效地完成任务计算。</p> 
<h4><a id="12RDD_34"></a>1.2、RDD的依赖</h4> 
<p>RDD依赖：一个RDD的形成可能是由一个或者多个RDD得到的，此时这个RDD和之前的RDD之间产生依赖关系。</p> 
<p>在Spark中，RDD之间的依赖关系，主要有二种类型：</p> 
<ul><li>窄依赖</li></ul> 
<ol><li>作用: 能够让Spark程序并行计算。也就是一个分区数据计算出现问题以后，其他的分区计算不受到任何影响。</li><li>特点: 父RDD的分区和子RDD的分区关系是一对一的关系。也就是父RDD分区的数据会整个被下游子RDD的分区接收。</li></ol> 
<p><img src="https://images2.imgbox.com/97/84/kfzdm4aX_o.png" alt="在这里插入图片描述"></p> 
<ul><li>宽依赖</li></ul> 
<ol><li>作用: 划分Stage的重要依据。宽依赖也叫做Shuffle依赖。</li><li>特点: 父RDD的分区和子RDD的分区关系是一对多的关系，也就是父RDD的分区数据会被分成多份给到下游子RDD的多个分区所接收。</li><li>注意:为了避免数据不完整，如果有宽依赖，shuffle下游的其他操作，必须等待shuffle执行完成以后才能够继续执行。</li></ol> 
<p><img src="https://images2.imgbox.com/c5/92/ECYvmRy9_o.png" alt="在这里插入图片描述"></p> 
<ul><li>说明 
  <ol><li>在实际使用中，不需要纠结哪些算子会存在shuffle，以需求为目标。虽然shuffle的存在会影响一定的效率, 但是以完成任务为准则，<strong>该用那个算子，就使用那个算子即可，不要过分纠结</strong>。</li><li>算子中一般以ByKey结尾的会发生shuffle另外是重分区算子也会发生shuffle。</li></ol> </li></ul> 
<h4><a id="13DAGStage_54"></a>1.3、DAG和Stage</h4> 
<ul><li> <p>DAG：有向无环图，主要描述一段执行任务，从开始一直往下走，不允许出现回调操作,Spark应用程序中，遇到一个Action算子，就会触发形成一个Job任务的产生。</p> </li><li> <p>思考：对于每一个Job的任务，都会产生一个DAG执行流程图，那么这个流程图是如何形成的呢?</p> </li></ul> 
<pre><code>层级关系：
1- 一个application应用程序 -&gt; 遇到一个Action算子，就会触发形成一个Job任务
2- 一个Job任务只有一个DAG有向无环图
3- 一个DAG有向无环图 -&gt; 有多个Stage
4- 一个Stage -&gt; 有多个Task线程

5- 一个RDD -&gt; 有多个分区
6- 一个分区会被一个Task线程所处理
</code></pre> 
<ul><li><strong>DAG执行流程图形成和Stage划分</strong><br> <img src="https://images2.imgbox.com/65/57/A6Z4elI4_o.png" alt="在这里插入图片描述"></li></ul> 
<pre><code>1- Spark应用程序遇到Action算子后，就会触发一个Job任务的产生。Job任务会将它所依赖的所有算子全部加载进来，形成一个Stage。

2- 接着从Action算子从后往前进行回溯，遇到窄依赖就将算子放在同一个Stage当中；如果遇到宽依赖，就划分形成新的Stage，最后一直回溯完成。
</code></pre> 
<ul><li>细化剖析Stage内部的流程<br> <img src="https://images2.imgbox.com/cf/dd/mDJ3SFNy_o.png" alt="在这里插入图片描述"></li><li>默认并行度的值确认</li></ul> 
<pre><code>因为是使用textFile读取HDFS上的文件，因此RDD分区数=max(文件的block块的数量, defaultMinPartition)，继续需要知道defaultMinPartition的值是多少。

defaultMinPartition=min(spark.default.parallelism,2)取最小值。最终我们确认spark.default.parallelism的参数值就能够最终确认RDD的分区数有多少个。

spark.default.parallelism参数值确认过程如下：
1- 如果有父RDD，就取父RDD的最大分区数
2- 如果没有父RDD，根据集群模式进行取值：
   2.1- 本地模式：机器的最大CPU核数
   2.2- （了解）Mesos：默认是8
   2.3- 其他模式：所有执行节点上的核总数或2，以较大者为准
</code></pre> 
<h4><a id="14Spark_Shuffle_91"></a>1.4、Spark Shuffle</h4> 
<ul><li>Spark中shuffle的发展历程</li></ul> 
<pre><code>1- 在1.1版本以前，Spark采用Hash shuffle (优化前 和 优化后)

2- 在1.1版本的时候，Spark推出了Sort Shuffle

3- 在1.5版本的时候，Spark引入钨丝计划(优化为主)

4- 在1.6版本的时候，将钨丝计划合并到sortShuffle中

5- 在2.0版本的时候，将Hash Shuffle移除，将Hash shuffle方案移植到Sort Shuffle
</code></pre> 
<p><img src="https://images2.imgbox.com/16/e1/ZmjZRIXZ_o.png" alt="在这里插入图片描述"></p> 
<ul><li> <p>未优化的Hash shuffle<br> <img src="https://images2.imgbox.com/28/7c/cBmEKcuJ_o.png" alt="在这里插入图片描述"></p> </li><li> <p>存在的问题<br> 上游（map端）的每个Task会产生与下游Task个数相等的小文件个数。这种情况会导致上游有非常多的小文件。另外，下游（reduce端）来拉取文件的时候，会有大量的网络IO和磁盘IO过程，因为要打开和读取多个小文件。</p> </li><li> <p>经过优化后的Hash shuffle<br> <img src="https://images2.imgbox.com/b9/f5/GCS6JS57_o.png" alt="在这里插入图片描述"><br> 变成了由每个Executor进程产生与下游Task个数相等的小文件数。这样可以大量减小小文件的产生，以及降低下游拉取文件时候的网络IO和磁盘IO过程。</p> </li><li> <p>Sort shuffle<br> <img src="https://images2.imgbox.com/8f/23/hOyvZ5zp_o.png" alt="在这里插入图片描述"></p> </li></ul> 
<pre><code>Sort Shuffle分成了两种: 普通机制和bypass机制。具体使用哪种，由Spark底层决定。

普通机制的运行过程: 每个上游Task线程处理数据，数据处理完以后，先放在内存中。接着对内存中的数据进行分区、排序。将内存中的数据溢写到磁盘，形成一个个的小文件。溢写完成以后，会将多个小文件合并成一个大的磁盘文件。并且针对每个大的磁盘文件，会提供一个索引文件。接着是下游Task根据索引文件来读取相应的数据。

bypass机制: 就是在普通机制的基础上，省略了排序的过程

bypass机制的触发条件是：
1- 上游RDD的分区数量最多不能超过200个
2- 上游不能对数据进行提前聚合操作（因为提前聚合，需要先进行分组操作，而分组的操作实际上是有排序的操作）
</code></pre> 
<h4><a id="15Job_127"></a>1.5、Job调度流程</h4> 
<ul><li>主要是讨论：在Driver内部，是如何调度任务<br> <img src="https://images2.imgbox.com/00/ab/TNHNmg3v_o.png" alt="在这里插入图片描述"></li></ul> 
<pre><code>1- Driver进程启动后，底层PY4J创建SparkContext顶级对象。在创建该对象的过程中，还会创建另外两个对象，分别是: DAGScheduler和TaskScheduler
	DAGScheduler: DAG调度器。将Job任务形成DAG有向无环图和划分Stage的阶段
	TaskScheduler: Task调度器。将Task线程分配给到具体的Executor执行

2- 一个Spark程序遇到一个Action算子就会触发产生一个Job任务。SparkContext将Job任务给到DAG调度器，拿到Job任务后，会将Job任务形成DAG有向无环图和划分Stage的阶段。并且会确定每个Stage阶段有多少个Task线程，会将众多的Task线程放到TaskSet的集合中。DAG调度器将TaskSet集合给到Task调度器

3- Task调度器拿到TaskSet集合以后，将Task分配给到给到具体的Executor执行。底层是基于SchedulerBackend调度队列来实现的。

4- Executor开始执行任务。并且Driver会监控各个Executor的执行状态，直到所有的Executor执行完成，就认为任务运行结束

5- 后续过程和之前一样
</code></pre> 
<h4><a id="16Spark_RDD_143"></a>1.6、Spark RDD并行度</h4> 
<ul><li>整个Spark应用中，影响并行度的因素有以下两个原因:<br> 1- 资源的并行度: Executor数量 和 CPU核心数 以及 内存的大小。<br> 2- 数据的并行度: Task的线程数 和 分区数量。</li></ul> 
<pre><code>一般将Task线程数设置为CPU核数的2-3倍。另外每个线程分配3-5GB的内存资源。
</code></pre> 
<ul><li>如何设置并行度</li></ul> 
<pre><code>语法: SparkConf().set("spark.default.parallelism", "num")

说明: spark.default.parallelism该参数是SparkCore中的参数。
该参数只会影响shuffle以后的分区数量。
另外该参数对parallelize并行化本地集合创建的RDD不起作用。
</code></pre> 
<ul><li>代码演示</li></ul> 
<pre><code class="prism language-1"># 导包
from pyspark import SparkContext, SparkConf
import os

# 绑定指定的python解释器
os.environ['SPARK_HOME'] = '/export/server/spark'
os.environ['PYSPARK_PYTHON'] = '/root/anaconda3/bin/python3'
os.environ['PYSPARK_DRIVER_PYTHON'] = '/root/anaconda3/bin/python3'
if __name__ == '__main__':
    # 6.1 TODO: 设置并行度
    conf = SparkConf().set('spark.default.parallelism', '6')

    # - 1.创建SparkContext对象
    sc = SparkContext(conf=conf)
    # - 2.数据输入
    textRDD = sc.textFile('file:///export/data/spark_project/spark_base/content.txt')
    # - 3.数据处理
    #   - 3.1文本内容切分
    flatMapRDD = textRDD.flatMap(lambda line: line.split(" "))
    #   - 3.2数据格式转换
    mapRDD = flatMapRDD.map(lambda word: (word, 1))

    # 6.2 TODO: shuffle之前查看分区数量
    print(f"shullfe之前分区数: {mapRDD.getNumPartitions()},分区内容:{mapRDD.glom().collect()}")

    #   - 3.3分组和聚合
    reduceRDD = mapRDD.reduceByKey(lambda agg, curr: agg + curr)
    
    # 6.3 TODO: shuffle之后查看分区数量
    print(f"shullfe之后分区数: {reduceRDD.getNumPartitions()},分区内容:{reduceRDD.glom().collect()}")

    # - 4.数据输出
    # print(reduceRDD.collect())
    # - 5.释放资源
    sc.stop()

</code></pre> 
<h2><a id="__197"></a>二. 常见面试题</h2> 
<h4><a id="1RDD_198"></a>1.简单介绍下RDD宽依赖和窄依赖的区别</h4> 
<pre><code>--- 窄依赖（Narrow Dependency）
1- 定义：每一个父RDD的分区最多被子RDD的一个分区所使用。这通常表现为一对一（OneToOneDependencies）或多对一（多个父RDD的分区对应于一个子RDD的分区）的关系。
2- 操作示例：map、filter、union等操作会产生窄依赖。这些操作的特点是，子RDD的每个分区都是基于父RDD的一个或多个特定分区计算得出的。
3- 容错处理：当窄依赖的子RDD数据丢失时，由于父RDD的一个分区只对应一个子RDD分区，因此只需要重新计算与子RDD分区对应的父RDD分区即可。
4- 优化特性：窄依赖可以进行流水线优化，利用fork/join机制，一个作业可以直接一个阶段完成，形成管道型的流水化处理。
--- 宽依赖（Wide Dependency 或 Shuffle Dependency）
1- 定义：子RDD的每一个分区都会使用所有父RDD的所有分区或多个分区。这通常表现为一对多（OneToManyDependencies）的关系。
2- 操作示例：groupByKey、reduceByKey、sortedByKey等操作会产生宽依赖。这些操作的特点是，子RDD的每个分区都可能依赖于父RDD的所有分区。
3- 容错处理：当宽依赖的子RDD数据丢失时，由于一个分区的数据通常由多个父RDD分区数据变换而来，因此可能需要重新计算父RDD的所有分区才能恢复数据。
4- 优化限制：宽依赖通常涉及shuffle操作，需要将数据写入磁盘并等待，因此无法形成管道型的流水化处理。
</code></pre> 
<ul><li>总结<br> 数据流动：窄依赖的数据流动是线性的，而宽依赖的数据流动是跨多个分区的。<br> 容错处理：窄依赖的容错处理更为高效，只需要重新计算部分数据；而宽依赖的容错处理可能涉及大量数据的重新计算。<br> 优化特性：窄依赖可以进行流水线优化，而宽依赖通常不能。<br> Shuffle操作：宽依赖通常伴随着shuffle操作，而窄依赖则没有。<br> 以上是对RDD宽依赖和窄依赖的简要介绍和区别分析。</li></ul> 
<h4><a id="2DAGStage_218"></a>2.简单介绍下DAG有向无环图如何划分Stage阶段的</h4> 
<ul><li> <p>1- Spark应用程序遇到Action算子后，就会触发一个Job任务的产生。Job任务会将它所依赖的所有算子全部加载进来，形成一个Stage。</p> </li><li> <p>2- 接着从Action算子从后往前进行回溯，遇到窄依赖就将算子放在同一个Stage当中；如果遇到宽依赖，就划分形成新的Stage，最后一直回溯完成。</p> </li></ul> 
<h4><a id="3rddjob_223"></a>3.请描述下rdd中job的整个调度流程</h4> 
<pre><code>1- Driver进程启动后，底层PY4J创建SparkContext顶级对象。在创建该对象的过程中，还会创建另外两个对象，分别是: DAGScheduler和TaskScheduler
    DAGScheduler: DAG调度器。将Job任务形成DAG有向无环图和划分Stage的阶段
    TaskScheduler: Task调度器。将Task线程分配给到具体的Executor执行

2- 一个Spark程序遇到一个Action算子就会触发产生一个Job任务。SparkContext将Job任务给到DAG调度器，拿到Job任务后，会将Job任务形成DAG有向无环图和划分Stage的阶段。并且会确定每个Stage阶段有多少个Task线程，会将众多的Task线程放到TaskSet的集合中。DAG调度器将TaskSet集合给到Task调度器

3- Task调度器拿到TaskSet集合以后，将Task分配给到给到具体的Executor执行。底层是基于SchedulerBackend调度队列来实现的。

4- Executor开始执行任务。并且Driver会监控各个Executor的执行状态，直到所有的Executor执行完成，就认为任务运行结束

5- 后续过程和之前一样
</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/dbffa28cffcb75ede73e7cf6b339b5f7/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Spark SQL函数详解：案例解析(第8天)</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/91b585364b3505fd84f2dca245815915/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">FastAPI教程III</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>