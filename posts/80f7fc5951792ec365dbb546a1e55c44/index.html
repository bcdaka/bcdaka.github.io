<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>秋叶大佬24年最新的Stable Diffusion整合包V4.6.7来了～ - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/80f7fc5951792ec365dbb546a1e55c44/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="秋叶大佬24年最新的Stable Diffusion整合包V4.6.7来了～">
  <meta property="og:description" content="！
「 无套路！文末提供下载方式 」
要说今年绘画圈最大的新秀
那妥妥的就Stable Diffution
V4升级版无需安装**，直接解压就能用
（在此要感谢秋葉aaaki大佬的分享！）
比之前推送的更加智能、快速和简单
有多简单呢？这么说吧
之前的版本需要初中生级别
现在的V4加强版小学生也能上手！
1、Stable Diffusion 是什么？
Stable Diffusion（简称SD）是一种生成式人工智能，于2022年发布，主要用于根据文本描述生成详细图像，也可用于其他任务，如图像的修补、扩展和通过文本提示指导图像到图像的转换。除图像外，您还可以使用该模型创建视频和动画。
这是AI绘画第一次能在可以在消费级显卡上运行，任何人都可以下载模型并生成自己的图像。另外，SD高质量的成图以及强大的自由度（自定义、个性化）受到诸多网友的追捧。Stable
Diffusion XL 1.0 (SDXL 1.0) 是Stable Diffusion的一个更为高级和优化的版本，它在模型规模、图像质量、语言理解和模型架构等方面都有显著的改进。
Stable Diffusion 能做什么？
首先，大家在入坑SD前，务必要清楚现阶段的SD到底能做什么？能否满足自己的需求？
Stable Diffusion 功能包括文本转图像、图像转图像、图形插图、图像编辑和视频创作。
**文本转图像生成：**最常见和最基础的功能。Stable Diffusion 会根据文本提示生成图像。
图像转图像生成使用输入图像和文本提示，您可以根据输入图像创建新图像。典型的案例是使用草图和合适的提示。
创作图形、插图和徽标使用一系列提示，可以创建各种风格的插图、图形和徽标。
图像编辑和修正可以使用 Stable Diffusion 来编辑和修正照片。例如，可以修复旧照片、移除图片中的对象、更改主体特征以及向图片添加新元素。
视频创作使用 GitHub 中的 Deforum 等功能，可以借助 Stable Diffusion 创作短视频片段和动画。另一种应用是为电影添加不同的风格。 还可以通过营造运动印象（例如流水）来为照片制作动画。
2、安装和部署Stable Diffusion** 介绍如何安装和部署Stable Diffusion。我使用的是秋葉aaaki的整合包，文章末尾提供180G整合包～‍‍‍‍
电脑系统：Windows10及以上/macOS Monterey (12.5)。
显卡：RTX3060及以上。
显存：8G及以上。
内存：16G及以上。
磁盘空间：500 SSD及以上
操作步骤
步骤一：右键解压Stable Diffusion安装包。
步骤二：双击Stable Diffusion安装包进入文件夹中，解压sd-webui-aki-v4.2。
步骤三：双击启动器运行依赖-dotnet-6.0.11，安装所需依赖。">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-03-22T20:13:20+08:00">
    <meta property="article:modified_time" content="2024-03-22T20:13:20+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">秋叶大佬24年最新的Stable Diffusion整合包V4.6.7来了～</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>！</p> 
<p><strong>「 无套路！文末提供下载方式 」</strong></p> 
<p>要说今年绘画圈最大的新秀</p> 
<p>那妥妥的就Stable Diffution</p> 
<p><strong>V4升级版无需安装</strong>**，直接解压就能用</p> 
<p>（在此要感谢秋葉aaaki大佬的分享！<strong>）</strong></p> 
<p>比之前推送的更加智能、快速和简单</p> 
<p>有多简单呢？这么说吧</p> 
<p>之前的版本需要初中生级别</p> 
<p>现在的V4加强版小学生也能上手！</p> 
<p><img src="https://images2.imgbox.com/69/f1/s5gp7SBF_o.png" alt=""></p> 
<p>1、Stable Diffusion 是什么？</p> 
<p>Stable Diffusion（简称SD）是一种生成式人工智能，于2022年发布，主要用于根据文本描述生成详细图像，也可用于其他任务，如图像的修补、扩展和通过文本提示指导图像到图像的转换。除图像外，您还可以使用该模型创建视频和动画。</p> 
<p>这是AI绘画第一次能在可以在消费级显卡上运行，任何人都可以下载模型并生成自己的图像。另外，SD高质量的成图以及强大的自由度（自定义、个性化）受到诸多网友的追捧。Stable</p> 
<p>Diffusion XL 1.0 (SDXL 1.0) 是Stable Diffusion的一个更为高级和优化的版本，它在模型规模、图像质量、语言理解和模型架构等方面都有显著的改进。</p> 
<p>Stable Diffusion 能做什么？</p> 
<hr> 
<p>首先，大家在入坑SD前，务必要清楚现阶段的SD到底能做什么？能否满足自己的需求？</p> 
<p>Stable Diffusion 功能包括文本转图像、图像转图像、图形插图、图像编辑和视频创作。</p> 
<ul><li> <p>**文本转图像生成：**最常见和最基础的功能。Stable Diffusion 会根据文本提示生成图像。</p> </li><li> <p><strong>图像转图像生成</strong>使用输入图像和文本提示，您可以根据输入图像创建新图像。典型的案例是使用草图和合适的提示。</p> </li><li> <p><strong>创作图形、插图和徽标</strong>使用一系列提示，可以创建各种风格的插图、图形和徽标。</p> </li><li> <p><strong>图像编辑和修正</strong>可以使用 Stable Diffusion 来编辑和修正照片。例如，可以修复旧照片、移除图片中的对象、更改主体特征以及向图片添加新元素。</p> </li><li> <p><strong>视频创作</strong>使用 GitHub 中的 Deforum 等功能，可以借助 Stable Diffusion 创作短视频片段和动画。另一种应用是为电影添加不同的风格。 还可以通过营造运动印象（例如流水）来为照片制作动画。</p> </li></ul> 
<h2><a id="2Stable_Diffusion_59"></a>2、安装和部署Stable Diffusion**</h2> 
<p><strong>介绍如何安装和部署Stable Diffusion。我使用的是秋葉aaaki的整合包，文章末尾提供180G整合包～‍‍‍‍</strong></p> 
<p>电脑系统：Windows10及以上/macOS Monterey (12.5)。<br> 显卡：RTX3060及以上。<br> 显存：8G及以上。<br> 内存：16G及以上。<br> 磁盘空间：500 SSD及以上</p> 
<p>操作步骤</p> 
<p>步骤一：右键解压Stable Diffusion安装包。</p> 
<p><img src="https://images2.imgbox.com/69/17/TMSjaCye_o.png" alt=""></p> 
<p><strong>步骤二</strong>：双击<strong>Stable Diffusion安装包</strong>进入文件夹中，解压<strong>sd-webui-aki-v4.2</strong>。</p> 
<p><img src="https://images2.imgbox.com/f2/6d/tUGiRBq9_o.png" alt=""></p> 
<p><strong>步骤三</strong>：双击<strong>启动器运行依赖-dotnet-6.0.11</strong>，安装所需依赖。</p> 
<p><img src="https://images2.imgbox.com/bc/25/PtbX2MQ0_o.png" alt=""></p> 
<p><strong>步骤四</strong>：双击<strong>sd-webui-aki-v4.xx</strong>进入该文件夹中，下拉找到<strong>A启动器</strong>并启动。</p> 
<blockquote> 
 <p>注：第一次启动，需要一些时间部署Python和Git环境，请耐心等待，后面启动就很快了。若未弹出WebUI界面，请将复制链接：http://127.0.0.1:7860 到浏览器中即可。</p> 
</blockquote> 
<p><img src="https://images2.imgbox.com/86/24/oQSFUsfh_o.png" alt=""></p> 
<p>若弹出Stable Diffusion WebUI界面，则表示启动成功。</p> 
<p><img src="https://images2.imgbox.com/5a/6e/9kTWUovW_o.png" alt=""></p> 
<p>3</p> 
<h2><a id="Stable_Diffusion_98"></a><strong>Stable Diffusion教程与模型</strong></h2> 
<p><img src="https://images2.imgbox.com/cb/50/z4B4nR2F_o.png" alt=""></p> 
<h2><a id="Stable_Diffusion_WebUI_103"></a><strong>Stable Diffusion WebUI界面介绍</strong></h2> 
<h3><a id="Stable_Diffusion_WebUI__108"></a>****▍<strong>Stable Diffusion WebUI</strong> <strong>介绍</strong></h3> 
<p>1. Stable Diffusion WebUI界面主要分为三个区域：<strong>模型选择区</strong>、<strong>功能选择区</strong>、<strong>参数配置区</strong>。</p> 
<p><img src="https://images2.imgbox.com/49/7c/jWN3JU1u_o.png" alt=""></p> 
<p>2. 里面的参数非常多，第一次看到定会眼花缭乱，我对此进行了一次归类分组，这些参数主要分为两类：</p> 
<p><strong>一是</strong>为了告诉AI，用户的需求是什么，进而完成作图任务，称为<strong>基础参数</strong>。如提示词框、模型选择，迭代步数，采样器，图片尺寸等。</p> 
<p><strong>二是</strong>为了高效率地完成这个任务而存在的参数，称为<strong>额外参数</strong>，是非必要的参数。如垃圾桶，一键清除提示词、文件夹、打包下载、预设样式等。</p> 
<p>那么，现在我们在看到某个参数时就知道它大致的作用是什么了。</p> 
<p><img src="https://images2.imgbox.com/e4/9d/dK8PFfqe_o.png" alt=""></p> 
<h3><a id="Stable_Diffusion__125"></a><strong>Stable Diffusion 布局/参数介绍</strong></h3> 
<p>接下来我将依次介绍Stable Diffusion文生图功能中的参数，指导用户快速了解和使用这些参数，以便更好地出图。</p> 
<blockquote> 
 <p>注：1. 这里的参数介绍只起到<strong>指导性作用</strong>，若想进一步了解各个参数的细节和原理，请阅读后续的文章。2. 由于这是整合包相比较原生的Stable Diffusion安装包，功能较多，且已经汉化了。</p> 
</blockquote> 
<h4><a id="_132"></a><strong>模型选择区</strong></h4> 
<p><img src="https://images2.imgbox.com/84/bb/fxmkrjyl_o.png" alt=""></p> 
<p><strong>1. Stable Diffusion模型</strong>：下拉选择大模型，默认<strong>anyting-V5模型</strong>。请根据自身需求选择不同类型的模型，如现实主义风格的模型；动漫，二次元风格的模型。</p> 
<p><strong>2. 外挂VAE模型</strong>：下拉选择VAE模型，默认<strong>无</strong>。是可选操作，可以选择不同效果的VAE模型，对成图细节或颜色进行修复，同时选择VAE也可以起到节省电脑算力的作用。</p> 
<p><strong>3. CLIP终止层数（Clip Skip）</strong>：滑动确认或输入层数，层数范围为1~12层，默认层数为<strong>2</strong>。1层，成图更加精确；2层，成图更加平衡，即AI遵循提示词，也有一定自己的创意；3-12层，成图更加有创意。<strong>这里推荐2层</strong>。若你希望AI更加有自己的创意，还是请调节<strong>提示词引导系数（CFG Scale</strong>）参数，效果会更好。</p> 
<blockquote> 
 <p>注：选择模型时，需要提前下载模型并存储到对应的路径中。模型下载可前往：huggingface网站或Civital网站。Stable Diffusion模型存储位置是：<code>*\models\Stable-diffusion</code>。VAE模型存储位置是：<code>*\models\VAE</code>。存储完后，点击“🔄”即可。</p> 
</blockquote> 
<h4><a id="_146"></a><strong>功能配置区</strong></h4> 
<p><img src="https://images2.imgbox.com/80/17/5EJa6RtR_o.png" alt=""></p> 
<h4><a id="_152"></a><strong>参数配置区</strong></h4> 
<p>简单介绍各个参数信息，分为基础参数、额外参数以及老版本的参数。 <img src="https://images2.imgbox.com/a2/70/s6vk0vfW_o.png" alt=""></p> 
<h5><a id="_156"></a></h5> 
<h5><a id="_158"></a><strong>基础参数</strong></h5> 
<p><strong>1. 正向提示词（Prompt）</strong>：输入你希望图片中出现什么内容。仅支持英文输入。</p> 
<p><strong>2. 反向提示词（Negative prompt）</strong>：输入你不希望图片中出现什么内容，比如多手指。仅支持英文输入。</p> 
<p><strong>3. 迭代步数（Sampling Steps）</strong>：设置图片去噪的步数，步数越多画面越精细，出图时间也越长。步数范围1～150步，1～19步更加模糊，粗糙；20～40步，更加平衡；40～150步更加精细。其中并不是步数越多越好，为了避免过犹不及，这里<strong>推荐20～40步，更加平衡</strong>。</p> 
<p><strong>4. 采样方法（Sampler Method）</strong>：点击勾选采样方法。不同的采样方法，有不同效果，这里大家多次尝试即可。</p> 
<p><strong>5. 高分辨率修复（Hires. fix</strong>）：勾选即可将图片的分辨率放大。如从512_512px到1024_1024。</p> 
<p>请根据自身显卡性能，设置图片基础分辨率，请勿设置的过高，否则在勾选<strong>高分辨率修复</strong>后，会显示：Out Of Memory Error，爆显存了。</p> 
<p><strong>6. Refiner</strong>：待补充。</p> 
<p><strong>7. 尺寸（宽度、高度）</strong>：设置成图的尺寸。默认512_512px。推荐的尺寸有：512_768px、768_512px、768_1152。</p> 
<p><strong>8. 总批次数</strong>：指一次生成图片多少张，这里指陆续跑图。根据显卡性能，酌情设置，推荐1~4。</p> 
<p><strong>9. 单批数量</strong>：指一次同时生成几张图片，这里指同时跑图。显卡压力更大，不建议设置为2以上。</p> 
<p><strong>10. 提示词引导系数（CFG Scale）</strong>：AI遵循提示词的程度/成图与提示词相关度。数值越低更加精确，越高则更有创造力，这里推荐<strong>5~7更加平衡</strong>。</p> 
<blockquote> 
 <p>注：该参数类似于New Bing对话框中的选择对话样式，分为更有创造力、更平衡、更精确。提示词引导系数（CFG Scale）则是以具体的数值来供用户设置。</p> 
 <p><img src="https://images2.imgbox.com/20/7e/dBTKQnyF_o.png" alt=""></p> 
</blockquote> 
<p><strong>11. 随机种子数（Seed）</strong>：设置成图是否随机。文本框默认-1，表示随机产生不同的图片。点击“🎲”将随机种子设置为-1；点击“♻️”将成图的种子数（即唯一编码），设置为随机种子数，在其他参数不变的情况下生成的图片相似99%；点击“⏹️”则是进行更多设置。</p> 
<p><strong>12. 脚本（Script）</strong>：一键测试提示词或各个参数变化对成图的影响。选项默认<strong>无</strong>，分为<strong>提示词矩阵</strong>、<strong>从文本框或文件载入提示词</strong>、<strong>X/Y/Z图表</strong>、<strong>controlnet m2m</strong>。</p> 
<p><img src="https://images2.imgbox.com/66/2b/ttbXL0kg_o.png" alt=""></p> 
<p>关于模型（和谐部分，请自行查阅）</p> 
<p>我们现在可以在很多的模型网站，比如c站、huggingface，也就是抱脸网，上找到很多的训练好的stable diffusion 模型。比如我现在已经用过的Linaqruf/animagine-xl 和 xiaolxl/GuoFeng3模型。</p> 
<p>Linaqruf/animagine-xl 是一个可以生成优质动漫风格图像的SD模型。我们只需要输入设计好的提示词，Linaqruf/animagine-xl 就可以自动生成相应的动漫图片了。下面是通过 Linaqruf/animagine-xl 生成的卡通图片：</p> 
<p><img src="https://images2.imgbox.com/ad/a8/Em8SL2Ss_o.png" alt=""></p> 
<p>xiaolxl/GuoFeng3 是一个中国华丽古风风格模型，也可以说是一个古风游戏角色模型，具有2.5D的质感。相比于前几代，第三代大幅度减少上手难度，增加了场景元素与男性古风人物，除此之外为了模型能更好地适应其它TAG，还增加了其它风格的元素。</p> 
<p>相比于前几代，这一代对脸和手的崩坏有一定的修复，同时素材大小也提高到了最长边1024。效果图如下：</p> 
<p><img src="https://images2.imgbox.com/4c/39/VohuSj2e_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/b1/a7/fFJAFZVj_o.png" alt="在这里插入图片描述"></p> 
<p><strong>Stable Diffusion</strong></p> 
<h2><a id="180G_216"></a><strong>180G</strong></h2> 
<h2><a id="aaaki_218"></a>秋葉aaaki整合包+教程‍‍‍‍‍‍*</h2> 
<p><img src="https://images2.imgbox.com/f8/e5/jz88YEjn_o.png" alt=""></p> 
<p>下载整合包后，点击里面的启动器，点击启动界面的一键启动，启动器会自动启动Stable Diffusion Web UI，并打开浏览器</p> 
<p><img src="https://images2.imgbox.com/03/7e/FbtZI9it_o.png" alt=""></p> 
<p><img src="https://images2.imgbox.com/31/2c/LMfx1685_o.png" alt=""></p> 
<p>打开后的Stable Diffusion Web UI界面。</p> 
<p><img src="https://images2.imgbox.com/2e/5c/Wl7KRUFx_o.png" alt=""></p> 
<p>使用的时候，输入正面提示词和反面提示词（非必须），其他的选项使用默认的就行，然后点击 生成，稍微等待一会，就可以得到生成的图片了。</p> 
<p>Stable Diffusion Web UI 界面原本是英文的，我们只需要在其启动器的高级设置中启用云端页面汉化设置，就可以完成Stable Diffusion Web UI 汉化。</p> 
<p><img src="https://images2.imgbox.com/41/b0/kjDp708U_o.png" alt=""></p> 
<p>文末扫码获取这些资源。</p> 
<h3><a id="_262"></a>写在最后</h3> 
<p>AIGC技术的未来发展前景广阔，随着人工智能技术的不断发展，AIGC技术也将不断提高。未来，AIGC技术将在游戏和计算领域得到更广泛的应用，使游戏和计算系统具有更高效、更智能、更灵活的特性。同时，AIGC技术也将与人工智能技术紧密结合，在更多的领域得到广泛应用，对程序员来说影响至关重要。未来，AIGC技术将继续得到提高，同时也将与人工智能技术紧密结合，在更多的领域得到广泛应用。</p> 
<p><font face="幼圆" size="4" color="red">感兴趣的小伙伴，赠送全套AIGC学习资料和安装工具，包含AI绘画、AI人工智能等前沿科技教程，模型插件，具体看下方。<br> </font><br> <img src="https://images2.imgbox.com/51/94/B7g41wM7_o.jpg"></p> 
<p><strong>一、AIGC所有方向的学习路线</strong></p> 
<p>AIGC所有方向的技术点做的整理，形成各个领域的知识点汇总，它的用处就在于，你可以按照下面的知识点去找对应的学习资源，保证自己学得较为全面。</p> 
<p><img src="https://images2.imgbox.com/ca/d4/Ag4Dkpy0_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/1a/83/rp88O1Se_o.png" alt="在这里插入图片描述"></p> 
<p><strong>二、AIGC必备工具</strong></p> 
<p>工具都帮大家整理好了，安装就可直接上手！<br> <img src="https://images2.imgbox.com/f8/27/fdPWgkNg_o.png" alt="在这里插入图片描述"></p> 
<p><strong>三、最新AIGC学习笔记</strong></p> 
<p>当我学到一定基础，有自己的理解能力的时候，会去阅读一些前辈整理的书籍或者手写的笔记资料，这些笔记详细记载了他们对一些技术点的理解，这些理解是比较独到，可以学到不一样的思路。<br> <img src="https://images2.imgbox.com/5c/e9/IKBgZGcc_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/0b/ff/byIIHugF_o.png" alt="在这里插入图片描述"></p> 
<p><strong>四、AIGC视频教程合集</strong></p> 
<p>观看全面零基础学习视频，看视频学习是最快捷也是最有效果的方式，跟着视频中老师的思路，从基础到深入，还是很容易入门的。</p> 
<p><img src="https://images2.imgbox.com/c5/89/Co3KYrcw_o.png" alt="在这里插入图片描述"></p> 
<p><strong>五、实战案例</strong></p> 
<p>纸上得来终觉浅，要学会跟着视频一起敲，要动手实操，才能将自己的所学运用到实际当中去，这时候可以搞点实战案例来学习。<br> <img src="https://images2.imgbox.com/74/84/TdWiu4of_o.png" alt="在这里插入图片描述"></p> 
<img src="https://images2.imgbox.com/d1/3b/AddLOsl7_o.jpg"> 若有侵权，请联系删除
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/485fc4fe983fad44cad0287129a8aa77/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">这5款国内可用的宝藏AI绘画工具，不允许有人还不知道！</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/bc6891759085ab038ee7b92172db29af/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">数据结构——单向链表（C语言版）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>