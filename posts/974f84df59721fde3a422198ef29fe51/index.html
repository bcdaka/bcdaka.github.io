<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>大数据基础hadoop / hive / hbase - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/974f84df59721fde3a422198ef29fe51/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="大数据基础hadoop / hive / hbase">
  <meta property="og:description" content="前言 大数据之hadoop / hive / hbase 的区别是什么？
1. hadoop
它是一个分布式计算&#43;分布式文件系统，前者其实就是 MapReduce，后者是 HDFS 。后者可以独立运行，前者可以选择性使用，也可以不使用
2. hive
通俗的说是一个数据仓库，仓库中的数据是被hdfs管理的数据文件，它支持类似sql语句的功能，你可以通过该语句完成分布式环境下的计算功能，hive会把语句转换成MapReduce，然后交给hadoop执行。这里的计算，仅限于查找和分析，而不是更新、增加和删除。
它的优势是对历史数据进行处理，用时下流行的说法是离线计算，因为它的底层是MapReduce，MapReduce在实时计算上性能很差。它的做法是把数据文件加载进来作为一个hive表（或者外部表），让你觉得你的sql操作的是传统的表。
3. hbase
通俗的说，hbase的作用类似于数据库，传统数据库管理的是集中的本地数据文件，而hbase基于hdfs实现对分布式数据文件的管理，比如增删改查。也就是说，hbase只是利用hadoop的hdfs帮助其管理数据的持久化文件（HFile），它跟MapReduce没任何关系。
hbase的优势在于实时计算，所有实时数据都直接存入hbase中，客户端通过API直接访问hbase，实现实时计算。由于它使用的是nosql，或者说是列式结构，从而提高了查找性能，使其能运用于大数据场景，这是它跟MapReduce的区别。
总结：
hadoop是hive和hbase的基础，hive依赖hadoop，而hbase仅依赖hadoop的hdfs模块。
hive适用于离线数据的分析，操作的是通用格式的（如通用的日志文件）、被hadoop管理的数据文件，它支持类sql，比编写MapReduce的java代码来的更加方便，它的定位是数据仓库，存储和分析历史数据。
hbase适用于实时计算，采用列式结构的nosql，操作的是自己生成的特殊格式的HFile、被hadoop管理的数据文件，它的定位是数据库，或者叫DBMS。
hive可以直接操作hdfs中的文件作为它的表的数据，也可以使用hbase数据库作为它的表。
一、HADOOP基础 1.大数据基础组件HDFS -分布式存储 参考：(超详细)大数据Hadoop之HDFS组件_[root@hadoop100 sbin]# start-dfs.sh starting namen-CSDN博客
【基础知识】大数据组件HDFS简述-CSDN博客
HDFS全称为Hadoop Distributed File System，很简单Hadoop的分布式文件存储系统。
定义： HDFS，它是一个文件系统，用于存储文件，通过目录树来定位文件；其次，它是分布式的，由很多服务器联合起来实现其功能，集群中的服务 器有各自的角色。
​ HDFS 的使用场景：适合一次写入，多次读出的场景。一个文件经过创建、写入和关闭 之后就不需要改变。
​ HDFS 的组成节点：
HDFS是经典的Master和Slave架构，每一个HDFS集群包括一个NameNode和多个DataNode。
Master-Slave架构常见于分布式系统或数据库管理系统。Master-Slave架构具有可伸缩性和容错性，能够处理更多并发请求，并在主节点故障时通过从节点继续提供服务，提高系统的可用性和可靠性。
主节点（Master）负责整个系统的协调和管理，接收并分配任务给从节点（Slave）。
从节点执行主节点分配的任务，可能包括读取、计算或存储数据。在数据库系统中，从节点还负责数据的复制和备份，以提高系统的可用性和容错性。
NameNode管理所有文件的元数据信息，并且负责与客户端交互。
DataNode负责管理存储在该节点上的文件。每一个上传到HDFS的文件都会被划分为一个或多个数据块，这些数据块根据HDFS集群的数据备份策略被分配到不同的DataNode上，位置信息交由NameNode统一管理。
Client客户端
​ 1): 文件切分。文件上传HDFS时，Client将文件切分成一个一个的Block，然后进行上传；
​ 2): 与NameNode交互，获取文件的位置信息；
​ 3): 与DataNode交互，读取或者写入数据；
​ 4): Client提供一些命令来管理HDFS，比如NameNode格式化；
​ 5): Client可以通过一些命令来访问HDFS，比如对HDFS增删查改操作；">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-04-15T16:51:48+08:00">
    <meta property="article:modified_time" content="2024-04-15T16:51:48+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">大数据基础hadoop / hive / hbase</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2>前言</h2> 
<p>大数据之hadoop / hive / hbase 的区别是什么？</p> 
<p>1. hadoop<br> 它是一个<strong>分布式计算+分布式文件系统</strong>，前者其实就是 <strong>MapReduce</strong>，后者是 <strong>HDFS</strong> 。后者可以独立运行，前者可以选择性使用，也可以不使用</p> 
<p>2. hive<br> 通俗的说是一个<strong>数据仓库</strong>，仓库中的数据是被hdfs管理的数据文件，它支持类似sql语句的功能，你可以通过该语句完成分布式环境下的计算功能，<strong>hive会把语句转换成MapReduce，然后交给hadoop执行</strong>。这里的计算，仅限于查找和分析，而不是更新、增加和删除。<br> 它的优势是对历史数据进行处理，用时下流行的说法是离线计算，因为它的<strong>底层是MapReduce</strong>，MapReduce在实时计算上性能很差。它的做法是把数据文件加载进来作为一个hive表（或者外部表），让你觉得你的sql操作的是传统的表。</p> 
<p>3. hbase<br> 通俗的说，hbase的作用类似于数据库，传统数据库管理的是集中的本地数据文件，而<strong>hbase基于hdfs实现对分布式数据文件的管理，比如增删改查</strong>。也就是说，hbase只是利用hadoop的hdfs帮助其管理数据的持久化文件（HFile），<strong>它跟MapReduce没任何关系。</strong><br><strong>hbase的优势在于实时计算</strong>，所有实时数据都直接存入hbase中，客户端通过API直接访问hbase，实现实时计算。由于它使用的是nosql，或者说是列式结构，从而提高了查找性能，使其能运用于大数据场景，这是它跟MapReduce的区别。</p> 
<blockquote> 
 <p>总结：<br><strong>hadoop是hive和hbase的基础</strong>，hive依赖hadoop，而hbase仅依赖hadoop的hdfs模块。<br> hive适用于<strong>离线数据的分析</strong>，操作的是通用格式的（如通用的日志文件）、被hadoop管理的数据文件，它支持类sql，比编写MapReduce的java代码来的更加方便，它的定位是数据仓库，存储和分析历史数据。<br> hbase适用于<strong>实时计算</strong>，采用列式结构的nosql，操作的是自己生成的特殊格式的HFile、被hadoop管理的数据文件，它的定位是数据库，或者叫DBMS。<br> hive可以直接操作hdfs中的文件作为它的表的数据，也可以使用hbase数据库作为它的表。</p> 
</blockquote> 
<h2>一、HADOOP基础</h2> 
<p><img alt="" height="437" src="https://images2.imgbox.com/59/67/ey6mhaDd_o.png" width="798"></p> 
<h3><span style="color:#fe2c24;">1.大数据基础组件HDFS -分布式存储</span></h3> 
<p>参考：<a href="https://blog.csdn.net/weixin_53227758/article/details/120977051" title="(超详细)大数据Hadoop之HDFS组件_[root@hadoop100 sbin]# start-dfs.sh starting namen-CSDN博客">(超详细)大数据Hadoop之HDFS组件_[root@hadoop100 sbin]# start-dfs.sh starting namen-CSDN博客</a></p> 
<p><a href="https://blog.csdn.net/weixin_44325637/article/details/135067947" title="【基础知识】大数据组件HDFS简述-CSDN博客">【基础知识】大数据组件HDFS简述-CSDN博客</a></p> 
<p>HDFS全称为<strong>Hadoop Distributed File System</strong>，很简单Hadoop的<strong>分布式文件存储系统</strong>。</p> 
<p><span style="color:#4da8ee;"><strong> 定义：</strong></span> HDFS，它是一个文件系统，用于存储文件，通过目录树来定位文件；其次，它是分布式的，由很多服务器联合起来实现其功能，集群中的服务 器有各自的角色。</p> 
<p><span style="color:#4da8ee;">​ <strong>HDFS 的使用场景</strong>：</span>适合一次写入，多次读出的场景。一个文件经过创建、写入和关闭 之后就不需要改变。</p> 
<p><span style="color:#4da8ee;">​ <strong>HDFS 的组成节点</strong>：</span></p> 
<p>HDFS是经典的Master和Slave架构，每一个HDFS集群包括一个NameNode和多个DataNode。</p> 
<blockquote> 
 <p>Master-Slave架构常见于分布式系统或数据库管理系统。Master-Slave架构具有可伸缩性和容错性，能够处理更多并发请求，并在主节点故障时通过从节点继续提供服务，提高系统的可用性和可靠性。</p> 
 <p>主节点（Master）负责整个系统的协调和管理，接收并分配任务给从节点（Slave）。</p> 
 <p>从节点执行主节点分配的任务，可能包括读取、计算或存储数据。在数据库系统中，从节点还负责数据的复制和备份，以提高系统的可用性和容错性。</p> 
</blockquote> 
<p><img alt="" height="391" src="https://images2.imgbox.com/25/07/FphWlaT5_o.png" width="768"></p> 
<p>NameNode管理所有文件的元数据信息，并且负责与客户端交互。</p> 
<p>DataNode负责管理存储在该节点上的文件。每一个上传到HDFS的文件都会被划分为一个或多个数据块，这些数据块根据HDFS集群的数据备份策略被分配到不同的DataNode上，位置信息交由NameNode统一管理。</p> 
<p><strong> Client客户端</strong><br> ​ 1): 文件切分。文件上传HDFS时，Client将文件切分成一个一个的Block，然后进行上传；</p> 
<p>​ 2): 与NameNode交互，获取文件的位置信息；</p> 
<p>​ 3): 与DataNode交互，读取或者写入数据；</p> 
<p>​ 4): Client提供一些命令来管理HDFS，比如NameNode格式化；</p> 
<p>​ 5): Client可以通过一些命令来访问HDFS，比如对HDFS增删查改操作；</p> 
<p><strong>NameNode</strong><br> 用于管理文件系统的命名空间、维护文件系统的目录结构树以及元数据信息，记录写入的每个数据块（Block）与其归属文件的对应关系，处理客户端读写请求。<br> 此信息以命名空间镜像（FSImage）和编辑日志（EditsLog）两种形式持久化在本地磁盘中。</p> 
<blockquote> 
 <p>命名空间镜像（FSImage）是文件系统的快照，包含所有文件、目录和属性信息，存储在本地磁盘上。系统启动时加载到内存，然后应用编辑日志（EditsLog）中的变更，以恢复到最新状态。编辑日志记录每次操作，如创建、删除、重命名等，顺序追加到文件中，用于恢复文件系统的变更历史。</p> 
</blockquote> 
<p><strong>DataNode</strong><br> DataNode是文件的实际存放位置。<br> DataNode会根据NameNode或Client的指令来存储或者提供数据块，并且定期的向NameNode汇报该DataNode存储的数据块信息。</p> 
<p><strong>SecondaryNameNode节点（Standby NameNode）：</strong></p> 
<p>并非NameNode的热备。当NameNode挂掉的时候，它并不 能马上替换NameNode并提供服务。</p> 
<blockquote> 
 <p>（在计算机系统中，热备Hot Standby是指在主要组件或设备发生故障时，系统能够迅速切换到备用组件或设备上，以继续提供服务。）</p> 
</blockquote> 
<p>1): 定期把NameNode的 fsimage 和 edits 下载到本地，再将它们加载到内存并进行合并，最后把合并后新的 fsimage 返回NameNode</p> 
<p>​ 2): 做备份</p> 
<p>​ 3): 防止edits过大</p> 
<p>​ 4): 在紧急情况下，可辅助恢复NameNode。</p> 
<p><span style="color:#4da8ee;"><strong>Blocks</strong></span></p> 
<p><strong>HDFS中的文件在物理上是分块存储（Block）</strong>，块的大小可以通过配置参数 ( dfs.blocksize）来规定，默认大小在Hadoop2.x/3.x版本中是128M，1.x版本中是64M。<br> HDFS将文件拆分成128 MB大小的数据块进行存储，这些Block可能存储在不同的节点上。HDFS可以存储更大的单个文件，甚至超过任何一个磁盘所能容纳的大小。一个Block默认存储3个副本（EMR Core节点如果使用云盘，则为2副本），以Block为粒度将副本存储在多个节点上。</p> 
<blockquote> 
 <p>为什么块的大小不能设置太小，也不能设置太大？</p> 
 <p>（1）HDFS的块设置太小，会增加寻址时间，程序一直在找块的开始位置； （2）如果块设置的太大，从磁盘传输数据的时间会明显大于定位这个块开 始位置所需的时间。导致程序在处理这块数据时，会非常慢。 总结：HDFS块的大小设置主要取决于磁盘传输速率。</p> 
</blockquote> 
<h3><span style="color:#fe2c24;">2.MapReduce  -离线计算</span></h3> 
<p>MapReduce 是一种编程模型，用于大规模数据集的并行处理。它由 Google 在 2004 年提出，并被广泛应用于大数据处理领域。MapReduce 的核心思想是将复杂的数据处理任务分解为两个主要的步骤：Map（映射）和 Reduce（归约），通过这两个步骤，可以在大量计算节点上分布式地处理和生成大数据集的结果。</p> 
<p>Map 阶段：</p> 
<p>在 Map 阶段，输入数据被分割成独立的块，这些块由 Map 函数处理。Map 函数对输入数据的每个块独立地执行操作，并将结果输出为一系列的键值对（key-value pairs）。这些键值对是中间结果，它们可以跨越网络传输到下一个阶段。</p> 
<p>Reduce 阶段</p> 
<p>Reduce 阶段跟随 Map 阶段，它接收来自 Map 阶段的中间结果。Reduce 函数对具有相同键（key）的值（value）进行合并操作，从而生成最终的输出。这个过程可以看作是对中间结果的一种归约（reduce），因此得名 Reduce。Reduce 阶段的输出是最终的处理结果，通常是按照键排序的。</p> 
<p>MapReduce 的优势</p> 
<ol><li><strong>可扩展性</strong>：MapReduce 模型可以轻松地扩展到处理 PB 级别的数据集。</li><li><strong>容错性</strong>：MapReduce 框架能够自动处理节点故障，重新调度任务，并确保数据处理的完整性。</li><li><strong>简化并行计算</strong>：开发者只需关注 Map 和 Reduce 函数的编写，而无需管理底层的并行计算和数据分布。</li><li><strong>灵活性</strong>：MapReduce 适用于各种类型的数据处理任务，包括但不限于计数、排序、索引等。</li></ol> 
<p>MapReduce 的应用</p> 
<p>MapReduce 模型最初是为处理搜索引擎的索引数据而设计的，但后来被广泛应用于各种大数据处理场景，如日志分析、基因组学研究、社交网络分析等。</p> 
<p>结论</p> 
<p>MapReduce 的思想是通过将大数据处理任务分解为简单的 Map 和 Reduce 操作，利用分布式计算资源并行处理数据，从而实现高效、可扩展和容错的数据处理能力。尽管 MapReduce 在某些情况下可能不如其他新兴的大数据处理框架（如 Apache Spark）灵活或高效，但它在大数据处理历史上仍然占有重要地位，并且为后续技术的发展奠定了基础。</p> 
<h3><span style="color:#fe2c24;">3.Yarn  - 资源调度</span></h3> 
<p>Yarn是一个资源调度平台，负责为运算程序提供服务器运算资源，相当于一个分布式的操作系统平台。</p> 
<p>通过 ResourceManager、NodeManager、应用程序主管RM和容器<strong>Container</strong>之间的协作，实现灵活高效的资源管理和任务调度。</p> 
<p><img alt="" height="409" src="https://images2.imgbox.com/df/45/Siy1uCk3_o.png" width="528"></p> 
<p><span style="color:#4da8ee;"><strong>Yarn组成</strong></span></p> 
<p><strong>ResourceManager（RM）资源管理器</strong></p> 
<p>ResourceManager 是整个 YARN 系统的主要组件，负责集群资源的管理和分配。它包含两个主要组件：调度器（Scheduler）和应用程序管理器（ApplicationManager）。</p> 
<ol><li>处理客户端请求；</li><li>监控NodeManager；</li><li>启动或监控ApplicationMaster；</li><li>资源的分配与调度</li></ol> 
<p><strong>NodeManager（NM）节点管理器</strong></p> 
<p>NodeManager 是运行在集群节点上的代理，负责管理单个节点上的资源。</p> 
<ol><li>管理单个节点上的资源；</li><li>接受来自ResouceManager的命令；</li><li>启动/停止容器（Container）</li><li>处理来自ApplicationMaster的命令。</li></ol> 
<p><strong>ApplicationMaster（AM）应用程序主管</strong></p> 
<p>每个在 YARN 上运行的应用程序都会有一个对应的 ApplicationMaster。它负责协调和管理应用程序的执行。一旦 ResourceManager 分配了资源，ApplicationMaster 就会与 NodeManager 通信，并向其请求启动容器来执行特定的任务。它还负责监控任务的执行进度、处理任务失败和重新启动任务等。</p> 
<ol><li>负责数据的切分；</li><li>为应用程序申请资源并分配给内部的任务；</li><li>任务的监控与容错。</li></ol> 
<p id="slide-5"><strong>Container容器</strong></p> 
<p>Container是yarn中的资源抽象，它封装了某个节点上的维度资源，如：内存、CPU、硬盘和网络等。每个容器由 NodeManager 在集群节点上启动和管理，它可以运行一个应用程序的特定任务或进程。</p> 
<p><span style="color:#4da8ee;"><strong>Yarn基本流程</strong></span></p> 
<ol><li><span style="color:#0d0016;">用户向YARN中提交应用程序，其中包括ApplicationMaster程序、启动ApplicationMaster的命令、用户程序</span></li><li><span style="color:#0d0016;">ResourceManager为该应用程序分配第一个Container，并与对应的Node-Manager通信，要求它在这个Container中启动应用程序的ApplicationMaster</span></li><li><span style="color:#0d0016;">ApplicationMaster首先向ResourceManager注册，这样用户可以直接通过ResourceManage查看应用程序的运行状态，然后它将为各个任务申请资源，并监控它的运行状态，直到运行结束，即重复步骤4~7</span></li><li><span style="color:#0d0016;">ApplicationMaster采用轮询的方式通过RPC协议向ResourceManager申请和领取资源</span></li><li><span style="color:#0d0016;">一旦ApplicationMaster申请到资源后，便与对应的NodeManager通信，要求它启动任务</span></li><li><span style="color:#0d0016;">NodeManager为任务设置好运行环境(包括环境变量、JAR包、二进制程序等)后，将任务启动命令写到一个脚本中，并通过运行该脚本启动任务</span></li><li><span style="color:#0d0016;">各个任务通过某个RPC协议向ApplicationMaster汇报自己的状态和进度，以让ApplicationMaster随时掌握各个任务的运行状态，从而可以在任务失败时重新启动任务。在应用程序运行过程中，用户可随时通过RPC向ApplicationMaster查询应用程序的当前运行状态</span></li><li><span style="color:#0d0016;">应用程序运行完成后，ApplicationMaster向ResourceManager注销并关闭自己</span></li></ol> 
<h2><span style="color:#0d0016;">二、Hive</span></h2> 
<p><span style="color:#0d0016;">参考：</span><a href="https://zhuanlan.zhihu.com/p/82746290" rel="nofollow" title="大数据之Hadoop的数据仓库Hive - 知乎 (zhihu.com)">大数据之Hadoop的数据仓库Hive - 知乎 (zhihu.com)</a><a href="https://blog.csdn.net/JunLeon/article/details/121606429" title="（超详细）大数据技术之Hive的实战_hive实战-CSDN博客">（超详细）大数据技术之Hive的实战_hive实战-CSDN博客</a></p> 
<p>Hive是基于Hadoop的<strong>数据仓库</strong>工具，由Facebook开发，在某种程度上可以看成是用户编程接口，本身并不存储和处理数据，依赖于HDFS存储数据，依赖MR处理数据，执行程序运行在Yarn上。有类SQL语言HiveQL，不完全支持SQL标准，如，不支持更新操作、索引和事务，其子查询和连接操作也存在很多限制。</p> 
<h3>1.Hive原理</h3> 
<p>Hive的运行原理是<u><strong>将查询转换为一系列MapReduce任务</strong></u>，在Hadoop集群上并行执行这些任务，并将结果返回给用户。这种并行处理的方式使得Hive能够高效地处理大规模的数据集。</p> 
<p><img alt="" height="342" src="https://images2.imgbox.com/99/9b/dRESrnRx_o.png" width="688"></p> 
<p>1. 元数据存储：Hive使用一个元数据存储来管理Hadoop文件系统中的数据。元数据存储包括表、分区、列和数据位置的信息。Hive使用这些元数据来解析和优化查询。</p> 
<p>2. 查询解析和优化：当用户提交一个查询时，Hive首先会解析查询语句，并根据元数据来确定查询涉及的表、列和分区。然后，Hive会对查询进行优化，以尽量减少查询的开销。优化过程包括选择合适的查询计划、重写查询和推测执行等。</p> 
<p>3. 查询执行：在查询执行阶段，Hive将查询转换为一系列Hadoop MapReduce任务。这些任务由Hive的查询执行引擎生成，并在Hadoop集群上运行。每个任务负责处理数据的一部分，并生成中间结果。</p> 
<p>4. 结果返回：一旦所有的MapReduce任务完成，Hive会收集和合并中间结果，并将最终结果返回给用户。如果查询需要将结果保存到Hadoop文件系统中，Hive还会将结果写入指定的目录。</p> 
<h3>2.Hive的应用场景</h3> 
<p>Hive构建在Hadoop文件系统之上，Hive不提供实时的查询和基于行级的数据更新操作，不适合需要低延迟的应用，如联机事务处理（On-line Transaction Processing，OLTP）相关应用。</p> 
<p>        Hive适用于联机分析处理（On-Line Analytical Processing，OLAP），应用场景如图所示：</p> 
<p><img alt="" height="171" src="https://images2.imgbox.com/91/b4/pbrocryI_o.png" width="730"></p> 
<p> Hive是用于查询分布式大型数据集的数据仓库，相比于传统数据仓库，在大数据的查询上有其独特的优势，但同时也牺牲了一部分性能。</p> 
<h4 id="4%E3%80%81Hive%E4%B8%8E%E4%BC%A0%E7%BB%9F%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E7%9A%84%E5%8C%BA%E5%88%AB">Hive与传统数据仓库的区别：</h4> 
<p><img alt="" height="531" src="https://images2.imgbox.com/e9/41/gOIeLtzm_o.png" width="805"></p> 
<h3>3.Hive结构</h3> 
<p><img alt="" height="499" src="https://images2.imgbox.com/96/da/PTIIabF6_o.png" width="650"></p> 
<p><strong>Hive主要由以下三个模块组成：</strong></p> 
<p>用户接口模块，含CLI、HWI、JDBC、Thrift Server等，用来实现对Hive的访问。CLI是Hive自带的命令行界面；HWI是Hive的一个简单网页界面；JDBC、ODBC以及Thrift Server可向用户提供进行编程的接口，其中Thrift Server是基于Thrift软件框架开发的，提供Hive的RPC通信接口。</p> 
<p>驱动模块（Driver），含编译器、优化器、执行器等，负责把HiveQL语句转换成一系列MR作业，所有命令和查询都会进入驱动模块，通过该模块的解析变异，对计算过程进行优化，然后按照指定的步骤执行。</p> 
<p>元数据存储模块（Metastore），是一个独立的关系型数据库，通常与MySQL数据库连接后创建的一个MySQL实例，也可以是Hive自带的Derby数据库实例。此模块主要保存表模式和其他系统元数据，如表的名称、表的列及其属性、表的分区及其属性、表的属性、表中数据所在位置信息等。</p> 
<h3>4.Hive的数据存储模型</h3> 
<p>Hive主要包括三类数据模型：表（Table）、分区（Partition）和桶（Bucket）。</p> 
<h4>1）Hive的分区和分桶</h4> 
<p>Hive以数据库表的形式组织数据，便于高效查询分析。针对大数据集，Hive会对数据进行分区处理，例如按日期、地区等列值进行分区。分区以目录形式存在，提高了局部数据查询的效率。此外，Hive还可以将表或分区进一步组织为桶，桶是比分区更细的数据划分方式，每个桶是一个文件。用户可指定桶的个数，Hive根据哈希值将数据划分到不同桶中。分桶提供了额外的结构，在处理某些查询时可以提高效率，例如join操作和表的合并，使数据抽样更加高效。</p> 
<h4>2）Hive的托管表和外部表</h4> 
<p>Hive中的表分为两种：托管表（内部表）和外部表。托管表由Hive管理数据，而外部表仅记录数据路径，不移动数据至仓库目录。删除托管表会同时删除元数据和数据，而删除外部表只会删除元数据，保留数据在仓库外部。</p> 
<p>选择使用哪种表取决于数据处理需求：托管表适用于完全由Hive处理的数据集，而外部表适用于需要与其他工具共享数据或组织成不同表的情况。</p> 
<h3>5.Hive在企业大数据分析平台中的应用</h3> 
<p>企业中一种常见的大数据分析平台部署框架：</p> 
<p><img alt="" height="249" src="https://images2.imgbox.com/4d/8e/yfTPECvA_o.png" width="357"></p> 
<p>Hive和Pig用于报表中心，Hive用于分析报表，Pig用于报表中数据的转换工作。</p> 
<p>HBase用于在线业务，HDFS不支持随机读写操作，而HBase正是为此开发，可较好地支持实时访问数据。</p> 
<p>Mahout提供一些可扩展的机器学习领域的经典算法实现，用于创建商务智能（BI）应用程序。</p> 
<h2><span style="color:#0d0016;">三、Hbase</span></h2> 
<p><span style="color:#0d0016;">参考：</span><a href="https://zhuanlan.zhihu.com/p/145551967" rel="nofollow" title="我终于看懂了HBase，太不容易了... - 知乎 (zhihu.com)">我终于看懂了HBase，太不容易了... - 知乎 (zhihu.com)</a></p> 
<p><img alt="" height="248" src="https://images2.imgbox.com/b0/3d/xWm7S6Kt_o.png" width="785"></p> 
<p>Apache HBase 是在HDFS的基础之上构建的 Hadoop 数据库，一个分布式、可伸缩的<strong>大数据存储</strong>。</p> 
<p>HDFS是文件系统，而HBase是数据库。「<strong>可以把HBase当做是MySQL，把HDFS当做是硬盘。HBase只是一个NoSQL数据库，把数据存在HDFS上</strong>」。</p> 
<blockquote> 
 <p>数据库是一个以某种<strong>有组织的方式存储的数据集合</strong>。</p> 
</blockquote> 
<h3>1.为什么要用Hbase？</h3> 
<p>HBase可以以<strong>低成本</strong>来<strong>存储海量</strong>的数据并且支持高并发随机写和实时查询。</p> 
<p><strong>存储数据的”结构“可以地非常灵活，</strong>是一个NoSQL数据库</p> 
<h3 style="background-color:transparent;"><strong>2.Hbase架构</strong></h3> 
<p><img alt="" height="363" src="https://images2.imgbox.com/24/d8/V1RNrOSn_o.png" width="724"></p> 
<p>1、<strong>Client</strong>客户端，它提供了访问HBase的接口，并且维护了对应的cache来加速HBase的访问。</p> 
<p>2、<strong>Zookeeper</strong>存储HBase的元数据（meta表），无论是读还是写数据，都是去Zookeeper里边拿到meta元数据<strong>告诉给客户端去哪台机器读写数据</strong></p> 
<p>3、<strong>HRegionServer</strong>它是处理客户端的读写请求，负责与HDFS底层交互，是真正干活的节点。</p> 
<p>总结大致的流程就是：client请求到Zookeeper，然后Zookeeper返回HRegionServer地址给client，client得到Zookeeper返回的地址去请求HRegionServer，HRegionServer读写数据后返回给client。</p> 
<p><img alt="" height="652" src="https://images2.imgbox.com/41/31/Pafmlebg_o.png" width="695"></p> 
<p><strong>HRegionServer</strong></p> 
<ul><li>HRegionServer是真正干活的机器（用于与hdfs交互），我们HBase表用RowKey来横向切分表</li><li>HRegion里边会有多个Store，每个Store其实就是一个列族的数据（所以我们可以说HBase是基于列族存储的）</li><li>Store里边有Men Store和StoreFile(HFile)，其实就是先走一层内存，然后再刷到磁盘的结构</li></ul> 
<p><strong>Store</strong></p> 
<p>•Store是Region服务器的核心</p> 
<p>•多个StoreFile合并成一个</p> 
<p>•单个StoreFile过大时，又触发分裂操作，1个父Region被分裂成两个子Region </p> 
<p><strong>HLog</strong></p> 
<p>Zookeeper实时监测Region服务器状态。</p> 
<p>一旦某服务器故障，Zookeeper通知Master。Master处理故障服务器上的遗留HLog文件，这些文件包含多个Region对象的日志。</p> 
<p>系统拆分HLog数据，按照Region对象归类，发送给相应服务器。服务器收到分配的Region对象和相关日志，重新操作日志，将数据写入MemStore缓存，再刷新到磁盘文件，完成数据恢复。</p> 
<p>共用日志提升写操作性能，但恢复时需分拆日志。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/dd7d81c9e95b5d4b509b9e275a80f0ce/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Python 大麦抢票脚本</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/7cb9c45b24e232a37a3e85b030c44105/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【C&#43;&#43;】unordered_map &amp; unordered_set 底层刨析</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>