<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【人工智能】Transformers之Pipeline（概述）：30w&#43;大模型极简应用 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/48843f9826eeebb89f9799e1e9015fee/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="【人工智能】Transformers之Pipeline（概述）：30w&#43;大模型极简应用">
  <meta property="og:description" content="​​​​​​​
目录
一、引言 二、pipeline库
2.1 概述
2.2 使用task实例化pipeline对象
2.2.1 基于task实例化“自动语音识别”
2.2.2 task列表
2.2.3 task默认模型
2.3 使用model实例化pipeline对象
2.3.1 基于model实例化“自动语音识别”
2.3.2 查看model与task的对应关系
三、总结
一、引言 pipeline（管道）是huggingface transformers库中一种极简方式使用大模型推理的抽象，将所有大模型分为语音（Audio）、计算机视觉（Computer vision）、自然语言处理（NLP）、多模态（Multimodal）等4大类，28小类任务（tasks）。共计覆盖32万个模型
本文对pipeline进行整体介绍，之后本专栏以每个task为主题，分别介绍各种task使用方法。
二、pipeline库 2.1 概述 管道是一种使用模型进行推理的简单而好用的方法。这些管道是从库中抽象出大部分复杂代码的对象，提供了专用于多项任务的简单 API，包括命名实体识别、掩码语言建模、情感分析、特征提取和问答。在使用上，主要有2种方法
使用task实例化pipeline对象使用model实例化pipeline对象 2.2 使用task实例化pipeline对象 2.2.1 基于task实例化“自动语音识别” 自动语音识别的task为automatic-speech-recognition：
import os os.environ[&#34;HF_ENDPOINT&#34;] = &#34;https://hf-mirror.com&#34; os.environ[&#34;CUDA_VISIBLE_DEVICES&#34;] = &#34;2&#34; from transformers import pipeline speech_file = &#34;./output_video_enhanced.mp3&#34; pipe = pipeline(task=&#34;automatic-speech-recognition&#34;) result = pipe(speech_file) print(result) 2.2.2 task列表 task共计28类，按首字母排序，列表如下，直接替换2.2.1代码中的pipeline的task即可应用：
&#34;audio-classification&#34;：将返回一个AudioClassificationPipeline。&#34;automatic-speech-recognition&#34;：将返回一个AutomaticSpeechRecognitionPipeline。&#34;depth-estimation&#34;：将返回一个DepthEstimationPipeline。&#34;document-question-answering&#34;：将返回一个DocumentQuestionAnsweringPipeline。&#34;feature-extraction&#34;：将返回一个FeatureExtractionPipeline。&#34;fill-mask&#34;：将返回一个FillMaskPipeline：。&#34;image-classification&#34;：将返回一个ImageClassificationPipeline。&#34;image-feature-extraction&#34;：将返回一个ImageFeatureExtractionPipeline。&#34;image-segmentation&#34;：将返回一个ImageSegmentationPipeline。&#34;image-to-image&#34;：将返回一个ImageToImagePipeline。&#34;image-to-text&#34;：将返回一个ImageToTextPipeline。&#34;mask-generation&#34;：将返回一个MaskGenerationPipeline。&#34;object-detection&#34;：将返回一个ObjectDetectionPipeline。&#34;question-answering&#34;：将返回一个QuestionAnsweringPipeline。&#34;summarization&#34;：将返回一个SummarizationPipeline。&#34;table-question-answering&#34;：将返回一个TableQuestionAnsweringPipeline。&#34;text2text-generation&#34;：将返回一个Text2TextGenerationPipeline。&#34;text-classification&#34;(&#34;sentiment-analysis&#34;可用别名)：将返回一个 TextClassificationPipeline。&#34;text-generation&#34;：将返回一个TextGenerationPipeline：。&#34;text-to-audio&#34;（&#34;text-to-speech&#34;可用别名）：将返回一个TextToAudioPipeline：。&#34;token-classification&#34;(&#34;ner&#34;可用别名)：将返回一个TokenClassificationPipeline。&#34;translation&#34;：将返回一个TranslationPipeline。&#34;translation_xx_to_yy&#34;：将返回一个TranslationPipeline。&#34;video-classification&#34;：将返回一个VideoClassificationPipeline。&#34;visual-question-answering&#34;：将返回一个VisualQuestionAnsweringPipeline。&#34;zero-shot-classification&#34;：将返回一个ZeroShotClassificationPipeline。&#34;zero-shot-image-classification&#34;：将返回一个ZeroShotImageClassificationPipeline。&#34;zero-shot-audio-classification&#34;：将返回一个ZeroShotAudioClassificationPipeline。&#34;zero-shot-object-detection&#34;：将返回一个ZeroShotObjectDetectionPipeline。 2.2.3 task默认模型 针对每一个task，pipeline默认配置了模型，可以通过pipeline源代码查看：
SUPPORTED_TASKS = { &#34;">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-07-10T21:33:17+08:00">
    <meta property="article:modified_time" content="2024-07-10T21:33:17+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【人工智能】Transformers之Pipeline（概述）：30w&#43;大模型极简应用</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h3><a id="_0"></a></h3> 
<p id="%C2%A0%E2%80%8B%E7%BC%96%E8%BE%91">​​​​​​​<img alt="" height="402" src="https://images2.imgbox.com/8b/2c/ujFBZ5XY_o.png" width="1200"></p> 
<p id="main-toc"><strong>目录</strong></p> 
<p id="-toc" style="margin-left:40px;"></p> 
<p id="%E4%B8%80%E3%80%81%E5%BC%95%E8%A8%80%C2%A0-toc" style="margin-left:0px;"><a href="#%E4%B8%80%E3%80%81%E5%BC%95%E8%A8%80%C2%A0" rel="nofollow">一、引言 </a></p> 
<p id="%E4%BA%8C%E3%80%81Tokenizer-toc" style="margin-left:0px;"><a href="#%E4%BA%8C%E3%80%81Tokenizer" rel="nofollow">二、pipeline库</a></p> 
<p id="2.1%20%E6%A6%82%E8%BF%B0-toc" style="margin-left:40px;"><a href="#2.1%20%E6%A6%82%E8%BF%B0" rel="nofollow">2.1 概述</a></p> 
<p id="2.2%20%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95-toc" style="margin-left:40px;"><a href="#2.2%20%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95" rel="nofollow">2.2 使用task实例化pipeline对象</a></p> 
<p id="2.2.1%C2%A0%E5%AE%89%E8%A3%85timm%E5%BA%93-toc" style="margin-left:80px;"><a href="#2.2.1%C2%A0%E5%AE%89%E8%A3%85timm%E5%BA%93" rel="nofollow">2.2.1 基于task实例化“自动语音识别”</a></p> 
<p id="2.2.2%20%E5%AF%BC%E5%85%A5%E5%BF%85%E8%A6%81%E7%9A%84%E5%BA%93-toc" style="margin-left:80px;"><a href="#2.2.2%20%E5%AF%BC%E5%85%A5%E5%BF%85%E8%A6%81%E7%9A%84%E5%BA%93" rel="nofollow">2.2.2 task列表</a></p> 
<p id="2.2.3%C2%A0task%E9%BB%98%E8%AE%A4%E6%A8%A1%E5%9E%8B-toc" style="margin-left:80px;"><a href="#2.2.3%C2%A0task%E9%BB%98%E8%AE%A4%E6%A8%A1%E5%9E%8B" rel="nofollow">2.2.3 task默认模型</a></p> 
<p id="2.3%C2%A0%E4%BD%BF%E7%94%A8model%E5%AE%9E%E4%BE%8B%E5%8C%96pipeline%E5%AF%B9%E8%B1%A1-toc" style="margin-left:40px;"><a href="#2.3%C2%A0%E4%BD%BF%E7%94%A8model%E5%AE%9E%E4%BE%8B%E5%8C%96pipeline%E5%AF%B9%E8%B1%A1" rel="nofollow">2.3 使用model实例化pipeline对象</a></p> 
<p id="2.3.1%20%E5%9F%BA%E4%BA%8Emodel%E5%AE%9E%E4%BE%8B%E5%8C%96%E2%80%9C%E8%87%AA%E5%8A%A8%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E2%80%9D-toc" style="margin-left:80px;"><a href="#2.3.1%20%E5%9F%BA%E4%BA%8Emodel%E5%AE%9E%E4%BE%8B%E5%8C%96%E2%80%9C%E8%87%AA%E5%8A%A8%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E2%80%9D" rel="nofollow">2.3.1 基于model实例化“自动语音识别”</a></p> 
<p id="%C2%A02.3.2%20%E6%9F%A5%E7%9C%8Bmodel%E4%B8%8Etask%E7%9A%84%E5%AF%B9%E5%BA%94%E5%85%B3%E7%B3%BB-toc" style="margin-left:80px;"><a href="#%C2%A02.3.2%20%E6%9F%A5%E7%9C%8Bmodel%E4%B8%8Etask%E7%9A%84%E5%AF%B9%E5%BA%94%E5%85%B3%E7%B3%BB" rel="nofollow"> 2.3.2 查看model与task的对应关系</a></p> 
<p id="2.2.4%C2%A0%E9%80%89%E6%8B%A9%E6%A8%A1%E5%9E%8B-toc" style="margin-left:0px;"><a href="#2.2.4%C2%A0%E9%80%89%E6%8B%A9%E6%A8%A1%E5%9E%8B" rel="nofollow">三、总结</a></p> 
<hr id="hr-toc"> 
<p></p> 
<h2 id="%E4%B8%80%E3%80%81%E5%BC%95%E8%A8%80%C2%A0">一、引言 </h2> 
<p> pipeline（管道）是huggingface transformers库中一种极简方式使用大模型推理的抽象，将所有大模型分为语音（Audio）、计算机视觉（Computer vision）、自然语言处理（NLP）、多模态（Multimodal）等4大类，28小类任务（tasks）。共计覆盖32万个模型</p> 
<p><img alt="" height="1200" src="https://images2.imgbox.com/e5/0a/2INcdaBh_o.jpg" width="1065"></p> 
<p>本文对pipeline进行整体介绍，之后本专栏以每个task为主题，分别介绍各种task使用方法。</p> 
<h2 id="%E4%BA%8C%E3%80%81Tokenizer">二、pipeline库</h2> 
<h3 id="2.1%20%E6%A6%82%E8%BF%B0">2.1 概述</h3> 
<p><code>管道是一种使用模型进行推理的简单而好用的方法。这些管道是从库中抽象出大部分复杂代码的对象，提供了专用于多项任务的简单 API，包括命名实体识别、掩码语言建模、情感分析、特征提取和问答</code>。在使用上，主要有2种方法</p> 
<blockquote> 
 <ul><li>使用task实例化pipeline对象</li><li>使用model实例化pipeline对象</li></ul> 
</blockquote> 
<h3 id="2.2%20%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95">2.2 使用task实例化pipeline对象</h3> 
<h4 id="2.2.1%C2%A0%E5%AE%89%E8%A3%85timm%E5%BA%93">2.2.1 基于task实例化“自动语音识别”</h4> 
<p>自动语音识别的task为automatic-speech-recognition：</p> 
<pre><code class="language-python">import os
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
os.environ["CUDA_VISIBLE_DEVICES"] = "2"

from transformers import pipeline

speech_file = "./output_video_enhanced.mp3"
pipe = pipeline(task="automatic-speech-recognition")
result = pipe(speech_file)
print(result)</code></pre> 
<h4 id="2.2.2%20%E5%AF%BC%E5%85%A5%E5%BF%85%E8%A6%81%E7%9A%84%E5%BA%93">2.2.2 task列表</h4> 
<p>task共计28类，按首字母排序，列表如下，直接替换2.2.1代码中的pipeline的task即可应用：</p> 
<blockquote> 
 <ul style="margin-left:0;"><li><code>"audio-classification"</code>：将返回一个<a href="https://huggingface.co/docs/transformers/v4.42.0/en/main_classes/pipelines#transformers.AudioClassificationPipeline" rel="nofollow" title="AudioClassificationPipeline">AudioClassificationPipeline</a>。</li><li><code>"automatic-speech-recognition"</code>：将返回一个<a href="https://huggingface.co/docs/transformers/v4.42.0/en/main_classes/pipelines#transformers.AutomaticSpeechRecognitionPipeline" rel="nofollow" title="AutomaticSpeechRecognitionPipeline">AutomaticSpeechRecognitionPipeline</a>。</li><li><code>"depth-estimation"</code>：将返回一个<a href="https://huggingface.co/docs/transformers/v4.42.0/en/main_classes/pipelines#transformers.DepthEstimationPipeline" rel="nofollow" title="DepthEstimationPipeline">DepthEstimationPipeline</a>。</li><li><code>"document-question-answering"</code>：将返回一个<a href="https://huggingface.co/docs/transformers/v4.42.0/en/main_classes/pipelines#transformers.DocumentQuestionAnsweringPipeline" rel="nofollow" title="DocumentQuestionAnsweringPipeline">DocumentQuestionAnsweringPipeline</a>。</li><li><code>"feature-extraction"</code>：将返回一个<a href="https://huggingface.co/docs/transformers/v4.42.0/en/main_classes/pipelines#transformers.FeatureExtractionPipeline" rel="nofollow" title="FeatureExtractionPipeline">FeatureExtractionPipeline</a>。</li><li><code>"fill-mask"</code>：将返回一个<a href="https://huggingface.co/docs/transformers/v4.42.0/en/main_classes/pipelines#transformers.FillMaskPipeline" rel="nofollow" title="FillMaskPipeline">FillMaskPipeline</a>：。</li><li><code>"image-classification"</code>：将返回一个<a href="https://huggingface.co/docs/transformers/v4.42.0/en/main_classes/pipelines#transformers.ImageClassificationPipeline" rel="nofollow" title="ImageClassificationPipeline">ImageClassificationPipeline</a>。</li><li><code>"image-feature-extraction"</code>：将返回一个<a href="https://huggingface.co/docs/transformers/v4.42.0/en/main_classes/pipelines#transformers.ImageFeatureExtractionPipeline" rel="nofollow" title="ImageFeatureExtractionPipeline">ImageFeatureExtractionPipeline</a>。</li><li><code>"image-segmentation"</code>：将返回一个<a href="https://huggingface.co/docs/transformers/v4.42.0/en/main_classes/pipelines#transformers.ImageSegmentationPipeline" rel="nofollow" title="ImageSegmentationPipeline">ImageSegmentationPipeline</a>。</li><li><code>"image-to-image"</code>：将返回一个<a href="https://huggingface.co/docs/transformers/v4.42.0/en/main_classes/pipelines#transformers.ImageToImagePipeline" rel="nofollow" title="ImageToImagePipeline">ImageToImagePipeline</a>。</li><li><code>"image-to-text"</code>：将返回一个<a href="https://huggingface.co/docs/transformers/v4.42.0/en/main_classes/pipelines#transformers.ImageToTextPipeline" rel="nofollow" title="ImageToTextPipeline">ImageToTextPipeline</a>。</li><li><code>"mask-generation"</code>：将返回一个<a href="https://huggingface.co/docs/transformers/v4.42.0/en/main_classes/pipelines#transformers.MaskGenerationPipeline" rel="nofollow" title="MaskGenerationPipeline">MaskGenerationPipeline</a>。</li><li><code>"object-detection"</code>：将返回一个<a href="https://huggingface.co/docs/transformers/v4.42.0/en/main_classes/pipelines#transformers.ObjectDetectionPipeline" rel="nofollow" title="ObjectDetectionPipeline">ObjectDetectionPipeline</a>。</li><li><code>"question-answering"</code>：将返回一个<a href="https://huggingface.co/docs/transformers/v4.42.0/en/main_classes/pipelines#transformers.QuestionAnsweringPipeline" rel="nofollow" title="QuestionAnsweringPipeline">QuestionAnsweringPipeline</a>。</li><li><code>"summarization"</code>：将返回一个<a href="https://huggingface.co/docs/transformers/v4.42.0/en/main_classes/pipelines#transformers.SummarizationPipeline" rel="nofollow" title="SummarizationPipeline">SummarizationPipeline</a>。</li><li><code>"table-question-answering"</code>：将返回一个<a href="https://huggingface.co/docs/transformers/v4.42.0/en/main_classes/pipelines#transformers.TableQuestionAnsweringPipeline" rel="nofollow" title="TableQuestionAnsweringPipeline">TableQuestionAnsweringPipeline</a>。</li><li><code>"text2text-generation"</code>：将返回一个<a href="https://huggingface.co/docs/transformers/v4.42.0/en/main_classes/pipelines#transformers.Text2TextGenerationPipeline" rel="nofollow" title="Text2TextGenerationPipeline">Text2TextGenerationPipeline</a>。</li><li><code>"text-classification"</code>(<code>"sentiment-analysis"</code>可用别名)：将返回一个 <a href="https://huggingface.co/docs/transformers/v4.42.0/en/main_classes/pipelines#transformers.TextClassificationPipeline" rel="nofollow" title="TextClassificationPipeline">TextClassificationPipeline</a>。</li><li><code>"text-generation"</code>：将返回一个<a href="https://huggingface.co/docs/transformers/v4.42.0/en/main_classes/pipelines#transformers.TextGenerationPipeline" rel="nofollow" title="TextGenerationPipeline">TextGenerationPipeline</a>：。</li><li><code>"text-to-audio"</code>（<code>"text-to-speech"</code>可用别名）：将返回一个<a href="https://huggingface.co/docs/transformers/v4.42.0/en/main_classes/pipelines#transformers.TextToAudioPipeline" rel="nofollow" title="TextToAudioPipeline">TextToAudioPipeline</a>：。</li><li><code>"token-classification"</code>(<code>"ner"</code>可用别名)：将返回一个<a href="https://huggingface.co/docs/transformers/v4.42.0/en/main_classes/pipelines#transformers.TokenClassificationPipeline" rel="nofollow" title="TokenClassificationPipeline">TokenClassificationPipeline</a>。</li><li><code>"translation"</code>：将返回一个<a href="https://huggingface.co/docs/transformers/v4.42.0/en/main_classes/pipelines#transformers.TranslationPipeline" rel="nofollow" title="TranslationPipeline">TranslationPipeline</a>。</li><li><code>"translation_xx_to_yy"</code>：将返回一个<a href="https://huggingface.co/docs/transformers/v4.42.0/en/main_classes/pipelines#transformers.TranslationPipeline" rel="nofollow" title="TranslationPipeline">TranslationPipeline</a>。</li><li><code>"video-classification"</code>：将返回一个<a href="https://huggingface.co/docs/transformers/v4.42.0/en/main_classes/pipelines#transformers.VideoClassificationPipeline" rel="nofollow" title="VideoClassificationPipeline">VideoClassificationPipeline</a>。</li><li><code>"visual-question-answering"</code>：将返回一个<a href="https://huggingface.co/docs/transformers/v4.42.0/en/main_classes/pipelines#transformers.VisualQuestionAnsweringPipeline" rel="nofollow" title="VisualQuestionAnsweringPipeline">VisualQuestionAnsweringPipeline</a>。</li><li><code>"zero-shot-classification"</code>：将返回一个<a href="https://huggingface.co/docs/transformers/v4.42.0/en/main_classes/pipelines#transformers.ZeroShotClassificationPipeline" rel="nofollow" title="ZeroShotClassificationPipeline">ZeroShotClassificationPipeline</a>。</li><li><code>"zero-shot-image-classification"</code>：将返回一个<a href="https://huggingface.co/docs/transformers/v4.42.0/en/main_classes/pipelines#transformers.ZeroShotImageClassificationPipeline" rel="nofollow" title="ZeroShotImageClassificationPipeline">ZeroShotImageClassificationPipeline</a>。</li><li><code>"zero-shot-audio-classification"</code>：将返回一个<a href="https://huggingface.co/docs/transformers/v4.42.0/en/main_classes/pipelines#transformers.ZeroShotAudioClassificationPipeline" rel="nofollow" title="ZeroShotAudioClassificationPipeline">ZeroShotAudioClassificationPipeline</a>。</li><li><code>"zero-shot-object-detection"</code>：将返回一个<a href="https://huggingface.co/docs/transformers/v4.42.0/en/main_classes/pipelines#transformers.ZeroShotObjectDetectionPipeline" rel="nofollow" title="ZeroShotObjectDetectionPipeline">ZeroShotObjectDetectionPipeline</a>。</li></ul> 
</blockquote> 
<h4 id="2.2.3%C2%A0task%E9%BB%98%E8%AE%A4%E6%A8%A1%E5%9E%8B">2.2.3 task默认模型</h4> 
<p>针对每一个task，pipeline默认配置了模型，可以通过pipeline源代码查看：</p> 
<pre><code class="language-python">SUPPORTED_TASKS = {
    "audio-classification": {
        "impl": AudioClassificationPipeline,
        "tf": (),
        "pt": (AutoModelForAudioClassification,) if is_torch_available() else (),
        "default": {"model": {"pt": ("superb/wav2vec2-base-superb-ks", "372e048")}},
        "type": "audio",
    },
    "automatic-speech-recognition": {
        "impl": AutomaticSpeechRecognitionPipeline,
        "tf": (),
        "pt": (AutoModelForCTC, AutoModelForSpeechSeq2Seq) if is_torch_available() else (),
        "default": {"model": {"pt": ("facebook/wav2vec2-base-960h", "55bb623")}},
        "type": "multimodal",
    },
    "text-to-audio": {
        "impl": TextToAudioPipeline,
        "tf": (),
        "pt": (AutoModelForTextToWaveform, AutoModelForTextToSpectrogram) if is_torch_available() else (),
        "default": {"model": {"pt": ("suno/bark-small", "645cfba")}},
        "type": "text",
    },
    "feature-extraction": {
        "impl": FeatureExtractionPipeline,
        "tf": (TFAutoModel,) if is_tf_available() else (),
        "pt": (AutoModel,) if is_torch_available() else (),
        "default": {
            "model": {
                "pt": ("distilbert/distilbert-base-cased", "935ac13"),
                "tf": ("distilbert/distilbert-base-cased", "935ac13"),
            }
        },
        "type": "multimodal",
    },
    "text-classification": {
        "impl": TextClassificationPipeline,
        "tf": (TFAutoModelForSequenceClassification,) if is_tf_available() else (),
        "pt": (AutoModelForSequenceClassification,) if is_torch_available() else (),
        "default": {
            "model": {
                "pt": ("distilbert/distilbert-base-uncased-finetuned-sst-2-english", "af0f99b"),
                "tf": ("distilbert/distilbert-base-uncased-finetuned-sst-2-english", "af0f99b"),
            },
        },
        "type": "text",
    },
    "token-classification": {
        "impl": TokenClassificationPipeline,
        "tf": (TFAutoModelForTokenClassification,) if is_tf_available() else (),
        "pt": (AutoModelForTokenClassification,) if is_torch_available() else (),
        "default": {
            "model": {
                "pt": ("dbmdz/bert-large-cased-finetuned-conll03-english", "f2482bf"),
                "tf": ("dbmdz/bert-large-cased-finetuned-conll03-english", "f2482bf"),
            },
        },
        "type": "text",
    },
    "question-answering": {
        "impl": QuestionAnsweringPipeline,
        "tf": (TFAutoModelForQuestionAnswering,) if is_tf_available() else (),
        "pt": (AutoModelForQuestionAnswering,) if is_torch_available() else (),
        "default": {
            "model": {
                "pt": ("distilbert/distilbert-base-cased-distilled-squad", "626af31"),
                "tf": ("distilbert/distilbert-base-cased-distilled-squad", "626af31"),
            },
        },
        "type": "text",
    },
    "table-question-answering": {
        "impl": TableQuestionAnsweringPipeline,
        "pt": (AutoModelForTableQuestionAnswering,) if is_torch_available() else (),
        "tf": (TFAutoModelForTableQuestionAnswering,) if is_tf_available() else (),
        "default": {
            "model": {
                "pt": ("google/tapas-base-finetuned-wtq", "69ceee2"),
                "tf": ("google/tapas-base-finetuned-wtq", "69ceee2"),
            },
        },
        "type": "text",
    },
    "visual-question-answering": {
        "impl": VisualQuestionAnsweringPipeline,
        "pt": (AutoModelForVisualQuestionAnswering,) if is_torch_available() else (),
        "tf": (),
        "default": {
            "model": {"pt": ("dandelin/vilt-b32-finetuned-vqa", "4355f59")},
        },
        "type": "multimodal",
    },
    "document-question-answering": {
        "impl": DocumentQuestionAnsweringPipeline,
        "pt": (AutoModelForDocumentQuestionAnswering,) if is_torch_available() else (),
        "tf": (),
        "default": {
            "model": {"pt": ("impira/layoutlm-document-qa", "52e01b3")},
        },
        "type": "multimodal",
    },
    "fill-mask": {
        "impl": FillMaskPipeline,
        "tf": (TFAutoModelForMaskedLM,) if is_tf_available() else (),
        "pt": (AutoModelForMaskedLM,) if is_torch_available() else (),
        "default": {
            "model": {
                "pt": ("distilbert/distilroberta-base", "ec58a5b"),
                "tf": ("distilbert/distilroberta-base", "ec58a5b"),
            }
        },
        "type": "text",
    },
    "summarization": {
        "impl": SummarizationPipeline,
        "tf": (TFAutoModelForSeq2SeqLM,) if is_tf_available() else (),
        "pt": (AutoModelForSeq2SeqLM,) if is_torch_available() else (),
        "default": {
            "model": {"pt": ("sshleifer/distilbart-cnn-12-6", "a4f8f3e"), "tf": ("google-t5/t5-small", "d769bba")}
        },
        "type": "text",
    },
    # This task is a special case as it's parametrized by SRC, TGT languages.
    "translation": {
        "impl": TranslationPipeline,
        "tf": (TFAutoModelForSeq2SeqLM,) if is_tf_available() else (),
        "pt": (AutoModelForSeq2SeqLM,) if is_torch_available() else (),
        "default": {
            ("en", "fr"): {"model": {"pt": ("google-t5/t5-base", "686f1db"), "tf": ("google-t5/t5-base", "686f1db")}},
            ("en", "de"): {"model": {"pt": ("google-t5/t5-base", "686f1db"), "tf": ("google-t5/t5-base", "686f1db")}},
            ("en", "ro"): {"model": {"pt": ("google-t5/t5-base", "686f1db"), "tf": ("google-t5/t5-base", "686f1db")}},
        },
        "type": "text",
    },
    "text2text-generation": {
        "impl": Text2TextGenerationPipeline,
        "tf": (TFAutoModelForSeq2SeqLM,) if is_tf_available() else (),
        "pt": (AutoModelForSeq2SeqLM,) if is_torch_available() else (),
        "default": {"model": {"pt": ("google-t5/t5-base", "686f1db"), "tf": ("google-t5/t5-base", "686f1db")}},
        "type": "text",
    },
    "text-generation": {
        "impl": TextGenerationPipeline,
        "tf": (TFAutoModelForCausalLM,) if is_tf_available() else (),
        "pt": (AutoModelForCausalLM,) if is_torch_available() else (),
        "default": {"model": {"pt": ("openai-community/gpt2", "6c0e608"), "tf": ("openai-community/gpt2", "6c0e608")}},
        "type": "text",
    },
    "zero-shot-classification": {
        "impl": ZeroShotClassificationPipeline,
        "tf": (TFAutoModelForSequenceClassification,) if is_tf_available() else (),
        "pt": (AutoModelForSequenceClassification,) if is_torch_available() else (),
        "default": {
            "model": {
                "pt": ("facebook/bart-large-mnli", "c626438"),
                "tf": ("FacebookAI/roberta-large-mnli", "130fb28"),
            },
            "config": {
                "pt": ("facebook/bart-large-mnli", "c626438"),
                "tf": ("FacebookAI/roberta-large-mnli", "130fb28"),
            },
        },
        "type": "text",
    },
    "zero-shot-image-classification": {
        "impl": ZeroShotImageClassificationPipeline,
        "tf": (TFAutoModelForZeroShotImageClassification,) if is_tf_available() else (),
        "pt": (AutoModelForZeroShotImageClassification,) if is_torch_available() else (),
        "default": {
            "model": {
                "pt": ("openai/clip-vit-base-patch32", "f4881ba"),
                "tf": ("openai/clip-vit-base-patch32", "f4881ba"),
            }
        },
        "type": "multimodal",
    },
    "zero-shot-audio-classification": {
        "impl": ZeroShotAudioClassificationPipeline,
        "tf": (),
        "pt": (AutoModel,) if is_torch_available() else (),
        "default": {
            "model": {
                "pt": ("laion/clap-htsat-fused", "973b6e5"),
            }
        },
        "type": "multimodal",
    },
    "image-classification": {
        "impl": ImageClassificationPipeline,
        "tf": (TFAutoModelForImageClassification,) if is_tf_available() else (),
        "pt": (AutoModelForImageClassification,) if is_torch_available() else (),
        "default": {
            "model": {
                "pt": ("google/vit-base-patch16-224", "5dca96d"),
                "tf": ("google/vit-base-patch16-224", "5dca96d"),
            }
        },
        "type": "image",
    },
    "image-feature-extraction": {
        "impl": ImageFeatureExtractionPipeline,
        "tf": (TFAutoModel,) if is_tf_available() else (),
        "pt": (AutoModel,) if is_torch_available() else (),
        "default": {
            "model": {
                "pt": ("google/vit-base-patch16-224", "3f49326"),
                "tf": ("google/vit-base-patch16-224", "3f49326"),
            }
        },
        "type": "image",
    },
    "image-segmentation": {
        "impl": ImageSegmentationPipeline,
        "tf": (),
        "pt": (AutoModelForImageSegmentation, AutoModelForSemanticSegmentation) if is_torch_available() else (),
        "default": {"model": {"pt": ("facebook/detr-resnet-50-panoptic", "fc15262")}},
        "type": "multimodal",
    },
    "image-to-text": {
        "impl": ImageToTextPipeline,
        "tf": (TFAutoModelForVision2Seq,) if is_tf_available() else (),
        "pt": (AutoModelForVision2Seq,) if is_torch_available() else (),
        "default": {
            "model": {
                "pt": ("ydshieh/vit-gpt2-coco-en", "65636df"),
                "tf": ("ydshieh/vit-gpt2-coco-en", "65636df"),
            }
        },
        "type": "multimodal",
    },
    "object-detection": {
        "impl": ObjectDetectionPipeline,
        "tf": (),
        "pt": (AutoModelForObjectDetection,) if is_torch_available() else (),
        "default": {"model": {"pt": ("facebook/detr-resnet-50", "2729413")}},
        "type": "multimodal",
    },
    "zero-shot-object-detection": {
        "impl": ZeroShotObjectDetectionPipeline,
        "tf": (),
        "pt": (AutoModelForZeroShotObjectDetection,) if is_torch_available() else (),
        "default": {"model": {"pt": ("google/owlvit-base-patch32", "17740e1")}},
        "type": "multimodal",
    },
    "depth-estimation": {
        "impl": DepthEstimationPipeline,
        "tf": (),
        "pt": (AutoModelForDepthEstimation,) if is_torch_available() else (),
        "default": {"model": {"pt": ("Intel/dpt-large", "e93beec")}},
        "type": "image",
    },
    "video-classification": {
        "impl": VideoClassificationPipeline,
        "tf": (),
        "pt": (AutoModelForVideoClassification,) if is_torch_available() else (),
        "default": {"model": {"pt": ("MCG-NJU/videomae-base-finetuned-kinetics", "4800870")}},
        "type": "video",
    },
    "mask-generation": {
        "impl": MaskGenerationPipeline,
        "tf": (),
        "pt": (AutoModelForMaskGeneration,) if is_torch_available() else (),
        "default": {"model": {"pt": ("facebook/sam-vit-huge", "997b15")}},
        "type": "multimodal",
    },
    "image-to-image": {
        "impl": ImageToImagePipeline,
        "tf": (),
        "pt": (AutoModelForImageToImage,) if is_torch_available() else (),
        "default": {"model": {"pt": ("caidas/swin2SR-classical-sr-x2-64", "4aaedcb")}},
        "type": "image",
    },
}</code></pre> 
<h3 id="2.3%C2%A0%E4%BD%BF%E7%94%A8model%E5%AE%9E%E4%BE%8B%E5%8C%96pipeline%E5%AF%B9%E8%B1%A1">2.3 使用model实例化pipeline对象</h3> 
<h4 id="2.3.1%20%E5%9F%BA%E4%BA%8Emodel%E5%AE%9E%E4%BE%8B%E5%8C%96%E2%80%9C%E8%87%AA%E5%8A%A8%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E2%80%9D">2.3.1 基于model实例化“自动语音识别”</h4> 
<p>如果不想使用task中默认的模型，可以指定huggingface中的模型：</p> 
<pre><code class="language-python">import os
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
os.environ["CUDA_VISIBLE_DEVICES"] = "2"

from transformers import pipeline

speech_file = "./output_video_enhanced.mp3"
#transcriber = pipeline(task="automatic-speech-recognition", model="openai/whisper-medium")
pipe = pipeline(model="openai/whisper-medium")
result = pipe(speech_file)
print(result)</code></pre> 
<h4 id="%C2%A02.3.2%20%E6%9F%A5%E7%9C%8Bmodel%E4%B8%8Etask%E7%9A%84%E5%AF%B9%E5%BA%94%E5%85%B3%E7%B3%BB"> 2.3.2 查看model与task的对应关系</h4> 
<p>可以登录<a href="https://huggingface.co/tasks" rel="nofollow" title="https://huggingface.co/tasks">https://huggingface.co/tasks</a>查看</p> 
<p><img alt="" height="1155" src="https://images2.imgbox.com/bb/c3/48HsRIhp_o.png" width="1200"></p> 
<h2 id="2.2.4%C2%A0%E9%80%89%E6%8B%A9%E6%A8%A1%E5%9E%8B"><strong>三、总结</strong></h2> 
<p>本文为transformers之pipeline专栏的第0篇，后面会以每个task为一篇，共计讲述28+个tasks的用法，通过28个tasks的pipeline使用学习，可以掌握语音、计算机视觉、自然语言处理、多模态乃至强化学习等30w+个huggingface上的开源大模型。让你成为大模型领域的专家！</p> 
<p></p> 
<p>期待您的3连+关注，如何还有时间，欢迎阅读我的其他文章：</p> 
<p>《AI—工程篇》</p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/138583814?spm=1001.2014.3001.5501" title="AI智能体研发之路-工程篇（一）：Docker助力AI智能体开发提效">AI智能体研发之路-工程篇（一）：Docker助力AI智能体开发提效</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/138543709?spm=1001.2014.3001.5501" title="AI智能体研发之路-工程篇（二）：Dify智能体开发平台一键部署">AI智能体研发之路-工程篇（二）：Dify智能体开发平台一键部署</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/138506272?spm=1001.2014.3001.5501" title="AI智能体研发之路-工程篇（三）：大模型推理服务框架Ollama一键部署">AI智能体研发之路-工程篇（三）：大模型推理服务框架Ollama一键部署</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/138531565?spm=1001.2014.3001.5501" title="AI智能体研发之路-工程篇（四）：大模型推理服务框架Xinference一键部署">AI智能体研发之路-工程篇（四）：大模型推理服务框架Xinference一键部署</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/138673899?spm=1001.2014.3001.5501" title="AI智能体研发之路-工程篇（五）：大模型推理服务框架LocalAI一键部署">AI智能体研发之路-工程篇（五）：大模型推理服务框架LocalAI一键部署</a></p> 
<p>《AI—模型篇》</p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/138819599?spm=1001.2014.3001.5501" title="AI智能体研发之路-模型篇（一）：大模型训练框架LLaMA-Factory在国内网络环境下的安装、部署及使用">AI智能体研发之路-模型篇（一）：大模型训练框架LLaMA-Factory在国内网络环境下的安装、部署及使用</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139131558?spm=1001.2014.3001.5501" title="AI智能体研发之路-模型篇（二）：DeepSeek-V2-Chat 训练与推理实战">AI智能体研发之路-模型篇（二）：DeepSeek-V2-Chat 训练与推理实战</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139219617?spm=1001.2014.3001.5502" title="AI智能体研发之路-模型篇（三）：中文大模型开、闭源之争">AI智能体研发之路-模型篇（三）：中文大模型开、闭源之争</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139237430?spm=1001.2014.3001.5502" title="AI智能体研发之路-模型篇（四）：一文入门pytorch开发">AI智能体研发之路-模型篇（四）：一文入门pytorch开发</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139249095?spm=1001.2014.3001.5502" title="AI智能体研发之路-模型篇（五）：pytorch vs tensorflow框架DNN网络结构源码级对比">AI智能体研发之路-模型篇（五）：pytorch vs tensorflow框架DNN网络结构源码级对比</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139263131?spm=1001.2014.3001.5502" title="AI智能体研发之路-模型篇（六）：【机器学习】基于tensorflow实现你的第一个DNN网络">AI智能体研发之路-模型篇（六）：【机器学习】基于tensorflow实现你的第一个DNN网络</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139307081?spm=1001.2014.3001.5502" title="AI智能体研发之路-模型篇（七）：【机器学习】基于YOLOv10实现你的第一个视觉AI大模型">AI智能体研发之路-模型篇（七）：【机器学习】基于YOLOv10实现你的第一个视觉AI大模型</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139422184?spm=1001.2014.3001.5501" title="AI智能体研发之路-模型篇（八）：【机器学习】Qwen1.5-14B-Chat大模型训练与推理实战">AI智能体研发之路-模型篇（八）：【机器学习】Qwen1.5-14B-Chat大模型训练与推理实战</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139497336?spm=1001.2014.3001.5502" title="AI智能体研发之路-模型篇（九）：【机器学习】GLM4-9B-Chat大模型/GLM-4V-9B多模态大模型概述、原理及推理实战">AI智能体研发之路-模型篇（九）：【机器学习】GLM4-9B-Chat大模型/GLM-4V-9B多模态大模型概述、原理及推理实战</a></p> 
<p>《AI—Transformers应用》</p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139478765?spm=1001.2014.3001.5502" title="【AI大模型】Transformers大模型库（一）：Tokenizer">【AI大模型】Transformers大模型库（一）：Tokenizer</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139481089?spm=1001.2014.3001.5502" title="【AI大模型】Transformers大模型库（二）：AutoModelForCausalLM">【AI大模型】Transformers大模型库（二）：AutoModelForCausalLM</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139481581?spm=1001.2014.3001.5502" title="【AI大模型】Transformers大模型库（三）：特殊标记（special tokens）">【AI大模型】Transformers大模型库（三）：特殊标记（special tokens）</a></p> 
<p><a href="https://blog.csdn.net/weixin_48007632/article/details/139483010?spm=1001.2014.3001.5502" title="【AI大模型】Transformers大模型库（四）：AutoTokenizer">【AI大模型】Transformers大模型库（四）：AutoTokenizer</a></p> 
<p><a href="https://mp.csdn.net/mp_blog/manage/article?spm=1011.2124.3001.5298" title="【AI大模型】Transformers大模型库（五）：AutoModel、Model Head及查看模型结构">【AI大模型】Transformers大模型库（五）：AutoModel、Model Head及查看模型结构</a></p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/6da709b153a0d30a05f9962b95564b7e/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">数据仓库哈哈</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/965b3d2fe5247204594096df5b9d7dcb/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">MMII 的多模态医学图像交互框架：更直观地理解人体解剖结构和疾病</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>