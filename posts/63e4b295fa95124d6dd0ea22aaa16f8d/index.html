<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【扩散模型】LCM LoRA:一个通用的Stable Diffusion加速模块 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/63e4b295fa95124d6dd0ea22aaa16f8d/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="【扩散模型】LCM LoRA:一个通用的Stable Diffusion加速模块">
  <meta property="og:description" content="潜在一致性模型：[2310.04378] Latent Consistency Models: Synthesizing High-Resolution Images with Few-Step Inference (arxiv.org)
原文：Paper page - Latent Consistency Models: Synthesizing High-Resolution Images with Few-Step Inference (huggingface.co)
简介：LCM 只需 4,000 个训练步骤（约 32 个 A100 GPU/小时）即可从任何预训练的稳定扩散 (SD) 中提取出来，只需 2~4 个步骤甚至一步即可生成高质量的 768 x 768 分辨率图像，从而显着加速文本转换 -图像生成。 潜在一致性模型 介绍 潜在扩散模型(Latent Diffusion models, ldm)在高分辨率图像合成方面取得了显著的成果。然而，迭代采样过程计算量大，导致生成速度慢。受一致性模型的启发，我们提出了潜在一致性模型(Latent Consistency Models, lcm)，能够在任何预训练的ldm上以最小的步骤进行快速推理，包括稳定扩散。
原理：将引导反向扩散过程视为求解增强概率流ODE (PF-ODE)， lcm设计用于直接预测潜在空间中此类ODE的解，从而减少了多次迭代的需要，并允许快速，高保真采样。有效地从预训练的无分类器引导扩散模型中提取，高质量的768×768 2 ~ 4步LCM仅需32 A100 GPU小时即可进行训练。此外，引入了潜在一致性微调(LCF)，这是一种针对自定义图像数据集微调LCF的新方法。
一致性模型(CMs)：作为一种新型生成模型显示出巨大的潜力，可以在保持生成质量的同时加快采样速度。一致性模型采用一致性映射，直接将ODE轨迹中的任意点映射到原点，实现快速一步生成。可以通过提取预训练的扩散模型或作为独立的生成模型进行训练。
原理 潜在空间中的一致性蒸馏 在诸如稳定扩散（Stable Diffusion, SD）(Rombach et al, 2022)等大规模扩散模型中，利用图像的潜在空间有效地提高了图像生成质量并减少了计算负载。在SD中，首先训练一个自编码器（E, D）来将高维图像数据压缩为低维潜在向量 𝑧=𝐸(𝑥)，然后解码以重建图像 𝑥ˆ=𝐷(𝑧)。在潜在空间中训练扩散模型与基于像素的模型相比，大大降低了计算成本并加快了推理过程；潜在扩散模型（LDMs）使得在笔记本电脑的GPU上生成高分辨率图像成为可能。">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-07-08T16:19:56+08:00">
    <meta property="article:modified_time" content="2024-07-08T16:19:56+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【扩散模型】LCM LoRA:一个通用的Stable Diffusion加速模块</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>潜在一致性模型：<a href="https://arxiv.org/abs/2310.04378" rel="nofollow" title="[2310.04378] Latent Consistency Models: Synthesizing High-Resolution Images with Few-Step Inference (arxiv.org)">[2310.04378] Latent Consistency Models: Synthesizing High-Resolution Images with Few-Step Inference (arxiv.org)</a></p> 
<p>原文：<a href="https://huggingface.co/papers/2310.04378" rel="nofollow" title="Paper page - Latent Consistency Models: Synthesizing High-Resolution Images with Few-Step Inference (huggingface.co)">Paper page - Latent Consistency Models: Synthesizing High-Resolution Images with Few-Step Inference (huggingface.co)</a></p> 
<p>简介：LCM 只需 4,000 个训练步骤（约 32 个 A100 GPU/小时）即可从任何预训练的稳定扩散 (SD) 中提取出来，只需 2~4 个步骤甚至一步即可生成高质量的 768 x 768 分辨率图像，从而显着加速文本转换 -图像生成。 </p> 
<p></p> 
<h3 style="background-color:transparent;">潜在一致性模型</h3> 
<h4>介绍</h4> 
<p>潜在扩散模型(Latent Diffusion models, ldm)在高分辨率图像合成方面取得了显著的成果。然而，迭代采样过程计算量大，导致生成速度慢。受一致性模型的启发，我们提出了潜在一致性模型(Latent Consistency Models, lcm)，能够在任何预训练的ldm上以最小的步骤进行快速推理，包括稳定扩散。</p> 
<p>原理：将引导反向扩散过程视为求解增强概率流ODE (PF-ODE)， lcm设计用于直接预测潜在空间中此类ODE的解，从而减少了多次迭代的需要，并允许快速，高保真采样。有效地从预训练的无分类器引导扩散模型中提取，高质量的768×768 2 ~ 4步LCM仅需32 A100 GPU小时即可进行训练。此外，引入了潜在一致性微调(LCF)，这是一种针对自定义图像数据集微调LCF的新方法。</p> 
<p>一致性模型(CMs)：作为一种新型生成模型显示出巨大的潜力，可以在保持生成质量的同时加快采样速度。一致性模型采用一致性映射，直接将ODE轨迹中的任意点映射到原点，实现快速一步生成。可以通过提取预训练的扩散模型或作为独立的生成模型进行训练。</p> 
<h4>原理</h4> 
<h5 style="background-color:transparent;">潜在空间中的一致性蒸馏</h5> 
<p>在诸如稳定扩散（Stable Diffusion, SD）(Rombach et al, 2022)等大规模扩散模型中，利用图像的潜在空间有效地提高了图像生成质量并减少了计算负载。在SD中，首先训练一个自编码器（E, D）来将高维图像数据压缩为低维潜在向量 𝑧=𝐸(𝑥)，然后解码以重建图像 𝑥ˆ=𝐷(𝑧)。在潜在空间中训练扩散模型与基于像素的模型相比，大大降低了计算成本并加快了推理过程；潜在扩散模型（LDMs）使得在笔记本电脑的GPU上生成高分辨率图像成为可能。</p> 
<p>对于潜在一致性模型（LCMs），我们利用潜在空间的一致性蒸馏优势，与一致性模型（CMs）(Song et al, 2023)中使用的像素空间形成对比。这种方法被称为潜在一致性蒸馏（LCD），应用于预训练的SD，允许在1至4步内合成高分辨率的768×768图像。我们专注于条件生成。回顾一下逆扩散过程的PF-ODE：</p> 
<p><img alt="" height="79" src="https://images2.imgbox.com/20/c4/D0Lok391_o.png" width="1078"></p> 
<p>其中𝑧𝑡是图像潜在变量，𝜖𝜃(𝑧𝑡,𝑐,𝑡) 是噪声预测模型，𝑐 是给定的条件（例如文本）。通过从 𝑇 到 0 解决 PF-ODE 可以抽取样本。为了执行潜在一致性蒸馏（LCD），我们引入一致性函数 𝑓𝜃:(𝑧𝑡,𝑐,𝑡)→𝑧0​，直接预测 𝑡=0 时 PF-ODE 的解（公式8）。通过噪声预测模型 𝜖^𝜃参数化 𝑓𝜃，如下所示：</p> 
<p><img alt="" height="72" src="https://images2.imgbox.com/32/19/wYW1XFT2_o.png" width="1149"></p> 
<p>其中 𝑐skip(0)=1，𝑐out(0)=0，且 𝜖^𝜃(𝑧,𝑐,𝑡) 是噪声预测模型，其初始参数与教师扩散模型相同。假设有一个高效的ODE求解器 Ψ(𝑧𝑡,𝑡,𝑠,𝑐)，用于近似积分公式8的右侧，从时间 𝑡 到 𝑠。在实际操作中，可以使用DDIM，DPM-Solver或DPM-Solver++ 作为 Ψ(⋅,⋅,⋅,⋅)。</p> 
<p>只在训练/蒸馏中使用这些求解器，而不是在推理中。潜在一致性模型（LCM）旨在通过最小化一致性蒸馏损失来预测PF-ODE的解：</p> 
<p><img alt="" height="329" src="https://images2.imgbox.com/ef/fb/bMcIHsbI_o.png" width="1200"></p> 
<h5>通过求解增强的PF-ODE进行单阶段引导蒸馏</h5> 
<p>无分类器引导（Classifier-free guidance, CFG）对于在稳定扩散（SD）中合成高质量的文本对齐图像至关重要，通常需要大于6的CFG比例 𝜔。因此，将CFG集成到蒸馏方法中变得不可或缺。之前的方法 Guided-Distill引入了一个两阶段蒸馏以支持从引导扩散模型中进行少步采样。然而，这种方法计算密集估计，2步推理至少需要45个A100 GPU天）。相比之下，潜在一致性模型（LCM）仅需要32个A100 GPU小时的训练时间来进行2步推理，如图1所示。此外，两阶段引导蒸馏可能导致累积误差，导致性能不佳。相反，LCM通过求解增强的PF-ODE采用高效的单阶段引导蒸馏。回顾在逆扩散过程中使用的CFG：</p> 
<p><img alt="" height="65" src="https://images2.imgbox.com/cd/31/wzcKGRo1_o.png" width="1075"></p> 
<p>其中用条件噪声和无条件噪声的线性组合代替原有的噪声预测，ω称为引导标度。为了从引导逆向过程中采样，我们需要求解以下增广的PF-ODE(即，与ω相关的项增广):</p> 
<p><img alt="" height="73" src="https://images2.imgbox.com/f9/45/T3m8HiNm_o.png" width="1089"></p> 
<p>为了有效地进行一级导向蒸馏，我们引入增广一致性函数fθ:(zt， ω， c, t)→z0来直接预测t = 0时增广PF-ODE (Eq. 13)的解。我们以与Eq. 9相同的方式参数化fθ，除了λ θ(z, c, t)被λ ϵθ(z， ω， c, t)取代，这是一个用与教师扩散模型相同的参数初始化的噪声预测模型，但还包含额外的可训练参数，用于ω的调节。一致性损失与Eq. 10相同，只是我们使用增广一致性函数fθ(zt， ω， c, t)。</p> 
<p><img alt="" height="64" src="https://images2.imgbox.com/44/c6/BGHtnAUm_o.png" width="1200"></p> 
<p><img alt="" height="486" src="https://images2.imgbox.com/9c/05/91cdlOhC_o.png" width="1200"></p> 
<h5>跳过时间步加速蒸馏</h5> 
<p>离散扩散模型通常通过长时间步长计划 {𝑡𝑖}𝑖（也称为离散化计划或时间计划）训练噪声预测模型，以实现高质量的生成结果。例如，稳定扩散（SD）有一个长度为1000的时间计划。然而，直接将潜在一致性蒸馏（LCD）应用于具有如此长时间计划的SD可能会有问题。模型需要在所有1000个时间步长上进行采样，而一致性损失试图使LCM模型 𝑓𝜃(𝑧𝑡𝑛+1,𝑐,𝑡𝑛+1) 的预测与在相同轨迹上下一步 𝑓𝜃(𝑧𝑡𝑛,𝑐,𝑡𝑛) 的预测对齐。由于 𝑡𝑛 − 𝑡𝑛+1​ 很小，𝑧𝑡𝑛 和 𝑧𝑡𝑛+1（因此 𝑓𝜃(𝑧𝑡𝑛+1,𝑐,𝑡𝑛+1)和 𝑓𝜃(𝑧𝑡𝑛,𝑐,𝑡𝑛)）已经彼此接近，导致一致性损失很小，因此收敛速度慢。</p> 
<p>为了解决这个问题，我们引入了跳步方法（SKIPPING-STEP），大大缩短了时间计划的长度（从数千缩短到几十），以实现快速收敛，同时保持生成质量。</p> 
<p>一致性模型（CMs）使用EDM连续时间计划，并使用欧拉或Heun求解器作为数值连续PF-ODE求解器。对于LCMs，为了适应稳定扩散中的离散时间计划，我们使用DDIM，DPM-Solver或DPM-Solver++作为ODE求解器。</p> 
<p>现在，我们介绍潜在一致性蒸馏（LCD）中的跳步方法。与确保相邻时间步长 𝑡𝑛+1→𝑡𝑛 之间的一致性不同，LCMs旨在确保当前时间步长和相隔 𝑘 步的时间步长 𝑡𝑛+𝑘→𝑡𝑛之间的一致性。注意，设置 𝑘=1k=1 会恢复到中的原始计划，导致收敛速度慢，而非常大的 𝑘 可能会导致ODE求解器的大近似误差。在我们的主要实验中，我们设置 𝑘=20，将时间计划的长度从数千减少到几十。第5.2节的结果显示了不同 k 值的效果，并揭示跳步方法在加速LCD过程中的重要性。具体来说，公式14中的一致性蒸馏损失被修改为确保从 𝑡𝑛+𝑘 到 𝑡𝑛 的一致性：</p> 
<p><img alt="" height="260" src="https://images2.imgbox.com/cd/79/lhG767RF_o.png" width="1200"></p> 
<p> 上述推导类似于公式15。对于LCM，我们在此使用三种可能的ODE求解器：DDIM (Song et al, 2020a)、DPM-Solver (Lu et al, 2022a)、DPM-Solver++。</p> 
<p><img alt="" height="146" src="https://images2.imgbox.com/79/af/ap66qOxq_o.png" width="1200"></p> 
<p></p> 
<h3 style="background-color:transparent;">LCM-LoRA</h3> 
<h4>原理</h4> 
<blockquote> 
 <p>在使用原始 LCM 蒸馏时，每个模型都需要单独蒸馏。而 LCM LoRA 的核心思想是只对少量适配器 (<a href="https://huggingface.co/docs/peft/conceptual_guides/lora" rel="nofollow" title="即 LoRA 层">即 LoRA 层</a>) 进行训练，而不用对完整模型进行训练。推理时，可将生成的 LoRA 用于同一模型的任何微调版本，而无需对每个版本都进行蒸馏。训练自己的 LoRA流程如下:</p> 
 <ol><li>从 Hub 中选择一个教师模型。如: 你可以使用 <a href="https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0" rel="nofollow" title="SDXL (base)">SDXL (base)</a>，或其任何微调版或 dreambooth 微调版。</li><li>在该模型上 <a href="https://huggingface.co/blog/zh/lcm_lora#%E5%A6%82%E4%BD%95%E8%AE%AD%E7%BB%83-lcm-%E6%A8%A1%E5%9E%8B%E5%8F%8A-lcm-lora" rel="nofollow" title="训练 LCM LoRA 模型">训练 LCM LoRA 模型</a>。LoRA 是一种参数高效的微调 (PEFT)，其实现成本比全模型微调要便宜得多。</li><li>将 LoRA 与任何 SDXL 模型和 LCM 调度器一起组成一个pipeline，进行推理。就这样！用这个流水线，你只需几步推理即可生成高质量的图像。</li></ol> 
</blockquote> 
<h4></h4> 
<h4>推理</h4> 
<p>根据<a href="https://huggingface.co/blog/zh/lcm_lora#%E5%A6%82%E4%BD%95%E8%AE%AD%E7%BB%83-lcm-%E6%A8%A1%E5%9E%8B%E5%8F%8A-lcm-lora" rel="nofollow" title="使用 LCM LoRA 4 步完成 SDXL 推理 (huggingface.co)">使用 LCM LoRA 4 步完成 SDXL 推理 (huggingface.co)</a> 的说明进行推理。给出的使用说明只进行了T2I的示例，不知道Talking face生成的结果如何，首先尝试直接使用了SD-v1.5的预训练权重：<a href="https://huggingface.co/latent-consistency/lcm-lora-sdv1-5" rel="nofollow" title="latent-consistency/lcm-lora-sdv1-5 · Hugging Face">latent-consistency/lcm-lora-sdv1-5 · Hugging Face</a></p> 
<p>生成一段14s的视频，原模型用时：15min</p> 
<p><img alt="" height="151" src="https://images2.imgbox.com/50/6c/eiqhw1i9_o.png" width="1200"></p> 
<p>使用LCM-LoRA后：</p> 
<p>首先有一个diffusers库版本不匹配的问题，anipotrait使用的diffusers==0.24.0，而必须的load_lora_weights函数在新版本diffusers，更新库后编译报错</p> 
<p></p> 
<h4>训练</h4> 
<p>参考：<a href="https://huggingface.co/blog/zh/lcm_lora#%E5%A6%82%E4%BD%95%E8%AE%AD%E7%BB%83-lcm-%E6%A8%A1%E5%9E%8B%E5%8F%8A-lcm-lora" rel="nofollow" title="使用 LCM LoRA 4 步完成 SDXL 推理 (huggingface.co)">使用 LCM LoRA 4 步完成 SDXL 推理 (huggingface.co)</a></p> 
<p>Stable Diffusion 1.5 训练脚本：<a href="https://github.com/huggingface/diffusers/blob/main/examples/consistency_distillation/README.md" title="diffusers/examples/consistency_distillation/README.md at main · huggingface/diffusers (github.com)">diffusers/examples/consistency_distillation/README.md at main · huggingface/diffusers (github.com)</a></p> 
<p>使用时，先加载微调后的模型，然后加载适合 Stable Diffusion v1.5 的 LCM LoRA 权重：</p> 
<pre><code class="language-python">from diffusers import DiffusionPipeline, LCMScheduler
import torch

model_id = "wavymulder/collage-diffusion"
lcm_lora_id = "latent-consistency/lcm-lora-sdv1-5"

pipe = DiffusionPipeline.from_pretrained(model_id, variant="fp16")
pipe.scheduler = LCMScheduler.from_config(pipe.scheduler.config)
pipe.load_lora_weights(lcm_lora_id)
pipe.to(device="cuda", dtype=torch.float16)

prompt = "collage style kid sits looking at the night sky, full of stars"

generator = torch.Generator(device=pipe.device).manual_seed(1337)
images = pipe(
    prompt=prompt,
    generator=generator,
    negative_prompt=negative_prompt,
    num_inference_steps=4,
    guidance_scale=1,
).images[0]
images
</code></pre> 
<ul><li>使用 Stable Diffusion v1.5 模型去实例化一个标准的 diffusion pipeline。</li><li>应用 LCM-LoRA。</li><li>将调度器改为 LCMScheduler，这是 LCM 模型使用的调度器。</li></ul> 
<p></p> 
<p></p> 
<p>其他SD优化方案：<a href="https://blog.csdn.net/Taobaojishu/article/details/138236898?spm=1001.2101.3001.6650.3&amp;utm_medium=distribute.pc_relevant.none-task-blog-2~default~YuanLiJiHua~Position-3-138236898-blog-134624432.235%5Ev43%5Epc_blog_bottom_relevance_base4&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~YuanLiJiHua~Position-3-138236898-blog-134624432.235%5Ev43%5Epc_blog_bottom_relevance_base4&amp;utm_relevant_index=4" title="diffusers SD推理加速方案的调研实践总结-CSDN博客">diffusers SD推理加速方案的调研实践总结-CSDN博客</a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/f91fbc3f98ec36f7332997fc21889eb4/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">绝区伍--2024年AI发展路线图</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/d66c396cfd5de4601883bf13929c1ea7/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">浅谈CSS属性：clip-path</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>