<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【DataSophon】DataSophon1.2.1服务组件开启 kerberos - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/267e0876d5c66d8895fbd6df89f41e60/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="【DataSophon】DataSophon1.2.1服务组件开启 kerberos">
  <meta property="og:description" content="目录
一、DataSophon是什么
1.1 DataSophon概述
1.2 架构概览
1.3 设计思想
二、集成组件
三、环境准备
四、安装kerberos服务
4.1 Zookeeper
4.2 HDFS
4.3 HBase
4.4 YARN
4.5 hive
【DataSophon】大数据管理平台DataSophon-1.2.1安装部署详细流程-CSDN博客
【DataSophon】大数据服务组件之Flink升级_datasophon1.2 升级flink-CSDN博客
【DataSophon】大数据管理平台DataSophon-1.2.1基本使用-CSDN博客
一、DataSophon是什么 1.1 DataSophon概述 DataSophon也是个类似的管理平台，只不过与智子不同的是，智子的目的是锁死人类的基础科学阻碍人类技术爆炸，而DataSophon是致力于自动化监控、运维、管理大数据基础组件和节点的，帮助您快速构建起稳定，高效的大数据集群服务。
主要特性有:
快速部署,可快速完成300个节点的大数据集群部署兼容复杂环境,极少的依赖使其很容易适配各种复杂环境监控指标全面丰富，基于生产实践展示用户最关心的监控指标灵活便捷的告警服务，可实现用户自定义告警组和告警指标可扩展性强，用户可通过配置的方式集成或升级大数据组件 官方地址：DataSophon | DataSophon
GITHUB地址：datasophon/README_CN.md at dev · datavane/datasophon
1.2 架构概览 1.3 设计思想 为设计出轻量级，高性能，高可扩的，可满足国产化环境要求的大数据集群管理平台。需满足以下设计要求：
（1）一次编译，处处运行，项目部署仅依赖java环境，无其他系统环境依赖。
（2）DataSophon工作端占用资源少，不占用大数据计算节点资源。
（3）可扩展性高，可通过配置的方式集成托管第三方组件。
二、集成组件 各集成组件均进行过兼容性测试，并稳定运行于300&#43;个节点规模的大数据集群，日处理数据量约4000亿条。在海量数据下，各大数据组件调优成本低，平台默认展示用户关心和需要调优的配置。如下DDP1.2.1服务版本信息：
序号
名称
版本
描述
1
HDFS
3.3.3
分布式大数据存储
2
YARN
3.3.3
分布式资源调度与管理平台
3
ZooKeeper
3.5.10
分布式协调系统
4
FLINK
1.16.2
实时计算引擎">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-07-04T09:26:03+08:00">
    <meta property="article:modified_time" content="2024-07-04T09:26:03+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【DataSophon】DataSophon1.2.1服务组件开启 kerberos</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p id="uf85a3ef9"><img alt="" height="516" src="https://images2.imgbox.com/15/15/8zkTgOSO_o.png" width="916"></p> 
<p id="main-toc"><strong>目录</strong></p> 
<p id="NIwLt-toc" style="margin-left:0px;"><a href="#NIwLt" rel="nofollow">一、DataSophon是什么</a></p> 
<p id="qp5UO-toc" style="margin-left:40px;"><a href="#qp5UO" rel="nofollow">1.1 DataSophon概述</a></p> 
<p id="qyuIT-toc" style="margin-left:40px;"><a href="#qyuIT" rel="nofollow">1.2 架构概览</a></p> 
<p id="P2f5B-toc" style="margin-left:40px;"><a href="#P2f5B" rel="nofollow">1.3 设计思想</a></p> 
<p id="QKjbS-toc" style="margin-left:0px;"><a href="#QKjbS" rel="nofollow">二、集成组件</a></p> 
<p id="Rs4lX-toc" style="margin-left:0px;"><a href="#Rs4lX" rel="nofollow">三、环境准备</a></p> 
<p id="x1QZB-toc" style="margin-left:0px;"><a href="#x1QZB" rel="nofollow">四、安装kerberos服务</a></p> 
<p id="rcxY1-toc" style="margin-left:40px;"><a href="#rcxY1" rel="nofollow">4.1 Zookeeper</a></p> 
<p id="prmk2-toc" style="margin-left:40px;"><a href="#prmk2" rel="nofollow">4.2 HDFS</a></p> 
<p id="OfQqh-toc" style="margin-left:40px;"><a href="#OfQqh" rel="nofollow">4.3 HBase</a></p> 
<p id="T6ETR-toc" style="margin-left:40px;"><a href="#T6ETR" rel="nofollow">4.4 YARN</a></p> 
<p id="SqoX1-toc" style="margin-left:40px;"><a href="#SqoX1" rel="nofollow">4.5 hive</a></p> 
<hr> 
<p id="u2c333889"><a href="https://blog.csdn.net/qq_35995514/article/details/134977367?csdn_share_tail=%7B%22type%22%3A%22blog%22%2C%22rType%22%3A%22article%22%2C%22rId%22%3A%22134977367%22%2C%22source%22%3A%22qq_35995514%22%7D" title="【DataSophon】大数据管理平台DataSophon-1.2.1安装部署详细流程-CSDN博客">【DataSophon】大数据管理平台DataSophon-1.2.1安装部署详细流程-CSDN博客</a></p> 
<p id="u7fb7b925"><a href="https://kangll.blog.csdn.net/article/details/135031780?spm=1001.2014.3001.5502" rel="nofollow" title="【DataSophon】大数据服务组件之Flink升级_datasophon1.2 升级flink-CSDN博客">【DataSophon】大数据服务组件之Flink升级_datasophon1.2 升级flink-CSDN博客</a></p> 
<p id="u4c297e1c"><a href="https://blog.csdn.net/qq_35995514/article/details/135031693?spm=1001.2014.3001.5501" title="【DataSophon】大数据管理平台DataSophon-1.2.1基本使用-CSDN博客">【DataSophon】大数据管理平台DataSophon-1.2.1基本使用-CSDN博客</a></p> 
<hr> 
<h2 id="NIwLt"><span style="color:#956fe7;">一、DataSophon是什么</span></h2> 
<hr id="S1wrI"> 
<h3 id="qp5UO"><span style="color:#4da8ee;">1.1 DataSophon概述</span></h3> 
<hr id="ETDC7"> 
<blockquote> 
 <p id="u0e8827e6">DataSophon也是个类似的管理平台，只不过与智子不同的是，智子的目的是锁死人类的基础科学阻碍人类技术爆炸，而DataSophon是致力于自动化监控、运维、管理大数据基础组件和节点的，帮助您快速构建起稳定，高效的大数据集群服务。</p> 
</blockquote> 
<p id="ue5e94903"><strong>主要特性有:</strong></p> 
<ul><li id="ue27c125a">快速部署,可快速完成300个节点的大数据集群部署</li><li id="uac9e7e65">兼容复杂环境,极少的依赖使其很容易适配各种复杂环境</li><li id="uf51937ed">监控指标全面丰富，基于生产实践展示用户最关心的监控指标</li><li id="u776ac6c4">灵活便捷的告警服务，可实现用户自定义告警组和告警指标</li><li id="ufb5321d0">可扩展性强，用户可通过配置的方式集成或升级大数据组件</li></ul> 
<p id="ud840ef1c"><strong>官方地址</strong>：DataSophon | DataSophon</p> 
<p id="ucca333ed"><strong>GITHUB地址：</strong>datasophon/README_CN.md at dev · datavane/datasophon</p> 
<p id="u8b02f170"><img alt="" height="327" src="https://images2.imgbox.com/92/f8/H8sbt6BB_o.png" width="929"></p> 
<h3 id="qyuIT"><span style="color:#4da8ee;">1.2 架构概览</span></h3> 
<hr id="LdqaT"> 
<p id="uce020c4f"></p> 
<p class="img-center"><img alt="" height="503" id="u3a620d3d" src="https://images2.imgbox.com/41/86/CDw4p0MX_o.png" width="711"></p> 
<h3 id="P2f5B"><span style="color:#4da8ee;">1.3 设计思想</span></h3> 
<hr id="rGBFN"> 
<p id="ud69d7dfd">为设计出轻量级，高性能，高可扩的，可满足国产化环境要求的大数据集群管理平台。需满足以下设计要求：</p> 
<p id="u13179773">（1）一次编译，处处运行，项目部署仅依赖java环境，无其他系统环境依赖。</p> 
<p id="u7261ddb3">（2）DataSophon工作端占用资源少，不占用大数据计算节点资源。</p> 
<p id="ubc1680e0">（3）可扩展性高，可通过配置的方式集成托管第三方组件。</p> 
<hr id="EBsHF"> 
<h2 id="QKjbS"><span style="color:#956fe7;">二、集成组件</span></h2> 
<hr id="kNgfY"> 
<p id="u6b6f5097">各集成组件均进行过兼容性测试，并稳定运行于300+个节点规模的大数据集群，日处理数据量约4000亿条。在海量数据下，各大数据组件调优成本低，平台默认展示用户关心和需要调优的配置。如下DDP1.2.1服务版本信息：</p> 
<table id="YsyEd"><tbody><tr><td> <p id="u9e8a871e"><strong>序号</strong></p> </td><td> <p id="u30f6d2b0"><strong>名称</strong></p> </td><td> <p id="u383555c3"><strong>版本</strong></p> </td><td> <p id="u23036f29"><strong>描述</strong></p> </td></tr><tr><td> <p id="u940b003d">1</p> </td><td> <p id="uc98d4935">HDFS</p> </td><td> <p id="u9b78d150">3.3.3</p> </td><td> <p id="u7c05d2cf">分布式大数据存储</p> </td></tr><tr><td> <p id="uc9715e9a">2</p> </td><td> <p id="u3b1f117d">YARN</p> </td><td> <p id="uc049fc62">3.3.3</p> </td><td> <p id="ua1d2a88f">分布式资源调度与管理平台</p> </td></tr><tr><td> <p id="ua4d6c5f6">3</p> </td><td> <p id="u13835e37">ZooKeeper</p> </td><td> <p id="u43182fab">3.5.10</p> </td><td> <p id="ubb7e47d5">分布式协调系统</p> </td></tr><tr><td> <p id="uecdb6a1c">4</p> </td><td> <p id="ub5bf3a70">FLINK</p> </td><td> <p id="u6eb86e5b">1.16.2</p> </td><td> <p id="uc61041b5">实时计算引擎</p> </td></tr><tr><td> <p id="u01a3755d">5</p> </td><td> <p id="ub6190682">DolphoinScheduler</p> </td><td> <p id="u0d7b4d06">3.1.8</p> </td><td> <p id="u3caaa5e0">分布式易扩展的可视化工作流任务调度平台</p> </td></tr><tr><td> <p id="ud89467c7">6</p> </td><td> <p id="u51f5417d">StreamPark</p> </td><td> <p id="u1b1c98b1">2.1.1</p> </td><td> <p id="u89c95b3e">流处理极速开发框架,流批一体&amp;湖仓一体的云原生平台</p> </td></tr><tr><td> <p id="ud4f386a9">7</p> </td><td> <p id="u90ba237e">Spark</p> </td><td> <p id="uc44657f1">3.1.3</p> </td><td> <p id="uc3384436">分布式计算系统</p> </td></tr><tr><td> <p id="ueadda3be">8</p> </td><td> <p id="uce68b0f4">Hive</p> </td><td> <p id="uf6154bf9">3.1.0</p> </td><td> <p id="ub2c4de4e">离线数据仓库</p> </td></tr><tr><td> <p id="u0edf3fc4">9</p> </td><td> <p id="u3a0761b9">Kafka</p> </td><td> <p id="u3af0a36e">2.4.1</p> </td><td> <p id="u28a33f24">高吞吐量分布式发布订阅消息系统</p> </td></tr><tr><td> <p id="ue610dcd6">10</p> </td><td> <p id="uacd16096">Trino</p> </td><td> <p id="u8a7c6fd0">367</p> </td><td> <p id="u2e0bfd4b">分布式Sql交互式查询引擎</p> </td></tr><tr><td> <p id="u5b6b9baf">11</p> </td><td> <p id="ufed4049e">Doris</p> </td><td> <p id="u14cc9525">1.2.6</p> </td><td> <p id="udc8b065e">新一代极速全场景MPP数据库</p> </td></tr><tr><td> <p id="u1456a256">12</p> </td><td> <p id="u54cf4e46">Hbase</p> </td><td> <p id="u63ccb275">2.4.16</p> </td><td> <p id="u3da10e73">分布式列式存储数据库</p> </td></tr><tr><td> <p id="u980a51a3">13</p> </td><td> <p id="u4159c138">Ranger</p> </td><td> <p id="ue0921ac8">2.1.0</p> </td><td> <p id="u57937902">权限控制框架</p> </td></tr><tr><td> <p id="u8eb9e9d1">14</p> </td><td> <p id="u5709113d">ElasticSearch</p> </td><td> <p id="udcf133ed">7.16.2</p> </td><td> <p id="u76548255">高性能搜索引擎</p> </td></tr><tr><td> <p id="u6ade8000">15</p> </td><td> <p id="ua6b1a54e">Prometheus</p> </td><td> <p id="ue85daa1d">2.17.2</p> </td><td> <p id="u67fe97ec">高性能监控指标采集与告警系统</p> </td></tr><tr><td> <p id="u0c72613b">16</p> </td><td> <p id="u22163325">Grafana</p> </td><td> <p id="u97f7406f">9.1.6</p> </td><td> <p id="u0051a713">监控分析与数据可视化套件</p> </td></tr><tr><td> <p id="u87ecb5dd">17</p> </td><td> <p id="uc6acc3f9">AlertManager</p> </td><td> <p id="u42a85239">0.23.0</p> </td><td> <p id="ubeb31845">告警通知管理系统</p> </td></tr></tbody></table> 
<hr id="O7IvB"> 
<h2 id="Rs4lX"><span style="color:#956fe7;">三、环境准备</span></h2> 
<hr id="q2REn"> 
<table id="x6pKW"><tbody><tr><td> <p id="u4bde30ab"><strong>IP</strong></p> </td><td> <p id="u024bc5c2"><strong>主机名</strong></p> </td></tr><tr><td> <p id="u2ddec405">192.168.2.115</p> </td><td> <p id="u2a77ce2b">ddp01</p> </td></tr><tr><td> <p id="ucbab6944">192.168.2.116</p> </td><td> <p id="ud6999f94">ddp02</p> </td></tr><tr><td> <p id="ud2a0d9de">192.168.2.120</p> </td><td> <p id="ueb914bec">ddp03</p> </td></tr></tbody></table> 
<hr> 
<h2 id="x1QZB"><span style="color:#956fe7;">四、安装kerberos服务</span></h2> 
<hr id="QWioo"> 
<p id="u451bd3ac">选择kerberos服务<img alt="" height="732" src="https://images2.imgbox.com/53/f0/vsXjEHyp_o.png" width="1200"></p> 
<p id="u115edcbc"></p> 
<p id="u2ec326c3">选择 KDC和 Kadmin安装节点</p> 
<p id="u260ebd04"></p> 
<p class="img-center"><img alt="" height="584" id="u525918a0" src="https://images2.imgbox.com/30/bc/SWYW4Wgi_o.png" width="1200"></p> 
<p id="u9d3d3680">选择Client安装节点</p> 
<p class="img-center"><img alt="" height="524" id="ua681a695" src="https://images2.imgbox.com/a4/97/xKL4fnR4_o.png" width="1200"></p> 
<p id="u1853f726"></p> 
<p id="ue7f3e8c9">域名使用默认的 HADOOP.COM ，如需修为改自定义 则需要比如在HBase zk-jaas.ftl 改为传参，因为他默认是写死为 HADOOP.COM。</p> 
<p class="img-center"><img alt="" height="632" id="uf1a30818" src="https://images2.imgbox.com/b2/0d/cJEPMwbZ_o.png" width="1200"></p> 
<p id="u3483dcfd"></p> 
<p id="ua64718b8">如下是datasophon-woker ，下的 zk-jaas.ftl默认配置<img alt="" height="299" src="https://images2.imgbox.com/e8/bc/YIWH6SkY_o.png" width="1060"></p> 
<p id="u34efc966"></p> 
<p id="ued19bcd1">修改后的</p> 
<pre id="TFCs4"><code>
&lt;#assign realm = zkRealm!""&gt;
&lt;#if realm?has_content&gt;
 Client {
 com.sun.security.auth.module.Krb5LoginModule required
 useKeyTab=true
 keyTab="/etc/security/keytab/hbase.keytab"
 useTicketCache=false
 principal="hbase/${host}@${realm}";
 };
&lt;/#if&gt;</code></pre> 
<p id="ud56c92a5"></p> 
<p id="u73f24e38">安装完成<img alt="" height="648" src="https://images2.imgbox.com/3e/02/Fxw5q5eT_o.png" width="1200"></p> 
<p id="ubb2cb7eb"></p> 
<h3 id="rcxY1"><span style="color:#4da8ee;">4.1 Zookeeper</span></h3> 
<hr id="oV3En"> 
<p id="ud3ebc542">enableKerberos 点击开启即可后重启即可。</p> 
<p class="img-center"><img alt="" height="568" id="u5bcba3e9" src="https://images2.imgbox.com/56/1b/jVegRZgn_o.png" width="1200"></p> 
<p id="u4e6af6fc"></p> 
<h3 id="prmk2"><span style="color:#4da8ee;">4.2 HDFS</span></h3> 
<hr id="LdDhl"> 
<p id="u18bd2e38">如下图 按钮开启kerberos</p> 
<p class="img-center"><img alt="" height="749" id="u4aff8778" src="https://images2.imgbox.com/48/d4/foDLNcqw_o.png" width="1200"></p> 
<p id="u61027f8f"></p> 
<p id="u093ec11b">开启之后我们需要重启HDFS服务，全部重启可能会报错，我们可以对服务内部的角色逐个重启。</p> 
<p class="img-center"><img alt="" height="666" id="ucc4c4ddf" src="https://images2.imgbox.com/e8/ac/xPIVXuyx_o.png" width="1200"></p> 
<p id="ud84da7ea"></p> 
<p id="u407a9101"></p> 
<h3 id="OfQqh"><span style="color:#4da8ee;">4.3 HBase</span></h3> 
<hr id="rGobM"> 
<p id="u6bfb7426">开启</p> 
<p class="img-center"><img alt="" height="559" id="uf12d66e8" src="https://images2.imgbox.com/0a/5b/tWu2Yxad_o.png" width="1200"></p> 
<p id="ufb555ae3"></p> 
<p id="u80cd841c">HBase2.4.16 开启Kerberos后 HMaster启动报错</p> 
<pre id="o8TiW"><code>2024-06-12 10:40:46,421 ERROR [main] regionserver.HRegionServer: Failed construction RegionServer
org.apache.hadoop.hbase.ZooKeeperConnectionException: master:16000-0x1000ff4d1270007, quorum=ddp01:2181,ddp02:2181,ddp03:2181, baseZNode=/hbase Unexpected KeeperException creating base node
	at org.apache.hadoop.hbase.zookeeper.ZKWatcher.createBaseZNodes(ZKWatcher.java:258)
	at org.apache.hadoop.hbase.zookeeper.ZKWatcher.&lt;init&gt;(ZKWatcher.java:182)
	at org.apache.hadoop.hbase.zookeeper.ZKWatcher.&lt;init&gt;(ZKWatcher.java:135)
	at org.apache.hadoop.hbase.regionserver.HRegionServer.&lt;init&gt;(HRegionServer.java:662)
	at org.apache.hadoop.hbase.master.HMaster.&lt;init&gt;(HMaster.java:425)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.hbase.master.HMaster.constructMaster(HMaster.java:2926)
	at org.apache.hadoop.hbase.master.HMasterCommandLine.startMaster(HMasterCommandLine.java:247)
	at org.apache.hadoop.hbase.master.HMasterCommandLine.run(HMasterCommandLine.java:145)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.hadoop.hbase.util.ServerCommandLine.doMain(ServerCommandLine.java:140)
	at org.apache.hadoop.hbase.master.HMaster.main(HMaster.java:2946)
Caused by: org.apache.zookeeper.KeeperException$InvalidACLException: KeeperErrorCode = InvalidACL for /hbase
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:128)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:54)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:1538)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.createNonSequential(RecoverableZooKeeper.java:525)
	at org.apache.hadoop.hbase.zookeeper.RecoverableZooKeeper.create(RecoverableZooKeeper.java:505)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.createWithParents(ZKUtil.java:874)
	at org.apache.hadoop.hbase.zookeeper.ZKUtil.createWithParents(ZKUtil.java:856)
	at org.apache.hadoop.hbase.zookeeper.ZKWatcher.createBaseZNodes(ZKWatcher.java:249)
	... 14 more
2024-06-12 10:40:46,424 ERROR [main] master.HMasterCommandLine: Master exiting
</code></pre> 
<p id="ue3683eb7"><strong>问题解决</strong>：没有使用默认的HADOOP域修改为自定义之后有的配置文件无法完成动态更新，包括配置页面也是如此需要手动更新，那我之后也就采用了默认的 HADOOP域。</p> 
<p id="u6cd2eec7">zk-jaas.conf</p> 
<p class="img-center"><img alt="" height="347" id="ubae05418" src="https://images2.imgbox.com/51/c8/jjLk04ye_o.png" width="878"></p> 
<p id="ub5387a94"></p> 
<p id="u30d6687f">或者可以修改zk_jaas.ftl安装文件</p> 
<pre id="wlHz1"><code>
&lt;#assign realm = zkRealm!""&gt;
&lt;#if realm?has_content&gt;
 Client {
 com.sun.security.auth.module.Krb5LoginModule required
 useKeyTab=true
 keyTab="/etc/security/keytab/hbase.keytab"
 useTicketCache=false
 principal="hbase/${host}@${realm}";
 };
&lt;/#if&gt;</code></pre> 
<p id="ud3f8aca0">修改后接着报错如下：</p> 
<pre id="O5jnK"><code>2024-06-14 15:07:23,137 INFO  [Thread-24] hdfs.DataStreamer: Exception in createBlockOutputStream
java.io.IOException: Invalid token in javax.security.sasl.qop: D
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil.readSaslMessage(DataTransferSaslUtil.java:220)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.doSaslHandshake(SaslDataTransferClient.java:553)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.getSaslStreams(SaslDataTransferClient.java:455)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.send(SaslDataTransferClient.java:298)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.checkTrustAndSend(SaslDataTransferClient.java:245)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.socketSend(SaslDataTransferClient.java:203)
	at org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient.socketSend(SaslDataTransferClient.java:193)
	at org.apache.hadoop.hdfs.DataStreamer.createBlockOutputStream(DataStreamer.java:1705)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1655)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:710)
2024-06-14 15:07:23,138 WARN  [Thread-24] hdfs.DataStreamer: Abandoning BP-268430271-192.168.2.115-1717646949749:blk_1073742094_1293
2024-06-14 15:07:23,159 WARN  [Thread-24] hdfs.DataStreamer: Excluding datanode DatanodeInfoWithStorage[192.168.2.120:1026,DS-3dec681b-fa1e-4bdc-89bf-0fd969f7ddbe,DISK]
2024-06-14 15:07:23,187 INFO  [Thread-24] hdfs.DataStreamer: Exception in createBlockOutputStream
java.io.IOException: Invalid token in javax.security.sasl.qop:  
</code></pre> 
<p id="uc41234b3">查询GitHub看是HBase 开启kerberos 版本不兼容 ，启动有问题</p> 
<p id="u3a98c07f"><a href="https://hbase.apache.org/downloads.html" rel="nofollow" title="Apache HBase – Apache HBase Downloads">Apache HBase – Apache HBase Downloads</a></p> 
<p class="img-center"><img alt="" height="790" id="ub4ff1f2a" src="https://images2.imgbox.com/a1/d7/dxYhVnkR_o.png" width="1200"></p> 
<p id="u968f913e"></p> 
<p id="ueb6d87cd">查看 Hadoop与HBase的版本兼容性：<a href="https://hbase.apache.org/book.html#hadoop" rel="nofollow" title="Apache HBase® Reference Guide">Apache HBase® Reference Guide</a></p> 
<p id="uf59b6adc"><a href="https://github.com/datavane/datasophon/issues/445" title="[Bug] [Module Name] v2.4.16 hbase in kerberos did't run  · Issue #445 · datavane/datasophon · GitHub">[Bug] [Module Name] v2.4.16 hbase in kerberos did't run · Issue #445 · datavane/datasophon · GitHub</a></p> 
<p id="ud59fbf94"></p> 
<p class="img-center"><img alt="" height="555" id="u72733862" src="https://images2.imgbox.com/4c/42/QfG1J8kA_o.png" width="735"></p> 
<p id="u4f9d3806">如上测试 使用 HBase2.4.16 那我们换成2.0.2 再次测试安装 ，HBase 版本换为2.0.2 需要修改启动脚本。</p> 
<pre id="nFHjI"><code>bin/hbase-daemon.sh </code></pre> 
<p id="ueb3b0a5d"><img alt="" height="479" src="https://images2.imgbox.com/41/2c/FmliLvSk_o.png" width="960"></p> 
<p id="u9470f9fc">增加监控信息，至于修改脚本的具体信息我们可以参考HBase 2.4.16 的写法修改即可。</p> 
<pre id="sdiZU"><code>bin/hbase</code></pre> 
<p id="uc44b3b8a"><img alt="" height="269" src="https://images2.imgbox.com/2f/22/lmBDh8iY_o.png" width="1200"></p> 
<p id="ud8e334bc"></p> 
<p id="u689e985e">修改完成后，我们再次安装 HBase 并开启kerberos成功，至于高版本的兼容性 我们后面再研究。<img alt="" height="692" src="https://images2.imgbox.com/b4/f3/p3RACx5d_o.png" width="1200"></p> 
<p id="ue47562f1"></p> 
<h3 id="T6ETR"><span style="color:#4da8ee;">4.4 YARN</span></h3> 
<hr id="xLBn9"> 
<p id="u41c939c4">NodeManager启动报错如下：</p> 
<pre id="gGfGO"><code>2024-06-12 09:23:55,033 WARN org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationExecutor: Shell execution returned exit code: 127. Privileged Execution Operation Stderr: 
/opt/datasophon/hadoop-3.3.3/bin/container-executor: error while loading shared libraries: libcrypto.so.1.1: cannot open shared object file: No such file or directory

Stdout: 
Full command array for failed execution: 
[/opt/datasophon/hadoop-3.3.3/bin/container-executor, --checksetup]
2024-06-12 09:23:55,034 WARN org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor: Exit code from container executor initialization is : 127
org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationException: ExitCodeException exitCode=127: /opt/datasophon/hadoop-3.3.3/bin/container-executor: error while loading shared libraries: libcrypto.so.1.1: cannot open shared object file: No such file or directory

	at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationExecutor.executePrivilegedOperation(PrivilegedOperationExecutor.java:182)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.linux.privileged.PrivilegedOperationExecutor.executePrivilegedOperation(PrivilegedOperationExecutor.java:208)
	at org.apache.hadoop.yarn.server.nodemanager.LinuxContainerExecutor.init(LinuxContainerExecutor.java:330)
	at org.apache.hadoop.yarn.server.nodemanager.NodeManager.serviceInit(NodeManager.java:403)
	at org.apache.hadoop.service.AbstractService.init(AbstractService.java:164)
	at org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartNodeManager(NodeManager.java:962)
	at org.apache.hadoop.yarn.server.nodemanager.NodeManager.main(NodeManager.java:1042)
Caused by: ExitCodeException exitCode=127: /opt/datasophon/hadoop-3.3.3/bin/container-executor: error while loading shared libraries: libcrypto.so.1.1: cannot open shared object file: No such file or directory
</code></pre> 
<p id="ub757bf5b">执行命令报错如下：</p> 
<pre id="NndFT"><code>/opt/datasophon/hadoop-3.3.3/bin/container-executor</code></pre> 
<p id="u90ed4388"></p> 
<p class="img-center"><img alt="" height="130" id="ufcd2e46c" src="https://images2.imgbox.com/c5/83/Zd93T9F5_o.png" width="1200"></p> 
<p id="u718be5da">那我们就安装openssl</p> 
<pre id="zgJQ2"><code># 下载libcrypto.so.1.1o.tar.gz  执行如下命令
cd ~
wget https://www.openssl.org/source/openssl-1.1.1o.tar.gz

# 解压libcrypto.so.1.1o.tar.gz 执行如下命令
sudo tar -zxvf openssl-1.1.1o.tar.gz
  
# 切换到解压好的openssl-1.1.1o目录下
cd openssl-1.1.1o
  
#编译安装
sudo ./config
sudo make
sudo make install</code></pre> 
<p id="u0c718a34"></p> 
<p class="img-center"><img alt="" height="109" id="u05ac8cbb" src="https://images2.imgbox.com/a2/41/EbfWQ1sY_o.png" width="939"></p> 
<p id="u48947c7f">既然有这个库，那就好办了，把它创建一下软链到/usr/lib64的路径中</p> 
<pre id="zgbXi"><code>ln -s /usr/local/lib64/libcrypto.so.1.1 /usr/lib64/libcrypto.so.1.1</code></pre> 
<p id="u26d0c186">再次启动NodeManager</p> 
<p class="img-center"><img alt="" height="677" id="u15113e38" src="https://images2.imgbox.com/05/a7/q26AcgBI_o.png" width="1200"></p> 
<p id="u17ead0ed"></p> 
<p id="u77b1b93e"></p> 
<p id="u9c7c3df7">认证过后，运行任务可能报HDFS访问的权限问题：</p> 
<p class="img-center"><img alt="" height="733" id="u75ecec84" src="https://images2.imgbox.com/b3/8a/P6sNKUcD_o.png" width="1200"></p> 
<p id="u822b759a"></p> 
<p id="u5366e130">我们修改下权限</p> 
<pre id="x4c8T"><code>kinit -kt /etc/security/keytab/nn.service.keytab nn/ddp01@WINNER.COM
hdfs dfs -chmod -R 777   /tmp/hadoop-yarn/</code></pre> 
<p id="ueb0f87f5"></p> 
<h3 id="SqoX1"><span style="color:#4da8ee;">4.5 hive</span></h3> 
<hr id="UTgue"> 
<p id="ua88a48f7">开启 Kerberos</p> 
<p class="img-center"><img alt="" height="743" id="uc0d526a8" src="https://images2.imgbox.com/1a/47/mRehbEPX_o.png" width="1200"></p> 
<p id="u97e3a7ad"></p> 
<p id="ue0a5464a">HiveServer2有warning信息 我们不管</p> 
<pre id="Yk9h9"><code>2024-06-21 15:05:51 INFO  HiveServer2:877 - Stopping/Disconnecting tez sessions.
2024-06-21 15:05:51 INFO  HiveServer2:883 - Stopped tez session pool manager.
2024-06-21 15:05:51 WARN  HiveServer2:1064 - Error starting HiveServer2 on attempt 1, will retry in 60000ms
java.lang.NoClassDefFoundError: org/apache/tez/dag/api/TezConfiguration
	at org.apache.hadoop.hive.ql.exec.tez.TezSessionPoolSession$AbstractTriggerValidator.startTriggerValidator(TezSessionPoolSession.java:74)
	at org.apache.hadoop.hive.ql.exec.tez.TezSessionPoolManager.initTriggers(TezSessionPoolManager.java:207)
	at org.apache.hadoop.hive.ql.exec.tez.TezSessionPoolManager.startPool(TezSessionPoolManager.java:114)
	at org.apache.hive.service.server.HiveServer2.initAndStartTezSessionPoolManager(HiveServer2.java:839)
	at org.apache.hive.service.server.HiveServer2.startOrReconnectTezSessions(HiveServer2.java:822)
	at org.apache.hive.service.server.HiveServer2.start(HiveServer2.java:745)
	at org.apache.hive.service.server.HiveServer2.startHiveServer2(HiveServer2.java:1037)
	at org.apache.hive.service.server.HiveServer2.access$1600(HiveServer2.java:140)
	at org.apache.hive.service.server.HiveServer2$StartOptionExecutor.execute(HiveServer2.java:1305)
	at org.apache.hive.service.server.HiveServer2.main(HiveServer2.java:1149)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:323)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:236)
Caused by: java.lang.ClassNotFoundException: org.apache.tez.dag.api.TezConfiguration
	at java.net.URLClassLoader.findClass(URLClassLoader.java:387)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:355)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	... 16 more
</code></pre> 
<p id="ufec0098b"></p> 
<p id="u1b0edc66">命令行show databases报错如下:</p> 
<pre id="Ceokb"><code>2024-06-25 09:26:17 WARN  ThriftCLIService:795 - Error fetching results: 
org.apache.hive.service.cli.HiveSQLException: java.io.IOException: java.io.IOException: Can't get Master Kerberos principal for use as renewer
	at org.apache.hive.service.cli.operation.SQLOperation.getNextRowSet(SQLOperation.java:465)
	at org.apache.hive.service.cli.operation.OperationManager.getOperationNextRowSet(OperationManager.java:309)
	at org.apache.hive.service.cli.session.HiveSessionImpl.fetchResults(HiveSessionImpl.java:905)
	at org.apache.hive.service.cli.CLIService.fetchResults(CLIService.java:561)
	at org.apache.hive.service.cli.thrift.ThriftCLIService.FetchResults(ThriftCLIService.java:786)
	at org.apache.hive.service.rpc.thrift.TCLIService$Processor$FetchResults.getResult(TCLIService.java:1837)
	at org.apache.hive.service.rpc.thrift.TCLIService$Processor$FetchResults.getResult(TCLIService.java:1822)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39)
	at org.apache.hadoop.hive.metastore.security.HadoopThriftAuthBridge$Server$TUGIAssumingProcessor.process(HadoopThriftAuthBridge.java:647)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.IOException: java.io.IOException: Can't get Master Kerberos principal for use as renewer
	at org.apache.hadoop.hive.ql.exec.FetchOperator.getNextRow(FetchOperator.java:602)
	at org.apache.hadoop.hive.ql.exec.FetchOperator.pushRow(FetchOperator.java:509)
	at org.apache.hadoop.hive.ql.exec.FetchTask.fetch(FetchTask.java:146)
	at org.apache.hadoop.hive.ql.Driver.getResults(Driver.java:2691)
	at org.apache.hadoop.hive.ql.reexec.ReExecDriver.getResults(ReExecDriver.java:229)
	at org.apache.hive.service.cli.operation.SQLOperation.getNextRowSet(SQLOperation.java:460)
	... 13 more
Caused by: java.io.IOException: Can't get Master Kerberos principal for use as renewer
	at org.apache.hadoop.mapreduce.security.TokenCache.obtainTokensForNamenodesInternal(TokenCache.java:134)
	at org.apache.hadoop.mapreduce.security.TokenCache.obtainTokensForNamenodesInternal(TokenCache.java:102)
	at org.apache.hadoop.mapreduce.security.TokenCache.obtainTokensForNamenodes(TokenCache.java:81)
	at org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:221)
	at org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:332)
	at org.apache.hadoop.hive.ql.exec.FetchOperator.generateWrappedSplits(FetchOperator.java:425)
	at org.apache.hadoop.hive.ql.exec.FetchOperator.getNextSplits(FetchOperator.java:395)
	at org.apache.hadoop.hive.ql.exec.FetchOperator.getRecordReader(FetchOperator.java:314)
	at org.apache.hadoop.hive.ql.exec.FetchOperator.getNextRow(FetchOperator.java:540)
	... 18 more
</code></pre> 
<p id="u0d5c291b">执行 insert 语句报错如下：</p> 
<pre id="jYFqq"><code>2024-06-25 14:20:56,454 Stage-1 map = 0%,  reduce = 0%
2024-06-25 14:20:56 INFO  Task:1224 - 2024-06-25 14:20:56,454 Stage-1 map = 0%,  reduce = 0%
2024-06-25 14:20:56 WARN  Counters:235 - Group org.apache.hadoop.mapred.Task$Counter is deprecated. Use org.apache.hadoop.mapreduce.TaskCounter instead
Ended Job = job_1719295126228_0001 with errors
2024-06-25 14:20:56 ERROR Task:1247 - Ended Job = job_1719295126228_0001 with errors
Error during job, obtaining debugging information...
2024-06-25 14:20:56 ERROR Task:1247 - Error during job, obtaining debugging information...
2024-06-25 14:20:57 INFO  YarnClientImpl:504 - Killed application application_1719295126228_0001
2024-06-25 14:20:57 INFO  ReOptimizePlugin:70 - ReOptimization: retryPossible: false
FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask
2024-06-25 14:20:57 ERROR Driver:1247 - FAILED: Execution Error, return code 2 from org.apache.hadoop.hive.ql.exec.mr.MapRedTask
MapReduce Jobs Launched: 
2024-06-25 14:20:57 INFO  Driver:1224 - MapReduce Jobs Launched: 
2024-06-25 14:20:57 WARN  Counters:235 - Group FileSystemCounters is deprecated. Use org.apache.hadoop.mapreduce.FileSystemCounter instead
Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
2024-06-25 14:20:57 INFO  Driver:1224 - Stage-Stage-1:  HDFS Read: 0 HDFS Write: 0 FAIL
Total MapReduce CPU Time Spent: 0 msec
2024-06-25 14:20:57 INFO  Driver:1224 - Total MapReduce CPU Time Spent: 0 msec
2024-06-25 14:20:57 INFO  Driver:2531 - Completed executing command(queryId=hdfs_20240625142022_e1ec801e-ee1d-411e-b96d-d4141b5e2918); Time taken: 33.984 seconds
2024-06-25 14:20:57 INFO  Driver:285 - Concurrency mode is disabled, not creating a lock manager
2024-06-25 14:20:57 INFO  HiveConf:5034 - Using the default value passed in for log id: 202267cf-76bc-43ff-8545-67bd0b4d73ce
2024-06-25 14:20:57 INFO  SessionState:449 - Resetting thread name to  main
</code></pre> 
<p id="u2e80fbe6">如上问题是 没有安装yarn 服务，大意了，这种服务组件强依赖的检查机制还需要升级一下。</p> 
<p id="ucff93880"></p> 
<hr id="i6RUZ"> 
<p id="u8eebca5e">DDP集成rananger:</p> 
<p id="u1e52fce1"><a href="https://www.yuque.com/ugouth/rgxsow/kabqlnbtrgmewn09?singleDoc=" rel="nofollow" title="datasophon集成rangerusersync · 语雀">datasophon集成rangerusersync · 语雀</a></p> 
<p id="uc1054414">DDP集成Hue:</p> 
<p id="u1f10a6bf"><a href="https://www.yuque.com/ugouth/blldor/vhaduiq39kpu317p?singleDoc#%20%E3%80%8Adatasophon%E9%9B%86%E6%88%90hue%E3%80%8B" rel="nofollow" title="datasophon集成hue · 语雀">datasophon集成hue · 语雀</a></p> 
<p id="u9543c832"><a href="https://www.cnblogs.com/yjt1993/p/11769541.html" rel="nofollow" title="zookeeper、hbase集成kerberos - 北漂-boy - 博客园">zookeeper、hbase集成kerberos - 北漂-boy - 博客园</a></p> 
<p id="u2280e36f"><a href="https://blog.csdn.net/sahtk89452/article/details/137482409" title="Kerberos安全认证-连载11-HBase Kerberos安全配置及访问_kerberos hbase(4)_hbase2.2.6适配java版本-CSDN博客">Kerberos安全认证-连载11-HBase Kerberos安全配置及访问_kerberos hbase(4)_hbase2.2.6适配java版本-CSDN博客</a></p> 
<p id="uc513c3ea">HBase 官网：<a href="https://hbase.apache.org/book.html#hadoop" rel="nofollow" title="Apache HBase® Reference Guide">Apache HBase® Reference Guide</a></p> 
<p id="u5b4e9889"><a href="https://blog.csdn.net/sahtk89452/article/details/137482409" title="Kerberos安全认证-连载11-HBase Kerberos安全配置及访问_kerberos hbase(4)_hbase 配置 kerberos 认证-CSDN博客">Kerberos安全认证-连载11-HBase Kerberos安全配置及访问_kerberos hbase(4)_hbase 配置 kerberos 认证-CSDN博客</a></p> 
<p id="u82847ab4">/opt/datasophon/hadoop-3.3.3/ranger-hdfs-plugin/enable-hdfs-plugin.sh</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/890d45d77f5f87016a1b4d9eda3ae7c9/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">GNU/Linux - Linux Kernel Device model</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/542f7906705c6a3388bfb5da4cab0bbe/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">实战大数据：分布式大数据分析处理系统的开发与应用</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>