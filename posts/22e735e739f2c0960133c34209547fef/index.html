<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【AI】在docker中部署ollama体验AI模型 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/22e735e739f2c0960133c34209547fef/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="【AI】在docker中部署ollama体验AI模型">
  <meta property="og:description" content="在docker中部署ollama体验AI模型 1.docker部署ollama1.1.CPU模式1.2.GPU模式（需要有NVIDIA显卡支持）1.2.1.安装英伟达容器工具包（以Ubuntu22.04为例）1.2.2.docker使用GPU运行ollama 2.docker部署ollama web ui3.使用docker中的ollama下载并运行AI模型（示例为阿里通义千问4b-chat）4.ollama模型仓库（可以选择自己想用的模型安装体验） 1.docker部署ollama 1.1.CPU模式 docker run -d -v /opt/ai/ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama 1.2.GPU模式（需要有NVIDIA显卡支持） 1.2.1.安装英伟达容器工具包（以Ubuntu22.04为例） 其他系统请参考：英伟达官方文档
# 1.配置apt源 curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \ &amp;&amp; curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \ sed &#39;s#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g&#39; | \ sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list # 2.更新源 sudo apt-get update # 3.安装工具包 sudo apt-get install -y nvidia-container-toolkit 1.2.2.docker使用GPU运行ollama docker run --gpus all -d -v /opt/ai/ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama 2.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-04-17T15:23:18+08:00">
    <meta property="article:modified_time" content="2024-04-17T15:23:18+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【AI】在docker中部署ollama体验AI模型</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-dracula">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>在docker中部署ollama体验AI模型</h4> 
 <ul><li><a href="#1dockerollama_1" rel="nofollow">1.docker部署ollama</a></li><li><ul><li><a href="#11CPU_2" rel="nofollow">1.1.CPU模式</a></li><li><a href="#12GPUNVIDIA_6" rel="nofollow">1.2.GPU模式（需要有NVIDIA显卡支持）</a></li><li><ul><li><a href="#121Ubuntu2204_7" rel="nofollow">1.2.1.安装英伟达容器工具包（以Ubuntu22.04为例）</a></li><li><a href="#122dockerGPUollama_20" rel="nofollow">1.2.2.docker使用GPU运行ollama</a></li></ul> 
  </li></ul> 
  </li><li><a href="#2dockerollama_web_ui_24" rel="nofollow">2.docker部署ollama web ui</a></li><li><a href="#3dockerollamaAI4bchat_28" rel="nofollow">3.使用docker中的ollama下载并运行AI模型（示例为阿里通义千问4b-chat）</a></li><li><a href="#4ollama_32" rel="nofollow">4.ollama模型仓库（可以选择自己想用的模型安装体验）</a></li></ul> 
</div> 
<p></p> 
<h2><a id="1dockerollama_1"></a>1.docker部署ollama</h2> 
<h3><a id="11CPU_2"></a>1.1.CPU模式</h3> 
<pre><code class="prism language-sh"><span class="token function">docker</span> run <span class="token parameter variable">-d</span> <span class="token parameter variable">-v</span> /opt/ai/ollama:/root/.ollama <span class="token parameter variable">-p</span> <span class="token number">11434</span>:11434 <span class="token parameter variable">--name</span> ollama ollama/ollama
</code></pre> 
<h3><a id="12GPUNVIDIA_6"></a>1.2.GPU模式（需要有NVIDIA显卡支持）</h3> 
<h4><a id="121Ubuntu2204_7"></a>1.2.1.安装英伟达容器工具包（以Ubuntu22.04为例）</h4> 
<p>其他系统请参考：<a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/arch-overview.html" rel="nofollow">英伟达官方文档</a></p> 
<pre><code class="prism language-sh"><span class="token comment"># 1.配置apt源</span>
<span class="token function">curl</span> <span class="token parameter variable">-fsSL</span> https://nvidia.github.io/libnvidia-container/gpgkey <span class="token operator">|</span> <span class="token function">sudo</span> gpg <span class="token parameter variable">--dearmor</span> <span class="token parameter variable">-o</span> /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg <span class="token punctuation">\</span>
  <span class="token operator">&amp;&amp;</span> <span class="token function">curl</span> <span class="token parameter variable">-s</span> <span class="token parameter variable">-L</span> https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list <span class="token operator">|</span> <span class="token punctuation">\</span>
    <span class="token function">sed</span> <span class="token string">'s#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g'</span> <span class="token operator">|</span> <span class="token punctuation">\</span>
    <span class="token function">sudo</span> <span class="token function">tee</span> /etc/apt/sources.list.d/nvidia-container-toolkit.list
<span class="token comment"># 2.更新源</span>
<span class="token function">sudo</span> <span class="token function">apt-get</span> update
<span class="token comment"># 3.安装工具包</span>
<span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> <span class="token parameter variable">-y</span> nvidia-container-toolkit
</code></pre> 
<h4><a id="122dockerGPUollama_20"></a>1.2.2.docker使用GPU运行ollama</h4> 
<pre><code class="prism language-sh"><span class="token function">docker</span> run <span class="token parameter variable">--gpus</span> all <span class="token parameter variable">-d</span> <span class="token parameter variable">-v</span> /opt/ai/ollama:/root/.ollama <span class="token parameter variable">-p</span> <span class="token number">11434</span>:11434 <span class="token parameter variable">--name</span> ollama ollama/ollama
</code></pre> 
<h2><a id="2dockerollama_web_ui_24"></a>2.docker部署ollama web ui</h2> 
<pre><code class="prism language-sh"><span class="token function">docker</span> run <span class="token parameter variable">-d</span> <span class="token parameter variable">-p</span> <span class="token number">8080</span>:8080 --add-host<span class="token operator">=</span>host.docker.internal:host-gateway <span class="token parameter variable">--name</span> ollama-webui <span class="token parameter variable">--restart</span> always ghcr.io/ollama-webui/ollama-webui:main
</code></pre> 
<h2><a id="3dockerollamaAI4bchat_28"></a>3.使用docker中的ollama下载并运行AI模型（示例为阿里通义千问4b-chat）</h2> 
<pre><code class="prism language-sh"><span class="token function">docker</span> <span class="token builtin class-name">exec</span> <span class="token parameter variable">-it</span> ollama ollama run qwen:4b-chat
</code></pre> 
<h2><a id="4ollama_32"></a>4.ollama模型仓库（可以选择自己想用的模型安装体验）</h2> 
<p><a href="https://ollama.com/library" rel="nofollow">ollama模型仓库</a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/77d2d11e10e078ed8c65a0da1510de65/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">WebGIS面试题（第五期）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/f9674090e0e8b5eb61f3b99d62e6b0f9/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">网上订餐系统|基于springboot的网上订餐系统设计与实现(源码&#43;数据库&#43;文档)</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>