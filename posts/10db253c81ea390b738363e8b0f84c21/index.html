<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Hadoop3.x完全分布式模式下slaveDataNode节点未启动调整 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/10db253c81ea390b738363e8b0f84c21/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="Hadoop3.x完全分布式模式下slaveDataNode节点未启动调整">
  <meta property="og:description" content="目录
前言
一、问题重现
1、查询Hadoop版本
2、集群启动Hadoop
二、问题分析
三、Hadoop3.x的集群配置
1、停止Hadoop服务
2、配置workers
3、从节点检测
4、WebUI监控
总结
前言 在大数据的世界里，Hadoop绝对是一个值得学习的框架。关于Hadoop的知识，有很多博主和视频博主都做了很详细的教程，感兴趣的朋友甚至可以去官网看看。比如其分布式架构的实现，在这里都不在赘述，大家可以通过多种途径进行学习。
这篇博客出现得场景缘由是最近基于Hbase2.4.11搭建完全分布式集群，集群的节点是3。至于为什么是3，主要是机器有限，而且是同一台物理主机上进行虚拟搭建的。Hbase的底层存储是存放在Hdfs中的，由此必须要安装Hadoop。
众所周知，在完全分布式环境下，我们可以只在Master节点上直接运行start-all.sh命令，整个集群都会自动启动。本文描述的是在Hadoop3.1.3的完全分布式环境下，slave节点的DataNode节点未能成功启动的问题以及通过修改配置来解决的办法，希望能帮助到遇到这个问题的朋友。请注意，由于不同的版本，可能解决办法不一致，请谨慎参考。博主就遇到过，在Hadoop2.x的配置和Hadoop3.x的配置不一致的问题。博文的参考仅限于Hadoop3.x，如果您使用的不是这个系列的版本，那么您可以去别的地方寻找答案。
一、问题重现 1、查询Hadoop版本 使用管理账号登录到系统，使用hadoop version可以查看版本。
[root@master bin]# hadoop version 可以看到输出如下：
Hadoop 3.1.3 Source code repository https://gitbox.apache.org/repos/asf/hadoop.git -r ba631c436b806728f8ec2f54ab1e289526c90579 Compiled by ztang on 2019-09-12T02:47Z Compiled with protoc 2.5.0 From source with checksum ec785077c385118ac91aadde5ec9799 This command was run using /software/hadoop/share/hadoop/common/hadoop-common-3.1.3.jar 2、集群启动Hadoop 登录master节点，进入hadoop的sbin目录，启动集群，参考命令如下：
[root@master bin]# cd /software/hadoop/sbin [root@master sbin]# ./start-all.sh 这里请注意，hadoop的安装目录，请根据实际目录进行修改，否则会影响运行。通常以上命令后会有以下输出。输出以下姓名就表示已经完成了hadoop的启动。
Starting namenodes on [master] 上一次登录：三 12月 13 11:31:20 CST 2023pts/0 上 Starting datanodes 上一次登录：三 12月 13 11:31:39 CST 2023pts/0 上 Starting secondary namenodes [master] 上一次登录：三 12月 13 11:31:41 CST 2023pts/0 上 Starting resourcemanager 上一次登录：三 12月 13 11:31:44 CST 2023pts/0 上 Starting nodemanagers 上一次登录：三 12月 13 11:31:48 CST 2023pts/0 上 如果是正常的集群启动，那么master、slave1、slave2三台机器上都会有DataNode进程。可以分别在三台机器上进行进程查询，这里使用jps命令。">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2023-12-19T06:30:00+08:00">
    <meta property="article:modified_time" content="2023-12-19T06:30:00+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Hadoop3.x完全分布式模式下slaveDataNode节点未启动调整</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2><a id="_0"></a></h2> 
<p id="main-toc"><strong>目录</strong></p> 
<p id="-toc" style="margin-left:0px;"></p> 
<p id="%E5%89%8D%E8%A8%80-toc" style="margin-left:0px;"><a href="#%E5%89%8D%E8%A8%80" rel="nofollow">前言</a></p> 
<p id="%E4%B8%80%E3%80%81%E9%97%AE%E9%A2%98%E9%87%8D%E7%8E%B0-toc" style="margin-left:0px;"><a href="#%E4%B8%80%E3%80%81%E9%97%AE%E9%A2%98%E9%87%8D%E7%8E%B0" rel="nofollow">一、问题重现</a></p> 
<p id="1%E3%80%81%E6%9F%A5%E8%AF%A2Hadoop%E7%89%88%E6%9C%AC-toc" style="margin-left:40px;"><a href="#1%E3%80%81%E6%9F%A5%E8%AF%A2Hadoop%E7%89%88%E6%9C%AC" rel="nofollow">1、查询Hadoop版本</a></p> 
<p id="%C2%A02%E3%80%81%E9%9B%86%E7%BE%A4%E5%90%AF%E5%8A%A8Hadoop-toc" style="margin-left:40px;"><a href="#%C2%A02%E3%80%81%E9%9B%86%E7%BE%A4%E5%90%AF%E5%8A%A8Hadoop" rel="nofollow"> 2、集群启动Hadoop</a></p> 
<p id="%E4%BA%8C%E3%80%81%E9%97%AE%E9%A2%98%E5%88%86%E6%9E%90-toc" style="margin-left:0px;"><a href="#%E4%BA%8C%E3%80%81%E9%97%AE%E9%A2%98%E5%88%86%E6%9E%90" rel="nofollow">二、问题分析</a></p> 
<p id="%E4%B8%89%E3%80%81Hadoop3.x%E7%9A%84%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE-toc" style="margin-left:0px;"><a href="#%E4%B8%89%E3%80%81Hadoop3.x%E7%9A%84%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE" rel="nofollow">三、Hadoop3.x的集群配置</a></p> 
<p id="1%E3%80%81%E5%81%9C%E6%AD%A2Hadoop%E6%9C%8D%E5%8A%A1-toc" style="margin-left:40px;"><a href="#1%E3%80%81%E5%81%9C%E6%AD%A2Hadoop%E6%9C%8D%E5%8A%A1" rel="nofollow">1、停止Hadoop服务</a></p> 
<p id="2%E3%80%81%E9%85%8D%E7%BD%AEworkers-toc" style="margin-left:40px;"><a href="#2%E3%80%81%E9%85%8D%E7%BD%AEworkers" rel="nofollow">2、配置workers</a></p> 
<p id="3%E3%80%81%E4%BB%8E%E8%8A%82%E7%82%B9%E6%A3%80%E6%B5%8B-toc" style="margin-left:40px;"><a href="#3%E3%80%81%E4%BB%8E%E8%8A%82%E7%82%B9%E6%A3%80%E6%B5%8B" rel="nofollow">3、从节点检测</a></p> 
<p id="4%E3%80%81WebUI%E7%9B%91%E6%8E%A7-toc" style="margin-left:40px;"><a href="#4%E3%80%81WebUI%E7%9B%91%E6%8E%A7" rel="nofollow">4、WebUI监控</a></p> 
<p id="%E6%80%BB%E7%BB%93-toc" style="margin-left:0px;"><a href="#%E6%80%BB%E7%BB%93" rel="nofollow">总结</a></p> 
<hr id="hr-toc"> 
<p></p> 
<h2 id="%E5%89%8D%E8%A8%80">前言</h2> 
<p>        在大数据的世界里，Hadoop绝对是一个值得学习的框架。关于Hadoop的知识，有很多博主和视频博主都做了很详细的教程，感兴趣的朋友甚至可以去官网看看。比如其分布式架构的实现，在这里都不在赘述，大家可以通过多种途径进行学习。</p> 
<p>        这篇博客出现得场景缘由是最近基于Hbase2.4.11搭建完全分布式集群，集群的节点是3。至于为什么是3，主要是机器有限，而且是同一台物理主机上进行虚拟搭建的。Hbase的底层存储是存放在Hdfs中的，由此必须要安装Hadoop。</p> 
<p>        众所周知，在完全分布式环境下，我们可以只在Master节点上直接运行start-all.sh命令，整个集群都会自动启动。本文描述的是在Hadoop3.1.3的完全分布式环境下，slave节点的DataNode节点未能成功启动的问题以及通过修改配置来解决的办法，希望能帮助到遇到这个问题的朋友。请注意，由于不同的版本，可能解决办法不一致，请谨慎参考。博主就遇到过，在Hadoop2.x的配置和Hadoop3.x的配置不一致的问题。博文的参考仅限于Hadoop3.x，如果您使用的不是这个系列的版本，那么您可以去别的地方寻找答案。</p> 
<h2 id="%E4%B8%80%E3%80%81%E9%97%AE%E9%A2%98%E9%87%8D%E7%8E%B0">一、问题重现</h2> 
<h3 id="1%E3%80%81%E6%9F%A5%E8%AF%A2Hadoop%E7%89%88%E6%9C%AC">1、查询Hadoop版本</h3> 
<p>        使用管理账号登录到系统，使用hadoop version可以查看版本。</p> 
<pre><code class="language-bash">[root@master bin]# hadoop version</code></pre> 
<p>         可以看到输出如下：</p> 
<pre><code class="language-bash">Hadoop 3.1.3
Source code repository https://gitbox.apache.org/repos/asf/hadoop.git -r ba631c436b806728f8ec2f54ab1e289526c90579
Compiled by ztang on 2019-09-12T02:47Z
Compiled with protoc 2.5.0
From source with checksum ec785077c385118ac91aadde5ec9799
This command was run using /software/hadoop/share/hadoop/common/hadoop-common-3.1.3.jar</code></pre> 
<p><img alt="" height="90" src="https://images2.imgbox.com/7f/34/rUwkWYwB_o.png" width="554"></p> 
<h3 id="%C2%A02%E3%80%81%E9%9B%86%E7%BE%A4%E5%90%AF%E5%8A%A8Hadoop"> 2、集群启动Hadoop</h3> 
<p>         登录master节点，进入hadoop的sbin目录，启动集群，参考命令如下：</p> 
<pre><code class="language-bash">[root@master bin]# cd /software/hadoop/sbin
[root@master sbin]# ./start-all.sh</code></pre> 
<p>        这里请注意，hadoop的安装目录，请根据实际目录进行修改，否则会影响运行。通常以上命令后会有以下输出。输出以下姓名就表示已经完成了hadoop的启动。</p> 
<pre><code class="language-bash">Starting namenodes on [master]
上一次登录：三 12月 13 11:31:20 CST 2023pts/0 上
Starting datanodes
上一次登录：三 12月 13 11:31:39 CST 2023pts/0 上
Starting secondary namenodes [master]
上一次登录：三 12月 13 11:31:41 CST 2023pts/0 上
Starting resourcemanager
上一次登录：三 12月 13 11:31:44 CST 2023pts/0 上
Starting nodemanagers
上一次登录：三 12月 13 11:31:48 CST 2023pts/0 上</code></pre> 
<p><img alt="" height="180" src="https://images2.imgbox.com/8c/cd/xErh8TDP_o.png" width="387"></p> 
<p>        如果是正常的集群启动，那么master、slave1、slave2三台机器上都会有DataNode进程。可以分别在三台机器上进行进程查询，这里使用jps命令。</p> 
<p>        Master进程如下：</p> 
<pre><code class="language-bash">[root@master sbin]# jps
9351 NameNode
1608 QuorumPeerMain
10537 Jps
9755 SecondaryNameNode
10027 ResourceManager
10365 NodeManager
9535 DataNode</code></pre> 
<p>        我们可以发现，Master上，NodeManager、NameNode、DataNode服务都是正常的。然后登录到slave1和slave2两台服务器上，同样使用jps命令查看机器进程。</p> 
<pre><code class="language-bash">slave1上进程
[root@slave1 hadoop]# jps
4113 Jps
1605 QuorumPeerMain</code></pre> 
<p>        同样的，在slave2上也是一样的问题，从节点的DataNode并没有启动，这样子相当于集群启动失败。此时只有master一个节点进行对外提供服务，显然这不是很妙。</p> 
<h2 id="%E4%BA%8C%E3%80%81%E9%97%AE%E9%A2%98%E5%88%86%E6%9E%90">二、问题分析</h2> 
<p>        其实出现这个问题的原因也比较简单，还是集群设置的问题。在进行大数据各个组件的学习时，一定要注意版本，不同的版本配置的方式不一样，有可能配置目录或者配置文件修改修改了。因此最好是按照官网的说明进行配置最好。本文描述的问题，是因为在Hadoop3.x版本中，集群配置的设置文件是workers而不是slaves，slaves应该是之前的版本的集群配置。</p> 
<h2 id="%E4%B8%89%E3%80%81Hadoop3.x%E7%9A%84%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE">三、Hadoop3.x的集群配置</h2> 
<h3 id="1%E3%80%81%E5%81%9C%E6%AD%A2Hadoop%E6%9C%8D%E5%8A%A1">1、停止Hadoop服务</h3> 
<p>        执行以下命令，停止Hadoop服务。</p> 
<pre><code class="language-bash">[root@master sbin]# ./stop-all.sh
Stopping namenodes on [master]
上一次登录：三 12月 13 11:08:17 CST 2023pts/0 上
Stopping datanodes
上一次登录：三 12月 13 11:31:13 CST 2023pts/0 上
Stopping secondary namenodes [master]
上一次登录：三 12月 13 11:31:14 CST 2023pts/0 上
Stopping nodemanagers
上一次登录：三 12月 13 11:31:16 CST 2023pts/0 上
Stopping resourcemanager
上一次登录：三 12月 13 11:31:18 CST 2023pts/0 上</code></pre> 
<p><img alt="" height="168" src="https://images2.imgbox.com/94/64/wBOQRjbj_o.png" width="387"></p> 
<h3 id="2%E3%80%81%E9%85%8D%E7%BD%AEworkers">2、配置workers</h3> 
<p><img alt="" height="31" src="https://images2.imgbox.com/c0/f6/Lra97441_o.png" width="597"></p> 
<pre><code class="language-bash">capacity-scheduler.xml  hadoop-env.cmd              hadoop-user-functions.sh.example  httpfs-signature.secret  kms-log4j.properties  mapred-env.sh               slaves                         workers                       yarn-site.xml
configuration.xsl       hadoop-env.sh               hdfs-site.xml                     httpfs-site.xml          kms-site.xml          mapred-queues.xml.template  ssl-client.xml.example         yarn-env.cmd
container-executor.cfg  hadoop-metrics2.properties  httpfs-env.sh                     kms-acls.xml             log4j.properties      mapred-site.xml             ssl-server.xml.example         yarn-env.sh
core-site.xml           hadoop-policy.xml           httpfs-log4j.properties           kms-env.sh               mapred-env.cmd        shellprofile.d              user_ec_policies.xml.template  yarnservice-log4j.properties</code></pre> 
<p>        首先使用cat命令查看默认的配置，</p> 
<pre><code class="language-bash">cat workers</code></pre> 
<p>        可以看到workers的内容如下：</p> 
<pre><code class="language-bash">localhost</code></pre> 
<p>        即默认的情况下，Hadoop在本机启动，不加入分布式集群，因此无法随着集群的启动而启动。所以我们要把机器加入到集群环境中，在workers文件中，将master、slave1、slave2追加进去。</p> 
<pre><code class="language-bash">Vi workers</code></pre> 
<pre><code class="language-bash">master
slave1
slave2</code></pre> 
<p>        配置完成后，可以使用scp命令复制到slave1和slave2节点，也可以使用同样的方式进行修改。修改完成后保存相应配置。最后到master的机器上，重启集群。</p> 
<pre><code class="language-bash">[root@master sbin]# ./start-all.sh</code></pre> 
<pre><code class="language-bash">Starting namenodes on [master]
上一次登录：三 12月 13 11:31:20 CST 2023pts/0 上
Starting datanodes
上一次登录：三 12月 13 11:31:39 CST 2023pts/0 上
Starting secondary namenodes [master]
上一次登录：三 12月 13 11:31:41 CST 2023pts/0 上
Starting resourcemanager
上一次登录：三 12月 13 11:31:44 CST 2023pts/0 上
Starting nodemanagers
上一次登录：三 12月 13 11:31:48 CST 2023pts/0 上</code></pre> 
<p><img alt="" height="172" src="https://images2.imgbox.com/6a/b9/SoCNVMVI_o.png" width="367"></p> 
<h3 id="3%E3%80%81%E4%BB%8E%E8%8A%82%E7%82%B9%E6%A3%80%E6%B5%8B">3、从节点检测</h3> 
<p>        在master节点上运行start-all.sh后，分别在slave1、slave2两台机器上进行进程检测。执行命令如下：</p> 
<pre><code class="language-bash">[root@slave1 hadoop]# jps
3841 DataNode
4145 Jps
1605 QuorumPeerMain
3960 NodeManager</code></pre> 
<p><img alt="" height="85" src="https://images2.imgbox.com/a1/ec/gNfmvrjw_o.png" width="249"></p> 
<p>        我们发现，DataNode和NodeManager进程都已经正常启动，slave2也是一样的。由此，Hadoop3.x集群服务完全启动。</p> 
<h3 id="4%E3%80%81WebUI%E7%9B%91%E6%8E%A7">4、WebUI监控</h3> 
<p>        除了使用命令行的方式监控hadoop，其内部也提供了webui的监控方式。</p> 
<p class="img-center"><img alt="" height="164" src="https://images2.imgbox.com/e2/df/gfwORvgw_o.png" width="553"></p> 
<p class="img-center"><img alt="" height="412" src="https://images2.imgbox.com/80/d5/fJ40MjuR_o.png" width="553"></p> 
<p class="img-center"><img alt="" height="268" src="https://images2.imgbox.com/62/9d/iBORw0QL_o.png" width="552"></p> 
<h2 id="%E6%80%BB%E7%BB%93">总结</h2> 
<p>         以上就是本文的主要内容，本文描述的是在Hadoop3.1.3的完全分布式环境下，slave节点的DataNode节点未能成功启动的问题以及通过修改配置来解决的办法，希望能帮助到遇到这个问题的朋友。行文仓促，有很多不当之处，请朋友们批评指正。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/d4407673eb482f5e922c05b0c52360ea/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">免费实用的 Redis 可视化工具推荐, Redis DeskTop Manager 及 Another Redis Desktop Manager 的安装与使用，Redis Insight 下载安装</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/2872d8d8b8f2bc569a1ac865662ed2ab/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【MySQL】窗口函数详解（概念&#43;练习&#43;实战）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>