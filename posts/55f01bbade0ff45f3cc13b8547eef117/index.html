<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>用自然语言来编程GitHub Copilot；提高代码质量开源工具GPTLint；LLMs开源医学Meditron - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/55f01bbade0ff45f3cc13b8547eef117/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="用自然语言来编程GitHub Copilot；提高代码质量开源工具GPTLint；LLMs开源医学Meditron">
  <meta property="og:description" content="✨ 1: GitHub Copilot Workspace 以Copilot 为中心的创新开发者环境，让开发者能用自然语言从构思到编码再到软件开发。
GitHub Copilot Workspace是一个以Copilot为中心的开发者环境，旨在使用自然语言从构思、编码到软件开发的全过程中提供帮助。它标志着开发环境的一次重大变革，通过不同的Copilot-powered代理从开始到结束提供支持，同时让开发者完全控制整个过程。
GitHub Copilot Workspace是为了降低软件开发的门槛，加速从想法到实现的过程，特别适合那些希望提升生产力、优化团队协作和利用AI技术来简化开发工作的专业和业余开发者。
地址：https://github.blog/2024-04-29-github-copilot-workspace/
✨ 2: 神秘的gpt2-chatbot 神秘的gpt2-chatbot 表现和GPT4不分上下
一个名为&#34;gpt2-chatbot&#34;的神秘大模型在AI社区引起了轰动，其性能被认为超越了GPT-4，引发了广泛的讨论和猜测。
有人认为&#34;gpt2-chatbot&#34;可能是GPT-4.5、GPT-5或者是一个真正的GPT-2模型，其输出质量和表现引发了对其真实身份的猜测和讨论。
地址：https://chat.lmsys.org/
✨ 3: GPTLint 基于大型语言模型的提高代码质量工具
GPTLint是一款基于大型语言模型（LLMs）的代码质量工具，其设计初衷是为了在代码库中强制执行更高层次的最佳实践，超越了传统的静态分析工具如eslint所能达到的水平。
GPTLint能够识别和推荐改善代码质量的做法，这些是基于抽象语法树（AST）的方法无法实现的。
GPTLint是为那些追求代码质量，特别是在执行高层次最佳实践方面不惜一切代价的开发者和团队设计的。无论是想超越传统静态分析工具的限制，还是希望在项目中引入更先进的代码审查机制，GPTLint提供了一种新颖的解决方案。
地址：https://github.com/gptlint/gptlint
✨ 4: Meditron 基于大型语言模型（LLMs）的开源医学套件
Meditron是一个基于大型语言模型（LLMs）的开源医学套件，主要包括Meditron-7B和Meditron-70B两个模型。这些模型是通过在丰富的医学领域语料上持续进行预训练，从Llama-2模型调整而来的，涵盖了精选的PubMed论文摘要、国际认可的医学指南新数据集，以及广泛的通用领域语料。
Meditron特别适用于多种医学推理任务，并且经过相关数据的微调后，其表现超越了Llama-2-70B、GPT-3.5和Flan-PaLM等先前的模型。
模型地址：https://huggingface.co/epfl-llm
Meditron提供了一个强大的工具集，旨在通过高质量的医学大语言模型支持医疗保健行业的各项需求。然而，考虑到其对安全性和适用性的限制，应谨慎使用，并在具体投入使用前进行充分测试。
地址：https://github.com/epfLLM/meditron
✨ 5: Chinese-LLaMA-Alpaca-3 一代开源大模型Llama-3开发的项目，专注于中文语言处理
该项目提供了两个核心模型：中文Llama-3基座模型和中文Llama-3-Instruct指令精调大模型。这些模型利用大规模中文数据进行增量预训练，并利用精选指令数据进行精调，以进一步提升中文语义理解和指令执行能力。
Chinese-LLaMA-Alpaca-3项目为中文自然语言处理领域的研究者和开发者提供了一个高质量的资源，可以用于教育、研究以及商业探索。无论是深入研究大模型的内部机制，还是开发实用的应用程序，该项目都提供了强有力的支持。
地址：https://github.com/ymcui/Chinese-LLaMA-Alpaca-3
更多AI工具，参考国内AiBard123，Github-AiBard123">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-04-30T15:35:39+08:00">
    <meta property="article:modified_time" content="2024-04-30T15:35:39+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">用自然语言来编程GitHub Copilot；提高代码质量开源工具GPTLint；LLMs开源医学Meditron</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-tomorrow-night">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h4><a id="__1__GitHub_Copilot_Workspace_httpsgithubblog20240429githubcopilotworkspace_2"></a><a href="https://github.blog/2024-04-29-github-copilot-workspace/" rel="nofollow"> ✨ 1: GitHub Copilot Workspace </a></h4> 
<p>以Copilot 为中心的创新开发者环境，让开发者能用自然语言从构思到编码再到软件开发。</p> 
<p><img src="https://images2.imgbox.com/c7/47/crVxHRtt_o.jpg" alt="在这里插入图片描述"></p> 
<p>GitHub Copilot Workspace是一个以Copilot为中心的开发者环境，旨在使用自然语言从构思、编码到软件开发的全过程中提供帮助。它标志着开发环境的一次重大变革，通过不同的Copilot-powered代理从开始到结束提供支持，同时让开发者完全控制整个过程。</p> 
<p>GitHub Copilot Workspace是为了降低软件开发的门槛，加速从想法到实现的过程，特别适合那些希望提升生产力、优化团队协作和利用AI技术来简化开发工作的专业和业余开发者。</p> 
<p>地址：https://github.blog/2024-04-29-github-copilot-workspace/</p> 
<h4><a id="__2__gpt2chatbot_httpschatlmsysorg_17"></a><a href="https://chat.lmsys.org/" rel="nofollow"> ✨ 2: 神秘的gpt2-chatbot </a></h4> 
<p>神秘的gpt2-chatbot 表现和GPT4不分上下</p> 
<p><img src="https://images2.imgbox.com/b7/41/xLdCcYpR_o.jpg" alt="在这里插入图片描述"></p> 
<p>一个名为"gpt2-chatbot"的神秘大模型在AI社区引起了轰动，其性能被认为超越了GPT-4，引发了广泛的讨论和猜测。</p> 
<p>有人认为"gpt2-chatbot"可能是GPT-4.5、GPT-5或者是一个真正的GPT-2模型，其输出质量和表现引发了对其真实身份的猜测和讨论。</p> 
<p>地址：https://chat.lmsys.org/</p> 
<h4><a id="__3__GPTLint_httpsgithubcomgptlintgptlint_33"></a><a href="https://github.com/gptlint/gptlint"> ✨ 3: GPTLint </a></h4> 
<p>基于大型语言模型的提高代码质量工具</p> 
<p><img src="https://images2.imgbox.com/f7/0f/vwpxh2wM_o.jpg" alt="在这里插入图片描述"></p> 
<p>GPTLint是一款基于大型语言模型（LLMs）的代码质量工具，其设计初衷是为了在代码库中强制执行更高层次的最佳实践，超越了传统的静态分析工具如<code>eslint</code>所能达到的水平。</p> 
<p>GPTLint能够识别和推荐改善代码质量的做法，这些是基于抽象语法树（AST）的方法无法实现的。</p> 
<p>GPTLint是为那些追求代码质量，特别是在执行高层次最佳实践方面不惜一切代价的开发者和团队设计的。无论是想超越传统静态分析工具的限制，还是希望在项目中引入更先进的代码审查机制，GPTLint提供了一种新颖的解决方案。</p> 
<p>地址：https://github.com/gptlint/gptlint</p> 
<h4><a id="__4__Meditron_httpsgithubcomepfLLMmeditron_51"></a><a href="https://github.com/epfLLM/meditron"> ✨ 4: Meditron </a></h4> 
<p>基于大型语言模型（LLMs）的开源医学套件</p> 
<p><img src="https://images2.imgbox.com/ec/55/JRMCnkoI_o.jpg" alt="在这里插入图片描述"></p> 
<p>Meditron是一个基于大型语言模型（LLMs）的开源医学套件，主要包括Meditron-7B和Meditron-70B两个模型。这些模型是通过在丰富的医学领域语料上持续进行预训练，从Llama-2模型调整而来的，涵盖了精选的PubMed论文摘要、国际认可的医学指南新数据集，以及广泛的通用领域语料。</p> 
<p>Meditron特别适用于多种医学推理任务，并且经过相关数据的微调后，其表现超越了Llama-2-70B、GPT-3.5和Flan-PaLM等先前的模型。</p> 
<p>模型地址：https://huggingface.co/epfl-llm</p> 
<p>Meditron提供了一个强大的工具集，旨在通过高质量的医学大语言模型支持医疗保健行业的各项需求。然而，考虑到其对安全性和适用性的限制，应谨慎使用，并在具体投入使用前进行充分测试。</p> 
<p>地址：https://github.com/epfLLM/meditron</p> 
<h4><a id="__5__ChineseLLaMAAlpaca3_httpsgithubcomymcuiChineseLLaMAAlpaca3_71"></a><a href="https://github.com/ymcui/Chinese-LLaMA-Alpaca-3"> ✨ 5: Chinese-LLaMA-Alpaca-3 </a></h4> 
<p>一代开源大模型Llama-3开发的项目，专注于中文语言处理</p> 
<p><img src="https://images2.imgbox.com/ad/f5/x1Qbk9xb_o.jpg" alt="在这里插入图片描述"></p> 
<p>该项目提供了两个核心模型：<strong>中文Llama-3基座模型</strong>和<strong>中文Llama-3-Instruct指令精调大模型</strong>。这些模型利用大规模中文数据进行增量预训练，并利用精选指令数据进行精调，以进一步提升中文语义理解和指令执行能力。</p> 
<p>Chinese-LLaMA-Alpaca-3项目为中文自然语言处理领域的研究者和开发者提供了一个高质量的资源，可以用于教育、研究以及商业探索。无论是深入研究大模型的内部机制，还是开发实用的应用程序，该项目都提供了强有力的支持。</p> 
<p>地址：https://github.com/ymcui/Chinese-LLaMA-Alpaca-3</p> 
<br> 
<br> 
<p>更多AI工具，参考<a href="https://aibard123.top/" rel="nofollow">国内AiBard123</a>，<a href="https://aibard123.com/" rel="nofollow">Github-AiBard123</a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/f22d7d3f47e3adc8c116ab6d770fc464/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Android14 普通应用registerReceiver注册广播报错One of RECEIVER_EXPORTED or RECEIVER_NOT_EXPORTED should be</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/c795726e118e10d01e74a8d108fc23f1/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">AI大模型探索之路-训练篇5：大语言模型预训练数据准备-词元化</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>