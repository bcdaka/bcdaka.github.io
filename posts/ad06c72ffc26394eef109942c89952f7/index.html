<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Mac环境下ollama部署和体验 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/ad06c72ffc26394eef109942c89952f7/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="Mac环境下ollama部署和体验">
  <meta property="og:description" content="欢迎访问我的GitHub 这里分类和汇总了欣宸的全部原创(含配套源码)：https://github.com/zq2599/blog_demos
关于ollama ollama和LLM（大型语言模型）的关系，类似于docker和镜像，可以在ollama服务中管理和运行各种LLM，下面是ollama命令的参数，与docker管理镜像很类似，可以下载、删除、运行各种LLM Available Commands: serve Start ollama create Create a model from a Modelfile show Show information for a model run Run a model pull Pull a model from a registry push Push a model to a registry list List models cp Copy a model rm Remove a model help Help about any command 官网：https://ollama.com/非常简洁
本篇概览 作为入门操作的笔记，本篇记录了部署和简单体验ollama的过程，并且通过docker部署了web-ui，尝试通过页面使用大模型本次操作的环境如下 电脑：macbook pro m1，Sonoma 14.4.1ollama：0.1.32 安装 在官网首页点击Download即可下载，得到zip安装包，解压后就是应用程序了
会提示是否移动到应用程序目录，回车确认
打开后是个简单的页面
完成安装，会有一个提示，告诉你如何安装指定模型
关于模型 ollama支持的全量模型在这里：https://ollama.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-05-02T23:55:46+08:00">
    <meta property="article:modified_time" content="2024-05-02T23:55:46+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Mac环境下ollama部署和体验</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h4><a id="GitHub_0"></a>欢迎访问我的GitHub</h4> 
<blockquote> 
 <p>这里分类和汇总了欣宸的全部原创(含配套源码)：<a href="https://github.com/zq2599/blog_demos">https://github.com/zq2599/blog_demos</a></p> 
</blockquote> 
<h4><a id="ollama_2"></a>关于ollama</h4> 
<ul><li>ollama和LLM（大型语言模型）的关系，类似于docker和镜像，可以在ollama服务中管理和运行各种LLM，下面是ollama命令的参数，与docker管理镜像很类似，可以下载、删除、运行各种LLM</li></ul> 
<pre><code class="prism language-shell">Available Commands:
  serve       Start ollama
  create      Create a model from a Modelfile
  show        Show information <span class="token keyword">for</span> a model
  run         Run a model
  pull        Pull a model from a registry
  push        Push a model to a registry
  list        List models
  <span class="token function">cp</span>          Copy a model
  <span class="token function">rm</span>          Remove a model
  <span class="token builtin class-name">help</span>        Help about any <span class="token builtin class-name">command</span>
</code></pre> 
<ul><li>官网：https://ollama.com/</li><li>非常简洁<br> <img src="https://images2.imgbox.com/63/3a/jneMoHwU_o.png" alt="在这里插入图片描述"></li></ul> 
<h4><a id="_20"></a>本篇概览</h4> 
<ul><li>作为入门操作的笔记，本篇记录了部署和简单体验ollama的过程，并且通过docker部署了web-ui，尝试通过页面使用大模型</li><li>本次操作的环境如下</li></ul> 
<ol><li>电脑：macbook pro m1，Sonoma 14.4.1</li><li>ollama：0.1.32</li></ol> 
<h4><a id="_25"></a>安装</h4> 
<ul><li>在官网首页点击<font color="blue">Download</font>即可下载，得到zip安装包，解压后就是应用程序了<br> <img src="https://images2.imgbox.com/79/7b/XZ8dZ7qv_o.png" alt="在这里插入图片描述"></li><li>会提示是否移动到应用程序目录，回车确认<br> <img src="https://images2.imgbox.com/26/77/s4D4tYHG_o.png" alt="在这里插入图片描述"></li><li>打开后是个简单的页面<br> <img src="https://images2.imgbox.com/6c/5f/UBYtRzoN_o.png" alt="在这里插入图片描述"></li><li>完成安装，会有一个提示，告诉你如何安装指定模型<br> <img src="https://images2.imgbox.com/4c/93/8jRDo8hE_o.png" alt="在这里插入图片描述"></li></ul> 
<h4><a id="_35"></a>关于模型</h4> 
<ul><li>ollama支持的全量模型在这里：https://ollama.com/library</li><li>官方给出的部分模型</li></ul> 
<table><thead><tr><th>Model</th><th>Parameters</th><th>Size</th><th>下载命令</th></tr></thead><tbody><tr><td>Llama 3</td><td>8B</td><td>4.7GB</td><td><code>ollama run llama3</code></td></tr><tr><td>Llama 3</td><td>70B</td><td>40GB</td><td><code>ollama run llama3:70b</code></td></tr><tr><td>Phi-3</td><td>3.8B</td><td>2.3GB</td><td><code>ollama run phi3</code></td></tr><tr><td>Mistral</td><td>7B</td><td>4.1GB</td><td><code>ollama run mistral</code></td></tr><tr><td>Neural Chat</td><td>7B</td><td>4.1GB</td><td><code>ollama run neural-chat</code></td></tr><tr><td>Starling</td><td>7B</td><td>4.1GB</td><td><code>ollama run starling-lm</code></td></tr><tr><td>Code Llama</td><td>7B</td><td>3.8GB</td><td><code>ollama run codellama</code></td></tr><tr><td>Llama 2 Uncensored</td><td>7B</td><td>3.8GB</td><td><code>ollama run llama2-uncensored</code></td></tr><tr><td>LLaVA</td><td>7B</td><td>4.5GB</td><td><code>ollama run llava</code></td></tr><tr><td>Gemma</td><td>2B</td><td>1.4GB</td><td><code>ollama run gemma:2b</code></td></tr><tr><td>Gemma</td><td>7B</td><td>4.8GB</td><td><code>ollama run gemma:7b</code></td></tr><tr><td>Solar</td><td>10.7B</td><td>6.1GB</td><td><code>ollama run solar</code></td></tr></tbody></table> 
<ul><li>另外需要注意的是本地内存是否充足，7B参数的模型需要8G内存，13B需要16G内存，33B需要32G内存</li></ul> 
<h4><a id="8BLlama3_56"></a>运行8B的Llama3</h4> 
<ul><li>我的mac笔记本内存16G，所以打算运行8B的Llama3，命令如下</li></ul> 
<pre><code class="prism language-shell">ollama run llama3
</code></pre> 
<ul><li>第一次运行，因为没有模型文件，所以需要下载，等待下载中<br> <img src="https://images2.imgbox.com/3a/dc/Z8JvMVOU_o.png" alt="在这里插入图片描述">- 下载完毕后就可以问答了</li></ul> 
<p><img src="https://images2.imgbox.com/a4/68/W77r6pu2_o.png" alt="在这里插入图片描述"></p> 
<ul><li>退出的方法是输入<font color="blue">/bye</font></li></ul> 
<h4><a id="Linux_67"></a>Linux版本</h4> 
<ul><li>如果操作系统是Linux，安装命令如下</li></ul> 
<pre><code class="prism language-shell"><span class="token function">curl</span> <span class="token parameter variable">-fsSL</span> https://ollama.com/install.sh <span class="token operator">|</span> <span class="token function">sh</span>
</code></pre> 
<ul><li>安装完成后还要启动</li></ul> 
<pre><code class="prism language-shell">ollama serve
</code></pre> 
<h4><a id="webui_76"></a>webui</h4> 
<ul><li>如果电脑上装有docker，请执行以下命令来启动ollama的webui</li></ul> 
<pre><code class="prism language-shell"><span class="token function">docker</span> run <span class="token parameter variable">-d</span> <span class="token parameter variable">-p</span> <span class="token number">3000</span>:8080 --add-host<span class="token operator">=</span>host.docker.internal:host-gateway <span class="token parameter variable">-v</span> open-webui:/app/backend/data <span class="token parameter variable">--name</span> open-webui <span class="token parameter variable">--restart</span> always ghcr.io/open-webui/open-webui:main
</code></pre> 
<ul><li>出现登录页面，需要点击右下角的<font color="blue">Sign up</font>先注册<br> <img src="https://images2.imgbox.com/7d/27/0d65XGos_o.png" alt="在这里插入图片描述"></li><li>完成注册后，第一次登录会出现特性介绍<br> <img src="https://images2.imgbox.com/c1/ca/82Snnl29_o.png" alt="在这里插入图片描述"></li><li>可以在这里修改系统语言<br> <img src="https://images2.imgbox.com/fb/e5/34Jsk4f3_o.png" alt="在这里插入图片描述"></li><li>接下来试试聊天功能，先是选择模型，由于刚才已经下载过模型了，这里只要选择即可，如下图<br> <img src="https://images2.imgbox.com/9d/0f/CefI4oAH_o.png" alt="在这里插入图片描述"></li><li>然后就可以对话了<br> <img src="https://images2.imgbox.com/32/1d/116XnXdp_o.png" alt="在这里插入图片描述"></li><li>在设置页面可以管理模型<br> <img src="https://images2.imgbox.com/0e/0b/U2672FTh_o.png" alt="在这里插入图片描述"></li><li>至此，最基础的操作已经完成，如果您正处于初步尝试阶段，希望本文可以给您一些参考</li></ul> 
<h4><a id="_94"></a>你不孤单，欣宸原创一路相伴</h4> 
<ol><li><a href="https://xinchen.blog.csdn.net/article/details/105068742" rel="nofollow">Java系列</a></li><li><a href="https://xinchen.blog.csdn.net/article/details/105086498" rel="nofollow">Spring系列</a></li><li><a href="https://xinchen.blog.csdn.net/article/details/105086732" rel="nofollow">Docker系列</a></li><li><a href="https://xinchen.blog.csdn.net/article/details/105086794" rel="nofollow">kubernetes系列</a></li><li><a href="https://xinchen.blog.csdn.net/article/details/105086850" rel="nofollow">数据库+中间件系列</a></li><li><a href="https://xinchen.blog.csdn.net/article/details/105086920" rel="nofollow">DevOps系列</a></li></ol>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/925e7e9de61cbaf44845b227e03365f4/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">从原理到实践：学习Java中OutputStreamWriter的使用方法</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/0bbcabea9b79c595524c28be1e1711e8/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">最新AI创作系统，ChatGPT商业运营系统网站源码，SparkAi-v6.5.0，Ai绘画/GPTs应用，文档对话</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>