<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【机器学习】树模型以及决策树的基本概念、决策树与随机森林的区别以及决策树在python中的实例代码 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/b9f77d5d741e18b30efb601cc1b64952/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="【机器学习】树模型以及决策树的基本概念、决策树与随机森林的区别以及决策树在python中的实例代码">
  <meta property="og:description" content="引言 机器学习中的树模型是一种广泛使用的算法，主要用于分类和回归任务
文章目录 引言一、树模型1.1 常见的树模型1.1.1 决策树（Decision Tree）1.1.2 分类与回归树（CART）1.1.3 ID3算法1.1.4 C4.5算法1.1.5 随机森林（Random Forest）1.1.6 梯度提升树（Gradient Boosting Decision Tree, GBDT）1.1.7 XGBoost 1.2 树模型的特点 二、决策树2.1 决策树的定义2.2 决策树的组成部分2.3 决策树的构建过程2.4 停止条件2.5 决策树的优缺点2.5.1 优点2.5.2 缺点 2.6 总结 三、决策树和随机森林的区别3.1 决策树3.1.1 结构3.1.2 预测3.1.3 过拟合3.1.4 稳定性 3.2 随机森林3.2.1 结构3.2.2 预测3.2.3 过拟合3.2.4 稳定性 3.3 主要区别3.4 总结 四、决策树在python中的实例4.1 数据准备4.2 模型构建与训练4.3 模型评估4.4 决策树可视化4.5 总结 一、树模型 树模型通过一系列的决策规则来预测目标变量的值
1.1 常见的树模型 1.1.1 决策树（Decision Tree） 决策树是一种基本的树模型，它通过一系列的判断节点来对数据进行分类或回归。每个节点代表一个特征，每个分支代表一个特征的取值，最终的叶子节点代表预测结果 1.1.2 分类与回归树（CART） CART是一种决策树算法，它可以用于分类（Classification and Regression Trees）和回归任务。CART通过基尼不纯度或均方误差来选择最优的特征和切分点 1.1.3 ID3算法 ID3（Iterative Dichotomiser 3）是一种基于信息增益的决策树算法。它选择具有最高信息增益的特征来分割数据集，直到满足停止条件 1.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-09-04T12:45:06+08:00">
    <meta property="article:modified_time" content="2024-09-04T12:45:06+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【机器学习】树模型以及决策树的基本概念、决策树与随机森林的区别以及决策树在python中的实例代码</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_0"></a>引言</h2> 
<blockquote> 
 <p>机器学习中的树模型是一种广泛使用的算法，主要用于分类和回归任务</p> 
</blockquote> 
<p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#_0" rel="nofollow">引言</a></li><li><a href="#_6" rel="nofollow">一、树模型</a></li><li><ul><li><a href="#11__8" rel="nofollow">1.1 常见的树模型</a></li><li><ul><li><a href="#111_Decision_Tree_9" rel="nofollow">1.1.1 决策树（Decision Tree）</a></li><li><a href="#112_CART_11" rel="nofollow">1.1.2 分类与回归树（CART）</a></li><li><a href="#113_ID3_13" rel="nofollow">1.1.3 ID3算法</a></li><li><a href="#114_C45_15" rel="nofollow">1.1.4 C4.5算法</a></li><li><a href="#115_Random_Forest_17" rel="nofollow">1.1.5 随机森林（Random Forest）</a></li><li><a href="#116_Gradient_Boosting_Decision_Tree_GBDT_19" rel="nofollow">1.1.6 梯度提升树（Gradient Boosting Decision Tree, GBDT）</a></li><li><a href="#117_XGBoost_21" rel="nofollow">1.1.7 XGBoost</a></li></ul> 
   </li><li><a href="#12__24" rel="nofollow">1.2 树模型的特点</a></li></ul> 
  </li><li><a href="#_34" rel="nofollow">二、决策树</a></li><li><ul><li><a href="#21__35" rel="nofollow">2.1 决策树的定义</a></li><li><a href="#22__37" rel="nofollow">2.2 决策树的组成部分</a></li><li><a href="#23__42" rel="nofollow">2.3 决策树的构建过程</a></li><li><a href="#24__47" rel="nofollow">2.4 停止条件</a></li><li><a href="#25__52" rel="nofollow">2.5 决策树的优缺点</a></li><li><ul><li><a href="#251__53" rel="nofollow">2.5.1 优点</a></li><li><a href="#252__58" rel="nofollow">2.5.2 缺点</a></li></ul> 
   </li><li><a href="#26__62" rel="nofollow">2.6 总结</a></li></ul> 
  </li><li><a href="#_65" rel="nofollow">三、决策树和随机森林的区别</a></li><li><ul><li><a href="#31__67" rel="nofollow">3.1 决策树</a></li><li><ul><li><a href="#311__68" rel="nofollow">3.1.1 结构</a></li><li><a href="#312__70" rel="nofollow">3.1.2 预测</a></li><li><a href="#313__72" rel="nofollow">3.1.3 过拟合</a></li><li><a href="#314__74" rel="nofollow">3.1.4 稳定性</a></li></ul> 
   </li><li><a href="#32__76" rel="nofollow">3.2 随机森林</a></li><li><ul><li><a href="#321__77" rel="nofollow">3.2.1 结构</a></li><li><a href="#322__79" rel="nofollow">3.2.2 预测</a></li><li><a href="#323__81" rel="nofollow">3.2.3 过拟合</a></li><li><a href="#324__83" rel="nofollow">3.2.4 稳定性</a></li></ul> 
   </li><li><a href="#33__85" rel="nofollow">3.3 主要区别</a></li><li><a href="#34__91" rel="nofollow">3.4 总结</a></li></ul> 
  </li><li><a href="#python_95" rel="nofollow">四、决策树在python中的实例</a></li><li><ul><li><a href="#41__96" rel="nofollow">4.1 数据准备</a></li><li><a href="#42__108" rel="nofollow">4.2 模型构建与训练</a></li><li><a href="#43__116" rel="nofollow">4.3 模型评估</a></li><li><a href="#44__126" rel="nofollow">4.4 决策树可视化</a></li><li><a href="#45__142" rel="nofollow">4.5 总结</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h2><a id="_6"></a>一、树模型</h2> 
<p>树模型通过一系列的决策规则来预测目标变量的值</p> 
<h3><a id="11__8"></a>1.1 常见的树模型</h3> 
<h4><a id="111_Decision_Tree_9"></a>1.1.1 决策树（Decision Tree）</h4> 
<ul><li>决策树是一种基本的树模型，它通过一系列的判断节点来对数据进行分类或回归。每个节点代表一个特征，每个分支代表一个特征的取值，最终的叶子节点代表预测结果</li></ul> 
<h4><a id="112_CART_11"></a>1.1.2 分类与回归树（CART）</h4> 
<ul><li>CART是一种决策树算法，它可以用于分类（Classification and Regression Trees）和回归任务。CART通过基尼不纯度或均方误差来选择最优的特征和切分点</li></ul> 
<h4><a id="113_ID3_13"></a>1.1.3 ID3算法</h4> 
<ul><li>ID3（Iterative Dichotomiser 3）是一种基于信息增益的决策树算法。它选择具有最高信息增益的特征来分割数据集，直到满足停止条件</li></ul> 
<h4><a id="114_C45_15"></a>1.1.4 C4.5算法</h4> 
<ul><li>C4.5是ID3的改进版本，它使用增益率（Gain Ratio）来选择特征，以减少对具有大量值的特征的偏好。C4.5还可以处理缺失值和数据离散化</li></ul> 
<h4><a id="115_Random_Forest_17"></a>1.1.5 随机森林（Random Forest）</h4> 
<ul><li>随机森林是一种集成学习方法，它通过构建多棵决策树并对它们的预测结果进行投票来提高模型的准确性和稳定性。随机森林在训练过程中引入了随机性，从而降低了过拟合的风险</li></ul> 
<h4><a id="116_Gradient_Boosting_Decision_Tree_GBDT_19"></a>1.1.6 梯度提升树（Gradient Boosting Decision Tree, GBDT）</h4> 
<ul><li>梯度提升树是一种强大的集成学习算法，它通过迭代地训练决策树来最小化损失函数。每棵树都是为了纠正前一棵树的错误而构建的</li></ul> 
<h4><a id="117_XGBoost_21"></a>1.1.7 XGBoost</h4> 
<ul><li>XGBoost是梯度提升树的一个高效实现，它在训练速度和模型性能方面进行了优化。XGBoost支持自定义损失函数，并具有正则化项，可以有效防止过拟合</li></ul> 
<h3><a id="12__24"></a>1.2 树模型的特点</h3> 
<ul><li>易于理解和使用</li><li>能够处理非线性关系</li><li>对数据预处理要求较低</li><li>可以处理分类和回归问题</li><li>容易过拟合，需要通过剪枝、随机森林或梯度提升等方法来优化</li></ul> 
<p><img src="https://images2.imgbox.com/e4/13/zn5GYZe4_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="_34"></a>二、决策树</h2> 
<h3><a id="21__35"></a>2.1 决策树的定义</h3> 
<p>决策树是一种常见的机器学习算法，用于分类和回归任务。它的工作原理是通过一系列的判断条件来对数据进行分割，直到达到某个终止条件</p> 
<h3><a id="22__37"></a>2.2 决策树的组成部分</h3> 
<ol><li><strong>根节点（Root Node）</strong>：包含整个数据集，是决策树的起始点</li><li><strong>内部节点（Internal Node）</strong>：代表一个特征或属性，用来对数据进行分割</li><li><strong>叶节点（Leaf Node）</strong>：代表决策结果，对于分类问题，通常是所属的类别；对于回归问题，则是预测的值</li><li><strong>分支（Branch）</strong>：连接节点，表示数据的流向</li></ol> 
<h3><a id="23__42"></a>2.3 决策树的构建过程</h3> 
<ol><li><strong>特征选择</strong>：选择最优的特征来对数据进行分割。常用的特征选择标准包括信息增益（ID3算法）、增益率（C4.5算法）和基尼不纯度（CART算法）</li><li><strong>分割点选择</strong>：对于选定的特征，需要确定一个分割点，以最大化分割效果。例如，对于连续值特征，可能需要找到一个数值，使得数据在该数值两侧尽可能分开</li><li><strong>树的生成</strong>：重复上述两个步骤，递归地对子集进行分割，直到满足停止条件</li><li><strong>剪枝</strong>：为了防止过拟合，需要对决策树进行剪枝。剪枝有两种方法：预剪枝（在树生成过程中提前停止）和后剪枝（生成完整树后进行修剪）</li></ol> 
<h3><a id="24__47"></a>2.4 停止条件</h3> 
<ul><li>当节点的数据都属于同一类别时，停止分割</li><li>当节点的数据量低于一个预设的阈值时，停止分割</li><li>当节点的信息增益、增益率或基尼不纯度低于一个预设的阈值时，停止分割</li><li>当树达到预设的最大深度时，停止分割</li></ul> 
<h3><a id="25__52"></a>2.5 决策树的优缺点</h3> 
<h4><a id="251__53"></a>2.5.1 优点</h4> 
<ul><li>易于理解和解释</li><li>需要较少的数据预处理</li><li>能够处理数值型和类别型数据</li><li>能够处理非线性关系</li></ul> 
<h4><a id="252__58"></a>2.5.2 缺点</h4> 
<ul><li>容易过拟合，特别是在没有剪枝的情况下</li><li>对于类别不平衡的数据，决策树可能会偏向于多数类</li><li>决策树可能会不稳定，因为数据的小变化可能导致树结构的大变化</li></ul> 
<h3><a id="26__62"></a>2.6 总结</h3> 
<p>在实际应用中，决策树通常需要配合剪枝技术来提高其在未知数据上的泛化能力。此外，决策树也可以作为集成学习方法（如随机森林、梯度提升树）的一部分，以提高模型的性能</p> 
<h2><a id="_65"></a>三、决策树和随机森林的区别</h2> 
<blockquote> 
 <p>决策树和随机森林都是基于树模型的机器学习算法，但它们在构建方式和性能上存在显著的区别</p> 
</blockquote> 
<h3><a id="31__67"></a>3.1 决策树</h3> 
<h4><a id="311__68"></a>3.1.1 结构</h4> 
<ul><li>决策树是一个单一的树结构，其中每个内部节点代表一个特征，每个分支代表一个特征的取值，而叶节点代表一个决策结果</li></ul> 
<h4><a id="312__70"></a>3.1.2 预测</h4> 
<ul><li>使用决策树进行预测时，数据会从根节点开始，沿着树的结构向下移动，直到达到一个叶节点，该叶节点的值即为预测结果</li></ul> 
<h4><a id="313__72"></a>3.1.3 过拟合</h4> 
<ul><li>决策树容易过拟合，特别是在没有进行适当剪枝的情况下。它可能会学习到训练数据中的噪声和异常值，导致在测试数据上表现不佳</li></ul> 
<h4><a id="314__74"></a>3.1.4 稳定性</h4> 
<ul><li>由于决策树依赖于训练数据的具体情况，因此它们可能对数据的微小变化非常敏感，导致模型的不稳定性</li></ul> 
<h3><a id="32__76"></a>3.2 随机森林</h3> 
<h4><a id="321__77"></a>3.2.1 结构</h4> 
<ul><li>随机森林是由多个决策树组成的集成模型。每棵树都是在训练数据的随机子集上训练得到的，并且每个节点的分裂都是基于随机选择的特征子集</li></ul> 
<h4><a id="322__79"></a>3.2.2 预测</h4> 
<ul><li>随机森林进行预测时，会聚合所有决策树的预测结果。对于分类问题，通常采用多数投票法；对于回归问题，通常采用平均法</li></ul> 
<h4><a id="323__81"></a>3.2.3 过拟合</h4> 
<ul><li>随机森林通过引入随机性（数据样本的随机性和特征选择的随机性）来减少过拟合的风险。集成多个决策树可以提高模型的泛化能力</li></ul> 
<h4><a id="324__83"></a>3.2.4 稳定性</h4> 
<ul><li>由于随机森林是基于多棵树的投票，因此它通常比单个决策树更稳定，对数据的波动不那么敏感</li></ul> 
<h3><a id="33__85"></a>3.3 主要区别</h3> 
<ul><li><strong>集成方法</strong>：随机森林是一种集成学习方法，它结合了多棵决策树的预测结果，而决策树是单个模型</li><li><strong>随机性</strong>：随机森林在训练过程中引入了随机性，包括样本的随机抽取（自助抽样）和特征的随机选择，而决策树通常不引入这种随机性</li><li><strong>性能</strong>：随机森林通常在大多数情况下都比单个决策树表现得更好，尤其是在减少过拟合和提高泛化能力方面</li><li><strong>计算复杂度</strong>：随机森林的训练和预测通常比单个决策树要慢，因为它需要处理多棵树</li><li><strong>可解释性</strong>：单个决策树更容易解释，因为它们的结构更简单。随机森林的解释性较差，因为它涉及多棵树的综合结果</li></ul> 
<h3><a id="34__91"></a>3.4 总结</h3> 
<p>总的来说，随机森林是决策树的一种扩展，它通过集成多个决策树来提高预测性能和模型的稳定性</p> 
<h2><a id="python_95"></a>四、决策树在python中的实例</h2> 
<h3><a id="41__96"></a>4.1 数据准备</h3> 
<blockquote> 
 <p>在这个实例中，我们将使用scikit-learn库中的乳腺癌数据集来构建一个决策树模型。这个数据集包含了乳腺肿瘤细胞核的特征，以及它们是良性还是恶性的标签</p> 
</blockquote> 
<pre><code class="prism language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> load_breast_cancer
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split
<span class="token comment"># 加载数据集</span>
data <span class="token operator">=</span> load_breast_cancer<span class="token punctuation">(</span><span class="token punctuation">)</span>
X <span class="token operator">=</span> data<span class="token punctuation">.</span>data
y <span class="token operator">=</span> data<span class="token punctuation">.</span>target
<span class="token comment"># 划分训练集和测试集</span>
X_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.3</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="42__108"></a>4.2 模型构建与训练</h3> 
<blockquote> 
 <p>接下来，我们将构建一个决策树分类器，并使用训练集数据进行训练</p> 
</blockquote> 
<pre><code class="prism language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>tree <span class="token keyword">import</span> DecisionTreeClassifier
<span class="token comment"># 创建决策树分类器</span>
clf <span class="token operator">=</span> DecisionTreeClassifier<span class="token punctuation">(</span>random_state<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span>
clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>
</code></pre> 
<h3><a id="43__116"></a>4.3 模型评估</h3> 
<blockquote> 
 <p>训练完成后，我们将在测试集上评估模型的性能</p> 
</blockquote> 
<pre><code class="prism language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> accuracy_score
<span class="token comment"># 在测试集上进行预测</span>
y_pred <span class="token operator">=</span> clf<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span>
<span class="token comment"># 计算准确率</span>
accuracy <span class="token operator">=</span> accuracy_score<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"模型准确率: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>accuracy<span class="token punctuation">:</span><span class="token format-spec">.2f</span><span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="44__126"></a>4.4 决策树可视化</h3> 
<blockquote> 
 <p>为了更好地理解模型，我们可以将决策树可视化</p> 
</blockquote> 
<pre><code class="prism language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>tree <span class="token keyword">import</span> plot_tree
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token comment"># 可视化决策树</span>
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plot_tree<span class="token punctuation">(</span>clf<span class="token punctuation">,</span> filled<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> feature_names<span class="token operator">=</span>data<span class="token punctuation">.</span>feature_names<span class="token punctuation">,</span> class_names<span class="token operator">=</span>data<span class="token punctuation">.</span>target_names<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p>输出结果：<br> <img src="https://images2.imgbox.com/26/32/OHV5Lwm6_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/1d/f7/WNERUgjl_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="45__142"></a>4.5 总结</h3> 
<p>这个实例展示了如何使用Python和scikit-learn库来构建、训练和评估一个决策树分类器，并且如何将其可视化。通过这种方式，我们可以直观地看到模型是如何根据不同的特征来做出决策的</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/678e70b3b9ab2ffc7bcb6800d062a921/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">全面掌握MySQL数据备份策略的风险管理</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/935c87b1787f0fa494889fbff465385b/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【ORACLE】独有的函数</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>