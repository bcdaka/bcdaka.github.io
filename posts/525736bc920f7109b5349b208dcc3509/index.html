<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>利用 Selenium 和 Python 实现网页新闻链接抓取 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/525736bc920f7109b5349b208dcc3509/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="利用 Selenium 和 Python 实现网页新闻链接抓取">
  <meta property="og:description" content="在网络数据分析和信息检索中，爬虫是一项非常重要的技术。爬虫可以自动化地从网页中提取信息，极大地提升数据收集的效率。本文将以一个具体的代码实例，讲解如何使用 Selenium 库进行网页新闻链接的抓取。
前期准备 在开始之前，需要确保系统已经安装了 Python 以及 Selenium 库。可以通过以下命令进行安装：
pip install selenium 此外，还需要下载适用于浏览器的驱动程序。本文示例中使用的是 Firefox 驱动程序。如果使用的是 Chrome 浏览器，需要下载相应的 Chrome 驱动程序。下载完成后，将驱动程序放在系统的 PATH 路径中。
代码实现 以下是实现从网页中抓取新闻链接的完整代码：
from selenium import webdriver import time # 此处下载的是Firefox驱动，所以用Firefox()函数打开浏览器， # 若下载的是Chrome驱动，则利用Chrome()函数打开浏览器 driver = webdriver.Firefox() # 将提取的新闻链接保存在listhref列表中 listhref = [] url = &#34;https://www.163.com/search?keyword=中国芯片&#34; # 通过分析网页结构可知，网页的所有新闻都存放在”class”=”keyword_list”的节点下， # 右键复制该节点XPath路径，为”/html/body/div[2]/div[2]/div[1]/div[2]”， # 再对某一个新闻进行分析，得到新闻链接存放的节点a的XPath路径， # 此时不用添加标号，就可以查询到所有满足条件的新闻链接 xpath_name = &#34;/html/body/div[2]/div[2]/div[1]/div[2]/div/h3/a&#34; # 根据网页链接打开浏览器 driver.get(url=url) # 这里设计了两个临时变量，分别保存现在滚动条距离页面顶层的高度和上一次滚动条的高度， # 用来判断是否滚动条已经到达页面底部，无法继续下滑 nowTop = 0 tempTop = -1 # 不断向下滚动滚动条并且保存新闻链接 while True: # 保存网页链接存取在的位置节点 name = driver.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-07-09T14:53:48+08:00">
    <meta property="article:modified_time" content="2024-07-09T14:53:48+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">利用 Selenium 和 Python 实现网页新闻链接抓取</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-tomorrow-night">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p><img src="https://images2.imgbox.com/34/0e/Uf5nLElE_o.png" alt="在这里插入图片描述"></p> 
<p>在网络数据分析和信息检索中，爬虫是一项非常重要的技术。爬虫可以自动化地从网页中提取信息，极大地提升数据收集的效率。本文将以一个具体的代码实例，讲解如何使用 Selenium 库进行网页新闻链接的抓取。</p> 
<h3><a id="_5"></a>前期准备</h3> 
<p>在开始之前，需要确保系统已经安装了 Python 以及 Selenium 库。可以通过以下命令进行安装：</p> 
<pre><code class="prism language-bash">pip <span class="token function">install</span> selenium
</code></pre> 
<p>此外，还需要下载适用于浏览器的驱动程序。本文示例中使用的是 Firefox 驱动程序。如果使用的是 Chrome 浏览器，需要下载相应的 Chrome 驱动程序。下载完成后，将驱动程序放在系统的 PATH 路径中。</p> 
<h3><a id="_15"></a>代码实现</h3> 
<p>以下是实现从网页中抓取新闻链接的完整代码：</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> selenium <span class="token keyword">import</span> webdriver  
<span class="token keyword">import</span> time

<span class="token comment"># 此处下载的是Firefox驱动，所以用Firefox()函数打开浏览器，</span>
<span class="token comment"># 若下载的是Chrome驱动，则利用Chrome()函数打开浏览器</span>
driver <span class="token operator">=</span> webdriver<span class="token punctuation">.</span>Firefox<span class="token punctuation">(</span><span class="token punctuation">)</span>  
  
<span class="token comment"># 将提取的新闻链接保存在listhref列表中</span>
listhref <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  
url <span class="token operator">=</span> <span class="token string">"https://www.163.com/search?keyword=中国芯片"</span>  

<span class="token comment"># 通过分析网页结构可知，网页的所有新闻都存放在”class”=”keyword_list”的节点下，</span>
<span class="token comment"># 右键复制该节点XPath路径，为”/html/body/div[2]/div[2]/div[1]/div[2]”，</span>
<span class="token comment"># 再对某一个新闻进行分析，得到新闻链接存放的节点a的XPath路径，</span>
<span class="token comment"># 此时不用添加标号，就可以查询到所有满足条件的新闻链接</span>
xpath_name <span class="token operator">=</span> <span class="token string">"/html/body/div[2]/div[2]/div[1]/div[2]/div/h3/a"</span>  
  
<span class="token comment"># 根据网页链接打开浏览器</span>
driver<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token operator">=</span>url<span class="token punctuation">)</span>  
  
<span class="token comment"># 这里设计了两个临时变量，分别保存现在滚动条距离页面顶层的高度和上一次滚动条的高度，</span>
<span class="token comment"># 用来判断是否滚动条已经到达页面底部，无法继续下滑</span>
nowTop <span class="token operator">=</span> <span class="token number">0</span>  
tempTop <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span>  

<span class="token comment"># 不断向下滚动滚动条并且保存新闻链接</span>
<span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>  
  <span class="token comment"># 保存网页链接存取在的位置节点</span>
  name <span class="token operator">=</span> driver<span class="token punctuation">.</span>find_elements_by_xpath<span class="token punctuation">(</span>xpath_name<span class="token punctuation">)</span>  
  <span class="token comment"># 遍历各个节点</span>
  <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>name<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  
    <span class="token comment"># 判断当前下标有没有文本  </span>
    <span class="token keyword">if</span> name<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">.</span>text<span class="token punctuation">:</span>  
      <span class="token comment"># 有则添加进列表，通过get_attribute函数获得’href’属性的值，获得新闻链接 </span>
      listhref<span class="token punctuation">.</span>append<span class="token punctuation">(</span>name<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">.</span>get_attribute<span class="token punctuation">(</span><span class="token string">'href'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  
    <span class="token keyword">else</span><span class="token punctuation">:</span>  
      <span class="token keyword">pass</span>  

  <span class="token comment"># 执行下拉滚动操作</span>
  driver<span class="token punctuation">.</span>execute_script<span class="token punctuation">(</span><span class="token string">"window.scrollBy(0,1000)"</span><span class="token punctuation">)</span>  
  <span class="token comment"># 睡眠让滚动条反应一下</span>
  time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span>  
	  
  <span class="token comment"># 获得滚动条距离顶部的距离</span>
  nowTop <span class="token operator">=</span> driver<span class="token punctuation">.</span>execute_script<span class="token punctuation">(</span><span class="token string">"return document.documentElement.scrollTop || window.pageYOffset || document.body.scrollTop;"</span><span class="token punctuation">)</span>  
  
  <span class="token comment"># 如果滚动条距离顶部的距离不再变化，意味着已经到达页面底部，可以退出循环</span>
  <span class="token keyword">if</span> nowTop <span class="token operator">==</span> tempTop<span class="token punctuation">:</span>  
    <span class="token keyword">break</span>  
  tempTop <span class="token operator">=</span> nowTop  
     
<span class="token comment"># 完成后关闭浏览器  </span>
driver<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>  

<span class="token comment"># 检查新闻链接是否保存成功</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>listhref<span class="token punctuation">)</span>
</code></pre> 
<h3><a id="_78"></a>代码讲解</h3> 
<h4><a id="1__80"></a>1. 初始化浏览器驱动</h4> 
<p>首先，通过 <code>webdriver.Firefox()</code> 初始化 Firefox 浏览器驱动。如果使用 Chrome 浏览器，可以替换为 <code>webdriver.Chrome()</code>。</p> 
<h4><a id="2__URL__XPath_84"></a>2. 设置目标 URL 和 XPath</h4> 
<p>目标 URL 设置为网易新闻的搜索页面，通过关键词“<strong>中国芯片</strong>”进行搜索。通过分析网页结构，确定新闻链接的 XPath 路径。</p> 
<h4><a id="3__88"></a>3. 打开浏览器并加载网页</h4> 
<p>使用 <code>driver.get(url)</code> 方法打开目标网页。</p> 
<h4><a id="4__92"></a>4. 滚动页面并提取链接</h4> 
<p>为了提取所有的新闻链接，需要不断向下滚动页面。通过 <code>driver.execute_script("window.scrollBy(0,1000)")</code> 实现页面滚动，并通过 <code>time.sleep(5)</code> 暂停 5 秒，等待页面加载新内容。</p> 
<h4><a id="5__96"></a>5. 判断是否到达页面底部</h4> 
<p>利用两个变量 <code>nowTop</code> 和 <code>tempTop</code> 判断是否到达页面底部。如果滚动条距离顶部的高度不再变化，说明已经到达页面底部，此时退出循环。</p> 
<h4><a id="6__100"></a>6. 关闭浏览器并输出结果</h4> 
<p>循环结束后，关闭浏览器，并输出抓取到的新闻链接列表 <code>listhref</code>。</p> 
<h3><a id="_104"></a>注意事项</h3> 
<ol><li><strong>浏览器驱动</strong>：确保浏览器驱动与浏览器版本匹配，并将驱动程序放在系统的 PATH 路径中。</li><li><strong>页面加载时间</strong>：根据网络环境和页面复杂度，适当调整 <code>time.sleep()</code> 的时间。</li><li><strong>反爬虫机制</strong>：一些网站可能有反爬虫机制，如频繁访问可能导致 IP 被封禁。可以通过设置代理、调整访问频率等方式进行规避。</li></ol> 
<p>通过本文的实例，可以帮助读者了解如何使用 Selenium 库进行网页数据抓取，并应用于实际的爬虫项目中。希望这篇文章对你有所帮助！</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/749d078c363ff1bf5c5c7c38366a739e/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">VSCode无法连接网络安装插件-手动安装插件</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/014f438b7d215f024ccdd296ca37b22c/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【一】m2芯片的mac中安装ubuntu24虚拟机集群</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>