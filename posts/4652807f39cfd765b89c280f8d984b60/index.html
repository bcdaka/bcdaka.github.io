<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>[LLM]Streamlit&#43;LLM(大型语言模型)创建实用且强大的Web聊天机器人 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/4652807f39cfd765b89c280f8d984b60/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="[LLM]Streamlit&#43;LLM(大型语言模型)创建实用且强大的Web聊天机器人">
  <meta property="og:description" content="Streamlit 和 Streamlit_chat Streamlit 是一个开源框架，使开发人员能够快速构建和共享用于机器学习和数据科学项目的交互式 Web 应用程序。它还提供了一系列小部件，只需要一行 Python 代码即可创建，例如st.table(…)。对于我们创建一个简单的用于私人使用的聊天机器人网站来说，Streamlit 是一个非常合适的库，它还提供了第三方 Streamlit_chat 库，进一步方便我们生成“聊天式” Web 应用程序，因为我们不需要写大量的 HTML 元素和 CSS 内容。
Streamlit是时下比较热门的一个基于Python的Web应用程序框架,它可以在几分钟内将数据转化为可共享的Web应用程序，无需前端开发经验，使用纯Python代码实现，简单且高效。
ChatGPT(LLM)是目前非常火的OpenAI公司开发的聊天机器人模型，它无所不知就像一本大百科全书，它可以帮你做很多繁杂的日常工作，比如可以代你写文章，代你做excel表格，甚至代你写代码。今天我们要将两者结合起来开发一个基于web的应用聊天小程序。
我们需要在python环境中安装openai和streamlit的第三方python包，可以通过在命令行窗口中安装这些包：
pip install openai pip install streamlit pip install streamlit_chat 聊天机器人接口参数说明
model： 模型名词
prompt：对机器人提出的问题
temperature：温度参数，该参数控制生成文本的随机性级别。较高的温度参数会导致更多变化且可能不太连贯的响应，而较低的t温度参数会产生更可预测且可能更连贯的响应。
max_tokens：应答语句的长度 创建聊天Python代码文件 我们需要创建一个用于聊天的streamlit的代码文件 chat_bot.py
# chat_bot.py import openai import streamlit as st from streamlit_chat import message # 申请的api_key # openai.api_key = &#34;xxxxxxxxxxxxxxxxx&#34; # 使用本地llama_cpp_python启动了下local LLM API openai.api_base = &#34;http://localhost:8000/v1&#34; # point to the local server openai.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2023-12-20T11:19:41+08:00">
    <meta property="article:modified_time" content="2023-12-20T11:19:41+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">[LLM]Streamlit&#43;LLM(大型语言模型)创建实用且强大的Web聊天机器人</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h3 id="streamlit-%E5%92%8C-streamlitchat"><strong>Streamlit 和 Streamlit_chat</strong></h3> 
<p>Streamlit 是一个开源框架，使开发人员能够快速构建和共享用于机器学习和数据科学项目的交互式 Web 应用程序。它还提供了一系列小部件，只需要一行 Python 代码即可创建，例如<code>st.table(…)</code>。对于我们创建一个简单的用于私人使用的聊天机器人网站来说，Streamlit 是一个非常合适的库，它还提供了第三方 Streamlit_chat 库，进一步方便我们生成“聊天式” Web 应用程序，因为我们不需要写大量的 HTML 元素和 CSS 内容。</p> 
<p>Streamlit是时下比较热门的一个基于Python的Web应用程序框架,它可以在几分钟内将数据转化为可共享的Web应用程序，无需前端开发经验，使用纯Python代码实现，简单且高效。</p> 
<p>ChatGPT(LLM)是目前非常火的OpenAI公司开发的聊天机器人模型，它无所不知就像一本大百科全书，它可以帮你做很多繁杂的日常工作，比如可以代你写文章，代你做excel表格，甚至代你写代码。今天我们要将两者结合起来开发一个基于web的应用聊天小程序。</p> 
<p><br> 我们需要在python环境中安装openai和streamlit的第三方python包，可以通过在命令行窗口中安装这些包：</p> 
<pre><code class="language-bash">pip install openai
pip install streamlit
pip install streamlit_chat</code></pre> 
<p><strong>聊天机器人接口参数说明</strong><br> model： 模型名词<br> prompt：对机器人提出的问题<br> temperature：温度参数，该参数控制生成文本的随机性级别。较高的温度参数会导致更多变化且可能不太连贯的响应，而较低的t温度参数会产生更可预测且可能更连贯的响应。<br> max_tokens：应答语句的长度 <br>  </p> 
<h3>创建聊天Python代码文件</h3> 
<p>我们需要创建一个用于聊天的streamlit的代码文件 chat_bot.py</p> 
<pre><code class="language-python"># chat_bot.py

import openai
import streamlit as st
from streamlit_chat import message

# 申请的api_key
# openai.api_key = "xxxxxxxxxxxxxxxxx"

# 使用本地llama_cpp_python启动了下local LLM API
openai.api_base = "http://localhost:8000/v1"  # point to the local server
openai.api_key = ""  # no need for an API key

if 'prompts' not in st.session_state:
    st.session_state['prompts'] = [{"role": "system", "content": "您是一个乐于助人的助手。尽量简洁明了地回答问题，并带有一点幽默表达。"}]

if 'generated' not in st.session_state:
    st.session_state['generated'] = []

if 'past' not in st.session_state:
    st.session_state['past'] = []


def generate_response(prompt):
    st.session_state['prompts'].append({"role": "user", "content": prompt})
    completion = openai.ChatCompletion.create(
        model="local-model",
        messages=st.session_state['prompts'],
        max_tokens=1024,
        temperature=0.6
    )
    message = completion.choices[0].message.content
    return message


def end_click():
    st.session_state['prompts'] = [{"role": "system", "content": "您是一个乐于助人的助手。尽量简洁明了地回答问题，并带有一点幽默表达。"}]
    st.session_state['past'] = []
    st.session_state['generated'] = []
    st.session_state['user'] = ""


def chat_click():
    if st.session_state['user'] != '':
        chat_input = st.session_state['user']
        output = generate_response(chat_input)
        st.session_state['past'].append(chat_input)
        st.session_state['generated'].append(output)
        st.session_state['prompts'].append({"role": "assistant", "content": output})
        st.session_state['user'] = ""


st.title("我的聊天机器人")

user_input = st.text_input("输入:", key="user")
chat_button = st.button("发送", on_click=chat_click)
end_button = st.button("新聊天", on_click=end_click)

if st.session_state['generated']:
    for i in range(0, len(st.session_state['generated']), 1):
        message(st.session_state['past'][i], is_user=True)
        message(st.session_state['generated'][i], key=str(i))
</code></pre> 
<h3>启动Streamlit</h3> 
<p> 我们需要在命令行窗口执行启动streamlit的命令：</p> 
<pre><code>streamlit run chat_bot.py</code></pre> 
<p>输入启动streamlit命令后，会弹出浏览器, 如果没有弹出浏览器可以自行打开浏览器并输入上图中的url地址，接下来就可以开始和ChatGPT聊天了：</p> 
<p><img alt="" height="874" src="https://images2.imgbox.com/0f/74/mC5tYffS_o.png" width="1200"></p> 
<p><br>  </p> 
<h3>参考资料</h3> 
<p><a href="https://docs.streamlit.io/" rel="nofollow" title="Streamlit documentation">Streamlit documentation</a></p> 
<p><br><a href="https://apifox.com/apiskills/streamlit-gpt-3-5/" rel="nofollow" title="如何使用 Streamlit 和 OpenAI GPT-3.5 创建实用且强大的聊天机器人 (apifox.com)">如何使用 Streamlit 和 OpenAI GPT-3.5 创建实用且强大的聊天机器人 (apifox.com)</a><br><a href="https://platform.openai.com/docs/introduction" rel="nofollow" title="OpenAI API documentation"></a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/3ecd793e4c0e4a2440134e4a85678b63/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">12 款在手，前端无忧——Vue UI 组件库</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/6b9bc5f90b2b361ccabbf519efd97115/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">前端vue上传时获取文件的md5哈希值</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>