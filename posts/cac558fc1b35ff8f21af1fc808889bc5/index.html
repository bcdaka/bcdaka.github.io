<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【机器学习】LightGBM: 优化机器学习的高效梯度提升决策树 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/cac558fc1b35ff8f21af1fc808889bc5/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="【机器学习】LightGBM: 优化机器学习的高效梯度提升决策树">
  <meta property="og:description" content="🌈个人主页: 鑫宝Code
🔥热门专栏: 闲话杂谈｜ 炫酷HTML | JavaScript基础 ​💫个人格言: &#34;如无必要，勿增实体&#34; 文章目录 LightGBM: 优化机器学习的高效梯度提升决策树引言一、LightGBM概览二、核心技术解析1. 直方图近似（Histogram Approximation）2. 基于梯度的单边采样（Gradient-Based One-Side Sampling, GOSS）3. 特征并行与数据并行 三、与其他GBDT实现的对比四、实践应用与调参技巧五、结论 LightGBM: 优化机器学习的高效梯度提升决策树 引言 在机器学习领域，梯度提升决策树(Gradient Boosting Decision Tree, GBDT)因其强大的预测能力和解释性而备受推崇。随着数据规模的日益增大，对模型训练速度和效率的需求也愈发迫切。在此背景下，Microsoft Research于2017年开源的LightGBM项目，凭借其高速度、高效率以及优秀的性能，在众多GBDT框架中脱颖而出，成为业界和学术界的新宠。本文将深入探讨LightGBM的核心优势、工作原理、关键特性和应用场景，旨在为读者提供一份全面而深入的理解指南。
一、LightGBM概览 诞生背景：面对传统GBDT在处理大规模数据集时遇到的内存消耗大、训练时间长等问题，LightGBM应运而生，它通过一系列创新算法设计显著提高了训练效率。
核心特点：
高效性：利用直方图近似和基于梯度的单边采样等技术，大幅减少计算量。低内存消耗：通过叶子权重直方图存储方式，极大降低了内存使用。高并行性：支持特征并行、数据并行和投票并行等多种并行策略，加速训练过程。灵活性：支持自定义目标函数和评估指标，满足多样化需求。 二、核心技术解析 1. 直方图近似（Histogram Approximation） 传统的GBDT方法在每一轮迭代中需要遍历所有数据来计算梯度，这在大数据场景下极为耗时。LightGBM引入了直方图的概念，将连续的特征值离散化为几个区间，仅需统计每个区间内的样本数量和梯度统计量，从而大大减少了计算量，加速了训练过程。
2. 基于梯度的单边采样（Gradient-Based One-Side Sampling, GOSS） GOSS是一种有效的样本抽样策略，它根据样本的梯度大小进行有偏抽样，保留梯度较大的样本和一部分梯度较小的样本，这样既保留了重要信息，又大幅度减少了计算量，进一步提升了效率。
3. 特征并行与数据并行 特征并行：将特征分配到不同的机器上进行独立的直方图构建，然后合并这些直方图，适用于特征维度较高的情况。数据并行：将数据集分割到不同机器，每台机器上分别建立自己的决策树，最后汇总决策树结果，适用于大数据集。
三、与其他GBDT实现的对比 与XGBoost相比，LightGBM在训练速度和内存使用上通常表现更优，特别是在数据量较大时。然而，XGBoost提供了更多的调参选项，对于高度定制化的任务可能更为灵活。两者各有千秋，选择应依据具体任务需求。
四、实践应用与调参技巧 应用领域：LightGBM广泛应用于推荐系统、搜索引擎排名、金融风控、医疗诊断等多个领域，以其高效、准确的特性解决了一系列实际问题。
调参建议：
学习率：初始值可设为0.1，过拟合时减小。树的最大深度：默认31，可根据数据复杂度调整。叶子节点最小样本数：控制模型复杂度，避免过拟合。特征抽样比例：通过调整feature_fraction参数平衡模型复杂度与性能。 以下是一个使用Python和LightGBM库进行分类任务的基本示例代码。这个例子中，我们将使用经典的鸢尾花（Iris）数据集来训练一个简单的LightGBM模型，并进行基本的模型评估。代码仅供参考🐶
# 导入所需库 import lightgbm as lgb from sklearn.datasets import load_iris from sklearn.model_selection import train_test_split from sklearn.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-06-15T12:16:24+08:00">
    <meta property="article:modified_time" content="2024-06-15T12:16:24+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【机器学习】LightGBM: 优化机器学习的高效梯度提升决策树</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-tomorrow-night">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <hr> 
<img src="https://images2.imgbox.com/ce/41/OXzsnvaR_o.png" alt="鑫宝Code" width="150px"> 
<br> 
<img src="https://images2.imgbox.com/88/25/dRZgrjNg_o.gif" width="300px"> 
<br> 
<p> <font color="#0099ff" size="3" face="粗体"><strong>🌈个人主页: <a href="https://xinbaocode.blog.csdn.net/" rel="nofollow">鑫宝Code</a></strong></font><br> <font color="#0099ff" size="3" face="粗体"><strong>🔥热门专栏: <a href="https://xinbaocode.blog.csdn.net/category_12565077.html" rel="nofollow">闲话杂谈</a>｜ <a href="https://xinbaocode.blog.csdn.net/category_12578048.html" rel="nofollow">炫酷HTML</a> | <a href="https://xinbaocode.blog.csdn.net/category_12578047.html" rel="nofollow">JavaScript基础</a> </strong></font><br> ​<font color="#0099ff" size="3" face="粗体"><strong>💫个人格言: "如无必要，勿增实体" </strong></font> <br><br> <img src="https://images2.imgbox.com/cc/ce/gKqvSDI0_o.gif" width="100%"> </p> 
<hr> 
<p></p> 
<p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><ul><li><ul><li><a href="#LightGBM__40" rel="nofollow">LightGBM: 优化机器学习的高效梯度提升决策树</a></li><li><ul><li><a href="#_42" rel="nofollow">引言</a></li><li><a href="#LightGBM_47" rel="nofollow">一、LightGBM概览</a></li><li><a href="#_58" rel="nofollow">二、核心技术解析</a></li><li><ul><li><a href="#1_Histogram_Approximation_60" rel="nofollow">1. 直方图近似（Histogram Approximation）</a></li><li><a href="#2_GradientBased_OneSide_Sampling_GOSS_65" rel="nofollow">2. 基于梯度的单边采样（Gradient-Based One-Side Sampling, GOSS）</a></li><li><a href="#3__70" rel="nofollow">3. 特征并行与数据并行</a></li></ul> 
     </li><li><a href="#GBDT_76" rel="nofollow">三、与其他GBDT实现的对比</a></li><li><a href="#_80" rel="nofollow">四、实践应用与调参技巧</a></li><li><a href="#_141" rel="nofollow">五、结论</a></li></ul> 
   </li></ul> 
  </li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h4><a id="LightGBM__40"></a>LightGBM: 优化机器学习的高效梯度提升决策树</h4> 
<h5><a id="_42"></a>引言</h5> 
<p>在机器学习领域，梯度提升决策树(Gradient Boosting Decision Tree, GBDT)因其强大的预测能力和解释性而备受推崇。随着数据规模的日益增大，对模型训练速度和效率的需求也愈发迫切。在此背景下，Microsoft Research于2017年开源的LightGBM项目，凭借其高速度、高效率以及优秀的性能，在众多GBDT框架中脱颖而出，成为业界和学术界的新宠。本文将深入探讨LightGBM的核心优势、工作原理、关键特性和应用场景，旨在为读者提供一份全面而深入的理解指南。<br> <img src="https://images2.imgbox.com/47/13/vhBsvsfa_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="LightGBM_47"></a>一、LightGBM概览</h5> 
<p><strong>诞生背景</strong>：面对传统GBDT在处理大规模数据集时遇到的内存消耗大、训练时间长等问题，LightGBM应运而生，它通过一系列创新算法设计显著提高了训练效率。</p> 
<p><strong>核心特点</strong>：</p> 
<ul><li><strong>高效性</strong>：利用直方图近似和基于梯度的单边采样等技术，大幅减少计算量。</li><li><strong>低内存消耗</strong>：通过叶子权重直方图存储方式，极大降低了内存使用。</li><li><strong>高并行性</strong>：支持特征并行、数据并行和投票并行等多种并行策略，加速训练过程。</li><li><strong>灵活性</strong>：支持自定义目标函数和评估指标，满足多样化需求。</li></ul> 
<h5><a id="_58"></a>二、核心技术解析</h5> 
<h6><a id="1_Histogram_Approximation_60"></a>1. 直方图近似（Histogram Approximation）</h6> 
<p>传统的GBDT方法在每一轮迭代中需要遍历所有数据来计算梯度，这在大数据场景下极为耗时。LightGBM引入了<strong>直方图</strong>的概念，将连续的特征值离散化为几个区间，仅需统计每个区间内的样本数量和梯度统计量，从而大大减少了计算量，加速了训练过程。<br> <img src="https://images2.imgbox.com/65/e7/KYOT1Vhm_o.png" alt="在这里插入图片描述"></p> 
<h6><a id="2_GradientBased_OneSide_Sampling_GOSS_65"></a>2. 基于梯度的单边采样（Gradient-Based One-Side Sampling, GOSS）</h6> 
<p>GOSS是一种有效的样本抽样策略，它根据样本的梯度大小进行有偏抽样，保留梯度较大的样本和一部分梯度较小的样本，这样既保留了重要信息，又大幅度减少了计算量，进一步提升了效率。<br> <img src="https://images2.imgbox.com/dc/51/YG8ZO9QM_o.png" alt="在这里插入图片描述"></p> 
<h6><a id="3__70"></a>3. 特征并行与数据并行</h6> 
<ul><li><strong>特征并行</strong>：将特征分配到不同的机器上进行独立的直方图构建，然后合并这些直方图，适用于特征维度较高的情况。</li><li><strong>数据并行</strong>：将数据集分割到不同机器，每台机器上分别建立自己的决策树，最后汇总决策树结果，适用于大数据集。<br> <img src="https://images2.imgbox.com/14/6a/j7LRnhla_o.png" alt="在这里插入图片描述"></li></ul> 
<h5><a id="GBDT_76"></a>三、与其他GBDT实现的对比</h5> 
<p>与XGBoost相比，LightGBM在训练速度和内存使用上通常表现更优，特别是在数据量较大时。然而，XGBoost提供了更多的调参选项，对于高度定制化的任务可能更为灵活。两者各有千秋，选择应依据具体任务需求。</p> 
<h5><a id="_80"></a>四、实践应用与调参技巧</h5> 
<p><strong>应用领域</strong>：LightGBM广泛应用于推荐系统、搜索引擎排名、金融风控、医疗诊断等多个领域，以其高效、准确的特性解决了一系列实际问题。</p> 
<p><strong>调参建议</strong>：</p> 
<ul><li><strong>学习率</strong>：初始值可设为0.1，过拟合时减小。</li><li><strong>树的最大深度</strong>：默认31，可根据数据复杂度调整。</li><li><strong>叶子节点最小样本数</strong>：控制模型复杂度，避免过拟合。</li><li><strong>特征抽样比例</strong>：通过调整<code>feature_fraction</code>参数平衡模型复杂度与性能。</li></ul> 
<p>以下是一个使用Python和LightGBM库进行分类任务的基本示例代码。这个例子中，我们将使用经典的鸢尾花（Iris）数据集来训练一个简单的LightGBM模型，并进行基本的模型评估。代码仅供参考🐶</p> 
<pre><code class="prism language-python"><span class="token comment"># 导入所需库</span>
<span class="token keyword">import</span> lightgbm <span class="token keyword">as</span> lgb
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> load_iris
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> accuracy_score<span class="token punctuation">,</span> classification_report

<span class="token comment"># 加载数据</span>
iris <span class="token operator">=</span> load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span>
X <span class="token operator">=</span> iris<span class="token punctuation">.</span>data
y <span class="token operator">=</span> iris<span class="token punctuation">.</span>target

<span class="token comment"># 划分训练集和测试集</span>
X_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span>

<span class="token comment"># 转换数据格式为LightGBM所需的类型</span>
lgb_train <span class="token operator">=</span> lgb<span class="token punctuation">.</span>Dataset<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> label<span class="token operator">=</span>y_train<span class="token punctuation">)</span>
lgb_eval <span class="token operator">=</span> lgb<span class="token punctuation">.</span>Dataset<span class="token punctuation">(</span>X_test<span class="token punctuation">,</span> label<span class="token operator">=</span>y_test<span class="token punctuation">,</span> reference<span class="token operator">=</span>lgb_train<span class="token punctuation">)</span>

<span class="token comment"># 设置参数</span>
params <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token string">'boosting_type'</span><span class="token punctuation">:</span> <span class="token string">'gbdt'</span><span class="token punctuation">,</span>
    <span class="token string">'objective'</span><span class="token punctuation">:</span> <span class="token string">'multiclass'</span><span class="token punctuation">,</span>
    <span class="token string">'num_class'</span><span class="token punctuation">:</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token comment"># 因为鸢尾花数据集有3个类别</span>
    <span class="token string">'metric'</span><span class="token punctuation">:</span> <span class="token string">'multi_logloss'</span><span class="token punctuation">,</span>
    <span class="token string">'num_leaves'</span><span class="token punctuation">:</span> <span class="token number">31</span><span class="token punctuation">,</span>
    <span class="token string">'learning_rate'</span><span class="token punctuation">:</span> <span class="token number">0.1</span><span class="token punctuation">,</span>
    <span class="token string">'feature_fraction'</span><span class="token punctuation">:</span> <span class="token number">0.9</span><span class="token punctuation">,</span>
    <span class="token string">'bagging_fraction'</span><span class="token punctuation">:</span> <span class="token number">0.8</span><span class="token punctuation">,</span>
    <span class="token string">'bagging_freq'</span><span class="token punctuation">:</span> <span class="token number">5</span><span class="token punctuation">,</span>
    <span class="token string">'verbose'</span><span class="token punctuation">:</span> <span class="token number">0</span>
<span class="token punctuation">}</span>

<span class="token comment"># 训练模型</span>
gbm <span class="token operator">=</span> lgb<span class="token punctuation">.</span>train<span class="token punctuation">(</span>params<span class="token punctuation">,</span>
                lgb_train<span class="token punctuation">,</span>
                num_boost_round<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span> <span class="token comment"># 可以根据需要调整迭代轮数</span>
                valid_sets<span class="token operator">=</span>lgb_eval<span class="token punctuation">,</span>
                early_stopping_rounds<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>

<span class="token comment"># 预测</span>
y_pred <span class="token operator">=</span> gbm<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span>
y_pred_class <span class="token operator">=</span> y_pred<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment"># 将概率转换为类别</span>

<span class="token comment"># 评估</span>
accuracy <span class="token operator">=</span> accuracy_score<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> y_pred_class<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Accuracy:"</span><span class="token punctuation">,</span> accuracy<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\nClassification Report:\n"</span><span class="token punctuation">,</span> classification_report<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> y_pred_class<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p>这段代码首先导入必要的库和数据集，然后划分训练集和测试集。接着，它将数据转换为LightGBM可以处理的格式，并定义了模型的参数。之后，模型通过训练数据进行训练，并在测试集上进行预测。最后，我们计算并打印出模型的准确率和分类报告，以便评估模型的表现。</p> 
<h5><a id="_141"></a>五、结论</h5> 
<p>LightGBM作为GBDT家族中的佼佼者，凭借其高效的算法设计和优异的性能表现，成为了现代机器学习领域不可或缺的工具之一。无论是处理大规模数据集，还是追求模型训练速度与资源效率的平衡，LightGBM都展现出了强大的竞争力。随着算法的持续优化和社区的不断贡献，我们有理由相信，LightGBM将在未来机器学习的探索之路上扮演更加重要的角色。</p> 
<img src="https://images2.imgbox.com/59/c8/UWWgSEX6_o.png" width="250" height="250"> 
<p> <img src="https://images2.imgbox.com/a2/d9/wLo4nalY_o.gif" alt="End"> </p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/e1fcec5708f86b851fde47665165ba99/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【算法专题--链表】反转链表II--高频面试题（图文详解，小白一看就会！！！）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/afc81cc94c1e4f2464edf95761f29166/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">基于单片机的无人监守点滴控制系统设计</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>