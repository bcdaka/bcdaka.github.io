<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>手把手带你搭建一个语音对话机器人，5分钟定制个人AI小助手（新手入门篇） - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/4c0364b74c810a7d0bc7de8b9687963c/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="手把手带你搭建一个语音对话机器人，5分钟定制个人AI小助手（新手入门篇）">
  <meta property="og:description" content="写在前面 如果你的身边有一个随时待命、聪明绝顶的AI小助手，能够听懂你的话，理解你的需求，用温暖的声音回应你，会是一种什么体验？
今天，带大家从0到1搭建一个语音对话机器人，分分钟拥有一个专属的个人AI小助手。
本文面向技术小白，以最通俗易懂的语言，最贴心的步骤指导，确保你能够轻松上手，快速掌握。
语音对话系统的基本组成有哪些？ 一个可以实现语音对话的机器人，通常需要由硬件和软件构成，硬件可以理解为机器人的躯体。
本篇主要来聊聊语音对话机器人的软件部分。
说到软件部分，通常又可以抽象为三个部分：
自动语音识别（Automatic Speech Recognition, 简称 ASR），相当于 机器人的耳朵，用于把我们的语音识别成文字；自然语言处理（Natural Language Processing, 简称 NLP），相当于 机器人的大脑，理解上一步得到的文字信息，并进行答复，当前主流的解决方案是大语言模型LLM；文本到语音合成（Text to Speech，简称 TTS），相当于 机器人的嘴巴，把上一步的答复用语音回答出来 如何快速搭建语音对话系统？ 为了帮助大家从0到1快速完成一个系统的搭建，本文将完全采用开源方案来实现。具体而言：
ASR 采用 FunASR，相比 OpenAI 开源的 Whisper，中文识别效果更好；
NLP 采用大语言模型（LLM）方案，比如我们这里可以采用 LLaMA3-8B，采用本地的 GPU 部署和运行，如果没有本地 GPU 资源，也可以调用云端 API 实现这一步；
TTS 采用 最新开源的 ChatTTS，它是专门为对话场景设计的文本转语音模型，支持英文和中文两种语言，效果非常惊艳。
1 语音识别 ASR ASR 采用阿里开源的 FunASR，相比 OpenAI 开源的 Whisper，中文识别效果更好。
GitHub地址：https://github.com/modelscope/FunASR
模型调用参考：https://modelscope.cn/studios/iic/funasr_app_clipvideo/summary
通过如下代码，我们简单测试一下返回结果和模型效果：
from funasr import AutoModel # asr model funasr_model = AutoModel(model=&#34;iic/speech_seaco_paraformer_large_asr_nat-zh-cn-16k-common-vocab8404-pytorch&#34;, vad_model=&#34;damo/speech_fsmn_vad_zh-cn-16k-common-pytorch&#34;, punc_model=&#34;damo/punc_ct-transformer_zh-cn-common-vocab272727-pytorch&#34;, spk_model=&#34;damo/speech_campplus_sv_zh-cn_16k-common&#34;, ) rec_result = funasr_model.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-06-16T16:04:06+08:00">
    <meta property="article:modified_time" content="2024-06-16T16:04:06+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">手把手带你搭建一个语音对话机器人，5分钟定制个人AI小助手（新手入门篇）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_1"></a>写在前面</h2> 
<p>如果你的身边有一个随时待命、聪明绝顶的AI小助手，能够听懂你的话，理解你的需求，用温暖的声音回应你，会是一种什么体验？</p> 
<p>今天，带大家从0到1搭建一个语音对话机器人，分分钟拥有一个专属的个人AI小助手。</p> 
<p>本文面向技术小白，以最通俗易懂的语言，最贴心的步骤指导，确保你能够轻松上手，快速掌握。</p> 
<h2><a id="_7"></a>语音对话系统的基本组成有哪些？</h2> 
<p>一个可以实现语音对话的机器人，通常需要由硬件和软件构成，硬件可以理解为机器人的躯体。</p> 
<p>本篇主要来聊聊语音对话机器人的软件部分。</p> 
<p>说到软件部分，通常又可以抽象为三个部分：</p> 
<ul><li>自动语音识别（Automatic Speech Recognition, 简称 <strong>ASR</strong>），相当于 <strong>机器人的耳朵</strong>，用于把我们的语音识别成文字；</li><li>自然语言处理（Natural Language Processing, 简称 <strong>NLP</strong>），相当于 <strong>机器人的大脑</strong>，理解上一步得到的文字信息，并进行答复，当前主流的解决方案是<strong>大语言模型LLM</strong>；</li><li>文本到语音合成（Text to Speech，简称 <strong>TTS</strong>），相当于 <strong>机器人的嘴巴</strong>，把上一步的答复用语音回答出来</li></ul> 
<p><img src="https://images2.imgbox.com/c8/a4/pTN0xwK6_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="_18"></a>如何快速搭建语音对话系统？</h2> 
<p>为了帮助大家从0到1快速完成一个系统的搭建，本文将<strong>完全采用开源</strong>方案来实现。具体而言：</p> 
<ul><li> <p>ASR 采用 FunASR，相比 OpenAI 开源的 Whisper，中文识别效果更好；</p> </li><li> <p>NLP 采用大语言模型（LLM）方案，比如我们这里可以采用 LLaMA3-8B，采用本地的 GPU 部署和运行，如果没有本地 GPU 资源，也可以调用云端 API 实现这一步；</p> </li><li> <p>TTS 采用 最新开源的 ChatTTS，它是专门为对话场景设计的文本转语音模型，支持英文和中文两种语言，效果非常惊艳。</p> </li></ul> 
<h3><a id="1__ASR_28"></a>1 语音识别 ASR</h3> 
<p>ASR 采用阿里开源的 FunASR，相比 OpenAI 开源的 Whisper，中文识别效果更好。</p> 
<blockquote> 
 <p>GitHub地址：https://github.com/modelscope/FunASR<br> 模型调用参考：https://modelscope.cn/studios/iic/funasr_app_clipvideo/summary</p> 
</blockquote> 
<p>通过如下代码，我们简单测试一下返回结果和模型效果：</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> funasr <span class="token keyword">import</span> AutoModel
<span class="token comment"># asr model</span>
funasr_model <span class="token operator">=</span> AutoModel<span class="token punctuation">(</span>model<span class="token operator">=</span><span class="token string">"iic/speech_seaco_paraformer_large_asr_nat-zh-cn-16k-common-vocab8404-pytorch"</span><span class="token punctuation">,</span>
                             vad_model<span class="token operator">=</span><span class="token string">"damo/speech_fsmn_vad_zh-cn-16k-common-pytorch"</span><span class="token punctuation">,</span>
                             punc_model<span class="token operator">=</span><span class="token string">"damo/punc_ct-transformer_zh-cn-common-vocab272727-pytorch"</span><span class="token punctuation">,</span>
                             spk_model<span class="token operator">=</span><span class="token string">"damo/speech_campplus_sv_zh-cn_16k-common"</span><span class="token punctuation">,</span>
                            <span class="token punctuation">)</span>
rec_result <span class="token operator">=</span> funasr_model<span class="token punctuation">.</span>generate<span class="token punctuation">(</span><span class="token string">"test.wav"</span><span class="token punctuation">,</span> return_raw_text<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> is_final<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
</code></pre> 
<p>接下来我们需要将其封装成一个 API ，方便后续调用。最简单的我们可以采用 FastAPI 来实现封装，示例代码如下：</p> 
<pre><code class="prism language-python"><span class="token comment"># 定义asr数据模型，用于接收POST请求中的数据</span>
<span class="token keyword">class</span> <span class="token class-name">ASRItem</span><span class="token punctuation">(</span>BaseModel<span class="token punctuation">)</span><span class="token punctuation">:</span>
    wav <span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token comment"># 输入音频，base64编码</span>
    time_stamp <span class="token punctuation">:</span> <span class="token builtin">int</span> <span class="token operator">=</span> <span class="token number">0</span> <span class="token comment"># 时间戳，可选，默认为0</span>

app <span class="token operator">=</span> FastAPI<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token decorator annotation punctuation">@app<span class="token punctuation">.</span>post</span><span class="token punctuation">(</span><span class="token string">"/asr"</span><span class="token punctuation">)</span>
<span class="token keyword">async</span> <span class="token keyword">def</span> <span class="token function">asr</span><span class="token punctuation">(</span>item<span class="token punctuation">:</span> ASRItem<span class="token punctuation">)</span><span class="token punctuation">:</span>
    time_stamp <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>item<span class="token punctuation">.</span>time_stamp<span class="token punctuation">)</span>
    <span class="token keyword">try</span><span class="token punctuation">:</span>
        data <span class="token operator">=</span> base64<span class="token punctuation">.</span>b64decode<span class="token punctuation">(</span>item<span class="token punctuation">.</span>wav<span class="token punctuation">)</span>
        rec_result <span class="token operator">=</span> funasr_model<span class="token punctuation">.</span>generate<span class="token punctuation">(</span>data<span class="token punctuation">,</span> return_raw_text<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> is_final<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        res <span class="token operator">=</span> rec_result<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'sentence_info'</span><span class="token punctuation">]</span> <span class="token keyword">if</span> time_stamp <span class="token keyword">else</span> rec_result<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'text'</span><span class="token punctuation">]</span>
        result_dict <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">"code"</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">"msg"</span><span class="token punctuation">:</span> <span class="token string">"ok"</span><span class="token punctuation">,</span> <span class="token string">"res"</span><span class="token punctuation">:</span> res<span class="token punctuation">}</span>
    <span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>
        result_dict <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">"code"</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">"msg"</span><span class="token punctuation">:</span> <span class="token builtin">str</span><span class="token punctuation">(</span>e<span class="token punctuation">)</span><span class="token punctuation">}</span>
    <span class="token keyword">return</span> result_dict

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    uvicorn<span class="token punctuation">.</span>run<span class="token punctuation">(</span>app<span class="token punctuation">,</span> host<span class="token operator">=</span><span class="token string">'0.0.0.0'</span><span class="token punctuation">,</span> port<span class="token operator">=</span><span class="token number">2002</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="2_LLM_71"></a>2 大语言模型（LLM）</h3> 
<p>为了实现对话功能，我们可以采用当前的大语言模型（LLM），对上一步识别出来的文字进行理解，并给出答复。</p> 
<p>本文的 LLM 采用 LLaMA3-8B，开源社区已经实现了对 LLaMA3-8B 的中文指令微调，为此中文效果会比原始版本效果更好。</p> 
<blockquote> 
 <p>GitHub地址：https://github.com/ymcui/Chinese-LLaMA-Alpaca-3<br> 模型地址：https://modelscope.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-instruct/summary</p> 
</blockquote> 
<p>在上述的 GitHub 仓库中，给出了一键部署的脚本，非常方便。四步走搞定它：</p> 
<ul><li>下载代码</li><li>下载模型</li><li>安装必要的包</li><li>服务启动</li></ul> 
<p><strong>step 1 下载代码：</strong></p> 
<pre><code class="prism language-python">git clone https<span class="token punctuation">:</span><span class="token operator">//</span>github<span class="token punctuation">.</span>com<span class="token operator">/</span>ymcui<span class="token operator">/</span>Chinese<span class="token operator">-</span>LLaMA<span class="token operator">-</span>Alpaca<span class="token operator">-</span><span class="token number">3</span>
</code></pre> 
<p><strong>step 2 下载模型：</strong></p> 
<pre><code class="prism language-python">git clone https<span class="token punctuation">:</span><span class="token operator">//</span>www<span class="token punctuation">.</span>modelscope<span class="token punctuation">.</span>cn<span class="token operator">/</span>ChineseAlpacaGroup<span class="token operator">/</span>llama<span class="token operator">-</span><span class="token number">3</span><span class="token operator">-</span>chinese<span class="token operator">-</span>8b<span class="token operator">-</span>instruct<span class="token punctuation">.</span>git
</code></pre> 
<p><strong>step 3 安装必要的包：</strong></p> 
<pre><code class="prism language-python">pip install fastapi uvicorn shortuuid sse_starlette peft bitsandbytes
pip install flash<span class="token operator">-</span>attn <span class="token operator">-</span><span class="token operator">-</span>no<span class="token operator">-</span>build<span class="token operator">-</span>isolation <span class="token comment"># 如果要使用flash-attention的话</span>
</code></pre> 
<p><strong>step 4 服务启动：</strong><br> 服务启动的代码如下，<code>--base_model</code> 替换为自己的模型路径，<code>--load_in_4bit</code> 指定了采用 4bit 量化。</p> 
<p><strong>注意：如果采用不量化的方案，显存占用12G，回复非常慢，有请求过来显存占用最高近14G，而采用4bit 量化，显存只占用 6G。</strong></p> 
<pre><code class="prism language-python">python scripts<span class="token operator">/</span>oai_api_demo<span class="token operator">/</span>openai_api_server<span class="token punctuation">.</span>py \
<span class="token operator">-</span><span class="token operator">-</span>base_model <span class="token operator">/</span>path<span class="token operator">/</span>to<span class="token operator">/</span>models<span class="token operator">/</span>llama<span class="token operator">-</span><span class="token number">3</span><span class="token operator">-</span>chinese<span class="token operator">-</span>8b<span class="token operator">-</span>instruct<span class="token operator">/</span> \
<span class="token operator">-</span><span class="token operator">-</span>gpus <span class="token number">2</span> \
<span class="token operator">-</span><span class="token operator">-</span>port <span class="token number">2001</span> \
<span class="token operator">-</span><span class="token operator">-</span>load_in_4bit \
<span class="token operator">-</span><span class="token operator">-</span>use_flash_attention_2 \
<span class="token operator">&gt;</span> log<span class="token punctuation">.</span>txt <span class="token number">2</span><span class="token operator">&gt;</span><span class="token operator">&amp;</span><span class="token number">1</span> <span class="token operator">&amp;</span>
</code></pre> 
<p><strong>step 5 服务调用：</strong><br> 为了实现 LLM 的个性化回答，当然需要给它设定一个特定的人设啦 ~ ，这一步可以通过<strong>人设提示词</strong>来轻松搞定。下面给一个示例：</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> openai <span class="token keyword">import</span> OpenAI

<span class="token comment"># 枚举所有可用的模型服务</span>
model_dict <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token string">'llama3-8b'</span><span class="token punctuation">:</span> <span class="token punctuation">{<!-- --></span>
        <span class="token string">'api_key'</span><span class="token punctuation">:</span> <span class="token string">'sk-xxx'</span><span class="token punctuation">,</span>
        <span class="token string">'base_url'</span><span class="token punctuation">:</span> <span class="token string">'http://10.18.32.170:2001/v1'</span><span class="token punctuation">,</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
<span class="token punctuation">}</span>

<span class="token comment"># 设置人设提示词，根据需要进行修改</span>
prompt_dict <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token string">'llama3-8b'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>
        <span class="token punctuation">{<!-- --></span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"system"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> <span class="token string">"你是猴哥的全能小助手，上知天文，下知地理，可解决生活中的一切困扰。"</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">]</span><span class="token punctuation">,</span>
<span class="token punctuation">}</span>

<span class="token keyword">class</span> <span class="token class-name">LLM_API</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> api_key<span class="token punctuation">,</span> base_url<span class="token punctuation">,</span> model<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>client <span class="token operator">=</span>  OpenAI<span class="token punctuation">(</span>
            api_key<span class="token operator">=</span>api_key<span class="token punctuation">,</span>
            base_url<span class="token operator">=</span>base_url<span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>model <span class="token operator">=</span> model
    
    <span class="token keyword">def</span> <span class="token function">__call__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> messages<span class="token punctuation">,</span> temperature<span class="token operator">=</span><span class="token number">0.7</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        completion <span class="token operator">=</span> self<span class="token punctuation">.</span>client<span class="token punctuation">.</span>chat<span class="token punctuation">.</span>completions<span class="token punctuation">.</span>create<span class="token punctuation">(</span>
            model<span class="token operator">=</span>self<span class="token punctuation">.</span>model<span class="token punctuation">,</span>
            messages<span class="token operator">=</span>messages<span class="token punctuation">,</span>
            temperature<span class="token operator">=</span>temperature<span class="token punctuation">,</span>
        <span class="token punctuation">)</span>
        <span class="token keyword">return</span> completion<span class="token punctuation">.</span>choices<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>message<span class="token punctuation">.</span>content

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    model <span class="token operator">=</span> <span class="token string">'llama3-8b'</span>
    llm <span class="token operator">=</span> LLM_API<span class="token punctuation">(</span>model_dict<span class="token punctuation">[</span>model<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'api_key'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> model_dict<span class="token punctuation">[</span>model<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'base_url'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> model<span class="token punctuation">)</span>
    user_question <span class="token operator">=</span> <span class="token string">"你是谁"</span>
    messages <span class="token operator">=</span> prompt_dict<span class="token punctuation">[</span>model<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">[</span><span class="token punctuation">{<!-- --></span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> user_question<span class="token punctuation">}</span><span class="token punctuation">,</span><span class="token punctuation">]</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>llm<span class="token punctuation">(</span>messages<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p>如果本地没有 GPU 资源部署 大语言模型，也可以选择调用云端 API 来实现这一步，猴哥下一篇就来梳理一下：<br> <strong>我们都可以调用哪些免费的 LLM API?</strong></p> 
<p><strong>欢迎追更！</strong></p> 
<h3><a id="3_TTS_168"></a>3 语音生成（TTS）</h3> 
<p>为了将大模型输出的文字生成语音返回，这里我们采用 2024.5 刚开源的项目 - ChatTTS，生成效果非常惊艳。关于 ChatTTS 的具体使用，猴哥会单独出一篇教程，否则本文的篇幅就太长了。</p> 
<p>同样还是采用 FastAPI 来实现封装，和部署 ASR 模型类似，在此不再赘述。</p> 
<p><strong>（PS：需要源码的可到文末自取~）</strong></p> 
<h3><a id="4_Gradio_176"></a>4 前端交互实现（Gradio）</h3> 
<p>Gradio是一个用于快速创建机器学习模型的交互式演示的开源库。它允许开发者通过简单的Python代码快速构建一个用户界面。</p> 
<p>为了快速搭建应用，我们还是要请出我们的老朋友 - Gradio，交互界面如图所示：<br> <img src="https://images2.imgbox.com/4f/55/Ysyiqtxp_o.png" alt="在这里插入图片描述"></p> 
<p>WebUI 代码奉上：</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> gradio <span class="token keyword">as</span> gr 
<span class="token keyword">from</span> speech_client <span class="token keyword">import</span> asr_damo_api<span class="token punctuation">,</span> tts_chat_api
<span class="token keyword">from</span> llm_client <span class="token keyword">import</span> LLM_API<span class="token punctuation">,</span> prompt_dict<span class="token punctuation">,</span> model_dict

host_avatar <span class="token operator">=</span> <span class="token string">'assets/host_image.png'</span>
user_avatar <span class="token operator">=</span> <span class="token string">'assets/user_image.png'</span>

model <span class="token operator">=</span> <span class="token string">'llama3-8b'</span>
<span class="token comment"># model = 'gpt-4'</span>
llm <span class="token operator">=</span> LLM_API<span class="token punctuation">(</span>model_dict<span class="token punctuation">[</span>model<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'api_key'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> model_dict<span class="token punctuation">[</span>model<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'base_url'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> model<span class="token punctuation">)</span>

<span class="token keyword">with</span> gr<span class="token punctuation">.</span>Blocks<span class="token punctuation">(</span>theme<span class="token operator">=</span>gr<span class="token punctuation">.</span>themes<span class="token punctuation">.</span>ThemeClass<span class="token punctuation">)</span> <span class="token keyword">as</span> demo<span class="token punctuation">:</span>
    state <span class="token operator">=</span> gr<span class="token punctuation">.</span>State<span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span><span class="token string">'messages'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
    <span class="token keyword">with</span> gr<span class="token punctuation">.</span>Row<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">with</span> gr<span class="token punctuation">.</span>Column<span class="token punctuation">(</span>scale<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            user_chatbot <span class="token operator">=</span> gr<span class="token punctuation">.</span>Chatbot<span class="token punctuation">(</span>
                value<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token string">'欢迎你来！'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                elem_classes<span class="token operator">=</span><span class="token string">"app-chatbot"</span><span class="token punctuation">,</span>
                avatar_images<span class="token operator">=</span><span class="token punctuation">[</span>host_avatar<span class="token punctuation">,</span> user_avatar<span class="token punctuation">]</span><span class="token punctuation">,</span>
                label<span class="token operator">=</span><span class="token string">"交互区"</span><span class="token punctuation">,</span>
                show_label<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                bubble_full_width<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
                height<span class="token operator">=</span><span class="token number">800</span><span class="token punctuation">)</span>
        <span class="token keyword">with</span> gr<span class="token punctuation">.</span>Column<span class="token punctuation">(</span>scale<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            audio_user <span class="token operator">=</span> gr<span class="token punctuation">.</span>Audio<span class="token punctuation">(</span>label<span class="token operator">=</span><span class="token string">"User Input"</span><span class="token punctuation">,</span> sources<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'microphone'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'filepath'</span><span class="token punctuation">)</span>
            user_text <span class="token operator">=</span> gr<span class="token punctuation">.</span>Textbox<span class="token punctuation">(</span>label<span class="token operator">=</span><span class="token string">"语音识别内容"</span><span class="token punctuation">)</span>
            user_submit <span class="token operator">=</span> gr<span class="token punctuation">.</span>Button<span class="token punctuation">(</span><span class="token string">"提交"</span><span class="token punctuation">,</span> variant<span class="token operator">=</span><span class="token string">"primary"</span><span class="token punctuation">)</span>
            audio_bot <span class="token operator">=</span> gr<span class="token punctuation">.</span>Audio<span class="token punctuation">(</span>label<span class="token operator">=</span><span class="token string">"Bot Output"</span><span class="token punctuation">,</span> autoplay<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'filepath'</span><span class="token punctuation">)</span>
   
    <span class="token keyword">def</span> <span class="token function">process_audio</span><span class="token punctuation">(</span>audio<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Processing audio:'</span><span class="token punctuation">,</span> audio<span class="token punctuation">)</span>
        text <span class="token operator">=</span> asr_damo_api<span class="token punctuation">(</span>audio<span class="token punctuation">,</span> time_stamp<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> srt<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span>
        <span class="token keyword">return</span> text

    <span class="token keyword">def</span> <span class="token function">user_submit_handler</span><span class="token punctuation">(</span>user_text<span class="token punctuation">,</span> state<span class="token punctuation">,</span> chatbot<span class="token punctuation">)</span><span class="token punctuation">:</span>
        chatbot<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>user_text<span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">yield</span> <span class="token punctuation">(</span>chatbot<span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span>
        messages <span class="token operator">=</span> state<span class="token punctuation">[</span><span class="token string">'messages'</span><span class="token punctuation">]</span>
        <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>messages<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            messages <span class="token operator">=</span> prompt_dict<span class="token punctuation">[</span>model<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">[</span><span class="token punctuation">{<!-- --></span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> user_text<span class="token punctuation">}</span><span class="token punctuation">]</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            messages<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> user_text<span class="token punctuation">}</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>messages<span class="token punctuation">)</span>
        response <span class="token operator">=</span> llm<span class="token punctuation">(</span>messages<span class="token punctuation">)</span>
        chatbot<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">)</span>
        messages<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">{<!-- --></span><span class="token string">"role"</span><span class="token punctuation">:</span> <span class="token string">"assistant"</span><span class="token punctuation">,</span> <span class="token string">"content"</span><span class="token punctuation">:</span> response<span class="token punctuation">}</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>messages<span class="token punctuation">)</span>
        state<span class="token punctuation">[</span><span class="token string">'messages'</span><span class="token punctuation">]</span> <span class="token operator">=</span> messages
        audio <span class="token operator">=</span> tts_chat_api<span class="token punctuation">(</span>response<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>audio<span class="token punctuation">)</span>
        <span class="token keyword">yield</span> <span class="token punctuation">(</span>chatbot<span class="token punctuation">,</span> audio<span class="token punctuation">)</span>
    
    audio_user<span class="token punctuation">.</span>stop_recording<span class="token punctuation">(</span>process_audio<span class="token punctuation">,</span> inputs<span class="token operator">=</span>audio_user<span class="token punctuation">,</span> outputs<span class="token operator">=</span>user_text<span class="token punctuation">)</span>
    user_submit<span class="token punctuation">.</span>click<span class="token punctuation">(</span>user_submit_handler<span class="token punctuation">,</span> inputs<span class="token operator">=</span><span class="token punctuation">[</span>user_text<span class="token punctuation">,</span> state<span class="token punctuation">,</span> user_chatbot<span class="token punctuation">]</span><span class="token punctuation">,</span> outputs<span class="token operator">=</span><span class="token punctuation">[</span>user_chatbot<span class="token punctuation">,</span> audio_bot<span class="token punctuation">]</span><span class="token punctuation">)</span>

demo<span class="token punctuation">.</span>launch<span class="token punctuation">(</span>server_name<span class="token operator">=</span><span class="token string">'0.0.0.0'</span><span class="token punctuation">,</span> server_port<span class="token operator">=</span><span class="token number">7861</span><span class="token punctuation">)</span>
</code></pre> 
<p>最后我们来看下效果：</p> 
<p></p> 
<div class="csdn-video-box"> 
 <iframe id="EPMLNDff-1718342864805" frameborder="0" src="https://live.csdn.net/v/embed/399092" allowfullscreen="true" data-mediaembed="csdn"></iframe> 
 <p>语音对话机器人-个人AI小助手</p> 
</div> 
<p></p> 
<h2><a id="_247"></a>未完待续</h2> 
<p>至此，一个语音对话交互系统就搭建好了，当然目前只是为了演示基本功能，界面还比较简陋，在此基础上 ，还可以增加更多功能：</p> 
<ul><li>ASR : 目前采用的 FunASR 模型，在有噪声情况下识别效果还有待增强，需要找到更有效的平替；</li><li>LLM：模型本地部署对很多小伙伴还是有一定门槛，需要找到平价 or 免费的云端 API</li><li>TTS：ChatTTS的效果非常不错，后续可以增加说话人身份，实现更丰富的输出；支持流式对话，像 GPT-4o 那样自然打断。</li></ul> 
<p>如果本文对你有帮助，欢迎<strong>点赞收藏</strong>备用！</p> 
<p>猴哥一直在做 AI 领域的研发和探索，会陆续跟大家分享路上的思考和心得。</p> 
<p>最近开始运营一个公众号，旨在分享关于AI效率工具、自媒体副业的一切。用心做内容，不辜负每一份关注。</p> 
<p>如需要获取本项目的源码，可关注后台发送 “机器人” 获取👇。<br> <img src="https://images2.imgbox.com/d4/11/8MC4zy2x_o.png" alt=""></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/e6e5d0b8398eb7134b752d69116c2b69/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">AI 定位！GeoSpyAI上传一张图片分析具体位置 不可思议! ! !</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/9999ff15583194f29125f79e1336b8df/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">spring boot3登录开发-邮箱登录/注册接口实现</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>