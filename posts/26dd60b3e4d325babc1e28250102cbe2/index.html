<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>大数据-kafka学习笔记_error while fetching metadata with correlation id - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/26dd60b3e4d325babc1e28250102cbe2/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="大数据-kafka学习笔记_error while fetching metadata with correlation id">
  <meta property="og:description" content="由多个kafka消费者组成的一组消费者组，用于同时消费处理kafka中一个主题所有分区中的数据。只要在创建kafka消费者的时候将group id设置成一样的，那么就可以创建多个消费者构成消费者组了。
一个主题的一个分区只能由一个消费者组内的一个消费者处理，否则会导致数据重复消费。一个消费者组的每个消费者负责消费不同分区的数据。
消费者组的好处：加快消费处理数据的速度，横向提高整个消费能力。如下图，一开始就一个消费者c1，他要自己一个人消费处理来自topicA主题的四个分区的数据，而我们可以增加三个消费者c2、c3、c4和c1构成一个消费者组来同时消费处理topicA主题的四个分区的数据，这样消费处理数据的速度就提升了。（前提是有多个分区）
主题 上面那样肯定不好，各种消息的的生产者（生产圆蛋蛋、生产方框框、生产小心心）将消息都发给kafka，然后kafka将消息都分类，每种分类都有相应的主题，然后消费者根据需要订阅相应的主题。就能收到对应的消息。
分区 如果一个主题的消息比较多，就可以考虑分区，分区可以分布在不同的服务器上，所以主题也可以分布在不同的服务器上，这样比单服务器处理快。
如果生成者没有指定分区，分区器就会根据每条消息的键算出消息该去哪个分区。键：就是每条消息的一个标记，决定了消息该去哪个分区。分区器：就是一个算法，算消息该去哪个分区，输入是键，输出是消息去的分区。
偏移量 偏移量就是消息在每个分区中的位置，kafka在收到消息的时候，会为每个消息设置偏移量，然后将消息存到磁盘中。
消费者只能按顺序消费读取。消费者如果要分区0的第四个，kafka就会说第三个还没读取，不给第四个。
kafka集群 一个broker就是一个kafka服务器。下面有两个broker构成了kafka集群，他们的数据通过复制同步，当有一个kafka宕机了，另一台就可以先顶上，保证了kafka的可靠性。
监控kafka 这个前提得先安装jdk
1、修改kafka的启动脚本
vim bin/kafka-server-start.sh
if [ “x$KAFKA_HEAP_OPTS” = “x” ]; then
export KAFKA_HEAP_OPTS=“-Xmx1G -Xms1G”
fi
改为
if [ “x$KAFKA_HEAP_OPTS” = “x” ]; then
export KAFKA_HEAP_OPTS=“-server -Xms2G -Xmx2G
-XX:PermSize=128m -XX:&#43;UseG1GC -XX:MaxGCPauseMillis=200
-XX:ParallelGCThreads=8 -XX:ConcGCThreads=5
-XX:InitiatingHeapOccupancyPercent=70”
export JMX_PORT=“9999”
#export KAFKA_HEAP_OPTS=“-Xmx1G -Xms1G”
fi
修改kafka进程信息：
-Xms2G：设置 Kafka 进程的初始堆内存大小为 2 GB。
-Xmx2G：设置 Kafka 进程的最大堆内存大小为 2 GB。
XX:PermSize=128m：设置持久代（PermGen）的初始大小为 128 MB。请注意，这个选项在 Java 8 和更新的版本中不再适用，因为 PermGen 已被 Metaspace 取代。">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-04-08T19:01:44+08:00">
    <meta property="article:modified_time" content="2024-04-08T19:01:44+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">大数据-kafka学习笔记_error while fetching metadata with correlation id</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>由多个kafka消费者组成的一组消费者组，用于同时消费处理kafka中一个主题所有分区中的数据。只要在创建kafka消费者的时候将group id设置成一样的，那么就可以创建多个消费者构成消费者组了。</p> 
<p>一个主题的一个分区只能由一个消费者组内的一个消费者处理，否则会导致数据重复消费。一个消费者组的每个消费者负责消费不同分区的数据。</p> 
<p>消费者组的好处：加快消费处理数据的速度，横向提高整个消费能力。如下图，一开始就一个消费者c1，他要自己一个人消费处理来自topicA主题的四个分区的数据，而我们可以增加三个消费者c2、c3、c4和c1构成一个消费者组来同时消费处理topicA主题的四个分区的数据，这样消费处理数据的速度就提升了。（<strong>前提是有多个分区</strong>）</p> 
<p><img src="https://images2.imgbox.com/78/bf/vi3p8prP_o.png" alt=""></p> 
<h4><a id="_14"></a>主题</h4> 
<p><img src="https://images2.imgbox.com/72/02/3Xw2MuUt_o.png" alt="在这里插入图片描述"></p> 
<p>上面那样肯定不好，各种消息的的生产者（生产圆蛋蛋、生产方框框、生产小心心）将消息都发给kafka，然后kafka将消息都分类，每种分类都有相应的主题，然后消费者根据需要订阅相应的主题。就能收到对应的消息。<br> <img src="https://images2.imgbox.com/06/74/IXRJu5Vz_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="_24"></a><strong>分区</strong></h4> 
<p>如果一个主题的消息比较多，就可以考虑分区，分区可以分布在不同的服务器上，所以主题也可以分布在不同的服务器上，这样比单服务器处理快。<br> <img src="https://images2.imgbox.com/c5/5b/MWb4KygO_o.png" alt="在这里插入图片描述"></p> 
<p>如果生成者没有指定分区，分区器就会根据每条消息的键算出消息该去哪个分区。键：就是每条消息的一个标记，决定了消息该去哪个分区。分区器：就是一个算法，算消息该去哪个分区，输入是键，输出是消息去的分区。<br> <img src="https://images2.imgbox.com/92/3e/Xgvns1Ee_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="_35"></a><strong>偏移量</strong></h4> 
<p>偏移量就是消息在每个分区中的位置，kafka在收到消息的时候，会为每个消息设置偏移量，然后将消息存到磁盘中。</p> 
<p>消费者只能按顺序消费读取。消费者如果要分区0的第四个，kafka就会说第三个还没读取，不给第四个。</p> 
<h4><a id="kafka_44"></a><strong>kafka集群</strong></h4> 
<p>一个broker就是一个kafka服务器。下面有两个broker构成了kafka集群，他们的数据通过复制同步，当有一个kafka宕机了，另一台就可以先顶上，保证了kafka的可靠性。</p> 
<p><img src="https://images2.imgbox.com/ca/71/zCDX9TNL_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="kafka_53"></a>监控kafka</h4> 
<p>这个前提得先安装jdk</p> 
<p>1、修改kafka的启动脚本</p> 
<p>vim bin/kafka-server-start.sh</p> 
<p>if [ “x$KAFKA_HEAP_OPTS” = “x” ]; then<br> export KAFKA_HEAP_OPTS=“-Xmx1G -Xms1G”<br> fi</p> 
<p>改为</p> 
<p>if [ “x$KAFKA_HEAP_OPTS” = “x” ]; then<br> export KAFKA_HEAP_OPTS=“-server -Xms2G -Xmx2G<br> -XX:PermSize=128m -XX:+UseG1GC -XX:MaxGCPauseMillis=200<br> -XX:ParallelGCThreads=8 -XX:ConcGCThreads=5<br> -XX:InitiatingHeapOccupancyPercent=70”<br> export JMX_PORT=“9999”<br> #export KAFKA_HEAP_OPTS=“-Xmx1G -Xms1G”<br> fi</p> 
<p>修改kafka进程信息：<br> -Xms2G：设置 Kafka 进程的初始堆内存大小为 2 GB。<br> -Xmx2G：设置 Kafka 进程的最大堆内存大小为 2 GB。<br> XX:PermSize=128m：设置持久代（PermGen）的初始大小为 128 MB。请注意，这个选项在 Java 8 和更新的版本中不再适用，因为 PermGen 已被 Metaspace 取代。<br> -XX:+UseG1GC：指定使用 G1 垃圾收集器。<br> -XX:MaxGCPauseMillis=200：设置最大垃圾收集暂停时间为 200 毫秒。<br> XX:ParallelGCThreads=8：设置并行垃圾收集线程的数量为 8。<br> XX:ConcGCThreads=5：设置并发垃圾收集线程的数量为 5。<br> XX:InitiatingHeapOccupancyPercent=70：设置堆内存占用百分比，当堆内存使用达到 70% 时，启动并发垃圾收集。<br> 这些参数的目的是调整 Kafka 进程的性能和垃圾收集行为，以满足特定的性能需求。请注意，这些参数的值可以根据你的 Kafka 部署和硬件资源进行调整。堆内存的大小和垃圾收集器的选择将影响 Kafka 的性能和稳定性。</p> 
<p>最后，这段脚本还设置了 JMX 端口为 9999，这是用于监控 Kafka 进程的 Java Management Extensions（JMX）端口。通过此端口，你可以使用 JMX 工具监控 Kafka 进程的性能指标和状态。如果需要监控 Kafka，你可以使用 JMX 工具连接到此端口。</p> 
<p>2、官网下载安装包</p> 
<p>https://www.kafka-eagle.org/</p> 
<p>3、上传解压</p> 
<p>第一次解压后，里面有个压缩包再解压才是真正的。<br> <img src="https://images2.imgbox.com/97/75/AFORxj0I_o.png" alt="在这里插入图片描述"></p> 
<p>/opt/module/efak/conf/system-config.properties</p> 
<p><img src="https://images2.imgbox.com/58/89/I7AMYu1l_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/4c/cd/N3uiiQwn_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/4e/f5/TQywXY6A_o.png" alt="在这里插入图片描述"></p> 
<p>5、配置环境变量</p> 
<p>$ sudo vim /etc/profile.d/my_env.sh</p> 
<h2><a id="kafkaEFAK_141"></a>kafkaEFAK</h2> 
<p>export KE_HOME=/opt/module/efak<br> export PATH=<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         P 
        
       
         A 
        
       
         T 
        
       
         H 
        
       
         : 
        
       
      
        PATH: 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord mathnormal" style="margin-right: 0.1389em;">P</span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right: 0.1389em;">T</span><span class="mord mathnormal" style="margin-right: 0.0813em;">H</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">:</span></span></span></span></span>KE_HOME/bin</p> 
<p>source /etc/profile</p> 
<p>6、启动</p> 
<p>/bin/kf.sh start</p> 
<h4><a id="_158"></a>压力测试</h4> 
<h2><a id="Kafka10000001k_163"></a>单Kafka服务器，生成者发送1000000条数据，每条大小1k，总共发送大约</h2> 
<p>bin/kafka-producer-perf-test.sh --topic test --record-size 1024 --num-records 1000000 --throughput 10000 --producer-props bootstrap.servers=linjl:9092 batch.size=16384 linger.ms=0</p> 
<p>batch.size=16384 linger.ms=0 9.76 MB/sec</p> 
<p>record-size 是一条信息有多大，单位是字节，本次测试设置为 1k。</p> 
<h4><a id="BUG_173"></a>BUG</h4> 
<p>1、Error while fetching metadata with correlation id : {LEADER_NOT_AVAILABLE}</p> 
<p><img src="https://images2.imgbox.com/d9/d0/6L2vu3qE_o.png" alt="在这里插入图片描述"></p> 
<p>2、</p> 
<p>[root@linjl kafka_2.12-3.0.0]# ./bin/kafka-console-consumer.sh --topic quickstart-events --bootstrap-server linjl:9092</p> 
<p>[2023-09-13 16:51:54,710] WARN [Consumer clientId=consumer-console-consumer-32025-1, groupId=console-consumer-32025] Error while fetching metadata with correlation id 2 : {quickstart-events=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)</p> 
<p>这个警告消息 “Error while fetching metadata with correlation id 2 : {quickstart-events=LEADER_NOT_AVAILABLE}” 表示 Kafka 消费者在尝试订阅主题 “quickstart-events” 时遇到了 “LEADER_NOT_AVAILABLE” 错误。这个错误通常表示消费者无法找到主题的 leader 分区，因此它无法读取消息。</p> 
<p>我的猜想： 可能是因为 Kafka 服务器无法从 ZooKeeper 获取到有关 “quickstart-events” 主题的元数据信息，包括分区的 Leader 信息。</p> 
<p>3、Received invalid metadata error in produce request on partition quickstart-events-0</p> 
<p>due to org.apache.kafka.common.errors.KafkaStorageException: Disk error when trying to access log file on the disk… Going to request metadata update now (org.apache.kafka.clients.producer.internals.Sender)</p> 
<p>表示在尝试将消息写入分区 “quickstart-events-0” 时，Kafka 生产者遇到了磁盘错误，无法访问日志文件。这个错误通常与磁盘故障或磁盘空间不足有关。</p> 
<p>4、Java客户端创建生产者，发送消息给kafka没响应。</p> 
<p>Properties properties = new Properties();<br> properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,“192.168.239.128:9092”);<br> // key,value 序列化（必须）：key.serializer，value.serializer<br> properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());<br> properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName())</p> 
<p>网络连接都能通，而且防火墙也都关了。</p> 
<p>解决：在server.properties配置文件中配置</p> 
<h2><a id="The_address_the_socket_server_listens_on_If_not_configured_the_host_name_will_be_equal_to_the_value_of_229"></a>The address the socket server listens on. If not configured, the host name will be equal to the value of</h2> 
<h2><a id="javanetInetAddressgetCanonicalHostName_with_PLAINTEXT_listener_name_and_port_9092_230"></a>java.net.InetAddress.getCanonicalHostName(), with PLAINTEXT listener name, and port 9092.</h2> 
<h2><a id="FORMAT_231"></a>FORMAT:</h2> 
<h2><a id="listeners__listener_namehost_nameport_232"></a>listeners = listener_name://host_name:port</h2> 
<h2><a id="EXAMPLE_233"></a>EXAMPLE:</h2> 
<h2><a id="listeners__PLAINTEXTyourhostname9092_234"></a>listeners = PLAINTEXT://your.host.name:9092</h2> 
<p>listeners=PLAINTEXT://192.168.239.128:9092</p> 
<p><img src="https://images2.imgbox.com/37/f8/1l2XDoFY_o.png" alt="1.png"></p> 
<p><img src="https://images2.imgbox.com/c8/a0/RIdRJ0ay_o.png" alt="2.png"></p> 
<h3><a id="kafkaflink_245"></a>kafka和flink结合案例</h3> 
<p>数据写入kafka，flink订阅消费</p> 
<p><img src="https://images2.imgbox.com/92/81/APYxBZur_o.png" alt="image"></p> 
<p><strong>安装kafka单服务</strong></p> 
<p>1、官方下载地址：http://kafka.apache.org/downloads.html</p> 
<p>2、解压安装包</p> 
<p>下载完将安装包上传到centos中，然后解压</p> 
<p>$ tar -zxvf kafka_2.12-3.0.0.tgz -C /opt/module/</p> 
<p>3、 修改解压后的文件名称</p> 
<p>$ mv kafka_2.12-3.0.0/ kafka</p> 
<p>4、进入到/opt/module/kafka 目录，修改配置文件</p> 
<p>$ cd config/</p> 
<p>$ vim server.properties</p> 
<p>#broker 的全局唯一编号，不能重复，只能是数字。<br> broker.id=0</p> 
<p><strong>自我介绍一下，小编13年上海交大毕业，曾经在小公司待过，也去过华为、OPPO等大厂，18年进入阿里一直到现在。</strong></p> 
<p><strong>深知大多数大数据工程师，想要提升技能，往往是自己摸索成长或者是报班学习，但对于培训机构动则几千的学费，着实压力不小。自己不成体系的自学效果低效又漫长，而且极易碰到天花板技术停滞不前！</strong></p> 
<p><strong>因此收集整理了一份《2024年大数据全套学习资料》，初衷也很简单，就是希望能够帮助到想自学提升又不知道该从何学起的朋友。</strong><br> <img src="https://images2.imgbox.com/b2/6f/xFitC1Ol_o.png" alt="img"><br> <img src="https://images2.imgbox.com/93/b7/wiKV19Cs_o.png" alt="img"><br> <img src="https://images2.imgbox.com/fe/a1/E28b1l0U_o.png" alt="img"><br> <img src="https://images2.imgbox.com/c5/0c/hLVe5dwI_o.png" alt="img"><br> <img src="https://images2.imgbox.com/6c/f5/GvFYhOhq_o.png" alt="img"></p> 
<p><strong>既有适合小白学习的零基础资料，也有适合3年以上经验的小伙伴深入学习提升的进阶课程，基本涵盖了95%以上大数据开发知识点，真正体系化！</strong></p> 
<p><strong>由于文件比较大，这里只是将部分目录大纲截图出来，每个节点里面都包含大厂面经、学习笔记、源码讲义、实战项目、讲解视频，并且后续会持续更新</strong></p> 
<p><strong>如果你觉得这些内容对你有帮助，可以添加VX：vip204888 （备注大数据获取）</strong><br> <img src="https://images2.imgbox.com/1a/0f/X7m1YqPU_o.png" alt="img"></p> 
<p>…(img-e0kPnmNY-1712574094642)]<br> [外链图片转存中…(img-3djsPkFd-1712574094642)]</p> 
<p><strong>既有适合小白学习的零基础资料，也有适合3年以上经验的小伙伴深入学习提升的进阶课程，基本涵盖了95%以上大数据开发知识点，真正体系化！</strong></p> 
<p><strong>由于文件比较大，这里只是将部分目录大纲截图出来，每个节点里面都包含大厂面经、学习笔记、源码讲义、实战项目、讲解视频，并且后续会持续更新</strong></p> 
<p><strong>如果你觉得这些内容对你有帮助，可以添加VX：vip204888 （备注大数据获取）</strong><br> [外链图片转存中…(img-2P86IC1S-1712574094643)]</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/5efd960fb2357385990413e737539450/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Unity 接入HybridCLR的点点滴滴，亲测三平台（PC、Android、WebGL）妥妥的。-问题分享</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/a84844ac09011403824a628549ea756a/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【利器篇】前端40&#43;精选VSCode插件，总有几个你未拥有！</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>