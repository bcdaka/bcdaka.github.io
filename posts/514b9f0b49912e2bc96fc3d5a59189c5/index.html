<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>X-D-Lab/MindChat-Qwen-7B-v2模型向量化出现llama runner process has terminated: signal: aborted (core dumpe问题 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/514b9f0b49912e2bc96fc3d5a59189c5/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="X-D-Lab/MindChat-Qwen-7B-v2模型向量化出现llama runner process has terminated: signal: aborted (core dumpe问题">
  <meta property="og:description" content="Error: llama runner process has terminated: signal: aborted (core dumped)详细错误日志：
2024-05-21T06:24:45.266916811Z time=2024-05-21T06:24:45.266Z level=INFO source=memory.go:127 msg=&#34;offload to gpu&#34; layers.real=-1 layers.estimate=41 memory.available=&#34;23.2 GiB&#34; memory.required.full=&#34;8.3 GiB&#34; memory.required.partial=&#34;8.3 GiB&#34; memory.required.kv=&#34;800.0 MiB&#34; memory.weights.total=&#34;6.8 GiB&#34; memory.weights.repeating=&#34;6.1 GiB&#34; memory.weights.nonrepeating=&#34;741.9 MiB&#34; memory.graph.full=&#34;301.8 MiB&#34; memory.graph.partial=&#34;606.0 MiB&#34; 2024-05-21T06:24:45.267462488Z time=2024-05-21T06:24:45.267Z level=INFO source=memory.go:127 msg=&#34;offload to gpu&#34; layers.real=-1 layers.estimate=41 memory.available=&#34;23.2 GiB&#34; memory.required.full=&#34;8.3 GiB&#34; memory.required.partial=&#34;8.3 GiB&#34; memory.required.kv=&#34;800.0 MiB&#34; memory.weights.total=&#34;6.8 GiB&#34; memory.weights.repeating=&#34;6.1 GiB&#34; memory.weights.nonrepeating=&#34;741.9 MiB&#34; memory.graph.full=&#34;301.8 MiB&#34; memory.graph.partial=&#34;606.0 MiB&#34; 2024-05-21T06:24:45.267705557Z time=2024-05-21T06:24:45.267Z level=INFO source=server.go:318 msg=&#34;starting llama server&#34;">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-05-22T10:10:49+08:00">
    <meta property="article:modified_time" content="2024-05-22T10:10:49+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">X-D-Lab/MindChat-Qwen-7B-v2模型向量化出现llama runner process has terminated: signal: aborted (core dumpe问题</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <blockquote> 
 <p>Error: llama runner process has terminated: signal: aborted (core dumped)详细错误日志：</p> 
</blockquote> 
<pre><code class="prism language-shell"><span class="token number">2024</span>-05-21T06:24:45.266916811Z <span class="token assign-left variable">time</span><span class="token operator">=</span><span class="token number">2024</span>-05-21T06:24:45.266Z <span class="token assign-left variable">level</span><span class="token operator">=</span>INFO <span class="token assign-left variable">source</span><span class="token operator">=</span>memory.go:127 <span class="token assign-left variable">msg</span><span class="token operator">=</span><span class="token string">"offload to gpu"</span> <span class="token assign-left variable">layers.real</span><span class="token operator">=</span>-1 <span class="token assign-left variable">layers.estimate</span><span class="token operator">=</span><span class="token number">41</span> <span class="token assign-left variable">memory.available</span><span class="token operator">=</span><span class="token string">"23.2 GiB"</span> <span class="token assign-left variable">memory.required.full</span><span class="token operator">=</span><span class="token string">"8.3 GiB"</span> <span class="token assign-left variable">memory.required.partial</span><span class="token operator">=</span><span class="token string">"8.3 GiB"</span> <span class="token assign-left variable">memory.required.kv</span><span class="token operator">=</span><span class="token string">"800.0 MiB"</span> <span class="token assign-left variable">memory.weights.total</span><span class="token operator">=</span><span class="token string">"6.8 GiB"</span> <span class="token assign-left variable">memory.weights.repeating</span><span class="token operator">=</span><span class="token string">"6.1 GiB"</span> <span class="token assign-left variable">memory.weights.nonrepeating</span><span class="token operator">=</span><span class="token string">"741.9 MiB"</span> <span class="token assign-left variable">memory.graph.full</span><span class="token operator">=</span><span class="token string">"301.8 MiB"</span> <span class="token assign-left variable">memory.graph.partial</span><span class="token operator">=</span><span class="token string">"606.0 MiB"</span>
<span class="token number">2024</span>-05-21T06:24:45.267462488Z <span class="token assign-left variable">time</span><span class="token operator">=</span><span class="token number">2024</span>-05-21T06:24:45.267Z <span class="token assign-left variable">level</span><span class="token operator">=</span>INFO <span class="token assign-left variable">source</span><span class="token operator">=</span>memory.go:127 <span class="token assign-left variable">msg</span><span class="token operator">=</span><span class="token string">"offload to gpu"</span> <span class="token assign-left variable">layers.real</span><span class="token operator">=</span>-1 <span class="token assign-left variable">layers.estimate</span><span class="token operator">=</span><span class="token number">41</span> <span class="token assign-left variable">memory.available</span><span class="token operator">=</span><span class="token string">"23.2 GiB"</span> <span class="token assign-left variable">memory.required.full</span><span class="token operator">=</span><span class="token string">"8.3 GiB"</span> <span class="token assign-left variable">memory.required.partial</span><span class="token operator">=</span><span class="token string">"8.3 GiB"</span> <span class="token assign-left variable">memory.required.kv</span><span class="token operator">=</span><span class="token string">"800.0 MiB"</span> <span class="token assign-left variable">memory.weights.total</span><span class="token operator">=</span><span class="token string">"6.8 GiB"</span> <span class="token assign-left variable">memory.weights.repeating</span><span class="token operator">=</span><span class="token string">"6.1 GiB"</span> <span class="token assign-left variable">memory.weights.nonrepeating</span><span class="token operator">=</span><span class="token string">"741.9 MiB"</span> <span class="token assign-left variable">memory.graph.full</span><span class="token operator">=</span><span class="token string">"301.8 MiB"</span> <span class="token assign-left variable">memory.graph.partial</span><span class="token operator">=</span><span class="token string">"606.0 MiB"</span>
<span class="token number">2024</span>-05-21T06:24:45.267705557Z <span class="token assign-left variable">time</span><span class="token operator">=</span><span class="token number">2024</span>-05-21T06:24:45.267Z <span class="token assign-left variable">level</span><span class="token operator">=</span>INFO <span class="token assign-left variable">source</span><span class="token operator">=</span>server.go:318 <span class="token assign-left variable">msg</span><span class="token operator">=</span><span class="token string">"starting llama server"</span> <span class="token assign-left variable">cmd</span><span class="token operator">=</span><span class="token string">"/tmp/ollama3703814779/runners/cuda_v11/ollama_llama_server --model /root/.ollama/models/blobs/sha256-1851048f09798b44b41e905f66e0a00be8f0145133931de67aac1d424117862c --ctx-size 2048 --batch-size 512 --embedding --log-disable --n-gpu-layers 41 --parallel 1 --port 35511"</span>
<span class="token number">2024</span>-05-21T06:24:45.267841042Z <span class="token assign-left variable">time</span><span class="token operator">=</span><span class="token number">2024</span>-05-21T06:24:45.267Z <span class="token assign-left variable">level</span><span class="token operator">=</span>INFO <span class="token assign-left variable">source</span><span class="token operator">=</span>sched.go:333 <span class="token assign-left variable">msg</span><span class="token operator">=</span><span class="token string">"loaded runners"</span> <span class="token assign-left variable">count</span><span class="token operator">=</span><span class="token number">1</span>
<span class="token number">2024</span>-05-21T06:24:45.267857398Z <span class="token assign-left variable">time</span><span class="token operator">=</span><span class="token number">2024</span>-05-21T06:24:45.267Z <span class="token assign-left variable">level</span><span class="token operator">=</span>INFO <span class="token assign-left variable">source</span><span class="token operator">=</span>server.go:488 <span class="token assign-left variable">msg</span><span class="token operator">=</span><span class="token string">"waiting for llama runner to start responding"</span>
<span class="token number">2024</span>-05-21T06:24:45.268153238Z <span class="token assign-left variable">time</span><span class="token operator">=</span><span class="token number">2024</span>-05-21T06:24:45.267Z <span class="token assign-left variable">level</span><span class="token operator">=</span>INFO <span class="token assign-left variable">source</span><span class="token operator">=</span>server.go:524 <span class="token assign-left variable">msg</span><span class="token operator">=</span><span class="token string">"waiting for server to become available"</span> <span class="token assign-left variable">status</span><span class="token operator">=</span><span class="token string">"llm server error"</span>
<span class="token number">2024</span>-05-21T06:24:45.283630907Z INFO <span class="token punctuation">[</span>main<span class="token punctuation">]</span> build info <span class="token operator">|</span> <span class="token assign-left variable">build</span><span class="token operator">=</span><span class="token number">1</span> <span class="token assign-left variable">commit</span><span class="token operator">=</span><span class="token string">"952d03d"</span> <span class="token assign-left variable">tid</span><span class="token operator">=</span><span class="token string">"140597682634752"</span> <span class="token assign-left variable">timestamp</span><span class="token operator">=</span><span class="token number">1716272685</span>
<span class="token number">2024</span>-05-21T06:24:45.283677293Z INFO <span class="token punctuation">[</span>main<span class="token punctuation">]</span> system info <span class="token operator">|</span> <span class="token assign-left variable">n_threads</span><span class="token operator">=</span><span class="token number">8</span> <span class="token assign-left variable">n_threads_batch</span><span class="token operator">=</span>-1 <span class="token assign-left variable">system_info</span><span class="token operator">=</span><span class="token string">"AVX = 1 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 0 | ARM_FMA = 0 | F16C = 0 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | "</span> <span class="token assign-left variable">tid</span><span class="token operator">=</span><span class="token string">"140597682634752"</span> <span class="token assign-left variable">timestamp</span><span class="token operator">=</span><span class="token number">1716272685</span> <span class="token assign-left variable">total_threads</span><span class="token operator">=</span><span class="token number">24</span>
<span class="token number">2024</span>-05-21T06:24:45.283751767Z INFO <span class="token punctuation">[</span>main<span class="token punctuation">]</span> HTTP server listening <span class="token operator">|</span> <span class="token assign-left variable">hostname</span><span class="token operator">=</span><span class="token string">"127.0.0.1"</span> <span class="token assign-left variable">n_threads_http</span><span class="token operator">=</span><span class="token string">"23"</span> <span class="token assign-left variable">port</span><span class="token operator">=</span><span class="token string">"35511"</span> <span class="token assign-left variable">tid</span><span class="token operator">=</span><span class="token string">"140597682634752"</span> <span class="token assign-left variable">timestamp</span><span class="token operator">=</span><span class="token number">1716272685</span>
<span class="token number">2024</span>-05-21T06:24:45.310000256Z llama_model_loader: loaded meta data with <span class="token number">21</span> key-value pairs and <span class="token number">483</span> tensors from /root/.ollama/models/blobs/sha256-1851048f09798b44b41e905f66e0a00be8f0145133931de67aac1d424117862c <span class="token punctuation">(</span>version GGUF V3 <span class="token punctuation">(</span>latest<span class="token punctuation">))</span>
<span class="token number">2024</span>-05-21T06:24:45.310015701Z llama_model_loader: Dumping metadata keys/values. Note: KV overrides <span class="token keyword">do</span> not apply <span class="token keyword">in</span> this output.
<span class="token number">2024</span>-05-21T06:24:45.310018241Z llama_model_loader: - kv   <span class="token number">0</span>:                       general.architecture str              <span class="token operator">=</span> qwen2
<span class="token number">2024</span>-05-21T06:24:45.310019996Z llama_model_loader: - kv   <span class="token number">1</span>:                               general.name str              <span class="token operator">=</span> MindChat-Qwen2-4B
<span class="token number">2024</span>-05-21T06:24:45.310021701Z llama_model_loader: - kv   <span class="token number">2</span>:                          qwen2.block_count u32              <span class="token operator">=</span> <span class="token number">40</span>
<span class="token number">2024</span>-05-21T06:24:45.310023255Z llama_model_loader: - kv   <span class="token number">3</span>:                       qwen2.context_length u32              <span class="token operator">=</span> <span class="token number">32768</span>
<span class="token number">2024</span>-05-21T06:24:45.310024815Z llama_model_loader: - kv   <span class="token number">4</span>:                     qwen2.embedding_length u32              <span class="token operator">=</span> <span class="token number">2560</span>
<span class="token number">2024</span>-05-21T06:24:45.310026428Z llama_model_loader: - kv   <span class="token number">5</span>:                  qwen2.feed_forward_length u32              <span class="token operator">=</span> <span class="token number">6912</span>
<span class="token number">2024</span>-05-21T06:24:45.310028051Z llama_model_loader: - kv   <span class="token number">6</span>:                 qwen2.attention.head_count u32              <span class="token operator">=</span> <span class="token number">20</span>
<span class="token number">2024</span>-05-21T06:24:45.310029594Z llama_model_loader: - kv   <span class="token number">7</span>:              qwen2.attention.head_count_kv u32              <span class="token operator">=</span> <span class="token number">20</span>
<span class="token number">2024</span>-05-21T06:24:45.310031212Z llama_model_loader: - kv   <span class="token number">8</span>:                       qwen2.rope.freq_base f32              <span class="token operator">=</span> <span class="token number">5000000.000000</span>
<span class="token number">2024</span>-05-21T06:24:45.310032784Z llama_model_loader: - kv   <span class="token number">9</span>:     qwen2.attention.layer_norm_rms_epsilon f32              <span class="token operator">=</span> <span class="token number">0.000001</span>
<span class="token number">2024</span>-05-21T06:24:45.310034441Z llama_model_loader: - kv  <span class="token number">10</span>:                          general.file_type u32              <span class="token operator">=</span> <span class="token number">1</span>
<span class="token number">2024</span>-05-21T06:24:45.310035972Z llama_model_loader: - kv  <span class="token number">11</span>:                       tokenizer.ggml.model str              <span class="token operator">=</span> gpt2
<span class="token number">2024</span>-05-21T06:24:45.310037561Z llama_model_loader: - kv  <span class="token number">12</span>:                         tokenizer.ggml.pre str              <span class="token operator">=</span> qwen2
<span class="token number">2024</span>-05-21T06:24:45.336203511Z llama_model_loader: - kv  <span class="token number">13</span>:                      tokenizer.ggml.tokens arr<span class="token punctuation">[</span>str,151936<span class="token punctuation">]</span>  <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"!"</span>, <span class="token string">"<span class="token entity" title='\"'>\"</span>"</span>, <span class="token string">"#"</span>, <span class="token string">"$"</span>, <span class="token string">"%"</span>, <span class="token string">"&amp;"</span>, <span class="token string">"'"</span>, <span class="token punctuation">..</span>.
<span class="token number">2024</span>-05-21T06:24:45.340927274Z llama_model_loader: - kv  <span class="token number">14</span>:                  tokenizer.ggml.token_type arr<span class="token punctuation">[</span>i32,151936<span class="token punctuation">]</span>  <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token number">1</span>, <span class="token punctuation">..</span>.
<span class="token number">2024</span>-05-21T06:24:45.367506788Z llama_model_loader: - kv  <span class="token number">15</span>:                      tokenizer.ggml.merges arr<span class="token punctuation">[</span>str,151387<span class="token punctuation">]</span>  <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"Ġ Ġ"</span>, <span class="token string">"ĠĠ ĠĠ"</span>, <span class="token string">"i n"</span>, <span class="token string">"Ġ t"</span>,<span class="token punctuation">..</span>.
<span class="token number">2024</span>-05-21T06:24:45.367513925Z llama_model_loader: - kv  <span class="token number">16</span>:                tokenizer.ggml.eos_token_id u32              <span class="token operator">=</span> <span class="token number">151645</span>
<span class="token number">2024</span>-05-21T06:24:45.367515206Z llama_model_loader: - kv  <span class="token number">17</span>:            tokenizer.ggml.padding_token_id u32              <span class="token operator">=</span> <span class="token number">151643</span>
<span class="token number">2024</span>-05-21T06:24:45.367516167Z llama_model_loader: - kv  <span class="token number">18</span>:                tokenizer.ggml.bos_token_id u32              <span class="token operator">=</span> <span class="token number">151643</span>
<span class="token number">2024</span>-05-21T06:24:45.367524184Z llama_model_loader: - kv  <span class="token number">19</span>:                    tokenizer.chat_template str              <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>% <span class="token keyword">for</span> <span class="token for-or-select variable">message</span> <span class="token keyword">in</span> messages %<span class="token punctuation">}</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">{<!-- --></span><span class="token string">'&lt;|im_...
2024-05-21T06:24:45.367525679Z llama_model_loader: - kv  20:               general.quantization_version u32              = 2
2024-05-21T06:24:45.367526625Z llama_model_loader: - type  f32:  201 tensors
2024-05-21T06:24:45.367527532Z llama_model_loader: - type  f16:  282 tensors
2024-05-21T06:24:45.434814810Z llama_model_load: error loading model: error loading model vocabulary: unknown pre-tokenizer type: '</span>qwen2<span class="token string">'
2024-05-21T06:24:45.434831117Z llama_load_model_from_file: exception loading model
2024-05-21T06:24:45.444744162Z terminate called after throwing an instance of '</span>std::runtime_error<span class="token string">'
2024-05-21T06:24:45.444757722Z   what():  error loading model vocabulary: unknown pre-tokenizer type: '</span>qwen2'
<span class="token number">2024</span>-05-21T06:24:45.519276490Z <span class="token assign-left variable">time</span><span class="token operator">=</span><span class="token number">2024</span>-05-21T06:24:45.518Z <span class="token assign-left variable">level</span><span class="token operator">=</span>ERROR <span class="token assign-left variable">source</span><span class="token operator">=</span>sched.go:339 <span class="token assign-left variable">msg</span><span class="token operator">=</span><span class="token string">"error loading llama server"</span> <span class="token assign-left variable">error</span><span class="token operator">=</span><span class="token string">"llama runner process has terminated: signal: aborted (core dumped) "</span>
<span class="token number">2024</span>-05-21T06:24:45.519423089Z <span class="token punctuation">[</span>GIN<span class="token punctuation">]</span> <span class="token number">2024</span>/05/21 - 06:24:45 <span class="token operator">|</span> <span class="token number">500</span> <span class="token operator">|</span>  <span class="token number">692</span>.156464ms <span class="token operator">|</span>       <span class="token number">127.0</span>.0.1 <span class="token operator">|</span> POST     <span class="token string">"/api/chat"</span>
</code></pre> 
<h4><a id="_47"></a>总结</h4> 
<blockquote> 
 <p>截至目前为止github上已经有人提出了解决了方案</p> 
</blockquote> 
<pre><code>cd llama.cpp 
git reset --hard 46e12c4692a37bdd31a0432fc5153d7d22bc7f72
</code></pre> 
<h4><a id="_54"></a>参考</h4> 
<ul><li><a href="https://github.com/ollama/ollama/issues/4529">git-hub-issue</a></li></ul>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/32f1b2a5fe929b72ba6290b78fa1d43e/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">《Spark 编程基础（Scala 版）》第 6 章 Spark SQL 实验 5 Spark SQL 编程初级实践 （超级详细版）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/1d63180899bb299f261b59ed8140ac71/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">JavaScript 中的数学与时光魔法：Math与Date对象大揭秘</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>