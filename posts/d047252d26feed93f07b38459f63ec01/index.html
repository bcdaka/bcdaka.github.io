<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【AI语音基础】ASR基本知识 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/d047252d26feed93f07b38459f63ec01/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="【AI语音基础】ASR基本知识">
  <meta property="og:description" content="目录
背景
语音识别ASR原理
HMM隐马尔可夫链语音识别
端到端语音识别
识别衡量标准
参考1
参考2
参考3
参考4
背景 语音识别（Speech Recognition）也被称为自动语音识别（英语：Automatic Speech Recognition, ASR），将语音音频转换为文字的技术。
简单点说：把语音音频转化为文字。
语音识别ASR原理 新手语音入门（三）： 语音识别ASR算法初探 | 编码与解码 | 声学模型与语音模型 | 贝叶斯公式 | 音素-云社区-华为云 (huaweicloud.com)
编码过程：语音识别的输入是声音，计算机无法直接处理，
需要编码过程将其转变为数字信息，并提取其中的特征进行处理。
编码时一般会将声音信号按照很短的时间间隔，切成小段，成为帧。
对于每一帧，可以通过某种规则（例如MFCC特征）提取信号中的特征，将其变成一个多维向量。向量中的每个维度都是这帧信号的一个特征。
解码过程：解码过程则是将编码得到的向量变成文字的过程，需要经过两个模型的处理，一个模型是声学模型，一个模型是语言模型。
声学模型通过处理编码得到的向量，将相邻的帧组合起来变成音素，如中文拼音中的声母和韵母，再组合起来变成单个单词或汉字。语言模型用来调整声学模型所得到的符合逻辑的字词，使识别结果变得通顺。 已知一段音频信号，处理成声学特征向量Acoustic Feature Vector后表示为，X=[x1,x2,x3,…]X=[x1​,x2​,x3​,…],其中xixi​表示一帧特征向量；可能的文本序列表示为W=[w1,w2,w3,…]W=[w1​,w2​,w3​,…],其中wiwi​表示一个词，求W∗=argmaxwP(W∣X)W∗=argmaxw​P(W∣X)，这便是语音识别的基本出发点。并且由贝叶斯公式可知：
其中，P(X∣W)P(X∣W)称之为声学模型（Acoustic Model, AM）, P（W）P（W）称之为语言模型（Language Model, LM），由于P(W)P(W)一般是一个不变量，可以省去不算。
许多研究将语音识别问题看做声学模型与语音模型两部分，分别求取P(X∣W)P(X∣W)和P(W)P(W)。
后来，基于深度学习和大数据的端对端（End-to-End）方法发展起来，直接计算P(W∣X)P(W∣X)，把声学模型和语言模型融为了一体。
语音识别的问题可以看做是语音到文本的对应关系，语音识别问题大体可以归结为文本基本组成单位的选择上。单位不同，则建模力度也随之改变。
图中文本基本组成单位从大到小分别是：
整句文本，如“Hello
World”,对应的语音建模尺度为整条语音。
词，如孤立词“Good”、“World”、对应的语音建模尺度大约为每个词的发音范围。
音素，如将“world”进一步表示为“/wɘrld//wɘrld/”,其中的每个音标作为基本单位，对应的语音建模尺度则缩减为每个音素的发音范围。
三音素，即考虑上下文的音素，如将音素“/d//d/”进一步表示为“/l−d−sil,/u−d−l/,…/l−d−sil,/u−d−l/,…”,对应的语音建模尺度是每个三音素的发音范围，长度与单音素差不多。
隐马尔可夫模型状态，即将每个三因素都用一个三状态隐马尔可夫模型表示，并用每个状态作为建模粒度，对应的语音建模尺度将进一步缩短。
上面每种实现方法都对应着不同的建模粒度，大体可以分为以隐马尔可夫模型结构和端对端的结构。
HMM隐马尔可夫链语音识别 新手语音入门（四）： 传统语音识别技术简介 | 隐马尔可夫链 | 声学/语言模型 | WFST解码-云社区-华为云 (huaweicloud.com)
隐马尔可夫链HMM模型自从1980年代被用于语音识别以来，一直都是实际语音识别系统的主流方法。
声学模型 P(X∣W)P(X∣W)对应的是声学模型，首先需要考虑的是，语音和文本的不定长关系使得二者的序列之间无法一一对应。隐马尔可夫链模型正好可以解决这个问题。
比如P(X│W)=P(x1,x2,x3∣w1,w2)P(X│W)=P(x1​,x2​,x3​∣w1​,w2​)可以表示成上面隐马尔可夫链的形式，图中ww是HMM的隐含状态，xx是HMM的观测值，隐含状态数与观测值数目不受彼此约束，这便解决了输入输出的不定长问题，并有:">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-05-15T10:36:15+08:00">
    <meta property="article:modified_time" content="2024-05-15T10:36:15+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【AI语音基础】ASR基本知识</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p id="main-toc"><strong>目录</strong></p> 
<p id="-toc" style="margin-left:0px;"></p> 
<p id="-toc" style="margin-left:0px;"></p> 
<p id="fcZ6U-toc" style="margin-left:0px;"><a href="#fcZ6U" rel="nofollow">背景</a></p> 
<p id="ppYha-toc" style="margin-left:0px;"><a href="#ppYha" rel="nofollow">语音识别ASR原理</a></p> 
<p id="HMM%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E9%93%BE%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB-toc" style="margin-left:40px;"><a href="#HMM%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E9%93%BE%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB" rel="nofollow">HMM隐马尔可夫链语音识别</a></p> 
<p id="%E7%AB%AF%E5%88%B0%E7%AB%AF%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB-toc" style="margin-left:40px;"><a href="#%E7%AB%AF%E5%88%B0%E7%AB%AF%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB" rel="nofollow">端到端语音识别</a></p> 
<p id="hJAQm-toc" style="margin-left:0px;"><a href="#hJAQm" rel="nofollow">识别衡量标准</a></p> 
<p id="JLhgS-toc" style="margin-left:40px;"><a href="#JLhgS" rel="nofollow">参考1</a></p> 
<p id="UWPeW-toc" style="margin-left:40px;"><a href="#UWPeW" rel="nofollow">参考2</a></p> 
<p id="z8ZXn-toc" style="margin-left:40px;"><a href="#z8ZXn" rel="nofollow">参考3</a></p> 
<p id="alDoh-toc" style="margin-left:40px;"><a href="#alDoh" rel="nofollow">参考4</a></p> 
<hr id="hr-toc"> 
<p></p> 
<h2></h2> 
<h2 id="fcZ6U">背景</h2> 
<p id="u91c81ee7">语音识别（Speech Recognition）也被称为自动语音识别（英语：Automatic Speech Recognition, ASR），将语音音频转换为文字的技术。</p> 
<p id="ub7c6c0e0">简单点说：把语音音频转化为文字。</p> 
<p id="u58048cba"></p> 
<h2 id="ppYha">语音识别ASR原理</h2> 
<p id="u66d8ed75"><a href="https://bbs.huaweicloud.com/blogs/320735" rel="nofollow" title="新手语音入门（三）： 语音识别ASR算法初探 | 编码与解码 | 声学模型与语音模型 | 贝叶斯公式 | 音素-云社区-华为云 (huaweicloud.com)">新手语音入门（三）： 语音识别ASR算法初探 | 编码与解码 | 声学模型与语音模型 | 贝叶斯公式 | 音素-云社区-华为云 (huaweicloud.com)</a></p> 
<p><img alt="" height="606" src="https://images2.imgbox.com/65/1d/DcRmz4AT_o.png" width="1200"></p> 
<p><strong>编码过程</strong>：语音识别的输入是声音，计算机无法直接处理，</p> 
<p>        需要编码过程将其转变为数字信息，并提取其中的特征进行处理。</p> 
<p>        编码时一般会将声音信号按照很短的时间间隔，切成小段，成为帧。</p> 
<p>        对于每一帧，可以通过某种规则（例如MFCC特征）提取信号中的特征，将其变成一个多维向量。向量中的每个维度都是这帧信号的一个特征。</p> 
<p><img alt="" height="308" src="https://images2.imgbox.com/d1/03/TxXO2jKe_o.png" width="578"></p> 
<p></p> 
<p><strong>解码过程</strong>：解码过程则是将编码得到的向量变成文字的过程，需要经过两个模型的处理，一个模型是声学模型，一个模型是语言模型。</p> 
<ul><li>声学模型通过处理编码得到的向量，将<span style="color:#fe2c24;">相邻的帧组合起来变成音素</span>，如中文拼音中的声母和韵母，再组合起来变成单个单词或汉字。</li><li>语言模型用来调整声学模型所得到的<span style="color:#fe2c24;">符合逻辑的字词，使识别结果变得通顺</span>。</li></ul> 
<p><img alt="" height="344" src="https://images2.imgbox.com/8f/92/Mc5Tzpsp_o.png" width="402"></p> 
<p></p> 
<p>已知一段<span style="color:#fe2c24;">音频信号</span>，处理成声学特征向量Acoustic Feature Vector后表示为，<span style="color:#fe2c24;">X=[x1,x2,x3,…]X=[x1​,x2​,x3​,…],其中xixi​表示一帧特征向量</span>；可能的文本序列表示为<span style="color:#4da8ee;">W=[w1,w2,w3,…]W=[w1​,w2​,w3​,…],其中wiwi​表示一个词</span>，求W∗=argmaxwP(W∣X)W∗=argmaxw​P(W∣X)，这便是语音识别的基本出发点。并且由贝叶斯公式可知：</p> 
<p><img alt="" height="168" src="https://images2.imgbox.com/05/44/NayC2YhD_o.png" width="608"></p> 
<p>其中，P(X∣W)P(X∣W)称之为声学模型（Acoustic Model, AM）, P（W）P（W）称之为语言模型（Language Model, LM），由于P(W)P(W)一般是一个不变量，可以省去不算。</p> 
<p>许多研究将语音识别问题看做声学模型与语音模型两部分，分别求取P(X∣W)P(X∣W)和P(W)P(W)。</p> 
<p></p> 
<p></p> 
<p>后来，基于深度学习和大数据的<span style="color:#fe2c24;">端对端（End-to-End）</span>方法发展起来，直接计算P(W∣X)P(W∣X)，把声学模型和语言模型融为了一体。</p> 
<p>        语音识别的问题可以看做是语音到文本的对应关系，语音识别问题大体可以归结为文本基本组成单位的选择上。单位不同，则建模力度也随之改变。</p> 
<p></p> 
<p class="img-center"><img alt="" height="269" src="https://images2.imgbox.com/01/20/6nTkENOW_o.png" width="595"></p> 
<p>图中文本基本组成单位从大到小分别是：</p> 
<ul><li> <p>整句文本，如“Hello<br> World”,对应的语音建模尺度为整条语音。</p> </li><li> <p>词，如孤立词“Good”、“World”、对应的语音建模尺度大约为每个词的发音范围。</p> </li><li> <p>音素，如将“world”进一步表示为“/wɘrld//wɘrld/”,其中的每个音标作为基本单位，对应的语音建模尺度则缩减为每个音素的发音范围。</p> </li><li> <p>三音素，即考虑上下文的音素，如将音素“/d//d/”进一步表示为“/l−d−sil,/u−d−l/,…/l−d−sil,/u−d−l/,…”,对应的语音建模尺度是每个三音素的发音范围，长度与单音素差不多。</p> </li><li> <p>隐马尔可夫模型状态，即将每个三因素都用一个三状态隐马尔可夫模型表示，并用每个状态作为建模粒度，对应的语音建模尺度将进一步缩短。</p> </li></ul> 
<p>上面每种实现方法都对应着不同的建模粒度，大体可以分为<span style="color:#fe2c24;">以隐马尔可夫模型结构</span>和<span style="color:#fe2c24;">端对端的结构</span>。</p> 
<h3 id="HMM%E9%9A%90%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E9%93%BE%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB">HMM隐马尔可夫链语音识别</h3> 
<p><a href="https://bbs.huaweicloud.com/blogs/320751" rel="nofollow" title="新手语音入门（四）： 传统语音识别技术简介 | 隐马尔可夫链 | 声学/语言模型 | WFST解码-云社区-华为云 (huaweicloud.com)">新手语音入门（四）： 传统语音识别技术简介 | 隐马尔可夫链 | 声学/语言模型 | WFST解码-云社区-华为云 (huaweicloud.com)</a></p> 
<p>隐马尔可夫链HMM模型自从1980年代被用于语音识别以来，一直都是实际语音识别系统的主流方法。</p> 
<ul><li>声学模型</li></ul> 
<p></p> 
<p>P(X∣W)P(X∣W)对应的是声学模型，<span style="color:#fe2c24;">首先需要考虑的是，语音和文本的不定长关系使得二者的序列之间无法一一对应。隐马尔可夫链模型正好可以解决这个问题</span>。</p> 
<p><img alt="" height="212" src="https://images2.imgbox.com/6e/42/A2kz6c2f_o.png" width="356"></p> 
<p>比如P(X│W)=P(x1,x2,x3∣w1,w2)P(X│W)=P(x1​,x2​,x3​∣w1​,w2​)可以表示成上面隐马尔可夫链的形式，图中ww是HMM的隐含状态，xx是<code>HMM</code>的观测值，隐含状态数与观测值数目不受彼此约束，这便解决了输入输出的不定长问题，并有:</p> 
<p>P(X│W)=P(w1)P(x1∣w1)P(w2∣w1)P(x2∣w2)P(w2∣w2)P(x3∣w2)P(X│W)=P(w1​)P(x1​∣w1​)P(w2​∣w1​)P(x2​∣w2​)P(w2​∣w2​)P(x3​∣w2​)</p> 
<p>其中，<code>HMM</code>的初始状态概率P(w1)P(w1​)和状态转移概率（P(w2∣w1)P(w2​∣w1​)、P(w2∣w2)）P(w2​∣w2​)）可以用常规的统计方法从样本总计算出来，主要的难点在于HMM发射概率（P(x1∣w1)P(x1​∣w1​)、P(x2∣w2)P(x2​∣w2​)和P(x3∣w2)P(x3​∣w2​)）的计算上，<span style="color:#fe2c24;">所以声学模型问题进一步细化到HMM<strong>发射概率</strong>（Emission Probabolity）的学习上。</span></p> 
<p><strong>GMM-HMM</strong></p> 
<p><strong>        高斯混合模型</strong>（Gaussion Mixture Model,GMM）是最常用的统计模型，给定充分的子高斯数，GMM可以拟和任意的概率分布，所以GMM成为首选的发射概率模型。</p> 
<p><strong>DNN-HMM</strong></p> 
<p>声学模型结构，语音特征作为DNN的输入，DNN的输出则用于计算HMM的发射概率。</p> 
<ul><li>语言模型</li></ul> 
<p>语言模型要解决的问题是如何计算P(W)，常用的方法基于n元语法（n-gram Grammer）或RNN。</p> 
<ul><li>解码器</li></ul> 
<p>选择使得P(W∣X)=P(X∣W)P(W)P(W∣X)=P(X∣W)P(W)最大的WW,所以解码本质上式一个搜索问题，并可借助<strong>加权有限状态转换机</strong>（Weighted Finite State Transducer, <code>WFST</code>）统一进行最优路径搜索。</p> 
<h3 id="%E7%AB%AF%E5%88%B0%E7%AB%AF%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB">端到端语音识别</h3> 
<p><a href="https://bbs.huaweicloud.com/blogs/320753" rel="nofollow" title="新手语音入门（五）： 端到端语音识别技术简介 | 卷积神经网络 | CTC损失函数 | 注意力机制-云社区-华为云 (huaweicloud.com)">新手语音入门（五）： 端到端语音识别技术简介 | 卷积神经网络 | CTC损失函数 | 注意力机制-云社区-华为云 (huaweicloud.com)</a></p> 
<p>输入是一整段语音，输出是对应的文本，两端都能处理成规则的数学表示形式，只要数据足够，模型合适，我们也许能训练出一个好的端对端模型。</p> 
<p></p> 
<p>对于输入：</p> 
<ul><li> 我们可以考虑将不同长度的数据转化为固定维度的向量序列。因此我们可以选择卷积神经网络（Convolutional Neural Network,CNN）进行转换，CNN通过控制池化层（Pooling Layer）的尺度来保证不同的输入转换后的维度相同。</li><li> 输入分帧逐次进入模型，可以使用RNN，虽然输入时分开进入，但是累积的历史信息会在最后以固定维度一次性输出，这两个方法常常用于基于注意力（Attention）的网络结构。</li></ul> 
<p></p> 
<p>对于输出，</p> 
<ul><li>先考虑输入长度不做处理的情况，因为语音识别中，真实输出的长度远小于输入的长度，可以引入空白标签充数，这是<strong>CTC</strong>（Connectionist Temporal Classification）损失函数常用的<code>技巧</code>。如果输出长度长于输入长度，则常规CTC就不合适了。</li><li>另一种情况是前述固定输入为一个长度的向量，然后根据这个向量解码出一个文本序列，此时输出长度需要其他机制判断是否结束输出，比如引入结束符标签</li></ul> 
<p>两个端对端方法即上文提到的<strong>基于CTC损失函数</strong>和<strong>注意力机制</strong>的深度学习方法</p> 
<ul><li>CTC是一种2006年就应用于语音识别的损失函数，输入是一个序列，输出是一个序列，该损失函数使得模型输出的序列尽可能的拟合目标序列。</li><li>RNN-T预测网络与编码器都使用LSTM,可以分别对历史输出y和历史语音特征（x，含当前时刻）进行<strong>信息累积</strong>。并通过一个全连接神经共同作用于新的输出，图中的p和h分别为预测网络和编码器的输出，形式为固定长度的向量。</li><li> <p>Transformer, 如下图所示，其摆脱了循环神经网络和卷积神经网络的禁锢，以及使用了多注意力机制，加速了并行计算能力。</p> </li></ul> 
<h2 id="hJAQm">识别衡量标准</h2> 
<p id="ue22e2ec5">语音识别，计算字错率WER、句错率SER</p> 
<p id="ub1598dac"></p> 
<h3 id="JLhgS">参考1</h3> 
<p id="u5e75f8d2"><a href="https://mp.weixin.qq.com/s/IbFNzg09-Yb65twXgis2Zw" rel="nofollow" title="AI产品经理需要了解的语音交互评价指标">AI产品经理需要了解的语音交互评价指标</a>，来自hanniman</p> 
<p id="u50408719"></p> 
<p id="u31e962d0"></p> 
<p id="u438a8b31"><strong>识别率</strong></p> 
<p id="ua66f1814">看纯引擎的识别率，以及不同信噪比状态下的识别率（信噪比模拟不同车速、车窗、空调状态等），还有在线/离线识别的区别。</p> 
<p id="ued16e19a">实际工作中，一般识别率的直接指标是“WER（词错误率，Word Error Rate）”</p> 
<p id="ud63b8cb4">定义：为了使识别出来的词序列和标准的词序列之间保持一致，需要进行替换、删除或者插入某些词，这些插入、替换或删除的词的总个数，除以标准的词序列中词的总个数的百分比，即为WER。</p> 
<p id="u9009459c">公式为：</p> 
<p id="ub966aa1c"></p> 
<p class="img-center"><img alt="" height="58" id="u3c1c8105" src="https://images2.imgbox.com/b9/3d/TXGvkH8W_o.jpg" width="486"></p> 
<ul><li id="u747bce06">Substitution——替换</li><li id="u3e291eae">Deletion——删除</li><li id="u35a7bb1a">Insertion——插入</li><li id="u2662413a">N——单词数目</li></ul> 
<p id="u43e8020b"><strong>3点说明</strong></p> 
<ol><li id="u026b217e">WER可以分男女、快慢、口音、数字/英文/中文等情况，分别来看。</li><li id="u54e93765">因为有插入词，所以理论上WER有可能大于100%，但实际中、特别是大样本量的时候，是不可能的，否则就太差了，不可能被商用。</li><li id="u8ded6d88">站在纯产品体验角度，很多人会以为识别率应该等于“句子识别正确的个数/总的句子个数”，即“识别（正确）率等于96%”这种，实际工作中，这个应该指向“SER（句错误率，Sentence Error Rate）”，即“句子识别错误的个数/总的句子个数”。不过据说在实际工作中，一般句错误率是字错误率的2~3倍，所以可能就不怎么看了。</li></ol> 
<p id="uf47aa21b"></p> 
<h3 id="UWPeW">参考2</h3> 
<p id="u824cc03b"><a href="https://www.cnblogs.com/yinlili/p/11393846.html" rel="nofollow" title="https://www.cnblogs.com/yinlili/p/11393846.html">https://www.cnblogs.com/yinlili/p/11393846.html</a>，有具体案例</p> 
<p id="ua90220ce"></p> 
<p id="u42347d88">英文，因为最小单元是Word，语音识别应该用"字错误率"（WER），</p> 
<p id="u85d2e685">中文，因为最小单元是字符，语音识别应该用“字符错误率”（CER）。</p> 
<p id="u774adf67"></p> 
<p id="uc883b542">1.2、句错率(SER)</p> 
<p id="u13bb9a6d">句错误率：Sentence Error Rate</p> 
<p id="u77e96665">解释：句子识别错误的的个数，除以总的句子个数即为SER</p> 
<p id="ub0518890">计算公式：(所有公式省了 * 100%)</p> 
<p id="ud403dea1"></p> 
<p id="ua1664f87">SER = 错误句数 / 总句数</p> 
<p id="ucfa54059">1.3、句正确率(S.Corr）</p> 
<p id="ue0fed1ab">句正确率：Sentence Correct</p> 
<p id="u3f483e8e">计算公式：</p> 
<p id="u5886fb09"></p> 
<p id="ubdf04954">S.Corr = 1 - SER = 正确句数 / 总句数</p> 
<p id="u784816ae"></p> 
<p id="ud624746a">行业水平</p> 
<p id="u3bab0e10">英语-WER；</p> 
<p id="uf03d5891">IBM：行业标准Switchboard语音识别任务，2016年 6.9%，2017年 5.5%</p> 
<p id="ue65f3449">微软：行业标准Switchboard语音识别任务，2016年 6.3% -&gt; 5.9%，2017年 5.1%，这个目前最低的。</p> 
<p id="udaba5124">说明：ICASSP2017上IBM说人类速记员WER是5.1%，一般认为5.9% 的字错率是人类速记员的水平。</p> 
<p id="u494eceb9"></p> 
<p id="u732a040c">中文-WER/CER：</p> 
<p id="u0393da38">小米：2018年 小米电视 2.81%</p> 
<p id="u2695d9e2">百度：2016年 短语识别 3.7%</p> 
<p id="ua476d50c">中文-W.Corr：</p> 
<p id="u7ef6a5bf">百度：2016年 识别准确率 97%</p> 
<p id="u77882c6c">搜狗：2016年 识别准确率 97%</p> 
<p id="u8ec3464f">讯飞：2016年 识别准确率 97%</p> 
<p id="u6c585af5">Findyou部分数据来源：</p> 
<p id="uf1967f39"></p> 
<p id="ueae786df">微软WER 5.9%：<a href="https://arxiv.org/abs/1610.05256" rel="nofollow" title="https://arxiv.org/abs/1610.05256">https://arxiv.org/abs/1610.05256</a></p> 
<p id="uc16f79ec">微软WER 5.1%： <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2017/08/ms_swbd17-2.pdf" rel="nofollow" title="https://www.microsoft.com/en-us/research/wp-content/uploads/2017/08/ms_swbd17-2.pdf">https://www.microsoft.com/en-us/research/wp-content/uploads/2017/08/ms_swbd17-2.pdf</a></p> 
<p id="ub2a7f1ec">小米电视CER 2.81% ：<a href="https://arxiv.org/pdf/1707.07167.pdf" rel="nofollow" title="https://arxiv.org/pdf/1707.07167.pdf">https://arxiv.org/pdf/1707.07167.pdf</a></p> 
<p id="ub01f70e0">国内百度等同时宣布识别准确率97% ： <a href="https://www.zhihu.com/question/53001402" rel="nofollow" title="为什么百度、搜狗、讯飞的语音识别宣称的准确率都是 97%？ - 知乎">为什么百度、搜狗、讯飞的语音识别宣称的准确率都是 97%？ - 知乎</a></p> 
<p id="u46f2cea6"></p> 
<h3 id="z8ZXn">参考3</h3> 
<p id="u7388c483">新手语音入门(一)：认识词错率WER与字错率CER ｜ 编辑距离 ｜ 莱文斯坦距离 ｜ 动态规划</p> 
<p id="u305ae86e"><a href="https://bbs.huaweicloud.com/blogs/315846" rel="nofollow" title="新手语音入门(一)：认识词错率WER与字错率CER ｜ 编辑距离 ｜ 莱文斯坦距离 ｜ 动态规划-云社区-华为云">新手语音入门(一)：认识词错率WER与字错率CER ｜ 编辑距离 ｜ 莱文斯坦距离 ｜ 动态规划-云社区-华为云</a></p> 
<ul><li id="u9c31e449">1. 字/词错率的概念</li></ul> 
<ul><li> 
  <ul><li id="ud4521f4d">1.1 词错率与字错率</li><li id="u462f0402">1.2 计算公式</li></ul></li></ul> 
<ul><li id="u4aefa839">2. 字错率的计算</li></ul> 
<ul><li> 
  <ul><li id="u4982704a">2.1 编辑距离的概念</li><li id="u72792225">2.2 编辑距离的求解</li></ul></li></ul> 
<p id="u89d2c89f"><strong>词错率</strong>（Word Error Rate, WER）是一项用于评价ASR性能的重要指标，用来评价预测文本与标准文本之间错误率，因此词错率最大的特点是越小越好。像英语、阿拉伯语语音转文本或语音识别任务中研究者常用WER衡量ASR效果好坏。</p> 
<p id="u7ebd21c4">因为英文语句中句子的最小单位是单词，而中文语句中的最小单位是汉字，因此在中文语音转文本任务或中文语音识别任务中使用<strong>字错率</strong>（Character Error Rate, CER）来衡量中文ASR效果好坏。</p> 
<p id="u8dd9eddf"><br>  </p> 
<p id="u44ef5872">计算公式是：</p> 
<p id="u3505d576">WER=S+D+IN=S+D+IS+D+C<em>W</em><em>E</em><em>R</em>=<em>N</em><em>S</em>+<em>D</em>+<em>I</em>=<em>S</em>+<em>D</em>+<em>C</em><em>S</em>+<em>D</em>+<em>I</em></p> 
<p id="u186adbba">假设有一个参考例句Ref和一段ASR系统转写语音后生成的预测文本Hyp。带入上面公式，S表示将Hyp转化为Ref时发生的替换数量，D表示将Hyp转化为Ref时发生的替换数量，I代表将Hypo转化为Ref时发生的插入数量，N代表Ref句子中总的字数或者英文单词数。C代表Hyp句子中识别正确的字数。即原参考句子总字数N = S+ D + C。</p> 
<p id="u3143c4a0">再说一句，根据维基百科里面的说法，<strong>N</strong><strong>就是原样例文本总的字数</strong>。</p> 
<p id="u38ae6fa0"></p> 
<h3 id="alDoh">参考4</h3> 
<p id="u208526ab"><a href="https://www.zhihu.com/question/53001402" rel="nofollow" title="为什么百度、搜狗、讯飞的语音识别宣称的准确率都是 97%？ - 知乎">为什么百度、搜狗、讯飞的语音识别宣称的准确率都是 97%？ - 知乎</a></p> 
<p id="uffd7da30">所有的测试结果是需要基于测试集：微软的5.9的WER是在NIST 2000 CTS上实现的。也就是94.1的识别率，这个是平了人类速记员的水平的。（ICASSP2017上IBM说人类速记员WER是5.1）</p> 
<p id="ucb2c7242"></p> 
<p id="u01f9bf10"></p> 
<p class="img-center"><img alt="" height="1200" id="uaf4cf7dd" src="https://images2.imgbox.com/66/3c/yTdkLrgt_o.png" width="1200"></p> 
<p id="u319587f9"></p> 
<p id="u785ee9dc"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/570fee3549bb049a40ff78ea28316075/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">uniapp开发h5页面的扫码功能(html5-qrcode和mumu-getQrcode两种方式)，以及后续用安卓扫码传h5的方法</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/024dab311a1674c6f51f30711e31ab29/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">一文搞懂前端渲染技术：什么是SSR、SSG、CSR？</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>