<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>AI | LLaMA-Factory 一个好用的微调工具 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/14028cffe261689e6f0377cd048e3b15/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="AI | LLaMA-Factory 一个好用的微调工具">
  <meta property="og:description" content="‘’ LLama Factory，这个工具能够高效且低成本地支持对 100 多个模型进行微调。LLama Factory 简化了模型微调的过程，并且易于访问，使用体验友好。此外，它还提供了由 Hiyouga 提供的 Hugging Face 空间，可用于对模型进行微调。
下载LLaMA-Factory ​ #下载LLaMA-Factory git clone https://github.com/hiyouga/LLaMA-Factory.git #创建一个环境 conda create -n llama_factory python=3.10 #切换到llama_factory环境 conda activate llama_factory #进入到LLaMA-Factory目录下 cd LLaMA-Factory #下载LLaMA-Factory所需要的包 pip install -r requirements.txt ​ 开始 启动页面： python src\train_web.py 进入可视化页面： 支持 Lora 和 GaLore 配置，以减少 GPU 的使用。用户可以通过简单的滑块轻松更改参数，如 dropout、epochs、批次大小等。同时，也有多个数据集选项可供选择以微调你的模型。正如本文所述，LLama Factory支持许多模型，包括不同版本的 LLama、mistral 和 Falcon。它还支持像 galore、badm 和 Lora 这样的高级算法，提供诸如flash attention、位置编码和缩放等各种功能。
此外，你还可以集成像 TensorBoard、VanDB 和 MLflow 这样的监控工具。为了更快地进行推理，你还可以使用Gradio 和 CLI。本质上，LLama Factory 提供了一系列多样化的选项，以增强模型性能并简化微调过程。
LLaMA-Factory有自带的数据集也可以自己生成数据集然后导入：">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-05-30T09:53:31+08:00">
    <meta property="article:modified_time" content="2024-05-30T09:53:31+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">AI | LLaMA-Factory 一个好用的微调工具</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h3>‘’</h3> 
<h3><img alt="" height="286" src="https://images2.imgbox.com/34/53/JQFPc4FD_o.png" width="1028"></h3> 
<p>LLama Factory，这个工具能够高效且低成本地支持对 100 多个模型进行微调。LLama Factory 简化了模型微调的过程，并且易于访问，使用体验友好。此外，它还提供了由 Hiyouga 提供的 Hugging Face 空间，可用于对模型进行微调。</p> 
<h3 id="h_694056983_2">下载LLaMA-Factory</h3> 
<pre><code class="hljs">​
#下载LLaMA-Factory
git clone https://github.com/hiyouga/LLaMA-Factory.git
#创建一个环境
conda create -n llama_factory python=3.10
#切换到llama_factory环境
conda activate llama_factory
#进入到LLaMA-Factory目录下
cd LLaMA-Factory
#下载LLaMA-Factory所需要的包
pip install -r requirements.txt

​</code></pre> 
<h3>开始</h3> 
<h4>启动页面：</h4> 
<pre><code class="hljs">python src\train_web.py</code></pre> 
<h4>进入可视化页面：</h4> 
<p><img alt="" height="964" src="https://images2.imgbox.com/75/5f/vCx5L1yk_o.png" width="1200"></p> 
<p></p> 
<p></p> 
<p>支持 Lora 和 GaLore 配置，以减少 GPU 的使用。用户可以通过简单的滑块轻松更改参数，如 dropout、epochs、批次大小等。同时，也有多个数据集选项可供选择以微调你的模型。正如本文所述，LLama Factory支持许多模型，包括不同版本的 LLama、mistral 和 Falcon。它还支持像 galore、badm 和 Lora 这样的高级算法，提供诸如flash attention、位置编码和缩放等各种功能。</p> 
<p>此外，你还可以集成像 TensorBoard、VanDB 和 MLflow 这样的监控工具。为了更快地进行推理，你还可以使用Gradio 和 CLI。本质上，LLama Factory 提供了一系列多样化的选项，以增强模型性能并简化微调过程。</p> 
<p></p> 
<p></p> 
<p>LLaMA-Factory有自带的数据集也可以自己生成数据集然后导入：</p> 
<p><img alt="" height="774" src="https://images2.imgbox.com/31/d7/taToWRfl_o.png" width="1200"></p> 
<p></p> 
<h4>自制微调数据集代码下载地址：</h4> 
<p></p> 
<pre><code class="hljs">https://github.com/KevinFanng/makeChatGLM3FinetuneData/blob/main/finetunningData_for_qwen_piliang.py</code></pre> 
<h4></h4> 
<h4>自制微调数据集代码读取Excel示例：</h4> 
<p></p> 
<pre><code>https://github.com/KevinFanng/makeChatGLM3FinetuneData/blob/main/%E5%8E%9F%E5%A7%8B%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F.xlsx</code></pre> 
<h4></h4> 
<h4> 自制微调数据集代码关键注释：</h4> 
<p></p> 
<h4><img alt="" height="922" src="https://images2.imgbox.com/61/9d/KhjxduXc_o.png" width="1200"></h4> 
<p></p> 
<h4>预览命令：</h4> 
<p></p> 
<p><img alt="" height="688" src="https://images2.imgbox.com/9a/ab/pbZK7yu2_o.png" width="1045"></p> 
<p></p> 
<h4>开始微调，点击开始：</h4> 
<p></p> 
<p><img alt="" height="517" src="https://images2.imgbox.com/c1/16/LWwhJhwy_o.png" width="1200"></p> 
<p></p> 
<h4>微调所需要的时间百分比：</h4> 
<p></p> 
<p><img alt="" height="235" src="https://images2.imgbox.com/aa/d8/ekzEOOOR_o.png" width="1200"></p> 
<p></p> 
<h3>报错：</h3> 
<p></p> 
<p>我当时跑的期间也会有报错，但是只要跟着教程走，就不会错，当时我的报错是关于torch版本的问题，原因是没有下载对应cuda的torch， 我当时候的解决方案是去torch官网下载对应自己版本的cuda。</p> 
<p></p> 
<h4>进入PyTorch官网：<a href="https://pytorch.org/" rel="nofollow" title="PyTorch">PyTorch</a>（魔法）</h4> 
<p></p> 
<p><img alt="" height="491" src="https://images2.imgbox.com/f6/69/GDfMCkWz_o.png" width="1025"></p> 
<p></p> 
<h4>Windows+R打开cmd小黑框：</h4> 
<p></p> 
<p><img alt="" height="228" src="https://images2.imgbox.com/97/b5/YOkk1Nk4_o.png" width="404"></p> 
<p></p> 
<h4>查看你的cuda版本：nvidia-smi</h4> 
<p></p> 
<p><img alt="" height="418" src="https://images2.imgbox.com/6d/f0/O0UJPwr2_o.png" width="852"></p> 
<p></p> 
<p>找到对应的cuda版本下载即可！</p> 
<p>可视化界面偶尔可能也出现报错，我们重新刷新页面即可继续</p> 
<p><img alt="" height="476" src="https://images2.imgbox.com/f5/b9/hsN7nqVR_o.png" width="956"></p> 
<p></p> 
<p></p> 
<h3>结语</h3> 
<p></p> 
<p>有效的微调已成为大型语言模型（LLMs）适应特定任务的必要条件之一。然而，这需要一定的努力，有时也相当具有挑战性。随着 Llama-Factory 的引入，这一全面的框架让训练更加高效，用户无需编写代码即可轻松为超过 100 个 LLMs 定制微调。</p> 
<p>现在，很多人对大型语言模型（LLMs）更加好奇，有这样想法的开发者可以试试 Llama-Factory 是否可以调整自己的模型。这有助于开源社区的成长和活跃。Llama-Factory 正变得广为人知，甚至已被列入 Awesome Transformers3 中，作为高效微调 LLMs 的工具。</p> 
<p>我们希望本文能鼓励更多开发者使用这一框架来创建有价值的 LLMs。不过请记得，在使用Llama-Factory微调LLMs时，遵守模型的许可规则很重要。</p> 
<p>至此，本文结束。我们看到了如今在几分钟内微调任何模型是多么容易。我们还可以使用 Hugging Face CLI 将这个模型推送到 Hugging Face Hub 上。</p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/2e02e2c64378603d8263e10535c1aaea/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Java 面试题：String、StringBuffer、StringBuilder 有什么区别？</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/c0c2859af7883846f21205d2c4f83260/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Stable Diffusion AI绘画：从创意词汇到艺术图画的魔法之旅</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>