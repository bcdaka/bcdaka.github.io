<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>AI绘画【comfyUI】两个自动蒙版操作，轻松实现一键更换背景 - 编程大咖</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/5c6be9c3a7cb1a91a787238d73e5d926/">
  <meta property="og:site_name" content="编程大咖">
  <meta property="og:title" content="AI绘画【comfyUI】两个自动蒙版操作，轻松实现一键更换背景">
  <meta property="og:description" content="大家好！我是向阳
在SD-webui里有个segment_anything插件，只需输入想要提取的元素，
就能帮我们一键生成图片的前景、背景和蒙版。
这期我就分享两个，在ComfyUI里面轻松去背景和生成蒙版的节点。
第一个：segment_anything 插件地址：https://github.com/storyicon/comfyui_segment_anything
注意：需要科学上网，如无法下载，请看文末扫描获取插件安装包
其实它的原理采用GroundingDINO作为对象检测器，通过我们输入的类别名称或引用表达式，来检测目标，
然后再经过大量数据训练的segment_anything_model，简称SAM模型，来处理图像，最后生成对象蒙版。
使用时会自动下载模型。你也可以根据下表，手动下载它们。如果自动下载速度慢，可以设置 HTTP_PROXY 和 HTTPS_PROXY 环境变量来使用代理。
从 https://huggingface.co/bert-base-uncased/tree/main 下载模型到 ComfyUI 根目录下的models/bert-base-uncased 文件夹中，如下所示：
ComfyUI models bert-base-uncased config.json model.safetensors tokenizer_config.json tokenizer.json vocab.txt 当然你也可以跳过此步骤。在推理过程中， bert-base-uncased 会通过 transformers 库自动下载，
其目录通常为 ~/.cache/huggingface/hub/models–bert-base-uncased
请直接将模型和配置文件下载到ComfyUI根目录下的 models/grounding-dino 目录中，无需修改文件名。
名称大小模型文件GroundingDINO_SwinT_OGC694MB请看文末扫描获取GroundingDINO_SwinB938MB请看文末扫描获取 SAM 模型 下载后放到ComfyUI根目录下的 models/sams 目录下，无需修改文件名。
根据自己的需要请看文末扫描获取模型，模型有大有小。
实操步骤 还是老规矩，先加载默认文生图工作流
默认文生图工作流
接着我们使用上面安装的segment_anything插件
可以看到，这个节点是要加载两个模型的，也就是上面我们下载的模型，并且需要一个图片作为参考图，它的输出则是一张图和一个遮罩。
我们按它的输入要求加载下需要的东西，并且我们希望他能扣出我的主体人物，所以我提示词给它：character，并且把图片和遮罩预览下，看看效果
小知识点：遮罩预览需要转成图像才能预览哦。
sam模型加载器处理模式，尽可能的选择GPU模式，速度更快。
可以看到，很简单就从图片了抠出了人物主体图像，并且生成了一个前景遮罩。
前景遮罩（Foreground Mask）：前景遮罩用于标识图像中前景物体的区域。在图像分割中，前景通常是我们关注的对象，比如人、动物或物体。前景遮罩用于分离前景和背景，使我们能够对前景物体进行单独的处理，如提取、替换背景或进行图像合成。
背景遮罩（Background Mask）：背景遮罩用于标识图像中背景区域的遮罩。它帮助我们确定哪些部分是背景，以便我们可以对背景进行操作，如替换、模糊或去除。背景遮罩在视频处理中特别有用，用于在动态场景中稳定背景或分离前景对象。
接下来我们把它接入文生图流程看看效果，这里我们其实已经是图生图的模式了，我们需要把遮罩和原图传给KSampler采样器，进行处理，图片进入latent我们都知道，只需要通过vae编码即可，遮罩我们需要使用到设置latent噪波遮罩这个节点，用户这个替换文生图中的空latent就可以了
我们再使用背景遮罩来试试效果，背景遮罩就是把前景遮罩反转即可，使用的节点是反转遮罩这个节点
这就是实现了，人物换背景了，而且整体来说还是很协调了。
第二种comfyui-was-node-suite中图像处理 was-node-suite-是comfyui中的一个泛节点套件，来源github作者：WAS-PlaiLabs
其中包含图像处理、文本处理等190个常用节点。部分节点如下图：
GitHub地址：https://github.com/WASasquatch/was-node-suite-comfyui
需要确保/ComfyUI/custom_nodes、was-node-suite-comfyui、 和WAS_Node_Suite.py具有写入权限。
加载
效果是一样的，生成前景遮罩">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-05-20T13:57:34+08:00">
    <meta property="article:modified_time" content="2024-05-20T13:57:34+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="编程大咖" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">编程大咖</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">AI绘画【comfyUI】两个自动蒙版操作，轻松实现一键更换背景</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>大家好！我是向阳</p> 
<p>在SD-webui里有个segment_anything插件，只需输入想要提取的元素，</p> 
<p>就能帮我们一键生成图片的前景、背景和蒙版。</p> 
<p>这期我就分享两个，在ComfyUI里面轻松去背景和生成蒙版的节点。</p> 
<h3><a id="segment_anything_12"></a>第一个：segment_anything</h3> 
<p>插件地址：https://github.com/storyicon/comfyui_segment_anything<br> 注意：需要科学上网，如无法下载，请看文末扫描获取插件安装包</p> 
<p><img src="https://images2.imgbox.com/03/21/sBw67sns_o.png" alt=""></p> 
<p>其实它的原理采用GroundingDINO作为对象检测器，通过我们输入的类别名称或引用表达式，来检测目标，</p> 
<p>然后再经过大量数据训练的segment_anything_model，简称SAM模型，来处理图像，最后生成对象蒙版。</p> 
<p>使用时会自动下载模型。你也可以根据下表，手动下载它们。如果自动下载速度慢，可以设置 HTTP_PROXY 和 HTTPS_PROXY 环境变量来使用代理。</p> 
<p>从 https://huggingface.co/bert-base-uncased/tree/main 下载模型到 ComfyUI 根目录下的models/bert-base-uncased 文件夹中，如下所示：</p> 
<pre><code>ComfyUI  
    models  
        bert-base-uncased  
            config.json  
            model.safetensors  
            tokenizer_config.json  
            tokenizer.json  
            vocab.txt  
</code></pre> 
<p>当然你也可以跳过此步骤。在推理过程中， bert-base-uncased 会通过 transformers 库自动下载，</p> 
<p>其目录通常为 ~/.cache/huggingface/hub/models–bert-base-uncased</p> 
<p>请直接将模型和配置文件下载到ComfyUI根目录下的 models/grounding-dino 目录中，无需修改文件名。</p> 
<table><thead><tr><th>名称</th><th>大小</th><th>模型文件</th></tr></thead><tbody><tr><td>GroundingDINO_SwinT_OGC</td><td>694MB</td><td>请看文末扫描获取</td></tr><tr><td>GroundingDINO_SwinB</td><td>938MB</td><td>请看文末扫描获取</td></tr></tbody></table> 
<h4><a id="SAM__52"></a>SAM 模型</h4> 
<p>下载后放到ComfyUI根目录下的 models/sams 目录下，无需修改文件名。</p> 
<p>根据自己的需要请看文末扫描获取模型，模型有大有小。</p> 
<p><img src="https://images2.imgbox.com/40/90/RhvTqpUS_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="_60"></a>实操步骤</h4> 
<p>还是老规矩，先加载默认文生图工作流</p> 
<p><img src="https://images2.imgbox.com/12/40/WC0oFehP_o.png" alt=""></p> 
<p>默认文生图工作流</p> 
<p>接着我们使用上面安装的segment_anything插件<img src="https://images2.imgbox.com/19/7b/L9WXqYFB_o.png" alt=""></p> 
<p><img src="https://images2.imgbox.com/4d/d3/0cfozyaB_o.png" alt=""></p> 
<p>可以看到，这个节点是要加载两个模型的，也就是上面我们下载的模型，并且需要一个图片作为参考图，它的输出则是一张图和一个遮罩。</p> 
<p>我们按它的输入要求加载下需要的东西，并且我们希望他能扣出我的主体人物，所以我提示词给它：<code>character</code>，并且把图片和遮罩预览下，看看效果</p> 
<p><strong>小知识点：遮罩预览需要转成图像才能预览哦。</strong></p> 
<p><img src="https://images2.imgbox.com/73/0d/SBchlMmX_o.png" alt=""></p> 
<p>sam模型加载器处理模式，尽可能的选择GPU模式，速度更快。</p> 
<p>可以看到，很简单就从图片了抠出了人物主体图像，并且生成了一个前景遮罩。</p> 
<ul><li> <p>前景遮罩（Foreground Mask）：前景遮罩用于标识图像中前景物体的区域。在图像分割中，前景通常是我们关注的对象，比如人、动物或物体。前景遮罩用于分离前景和背景，使我们能够对前景物体进行单独的处理，如提取、替换背景或进行图像合成。</p> </li><li> <p>背景遮罩（Background Mask）：背景遮罩用于标识图像中背景区域的遮罩。它帮助我们确定哪些部分是背景，以便我们可以对背景进行操作，如替换、模糊或去除。背景遮罩在视频处理中特别有用，用于在动态场景中稳定背景或分离前景对象。</p> </li></ul> 
<p>接下来我们把它接入文生图流程看看效果，这里我们其实已经是图生图的模式了，我们需要把遮罩和原图传给KSampler采样器，进行处理，图片进入latent我们都知道，只需要通过vae编码即可，遮罩我们需要使用到<code>设置latent噪波遮罩</code>这个节点，用户这个替换文生图中的空latent就可以了</p> 
<p><img src="https://images2.imgbox.com/5d/b9/iKbOp40Y_o.png" alt=""></p> 
<p>我们再使用背景遮罩来试试效果，背景遮罩就是把前景遮罩反转即可，使用的节点是<code>反转遮罩</code>这个节点</p> 
<p><img src="https://images2.imgbox.com/ca/00/plQbySHH_o.png" alt=""></p> 
<p>这就是实现了，人物换背景了，而且整体来说还是很协调了。<img src="https://images2.imgbox.com/4e/80/DHKTi7hO_o.jpg" alt=""></p> 
<h3><a id="comfyuiwasnodesuite_99"></a>第二种comfyui-was-node-suite中图像处理</h3> 
<p>was-node-suite-是comfyui中的一个泛节点套件，来源github作者：WAS-PlaiLabs</p> 
<p>其中包含图像处理、文本处理等190个常用节点。部分节点如下图：<img src="https://images2.imgbox.com/68/7a/o8mRVetw_o.png" alt=""></p> 
<p>GitHub地址：https://github.com/WASasquatch/was-node-suite-comfyui</p> 
<p>需要确保/ComfyUI/custom_nodes、was-node-suite-comfyui、 和WAS_Node_Suite.py具有写入权限。</p> 
<p><img src="https://images2.imgbox.com/7c/d1/jeu8taqB_o.png" alt=""></p> 
<p>加载</p> 
<p><img src="https://images2.imgbox.com/38/1d/UXljha3Y_o.png" alt=""></p> 
<p>效果是一样的，生成前景遮罩</p> 
<p><img src="https://images2.imgbox.com/63/69/j9D63PR8_o.png" alt=""></p> 
<p>背景遮罩：</p> 
<p><img src="https://images2.imgbox.com/03/e9/zECHqDbI_o.png" alt=""></p> 
<p>简单几个节点就实现背景替换，效果还是不错的。</p> 
<p>整体工作流如下，需要的朋友添加文末的微信获取。<img src="https://images2.imgbox.com/78/69/eivcDL4D_o.png" alt=""></p> 
<h3><a id="_128"></a>总结</h3> 
<ol><li> <p>使用<code>segment_anything</code>插件来一键生成图片的前景、背景和蒙版。插件使用GroundingDINO作为对象检测器，并通过SAM模型处理图像，生成对象蒙版。实操步骤包括加载默认的文生图工作流，使用<code>segment_anything</code>插件，并输入提示词来生成前景遮罩。</p> </li><li> <p>文章还介绍了<code>comfyui-was-node-suite</code>中的图像处理方法。这是一个包含190个常用节点的泛节点套件，可以用于图像处理、文本处理等。通过这个套件，可以使用简单的几个节点来实现背景替换的效果。</p> </li><li> <p>整体工作流包括加载文生图工作流，使用<code>segment_anything</code>或<code>comfyui-was-node-suite</code>中的节点来生成前景遮罩和背景遮罩，最后将遮罩和原图传给KSampler采样器进行处理，实现背景替换的效果。</p> </li></ol> 
<p><font face="幼圆" size="4" color="red">感兴趣的小伙伴，赠送全套AIGC学习资料，包含AI绘画、AI人工智能等前沿科技教程和软件工具，具体看这里。<br> </font><br> <img src="https://images2.imgbox.com/d4/23/Ns3L27OC_o.png"></p> 
<p>AIGC技术的未来发展前景广阔，随着人工智能技术的不断发展，AIGC技术也将不断提高。未来，AIGC技术将在游戏和计算领域得到更广泛的应用，使游戏和计算系统具有更高效、更智能、更灵活的特性。同时，AIGC技术也将与人工智能技术紧密结合，在更多的领域得到广泛应用，对程序员来说影响至关重要。未来，AIGC技术将继续得到提高，同时也将与人工智能技术紧密结合，在更多的领域得到广泛应用。<br>  <br> <img src="https://images2.imgbox.com/f6/97/QjijrzJL_o.png" alt="在这里插入图片描述"></p> 
<p><strong>一、AIGC所有方向的学习路线</strong></p> 
<p>AIGC所有方向的技术点做的整理，形成各个领域的知识点汇总，它的用处就在于，你可以按照下面的知识点去找对应的学习资源，保证自己学得较为全面。</p> 
<p><img src="https://images2.imgbox.com/a4/39/cfvejKAv_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/53/a8/RI0hupeX_o.png" alt="在这里插入图片描述"></p> 
<p><strong>二、AIGC必备工具</strong></p> 
<p>工具都帮大家整理好了，安装就可直接上手！<br> <img src="https://images2.imgbox.com/a2/2b/RS7IdNuk_o.png" alt="在这里插入图片描述"></p> 
<p><strong>三、最新AIGC学习笔记</strong></p> 
<p>当我学到一定基础，有自己的理解能力的时候，会去阅读一些前辈整理的书籍或者手写的笔记资料，这些笔记详细记载了他们对一些技术点的理解，这些理解是比较独到，可以学到不一样的思路。<br> <img src="https://images2.imgbox.com/19/58/ntobcU0P_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/ce/60/sONnUp7S_o.png" alt="在这里插入图片描述"></p> 
<p><strong>四、AIGC视频教程合集</strong></p> 
<p>观看全面零基础学习视频，看视频学习是最快捷也是最有效果的方式，跟着视频中老师的思路，从基础到深入，还是很容易入门的。</p> 
<p><img src="https://images2.imgbox.com/3e/5f/4JxhGd6D_o.png" alt="在这里插入图片描述"></p> 
<p><strong>五、实战案例</strong></p> 
<p>纸上得来终觉浅，要学会跟着视频一起敲，要动手实操，才能将自己的所学运用到实际当中去，这时候可以搞点实战案例来学习。<br> <img src="https://images2.imgbox.com/e6/be/CcF0odkS_o.png" alt="在这里插入图片描述"></p> 
<img src="https://images2.imgbox.com/5d/5d/LqznnfMs_o.png"> 若有侵权，请联系删除
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/c4398cccef22c424d639a4b2333d4959/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">0基础从前端到Web3 —— Vite &#43; React &#43; TS moveCall a &#43; b</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/ff196b38cd02015c85af8e6e88ca121c/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">No JVM could be found on your system. 在您的系统上找不到JVM。 Please define EXE4J JAVA HOME to point to an ins</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 编程大咖.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>