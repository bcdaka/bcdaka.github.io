<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>æœ€å¤§405Bï¼šLlama-3.1 å‘å¸ƒï¼Œç¬¬ä¸€æ—¶é—´è¯¦è§£ - ç¼–ç¨‹å¤§å’–</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://bcdaka.github.io/posts/5d311057d05ad505eb8d14f40f2b5130/">
  <meta property="og:site_name" content="ç¼–ç¨‹å¤§å’–">
  <meta property="og:title" content="æœ€å¤§405Bï¼šLlama-3.1 å‘å¸ƒï¼Œç¬¬ä¸€æ—¶é—´è¯¦è§£">
  <meta property="og:description" content="åœ¨è¿™ç¯‡æ–‡ç« å‘å‡ºæ—¶ Meta å‘å¸ƒäº† Llama 3.1 è¿™æ¬¡å‘å¸ƒ
åŒ—äº¬æ—¶é—´ï¼Œ2024 å¹´ 7 æœˆ 23 æ—¥ 23 ç‚¹ï¼ŒMeta æ­£å¼å‘å¸ƒäº†å…¶æœ€æ–°çš„å¼€æºæ¨¡å‹ - Llama 3.1, åŒ…å«8Bã€70B å’Œ 405B ä¸‰ä¸ªå°ºå¯¸ï¼Œæœ€å¤§ä¸Šä¸‹æ–‡æå‡åˆ°äº† 128kã€‚
å…¶ä¸­ï¼Œ405B æ˜¯å…¶è¿„ä»Šæœ€å¼ºå¤§çš„æ¨¡å‹ï¼Œä»è¯„åˆ†ä¸Šçœ‹ï¼Œè¶…è¿‡äº† GPT-4 0125ï¼Œå’Œ Claude 3.5 ä¸ç›¸ä¸Šä¸‹ã€‚
è¶£é—»ï¼šè¢«å·è·‘
æ˜¨å¤©ä¸‹åˆï¼Œ405B çš„ Llama ç–‘ä¼¼åœ¨ Hugging Face è¢«å·è·‘ï¼Œå¹¶åœ¨ Twitter ä¸Šå¼•èµ·äº†ä¸€å°æ³¢çš„è½°åŠ¨ï¼ˆä½†è¿™ä¸ªé“¾æ¥å·²ç»è®¿é—®ä¸åˆ°äº†ï¼‰ã€‚æ›´æœ‰å¥½äº‹è€…å°†å…¶è½¬åŒ–æˆäº†ç£åŠ›é“¾æ¥ï¼Œå¤§æ¦‚ 800G å¤§å°
ä¸Šä¸ªç‰ˆæœ¬æ˜¯ Llama-3
3ä¸ªæœˆå‰ï¼ŒMeta å¼€æºäº† Llama 3 çš„ 8B å’Œ 70B æ¨¡å‹ã€‚å…·ä½“å¯å‚è§ä¹‹å‰çš„æŠ¥é“ï¼šå…¨ç½‘é¦–å‘ï¼ŒMeta Llama-3 å…¨æ–¹ä½è¯¦è§£
ç¬¬ä¸€éƒ¨åˆ† è¿™æ¬¡å‘å¸ƒ å¼€æºçš„Llama 3.1 åŒ…å«8Bã€70B å’Œ 405B ä¸‰ä¸ªå°ºå¯¸ï¼Œæ€§èƒ½æå‡ï¼Œæœ€å¤§ä¸Šä¸‹æ–‡ä¸º 128kã€‚
Llama 3.1 è€æ¨¡å‹ï¼Œæ–°å‡çº§
ä¹‹å‰æ¨å‡ºçš„ 8B å’Œ 70B ç‰ˆæœ¬çš„ Llama-3 è¿æ¥äº†å…¨æ–°å‡çº§ï¼Œå˜æˆäº† Llama-3.">
  <meta property="og:locale" content="zh_CN">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-07-25T18:09:46+08:00">
    <meta property="article:modified_time" content="2024-07-25T18:09:46+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="ç¼–ç¨‹å¤§å’–" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">ç¼–ç¨‹å¤§å’–</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">æœ€å¤§405Bï¼šLlama-3.1 å‘å¸ƒï¼Œç¬¬ä¸€æ—¶é—´è¯¦è§£</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h3><a id="_0"></a>åœ¨è¿™ç¯‡æ–‡ç« å‘å‡ºæ—¶</h3> 
<h3><a id="Meta__Llama_31_3"></a>Meta å‘å¸ƒäº† Llama 3.1</h3> 
<hr> 
<p>è¿™æ¬¡å‘å¸ƒ</p> 
<p>åŒ—äº¬æ—¶é—´ï¼Œ2024 å¹´ 7 æœˆ 23 æ—¥ 23 ç‚¹ï¼ŒMeta æ­£å¼å‘å¸ƒäº†å…¶æœ€æ–°çš„å¼€æºæ¨¡å‹ - Llama 3.1, åŒ…å«8Bã€70B å’Œ 405B ä¸‰ä¸ªå°ºå¯¸ï¼Œæœ€å¤§ä¸Šä¸‹æ–‡æå‡åˆ°äº† 128kã€‚</p> 
<p>å…¶ä¸­ï¼Œ405B æ˜¯å…¶è¿„ä»Šæœ€å¼ºå¤§çš„æ¨¡å‹ï¼Œä»è¯„åˆ†ä¸Šçœ‹ï¼Œè¶…è¿‡äº† GPT-4 0125ï¼Œå’Œ Claude 3.5 ä¸ç›¸ä¸Šä¸‹ã€‚</p> 
<p><img src="https://images2.imgbox.com/40/5e/UZkXgkhY_o.png" alt=""></p> 
<p>è¶£é—»ï¼šè¢«å·è·‘</p> 
<p>æ˜¨å¤©ä¸‹åˆï¼Œ405B çš„ Llama ç–‘ä¼¼åœ¨ Hugging Face è¢«å·è·‘ï¼Œå¹¶åœ¨ Twitter ä¸Šå¼•èµ·äº†ä¸€å°æ³¢çš„è½°åŠ¨ï¼ˆä½†è¿™ä¸ªé“¾æ¥å·²ç»è®¿é—®ä¸åˆ°äº†ï¼‰ã€‚æ›´æœ‰å¥½äº‹è€…å°†å…¶è½¬åŒ–æˆäº†ç£åŠ›é“¾æ¥ï¼Œå¤§æ¦‚ 800G å¤§å°</p> 
<p><img src="https://images2.imgbox.com/f7/d5/R0PWhSoa_o.png" alt=""></p> 
<p>ä¸Šä¸ªç‰ˆæœ¬æ˜¯ Llama-3</p> 
<p>3ä¸ªæœˆå‰ï¼ŒMeta å¼€æºäº† Llama 3 çš„ 8B å’Œ 70B æ¨¡å‹ã€‚å…·ä½“å¯å‚è§ä¹‹å‰çš„æŠ¥é“ï¼šå…¨ç½‘é¦–å‘ï¼ŒMeta Llama-3 å…¨æ–¹ä½è¯¦è§£</p> 
<h3><a id="_35"></a>ç¬¬ä¸€éƒ¨åˆ†</h3> 
<h3><a id="_38"></a>è¿™æ¬¡å‘å¸ƒ</h3> 
<p>å¼€æºçš„Llama 3.1 åŒ…å«8Bã€70B å’Œ 405B ä¸‰ä¸ªå°ºå¯¸ï¼Œæ€§èƒ½æå‡ï¼Œæœ€å¤§ä¸Šä¸‹æ–‡ä¸º 128kã€‚</p> 
<h3><a id="Llama_31_45"></a>Llama 3.1</h3> 
<p>è€æ¨¡å‹ï¼Œæ–°å‡çº§</p> 
<p>ä¹‹å‰æ¨å‡ºçš„ 8B å’Œ 70B ç‰ˆæœ¬çš„ Llama-3 è¿æ¥äº†å…¨æ–°å‡çº§ï¼Œå˜æˆäº† Llama-3.1ï¼Œä¸Šä¸‹æ–‡é•¿åº¦å¢åŠ è‡³ 128Kï¼Œå¹¶ä¸”æœ‰äº†æ›´å¼ºçš„æ¨ç†èƒ½åŠ›ã€‚</p> 
<p>405B è¶…å¤§æ¯</p> 
<p>405B æ˜¯è¿™æ¬¡çš„å…¨æ–°å‘å¸ƒï¼Œéå¸¸èªæ˜ã€‚å’Œå½“ä¸‹æœ€å¼ºçš„ GPT-4 / Claude 3.5 æ——é¼“ç›¸å½“</p> 
<p><img src="https://images2.imgbox.com/87/92/t2I81LEm_o.png" alt=""></p> 
<p>å…¨é¢æå‡</p> 
<p>æ›´å¤šçš„æ¯”ç…§æµ‹è¯•å¦‚å¦‚ä¸‹</p> 
<p><img src="https://images2.imgbox.com/c1/e7/1lC42V0y_o.png" alt=""></p> 
<p><img src="https://images2.imgbox.com/02/47/kX460ak0_o.png" alt=""></p> 
<h3><a id="_68"></a>æ•°æ®è®­ç»ƒ</h3> 
<p>å·¨é‡æ•°æ®</p> 
<p>Llama 3 ä½¿ç”¨äº†è¶…è¿‡ 15 T token çš„å…¬å¼€æ•°æ®è¿›è¡Œè®­ç»ƒï¼Œä½¿ç”¨äº†è¶…è¿‡ 1.6 ä¸‡ä¸ª H100 GPU</p> 
<p>è®­ç»ƒæ€è·¯ï¼ˆæœ¬æ–‡é™„92é¡µPDFï¼‰</p> 
<p>é€‰æ‹©æ ‡å‡†çš„ä»…è§£ç å™¨ transformer æ¨¡å‹æ¶æ„è¿›è¡Œè°ƒæ•´ï¼Œè€Œä¸æ˜¯æ··åˆä¸“å®¶æ¨¡å‹ï¼Œä»¥æœ€å¤§åŒ–è®­ç»ƒç¨³å®šæ€§ã€‚é‡‡ç”¨äº†è¿­ä»£çš„åè®­ç»ƒç¨‹åºï¼Œæ¯ä¸€è½®ä½¿ç”¨ç›‘ç£å¾®è°ƒå’Œç›´æ¥åå¥½ä¼˜åŒ–ã€‚</p> 
<p>å¾®è°ƒ</p> 
<p>åœ¨åæœŸè®­ç»ƒä¸­ï¼ŒLlama é€šè¿‡è¿›è¡Œå¤šè½®å¯¹é½æ¥ç”Ÿæˆæœ€ç»ˆçš„èŠå¤©æ¨¡å‹ã€‚æ¯ä¸€è½®éƒ½æ¶‰åŠåˆ°ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ã€æ‹’ç»æŠ½æ ·ï¼ˆRSï¼‰å’Œç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰ã€‚ä½¿ç”¨åˆæˆæ•°æ®ç”Ÿæˆç»å¤§éƒ¨åˆ†çš„ SFT ç¤ºä¾‹ï¼Œå¤šæ¬¡è¿­ä»£ä»¥ç”Ÿæˆè´¨é‡æ›´é«˜çš„åˆæˆæ•°æ®ï¼Œè¦†ç›–æ‰€æœ‰èƒ½åŠ›ã€‚</p> 
<h3><a id="_83"></a>å¼€æº</h3> 
<p>å®˜æ–¹æ–‡æ¡£</p> 
<p>https://llama.meta.com/docs/overview/</p> 
<p>Hugging Face</p> 
<p>https://huggingface.co/meta-llama</p> 
<p>GitHub</p> 
<p>https://github.com/meta-llama</p> 
<p>Kaggle</p> 
<p>https://www.kaggle.com/organizations/metaresearch/models</p> 
<h3><a id="_2__105"></a>ç¬¬ 2 éƒ¨åˆ†</h3> 
<h3><a id="_108"></a>æ‰å…‹ä¼¯æ ¼çš„è‡´è¾</h3> 
<hr> 
<p>ä¼´éšè¿™æ¬¡å‘å¸ƒçš„ï¼Œæ˜¯æ‰å…‹ä¼¯æ ¼è‡´è¾ï¼š</p> 
<p>Open Source AI Is the Path Forward</p> 
<p>å¼€æºäººå·¥æ™ºèƒ½æ˜¯æœªæ¥çš„å‘å±•æ–¹å‘</p> 
<h3><a id="_124"></a>å¼€æºäººå·¥æ™ºèƒ½æ˜¯æœªæ¥çš„å‘å±•æ–¹å‘</h3> 
<p>In the early days of high-performance computing, the major tech companies of the day each invested heavily in developing their own closed source versions of Unix. It was hard to imagine at the time that any other approach could develop such advanced software. Eventually though, open source Linux gained popularity â€“ initially because it allowed developers to modify its code however they wanted and was more affordable, and over time because it became more advanced, more secure, and had a broader ecosystem supporting more capabilities than any closed Unix. Today, Linux is the industry standard foundation for both cloud computing and the operating systems that run most mobile devices â€“ and we all benefit from superior products because of it.</p> 
<p>åœ¨é«˜æ€§èƒ½è®¡ç®—çš„æ—©æœŸï¼Œå½“æ—¶çš„ä¸»è¦ç§‘æŠ€å…¬å¸éƒ½å¤§åŠ›æŠ•èµ„äºå¼€å‘è‡ªå·±çš„é—­æº Unix ç‰ˆæœ¬ã€‚å½“æ—¶å¾ˆéš¾æƒ³è±¡å…¶ä»–ä»»ä½•æ–¹æ³•èƒ½å¤Ÿå¼€å‘å‡ºå¦‚æ­¤å…ˆè¿›çš„è½¯ä»¶ã€‚ç„¶è€Œæœ€ç»ˆï¼Œå¼€æº Linux å˜å¾—æµè¡Œèµ·æ¥ - æœ€åˆæ˜¯å› ä¸ºå®ƒå…è®¸å¼€å‘äººå‘˜éšæ„ä¿®æ”¹å…¶ä»£ç å¹¶ä¸”æ›´åŠ ç»æµå®æƒ ï¼Œéšç€æ—¶é—´çš„æ¨ç§»ï¼Œå› ä¸ºå®ƒå˜å¾—æ›´åŠ å…ˆè¿›ã€æ›´åŠ å®‰å…¨ï¼Œå¹¶ä¸”æ‹¥æœ‰æ¯”ä»»ä½•é—­æº Unix æ›´å¤šåŠŸèƒ½çš„æ›´å¹¿æ³›ç”Ÿæ€ç³»ç»Ÿçš„æ”¯æŒã€‚å¦‚ä»Šï¼ŒLinux æ˜¯äº‘è®¡ç®—å’Œè¿è¡Œå¤§å¤šæ•°ç§»åŠ¨è®¾å¤‡çš„æ“ä½œç³»ç»Ÿçš„è¡Œä¸šæ ‡å‡†åŸºç¡€ - æˆ‘ä»¬éƒ½å› æ­¤å—ç›Šäºæ›´ä¼˜è´¨çš„äº§å“ã€‚</p> 
<p>I believe that AI will develop in a similar way. Today, several tech companies are developing leading closed models. But open source is quickly closing the gap. Last year, Llama 2 was only comparable to an older generation of models behind the frontier. This year, Llama 3 is competitive with the most advanced models and leading in some areas. Starting next year, we expect future Llama models to become the most advanced in the industry. But even before that, Llama is already leading on openness, modifiability, and cost efficiency.</p> 
<p>æˆ‘ç›¸ä¿¡äººå·¥æ™ºèƒ½ä¼šä»¥ç±»ä¼¼çš„æ–¹å¼å‘å±•ã€‚å¦‚ä»Šï¼Œæœ‰å‡ å®¶ç§‘æŠ€å…¬å¸æ­£åœ¨å¼€å‘é¢†å…ˆçš„å°é—­æ¨¡å‹ã€‚ä½†å¼€æºå¾ˆå¿«åœ¨ç¼©å°å·®è·ã€‚å»å¹´ï¼ŒLlama 2 åªèƒ½ä¸è¾¹ç¼˜ä¹‹åçš„æ—§ä¸€ä»£æ¨¡å‹ç›¸æå¹¶è®ºã€‚è€Œä»Šå¹´ï¼ŒLlama 3 åœ¨ä¸€äº›é¢†åŸŸå…·æœ‰ç«äº‰åŠ›ï¼Œç”šè‡³åœ¨æŸäº›æ–¹é¢é¢†å…ˆäºæœ€å…ˆè¿›çš„æ¨¡å‹ã€‚ä»æ˜å¹´å¼€å§‹ï¼Œæˆ‘ä»¬é¢„è®¡æœªæ¥çš„ Llama æ¨¡å‹å°†æˆä¸ºè¡Œä¸šä¸­æœ€å…ˆè¿›çš„ã€‚ä½†å³ä½¿åœ¨é‚£ä¹‹å‰ï¼ŒLlama å·²ç»åœ¨å¼€æ”¾æ€§ã€å¯ä¿®æ”¹æ€§å’Œæˆæœ¬æ•ˆç›Šæ–¹é¢å¤„äºé¢†å…ˆåœ°ä½ã€‚</p> 
<p>Today weâ€™re taking the next steps towards open source AI becoming the industry standard. Weâ€™re releasing Llama 3.1 405B, the first frontier-level open source AI model, as well as new and improved Llama 3.1 70B and 8B models. In addition to having significantly better cost/performance relative to closed models, the fact that the 405B model is open will make it the best choice for fine-tuning and distilling smaller models.</p> 
<p>ä»Šå¤©ï¼Œæˆ‘ä»¬æ­£åœ¨è¿ˆå‡ºè¿ˆå‘å¼€æºäººå·¥æ™ºèƒ½æˆä¸ºè¡Œä¸šæ ‡å‡†çš„ä¸‹ä¸€æ­¥ã€‚æˆ‘ä»¬å‘å¸ƒäº† Llama 3.1 405Bï¼Œè¿™æ˜¯ç¬¬ä¸€ä¸ªå‰æ²¿çº§åˆ«çš„å¼€æºäººå·¥æ™ºèƒ½æ¨¡å‹ï¼Œä»¥åŠæ–°çš„å’Œæ”¹è¿›çš„ Llama 3.1 70B å’Œ 8B æ¨¡å‹ã€‚é™¤äº†ç›¸å¯¹äºå°é—­æ¨¡å‹å…·æœ‰æ˜¾ç€æ›´å¥½çš„æˆæœ¬/æ€§èƒ½ä¹‹å¤–ï¼Œ405B æ¨¡å‹æ˜¯å¼€æºçš„äº‹å®å°†ä½¿å…¶æˆä¸ºå¾®è°ƒå’Œæç‚¼è¾ƒå°æ¨¡å‹çš„æœ€ä½³é€‰æ‹©ã€‚</p> 
<p>Beyond releasing these models, weâ€™re working with a range of companies to grow the broader ecosystem. Amazon, Databricks, and Nvidia are launching full suites of services to support developers fine-tuning and distilling their own models. Innovators like Groq have built low-latency, low-cost inference serving for all the new models. The models will be available on all major clouds including AWS, Azure, Google, Oracle, and more. Companies like Scale.AI, Dell, Deloitte, and others are ready to help enterprises adopt Llama and train custom models with their own data. As the community grows and more companies develop new services, we can collectively make Llama the industry standard and bring the benefits of AI to everyone.</p> 
<p>é™¤äº†å‘å¸ƒè¿™äº›æ¨¡å‹å¤–ï¼Œæˆ‘ä»¬è¿˜ä¸ä¸€ç³»åˆ—å…¬å¸åˆä½œï¼Œä»¥å‘å±•æ›´å¹¿æ³›çš„ç”Ÿæ€ç³»ç»Ÿã€‚äºšé©¬é€Šã€Databricks å’Œ Nvidia æ­£åœ¨æ¨å‡ºä¸€æ•´å¥—æœåŠ¡ï¼Œä»¥æ”¯æŒå¼€å‘äººå‘˜å¾®è°ƒå’Œæç‚¼è‡ªå·±çš„æ¨¡å‹ã€‚åƒ Groq è¿™æ ·çš„åˆ›æ–°è€…å·²ä¸ºæ‰€æœ‰æ–°æ¨¡å‹æ„å»ºäº†ä½å»¶è¿Ÿã€ä½æˆæœ¬çš„æ¨ç†æœåŠ¡ã€‚è¿™äº›æ¨¡å‹å°†åœ¨åŒ…æ‹¬ AWSã€Azureã€Googleã€Oracle ç­‰åœ¨å†…çš„æ‰€æœ‰ä¸»è¦äº‘ä¸Šæä¾›ã€‚åƒ Scale.AIã€æˆ´å°”ã€å¾·å‹¤ç­‰å…¬å¸å·²å‡†å¤‡å¥½å¸®åŠ©ä¼ä¸šé‡‡ç”¨ Llama å¹¶ä½¿ç”¨è‡ªå·±çš„æ•°æ®è®­ç»ƒå®šåˆ¶æ¨¡å‹ã€‚éšç€ç¤¾åŒºçš„å£®å¤§å’Œæ›´å¤šå…¬å¸å¼€å‘æ–°æœåŠ¡ï¼Œæˆ‘ä»¬å¯ä»¥å…±åŒå°† Llama æ‰“é€ æˆè¡Œä¸šæ ‡å‡†ï¼Œå¹¶å°†äººå·¥æ™ºèƒ½çš„å¥½å¤„å¸¦ç»™æ¯ä¸ªäººã€‚</p> 
<p>Meta is committed to open source AI. Iâ€™ll outline why I believe open source is the best development stack for you, why open sourcing Llama is good for Meta, and why open source AI is good for the world and therefore a platform that will be around for the long term.</p> 
<p>Meta è‡´åŠ›äºå¼€æºäººå·¥æ™ºèƒ½ã€‚æˆ‘å°†æ¦‚è¿°ä¸ºä»€ä¹ˆæˆ‘ç›¸ä¿¡å¼€æºæ˜¯æœ€é€‚åˆæ‚¨çš„å¼€å‘å †æ ˆï¼Œä¸ºä»€ä¹ˆå¼€æº Llama å¯¹ Meta æœ‰å¥½å¤„ï¼Œä»¥åŠä¸ºä»€ä¹ˆå¼€æºäººå·¥æ™ºèƒ½å¯¹ä¸–ç•Œæœ‰ç›Šï¼Œå› æ­¤æ˜¯ä¸€ä¸ªé•¿æœŸå­˜åœ¨çš„å¹³å°ã€‚</p> 
<p><strong>Why Open Source AI Is Good for Developers</strong></p> 
<p><strong>å¼€æºäººå·¥æ™ºèƒ½ä¹‹äºå¼€å‘è€…çš„ç›Šå¤„</strong></p> 
<p>When I talk to developers, CEOs, and government officials across the world, I usually hear several themes:</p> 
<p>å½“æˆ‘ä¸ä¸–ç•Œå„åœ°çš„å¼€å‘äººå‘˜ã€é¦–å¸­æ‰§è¡Œå®˜å’Œæ”¿åºœå®˜å‘˜äº¤è°ˆæ—¶ï¼Œé€šå¸¸ä¼šå¬åˆ°ä¸€äº›å…±åŒçš„ä¸»é¢˜ï¼š</p> 
<p>We need to train, fine-tune, and distill our own models. Every organization has different needs that are best met with models of different sizes that are trained or fine-tuned with their specific data. On-device tasks and classification tasks require small models, while more complicated tasks require larger models. Now youâ€™ll be able to take the most advanced Llama models, continue training them with your own data and then distill them down to a model of your optimal size â€“ without us or anyone else seeing your data.</p> 
<p>æˆ‘ä»¬éœ€è¦è®­ç»ƒã€å¾®è°ƒå’Œæç‚¼æˆ‘ä»¬è‡ªå·±çš„æ¨¡å‹ã€‚æ¯ä¸ªç»„ç»‡éƒ½æœ‰ä¸åŒçš„éœ€æ±‚ï¼Œæœ€å¥½ä½¿ç”¨ä¸åŒå°ºå¯¸çš„æ¨¡å‹æ¥æ»¡è¶³è¿™äº›éœ€æ±‚ï¼Œè¿™äº›æ¨¡å‹æ˜¯é€šè¿‡ç‰¹å®šæ•°æ®è¿›è¡Œè®­ç»ƒæˆ–å¾®è°ƒçš„ã€‚è®¾å¤‡ä¸Šçš„ä»»åŠ¡å’Œåˆ†ç±»ä»»åŠ¡éœ€è¦å°å‹æ¨¡å‹ï¼Œè€Œæ›´å¤æ‚çš„ä»»åŠ¡åˆ™éœ€è¦æ›´å¤§çš„æ¨¡å‹ã€‚ç°åœ¨ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨æœ€å…ˆè¿›çš„ Llama æ¨¡å‹ï¼Œç»§ç»­ä½¿ç”¨æ‚¨è‡ªå·±çš„æ•°æ®å¯¹å…¶è¿›è¡Œè®­ç»ƒï¼Œç„¶åå°†å…¶æç‚¼ä¸ºæ‚¨ç†æƒ³å°ºå¯¸çš„æ¨¡å‹ - è€Œæ— éœ€æˆ‘ä»¬æˆ–å…¶ä»–äººçœ‹åˆ°æ‚¨çš„æ•°æ®ã€‚</p> 
<p>We need to control our own destiny and not get locked into a closed vendor. Many organizations donâ€™t want to depend on models they cannot run and control themselves. They donâ€™t want closed model providers to be able to change their model, alter their terms of use, or even stop serving them entirely. They also donâ€™t want to get locked into a single cloud that has exclusive rights to a model. Open source enables a broad ecosystem of companies with compatible toolchains that you can move between easily.</p> 
<p>æˆ‘ä»¬éœ€è¦æŒæ§è‡ªå·±çš„å‘½è¿ï¼Œä¸è¦è¢«å›°åœ¨å°é—­çš„ä¾›åº”å•†ä¸­ã€‚è®¸å¤šç»„ç»‡ä¸æ„¿æ„ä¾èµ–ä»–ä»¬æ— æ³•è¿è¡Œå’Œæ§åˆ¶çš„æ¨¡å‹ã€‚ä»–ä»¬ä¸å¸Œæœ›å°é—­çš„æ¨¡å‹æä¾›å•†èƒ½å¤Ÿæ”¹å˜ä»–ä»¬çš„æ¨¡å‹ï¼Œä¿®æ”¹ä½¿ç”¨æ¡æ¬¾ï¼Œç”šè‡³å®Œå…¨åœæ­¢ä¸ºä»–ä»¬æä¾›æœåŠ¡ã€‚ä»–ä»¬ä¹Ÿä¸æƒ³è¢«é”å®šåœ¨ä¸€ä¸ªæ‹¥æœ‰æ¨¡å‹ç‹¬å®¶æƒåˆ©çš„å•ä¸€äº‘ä¸­ã€‚å¼€æºä½¿å¾—æœ‰å…¼å®¹å·¥å…·é“¾çš„å¹¿æ³›å…¬å¸ç”Ÿæ€ç³»ç»Ÿæˆä¸ºå¯èƒ½ï¼Œæ‚¨å¯ä»¥è½»æ¾åœ°åœ¨å®ƒä»¬ä¹‹é—´ç§»åŠ¨ã€‚</p> 
<p>We need to protect our data. Many organizations handle sensitive data that they need to secure and canâ€™t send to closed models over cloud APIs. Other organizations simply donâ€™t trust the closed model providers with their data. Open source addresses these issues by enabling you to run the models wherever you want. It is well-accepted that open source software tends to be more secure because it is developed more transparently.</p> 
<p>æˆ‘ä»¬éœ€è¦ä¿æŠ¤æˆ‘ä»¬çš„æ•°æ®ã€‚è®¸å¤šç»„ç»‡å¤„ç†æ•æ„Ÿæ•°æ®ï¼Œéœ€è¦ä¿æŠ¤å¹¶ä¸”ä¸èƒ½å°†å…¶å‘é€åˆ°äº‘ API ä¸Šçš„å°é—­æ¨¡å‹ã€‚å…¶ä»–ç»„ç»‡ç®€å•åœ°ä¸ä¿¡ä»»å°é—­æ¨¡å‹æä¾›å•†å¤„ç†ä»–ä»¬çš„æ•°æ®ã€‚å¼€æºé€šè¿‡ä½¿æ‚¨èƒ½å¤Ÿåœ¨ä»»ä½•åœ°æ–¹è¿è¡Œæ¨¡å‹æ¥è§£å†³è¿™äº›é—®é¢˜ã€‚ä¼—æ‰€å‘¨çŸ¥ï¼Œå¼€æºè½¯ä»¶å¾€å¾€æ›´å®‰å…¨ï¼Œå› ä¸ºå®ƒçš„å¼€å‘æ›´åŠ é€æ˜ã€‚</p> 
<p>We need a model that is efficient and affordable to run. Developers can run inference on Llama 3.1 405B on their own infra at roughly 50% the cost of using closed models like GPT-4o, for both user-facing and offline inference tasks.</p> 
<p>æˆ‘ä»¬éœ€è¦ä¸€ä¸ªé«˜æ•ˆä¸”ä»·æ ¼å®æƒ çš„æ¨¡å‹æ¥è¿è¡Œã€‚å¼€å‘è€…å¯ä»¥åœ¨ä»–ä»¬è‡ªå·±çš„åŸºç¡€è®¾æ–½ä¸Šè¿è¡Œ Llama 3.1 405B ä¸Šçš„æ¨ç†ï¼Œæˆæœ¬å¤§çº¦æ˜¯ä½¿ç”¨åƒ GPT-4o è¿™æ ·çš„å°é—­æ¨¡å‹çš„ 50%ï¼Œé€‚ç”¨äºç”¨æˆ·ç•Œé¢å’Œç¦»çº¿æ¨ç†ä»»åŠ¡ã€‚</p> 
<p>We want to invest in the ecosystem thatâ€™s going to be the standard for the long term. Lots of people see that open source is advancing at a faster rate than closed models, and they want to build their systems on the architecture that will give them the greatest advantage long term.</p> 
<p>æˆ‘ä»¬å¸Œæœ›æŠ•èµ„äºé‚£äº›å°†æˆä¸ºé•¿æœŸæ ‡å‡†çš„ç”Ÿæ€ç³»ç»Ÿã€‚è®¸å¤šäººè®¤ä¸ºå¼€æºå‘å±•é€Ÿåº¦æ¯”å°é—­æ¨¡å‹å¿«ï¼Œä»–ä»¬å¸Œæœ›åœ¨èƒ½å¤Ÿä¸ºä»–ä»¬æä¾›æœ€å¤§é•¿æœŸä¼˜åŠ¿çš„æ¶æ„ä¸Šæ„å»ºè‡ªå·±çš„ç³»ç»Ÿã€‚</p> 
<p><strong>Why Open Source AI Is Good for Meta</strong></p> 
<p><strong>ä¸ºä»€ä¹ˆå¼€æºäººå·¥æ™ºèƒ½å¯¹ Meta æœ‰ç›Š</strong></p> 
<p>Metaâ€™s business model is about building the best experiences and services for people. To do this, we must ensure that we always have access to the best technology, and that weâ€™re not locking into a competitorâ€™s closed ecosystem where they can restrict what we build.</p> 
<p>Meta çš„å•†ä¸šæ¨¡å¼æ˜¯è‡´åŠ›äºä¸ºäººä»¬æ‰“é€ æœ€ä½³ä½“éªŒå’ŒæœåŠ¡ã€‚ä¸ºäº†å®ç°è¿™ä¸€ç›®æ ‡ï¼Œæˆ‘ä»¬å¿…é¡»ç¡®ä¿å§‹ç»ˆèƒ½å¤Ÿè·å¾—æœ€å…ˆè¿›çš„æŠ€æœ¯ï¼Œé¿å…é™·å…¥ç«äº‰å¯¹æ‰‹çš„å°é—­ç”Ÿæ€ç³»ç»Ÿï¼Œä»–ä»¬å¯èƒ½ä¼šé™åˆ¶æˆ‘ä»¬çš„æ„å»ºã€‚</p> 
<p>One of my formative experiences has been building our services constrained by what Apple will let us build on their platforms. Between the way they tax developers, the arbitrary rules they apply, and all the product innovations they block from shipping, itâ€™s clear that Meta and many other companies would be freed up to build much better services for people if we could build the best versions of our products and competitors were not able to constrain what we could build. On a philosophical level, this is a major reason why I believe so strongly in building open ecosystems in AI and AR/VR for the next generation of computing.</p> 
<p>æˆ‘çš„ä¸€æ¬¡é‡è¦ç»å†æ˜¯åœ¨æˆ‘ä»¬çš„æœåŠ¡å—åˆ°è‹¹æœå¹³å°é™åˆ¶æ—¶å»ºè®¾ã€‚åœ¨ä»–ä»¬å¯¹å¼€å‘è€…å¾ç¨çš„æ–¹å¼ã€ä»–ä»¬æ–½åŠ çš„æ­¦æ–­è§„åˆ™ä»¥åŠé˜»æ­¢æˆ‘ä»¬æ¨å‡ºçš„æ‰€æœ‰äº§å“åˆ›æ–°ä¹‹é—´ï¼Œå¾ˆæ˜æ˜¾ï¼Œå¦‚æœæˆ‘ä»¬èƒ½å¤Ÿæ„å»ºæˆ‘ä»¬äº§å“çš„æœ€ä½³ç‰ˆæœ¬ä¸”ç«äº‰å¯¹æ‰‹æ— æ³•é™åˆ¶æˆ‘ä»¬çš„æ„å»ºï¼ŒMeta å’Œè®¸å¤šå…¶ä»–å…¬å¸å°†èƒ½å¤Ÿä¸ºäººä»¬æ„å»ºæ›´å¥½çš„æœåŠ¡ã€‚ä»å“²å­¦å±‚é¢ä¸Šè¯´ï¼Œè¿™æ˜¯æˆ‘åšä¿¡åœ¨ AI å’Œ AR/VR å¼€æ”¾ç”Ÿæ€ç³»ç»Ÿä¸­æ„å»ºä¸‹ä¸€ä»£è®¡ç®—çš„é‡è¦åŸå› ä¹‹ä¸€ã€‚</p> 
<p>People often ask if Iâ€™m worried about giving up a technical advantage by open sourcing Llama, but I think this misses the big picture for a few reasons:</p> 
<p>äººä»¬ç»å¸¸é—®æˆ‘æ˜¯å¦æ‹…å¿ƒé€šè¿‡å¼€æº Llama è€Œå¤±å»æŠ€æœ¯ä¼˜åŠ¿ï¼Œä½†æˆ‘è®¤ä¸ºè¿™æ ·åšå¿½ç•¥äº†æ›´é‡è¦çš„ä¸€äº›æ–¹é¢ï¼š</p> 
<p>First, to ensure that we have access to the best technology and arenâ€™t locked into a closed ecosystem over the long term, Llama needs to develop into a full ecosystem of tools, efficiency improvements, silicon optimizations, and other integrations. If we were the only company using Llama, this ecosystem wouldnâ€™t develop and weâ€™d fare no better than the closed variants of Unix.</p> 
<p>Second, I expect AI development will continue to be very competitive, which means that open sourcing any given model isnâ€™t giving away a massive advantage over the next best models at that point in time. The path for Llama to become the industry standard is by being consistently competitive, efficient, and open generation after generation.</p> 
<p>å…¶æ¬¡ï¼Œæˆ‘é¢„è®¡äººå·¥æ™ºèƒ½çš„å‘å±•å°†ç»§ç»­ä¿æŒç«äº‰æ¿€çƒˆï¼Œè¿™æ„å‘³ç€åœ¨æŸä¸€ç‰¹å®šæ—¶é—´ç‚¹å¼€æºä»»ä½•æ¨¡å‹å¹¶ä¸ä¼šç»™äºˆæ¯”ä¸‹ä¸€ä¸ªæœ€ä½³æ¨¡å‹æ›´å¤§çš„ä¼˜åŠ¿ã€‚Llama è¦æˆä¸ºè¡Œä¸šæ ‡å‡†ï¼Œå…³é”®åœ¨äºä¸€ä»£åˆä¸€ä»£åœ°ä¿æŒç«äº‰åŠ›ã€é«˜æ•ˆæ€§å’Œå¼€æ”¾æ€§ã€‚</p> 
<p>Third, a key difference between Meta and closed model providers is that selling access to AI models isnâ€™t our business model. That means openly releasing Llama doesnâ€™t undercut our revenue, sustainability, or ability to invest in research like it does for closed providers. (This is one reason several closed providers consistently lobby governments against open source.)</p> 
<p>ç¬¬ä¸‰ï¼ŒMeta å’Œå°é—­æ¨¡å‹æä¾›å•†ä¹‹é—´çš„ä¸€ä¸ªå…³é”®åŒºåˆ«æ˜¯ï¼Œå‡ºå”® AI æ¨¡å‹çš„è®¿é—®æƒé™å¹¶ä¸æ˜¯æˆ‘ä»¬çš„å•†ä¸šæ¨¡å¼ã€‚è¿™æ„å‘³ç€å…¬å¼€å‘å¸ƒ Llama å¹¶ä¸ä¼šæŸå®³æˆ‘ä»¬çš„æ”¶å…¥ã€å¯æŒç»­æ€§æˆ–ç ”ç©¶æŠ•èµ„èƒ½åŠ›ï¼Œå°±åƒå¯¹å°é—­æä¾›å•†é‚£æ ·ã€‚ï¼ˆè¿™ä¹Ÿæ˜¯å‡ å®¶å°é—­æä¾›å•†ä¸€ç›´åœ¨æ¸¸è¯´æ”¿åºœåå¯¹å¼€æºçš„åŸå› ä¹‹ä¸€ã€‚ï¼‰</p> 
<p>Finally, Meta has a long history of open source projects and successes. Weâ€™ve saved billions of dollars by releasing our server, network, and data center designs with Open Compute Project and having supply chains standardize on our designs. We benefited from the ecosystemâ€™s innovations by open sourcing leading tools like PyTorch, React, and many more tools. This approach has consistently worked for us when we stick with it over the long term.</p> 
<p>æœ€åï¼ŒMeta æ‹¥æœ‰æ‚ ä¹…çš„å¼€æºé¡¹ç›®å’ŒæˆåŠŸå†å²ã€‚é€šè¿‡ä¸ Open Compute Project å…±äº«æˆ‘ä»¬çš„æœåŠ¡å™¨ã€ç½‘ç»œå’Œæ•°æ®ä¸­å¿ƒè®¾è®¡ï¼Œå¹¶è®©ä¾›åº”é“¾æ ‡å‡†åŒ–æˆ‘ä»¬çš„è®¾è®¡ï¼Œæˆ‘ä»¬èŠ‚çœäº†æ•°åäº¿ç¾å…ƒã€‚æˆ‘ä»¬é€šè¿‡å¼€æºé¢†å…ˆå·¥å…·å¦‚ PyTorchã€React ç­‰å—ç›Šäºç”Ÿæ€ç³»ç»Ÿçš„åˆ›æ–°ã€‚é•¿æœŸåšæŒè¿™ç§æ–¹æ³•å¯¹æˆ‘ä»¬ä¸€ç›´æœ‰æ•ˆã€‚</p> 
<p><strong>Why Open Source AI Is Good for the World</strong></p> 
<p><strong>å¼€æºäººå·¥æ™ºèƒ½ä¹‹äºä¸–ç•Œçš„ç›Šå¤„</strong></p> 
<p>I believe that open source is necessary for a positive AI future. AI has more potential than any other modern technology to increase human productivity, creativity, and quality of life â€“ and to accelerate economic growth while unlocking progress in medical and scientific research. Open source will ensure that more people around the world have access to the benefits and opportunities of AI, that power isnâ€™t concentrated in the hands of a small number of companies, and that the technology can be deployed more evenly and safely across society.</p> 
<p>æˆ‘ç›¸ä¿¡å¼€æºå¯¹äºç§¯æçš„äººå·¥æ™ºèƒ½æœªæ¥æ˜¯å¿…è¦çš„ã€‚äººå·¥æ™ºèƒ½æ‹¥æœ‰æ¯”ä»»ä½•å…¶ä»–ç°ä»£æŠ€æœ¯æ›´å¤§çš„æ½œåŠ›ï¼Œå¯ä»¥æé«˜äººç±»çš„ç”Ÿäº§åŠ›ã€åˆ›é€ åŠ›å’Œç”Ÿæ´»è´¨é‡ï¼ŒåŠ é€Ÿç»æµå¢é•¿ï¼ŒåŒæ—¶åœ¨åŒ»å­¦å’Œç§‘å­¦ç ”ç©¶é¢†åŸŸæ¨åŠ¨è¿›å±•ã€‚å¼€æºå°†ç¡®ä¿å…¨çƒæ›´å¤šäººèƒ½å¤Ÿåˆ†äº«äººå·¥æ™ºèƒ½çš„å¥½å¤„å’Œæœºä¼šï¼Œé¿å…æƒåŠ›è¿‡åº¦é›†ä¸­åœ¨å°‘æ•°å…¬å¸æ‰‹ä¸­ï¼ŒåŒæ—¶å¯ä»¥æ›´å‡è¡¡ã€æ›´å®‰å…¨åœ°åœ¨ç¤¾ä¼šå„ä¸ªé¢†åŸŸæ¨å¹¿è¿™é¡¹æŠ€æœ¯ã€‚</p> 
<p>There is an ongoing debate about the safety of open source AI models, and my view is that open source AI will be safer than the alternatives. I think governments will conclude itâ€™s in their interest to support open source because it will make the world more prosperous and safer.</p> 
<p>ç›®å‰å­˜åœ¨å…³äºå¼€æº AI æ¨¡å‹å®‰å…¨æ€§çš„è¾©è®ºï¼Œæˆ‘è®¤ä¸ºå¼€æº AI å°†æ¯”å…¶ä»–é€‰æ‹©æ›´å®‰å…¨ã€‚æˆ‘è®¤ä¸ºå„å›½æ”¿åºœä¼šå¾—å‡ºç»“è®ºï¼Œæ”¯æŒå¼€æºç¬¦åˆä»–ä»¬çš„åˆ©ç›Šï¼Œå› ä¸ºè¿™å°†ä½¿ä¸–ç•Œæ›´åŠ ç¹è£å’Œå®‰å…¨ã€‚</p> 
<p>My framework for understanding safety is that we need to protect against two categories of harm: unintentional and intentional. Unintentional harm is when an AI system may cause harm even when it was not the intent of those running it to do so. For example, modern AI models may inadvertently give bad health advice. Or, in more futuristic scenarios, some worry that models may unintentionally self-replicate or hyper-optimize goals to the detriment of humanity. Intentional harm is when a bad actor uses an AI model with the goal of causing harm.</p> 
<p>æˆ‘å¯¹å®‰å…¨çš„ç†è§£æ¡†æ¶æ˜¯ï¼Œæˆ‘ä»¬éœ€è¦ä¿æŠ¤å…å—ä¸¤ç±»ä¼¤å®³ï¼šæ— æ„å’Œæœ‰æ„ã€‚æ— æ„ä¼¤å®³æ˜¯æŒ‡å½“äººå·¥æ™ºèƒ½ç³»ç»Ÿå¯èƒ½é€ æˆä¼¤å®³ï¼Œå³ä½¿è¿è¡Œå®ƒçš„äººå¹¶éæœ‰æ„è¿™æ ·åšã€‚ä¾‹å¦‚ï¼Œç°ä»£äººå·¥æ™ºèƒ½æ¨¡å‹å¯èƒ½æ— æ„ä¸­ç»™å‡ºé”™è¯¯çš„å¥åº·å»ºè®®ã€‚æˆ–è€…ï¼Œåœ¨æ›´å…·æœªæ¥æ„Ÿçš„åœºæ™¯ä¸­ï¼Œä¸€äº›äººæ‹…å¿ƒæ¨¡å‹å¯èƒ½æ— æ„ä¸­è‡ªæˆ‘å¤åˆ¶æˆ–è¿‡åº¦ä¼˜åŒ–ç›®æ ‡ï¼Œå¯¹äººç±»é€ æˆæŸå®³ã€‚æœ‰æ„ä¼¤å®³æ˜¯æŒ‡æ¶æ„ä½¿ç”¨äººå·¥æ™ºèƒ½æ¨¡å‹çš„åäººä»¥é€ æˆä¼¤å®³ã€‚</p> 
<p>Itâ€™s worth noting that unintentional harm covers the majority of concerns people have around AI â€“ ranging from what influence AI systems will have on the billions of people who will use them to most of the truly catastrophic science fiction scenarios for humanity. On this front, open source should be significantly safer since the systems are more transparent and can be widely scrutinized. Historically, open source software has been more secure for this reason. Similarly, using Llama with its safety systems like Llama Guard will likely be safer and more secure than closed models. For this reason, most conversations around open source AI safety focus on intentional harm.</p> 
<p>å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå¤§å¤šæ•°äººå¯¹äººå·¥æ™ºèƒ½çš„æ‹…å¿§ä¸»è¦é›†ä¸­åœ¨æ— æ„é€ æˆçš„ä¼¤å®³ä¸Š - ä» AI ç³»ç»Ÿå¯¹å°†ä½¿ç”¨å®ƒä»¬çš„æ•°åäº¿äººçš„å½±å“åˆ°äººç±»å¤§éƒ¨åˆ†çœŸæ­£ç¾éš¾æ€§çš„ç§‘å¹»åœºæ™¯ã€‚åœ¨è¿™æ–¹é¢ï¼Œå¼€æºåº”è¯¥æ›´å®‰å…¨ï¼Œå› ä¸ºè¿™äº›ç³»ç»Ÿæ›´åŠ é€æ˜ï¼Œå¯ä»¥è¢«å¹¿æ³›å®¡æŸ¥ã€‚ä»å†å²ä¸Šçœ‹ï¼Œå‡ºäºè¿™ä¸ªåŸå› ï¼Œå¼€æºè½¯ä»¶æ›´å®‰å…¨ã€‚åŒæ ·ï¼Œä½¿ç”¨å¸¦æœ‰ Llama Guard ç­‰å®‰å…¨ç³»ç»Ÿçš„ Llama å¯èƒ½æ¯”å°é—­æ¨¡å‹æ›´å®‰å…¨ã€æ›´å¯é ã€‚å› æ­¤ï¼Œå¤§å¤šæ•°å…³äºå¼€æº AI å®‰å…¨çš„è®¨è®ºéƒ½é›†ä¸­åœ¨æœ‰æ„é€ æˆçš„ä¼¤å®³ä¸Šã€‚</p> 
<p>Our safety process includes rigorous testing and red-teaming to assess whether our models are capable of meaningful harm, with the goal of mitigating risks before release. Since the models are open, anyone is capable of testing for themselves as well. We must keep in mind that these models are trained by information thatâ€™s already on the internet, so the starting point when considering harm should be whether a model can facilitate more harm than information that can quickly be retrieved from Google or other search results.</p> 
<p>æˆ‘ä»¬çš„å®‰å…¨æµç¨‹åŒ…æ‹¬ä¸¥æ ¼æµ‹è¯•å’Œçº¢é˜Ÿè¯„ä¼°ï¼Œä»¥è¯„ä¼°æˆ‘ä»¬çš„æ¨¡å‹æ˜¯å¦æœ‰é€ æˆå®è´¨æ€§å±å®³çš„èƒ½åŠ›ï¼Œç›®æ ‡æ˜¯åœ¨å‘å¸ƒä¹‹å‰å‡è½»é£é™©ã€‚ç”±äºè¿™äº›æ¨¡å‹æ˜¯å¼€æ”¾çš„ï¼Œä»»ä½•äººéƒ½å¯ä»¥è‡ªè¡Œæµ‹è¯•ã€‚æˆ‘ä»¬å¿…é¡»è®°ä½ï¼Œè¿™äº›æ¨¡å‹æ˜¯é€šè¿‡å·²ç»åœ¨äº’è”ç½‘ä¸Šçš„ä¿¡æ¯è¿›è¡Œè®­ç»ƒçš„ï¼Œå› æ­¤åœ¨è€ƒè™‘å±å®³æ—¶çš„èµ·ç‚¹åº”è¯¥æ˜¯æ¨¡å‹æ˜¯å¦èƒ½æ¯”å¯ä»¥ä»è°·æ­Œæˆ–å…¶ä»–æœç´¢ç»“æœä¸­å¿«é€Ÿè·å–çš„ä¿¡æ¯å¸¦æ¥æ›´å¤šå±å®³ã€‚</p> 
<p>When reasoning about intentional harm, itâ€™s helpful to distinguish between what individual or small scale actors may be able to do as opposed to what large scale actors like nation states with vast resources may be able to do.</p> 
<p>åœ¨æ€è€ƒæœ‰æ„å›¾çš„ä¼¤å®³æ—¶ï¼Œæœ‰åŠ©äºåŒºåˆ†ä¸ªäººæˆ–å°è§„æ¨¡è¡Œä¸ºè€…å¯èƒ½é‡‡å–çš„è¡ŒåŠ¨ï¼Œä¸æ‹¥æœ‰åºå¤§èµ„æºçš„å›½å®¶ç­‰å¤§è§„æ¨¡è¡Œä¸ºè€…å¯èƒ½é‡‡å–çš„è¡ŒåŠ¨ã€‚</p> 
<p>At some point in the future, individual bad actors may be able to use the intelligence of AI models to fabricate entirely new harms from the information available on the internet. At this point, the balance of power will be critical to AI safety. I think it will be better to live in a world where AI is widely deployed so that larger actors can check the power of smaller bad actors. This is how weâ€™ve managed security on our social networks â€“ our more robust AI systems identify and stop threats from less sophisticated actors who often use smaller scale AI systems. More broadly, larger institutions deploying AI at scale will promote security and stability across society. As long as everyone has access to similar generations of models â€“ which open source promotes â€“ then governments and institutions with more compute resources will be able to check bad actors with less compute.</p> 
<p>åœ¨æœªæ¥çš„æŸä¸ªæ—¶å€™ï¼Œä¸ªåˆ«ä¸è‰¯åˆ†å­å¯èƒ½ä¼šåˆ©ç”¨äººå·¥æ™ºèƒ½æ¨¡å‹çš„æ™ºèƒ½ï¼Œä»äº’è”ç½‘ä¸Šå¯è·å¾—çš„ä¿¡æ¯ä¸­åˆ¶é€ å…¨æ–°çš„å±å®³ã€‚åœ¨è¿™ä¸€ç‚¹ä¸Šï¼ŒæƒåŠ›çš„å¹³è¡¡å¯¹äººå·¥æ™ºèƒ½å®‰å…¨è‡³å…³é‡è¦ã€‚æˆ‘è®¤ä¸ºç”Ÿæ´»åœ¨ä¸€ä¸ªäººå·¥æ™ºèƒ½å¹¿æ³›éƒ¨ç½²çš„ä¸–ç•Œä¼šæ›´å¥½ï¼Œè¿™æ ·æ›´å¤§çš„è¡ŒåŠ¨è€…å¯ä»¥åˆ¶çº¦è¾ƒå°çš„ä¸è‰¯åˆ†å­çš„æƒåŠ›ã€‚è¿™å°±æ˜¯æˆ‘ä»¬åœ¨ç¤¾äº¤ç½‘ç»œä¸Šç®¡ç†å®‰å…¨çš„æ–¹å¼â€”â€”æˆ‘ä»¬æ›´å¼ºå¤§çš„äººå·¥æ™ºèƒ½ç³»ç»Ÿè¯†åˆ«å¹¶é˜»æ­¢é‚£äº›ç»å¸¸ä½¿ç”¨è¾ƒå°è§„æ¨¡äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„ä¸é‚£ä¹ˆå¤æ‚çš„è¡ŒåŠ¨è€…çš„å¨èƒã€‚æ›´å¹¿æ³›åœ°è¯´ï¼Œå¤§å‹æœºæ„å¤§è§„æ¨¡éƒ¨ç½²äººå·¥æ™ºèƒ½å°†ä¿ƒè¿›ç¤¾ä¼šçš„å®‰å…¨å’Œç¨³å®šã€‚åªè¦æ¯ä¸ªäººéƒ½èƒ½è®¿é—®ç›¸ä¼¼ä¸–ä»£çš„æ¨¡å‹ - è¿™æ­£æ˜¯å¼€æºæ‰€å€¡å¯¼çš„ - é‚£ä¹ˆæ‹¥æœ‰æ›´å¤šè®¡ç®—èµ„æºçš„æ”¿åºœå’Œæœºæ„å°±èƒ½å¤Ÿç”¨æ›´å°‘çš„è®¡ç®—èµ„æºæ¥å®¡æŸ¥ä¸è‰¯è¡Œä¸ºè€…ã€‚</p> 
<p>The next question is how the US and democratic nations should handle the threat of states with massive resources like China. The United Statesâ€™ advantage is decentralized and open innovation. Some people argue that we must close our models to prevent China from gaining access to them, but my view is that this will not work and will only disadvantage the US and its allies. Our adversaries are great at espionage, stealing models that fit on a thumb drive is relatively easy, and most tech companies are far from operating in a way that would make this more difficult. It seems most likely that a world of only closed models results in a small number of big companies plus our geopolitical adversaries having access to leading models, while startups, universities, and small businesses miss out on opportunities. Plus, constraining American innovation to closed development increases the chance that we donâ€™t lead at all. Instead, I think our best strategy is to build a robust open ecosystem and have our leading companies work closely with our government and allies to ensure they can best take advantage of the latest advances and achieve a sustainable first-mover advantage over the long term.</p> 
<p>ç¾å›½å’Œæ°‘ä¸»å›½å®¶åº”è¯¥å¦‚ä½•åº”å¯¹åƒä¸­å›½è¿™æ ·æ‹¥æœ‰å¤§é‡èµ„æºçš„å›½å®¶çš„å¨èƒæ˜¯ä¸‹ä¸€ä¸ªé—®é¢˜ã€‚ç¾å›½çš„ä¼˜åŠ¿åœ¨äºåˆ†æ•£å’Œå¼€æ”¾çš„åˆ›æ–°ã€‚æœ‰äººè®¤ä¸ºæˆ‘ä»¬å¿…é¡»å…³é—­æˆ‘ä»¬çš„æ¨¡å¼ï¼Œä»¥é˜²æ­¢ä¸­å›½è·å¾—å¯¹å®ƒä»¬çš„è®¿é—®ï¼Œä½†æˆ‘è®¤ä¸ºè¿™ä¸ä¼šå¥æ•ˆï¼Œåªä¼šç»™ç¾å›½åŠå…¶ç›Ÿå‹å¸¦æ¥ä¸åˆ©ã€‚æˆ‘ä»¬çš„å¯¹æ‰‹æ“…é•¿é—´è°æ´»åŠ¨ï¼Œçªƒå–é€‚åˆæ”¾åœ¨ä¸€ä¸ªæ‹‡æŒ‡é©±åŠ¨å™¨ä¸Šçš„æ¨¡å¼ç›¸å¯¹å®¹æ˜“ï¼Œè€Œå¤§å¤šæ•°ç§‘æŠ€å…¬å¸è¿œæœªä»¥ä½¿è¿™æ›´åŠ å›°éš¾çš„æ–¹å¼è¿ä½œã€‚ä¼¼ä¹æœ€æœ‰å¯èƒ½çš„æƒ…å†µæ˜¯ï¼Œåªæœ‰å°é—­æ¨¡å‹çš„ä¸–ç•Œä¼šå¯¼è‡´å°‘æ•°å‡ å®¶å¤§å…¬å¸ä»¥åŠæˆ‘ä»¬çš„åœ°ç¼˜æ”¿æ²»å¯¹æ‰‹èƒ½å¤Ÿè®¿é—®é¢†å…ˆçš„æ¨¡å‹ï¼Œè€Œåˆåˆ›å…¬å¸ã€å¤§å­¦å’Œå°å‹ä¼ä¸šåˆ™é”™å¤±æœºä¼šã€‚æ­¤å¤–ï¼Œå°†ç¾å›½çš„åˆ›æ–°é™åˆ¶åœ¨å°é—­å¼€å‘ä¸­ä¼šå¢åŠ æˆ‘ä»¬æ ¹æœ¬æ— æ³•é¢†å…ˆçš„å¯èƒ½æ€§ã€‚ç›¸åï¼Œæˆ‘è®¤ä¸ºæˆ‘ä»¬æœ€å¥½çš„ç­–ç•¥æ˜¯å»ºç«‹ä¸€ä¸ªå¼ºå¤§çš„å¼€æ”¾ç”Ÿæ€ç³»ç»Ÿï¼Œå¹¶è®©æˆ‘ä»¬é¢†å…ˆçš„å…¬å¸ä¸æˆ‘ä»¬çš„æ”¿åºœå’Œç›Ÿå‹å¯†åˆ‡åˆä½œï¼Œç¡®ä¿ä»–ä»¬èƒ½å¤Ÿæœ€å¥½åœ°åˆ©ç”¨æœ€æ–°è¿›å±•ï¼Œå¹¶åœ¨é•¿æœŸå†…å–å¾—å¯æŒç»­çš„å…ˆå‘ä¼˜åŠ¿ã€‚</p> 
<p>When you consider the opportunities ahead, remember that most of todayâ€™s leading tech companies and scientific research are built on open source software. The next generation of companies and research will use open source AI if we collectively invest in it. That includes startups just getting off the ground as well as people in universities and countries that may not have the resources to develop their own state-of-the-art AI from scratch.</p> 
<p>åœ¨è€ƒè™‘æœªæ¥çš„æœºé‡æ—¶ï¼Œè¯·è®°ä½ï¼Œä»Šå¤©å¤§å¤šæ•°é¢†å…ˆçš„ç§‘æŠ€å…¬å¸å’Œç§‘å­¦ç ”ç©¶éƒ½æ˜¯å»ºç«‹åœ¨å¼€æºè½¯ä»¶çš„åŸºç¡€ä¸Šçš„ã€‚å¦‚æœæˆ‘ä»¬å…±åŒæŠ•èµ„äºå¼€æºäººå·¥æ™ºèƒ½ï¼Œä¸‹ä¸€ä»£å…¬å¸å’Œç ”ç©¶å°†ä½¿ç”¨å¼€æºäººå·¥æ™ºèƒ½ã€‚è¿™åŒ…æ‹¬åˆšåˆšèµ·æ­¥çš„åˆåˆ›å…¬å¸ï¼Œä»¥åŠé‚£äº›å¯èƒ½æ²¡æœ‰èµ„æºä»å¤´å¼€å§‹å¼€å‘è‡ªå·±æœ€å…ˆè¿›äººå·¥æ™ºèƒ½çš„å¤§å­¦å’Œå›½å®¶çš„äººã€‚</p> 
<p>The bottom line is that open source AI represents the worldâ€™s best shot at harnessing this technology to create the greatest economic opportunity and security for everyone.</p> 
<p>å¼€æºäººå·¥æ™ºèƒ½ä»£è¡¨ç€ä¸–ç•Œæœ€å¥½çš„æœºä¼šï¼Œåˆ©ç”¨è¿™é¡¹æŠ€æœ¯åˆ›é€ æœ€å¤§çš„ç»æµæœºä¼šå’Œå®‰å…¨ä¿éšœã€‚</p> 
<p><strong>Letâ€™s Build This Together</strong></p> 
<p><strong>è®©æˆ‘ä»¬ä¸€èµ·å»ºè®¾è¿™ä¸ªé¡¹ç›®</strong></p> 
<p>With past Llama models, Meta developed them for ourselves and then released them, but didnâ€™t focus much on building a broader ecosystem. Weâ€™re taking a different approach with this release. Weâ€™re building teams internally to enable as many developers and partners as possible to use Llama, and weâ€™re actively building partnerships so that more companies in the ecosystem can offer unique functionality to their customers as well.</p> 
<p>åœ¨è¿‡å»çš„ç¾Šé©¼æ¨¡å‹ä¸­ï¼ŒMeta ä¸ºæˆ‘ä»¬è‡ªå·±å¼€å‘äº†å®ƒä»¬ï¼Œç„¶åå‘å¸ƒï¼Œä½†å¹¶æ²¡æœ‰è¿‡å¤šå…³æ³¨æ„å»ºæ›´å¹¿æ³›çš„ç”Ÿæ€ç³»ç»Ÿã€‚è¿™æ¬¡å‘å¸ƒæˆ‘ä»¬é‡‡å–äº†ä¸åŒçš„æ–¹å¼ã€‚æˆ‘ä»¬æ­£åœ¨å†…éƒ¨å»ºç«‹å›¢é˜Ÿï¼Œä»¥ä½¿å°½å¯èƒ½å¤šçš„å¼€å‘äººå‘˜å’Œåˆä½œä¼™ä¼´ä½¿ç”¨ç¾Šé©¼ï¼Œå¹¶ç§¯æå»ºç«‹åˆä½œå…³ç³»ï¼Œä»¥ä¾¿ç”Ÿæ€ç³»ç»Ÿä¸­æ›´å¤šå…¬å¸ä¹Ÿèƒ½ä¸ºå…¶å®¢æˆ·æä¾›ç‹¬ç‰¹åŠŸèƒ½ã€‚</p> 
<p>I believe the Llama 3.1 release will be an inflection point in the industry where most developers begin to primarily use open source, and I expect that approach to only grow from here. I hope youâ€™ll join us on this journey to bring the benefits of AI to everyone in the world.</p> 
<p>æˆ‘ç›¸ä¿¡ Llama 3.1 ç‰ˆæœ¬å°†æˆä¸ºè¡Œä¸šçš„ä¸€ä¸ªè½¬æŠ˜ç‚¹ï¼Œå¤§å¤šæ•°å¼€å‘äººå‘˜å°†å¼€å§‹ä¸»è¦ä½¿ç”¨å¼€æºï¼Œæˆ‘æœŸå¾…è¿™ç§æ–¹æ³•ä»è¿™é‡Œå¼€å§‹ä¸æ–­å¢é•¿ã€‚å¸Œæœ›æ‚¨èƒ½åŠ å…¥æˆ‘ä»¬ï¼Œä¸€èµ·åŠªåŠ›å°†äººå·¥æ™ºèƒ½çš„å¥½å¤„å¸¦ç»™ä¸–ç•Œä¸Šçš„æ¯ä¸ªäººã€‚</p> 
<p><strong>è¯»è€…ç¦åˆ©ï¼šå¦‚æœå¤§å®¶å¯¹å¤§æ¨¡å‹æ„Ÿå…´è¶£ï¼Œè¿™å¥—å¤§æ¨¡å‹å­¦ä¹ èµ„æ–™ä¸€å®šå¯¹ä½ æœ‰ç”¨</strong></p> 
<p><strong>å¯¹äº0åŸºç¡€å°ç™½å…¥é—¨ï¼š</strong></p> 
<blockquote> 
 <p>å¦‚æœä½ æ˜¯é›¶åŸºç¡€å°ç™½ï¼Œæƒ³å¿«é€Ÿå…¥é—¨å¤§æ¨¡å‹æ˜¯å¯ä»¥è€ƒè™‘çš„ã€‚</p> 
 <p>ä¸€æ–¹é¢æ˜¯å­¦ä¹ æ—¶é—´ç›¸å¯¹è¾ƒçŸ­ï¼Œå­¦ä¹ å†…å®¹æ›´å…¨é¢æ›´é›†ä¸­ã€‚<br> äºŒæ–¹é¢æ˜¯å¯ä»¥æ ¹æ®è¿™äº›èµ„æ–™è§„åˆ’å¥½å­¦ä¹ è®¡åˆ’å’Œæ–¹å‘ã€‚</p> 
</blockquote> 
<p>åŒ…æ‹¬ï¼šå¤§æ¨¡å‹å­¦ä¹ çº¿è·¯æ±‡æ€»ã€å­¦ä¹ é˜¶æ®µï¼Œå¤§æ¨¡å‹å®æˆ˜æ¡ˆä¾‹ï¼Œå¤§æ¨¡å‹å­¦ä¹ è§†é¢‘ï¼Œäººå·¥æ™ºèƒ½ã€æœºå™¨å­¦ä¹ ã€å¤§æ¨¡å‹ä¹¦ç±PDFã€‚å¸¦ä½ ä»é›¶åŸºç¡€ç³»ç»Ÿæ€§çš„å­¦å¥½å¤§æ¨¡å‹ï¼</p> 
<p>ğŸ˜æœ‰éœ€è¦çš„å°ä¼™ä¼´ï¼Œå¯ä»¥ä¿å­˜å›¾ç‰‡åˆ°<strong>wxæ‰«æäºŒvç </strong>å…è´¹é¢†å–ã€<code>ä¿è¯100%å…è´¹</code>ã€‘ğŸ†“<br> <img src="https://images2.imgbox.com/60/6c/34SrQcFu_o.png"></p> 
<h5><a id="httpsblogcsdnnet2301_76168381articledetails137261875ops_request_miscrequest_idbiz_id102utm_termE5A4A7E6A8A1E59E8Butm_mediumdistributepc_search_resultnonetaskblog2allsobaiduwebdefault0137261875142v100pc_search_result_base4spm1018222630014187AI_418"></a><a href="https://blog.csdn.net/2301_76168381/article/details/137261875?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=%E5%A4%A7%E6%A8%A1%E5%9E%8B&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-0-137261875.142%5Ev100%5Epc_search_result_base4&amp;spm=1018.2226.3001.4187"></a>ğŸ‘‰AIå¤§æ¨¡å‹å­¦ä¹ è·¯çº¿æ±‡æ€»ğŸ‘ˆ</h5> 
<p>å¤§æ¨¡å‹å­¦ä¹ è·¯çº¿å›¾ï¼Œæ•´ä½“åˆ†ä¸º7ä¸ªå¤§çš„é˜¶æ®µï¼š<strong>ï¼ˆå…¨å¥—æ•™ç¨‹æ–‡æœ«é¢†å–å“ˆï¼‰</strong><br> <img src="https://images2.imgbox.com/4f/4b/OcJ6TSGu_o.png" alt="                                                   "><br> <strong>ç¬¬ä¸€é˜¶æ®µï¼š</strong> ä»å¤§æ¨¡å‹ç³»ç»Ÿè®¾è®¡å…¥æ‰‹ï¼Œè®²è§£å¤§æ¨¡å‹çš„ä¸»è¦æ–¹æ³•ï¼›</p> 
<p><strong>ç¬¬äºŒé˜¶æ®µï¼š</strong> åœ¨é€šè¿‡å¤§æ¨¡å‹æç¤ºè¯å·¥ç¨‹ä»Promptsè§’åº¦å…¥æ‰‹æ›´å¥½å‘æŒ¥æ¨¡å‹çš„ä½œç”¨ï¼›</p> 
<p><strong>ç¬¬ä¸‰é˜¶æ®µï¼š</strong> å¤§æ¨¡å‹å¹³å°åº”ç”¨å¼€å‘å€ŸåŠ©é˜¿é‡Œäº‘PAIå¹³å°æ„å»ºç”µå•†é¢†åŸŸè™šæ‹Ÿè¯•è¡£ç³»ç»Ÿï¼›</p> 
<p><strong>ç¬¬å››é˜¶æ®µï¼š</strong> å¤§æ¨¡å‹çŸ¥è¯†åº“åº”ç”¨å¼€å‘ä»¥LangChainæ¡†æ¶ä¸ºä¾‹ï¼Œæ„å»ºç‰©æµè¡Œä¸šå’¨è¯¢æ™ºèƒ½é—®ç­”ç³»ç»Ÿï¼›</p> 
<p><strong>ç¬¬äº”é˜¶æ®µï¼š</strong> å¤§æ¨¡å‹å¾®è°ƒå¼€å‘å€ŸåŠ©ä»¥å¤§å¥åº·ã€æ–°é›¶å”®ã€æ–°åª’ä½“é¢†åŸŸæ„å»ºé€‚åˆå½“å‰é¢†åŸŸå¤§æ¨¡å‹ï¼›</p> 
<p><strong>ç¬¬å…­é˜¶æ®µï¼š</strong> ä»¥SDå¤šæ¨¡æ€å¤§æ¨¡å‹ä¸ºä¸»ï¼Œæ­å»ºäº†æ–‡ç”Ÿå›¾å°ç¨‹åºæ¡ˆä¾‹ï¼›</p> 
<p><strong>ç¬¬ä¸ƒé˜¶æ®µï¼š</strong> ä»¥å¤§æ¨¡å‹å¹³å°åº”ç”¨ä¸å¼€å‘ä¸ºä¸»ï¼Œé€šè¿‡æ˜Ÿç«å¤§æ¨¡å‹ï¼Œæ–‡å¿ƒå¤§æ¨¡å‹ç­‰æˆç†Ÿå¤§æ¨¡å‹æ„å»ºå¤§æ¨¡å‹è¡Œä¸šåº”ç”¨ã€‚</p> 
<h4><a id="httpsblogcsdnnet2301_76168381articledetails137261875ops_request_miscrequest_idbiz_id102utm_termE5A4A7E6A8A1E59E8Butm_mediumdistributepc_search_resultnonetaskblog2allsobaiduwebdefault0137261875142v100pc_search_result_base4spm1018222630014187_436"></a><a href="https://blog.csdn.net/2301_76168381/article/details/137261875?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=%E5%A4%A7%E6%A8%A1%E5%9E%8B&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-0-137261875.142%5Ev100%5Epc_search_result_base4&amp;spm=1018.2226.3001.4187"></a>ğŸ‘‰å¤§æ¨¡å‹å®æˆ˜æ¡ˆä¾‹ğŸ‘ˆ</h4> 
<p>å…‰å­¦ç†è®ºæ˜¯æ²¡ç”¨çš„ï¼Œè¦å­¦ä¼šè·Ÿç€ä¸€èµ·åšï¼Œè¦åŠ¨æ‰‹å®æ“ï¼Œæ‰èƒ½å°†è‡ªå·±çš„æ‰€å­¦è¿ç”¨åˆ°å®é™…å½“ä¸­å»ï¼Œè¿™æ—¶å€™å¯ä»¥æç‚¹å®æˆ˜æ¡ˆä¾‹æ¥å­¦ä¹ ã€‚</p> 
<p><img src="https://images2.imgbox.com/01/e1/bGB0stbB_o.jpg" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<h4><a id="httpsblogcsdnnet2301_76168381articledetails137261875ops_request_miscrequest_idbiz_id102utm_termE5A4A7E6A8A1E59E8Butm_mediumdistributepc_search_resultnonetaskblog2allsobaiduwebdefault0137261875142v100pc_search_result_base4spm1018222630014187PDF_442"></a><a href="https://blog.csdn.net/2301_76168381/article/details/137261875?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=%E5%A4%A7%E6%A8%A1%E5%9E%8B&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-0-137261875.142%5Ev100%5Epc_search_result_base4&amp;spm=1018.2226.3001.4187"></a>ğŸ‘‰å¤§æ¨¡å‹è§†é¢‘å’ŒPDFåˆé›†ğŸ‘ˆ</h4> 
<p>è§‚çœ‹é›¶åŸºç¡€å­¦ä¹ ä¹¦ç±å’Œè§†é¢‘ï¼Œçœ‹ä¹¦ç±å’Œè§†é¢‘å­¦ä¹ æ˜¯æœ€å¿«æ·ä¹Ÿæ˜¯æœ€æœ‰æ•ˆæœçš„æ–¹å¼ï¼Œè·Ÿç€è§†é¢‘ä¸­è€å¸ˆçš„æ€è·¯ï¼Œä»åŸºç¡€åˆ°æ·±å…¥ï¼Œè¿˜æ˜¯å¾ˆå®¹æ˜“å…¥é—¨çš„ã€‚<br> <img src="https://images2.imgbox.com/5c/cb/JyjcKncq_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"><br> <img src="https://images2.imgbox.com/77/7c/M6D94jOJ_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<h4><a id="httpsblogcsdnnet2301_76168381articledetails137261875ops_request_miscrequest_idbiz_id102utm_termE5A4A7E6A8A1E59E8Butm_mediumdistributepc_search_resultnonetaskblog2allsobaiduwebdefault0137261875142v100pc_search_result_base4spm1018222630014187_448"></a><a href="https://blog.csdn.net/2301_76168381/article/details/137261875?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=%E5%A4%A7%E6%A8%A1%E5%9E%8B&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-0-137261875.142%5Ev100%5Epc_search_result_base4&amp;spm=1018.2226.3001.4187"></a>ğŸ‘‰å­¦ä¼šåçš„æ”¶è·ï¼šğŸ‘ˆ</h4> 
<p><strong>â€¢ åŸºäºå¤§æ¨¡å‹å…¨æ ˆå·¥ç¨‹å®ç°</strong>ï¼ˆå‰ç«¯ã€åç«¯ã€äº§å“ç»ç†ã€è®¾è®¡ã€æ•°æ®åˆ†æç­‰ï¼‰ï¼Œé€šè¿‡è¿™é—¨è¯¾å¯è·å¾—ä¸åŒèƒ½åŠ›ï¼›</p> 
<p><strong>â€¢ èƒ½å¤Ÿåˆ©ç”¨å¤§æ¨¡å‹è§£å†³ç›¸å…³å®é™…é¡¹ç›®éœ€æ±‚ï¼š</strong> å¤§æ•°æ®æ—¶ä»£ï¼Œè¶Šæ¥è¶Šå¤šçš„ä¼ä¸šå’Œæœºæ„éœ€è¦å¤„ç†æµ·é‡æ•°æ®ï¼Œåˆ©ç”¨å¤§æ¨¡å‹æŠ€æœ¯å¯ä»¥æ›´å¥½åœ°å¤„ç†è¿™äº›æ•°æ®ï¼Œæé«˜æ•°æ®åˆ†æå’Œå†³ç­–çš„å‡†ç¡®æ€§ã€‚å› æ­¤ï¼ŒæŒæ¡å¤§æ¨¡å‹åº”ç”¨å¼€å‘æŠ€èƒ½ï¼Œå¯ä»¥è®©ç¨‹åºå‘˜æ›´å¥½åœ°åº”å¯¹å®é™…é¡¹ç›®éœ€æ±‚ï¼›</p> 
<p>â€¢ åŸºäºå¤§æ¨¡å‹å’Œä¼ä¸šæ•°æ®AIåº”ç”¨å¼€å‘ï¼Œ<strong>å®ç°å¤§æ¨¡å‹ç†è®ºã€æŒæ¡GPUç®—åŠ›ã€ç¡¬ä»¶ã€LangChainå¼€å‘æ¡†æ¶å’Œé¡¹ç›®å®æˆ˜æŠ€èƒ½ï¼Œ</strong> å­¦ä¼šFine-tuningå‚ç›´è®­ç»ƒå¤§æ¨¡å‹ï¼ˆæ•°æ®å‡†å¤‡ã€æ•°æ®è’¸é¦ã€å¤§æ¨¡å‹éƒ¨ç½²ï¼‰ä¸€ç«™å¼æŒæ¡ï¼›</p> 
<p><strong>â€¢ èƒ½å¤Ÿå®Œæˆæ—¶ä¸‹çƒ­é—¨å¤§æ¨¡å‹å‚ç›´é¢†åŸŸæ¨¡å‹è®­ç»ƒèƒ½åŠ›ï¼Œæé«˜ç¨‹åºå‘˜çš„ç¼–ç èƒ½åŠ›ï¼š</strong> å¤§æ¨¡å‹åº”ç”¨å¼€å‘éœ€è¦æŒæ¡æœºå™¨å­¦ä¹ ç®—æ³•ã€æ·±åº¦å­¦ä¹ æ¡†æ¶ç­‰æŠ€æœ¯ï¼Œè¿™äº›æŠ€æœ¯çš„æŒæ¡å¯ä»¥æé«˜ç¨‹åºå‘˜çš„ç¼–ç èƒ½åŠ›å’Œåˆ†æèƒ½åŠ›ï¼Œè®©ç¨‹åºå‘˜æ›´åŠ ç†Ÿç»ƒåœ°ç¼–å†™é«˜è´¨é‡çš„ä»£ç ã€‚</p> 
<h4><a id="httpsblogcsdnnet2301_76168381articledetails137261875ops_request_miscrequest_idbiz_id102utm_termE5A4A7E6A8A1E59E8Butm_mediumdistributepc_search_resultnonetaskblog2allsobaiduwebdefault0137261875142v100pc_search_result_base4spm1018222630014187_458"></a><a href="https://blog.csdn.net/2301_76168381/article/details/137261875?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=%E5%A4%A7%E6%A8%A1%E5%9E%8B&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-0-137261875.142%5Ev100%5Epc_search_result_base4&amp;spm=1018.2226.3001.4187"></a>ğŸ‘‰è·å–æ–¹å¼ï¼š</h4> 
<p>ğŸ˜æœ‰éœ€è¦çš„å°ä¼™ä¼´ï¼Œå¯ä»¥ä¿å­˜å›¾ç‰‡åˆ°<strong>wxæ‰«æäºŒvç </strong>å…è´¹é¢†å–ã€<code>ä¿è¯100%å…è´¹</code>ã€‘ğŸ†“<br> <img src="https://images2.imgbox.com/0c/37/uNtVtxbK_o.png"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/a341e2e68e642d9ac1d5b74f3344dc61/" rel="prev">
			<span class="pager__subtitle">Â«&thinsp;Previous</span>
			<p class="pager__title">å®‰å“æ‰‹æœºéƒ¨ç½²å¤§æ¨¡å‹å®æˆ˜</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/d7a7425be1ac0b079470ea63b7f379e1/" rel="next">
			<span class="pager__subtitle">Next&thinsp;Â»</span>
			<p class="pager__title">Java-æ ¹æ®å‰ç¼€-æ—¥æœŸ-æ•°å­—-ç”Ÿæˆæµæ°´å·ï¼ˆä¸é‡å¤ï¼‰</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 ç¼–ç¨‹å¤§å’–.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>